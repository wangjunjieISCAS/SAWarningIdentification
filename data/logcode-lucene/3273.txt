GitDiffStart: 3aa18151b365b83a6aef5b75d523561176b54c73 | Mon Jun 15 11:01:14 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index ebdc41d..0173c45 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -75,6 +75,13 @@ New Features
 * LUCENE-6504: Add Lucene53Codec, with norms implemented directly
   via the Directory's RandomAccessInput api. (Robert Muir)
 
+* LUCENE-6539: Add new DocValuesNumbersQuery, to match any document
+  containing one of the specified long values.  This change also
+  moves the existing DocValuesTermsQuery and DocValuesRangeQuery
+  to Lucene's sandbox module, since in general these queries are
+  quite slow and are only fast in specific cases.  (Adrien Grand,
+  Robert Muir, Mike McCandless)
+
 API Changes
 
 * LUCENE-6508: Simplify Lock api, there is now just 
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationDocValuesField.java b/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationDocValuesField.java
index ef3423d..5324a41 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationDocValuesField.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/collation/CollationDocValuesField.java
@@ -21,7 +21,6 @@ import java.text.Collator;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.search.DocValuesRangeQuery;
 import org.apache.lucene.util.BytesRef;
 
 /**
@@ -29,7 +28,7 @@ import org.apache.lucene.util.BytesRef;
  * <p>
  * This is more efficient that {@link CollationKeyAnalyzer} if the field 
  * only has one value: no uninversion is necessary to sort on the field, 
- * locale-sensitive range queries can still work via {@link DocValuesRangeQuery}, 
+ * locale-sensitive range queries can still work via {@code DocValuesRangeQuery}, 
  * and the underlying data structures built at index-time are likely more efficient 
  * and use less memory than FieldCache.
  */
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java b/lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java
index 10021fc..bbc2fa6 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/collation/TestCollationDocValuesField.java
@@ -17,22 +17,16 @@ package org.apache.lucene.collation;
  * limitations under the License.
  */
 
-import java.text.Collator;
-import java.util.Locale;
-
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DocValuesRangeQuery;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TopDocs;
@@ -41,6 +35,9 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 
+import java.text.Collator;
+import java.util.Locale;
+
 /**
  * trivial test of CollationDocValuesField
  */
@@ -110,8 +107,7 @@ public class TestCollationDocValuesField extends LuceneTestCase {
         String end = TestUtil.randomSimpleString(random());
         BytesRef lowerVal = new BytesRef(collator.getCollationKey(start).toByteArray());
         BytesRef upperVal = new BytesRef(collator.getCollationKey(end).toByteArray());
-        Query query = DocValuesRangeQuery.newBytesRefRange("collated", lowerVal, upperVal, true, true);
-        doTestRanges(is, start, end, query, collator);
+        doTestRanges(is, start, end, lowerVal, upperVal, collator);
       }
     } finally {
       ir.close();
@@ -119,25 +115,15 @@ public class TestCollationDocValuesField extends LuceneTestCase {
     }
   }
   
-  private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, Query query, Collator collator) throws Exception { 
-    QueryUtils.check(query);
-    
-    // positive test
-    TopDocs docs = is.search(query, is.getIndexReader().maxDoc());
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = is.doc(doc.doc).get("field");
-      assertTrue(collate(collator, value, startPoint) >= 0);
-      assertTrue(collate(collator, value, endPoint) <= 0);
-    }
-    
-    // negative test
-    BooleanQuery bq = new BooleanQuery();
-    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
-    bq.add(query, Occur.MUST_NOT);
-    docs = is.search(bq, is.getIndexReader().maxDoc());
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = is.doc(doc.doc).get("field");
-      assertTrue(collate(collator, value, startPoint) < 0 || collate(collator, value, endPoint) > 0);
+  private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, BytesRef startBR, BytesRef endBR, Collator collator) throws Exception { 
+    SortedDocValues dvs = MultiDocValues.getSortedValues(is.getIndexReader(), "collated");
+    for(int docID=0;docID<is.getIndexReader().maxDoc();docID++) {
+      StoredDocument doc = is.doc(docID);
+      String s = doc.getField("field").stringValue();
+      boolean collatorAccepts = collator.compare(s, startPoint) >= 0 && collator.compare(s, endPoint) <= 0;
+      BytesRef br = dvs.get(docID);
+      boolean luceneAccepts = br.compareTo(startBR) >= 0 && br.compareTo(endBR) <= 0;
+      assertEquals(collatorAccepts, luceneAccepts);
     }
   }
 }
diff --git a/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationDocValuesField.java b/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationDocValuesField.java
index 0ef292e..eee80bb 100644
--- a/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationDocValuesField.java
+++ b/lucene/analysis/icu/src/java/org/apache/lucene/collation/ICUCollationDocValuesField.java
@@ -19,7 +19,6 @@ package org.apache.lucene.collation;
 
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.search.DocValuesRangeQuery;
 import org.apache.lucene.util.BytesRef;
 
 import com.ibm.icu.text.Collator;
@@ -30,7 +29,7 @@ import com.ibm.icu.text.RawCollationKey;
  * <p>
  * This is more efficient that {@link ICUCollationKeyAnalyzer} if the field 
  * only has one value: no uninversion is necessary to sort on the field, 
- * locale-sensitive range queries can still work via {@link DocValuesRangeQuery}, 
+ * locale-sensitive range queries can still work via {@code DocValuesRangeQuery}, 
  * and the underlying data structures built at index-time are likely more efficient 
  * and use less memory than FieldCache.
  */
diff --git a/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java b/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
index 54af2e9..237fead 100644
--- a/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
+++ b/lucene/analysis/icu/src/test/org/apache/lucene/collation/TestICUCollationDocValuesField.java
@@ -21,15 +21,12 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.StringField;
 import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.MultiDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DocValuesRangeQuery;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryUtils;
-import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TopDocs;
@@ -108,33 +105,22 @@ public class TestICUCollationDocValuesField extends LuceneTestCase {
       String end = TestUtil.randomSimpleString(random());
       BytesRef lowerVal = new BytesRef(collator.getCollationKey(start).toByteArray());
       BytesRef upperVal = new BytesRef(collator.getCollationKey(end).toByteArray());
-      Query query = DocValuesRangeQuery.newBytesRefRange("collated", lowerVal, upperVal, true, true);
-      doTestRanges(is, start, end, query, collator);
+      doTestRanges(is, start, end, lowerVal, upperVal, collator);
     }
     
     ir.close();
     dir.close();
   }
   
-  private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, Query query, Collator collator) throws Exception { 
-    QueryUtils.check(query);
-    
-    // positive test
-    TopDocs docs = is.search(query, is.getIndexReader().maxDoc());
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = is.doc(doc.doc).get("field");
-      assertTrue(collator.compare(value, startPoint) >= 0);
-      assertTrue(collator.compare(value, endPoint) <= 0);
-    }
-    
-    // negative test
-    BooleanQuery bq = new BooleanQuery();
-    bq.add(new MatchAllDocsQuery(), Occur.SHOULD);
-    bq.add(query, Occur.MUST_NOT);
-    docs = is.search(bq, is.getIndexReader().maxDoc());
-    for (ScoreDoc doc : docs.scoreDocs) {
-      String value = is.doc(doc.doc).get("field");
-      assertTrue(collator.compare(value, startPoint) < 0 || collator.compare(value, endPoint) > 0);
+  private void doTestRanges(IndexSearcher is, String startPoint, String endPoint, BytesRef startBR, BytesRef endBR, Collator collator) throws Exception { 
+    SortedDocValues dvs = MultiDocValues.getSortedValues(is.getIndexReader(), "collated");
+    for(int docID=0;docID<is.getIndexReader().maxDoc();docID++) {
+      StoredDocument doc = is.doc(docID);
+      String s = doc.getField("field").stringValue();
+      boolean collatorAccepts = collator.compare(s, startPoint) >= 0 && collator.compare(s, endPoint) <= 0;
+      BytesRef br = dvs.get(docID);
+      boolean luceneAccepts = br.compareTo(startBR) >= 0 && br.compareTo(endBR) <= 0;
+      assertEquals(collatorAccepts, luceneAccepts);
     }
   }
 }
diff --git a/lucene/core/src/java/org/apache/lucene/search/DocValuesRangeQuery.java b/lucene/core/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
deleted file mode 100644
index 6b285e5..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
+++ /dev/null
@@ -1,240 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Objects;
-
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.DocValuesType;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedNumericDocValues;
-import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.ToStringUtils;
-
-/**
- * A range query that works on top of the doc values APIs. Such queries are
- * usually slow since they do not use an inverted index. However, in the
- * dense case where most documents match this query, it <b>might</b> be as
- * fast or faster than a regular {@link NumericRangeQuery}.
- * @lucene.experimental
- */
-public final class DocValuesRangeQuery extends Query {
-
-  /** Create a new numeric range query on a numeric doc-values field. The field
-   *  must has been indexed with either {@link DocValuesType#NUMERIC} or
-   *  {@link DocValuesType#SORTED_NUMERIC} doc values. */
-  public static Query newLongRange(String field, Long lowerVal, Long upperVal, boolean includeLower, boolean includeUpper) {
-    return new DocValuesRangeQuery(field, lowerVal, upperVal, includeLower, includeUpper);
-  }
-
-  /** Create a new numeric range query on a numeric doc-values field. The field
-   *  must has been indexed with {@link DocValuesType#SORTED} or
-   *  {@link DocValuesType#SORTED_SET} doc values. */
-  public static Query newBytesRefRange(String field, BytesRef lowerVal, BytesRef upperVal, boolean includeLower, boolean includeUpper) {
-    return new DocValuesRangeQuery(field, deepCopyOf(lowerVal), deepCopyOf(upperVal), includeLower, includeUpper);
-  }
-
-  private static BytesRef deepCopyOf(BytesRef b) {
-    if (b == null) {
-      return null;
-    } else {
-      return BytesRef.deepCopyOf(b);
-    }
-  }
-
-  private final String field;
-  private final Object lowerVal, upperVal;
-  private final boolean includeLower, includeUpper;
-
-  private DocValuesRangeQuery(String field, Object lowerVal, Object upperVal, boolean includeLower, boolean includeUpper) {
-    this.field = Objects.requireNonNull(field);
-    this.lowerVal = lowerVal;
-    this.upperVal = upperVal;
-    this.includeLower = includeLower;
-    this.includeUpper = includeUpper;
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (obj instanceof DocValuesRangeQuery == false) {
-      return false;
-    }
-    final DocValuesRangeQuery that = (DocValuesRangeQuery) obj;
-    return field.equals(that.field)
-        && Objects.equals(lowerVal, that.lowerVal)
-        && Objects.equals(upperVal, that.upperVal)
-        && includeLower == that.includeLower
-        && includeUpper == that.includeUpper
-        && super.equals(obj);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(field, lowerVal, upperVal, includeLower, includeUpper, getBoost());
-  }
-
-  @Override
-  public String toString(String field) {
-    StringBuilder sb = new StringBuilder();
-    if (this.field.equals(field) == false) {
-      sb.append(this.field).append(':');
-    }
-    sb.append(includeLower ? '[' : '{');
-    sb.append(lowerVal == null ? "*" : lowerVal.toString());
-    sb.append(" TO ");
-    sb.append(upperVal == null ? "*" : upperVal.toString());
-    sb.append(includeUpper ? ']' : '}');
-    sb.append(ToStringUtils.boost(getBoost()));
-    return sb.toString();
-  }
-
-  @Override
-  public Query rewrite(IndexReader reader) throws IOException {
-    if (lowerVal == null && upperVal == null) {
-      final FieldValueQuery rewritten = new FieldValueQuery(field);
-      rewritten.setBoost(getBoost());
-      return rewritten;
-    }
-    return this;
-  }
-
-  @Override
-  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    if (lowerVal == null && upperVal == null) {
-      throw new IllegalStateException("Both min and max values cannot be null, call rewrite first");
-    }
-    return new RandomAccessWeight(DocValuesRangeQuery.this) {
-      
-      @Override
-      protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {
-        if (lowerVal instanceof Long || upperVal instanceof Long) {
-
-          final SortedNumericDocValues values = DocValues.getSortedNumeric(context.reader(), field);
-
-          final long min;
-          if (lowerVal == null) {
-            min = Long.MIN_VALUE;
-          } else if (includeLower) {
-            min = (long) lowerVal;
-          } else {
-            min = 1 + (long) lowerVal;
-          }
-
-          final long max;
-          if (upperVal == null) {
-            max = Long.MAX_VALUE;
-          } else if (includeUpper) {
-            max = (long) upperVal;
-          } else {
-            max = -1 + (long) upperVal;
-          }
-
-          if (min > max) {
-            return null;
-          }
-
-          return new Bits() {
-
-            @Override
-            public boolean get(int doc) {
-              values.setDocument(doc);
-              final int count = values.count();
-              for (int i = 0; i < count; ++i) {
-                final long value = values.valueAt(i);
-                if (value >= min && value <= max) {
-                  return true;
-                }
-              }
-              return false;
-            }
-
-            @Override
-            public int length() {
-              return context.reader().maxDoc();
-            }
-
-          };
-
-        } else if (lowerVal instanceof BytesRef || upperVal instanceof BytesRef) {
-
-          final SortedSetDocValues values = DocValues.getSortedSet(context.reader(), field);
-
-          final long minOrd;
-          if (lowerVal == null) {
-            minOrd = 0;
-          } else {
-            final long ord = values.lookupTerm((BytesRef) lowerVal);
-            if (ord < 0) {
-              minOrd = -1 - ord;
-            } else if (includeLower) {
-              minOrd = ord;
-            } else {
-              minOrd = ord + 1;
-            }
-          }
-
-          final long maxOrd;
-          if (upperVal == null) {
-            maxOrd = values.getValueCount() - 1;
-          } else {
-            final long ord = values.lookupTerm((BytesRef) upperVal);
-            if (ord < 0) {
-              maxOrd = -2 - ord;
-            } else if (includeUpper) {
-              maxOrd = ord;
-            } else {
-              maxOrd = ord - 1;
-            }
-          }
-
-          if (minOrd > maxOrd) {
-            return null;
-          }
-
-          return new Bits() {
-
-            @Override
-            public boolean get(int doc) {
-              values.setDocument(doc);
-              for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {
-                if (ord >= minOrd && ord <= maxOrd) {
-                  return true;
-                }
-              }
-              return false;
-            }
-
-            @Override
-            public int length() {
-              return context.reader().maxDoc();
-            }
-
-          };
-
-        } else {
-          throw new AssertionError();
-        }
-      }
-    };
-  }
-
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/DocValuesTermsQuery.java b/lucene/core/src/java/org/apache/lucene/search/DocValuesTermsQuery.java
deleted file mode 100644
index 9f376b3..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/DocValuesTermsQuery.java
+++ /dev/null
@@ -1,185 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.AbstractList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Objects;
-
-import org.apache.lucene.index.DocValues;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.SortedSetDocValues;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.LongBitSet;
-
-/**
- * A {@link Query} that only accepts documents whose
- * term value in the specified field is contained in the
- * provided set of allowed terms.
- *
- * <p>
- * This is the same functionality as TermsQuery (from
- * queries/), but because of drastically different
- * implementations, they also have different performance
- * characteristics, as described below.
- *
- * <p>
- * With each search, this query translates the specified
- * set of Terms into a private {@link LongBitSet} keyed by
- * term number per unique {@link IndexReader} (normally one
- * reader per segment).  Then, during matching, the term
- * number for each docID is retrieved from the cache and
- * then checked for inclusion using the {@link LongBitSet}.
- * Since all testing is done using RAM resident data
- * structures, performance should be very fast, most likely
- * fast enough to not require further caching of the
- * DocIdSet for each possible combination of terms.
- * However, because docIDs are simply scanned linearly, an
- * index with a great many small documents may find this
- * linear scan too costly.
- *
- * <p>
- * In contrast, TermsQuery builds up an {@link FixedBitSet},
- * keyed by docID, every time it's created, by enumerating
- * through all matching docs using {@link org.apache.lucene.index.PostingsEnum} to seek
- * and scan through each term's docID list.  While there is
- * no linear scan of all docIDs, besides the allocation of
- * the underlying array in the {@link FixedBitSet}, this
- * approach requires a number of "disk seeks" in proportion
- * to the number of terms, which can be exceptionally costly
- * when there are cache misses in the OS's IO cache.
- *
- * <p>
- * Generally, this filter will be slower on the first
- * invocation for a given field, but subsequent invocations,
- * even if you change the allowed set of Terms, should be
- * faster than TermsQuery, especially as the number of
- * Terms being matched increases.  If you are matching only
- * a very small number of terms, and those terms in turn
- * match a very small number of documents, TermsQuery may
- * perform faster.
- *
- * <p>
- * Which query is best is very application dependent.
- */
-public class DocValuesTermsQuery extends Query {
-
-  private final String field;
-  private final BytesRef[] terms;
-
-  public DocValuesTermsQuery(String field, Collection<BytesRef> terms) {
-    this.field = Objects.requireNonNull(field);
-    Objects.requireNonNull(terms, "Collection of terms must not be null");
-    this.terms = terms.toArray(new BytesRef[terms.size()]);
-    ArrayUtil.timSort(this.terms, BytesRef.getUTF8SortedAsUnicodeComparator());
-  }
-
-  public DocValuesTermsQuery(String field, BytesRef... terms) {
-    this(field, Arrays.asList(terms));
-  }
-
-  public DocValuesTermsQuery(String field, String... terms) {
-    this(field, new AbstractList<BytesRef>() {
-      @Override
-      public BytesRef get(int index) {
-        return new BytesRef(terms[index]);
-      }
-      @Override
-      public int size() {
-        return terms.length;
-      }
-    });
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (obj instanceof DocValuesTermsQuery == false) {
-      return false;
-    }
-    DocValuesTermsQuery that = (DocValuesTermsQuery) obj;
-    if (!super.equals(obj)) {
-      return false;
-    }
-    if (!field.equals(that.field)) {
-      return false;
-    }
-    return Arrays.equals(terms, that.terms);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(field, Arrays.asList(terms), getBoost());
-  }
-
-  @Override
-  public String toString(String defaultField) {
-    StringBuilder sb = new StringBuilder();
-    sb.append(field).append(": [");
-    for (BytesRef term : terms) {
-      sb.append(term).append(", ");
-    }
-    if (terms.length > 0) {
-      sb.setLength(sb.length() - 2);
-    }
-    return sb.append(']').toString();
-  }
-
-  @Override
-  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    return new RandomAccessWeight(this) {
-
-      @Override
-      protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {
-        final SortedSetDocValues values = DocValues.getSortedSet(context.reader(), field);
-        final LongBitSet bits = new LongBitSet(values.getValueCount());
-        for (BytesRef term : terms) {
-          final long ord = values.lookupTerm(term);
-          if (ord >= 0) {
-            bits.set(ord);
-          }
-        }
-        return new Bits() {
-
-          @Override
-          public boolean get(int doc) {
-            values.setDocument(doc);
-            for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {
-              if (bits.get(ord)) {
-                return true;
-              }
-            }
-            return false;
-          }
-
-          @Override
-          public int length() {
-            return context.reader().maxDoc();
-          }
-
-        };
-      }
-    };
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestComplexExplanations.java b/lucene/core/src/test/org/apache/lucene/search/TestComplexExplanations.java
index 8a451d5..eb13645 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestComplexExplanations.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestComplexExplanations.java
@@ -73,11 +73,11 @@ public class TestComplexExplanations extends BaseExplanationTestCase {
           Occur.SHOULD);
 
     Query t = new FilteredQuery(new TermQuery(new Term(FIELD, "xx")),
-                                new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3})));
+                                new QueryWrapperFilter(matchTheseItems(new int[] {1,3})));
     t.setBoost(1000);
     q.add(t, Occur.SHOULD);
     
-    t = new ConstantScoreQuery(new ItemizedQuery(new int[] {0,2}));
+    t = new ConstantScoreQuery(matchTheseItems(new int[] {0,2}));
     t.setBoost(30);
     q.add(t, Occur.SHOULD);
     
@@ -136,11 +136,11 @@ public class TestComplexExplanations extends BaseExplanationTestCase {
           Occur.SHOULD);
     
     Query t = new FilteredQuery(new TermQuery(new Term(FIELD, "xx")),
-                                new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3})));
+                                new QueryWrapperFilter(matchTheseItems(new int[] {1,3})));
     t.setBoost(1000);
     q.add(t, Occur.SHOULD);
     
-    t = new ConstantScoreQuery(new ItemizedQuery(new int[] {0,2}));
+    t = new ConstantScoreQuery(matchTheseItems(new int[] {0,2}));
     t.setBoost(-20.0f);
     q.add(t, Occur.SHOULD);
     
@@ -207,11 +207,11 @@ public class TestComplexExplanations extends BaseExplanationTestCase {
   public void testFQ5() throws Exception {
     TermQuery query = new TermQuery(new Term(FIELD, "xx"));
     query.setBoost(0);
-    bqtest(new FilteredQuery(query, new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3}))), new int[] {3});
+    bqtest(new FilteredQuery(query, new QueryWrapperFilter(matchTheseItems(new int[] {1,3}))), new int[] {3});
   }
   
   public void testCSQ4() throws Exception {
-    Query q = new ConstantScoreQuery(new ItemizedQuery(new int[] {3}));
+    Query q = new ConstantScoreQuery(matchTheseItems(new int[] {3}));
     q.setBoost(0);
     bqtest(q, new int[] {3});
   }
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
deleted file mode 100644
index fc0ed49..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
+++ /dev/null
@@ -1,283 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.LongField;
-import org.apache.lucene.document.NumericDocValuesField;
-import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.document.SortedNumericDocValuesField;
-import org.apache.lucene.document.SortedSetDocValuesField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BytesRefBuilder;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.NumericUtils;
-import org.apache.lucene.util.TestUtil;
-
-public class TestDocValuesRangeQuery extends LuceneTestCase {
-
-  public void testDuelNumericRangeQuery() throws IOException {
-    final int iters = atLeast(10);
-      for (int iter = 0; iter < iters; ++iter) {
-      Directory dir = newDirectory();
-      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-      final int numDocs = atLeast(100);
-      for (int i = 0; i < numDocs; ++i) {
-        Document doc = new Document();
-        final int numValues = random().nextInt(2);
-        for (int j = 0; j < numValues; ++j) {
-          final long value = TestUtil.nextLong(random(), -100, 10000);
-          doc.add(new SortedNumericDocValuesField("dv", value));
-          doc.add(new LongField("idx", value, Store.NO));
-        }
-        iw.addDocument(doc);
-      }
-      if (random().nextBoolean()) {
-        iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
-      }
-      iw.commit();
-      final IndexReader reader = iw.getReader();
-      final IndexSearcher searcher = newSearcher(reader);
-      iw.close();
-
-      for (int i = 0; i < 100; ++i) {
-        final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-        final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-        final boolean minInclusive = random().nextBoolean();
-        final boolean maxInclusive = random().nextBoolean();
-        final Query q1 = NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive);
-        final Query q2 = DocValuesRangeQuery.newLongRange("dv", min, max, minInclusive, maxInclusive);
-        assertSameMatches(searcher, q1, q2, false);
-      }
-
-      reader.close();
-      dir.close();
-    }
-  }
-
-  private static BytesRef toSortableBytes(Long l) {
-    if (l == null) {
-      return null;
-    } else {
-      final BytesRefBuilder bytes = new BytesRefBuilder();
-      NumericUtils.longToPrefixCoded(l, 0, bytes);
-      return bytes.get();
-    }
-  }
-
-  public void testDuelNumericSorted() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    final int numDocs = atLeast(100);
-    for (int i = 0; i < numDocs; ++i) {
-      Document doc = new Document();
-      final int numValues = random().nextInt(3);
-      for (int j = 0; j < numValues; ++j) {
-        final long value = TestUtil.nextLong(random(), -100, 10000);
-        doc.add(new SortedNumericDocValuesField("dv1", value));
-        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
-      }
-      iw.addDocument(doc);
-    }
-    if (random().nextBoolean()) {
-      iw.deleteDocuments(DocValuesRangeQuery.newLongRange("dv1", 0L, 10L, true, true));
-    }
-    iw.commit();
-    final IndexReader reader = iw.getReader();
-    final IndexSearcher searcher = newSearcher(reader);
-    iw.close();
-
-    for (int i = 0; i < 100; ++i) {
-      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final boolean minInclusive = random().nextBoolean();
-      final boolean maxInclusive = random().nextBoolean();
-      final Query q1 = DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive);
-      final Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive);
-      assertSameMatches(searcher, q1, q2, true);
-    }
-
-    reader.close();
-    dir.close();
-  }
-
-  public void testScore() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    final int numDocs = atLeast(100);
-    for (int i = 0; i < numDocs; ++i) {
-      Document doc = new Document();
-      final int numValues = random().nextInt(3);
-      for (int j = 0; j < numValues; ++j) {
-        final long value = TestUtil.nextLong(random(), -100, 10000);
-        doc.add(new SortedNumericDocValuesField("dv1", value));
-        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
-      }
-      iw.addDocument(doc);
-    }
-    if (random().nextBoolean()) {
-      iw.deleteDocuments(DocValuesRangeQuery.newLongRange("dv1", 0L, 10L, true, true));
-    }
-    iw.commit();
-    final IndexReader reader = iw.getReader();
-    final IndexSearcher searcher = newSearcher(reader);
-    iw.close();
-
-    for (int i = 0; i < 100; ++i) {
-      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final boolean minInclusive = random().nextBoolean();
-      final boolean maxInclusive = random().nextBoolean();
-
-      final float boost = random().nextFloat() * 10;
-
-      final Query q1 = DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive);
-      q1.setBoost(boost);
-      final ConstantScoreQuery csq1 = new ConstantScoreQuery(DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive));
-      csq1.setBoost(boost);
-      assertSameMatches(searcher, q1, csq1, true);
-
-      final Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive);
-      q2.setBoost(boost);
-      final ConstantScoreQuery csq2 = new ConstantScoreQuery(DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive));
-      csq2.setBoost(boost);
-      assertSameMatches(searcher, q2, csq2, true);
-    }
-
-    reader.close();
-    dir.close();
-  }
-
-  public void testApproximation() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    final int numDocs = atLeast(100);
-    for (int i = 0; i < numDocs; ++i) {
-      Document doc = new Document();
-      final int numValues = random().nextInt(3);
-      for (int j = 0; j < numValues; ++j) {
-        final long value = TestUtil.nextLong(random(), -100, 10000);
-        doc.add(new SortedNumericDocValuesField("dv1", value));
-        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
-        doc.add(new LongField("idx", value, Store.NO));
-        doc.add(new StringField("f", random().nextBoolean() ? "a" : "b", Store.NO));
-      }
-      iw.addDocument(doc);
-    }
-    if (random().nextBoolean()) {
-      iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
-    }
-    iw.commit();
-    final IndexReader reader = iw.getReader();
-    final IndexSearcher searcher = newSearcher(reader);
-    iw.close();
-
-    for (int i = 0; i < 100; ++i) {
-      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
-      final boolean minInclusive = random().nextBoolean();
-      final boolean maxInclusive = random().nextBoolean();
-
-      BooleanQuery ref = new BooleanQuery();
-      ref.add(NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive), Occur.FILTER);
-      ref.add(new TermQuery(new Term("f", "a")), Occur.MUST);
-
-      BooleanQuery bq1 = new BooleanQuery();
-      bq1.add(DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive), Occur.FILTER);
-      bq1.add(new TermQuery(new Term("f", "a")), Occur.MUST);
-
-      assertSameMatches(searcher, ref, bq1, true);
-
-      BooleanQuery bq2 = new BooleanQuery();
-      bq2.add(DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive), Occur.FILTER);
-      bq2.add(new TermQuery(new Term("f", "a")), Occur.MUST);
-
-      assertSameMatches(searcher, ref, bq2, true);
-    }
-
-    reader.close();
-    dir.close();
-  }
-
-  private void assertSameMatches(IndexSearcher searcher, Query q1, Query q2, boolean scores) throws IOException {
-    final int maxDoc = searcher.getIndexReader().maxDoc();
-    final TopDocs td1 = searcher.search(q1, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
-    final TopDocs td2 = searcher.search(q2, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
-    assertEquals(td1.totalHits, td2.totalHits);
-    for (int i = 0; i < td1.scoreDocs.length; ++i) {
-      assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
-      if (scores) {
-        assertEquals(td1.scoreDocs[i].score, td2.scoreDocs[i].score, 10e-7);
-      }
-    }
-  }
-
-  public void testToString() {
-    assertEquals("f:[2 TO 5]", DocValuesRangeQuery.newLongRange("f", 2L, 5L, true, true).toString());
-    assertEquals("f:{2 TO 5]", DocValuesRangeQuery.newLongRange("f", 2L, 5L, false, true).toString());
-    assertEquals("f:{2 TO 5}", DocValuesRangeQuery.newLongRange("f", 2L, 5L, false, false).toString());
-    assertEquals("f:{* TO 5}", DocValuesRangeQuery.newLongRange("f", null, 5L, false, false).toString());
-    assertEquals("f:[2 TO *}", DocValuesRangeQuery.newLongRange("f", 2L, null, true, false).toString());
-
-    BytesRef min = new BytesRef("a");
-    BytesRef max = new BytesRef("b");
-    assertEquals("f:[[61] TO [62]]", DocValuesRangeQuery.newBytesRefRange("f", min, max, true, true).toString());
-    assertEquals("f:{[61] TO [62]]", DocValuesRangeQuery.newBytesRefRange("f", min, max, false, true).toString());
-    assertEquals("f:{[61] TO [62]}", DocValuesRangeQuery.newBytesRefRange("f", min, max, false, false).toString());
-    assertEquals("f:{* TO [62]}", DocValuesRangeQuery.newBytesRefRange("f", null, max, false, false).toString());
-    assertEquals("f:[[61] TO *}", DocValuesRangeQuery.newBytesRefRange("f", min, null, true, false).toString());
-  }
-
-  public void testDocValuesRangeSupportsApproximation() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(new NumericDocValuesField("dv1", 5L));
-    doc.add(new SortedDocValuesField("dv2", toSortableBytes(42L)));
-    iw.addDocument(doc);
-    iw.commit();
-    final IndexReader reader = iw.getReader();
-    final LeafReaderContext ctx = reader.leaves().get(0);
-    final IndexSearcher searcher = newSearcher(reader);
-    iw.close();
-
-    Query q1 = DocValuesRangeQuery.newLongRange("dv1", 0L, 100L, random().nextBoolean(), random().nextBoolean());
-    Weight w = searcher.createNormalizedWeight(q1, true);
-    Scorer s = w.scorer(ctx, null);
-    assertNotNull(s.asTwoPhaseIterator());
-
-    Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(0L), toSortableBytes(100L), random().nextBoolean(), random().nextBoolean());
-    w = searcher.createNormalizedWeight(q2, true);
-    s = w.scorer(ctx, null);
-    assertNotNull(s.asTwoPhaseIterator());
-
-    reader.close();
-    dir.close();
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java
deleted file mode 100644
index 28607e1..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java
+++ /dev/null
@@ -1,188 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestUtil;
-
-public class TestDocValuesTermsQuery extends LuceneTestCase {
-
-  public void testEquals() {
-    assertEquals(new DocValuesTermsQuery("foo", "bar"), new DocValuesTermsQuery("foo", "bar"));
-    assertEquals(new DocValuesTermsQuery("foo", "bar", "baz"), new DocValuesTermsQuery("foo", "baz", "bar"));
-    assertFalse(new DocValuesTermsQuery("foo", "bar").equals(new DocValuesTermsQuery("foo2", "bar")));
-    assertFalse(new DocValuesTermsQuery("foo", "bar").equals(new DocValuesTermsQuery("foo", "baz")));
-  }
-
-  public void testDuelTermsQuery() throws IOException {
-    final int iters = atLeast(2);
-    for (int iter = 0; iter < iters; ++iter) {
-      final List<Term> allTerms = new ArrayList<>();
-      final int numTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
-      for (int i = 0; i < numTerms; ++i) {
-        final String value = TestUtil.randomAnalysisString(random(), 10, true);
-        allTerms.add(new Term("f", value));
-      }
-      Directory dir = newDirectory();
-      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-      final int numDocs = atLeast(100);
-      for (int i = 0; i < numDocs; ++i) {
-        Document doc = new Document();
-        final Term term = allTerms.get(random().nextInt(allTerms.size()));
-        doc.add(new StringField(term.field(), term.text(), Store.NO));
-        doc.add(new SortedDocValuesField(term.field(), new BytesRef(term.text())));
-        iw.addDocument(doc);
-      }
-      if (numTerms > 1 && random().nextBoolean()) {
-        iw.deleteDocuments(new TermQuery(allTerms.get(0)));
-      }
-      iw.commit();
-      final IndexReader reader = iw.getReader();
-      final IndexSearcher searcher = newSearcher(reader);
-      iw.close();
-
-      if (reader.numDocs() == 0) {
-        // may occasionally happen if all documents got the same term
-        IOUtils.close(reader, dir);
-        continue;
-      }
-
-      for (int i = 0; i < 100; ++i) {
-        final float boost = random().nextFloat() * 10;
-        final int numQueryTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
-        List<Term> queryTerms = new ArrayList<>();
-        for (int j = 0; j < numQueryTerms; ++j) {
-          queryTerms.add(allTerms.get(random().nextInt(allTerms.size())));
-        }
-        final BooleanQuery bq = new BooleanQuery();
-        for (Term term : queryTerms) {
-          bq.add(new TermQuery(term), Occur.SHOULD);
-        }
-        Query q1 = new ConstantScoreQuery(bq);
-        q1.setBoost(boost);
-        List<String> bytesTerms = new ArrayList<>();
-        for (Term term : queryTerms) {
-          bytesTerms.add(term.text());
-        }
-        final Query q2 = new DocValuesTermsQuery("f", bytesTerms.toArray(new String[0]));
-        q2.setBoost(boost);
-        assertSameMatches(searcher, q1, q2, true);
-      }
-
-      reader.close();
-      dir.close();
-    }
-  }
-
-  public void testApproximation() throws IOException {
-    final int iters = atLeast(2);
-    for (int iter = 0; iter < iters; ++iter) {
-      final List<Term> allTerms = new ArrayList<>();
-      final int numTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
-      for (int i = 0; i < numTerms; ++i) {
-        final String value = TestUtil.randomAnalysisString(random(), 10, true);
-        allTerms.add(new Term("f", value));
-      }
-      Directory dir = newDirectory();
-      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-      final int numDocs = atLeast(100);
-      for (int i = 0; i < numDocs; ++i) {
-        Document doc = new Document();
-        final Term term = allTerms.get(random().nextInt(allTerms.size()));
-        doc.add(new StringField(term.field(), term.text(), Store.NO));
-        doc.add(new SortedDocValuesField(term.field(), new BytesRef(term.text())));
-        iw.addDocument(doc);
-      }
-      if (numTerms > 1 && random().nextBoolean()) {
-        iw.deleteDocuments(new TermQuery(allTerms.get(0)));
-      }
-      iw.commit();
-      final IndexReader reader = iw.getReader();
-      final IndexSearcher searcher = newSearcher(reader);
-      iw.close();
-
-      if (reader.numDocs() == 0) {
-        // may occasionally happen if all documents got the same term
-        IOUtils.close(reader, dir);
-        continue;
-      }
-
-      for (int i = 0; i < 100; ++i) {
-        final float boost = random().nextFloat() * 10;
-        final int numQueryTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
-        List<Term> queryTerms = new ArrayList<>();
-        for (int j = 0; j < numQueryTerms; ++j) {
-          queryTerms.add(allTerms.get(random().nextInt(allTerms.size())));
-        }
-        final BooleanQuery bq = new BooleanQuery();
-        for (Term term : queryTerms) {
-          bq.add(new TermQuery(term), Occur.SHOULD);
-        }
-        Query q1 = new ConstantScoreQuery(bq);
-        q1.setBoost(boost);
-        List<String> bytesTerms = new ArrayList<>();
-        for (Term term : queryTerms) {
-          bytesTerms.add(term.text());
-        }
-        final Query q2 = new DocValuesTermsQuery("f", bytesTerms.toArray(new String[0]));
-        q2.setBoost(boost);
-
-        BooleanQuery bq1 = new BooleanQuery();
-        bq1.add(q1, Occur.MUST);
-        bq1.add(new TermQuery(allTerms.get(0)), Occur.FILTER);
-
-        BooleanQuery bq2 = new BooleanQuery();
-        bq2.add(q2, Occur.MUST);
-        bq2.add(new TermQuery(allTerms.get(0)), Occur.FILTER);
-
-        assertSameMatches(searcher, bq1, bq2, true);
-      }
-
-      reader.close();
-      dir.close();
-    }
-  }
-
-  private void assertSameMatches(IndexSearcher searcher, Query q1, Query q2, boolean scores) throws IOException {
-    final int maxDoc = searcher.getIndexReader().maxDoc();
-    final TopDocs td1 = searcher.search(q1, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
-    final TopDocs td2 = searcher.search(q2, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
-    assertEquals(td1.totalHits, td2.totalHits);
-    for (int i = 0; i < td1.scoreDocs.length; ++i) {
-      assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
-      if (scores) {
-        assertEquals(td1.scoreDocs[i].score, td2.scoreDocs[i].score, 10e-7);
-      }
-    }
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
deleted file mode 100644
index 796336c..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
+++ /dev/null
@@ -1,75 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.SortedDocValuesField;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.store.Directory;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * A basic unit test for FieldCacheTermsFilter
- *
- * @see org.apache.lucene.search.DocValuesTermsQuery
- */
-public class TestFieldCacheTermsFilter extends LuceneTestCase {
-  public void testMissingTerms() throws Exception {
-    String fieldName = "field1";
-    Directory rd = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), rd);
-    for (int i = 0; i < 100; i++) {
-      Document doc = new Document();
-      int term = i * 10; //terms are units of 10;
-      doc.add(newStringField(fieldName, "" + term, Field.Store.YES));
-      doc.add(new SortedDocValuesField(fieldName, new BytesRef("" + term)));
-      w.addDocument(doc);
-    }
-    IndexReader reader = w.getReader();
-    w.close();
-
-    IndexSearcher searcher = newSearcher(reader);
-    int numDocs = reader.numDocs();
-    ScoreDoc[] results;
-
-    List<String> terms = new ArrayList<>();
-    terms.add("5");
-    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
-    assertEquals("Must match nothing", 0, results.length);
-
-    terms = new ArrayList<>();
-    terms.add("10");
-    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
-    assertEquals("Must match 1", 1, results.length);
-
-    terms = new ArrayList<>();
-    terms.add("10");
-    terms.add("20");
-    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
-    assertEquals("Must match 2", 2, results.length);
-
-    reader.close();
-    rd.close();
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSimpleExplanations.java b/lucene/core/src/test/org/apache/lucene/search/TestSimpleExplanations.java
index fa1eaf7..fe0cfe9 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSimpleExplanations.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSimpleExplanations.java
@@ -105,28 +105,28 @@ public class TestSimpleExplanations extends BaseExplanationTestCase {
   
   public void testFQ1() throws Exception {
     qtest(new FilteredQuery(new TermQuery(new Term(FIELD, "w1")),
-                            new QueryWrapperFilter(new ItemizedQuery(new int[] {0,1,2,3}))),
+                            new QueryWrapperFilter(matchTheseItems(new int[] {0,1,2,3}))),
           new int[] {0,1,2,3});
   }
   public void testFQ2() throws Exception {
     qtest(new FilteredQuery(new TermQuery(new Term(FIELD, "w1")),
-                            new QueryWrapperFilter(new ItemizedQuery(new int[] {0,2,3}))),
+                            new QueryWrapperFilter(matchTheseItems(new int[] {0,2,3}))),
           new int[] {0,2,3});
   }
   public void testFQ3() throws Exception {
     qtest(new FilteredQuery(new TermQuery(new Term(FIELD, "xx")),
-                            new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3}))),
+                            new QueryWrapperFilter(matchTheseItems(new int[] {1,3}))),
           new int[] {3});
   }
   public void testFQ4() throws Exception {
     TermQuery termQuery = new TermQuery(new Term(FIELD, "xx"));
     termQuery.setBoost(1000);
-    qtest(new FilteredQuery(termQuery, new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3}))),
+    qtest(new FilteredQuery(termQuery, new QueryWrapperFilter(matchTheseItems(new int[] {1,3}))),
           new int[] {3});
   }
   public void testFQ6() throws Exception {
     Query q = new FilteredQuery(new TermQuery(new Term(FIELD, "xx")),
-                                new QueryWrapperFilter(new ItemizedQuery(new int[] {1,3})));
+                                new QueryWrapperFilter(matchTheseItems(new int[] {1,3})));
     q.setBoost(1000);
     qtest(q, new int[] {3});
   }
@@ -134,15 +134,15 @@ public class TestSimpleExplanations extends BaseExplanationTestCase {
   /* ConstantScoreQueries */
   
   public void testCSQ1() throws Exception {
-    Query q = new ConstantScoreQuery(new ItemizedQuery(new int[] {0,1,2,3}));
+    Query q = new ConstantScoreQuery(matchTheseItems(new int[] {0,1,2,3}));
     qtest(q, new int[] {0,1,2,3});
   }
   public void testCSQ2() throws Exception {
-    Query q = new ConstantScoreQuery(new ItemizedQuery(new int[] {1,3}));
+    Query q = new ConstantScoreQuery(matchTheseItems(new int[] {1,3}));
     qtest(q, new int[] {1,3});
   }
   public void testCSQ3() throws Exception {
-    Query q = new ConstantScoreQuery(new ItemizedQuery(new int[] {0,2}));
+    Query q = new ConstantScoreQuery(matchTheseItems(new int[] {0,2}));
     q.setBoost(1000);
     qtest(q, new int[] {0,2});
   }
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesNumbersQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesNumbersQuery.java
new file mode 100644
index 0000000..ebd99f2
--- /dev/null
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesNumbersQuery.java
@@ -0,0 +1,122 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.SortedNumericDocValuesField;
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.SortedNumericDocValues;
+import org.apache.lucene.util.Bits;
+
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Objects;
+import java.util.Set;
+
+/**
+ * Like {@link DocValuesTermsQuery}, but this query only
+ * runs on a long {@link NumericDocValuesField} or a
+ * {@link SortedNumericDocValuesField}, matching
+ * all documents whose value in the specified field is
+ * contained in the provided set of long values.
+ *
+ * <p>
+ * <b>NOTE</b>: be very careful using this query: it is
+ * typically much slower than using {@code TermsQuery},
+ * but in certain specialized cases may be faster.
+ *
+ * @lucene.experimental
+ */
+public class DocValuesNumbersQuery extends Query {
+
+  private final String field;
+  private final Set<Long> numbers;
+
+  public DocValuesNumbersQuery(String field, Set<Long> numbers) {
+    this.field = Objects.requireNonNull(field);
+    this.numbers = Objects.requireNonNull(numbers, "Set of numbers must not be null");
+  }
+
+  public DocValuesNumbersQuery(String field, Long... numbers) {
+    this(field, new HashSet<Long>(Arrays.asList(numbers)));
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (!super.equals(obj)) {
+      return false;
+    }
+    // super.equals ensures we are the same class:
+    DocValuesNumbersQuery that = (DocValuesNumbersQuery) obj;
+    if (!field.equals(that.field)) {
+      return false;
+    }
+    return numbers.equals(that.numbers);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(field, numbers, getBoost());
+  }
+
+  @Override
+  public String toString(String defaultField) {
+    StringBuilder sb = new StringBuilder();
+    sb.append(field).append(": [");
+    for (Long number : numbers) {
+      sb.append(number).append(", ");
+    }
+    if (numbers.size() > 0) {
+      sb.setLength(sb.length() - 2);
+    }
+    return sb.append(']').toString();
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    return new RandomAccessWeight(this) {
+
+      @Override
+      protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {
+         final SortedNumericDocValues values = DocValues.getSortedNumeric(context.reader(), field);
+         return new Bits() {
+
+           @Override
+           public boolean get(int doc) {
+             values.setDocument(doc);
+             int count = values.count();
+             for(int i=0;i<count;i++) {
+               if (numbers.contains(values.valueAt(i))) {
+                 return true;
+               }
+             }
+
+             return false;
+          }
+
+          @Override
+          public int length() {
+            return context.reader().maxDoc();
+          }
+        };
+      }
+    };
+  }
+}
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
new file mode 100644
index 0000000..2e463a1
--- /dev/null
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesRangeQuery.java
@@ -0,0 +1,246 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Objects;
+
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.DocValuesType;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.SortedNumericDocValues;
+import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.ToStringUtils;
+
+/**
+ * A range query that works on top of the doc values APIs. Such queries are
+ * usually slow since they do not use an inverted index. However, in the
+ * dense case where most documents match this query, it <b>might</b> be as
+ * fast or faster than a regular {@link NumericRangeQuery}.
+ *
+ * <p>
+ * <b>NOTE</b>: be very careful using this query: it is
+ * typically much slower than using {@code TermsQuery},
+ * but in certain specialized cases may be faster.
+ *
+ * @lucene.experimental
+ */
+public final class DocValuesRangeQuery extends Query {
+
+  /** Create a new numeric range query on a numeric doc-values field. The field
+   *  must has been indexed with either {@link DocValuesType#NUMERIC} or
+   *  {@link DocValuesType#SORTED_NUMERIC} doc values. */
+  public static Query newLongRange(String field, Long lowerVal, Long upperVal, boolean includeLower, boolean includeUpper) {
+    return new DocValuesRangeQuery(field, lowerVal, upperVal, includeLower, includeUpper);
+  }
+
+  /** Create a new numeric range query on a numeric doc-values field. The field
+   *  must has been indexed with {@link DocValuesType#SORTED} or
+   *  {@link DocValuesType#SORTED_SET} doc values. */
+  public static Query newBytesRefRange(String field, BytesRef lowerVal, BytesRef upperVal, boolean includeLower, boolean includeUpper) {
+    return new DocValuesRangeQuery(field, deepCopyOf(lowerVal), deepCopyOf(upperVal), includeLower, includeUpper);
+  }
+
+  private static BytesRef deepCopyOf(BytesRef b) {
+    if (b == null) {
+      return null;
+    } else {
+      return BytesRef.deepCopyOf(b);
+    }
+  }
+
+  private final String field;
+  private final Object lowerVal, upperVal;
+  private final boolean includeLower, includeUpper;
+
+  private DocValuesRangeQuery(String field, Object lowerVal, Object upperVal, boolean includeLower, boolean includeUpper) {
+    this.field = Objects.requireNonNull(field);
+    this.lowerVal = lowerVal;
+    this.upperVal = upperVal;
+    this.includeLower = includeLower;
+    this.includeUpper = includeUpper;
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (obj instanceof DocValuesRangeQuery == false) {
+      return false;
+    }
+    final DocValuesRangeQuery that = (DocValuesRangeQuery) obj;
+    return field.equals(that.field)
+        && Objects.equals(lowerVal, that.lowerVal)
+        && Objects.equals(upperVal, that.upperVal)
+        && includeLower == that.includeLower
+        && includeUpper == that.includeUpper
+        && super.equals(obj);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(field, lowerVal, upperVal, includeLower, includeUpper, getBoost());
+  }
+
+  @Override
+  public String toString(String field) {
+    StringBuilder sb = new StringBuilder();
+    if (this.field.equals(field) == false) {
+      sb.append(this.field).append(':');
+    }
+    sb.append(includeLower ? '[' : '{');
+    sb.append(lowerVal == null ? "*" : lowerVal.toString());
+    sb.append(" TO ");
+    sb.append(upperVal == null ? "*" : upperVal.toString());
+    sb.append(includeUpper ? ']' : '}');
+    sb.append(ToStringUtils.boost(getBoost()));
+    return sb.toString();
+  }
+
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    if (lowerVal == null && upperVal == null) {
+      final FieldValueQuery rewritten = new FieldValueQuery(field);
+      rewritten.setBoost(getBoost());
+      return rewritten;
+    }
+    return this;
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    if (lowerVal == null && upperVal == null) {
+      throw new IllegalStateException("Both min and max values cannot be null, call rewrite first");
+    }
+    return new RandomAccessWeight(DocValuesRangeQuery.this) {
+      
+      @Override
+      protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {
+        if (lowerVal instanceof Long || upperVal instanceof Long) {
+
+          final SortedNumericDocValues values = DocValues.getSortedNumeric(context.reader(), field);
+
+          final long min;
+          if (lowerVal == null) {
+            min = Long.MIN_VALUE;
+          } else if (includeLower) {
+            min = (long) lowerVal;
+          } else {
+            min = 1 + (long) lowerVal;
+          }
+
+          final long max;
+          if (upperVal == null) {
+            max = Long.MAX_VALUE;
+          } else if (includeUpper) {
+            max = (long) upperVal;
+          } else {
+            max = -1 + (long) upperVal;
+          }
+
+          if (min > max) {
+            return null;
+          }
+
+          return new Bits() {
+
+            @Override
+            public boolean get(int doc) {
+              values.setDocument(doc);
+              final int count = values.count();
+              for (int i = 0; i < count; ++i) {
+                final long value = values.valueAt(i);
+                if (value >= min && value <= max) {
+                  return true;
+                }
+              }
+              return false;
+            }
+
+            @Override
+            public int length() {
+              return context.reader().maxDoc();
+            }
+
+          };
+
+        } else if (lowerVal instanceof BytesRef || upperVal instanceof BytesRef) {
+
+          final SortedSetDocValues values = DocValues.getSortedSet(context.reader(), field);
+
+          final long minOrd;
+          if (lowerVal == null) {
+            minOrd = 0;
+          } else {
+            final long ord = values.lookupTerm((BytesRef) lowerVal);
+            if (ord < 0) {
+              minOrd = -1 - ord;
+            } else if (includeLower) {
+              minOrd = ord;
+            } else {
+              minOrd = ord + 1;
+            }
+          }
+
+          final long maxOrd;
+          if (upperVal == null) {
+            maxOrd = values.getValueCount() - 1;
+          } else {
+            final long ord = values.lookupTerm((BytesRef) upperVal);
+            if (ord < 0) {
+              maxOrd = -2 - ord;
+            } else if (includeUpper) {
+              maxOrd = ord;
+            } else {
+              maxOrd = ord - 1;
+            }
+          }
+
+          if (minOrd > maxOrd) {
+            return null;
+          }
+
+          return new Bits() {
+
+            @Override
+            public boolean get(int doc) {
+              values.setDocument(doc);
+              for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {
+                if (ord >= minOrd && ord <= maxOrd) {
+                  return true;
+                }
+              }
+              return false;
+            }
+
+            @Override
+            public int length() {
+              return context.reader().maxDoc();
+            }
+
+          };
+
+        } else {
+          throw new AssertionError();
+        }
+      }
+    };
+  }
+
+}
diff --git a/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesTermsQuery.java b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesTermsQuery.java
new file mode 100644
index 0000000..8032628
--- /dev/null
+++ b/lucene/sandbox/src/java/org/apache/lucene/search/DocValuesTermsQuery.java
@@ -0,0 +1,192 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.AbstractList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Objects;
+
+import org.apache.lucene.index.DocValues;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.SortedSetDocValues;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.FixedBitSet;
+import org.apache.lucene.util.LongBitSet;
+
+/**
+ * A {@link Query} that only accepts documents whose
+ * term value in the specified field is contained in the
+ * provided set of allowed terms.
+ *
+ * <p>
+ * This is the same functionality as TermsQuery (from
+ * queries/), but because of drastically different
+ * implementations, they also have different performance
+ * characteristics, as described below.
+ *
+ * <p>
+ * <b>NOTE</b>: be very careful using this query: it is
+ * typically much slower than using {@code TermsQuery},
+ * but in certain specialized cases may be faster.
+ *
+ * <p>
+ * With each search, this query translates the specified
+ * set of Terms into a private {@link LongBitSet} keyed by
+ * term number per unique {@link IndexReader} (normally one
+ * reader per segment).  Then, during matching, the term
+ * number for each docID is retrieved from the cache and
+ * then checked for inclusion using the {@link LongBitSet}.
+ * Since all testing is done using RAM resident data
+ * structures, performance should be very fast, most likely
+ * fast enough to not require further caching of the
+ * DocIdSet for each possible combination of terms.
+ * However, because docIDs are simply scanned linearly, an
+ * index with a great many small documents may find this
+ * linear scan too costly.
+ *
+ * <p>
+ * In contrast, TermsQuery builds up an {@link FixedBitSet},
+ * keyed by docID, every time it's created, by enumerating
+ * through all matching docs using {@link org.apache.lucene.index.PostingsEnum} to seek
+ * and scan through each term's docID list.  While there is
+ * no linear scan of all docIDs, besides the allocation of
+ * the underlying array in the {@link FixedBitSet}, this
+ * approach requires a number of "disk seeks" in proportion
+ * to the number of terms, which can be exceptionally costly
+ * when there are cache misses in the OS's IO cache.
+ *
+ * <p>
+ * Generally, this filter will be slower on the first
+ * invocation for a given field, but subsequent invocations,
+ * even if you change the allowed set of Terms, should be
+ * faster than TermsQuery, especially as the number of
+ * Terms being matched increases.  If you are matching only
+ * a very small number of terms, and those terms in turn
+ * match a very small number of documents, TermsQuery may
+ * perform faster.
+ *
+ * <p>
+ * Which query is best is very application dependent.
+ *
+ * @lucene.experimental
+ */
+public class DocValuesTermsQuery extends Query {
+
+  private final String field;
+  private final BytesRef[] terms;
+
+  public DocValuesTermsQuery(String field, Collection<BytesRef> terms) {
+    this.field = Objects.requireNonNull(field);
+    Objects.requireNonNull(terms, "Collection of terms must not be null");
+    this.terms = terms.toArray(new BytesRef[terms.size()]);
+    ArrayUtil.timSort(this.terms, BytesRef.getUTF8SortedAsUnicodeComparator());
+  }
+
+  public DocValuesTermsQuery(String field, BytesRef... terms) {
+    this(field, Arrays.asList(terms));
+  }
+
+  public DocValuesTermsQuery(String field, String... terms) {
+    this(field, new AbstractList<BytesRef>() {
+      @Override
+      public BytesRef get(int index) {
+        return new BytesRef(terms[index]);
+      }
+      @Override
+      public int size() {
+        return terms.length;
+      }
+    });
+  }
+
+  @Override
+  public boolean equals(Object obj) {
+    if (obj instanceof DocValuesTermsQuery == false) {
+      return false;
+    }
+    DocValuesTermsQuery that = (DocValuesTermsQuery) obj;
+    if (!super.equals(obj)) {
+      return false;
+    }
+    if (!field.equals(that.field)) {
+      return false;
+    }
+    return Arrays.equals(terms, that.terms);
+  }
+
+  @Override
+  public int hashCode() {
+    return Objects.hash(field, Arrays.asList(terms), getBoost());
+  }
+
+  @Override
+  public String toString(String defaultField) {
+    StringBuilder sb = new StringBuilder();
+    sb.append(field).append(": [");
+    for (BytesRef term : terms) {
+      sb.append(term).append(", ");
+    }
+    if (terms.length > 0) {
+      sb.setLength(sb.length() - 2);
+    }
+    return sb.append(']').toString();
+  }
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    return new RandomAccessWeight(this) {
+
+      @Override
+      protected Bits getMatchingDocs(LeafReaderContext context) throws IOException {
+        final SortedSetDocValues values = DocValues.getSortedSet(context.reader(), field);
+        final LongBitSet bits = new LongBitSet(values.getValueCount());
+        for (BytesRef term : terms) {
+          final long ord = values.lookupTerm(term);
+          if (ord >= 0) {
+            bits.set(ord);
+          }
+        }
+        return new Bits() {
+
+          @Override
+          public boolean get(int doc) {
+            values.setDocument(doc);
+            for (long ord = values.nextOrd(); ord != SortedSetDocValues.NO_MORE_ORDS; ord = values.nextOrd()) {
+              if (bits.get(ord)) {
+                return true;
+              }
+            }
+            return false;
+          }
+
+          @Override
+          public int length() {
+            return context.reader().maxDoc();
+          }
+
+        };
+      }
+    };
+  }
+
+}
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesNumbersQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesNumbersQuery.java
new file mode 100644
index 0000000..81fc3dd
--- /dev/null
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesNumbersQuery.java
@@ -0,0 +1,194 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.SortedNumericDocValuesField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+public class TestDocValuesNumbersQuery extends LuceneTestCase {
+
+  public void testEquals() {
+    assertEquals(new DocValuesNumbersQuery("field", 17L, 42L), new DocValuesNumbersQuery("field", 17L, 42L));
+    assertEquals(new DocValuesNumbersQuery("field", 17L, 42L, 32416190071L), new DocValuesNumbersQuery("field", 17L, 32416190071L, 42L));
+    assertFalse(new DocValuesNumbersQuery("field", 42L).equals(new DocValuesNumbersQuery("field2", 42L)));
+    assertFalse(new DocValuesNumbersQuery("field", 17L, 42L).equals(new DocValuesNumbersQuery("field", 17L, 32416190071L)));
+  }
+
+  public void testDuelTermsQuery() throws IOException {
+    final int iters = atLeast(2);
+    for (int iter = 0; iter < iters; ++iter) {
+      final List<Long> allNumbers = new ArrayList<>();
+      final int numNumbers = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
+      for (int i = 0; i < numNumbers; ++i) {
+        allNumbers.add(random().nextLong());
+      }
+      Directory dir = newDirectory();
+      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+      final int numDocs = atLeast(100);
+      for (int i = 0; i < numDocs; ++i) {
+        Document doc = new Document();
+        final Long number = allNumbers.get(random().nextInt(allNumbers.size()));
+        doc.add(new StringField("text", number.toString(), Store.NO));
+        doc.add(new NumericDocValuesField("long", number));
+        doc.add(new SortedNumericDocValuesField("twolongs", number));
+        doc.add(new SortedNumericDocValuesField("twolongs", number*2));
+        iw.addDocument(doc);
+      }
+      if (numNumbers > 1 && random().nextBoolean()) {
+        iw.deleteDocuments(new TermQuery(new Term("text", allNumbers.get(0).toString())));
+      }
+      iw.commit();
+      final IndexReader reader = iw.getReader();
+      final IndexSearcher searcher = newSearcher(reader);
+      iw.close();
+
+      if (reader.numDocs() == 0) {
+        // may occasionally happen if all documents got the same term
+        IOUtils.close(reader, dir);
+        continue;
+      }
+
+      for (int i = 0; i < 100; ++i) {
+        final float boost = random().nextFloat() * 10;
+        final int numQueryNumbers = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
+        Set<Long> queryNumbers = new HashSet<>();
+        Set<Long> queryNumbersX2 = new HashSet<>();
+        for (int j = 0; j < numQueryNumbers; ++j) {
+          Long number = allNumbers.get(random().nextInt(allNumbers.size()));
+          queryNumbers.add(number);
+          queryNumbersX2.add(2*number);
+        }
+        final BooleanQuery bq = new BooleanQuery();
+        for (Long number : queryNumbers) {
+          bq.add(new TermQuery(new Term("text", number.toString())), Occur.SHOULD);
+        }
+        Query q1 = new ConstantScoreQuery(bq);
+        q1.setBoost(boost);
+
+        Query q2 = new DocValuesNumbersQuery("long", queryNumbers);
+        q2.setBoost(boost);
+        assertSameMatches(searcher, q1, q2, true);
+
+        Query q3 = new DocValuesNumbersQuery("twolongs", queryNumbers);
+        q3.setBoost(boost);
+        assertSameMatches(searcher, q1, q3, true);
+
+        Query q4 = new DocValuesNumbersQuery("twolongs", queryNumbersX2);
+        q4.setBoost(boost);
+        assertSameMatches(searcher, q1, q4, true);
+      }
+
+      reader.close();
+      dir.close();
+    }
+  }
+
+  public void testApproximation() throws IOException {
+    final int iters = atLeast(2);
+    for (int iter = 0; iter < iters; ++iter) {
+      final List<Long> allNumbers = new ArrayList<>();
+      final int numNumbers = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
+      for (int i = 0; i < numNumbers; ++i) {
+        allNumbers.add(random().nextLong());
+      }
+      Directory dir = newDirectory();
+      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+      final int numDocs = atLeast(100);
+      for (int i = 0; i < numDocs; ++i) {
+        Document doc = new Document();
+        final Long number = allNumbers.get(random().nextInt(allNumbers.size()));
+        doc.add(new StringField("text", number.toString(), Store.NO));
+        doc.add(new NumericDocValuesField("long", number));
+        iw.addDocument(doc);
+      }
+      if (numNumbers > 1 && random().nextBoolean()) {
+        iw.deleteDocuments(new TermQuery(new Term("text", allNumbers.get(0).toString())));
+      }
+      iw.commit();
+      final IndexReader reader = iw.getReader();
+      final IndexSearcher searcher = newSearcher(reader);
+      iw.close();
+
+      if (reader.numDocs() == 0) {
+        // may occasionally happen if all documents got the same term
+        IOUtils.close(reader, dir);
+        continue;
+      }
+
+      for (int i = 0; i < 100; ++i) {
+        final float boost = random().nextFloat() * 10;
+        final int numQueryNumbers = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
+        Set<Long> queryNumbers = new HashSet<>();
+        for (int j = 0; j < numQueryNumbers; ++j) {
+          queryNumbers.add(allNumbers.get(random().nextInt(allNumbers.size())));
+        }
+        final BooleanQuery bq = new BooleanQuery();
+        for (Long number : queryNumbers) {
+          bq.add(new TermQuery(new Term("text", number.toString())), Occur.SHOULD);
+        }
+        Query q1 = new ConstantScoreQuery(bq);
+        q1.setBoost(boost);
+        final Query q2 = new DocValuesNumbersQuery("long", queryNumbers);
+        q2.setBoost(boost);
+
+        BooleanQuery bq1 = new BooleanQuery();
+        bq1.add(q1, Occur.MUST);
+        bq1.add(new TermQuery(new Term("text", allNumbers.get(0).toString())), Occur.FILTER);
+
+        BooleanQuery bq2 = new BooleanQuery();
+        bq2.add(q2, Occur.MUST);
+        bq2.add(new TermQuery(new Term("text", allNumbers.get(0).toString())), Occur.FILTER);
+
+        assertSameMatches(searcher, bq1, bq2, true);
+      }
+
+      reader.close();
+      dir.close();
+    }
+  }
+
+  private void assertSameMatches(IndexSearcher searcher, Query q1, Query q2, boolean scores) throws IOException {
+    final int maxDoc = searcher.getIndexReader().maxDoc();
+    final TopDocs td1 = searcher.search(q1, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    final TopDocs td2 = searcher.search(q2, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    assertEquals(td1.totalHits, td2.totalHits);
+    for (int i = 0; i < td1.scoreDocs.length; ++i) {
+      assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
+      if (scores) {
+        assertEquals(td1.scoreDocs[i].score, td2.scoreDocs[i].score, 10e-7);
+      }
+    }
+  }
+}
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
new file mode 100644
index 0000000..fc0ed49
--- /dev/null
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesRangeQuery.java
@@ -0,0 +1,283 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.LongField;
+import org.apache.lucene.document.NumericDocValuesField;
+import org.apache.lucene.document.SortedDocValuesField;
+import org.apache.lucene.document.SortedNumericDocValuesField;
+import org.apache.lucene.document.SortedSetDocValuesField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.BytesRefBuilder;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.NumericUtils;
+import org.apache.lucene.util.TestUtil;
+
+public class TestDocValuesRangeQuery extends LuceneTestCase {
+
+  public void testDuelNumericRangeQuery() throws IOException {
+    final int iters = atLeast(10);
+      for (int iter = 0; iter < iters; ++iter) {
+      Directory dir = newDirectory();
+      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+      final int numDocs = atLeast(100);
+      for (int i = 0; i < numDocs; ++i) {
+        Document doc = new Document();
+        final int numValues = random().nextInt(2);
+        for (int j = 0; j < numValues; ++j) {
+          final long value = TestUtil.nextLong(random(), -100, 10000);
+          doc.add(new SortedNumericDocValuesField("dv", value));
+          doc.add(new LongField("idx", value, Store.NO));
+        }
+        iw.addDocument(doc);
+      }
+      if (random().nextBoolean()) {
+        iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
+      }
+      iw.commit();
+      final IndexReader reader = iw.getReader();
+      final IndexSearcher searcher = newSearcher(reader);
+      iw.close();
+
+      for (int i = 0; i < 100; ++i) {
+        final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+        final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+        final boolean minInclusive = random().nextBoolean();
+        final boolean maxInclusive = random().nextBoolean();
+        final Query q1 = NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive);
+        final Query q2 = DocValuesRangeQuery.newLongRange("dv", min, max, minInclusive, maxInclusive);
+        assertSameMatches(searcher, q1, q2, false);
+      }
+
+      reader.close();
+      dir.close();
+    }
+  }
+
+  private static BytesRef toSortableBytes(Long l) {
+    if (l == null) {
+      return null;
+    } else {
+      final BytesRefBuilder bytes = new BytesRefBuilder();
+      NumericUtils.longToPrefixCoded(l, 0, bytes);
+      return bytes.get();
+    }
+  }
+
+  public void testDuelNumericSorted() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    final int numDocs = atLeast(100);
+    for (int i = 0; i < numDocs; ++i) {
+      Document doc = new Document();
+      final int numValues = random().nextInt(3);
+      for (int j = 0; j < numValues; ++j) {
+        final long value = TestUtil.nextLong(random(), -100, 10000);
+        doc.add(new SortedNumericDocValuesField("dv1", value));
+        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
+      }
+      iw.addDocument(doc);
+    }
+    if (random().nextBoolean()) {
+      iw.deleteDocuments(DocValuesRangeQuery.newLongRange("dv1", 0L, 10L, true, true));
+    }
+    iw.commit();
+    final IndexReader reader = iw.getReader();
+    final IndexSearcher searcher = newSearcher(reader);
+    iw.close();
+
+    for (int i = 0; i < 100; ++i) {
+      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final boolean minInclusive = random().nextBoolean();
+      final boolean maxInclusive = random().nextBoolean();
+      final Query q1 = DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive);
+      final Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive);
+      assertSameMatches(searcher, q1, q2, true);
+    }
+
+    reader.close();
+    dir.close();
+  }
+
+  public void testScore() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    final int numDocs = atLeast(100);
+    for (int i = 0; i < numDocs; ++i) {
+      Document doc = new Document();
+      final int numValues = random().nextInt(3);
+      for (int j = 0; j < numValues; ++j) {
+        final long value = TestUtil.nextLong(random(), -100, 10000);
+        doc.add(new SortedNumericDocValuesField("dv1", value));
+        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
+      }
+      iw.addDocument(doc);
+    }
+    if (random().nextBoolean()) {
+      iw.deleteDocuments(DocValuesRangeQuery.newLongRange("dv1", 0L, 10L, true, true));
+    }
+    iw.commit();
+    final IndexReader reader = iw.getReader();
+    final IndexSearcher searcher = newSearcher(reader);
+    iw.close();
+
+    for (int i = 0; i < 100; ++i) {
+      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final boolean minInclusive = random().nextBoolean();
+      final boolean maxInclusive = random().nextBoolean();
+
+      final float boost = random().nextFloat() * 10;
+
+      final Query q1 = DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive);
+      q1.setBoost(boost);
+      final ConstantScoreQuery csq1 = new ConstantScoreQuery(DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive));
+      csq1.setBoost(boost);
+      assertSameMatches(searcher, q1, csq1, true);
+
+      final Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive);
+      q2.setBoost(boost);
+      final ConstantScoreQuery csq2 = new ConstantScoreQuery(DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive));
+      csq2.setBoost(boost);
+      assertSameMatches(searcher, q2, csq2, true);
+    }
+
+    reader.close();
+    dir.close();
+  }
+
+  public void testApproximation() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    final int numDocs = atLeast(100);
+    for (int i = 0; i < numDocs; ++i) {
+      Document doc = new Document();
+      final int numValues = random().nextInt(3);
+      for (int j = 0; j < numValues; ++j) {
+        final long value = TestUtil.nextLong(random(), -100, 10000);
+        doc.add(new SortedNumericDocValuesField("dv1", value));
+        doc.add(new SortedSetDocValuesField("dv2", toSortableBytes(value)));
+        doc.add(new LongField("idx", value, Store.NO));
+        doc.add(new StringField("f", random().nextBoolean() ? "a" : "b", Store.NO));
+      }
+      iw.addDocument(doc);
+    }
+    if (random().nextBoolean()) {
+      iw.deleteDocuments(NumericRangeQuery.newLongRange("idx", 0L, 10L, true, true));
+    }
+    iw.commit();
+    final IndexReader reader = iw.getReader();
+    final IndexSearcher searcher = newSearcher(reader);
+    iw.close();
+
+    for (int i = 0; i < 100; ++i) {
+      final Long min = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final Long max = random().nextBoolean() ? null : TestUtil.nextLong(random(), -100, 1000);
+      final boolean minInclusive = random().nextBoolean();
+      final boolean maxInclusive = random().nextBoolean();
+
+      BooleanQuery ref = new BooleanQuery();
+      ref.add(NumericRangeQuery.newLongRange("idx", min, max, minInclusive, maxInclusive), Occur.FILTER);
+      ref.add(new TermQuery(new Term("f", "a")), Occur.MUST);
+
+      BooleanQuery bq1 = new BooleanQuery();
+      bq1.add(DocValuesRangeQuery.newLongRange("dv1", min, max, minInclusive, maxInclusive), Occur.FILTER);
+      bq1.add(new TermQuery(new Term("f", "a")), Occur.MUST);
+
+      assertSameMatches(searcher, ref, bq1, true);
+
+      BooleanQuery bq2 = new BooleanQuery();
+      bq2.add(DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(min), toSortableBytes(max), minInclusive, maxInclusive), Occur.FILTER);
+      bq2.add(new TermQuery(new Term("f", "a")), Occur.MUST);
+
+      assertSameMatches(searcher, ref, bq2, true);
+    }
+
+    reader.close();
+    dir.close();
+  }
+
+  private void assertSameMatches(IndexSearcher searcher, Query q1, Query q2, boolean scores) throws IOException {
+    final int maxDoc = searcher.getIndexReader().maxDoc();
+    final TopDocs td1 = searcher.search(q1, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    final TopDocs td2 = searcher.search(q2, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    assertEquals(td1.totalHits, td2.totalHits);
+    for (int i = 0; i < td1.scoreDocs.length; ++i) {
+      assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
+      if (scores) {
+        assertEquals(td1.scoreDocs[i].score, td2.scoreDocs[i].score, 10e-7);
+      }
+    }
+  }
+
+  public void testToString() {
+    assertEquals("f:[2 TO 5]", DocValuesRangeQuery.newLongRange("f", 2L, 5L, true, true).toString());
+    assertEquals("f:{2 TO 5]", DocValuesRangeQuery.newLongRange("f", 2L, 5L, false, true).toString());
+    assertEquals("f:{2 TO 5}", DocValuesRangeQuery.newLongRange("f", 2L, 5L, false, false).toString());
+    assertEquals("f:{* TO 5}", DocValuesRangeQuery.newLongRange("f", null, 5L, false, false).toString());
+    assertEquals("f:[2 TO *}", DocValuesRangeQuery.newLongRange("f", 2L, null, true, false).toString());
+
+    BytesRef min = new BytesRef("a");
+    BytesRef max = new BytesRef("b");
+    assertEquals("f:[[61] TO [62]]", DocValuesRangeQuery.newBytesRefRange("f", min, max, true, true).toString());
+    assertEquals("f:{[61] TO [62]]", DocValuesRangeQuery.newBytesRefRange("f", min, max, false, true).toString());
+    assertEquals("f:{[61] TO [62]}", DocValuesRangeQuery.newBytesRefRange("f", min, max, false, false).toString());
+    assertEquals("f:{* TO [62]}", DocValuesRangeQuery.newBytesRefRange("f", null, max, false, false).toString());
+    assertEquals("f:[[61] TO *}", DocValuesRangeQuery.newBytesRefRange("f", min, null, true, false).toString());
+  }
+
+  public void testDocValuesRangeSupportsApproximation() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(new NumericDocValuesField("dv1", 5L));
+    doc.add(new SortedDocValuesField("dv2", toSortableBytes(42L)));
+    iw.addDocument(doc);
+    iw.commit();
+    final IndexReader reader = iw.getReader();
+    final LeafReaderContext ctx = reader.leaves().get(0);
+    final IndexSearcher searcher = newSearcher(reader);
+    iw.close();
+
+    Query q1 = DocValuesRangeQuery.newLongRange("dv1", 0L, 100L, random().nextBoolean(), random().nextBoolean());
+    Weight w = searcher.createNormalizedWeight(q1, true);
+    Scorer s = w.scorer(ctx, null);
+    assertNotNull(s.asTwoPhaseIterator());
+
+    Query q2 = DocValuesRangeQuery.newBytesRefRange("dv2", toSortableBytes(0L), toSortableBytes(100L), random().nextBoolean(), random().nextBoolean());
+    w = searcher.createNormalizedWeight(q2, true);
+    s = w.scorer(ctx, null);
+    assertNotNull(s.asTwoPhaseIterator());
+
+    reader.close();
+    dir.close();
+  }
+
+}
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java
new file mode 100644
index 0000000..28607e1
--- /dev/null
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestDocValuesTermsQuery.java
@@ -0,0 +1,188 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.SortedDocValuesField;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
+
+public class TestDocValuesTermsQuery extends LuceneTestCase {
+
+  public void testEquals() {
+    assertEquals(new DocValuesTermsQuery("foo", "bar"), new DocValuesTermsQuery("foo", "bar"));
+    assertEquals(new DocValuesTermsQuery("foo", "bar", "baz"), new DocValuesTermsQuery("foo", "baz", "bar"));
+    assertFalse(new DocValuesTermsQuery("foo", "bar").equals(new DocValuesTermsQuery("foo2", "bar")));
+    assertFalse(new DocValuesTermsQuery("foo", "bar").equals(new DocValuesTermsQuery("foo", "baz")));
+  }
+
+  public void testDuelTermsQuery() throws IOException {
+    final int iters = atLeast(2);
+    for (int iter = 0; iter < iters; ++iter) {
+      final List<Term> allTerms = new ArrayList<>();
+      final int numTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
+      for (int i = 0; i < numTerms; ++i) {
+        final String value = TestUtil.randomAnalysisString(random(), 10, true);
+        allTerms.add(new Term("f", value));
+      }
+      Directory dir = newDirectory();
+      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+      final int numDocs = atLeast(100);
+      for (int i = 0; i < numDocs; ++i) {
+        Document doc = new Document();
+        final Term term = allTerms.get(random().nextInt(allTerms.size()));
+        doc.add(new StringField(term.field(), term.text(), Store.NO));
+        doc.add(new SortedDocValuesField(term.field(), new BytesRef(term.text())));
+        iw.addDocument(doc);
+      }
+      if (numTerms > 1 && random().nextBoolean()) {
+        iw.deleteDocuments(new TermQuery(allTerms.get(0)));
+      }
+      iw.commit();
+      final IndexReader reader = iw.getReader();
+      final IndexSearcher searcher = newSearcher(reader);
+      iw.close();
+
+      if (reader.numDocs() == 0) {
+        // may occasionally happen if all documents got the same term
+        IOUtils.close(reader, dir);
+        continue;
+      }
+
+      for (int i = 0; i < 100; ++i) {
+        final float boost = random().nextFloat() * 10;
+        final int numQueryTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
+        List<Term> queryTerms = new ArrayList<>();
+        for (int j = 0; j < numQueryTerms; ++j) {
+          queryTerms.add(allTerms.get(random().nextInt(allTerms.size())));
+        }
+        final BooleanQuery bq = new BooleanQuery();
+        for (Term term : queryTerms) {
+          bq.add(new TermQuery(term), Occur.SHOULD);
+        }
+        Query q1 = new ConstantScoreQuery(bq);
+        q1.setBoost(boost);
+        List<String> bytesTerms = new ArrayList<>();
+        for (Term term : queryTerms) {
+          bytesTerms.add(term.text());
+        }
+        final Query q2 = new DocValuesTermsQuery("f", bytesTerms.toArray(new String[0]));
+        q2.setBoost(boost);
+        assertSameMatches(searcher, q1, q2, true);
+      }
+
+      reader.close();
+      dir.close();
+    }
+  }
+
+  public void testApproximation() throws IOException {
+    final int iters = atLeast(2);
+    for (int iter = 0; iter < iters; ++iter) {
+      final List<Term> allTerms = new ArrayList<>();
+      final int numTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 10));
+      for (int i = 0; i < numTerms; ++i) {
+        final String value = TestUtil.randomAnalysisString(random(), 10, true);
+        allTerms.add(new Term("f", value));
+      }
+      Directory dir = newDirectory();
+      RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+      final int numDocs = atLeast(100);
+      for (int i = 0; i < numDocs; ++i) {
+        Document doc = new Document();
+        final Term term = allTerms.get(random().nextInt(allTerms.size()));
+        doc.add(new StringField(term.field(), term.text(), Store.NO));
+        doc.add(new SortedDocValuesField(term.field(), new BytesRef(term.text())));
+        iw.addDocument(doc);
+      }
+      if (numTerms > 1 && random().nextBoolean()) {
+        iw.deleteDocuments(new TermQuery(allTerms.get(0)));
+      }
+      iw.commit();
+      final IndexReader reader = iw.getReader();
+      final IndexSearcher searcher = newSearcher(reader);
+      iw.close();
+
+      if (reader.numDocs() == 0) {
+        // may occasionally happen if all documents got the same term
+        IOUtils.close(reader, dir);
+        continue;
+      }
+
+      for (int i = 0; i < 100; ++i) {
+        final float boost = random().nextFloat() * 10;
+        final int numQueryTerms = TestUtil.nextInt(random(), 1, 1 << TestUtil.nextInt(random(), 1, 8));
+        List<Term> queryTerms = new ArrayList<>();
+        for (int j = 0; j < numQueryTerms; ++j) {
+          queryTerms.add(allTerms.get(random().nextInt(allTerms.size())));
+        }
+        final BooleanQuery bq = new BooleanQuery();
+        for (Term term : queryTerms) {
+          bq.add(new TermQuery(term), Occur.SHOULD);
+        }
+        Query q1 = new ConstantScoreQuery(bq);
+        q1.setBoost(boost);
+        List<String> bytesTerms = new ArrayList<>();
+        for (Term term : queryTerms) {
+          bytesTerms.add(term.text());
+        }
+        final Query q2 = new DocValuesTermsQuery("f", bytesTerms.toArray(new String[0]));
+        q2.setBoost(boost);
+
+        BooleanQuery bq1 = new BooleanQuery();
+        bq1.add(q1, Occur.MUST);
+        bq1.add(new TermQuery(allTerms.get(0)), Occur.FILTER);
+
+        BooleanQuery bq2 = new BooleanQuery();
+        bq2.add(q2, Occur.MUST);
+        bq2.add(new TermQuery(allTerms.get(0)), Occur.FILTER);
+
+        assertSameMatches(searcher, bq1, bq2, true);
+      }
+
+      reader.close();
+      dir.close();
+    }
+  }
+
+  private void assertSameMatches(IndexSearcher searcher, Query q1, Query q2, boolean scores) throws IOException {
+    final int maxDoc = searcher.getIndexReader().maxDoc();
+    final TopDocs td1 = searcher.search(q1, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    final TopDocs td2 = searcher.search(q2, maxDoc, scores ? Sort.RELEVANCE : Sort.INDEXORDER);
+    assertEquals(td1.totalHits, td2.totalHits);
+    for (int i = 0; i < td1.scoreDocs.length; ++i) {
+      assertEquals(td1.scoreDocs[i].doc, td2.scoreDocs[i].doc);
+      if (scores) {
+        assertEquals(td1.scoreDocs[i].score, td2.scoreDocs[i].score, 10e-7);
+      }
+    }
+  }
+}
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
new file mode 100644
index 0000000..796336c
--- /dev/null
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestFieldCacheTermsFilter.java
@@ -0,0 +1,75 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.SortedDocValuesField;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.store.Directory;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * A basic unit test for FieldCacheTermsFilter
+ *
+ * @see org.apache.lucene.search.DocValuesTermsQuery
+ */
+public class TestFieldCacheTermsFilter extends LuceneTestCase {
+  public void testMissingTerms() throws Exception {
+    String fieldName = "field1";
+    Directory rd = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), rd);
+    for (int i = 0; i < 100; i++) {
+      Document doc = new Document();
+      int term = i * 10; //terms are units of 10;
+      doc.add(newStringField(fieldName, "" + term, Field.Store.YES));
+      doc.add(new SortedDocValuesField(fieldName, new BytesRef("" + term)));
+      w.addDocument(doc);
+    }
+    IndexReader reader = w.getReader();
+    w.close();
+
+    IndexSearcher searcher = newSearcher(reader);
+    int numDocs = reader.numDocs();
+    ScoreDoc[] results;
+
+    List<String> terms = new ArrayList<>();
+    terms.add("5");
+    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    assertEquals("Must match nothing", 0, results.length);
+
+    terms = new ArrayList<>();
+    terms.add("10");
+    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    assertEquals("Must match 1", 1, results.length);
+
+    terms = new ArrayList<>();
+    terms.add("10");
+    terms.add("20");
+    results = searcher.search(new DocValuesTermsQuery(fieldName,  terms.toArray(new String[0])), numDocs).scoreDocs;
+    assertEquals("Must match 2", 2, results.length);
+
+    reader.close();
+    rd.close();
+  }
+}
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
index d6e364b..cc95341 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
@@ -112,19 +112,14 @@ public abstract class BaseExplanationTestCase extends LuceneTestCase {
   }
   
   /** 
-   * Convenience subclass of FieldCacheTermsFilter
+   * Convenience subclass of TermsQuery
    */
-  public static class ItemizedQuery extends DocValuesTermsQuery {
-    private static String[] int2str(int [] terms) {
-      String [] out = new String[terms.length];
-      for (int i = 0; i < terms.length; i++) {
-        out[i] = ""+terms[i];
-      }
-      return out;
-    }
-    public ItemizedQuery(int [] keys) {
-      super(KEY, int2str(keys));
+  protected Query matchTheseItems(int[] terms) {
+    BooleanQuery query = new BooleanQuery();
+    for(int term : terms) {
+      query.add(new BooleanClause(new TermQuery(new Term(KEY, ""+term)), BooleanClause.Occur.SHOULD));
     }
+    return query;
   }
 
   /** helper for generating MultiPhraseQueries */
diff --git a/solr/common-build.xml b/solr/common-build.xml
index df0b702..ab8e254 100644
--- a/solr/common-build.xml
+++ b/solr/common-build.xml
@@ -103,6 +103,7 @@
     <pathelement location="${queries.jar}"/>
     <pathelement location="${queryparser.jar}"/>
     <pathelement location="${join.jar}"/>
+    <pathelement location="${sandbox.jar}"/>
   </path>
 
   <path id="solr.base.classpath">
@@ -168,7 +169,7 @@
 
   <target name="prep-lucene-jars" 
   	      depends="jar-lucene-core, jar-backward-codecs, jar-analyzers-phonetic, jar-analyzers-kuromoji, jar-codecs,jar-expressions, jar-suggest, jar-highlighter, jar-memory,
-  	               jar-misc, jar-spatial, jar-grouping, jar-queries, jar-queryparser, jar-join">
+  	               jar-misc, jar-spatial, jar-grouping, jar-queries, jar-queryparser, jar-join, jar-sandbox">
   	  <property name="solr.deps.compiled" value="true"/>
   </target>
 	

