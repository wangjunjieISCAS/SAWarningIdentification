GitDiffStart: fe2d1194fb6b4323c87802549b8d81e0d8363326 | Tue Jul 24 01:56:39 2012 +0000
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilterFactory.java
new file mode 100644
index 0000000..97fc662
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilterFactory.java
@@ -0,0 +1,47 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+
+/**
+ * Factory for {@link ArabicNormalizationFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_arnormal" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ArabicNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ArabicNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+
+  public ArabicNormalizationFilter create(TokenStream input) {
+    return new ArabicNormalizationFilter(input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilterFactory.java
new file mode 100644
index 0000000..0baa6b5
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ar.ArabicStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+
+/**
+ * Factory for {@link ArabicStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_arstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ArabicNormalizationFilterFactory"/&gt;
+ *     &lt;filter class="solr.ArabicStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ArabicStemFilterFactory extends TokenFilterFactory {
+
+
+  public ArabicStemFilter create(TokenStream input) {
+    return new ArabicStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilterFactory.java
new file mode 100644
index 0000000..5c91995
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.bg.BulgarianStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link BulgarianStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_bgstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.BulgarianStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class BulgarianStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new BulgarianStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilterFactory.java
new file mode 100644
index 0000000..8928d64
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilterFactory.java
@@ -0,0 +1,43 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.br.BrazilianStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link BrazilianStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_brstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.BrazilianStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class BrazilianStemFilterFactory extends TokenFilterFactory {
+  public BrazilianStemFilter create(TokenStream in) {
+    return new BrazilianStemFilter(in);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterFactory.java
new file mode 100644
index 0000000..6e91a95
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterFactory.java
@@ -0,0 +1,71 @@
+package org.apache.solr.analysis;
+
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
+import org.apache.lucene.analysis.util.CharFilterFactory;
+
+import java.io.Reader;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+* Factory for {@link HTMLStripCharFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_html" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;charFilter class="solr.HTMLStripCharFilterFactory" escapedTags="a, title" /&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+ public class HTMLStripCharFilterFactory extends CharFilterFactory {
+  
+  Set<String> escapedTags = null;
+  Pattern TAG_NAME_PATTERN = Pattern.compile("[^\\s,]+");
+
+  public HTMLStripCharFilter create(Reader input) {
+    HTMLStripCharFilter charFilter;
+    if (null == escapedTags) {
+      charFilter = new HTMLStripCharFilter(input);
+    } else {
+      charFilter = new HTMLStripCharFilter(input, escapedTags);
+    }
+    return charFilter;
+  }
+  
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    String escapedTagsArg = args.get("escapedTags");
+    if (null != escapedTagsArg) {
+      Matcher matcher = TAG_NAME_PATTERN.matcher(escapedTagsArg);
+      while (matcher.find()) {
+        if (null == escapedTags) {
+          escapedTags = new HashSet<String>();
+        }
+        escapedTags.add(matcher.group(0));
+      }
+    }
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java
new file mode 100644
index 0000000..a518e4a
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilterFactory.java
@@ -0,0 +1,135 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.File;
+import java.io.IOException;
+import java.io.Reader;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.CharFilter;
+import org.apache.lucene.analysis.charfilter.MappingCharFilter;
+import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
+import org.apache.lucene.analysis.util.*;
+import org.apache.solr.common.util.StrUtils;
+
+/**
+ * Factory for {@link MappingCharFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_map" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;charFilter class="solr.MappingCharFilterFactory" mapping="mapping.txt"/&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ * @since Solr 1.4
+ *
+ */
+public class MappingCharFilterFactory extends CharFilterFactory implements
+    ResourceLoaderAware, MultiTermAwareComponent {
+
+  protected NormalizeCharMap normMap;
+  private String mapping;
+
+  public void inform(ResourceLoader loader) {
+    mapping = args.get( "mapping" );
+
+    if( mapping != null ){
+      List<String> wlist = null;
+      try{
+        File mappingFile = new File( mapping );
+        if( mappingFile.exists() ){
+          wlist = loader.getLines( mapping );
+        }
+        else{
+          List<String> files = StrUtils.splitFileNames( mapping );
+          wlist = new ArrayList<String>();
+          for( String file : files ){
+            List<String> lines = loader.getLines( file.trim() );
+            wlist.addAll( lines );
+          }
+        }
+      }
+      catch( IOException e ){
+        throw new InitializationException("IOException thrown while loading mappings", e);
+      }
+      final NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
+      parseRules( wlist, builder );
+      normMap = builder.build();
+    }
+  }
+
+  public CharFilter create(Reader input) {
+    return new MappingCharFilter(normMap,input);
+  }
+
+  // "source" => "target"
+  static Pattern p = Pattern.compile( "\"(.*)\"\\s*=>\\s*\"(.*)\"\\s*$" );
+
+  protected void parseRules( List<String> rules, NormalizeCharMap.Builder builder ){
+    for( String rule : rules ){
+      Matcher m = p.matcher( rule );
+      if( !m.find() )
+        throw new InitializationException("Invalid Mapping Rule : [" + rule + "], file = " + mapping);
+      builder.add( parseString( m.group( 1 ) ), parseString( m.group( 2 ) ) );
+    }
+  }
+
+  char[] out = new char[256];
+  
+  protected String parseString( String s ){
+    int readPos = 0;
+    int len = s.length();
+    int writePos = 0;
+    while( readPos < len ){
+      char c = s.charAt( readPos++ );
+      if( c == '\\' ){
+        if( readPos >= len )
+          throw new InitializationException("Invalid escaped char in [" + s + "]");
+        c = s.charAt( readPos++ );
+        switch( c ) {
+          case '\\' : c = '\\'; break;
+          case '"' : c = '"'; break;
+          case 'n' : c = '\n'; break;
+          case 't' : c = '\t'; break;
+          case 'r' : c = '\r'; break;
+          case 'b' : c = '\b'; break;
+          case 'f' : c = '\f'; break;
+          case 'u' :
+            if( readPos + 3 >= len )
+              throw new InitializationException("Invalid escaped char in [" + s + "]");
+            c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
+            readPos += 4;
+            break;
+        }
+      }
+      out[writePos++] = c;
+    }
+    return new String( out, 0, writePos );
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java
new file mode 100644
index 0000000..bea0bff
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilterFactory.java
@@ -0,0 +1,65 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.cjk.CJKBigramFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link CJKBigramFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_cjk" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.CJKWidthFilterFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.CJKBigramFilterFactory" 
+ *       han="true" hiragana="true" 
+ *       katakana="true" hangul="true" /&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class CJKBigramFilterFactory extends TokenFilterFactory {
+  int flags;
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    flags = 0;
+    if (getBoolean("han", true)) {
+      flags |= CJKBigramFilter.HAN;
+    }
+    if (getBoolean("hiragana", true)) {
+      flags |= CJKBigramFilter.HIRAGANA;
+    }
+    if (getBoolean("katakana", true)) {
+      flags |= CJKBigramFilter.KATAKANA;
+    }
+    if (getBoolean("hangul", true)) {
+      flags |= CJKBigramFilter.HANGUL;
+    }
+  }
+  
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new CJKBigramFilter(input, flags);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKWidthFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKWidthFilterFactory.java
new file mode 100644
index 0000000..3213b3c
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKWidthFilterFactory.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.cjk.CJKWidthFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link CJKWidthFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_cjk" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.CJKWidthFilterFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.CJKBigramFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+
+public class CJKWidthFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new CJKWidthFilter(input);
+  }
+  
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
new file mode 100644
index 0000000..f32df81
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilterFactory.java
@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
+import org.apache.lucene.analysis.core.StopAnalyzer;
+import org.apache.lucene.analysis.util.*;
+
+/**
+ * Constructs a {@link CommonGramsFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_cmmngrms" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.CommonGramsFilterFactory" words="commongramsstopwords.txt" ignoreCase="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+
+/*
+ * This is pretty close to a straight copy from StopFilterFactory
+ */
+public class CommonGramsFilterFactory extends TokenFilterFactory implements
+    ResourceLoaderAware {
+
+  public void inform(ResourceLoader loader) {
+    String commonWordFiles = args.get("words");
+    ignoreCase = getBoolean("ignoreCase", false);
+
+    if (commonWordFiles != null) {
+      try {
+        if ("snowball".equalsIgnoreCase(args.get("format"))) {
+          commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
+        } else {
+          commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
+        }
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading common word file", e);
+      }
+    } else {
+      commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
+    }
+  }
+      
+    //Force the use of a char array set, as it is the most performant, although this may break things if Lucene ever goes away from it.  See SOLR-1095
+    private CharArraySet commonWords;
+    private boolean ignoreCase;
+
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public CharArraySet getCommonWords() {
+    return commonWords;
+  }
+
+  public CommonGramsFilter create(TokenStream input) {
+    CommonGramsFilter commonGrams = new CommonGramsFilter(luceneMatchVersion, input, commonWords);
+    return commonGrams;
+  }
+}
+ 
+  
+  
\ No newline at end of file
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java
new file mode 100644
index 0000000..38e407f
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsQueryFilterFactory.java
@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
+import org.apache.lucene.analysis.commongrams.CommonGramsQueryFilter;
+import org.apache.lucene.analysis.core.StopAnalyzer;
+import org.apache.lucene.analysis.util.*;
+
+/**
+ * Construct {@link CommonGramsQueryFilter}.
+ * 
+ * This is pretty close to a straight copy from {@link StopFilterFactory}.
+ * 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_cmmngrmsqry" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.CommonGramsQueryFilterFactory" words="commongramsquerystopwords.txt" ignoreCase="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class CommonGramsQueryFilterFactory extends TokenFilterFactory
+    implements ResourceLoaderAware {
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public void inform(ResourceLoader loader) {
+    String commonWordFiles = args.get("words");
+    ignoreCase = getBoolean("ignoreCase", false);
+
+    if (commonWordFiles != null) {
+      try {
+        if ("snowball".equalsIgnoreCase(args.get("format"))) {
+          commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
+        } else {
+          commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
+        }
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading common word file", e);
+      }
+    } else {
+      commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
+    }
+  }
+
+  // Force the use of a char array set, as it is the most performant, although
+  // this may break things if Lucene ever goes away from it. See SOLR-1095
+  private CharArraySet commonWords;
+
+  private boolean ignoreCase;
+
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public CharArraySet getCommonWords() {
+    return commonWords;
+  }
+
+  /**
+   * Create a CommonGramsFilter and wrap it with a CommonGramsQueryFilter
+   */
+  public CommonGramsQueryFilter create(TokenStream input) {
+    CommonGramsFilter commonGrams = new CommonGramsFilter(luceneMatchVersion, input, commonWords);
+    CommonGramsQueryFilter commonGramsQuery = new CommonGramsQueryFilter(
+        commonGrams);
+    return commonGramsQuery;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
new file mode 100644
index 0000000..4664dc3
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilterFactory.java
@@ -0,0 +1,72 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+import org.apache.lucene.analysis.compound.*;
+import org.apache.lucene.analysis.util.*;
+import org.apache.lucene.analysis.TokenStream;
+
+import java.util.Map;
+import java.io.IOException;
+
+/** 
+ * Factory for {@link DictionaryCompoundWordTokenFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_dictcomp" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.DictionaryCompoundWordTokenFilterFactory" dictionary="dictionary.txt"
+ *     	     minWordSize="5" minSubwordSize="2" maxSubwordSize="15" onlyLongestMatch="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class DictionaryCompoundWordTokenFilterFactory extends TokenFilterFactory  implements ResourceLoaderAware {
+  private CharArraySet dictionary;
+  private String dictFile;
+  private int minWordSize;
+  private int minSubwordSize;
+  private int maxSubwordSize;
+  private boolean onlyLongestMatch;
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    assureMatchVersion();
+    dictFile = args.get("dictionary");
+    if (null == dictFile) {
+      throw new InitializationException("Missing required parameter: dictionary");
+    }
+
+    minWordSize= getInt("minWordSize",CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
+    minSubwordSize= getInt("minSubwordSize",CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE);
+    maxSubwordSize= getInt("maxSubwordSize",CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
+    onlyLongestMatch = getBoolean("onlyLongestMatch",true);
+  }
+  public void inform(ResourceLoader loader) {
+    try {
+      dictionary = super.getWordSet(loader, dictFile, false);
+    } catch (IOException e) {
+      throw new InitializationException("IOException thrown while loading dictionary", e);
+    }
+  }
+  public DictionaryCompoundWordTokenFilter create(TokenStream input) {
+    return new DictionaryCompoundWordTokenFilter(luceneMatchVersion,input,dictionary,minWordSize,minSubwordSize,maxSubwordSize,onlyLongestMatch);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
new file mode 100644
index 0000000..d4a0da3
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilterFactory.java
@@ -0,0 +1,109 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.commons.io.IOUtils;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase;
+import org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter;
+import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree;
+import org.apache.lucene.analysis.util.*;
+
+import java.util.Map;
+import java.io.InputStream;
+import org.xml.sax.InputSource;
+
+/**
+ * Factory for {@link HyphenationCompoundWordTokenFilter}.
+ * <p>
+ * This factory accepts the following parameters:
+ * <ul>
+ *  <li><code>hyphenator</code> (mandatory): path to the FOP xml hyphenation pattern. 
+ *  See <a href="http://offo.sourceforge.net/hyphenation/">http://offo.sourceforge.net/hyphenation/</a>.
+ *  <li><code>encoding</code> (optional): encoding of the xml hyphenation file. defaults to UTF-8.
+ *  <li><code>dictionary</code> (optional): dictionary of words. defaults to no dictionary.
+ *  <li><code>minWordSize</code> (optional): minimal word length that gets decomposed. defaults to 5.
+ *  <li><code>minSubwordSize</code> (optional): minimum length of subwords. defaults to 2.
+ *  <li><code>maxSubwordSize</code> (optional): maximum length of subwords. defaults to 15.
+ *  <li><code>onlyLongestMatch</code> (optional): if true, adds only the longest matching subword 
+ *    to the stream. defaults to false.
+ * </ul>
+ * <p>
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_hyphncomp" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.HyphenationCompoundWordTokenFilterFactory" hyphenator="hyphenator.xml" encoding="UTF-8"
+ *     	     dictionary="dictionary.txt" minWordSize="5" minSubwordSize="2" maxSubwordSize="15" onlyLongestMatch="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ * @see HyphenationCompoundWordTokenFilter
+ */
+public class HyphenationCompoundWordTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  private CharArraySet dictionary;
+  private HyphenationTree hyphenator;
+  private String dictFile;
+  private String hypFile;
+  private String encoding;
+  private int minWordSize;
+  private int minSubwordSize;
+  private int maxSubwordSize;
+  private boolean onlyLongestMatch;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    assureMatchVersion();
+    dictFile = args.get("dictionary");
+    if (args.containsKey("encoding"))
+      encoding = args.get("encoding");
+    hypFile = args.get("hyphenator");
+    if (null == hypFile) {
+      throw new InitializationException("Missing required parameter: hyphenator");
+    }
+
+    minWordSize = getInt("minWordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
+    minSubwordSize = getInt("minSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE);
+    maxSubwordSize = getInt("maxSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
+    onlyLongestMatch = getBoolean("onlyLongestMatch", false);
+  }
+  
+  public void inform(ResourceLoader loader) {
+    InputStream stream = null;
+    try {
+      if (dictFile != null) // the dictionary can be empty.
+        dictionary = getWordSet(loader, dictFile, false);
+      // TODO: Broken, because we cannot resolve real system id
+      // ResourceLoader should also supply method like ClassLoader to get resource URL
+      stream = loader.openResource(hypFile);
+      final InputSource is = new InputSource(stream);
+      is.setEncoding(encoding); // if it's null let xml parser decide
+      is.setSystemId(hypFile);
+      hyphenator = HyphenationCompoundWordTokenFilter.getHyphenationTree(is);
+    } catch (Exception e) { // TODO: getHyphenationTree really shouldn't throw "Exception"
+      throw new InitializationException("Exception thrown while loading dictionary and hyphenation file", e);
+    } finally {
+      IOUtils.closeQuietly(stream);
+    }
+  }
+  
+  public HyphenationCompoundWordTokenFilter create(TokenStream input) {
+    return new HyphenationCompoundWordTokenFilter(luceneMatchVersion, input, hyphenator, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java
new file mode 100644
index 0000000..678dda5
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/KeywordTokenizerFactory.java
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+
+/**
+ * Factory for {@link KeywordTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_keyword" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class KeywordTokenizerFactory extends TokenizerFactory {
+  public KeywordTokenizer create(Reader input) {
+    return new KeywordTokenizer(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java
new file mode 100644
index 0000000..fcd5691
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizerFactory.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.core.LetterTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link LetterTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_letter" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.LetterTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class LetterTokenizerFactory extends TokenizerFactory {
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public LetterTokenizer create(Reader input) {
+    return new LetterTokenizer(luceneMatchVersion, input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilterFactory.java
new file mode 100644
index 0000000..f49e557
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilterFactory.java
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.core.LowerCaseFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link LowerCaseFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_lwrcase" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class LowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public LowerCaseFilter create(TokenStream input) {
+    return new LowerCaseFilter(luceneMatchVersion,input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java
new file mode 100644
index 0000000..253d1ee
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizerFactory.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.core.LowerCaseTokenizer;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link LowerCaseTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_lwrcase" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.LowerCaseTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class LowerCaseTokenizerFactory extends TokenizerFactory implements MultiTermAwareComponent {
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public LowerCaseTokenizer create(Reader input) {
+    return new LowerCaseTokenizer(luceneMatchVersion,input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    LowerCaseFilterFactory filt = new LowerCaseFilterFactory();
+    filt.setLuceneMatchVersion(luceneMatchVersion);
+    filt.init(args);
+    return filt;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
new file mode 100644
index 0000000..7e49e39
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilterFactory.java
@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.util.*;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.core.StopAnalyzer;
+import org.apache.lucene.analysis.core.StopFilter;
+
+import java.util.Map;
+import java.io.IOException;
+
+/**
+ * Factory for {@link StopFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_stop" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.StopFilterFactory" ignoreCase="true"
+ *             words="stopwords.txt" enablePositionIncrements="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class StopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  @Override
+  public void inform(ResourceLoader loader) {
+    String stopWordFiles = args.get("words");
+    ignoreCase = getBoolean("ignoreCase",false);
+    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
+
+    if (stopWordFiles != null) {
+      try {
+        if ("snowball".equalsIgnoreCase(args.get("format"))) {
+          stopWords = getSnowballWordSet(loader, stopWordFiles, ignoreCase);
+        } else {
+          stopWords = getWordSet(loader, stopWordFiles, ignoreCase);
+        }
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading stopwords", e);
+      }
+    } else {
+      stopWords = new CharArraySet(luceneMatchVersion, StopAnalyzer.ENGLISH_STOP_WORDS_SET, ignoreCase);
+    }
+  }
+
+  private CharArraySet stopWords;
+  private boolean ignoreCase;
+  private boolean enablePositionIncrements;
+
+  public boolean isEnablePositionIncrements() {
+    return enablePositionIncrements;
+  }
+
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public CharArraySet getStopWords() {
+    return stopWords;
+  }
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    StopFilter stopFilter = new StopFilter(luceneMatchVersion,input,stopWords);
+    stopFilter.setEnablePositionIncrements(enablePositionIncrements);
+    return stopFilter;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
new file mode 100644
index 0000000..62c7912
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/TypeTokenFilterFactory.java
@@ -0,0 +1,85 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.core.TypeTokenFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.common.util.StrUtils;
+import org.apache.lucene.analysis.util.ResourceLoaderAware;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * Factory class for {@link TypeTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="chars" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.TypeTokenFilterFactory" types="stoptypes.txt"
+ *                   enablePositionIncrements="true" useWhiteList="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class TypeTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+
+  @Override
+  public void inform(ResourceLoader loader) {
+    String stopTypesFiles = args.get("types");
+    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
+    useWhitelist = getBoolean("useWhitelist", false);
+    if (stopTypesFiles != null) {
+      try {
+        List<String> files = StrUtils.splitFileNames(stopTypesFiles);
+        if (files.size() > 0) {
+          stopTypes = new HashSet<String>();
+          for (String file : files) {
+            List<String> typesLines = loader.getLines(file.trim());
+            stopTypes.addAll(typesLines);
+          }
+        }
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading types", e);
+      }
+    } else {
+      throw new InitializationException("Missing required parameter: types.");
+    }
+  }
+
+  private boolean useWhitelist;
+  private Set<String> stopTypes;
+  private boolean enablePositionIncrements;
+
+  public boolean isEnablePositionIncrements() {
+    return enablePositionIncrements;
+  }
+
+  public Set<String> getStopTypes() {
+    return stopTypes;
+  }
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new TypeTokenFilter(enablePositionIncrements, input, stopTypes, useWhitelist);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java
new file mode 100644
index 0000000..47bf213
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizerFactory.java
@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link WhitespaceTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class WhitespaceTokenizerFactory extends TokenizerFactory {
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public WhitespaceTokenizer create(Reader input) {
+    return new WhitespaceTokenizer(luceneMatchVersion,input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilterFactory.java
new file mode 100644
index 0000000..fd35534
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.cz.CzechStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ *  Factory for {@link CzechStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_czstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.CzechStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class CzechStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new CzechStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanLightStemFilterFactory.java
new file mode 100644
index 0000000..60824ce
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.de.GermanLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link GermanLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_delgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GermanLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GermanLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new GermanLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanMinimalStemFilterFactory.java
new file mode 100644
index 0000000..08a89da
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanMinimalStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.de.GermanMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link GermanMinimalStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_deminstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GermanMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GermanMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new GermanMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilterFactory.java
new file mode 100644
index 0000000..27ac20b
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilterFactory.java
@@ -0,0 +1,47 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.de.GermanNormalizationFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link GermanNormalizationFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_denorm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GermanNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ */
+public class GermanNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+
+  public TokenStream create(TokenStream input) {
+    return new GermanNormalizationFilter(input);
+  }
+  
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilterFactory.java
new file mode 100644
index 0000000..1e7edbd
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilterFactory.java
@@ -0,0 +1,43 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.de.GermanStemFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link GermanStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_destem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GermanStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GermanStemFilterFactory extends TokenFilterFactory {
+  public GermanStemFilter create(TokenStream in) {
+    return new GermanStemFilter(in);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java
new file mode 100644
index 0000000..8889920
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilterFactory.java
@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.el.GreekLowerCaseFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link GreekLowerCaseFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_glc" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.GreekLowerCaseFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GreekLowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+ 
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    assureMatchVersion();
+    if (args.containsKey("charset"))
+      throw new InitializationException(
+          "The charset parameter is no longer supported.  "
+          + "Please process your documents as Unicode instead.");
+  }
+
+  public GreekLowerCaseFilter create(TokenStream in) {
+    return new GreekLowerCaseFilter(luceneMatchVersion, in);
+  }
+
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemFilterFactory.java
new file mode 100644
index 0000000..d8dae6d
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/el/GreekStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.el.GreekStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link GreekStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_gstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.GreekLowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GreekStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class GreekStemFilterFactory extends TokenFilterFactory {
+
+  public TokenStream create(TokenStream input) {
+    return new GreekStemFilter(input);
+  }
+
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishMinimalStemFilterFactory.java
new file mode 100644
index 0000000..ed31a86
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishMinimalStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.en.EnglishMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link EnglishMinimalStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_enminstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.EnglishMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class EnglishMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new EnglishMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishPossessiveFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishPossessiveFilterFactory.java
new file mode 100644
index 0000000..36d153d
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishPossessiveFilterFactory.java
@@ -0,0 +1,49 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.en.EnglishPossessiveFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link EnglishPossessiveFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_enpossessive" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.EnglishPossessiveFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class EnglishPossessiveFilterFactory extends TokenFilterFactory {
+  
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+  
+  public TokenStream create(TokenStream input) {
+    return new EnglishPossessiveFilter(luceneMatchVersion, input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemFilterFactory.java
new file mode 100644
index 0000000..f8f4057
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemFilterFactory.java
@@ -0,0 +1,33 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.en.KStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link KStemFilter}
+ */
+public class KStemFilterFactory extends TokenFilterFactory {
+
+  public TokenFilter create(TokenStream input) {
+    return new KStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/PorterStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/PorterStemFilterFactory.java
new file mode 100644
index 0000000..c6dea10
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/PorterStemFilterFactory.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.en.PorterStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link PorterStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_porterstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.PorterStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PorterStemFilterFactory extends TokenFilterFactory {
+  public PorterStemFilter create(TokenStream input) {
+    return new PorterStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishLightStemFilterFactory.java
new file mode 100644
index 0000000..61c883b
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.es.SpanishLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link SpanishLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_eslgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.SpanishLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class SpanishLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new SpanishLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilterFactory.java
new file mode 100644
index 0000000..a0ae871
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilterFactory.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+
+import org.apache.lucene.analysis.CharFilter;
+import org.apache.lucene.analysis.fa.PersianCharFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.CharFilterFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+
+/**
+ * Factory for {@link PersianCharFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_fa" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;charFilter class="solr.PersianCharFilterFactory"/&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PersianCharFilterFactory extends CharFilterFactory implements MultiTermAwareComponent {
+
+  @Override
+  public CharFilter create(Reader input) {
+    return new PersianCharFilter(input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilterFactory.java
new file mode 100644
index 0000000..a0ccd43
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilterFactory.java
@@ -0,0 +1,50 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.fa.PersianNormalizationFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link PersianNormalizationFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_fanormal" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;charFilter class="solr.PersianCharFilterFactory"/&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.PersianNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PersianNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  public PersianNormalizationFilter create(TokenStream input) {
+    return new PersianNormalizationFilter(input);
+  }
+  
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishLightStemFilterFactory.java
new file mode 100644
index 0000000..0e70606
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fi/FinnishLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.fi.FinnishLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link FinnishLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_filgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.FinnishLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class FinnishLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new FinnishLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
new file mode 100644
index 0000000..c522ed4
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilterFactory.java
@@ -0,0 +1,64 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.util.*;
+import org.apache.lucene.analysis.fr.*;
+
+import java.io.IOException;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Factory for {@link ElisionFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_elsn" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.ElisionFilterFactory" 
+ *       articles="stopwordarticles.txt" ignoreCase="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ElisionFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+
+  private CharArraySet articles;
+
+  public void inform(ResourceLoader loader) {
+    String articlesFile = args.get("articles");
+    boolean ignoreCase = getBoolean("ignoreCase", false);
+
+    if (articlesFile != null) {
+      try {
+        articles = getWordSet(loader, articlesFile, ignoreCase);
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading articles", e);
+      }
+    }
+  }
+
+  public ElisionFilter create(TokenStream input) {
+    assureMatchVersion();
+    return articles == null ? new ElisionFilter(luceneMatchVersion,input) : 
+        new ElisionFilter(luceneMatchVersion,input,articles);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchLightStemFilterFactory.java
new file mode 100644
index 0000000..8b50110
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchLightStemFilterFactory.java
@@ -0,0 +1,41 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.fr.FrenchLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link FrenchLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_frlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.ElisionFilterFactory"/&gt;
+ *     &lt;filter class="solr.FrenchLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class FrenchLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new FrenchLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchMinimalStemFilterFactory.java
new file mode 100644
index 0000000..d3d3bf9
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchMinimalStemFilterFactory.java
@@ -0,0 +1,41 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.fr.FrenchMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link FrenchMinimalStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_frminstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.ElisionFilterFactory"/&gt;
+ *     &lt;filter class="solr.FrenchMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class FrenchMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new FrenchMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishLowerCaseFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishLowerCaseFilterFactory.java
new file mode 100644
index 0000000..e5f1d85
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ga/IrishLowerCaseFilterFactory.java
@@ -0,0 +1,49 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ga.IrishLowerCaseFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link IrishLowerCaseFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ga" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.IrishLowerCaseFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class IrishLowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new IrishLowerCaseFilter(input);
+  }
+
+  // this will 'mostly work', except for special cases, just like most other filters
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..4f838ab
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.gl.GalicianMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link GalicianMinimalStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_glplural" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GalicianMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GalicianMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new GalicianMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianStemFilterFactory.java
new file mode 100644
index 0000000..824a521
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.gl.GalicianStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link GalicianStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_glstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GalicianStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GalicianStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new GalicianStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilterFactory.java
new file mode 100644
index 0000000..6a11b19
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiNormalizationFilterFactory.java
@@ -0,0 +1,46 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.hi.HindiNormalizationFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link HindiNormalizationFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_hinormal" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.HindiNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class HindiNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  public TokenStream create(TokenStream input) {
+    return new HindiNormalizationFilter(input);
+  }
+  
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiStemFilterFactory.java
new file mode 100644
index 0000000..2e495e4
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.hi.HindiStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link HindiStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_histem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.HindiStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class HindiStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new HindiStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianLightStemFilterFactory.java
new file mode 100644
index 0000000..10aea57
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hu/HungarianLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.hu.HungarianLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link HungarianLightStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_hulgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.HungarianLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class HungarianLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new HungarianLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
new file mode 100644
index 0000000..38f6f59
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellStemFilterFactory.java
@@ -0,0 +1,117 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.hunspell.HunspellDictionary;
+import org.apache.lucene.analysis.hunspell.HunspellStemFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.lucene.analysis.util.ResourceLoaderAware;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * TokenFilterFactory that creates instances of {@link org.apache.lucene.analysis.hunspell.HunspellStemFilter}.
+ * Example config for British English including a custom dictionary, case insensitive matching:
+ * <pre class="prettyprint" >
+ * &lt;filter class=&quot;solr.HunspellStemFilterFactory&quot;
+ *    dictionary=&quot;en_GB.dic,my_custom.dic&quot;
+ *    affix=&quot;en_GB.aff&quot;
+ *    ignoreCase=&quot;true&quot; /&gt;</pre>
+ * Both parameters dictionary and affix are mandatory.
+ * <br/>
+ * The parameter ignoreCase (true/false) controls whether matching is case sensitive or not. Default false.
+ * <br/>
+ * The parameter strictAffixParsing (true/false) controls whether the affix parsing is strict or not. Default true.
+ * If strict an error while reading an affix rule causes a ParseException, otherwise is ignored.
+ * <br/>
+ * Dictionaries for many languages are available through the OpenOffice project.
+ * 
+ * See <a href="http://wiki.apache.org/solr/Hunspell">http://wiki.apache.org/solr/Hunspell</a>
+ */
+public class HunspellStemFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  
+  private static final String PARAM_DICTIONARY = "dictionary";
+  private static final String PARAM_AFFIX = "affix";
+  private static final String PARAM_IGNORE_CASE = "ignoreCase";
+  private static final String PARAM_STRICT_AFFIX_PARSING = "strictAffixParsing";
+  private static final String TRUE = "true";
+  private static final String FALSE = "false";
+  
+  private HunspellDictionary dictionary;
+  private boolean ignoreCase = false;
+
+  /**
+   * Loads the hunspell dictionary and affix files defined in the configuration
+   *  
+   * @param loader ResourceLoader used to load the files
+   */
+  public void inform(ResourceLoader loader) {
+    assureMatchVersion();
+    String dictionaryFiles[] = args.get(PARAM_DICTIONARY).split(",");
+    String affixFile = args.get(PARAM_AFFIX);
+    String pic = args.get(PARAM_IGNORE_CASE);
+    if(pic != null) {
+      if(pic.equalsIgnoreCase(TRUE)) ignoreCase = true;
+      else if(pic.equalsIgnoreCase(FALSE)) ignoreCase = false;
+      else throw new InitializationException("Unknown value for " + PARAM_IGNORE_CASE + ": " + pic + ". Must be true or false");
+    }
+
+    String strictAffixParsingParam = args.get(PARAM_STRICT_AFFIX_PARSING);
+    boolean strictAffixParsing = true;
+    if(strictAffixParsingParam != null) {
+      if(strictAffixParsingParam.equalsIgnoreCase(FALSE)) strictAffixParsing = false;
+      else if(strictAffixParsingParam.equalsIgnoreCase(TRUE)) strictAffixParsing = true;
+      else throw new InitializationException("Unknown value for " + PARAM_STRICT_AFFIX_PARSING + ": " + strictAffixParsingParam + ". Must be true or false");
+    }
+
+    InputStream affix = null;
+    List<InputStream> dictionaries = new ArrayList<InputStream>();
+
+    try {
+      dictionaries = new ArrayList<InputStream>();
+      for (String file : dictionaryFiles) {
+        dictionaries.add(loader.openResource(file));
+      }
+      affix = loader.openResource(affixFile);
+
+      this.dictionary = new HunspellDictionary(affix, dictionaries, luceneMatchVersion, ignoreCase, strictAffixParsing);
+    } catch (Exception e) {
+      throw new InitializationException("Unable to load hunspell data! [dictionary=" + args.get("dictionary") + ",affix=" + affixFile + "]", e);
+    } finally {
+      IOUtils.closeWhileHandlingException(affix);
+      IOUtils.closeWhileHandlingException(dictionaries);
+    }
+  }
+
+  /**
+   * Creates an instance of {@link org.apache.lucene.analysis.hunspell.HunspellStemFilter} that will filter the given
+   * TokenStream
+   *
+   * @param tokenStream TokenStream that will be filtered
+   * @return HunspellStemFilter that filters the TokenStream 
+   */
+  public TokenStream create(TokenStream tokenStream) {
+    return new HunspellStemFilter(tokenStream, dictionary);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianStemFilterFactory.java
new file mode 100644
index 0000000..92b1d46
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/id/IndonesianStemFilterFactory.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.id.IndonesianStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link IndonesianStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_idstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.IndonesianStemFilterFactory" stemDerivational="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class IndonesianStemFilterFactory extends TokenFilterFactory {
+  private boolean stemDerivational = true;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    stemDerivational = getBoolean("stemDerivational", true);
+  }
+
+  public TokenStream create(TokenStream input) {
+    return new IndonesianStemFilter(input, stemDerivational);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/in/IndicNormalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/in/IndicNormalizationFilterFactory.java
new file mode 100644
index 0000000..2709e75
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/in/IndicNormalizationFilterFactory.java
@@ -0,0 +1,46 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.in.IndicNormalizationFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link IndicNormalizationFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_innormal" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.IndicNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class IndicNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  public TokenStream create(TokenStream input) {
+    return new IndicNormalizationFilter(input);
+  }
+  
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianLightStemFilterFactory.java
new file mode 100644
index 0000000..7e79479
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.it.ItalianLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link ItalianLightStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_itlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.ItalianLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class ItalianLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new ItalianLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemFilterFactory.java
new file mode 100644
index 0000000..3fb4b26
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.lv.LatvianStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link LatvianStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_lvstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.LatvianStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class LatvianStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new LatvianStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
new file mode 100644
index 0000000..da507d9
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilterFactory.java
@@ -0,0 +1,49 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+import org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter;
+import org.apache.lucene.analysis.TokenStream;
+
+/** 
+ * Factory for {@link ASCIIFoldingFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ascii" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ASCIIFoldingFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ASCIIFoldingFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
+  public ASCIIFoldingFilter create(TokenStream input) {
+    return new ASCIIFoldingFilter(input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
new file mode 100644
index 0000000..e26bac2
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
@@ -0,0 +1,140 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.CapitalizationFilter;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Map;
+import java.util.StringTokenizer;
+
+/**
+ * Factory for {@link CapitalizationFilter}.
+ * <p/>
+ * The factory takes parameters:<br/>
+ * "onlyFirstWord" - should each word be capitalized or all of the words?<br/>
+ * "keep" - a keep word list.  Each word that should be kept separated by whitespace.<br/>
+ * "keepIgnoreCase - true or false.  If true, the keep list will be considered case-insensitive.<br/>
+ * "forceFirstLetter" - Force the first letter to be capitalized even if it is in the keep list<br/>
+ * "okPrefix" - do not change word capitalization if a word begins with something in this list.
+ * for example if "McK" is on the okPrefix list, the word "McKinley" should not be changed to
+ * "Mckinley"<br/>
+ * "minWordLength" - how long the word needs to be to get capitalization applied.  If the
+ * minWordLength is 3, "and" > "And" but "or" stays "or"<br/>
+ * "maxWordCount" - if the token contains more then maxWordCount words, the capitalization is
+ * assumed to be correct.<br/>
+ *
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_cptlztn" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.CapitalizationFilterFactory" onlyFirstWord="true"
+ *     	     keep="java solr lucene" keepIgnoreCase="false"
+ *     	     okPrefix="McK McD McA"/&gt;   
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ * @since solr 1.3
+ */
+public class CapitalizationFilterFactory extends TokenFilterFactory {
+  public static final String KEEP = "keep";
+  public static final String KEEP_IGNORE_CASE = "keepIgnoreCase";
+  public static final String OK_PREFIX = "okPrefix";
+  public static final String MIN_WORD_LENGTH = "minWordLength";
+  public static final String MAX_WORD_COUNT = "maxWordCount";
+  public static final String MAX_TOKEN_LENGTH = "maxTokenLength";
+  public static final String ONLY_FIRST_WORD = "onlyFirstWord";
+  public static final String FORCE_FIRST_LETTER = "forceFirstLetter";
+
+  //Map<String,String> keep = new HashMap<String, String>(); // not synchronized because it is only initialized once
+  CharArraySet keep;
+
+  Collection<char[]> okPrefix = Collections.emptyList(); // for Example: McK
+
+  int minWordLength = 0;  // don't modify capitalization for words shorter then this
+  int maxWordCount = CapitalizationFilter.DEFAULT_MAX_WORD_COUNT;
+  int maxTokenLength = CapitalizationFilter.DEFAULT_MAX_TOKEN_LENGTH;
+  boolean onlyFirstWord = true;
+  boolean forceFirstLetter = true; // make sure the first letter is capitol even if it is in the keep list
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    assureMatchVersion();
+
+    String k = args.get(KEEP);
+    if (k != null) {
+      StringTokenizer st = new StringTokenizer(k);
+      boolean ignoreCase = false;
+      String ignoreStr = args.get(KEEP_IGNORE_CASE);
+      if ("true".equalsIgnoreCase(ignoreStr)) {
+        ignoreCase = true;
+      }
+      keep = new CharArraySet(luceneMatchVersion, 10, ignoreCase);
+      while (st.hasMoreTokens()) {
+        k = st.nextToken().trim();
+        keep.add(k.toCharArray());
+      }
+    }
+
+    k = args.get(OK_PREFIX);
+    if (k != null) {
+      okPrefix = new ArrayList<char[]>();
+      StringTokenizer st = new StringTokenizer(k);
+      while (st.hasMoreTokens()) {
+        okPrefix.add(st.nextToken().trim().toCharArray());
+      }
+    }
+
+    k = args.get(MIN_WORD_LENGTH);
+    if (k != null) {
+      minWordLength = Integer.valueOf(k);
+    }
+
+    k = args.get(MAX_WORD_COUNT);
+    if (k != null) {
+      maxWordCount = Integer.valueOf(k);
+    }
+
+    k = args.get(MAX_TOKEN_LENGTH);
+    if (k != null) {
+      maxTokenLength = Integer.valueOf(k);
+    }
+
+    k = args.get(ONLY_FIRST_WORD);
+    if (k != null) {
+      onlyFirstWord = Boolean.valueOf(k);
+    }
+
+    k = args.get(FORCE_FIRST_LETTER);
+    if (k != null) {
+      forceFirstLetter = Boolean.valueOf(k);
+    }
+  }
+
+  public CapitalizationFilter create(TokenStream input) {
+    return new CapitalizationFilter(input, onlyFirstWord, keep, 
+      forceFirstLetter, okPrefix, minWordLength, maxWordCount, maxTokenLength);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilterFactory.java
new file mode 100755
index 0000000..91faf90
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/HyphenatedWordsFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.HyphenatedWordsFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link HyphenatedWordsFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_hyphn" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.HyphenatedWordsFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class HyphenatedWordsFilterFactory extends TokenFilterFactory {
+	public HyphenatedWordsFilter create(TokenStream input) {
+		return new HyphenatedWordsFilter(input);
+	}
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
new file mode 100644
index 0000000..86a5ed1
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilterFactory.java
@@ -0,0 +1,95 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.util.*;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.KeepWordFilter;
+
+import java.util.Map;
+import java.util.Set;
+import java.io.IOException;
+
+/**
+ * Factory for {@link KeepWordFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_keepword" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.KeepWordFilterFactory" words="keepwords.txt" ignoreCase="false" enablePositionIncrements="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class KeepWordFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+
+  public void inform(ResourceLoader loader) {
+    String wordFiles = args.get("words");
+    ignoreCase = getBoolean("ignoreCase", false);
+    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
+
+    if (wordFiles != null) {
+      try {
+        words = getWordSet(loader, wordFiles, ignoreCase);
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading words", e);
+      }
+    }
+  }
+
+  private CharArraySet words;
+  private boolean ignoreCase;
+  private boolean enablePositionIncrements;
+
+  /**
+   * Set the keep word list.
+   * NOTE: if ignoreCase==true, the words are expected to be lowercase
+   */
+  public void setWords(Set<String> words) {
+    this.words = new CharArraySet(luceneMatchVersion, words, ignoreCase);
+  }
+
+  public void setIgnoreCase(boolean ignoreCase) {    
+    if (words != null && this.ignoreCase != ignoreCase) {
+      words = new CharArraySet(luceneMatchVersion, words, ignoreCase);
+    }
+    this.ignoreCase = ignoreCase;
+  }
+
+  public boolean isEnablePositionIncrements() {
+    return enablePositionIncrements;
+  }
+
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public CharArraySet getWords() {
+    return words;
+  }
+
+  public KeepWordFilter create(TokenStream input) {
+    return new KeepWordFilter(enablePositionIncrements, input, words);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
new file mode 100644
index 0000000..3274a43
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeywordMarkerFilterFactory.java
@@ -0,0 +1,61 @@
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
+import org.apache.lucene.analysis.util.*;
+import org.apache.lucene.analysis.TokenStream;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Factory for {@link KeywordMarkerFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_keyword" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.KeywordMarkerFilterFactory" protected="protectedkeyword.txt" ignoreCase="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class KeywordMarkerFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  public static final String PROTECTED_TOKENS = "protected";
+  private CharArraySet protectedWords;
+  private boolean ignoreCase;
+  
+  public void inform(ResourceLoader loader) {
+    String wordFiles = args.get(PROTECTED_TOKENS);
+    ignoreCase = getBoolean("ignoreCase", false);
+    if (wordFiles != null) {  
+      try {
+        protectedWords = getWordSet(loader, wordFiles, ignoreCase);
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading protected words", e);
+      }
+    }
+  }
+  
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public TokenStream create(TokenStream input) {
+    return protectedWords == null ? input : new KeywordMarkerFilter(input, protectedWords);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
new file mode 100644
index 0000000..756b202
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LengthFilterFactory.java
@@ -0,0 +1,54 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.LengthFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link LengthFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_lngth" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LengthFilterFactory" min="0" max="1" enablePositionIncrements="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class LengthFilterFactory extends TokenFilterFactory {
+  int min,max;
+  boolean enablePositionIncrements;
+  public static final String MIN_KEY = "min";
+  public static final String MAX_KEY = "max";
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    min=Integer.parseInt(args.get(MIN_KEY));
+    max=Integer.parseInt(args.get(MAX_KEY));
+    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
+  }
+  
+  public LengthFilter create(TokenStream input) {
+    return new LengthFilter(enablePositionIncrements, input,min,max);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
new file mode 100644
index 0000000..0dfe9f9
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/LimitTokenCountFilterFactory.java
@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.LimitTokenCountFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link LimitTokenCountFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_lngthcnt" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LimitTokenCountFilterFactory" maxTokenCount="10"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class LimitTokenCountFilterFactory extends TokenFilterFactory {
+
+  int maxTokenCount;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init( args );
+    maxTokenCount = Integer.parseInt( args.get( "maxTokenCount" ) );
+  }
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new LimitTokenCountFilter( input, maxTokenCount );
+  }
+
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilterFactory.java
new file mode 100644
index 0000000..30d51bb
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/RemoveDuplicatesTokenFilterFactory.java
@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link RemoveDuplicatesTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_rmdup" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class RemoveDuplicatesTokenFilterFactory extends TokenFilterFactory {
+  public RemoveDuplicatesTokenFilter create(TokenStream input) {
+    return new RemoveDuplicatesTokenFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
new file mode 100644
index 0000000..c9bec3f
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/StemmerOverrideFilterFactory.java
@@ -0,0 +1,74 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.StemmerOverrideFilter;
+import org.apache.lucene.analysis.util.*;
+import org.apache.solr.common.util.StrUtils;
+
+/**
+ * Factory for {@link StemmerOverrideFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_dicstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.StemmerOverrideFilterFactory" dictionary="dictionary.txt" ignoreCase="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class StemmerOverrideFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  private CharArrayMap<String> dictionary = null;
+  private boolean ignoreCase;
+
+  public void inform(ResourceLoader loader) {
+    String dictionaryFiles = args.get("dictionary");
+    ignoreCase = getBoolean("ignoreCase", false);
+    if (dictionaryFiles != null) {
+      assureMatchVersion();
+      List<String> files = StrUtils.splitFileNames(dictionaryFiles);
+      try {
+        if (files.size() > 0) {
+          dictionary = new CharArrayMap<String>(luceneMatchVersion, 
+              files.size() * 10, ignoreCase);
+          for (String file : files) {
+            List<String> list = loader.getLines(file.trim());
+            for (String line : list) {
+              String[] mapping = line.split("\t", 2);
+              dictionary.put(mapping[0], mapping[1]);
+            }
+          }
+        }
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading dictionary", e);
+      }
+    }
+  }
+
+  public boolean isIgnoreCase() {
+    return ignoreCase;
+  }
+
+  public TokenStream create(TokenStream input) {
+    return dictionary == null ? input : new StemmerOverrideFilter(luceneMatchVersion, input, dictionary);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java
new file mode 100644
index 0000000..ef7fbae
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/TrimFilterFactory.java
@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.TrimFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link TrimFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_trm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.NGramTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.TrimFilterFactory" updateOffsets="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ * @see TrimFilter
+ */
+public class TrimFilterFactory extends TokenFilterFactory {
+  
+  protected boolean updateOffsets = false;
+  
+  @Override
+  public void init(Map<String,String> args) {
+    super.init( args );
+    
+    String v = args.get( "updateOffsets" );
+    if( v != null ) {
+      try {
+        updateOffsets = Boolean.valueOf( v );
+      }
+      catch( Exception ex ) {
+        throw new InitializationException("Error reading updateOffsets value.  Must be true or false.", ex);
+      }
+    }
+  }
+  
+  public TrimFilter create(TokenStream input) {
+    return new TrimFilter(input, updateOffsets);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
new file mode 100644
index 0000000..86239eb
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilterFactory.java
@@ -0,0 +1,200 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter;
+import org.apache.lucene.analysis.miscellaneous.WordDelimiterIterator;
+import org.apache.lucene.analysis.util.*;
+
+import org.apache.solr.common.util.StrUtils;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.SortedMap;
+import java.util.TreeMap;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.io.IOException;
+
+import static org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter.*;
+
+
+/**
+ * Factory for {@link WordDelimiterFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_wd" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.WordDelimiterFilterFactory" protected="protectedword.txt"
+ *             preserveOriginal="0" splitOnNumerics="1" splitOnCaseChange="1"
+ *             catenateWords="0" catenateNumbers="0" catenateAll="0"
+ *             generateWordParts="1" generateNumberParts="1" stemEnglishPossessive="1"
+ *             types="wdfftypes.txt" /&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class WordDelimiterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  public static final String PROTECTED_TOKENS = "protected";
+  public static final String TYPES = "types";
+  
+  public void inform(ResourceLoader loader) {
+    String wordFiles = args.get(PROTECTED_TOKENS);
+    if (wordFiles != null) {  
+      try {
+        protectedWords = getWordSet(loader, wordFiles, false);
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading protected words", e);
+      }
+    }
+    String types = args.get(TYPES);
+    if (types != null) {
+      try {
+        List<String> files = StrUtils.splitFileNames( types );
+        List<String> wlist = new ArrayList<String>();
+        for( String file : files ){
+          List<String> lines = loader.getLines( file.trim() );
+          wlist.addAll( lines );
+        }
+      typeTable = parseTypes(wlist);
+      } catch (IOException e) {
+        throw new InitializationException("IOException while loading types", e);
+      }
+    }
+  }
+
+  private CharArraySet protectedWords = null;
+  private int flags;
+  byte[] typeTable = null;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    if (getInt("generateWordParts", 1) != 0) {
+      flags |= GENERATE_WORD_PARTS;
+    }
+    if (getInt("generateNumberParts", 1) != 0) {
+      flags |= GENERATE_NUMBER_PARTS;
+    }
+    if (getInt("catenateWords", 0) != 0) {
+      flags |= CATENATE_WORDS;
+    }
+    if (getInt("catenateNumbers", 0) != 0) {
+      flags |= CATENATE_NUMBERS;
+    }
+    if (getInt("catenateAll", 0) != 0) {
+      flags |= CATENATE_ALL;
+    }
+    if (getInt("splitOnCaseChange", 1) != 0) {
+      flags |= SPLIT_ON_CASE_CHANGE;
+    }
+    if (getInt("splitOnNumerics", 1) != 0) {
+      flags |= SPLIT_ON_NUMERICS;
+    }
+    if (getInt("preserveOriginal", 0) != 0) {
+      flags |= PRESERVE_ORIGINAL;
+    }
+    if (getInt("stemEnglishPossessive", 1) != 0) {
+      flags |= STEM_ENGLISH_POSSESSIVE;
+    }
+  }
+
+  public WordDelimiterFilter create(TokenStream input) {
+    return new WordDelimiterFilter(input, typeTable == null ? WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE : typeTable,
+                                   flags, protectedWords);
+  }
+  
+  // source => type
+  private static Pattern typePattern = Pattern.compile( "(.*)\\s*=>\\s*(.*)\\s*$" );
+  
+  // parses a list of MappingCharFilter style rules into a custom byte[] type table
+  private byte[] parseTypes(List<String> rules) {
+    SortedMap<Character,Byte> typeMap = new TreeMap<Character,Byte>();
+    for( String rule : rules ){
+      Matcher m = typePattern.matcher(rule);
+      if( !m.find() )
+        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]");
+      String lhs = parseString(m.group(1).trim());
+      Byte rhs = parseType(m.group(2).trim());
+      if (lhs.length() != 1)
+        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Only a single character is allowed.");
+      if (rhs == null)
+        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Illegal type.");
+      typeMap.put(lhs.charAt(0), rhs);
+    }
+    
+    // ensure the table is always at least as big as DEFAULT_WORD_DELIM_TABLE for performance
+    byte types[] = new byte[Math.max(typeMap.lastKey()+1, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE.length)];
+    for (int i = 0; i < types.length; i++)
+      types[i] = WordDelimiterIterator.getType(i);
+    for (Map.Entry<Character,Byte> mapping : typeMap.entrySet())
+      types[mapping.getKey()] = mapping.getValue();
+    return types;
+  }
+  
+  private Byte parseType(String s) {
+    if (s.equals("LOWER"))
+      return LOWER;
+    else if (s.equals("UPPER"))
+      return UPPER;
+    else if (s.equals("ALPHA"))
+      return ALPHA;
+    else if (s.equals("DIGIT"))
+      return DIGIT;
+    else if (s.equals("ALPHANUM"))
+      return ALPHANUM;
+    else if (s.equals("SUBWORD_DELIM"))
+      return SUBWORD_DELIM;
+    else
+      return null;
+  }
+  
+  char[] out = new char[256];
+  
+  private String parseString(String s){
+    int readPos = 0;
+    int len = s.length();
+    int writePos = 0;
+    while( readPos < len ){
+      char c = s.charAt( readPos++ );
+      if( c == '\\' ){
+        if( readPos >= len )
+          throw new InitializationException("Invalid escaped char in [" + s + "]");
+        c = s.charAt( readPos++ );
+        switch( c ) {
+          case '\\' : c = '\\'; break;
+          case 'n' : c = '\n'; break;
+          case 't' : c = '\t'; break;
+          case 'r' : c = '\r'; break;
+          case 'b' : c = '\b'; break;
+          case 'f' : c = '\f'; break;
+          case 'u' :
+            if( readPos + 3 >= len )
+              throw new InitializationException("Invalid escaped char in [" + s + "]");
+            c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
+            readPos += 4;
+            break;
+        }
+      }
+      out[writePos++] = c;
+    }
+    return new String( out, 0, writePos );
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramFilterFactory.java
new file mode 100644
index 0000000..5ac1886
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramFilterFactory.java
@@ -0,0 +1,63 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Creates new instances of {@link EdgeNGramTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_edgngrm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.EdgeNGramFilterFactory" side="front" minGramSize="1" maxGramSize="1"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class EdgeNGramFilterFactory extends TokenFilterFactory {
+  private int maxGramSize = 0;
+
+  private int minGramSize = 0;
+
+  private String side;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    String maxArg = args.get("maxGramSize");
+    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
+        : EdgeNGramTokenFilter.DEFAULT_MAX_GRAM_SIZE);
+
+    String minArg = args.get("minGramSize");
+    minGramSize = (minArg != null ? Integer.parseInt(minArg)
+        : EdgeNGramTokenFilter.DEFAULT_MIN_GRAM_SIZE);
+
+    side = args.get("side");
+    if (side == null) {
+      side = EdgeNGramTokenFilter.Side.FRONT.getLabel();
+    }
+  }
+
+  public EdgeNGramTokenFilter create(TokenStream input) {
+    return new EdgeNGramTokenFilter(input, side, minGramSize, maxGramSize);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java
new file mode 100755
index 0000000..83f39de
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizerFactory.java
@@ -0,0 +1,61 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ngram.EdgeNGramTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Creates new instances of {@link EdgeNGramTokenizer}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_edgngrm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.EdgeNGramTokenizerFactory" side="front" minGramSize="1" maxGramSize="1"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class EdgeNGramTokenizerFactory extends TokenizerFactory {
+    private int maxGramSize = 0;
+
+    private int minGramSize = 0;
+
+    private String side;
+
+    @Override
+    public void init(Map<String, String> args) {
+        super.init(args);
+        String maxArg = args.get("maxGramSize");
+        maxGramSize = (maxArg != null ? Integer.parseInt(maxArg) : EdgeNGramTokenizer.DEFAULT_MAX_GRAM_SIZE);
+
+        String minArg = args.get("minGramSize");
+        minGramSize = (minArg != null ? Integer.parseInt(minArg) : EdgeNGramTokenizer.DEFAULT_MIN_GRAM_SIZE);
+
+        side = args.get("side");
+        if (side == null) {
+            side = EdgeNGramTokenizer.Side.FRONT.getLabel();
+        }
+    }
+
+    public EdgeNGramTokenizer create(Reader input) {
+        return new EdgeNGramTokenizer(input, side, minGramSize, maxGramSize);
+    }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramFilterFactory.java
new file mode 100644
index 0000000..d21708b
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramFilterFactory.java
@@ -0,0 +1,57 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Map;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ngram.NGramTokenFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link NGramTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ngrm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.NGramFilterFactory" minGramSize="1" maxGramSize="2"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class NGramFilterFactory extends TokenFilterFactory {
+  private int maxGramSize = 0;
+
+  private int minGramSize = 0;
+
+  /** Initialize the n-gram min and max sizes and the side from which one should start tokenizing. */
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    String maxArg = args.get("maxGramSize");
+    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
+        : NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE);
+
+    String minArg = args.get("minGramSize");
+    minGramSize = (minArg != null ? Integer.parseInt(minArg)
+        : NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE);
+  }
+
+  public NGramTokenFilter create(TokenStream input) {
+    return new NGramTokenFilter(input, minGramSize, maxGramSize);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java
new file mode 100755
index 0000000..c2ed40d
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizerFactory.java
@@ -0,0 +1,56 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ngram.NGramTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link NGramTokenizer}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ngrm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.NGramTokenizerFactory" minGramSize="1" maxGramSize="2"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class NGramTokenizerFactory extends TokenizerFactory {
+    private int maxGramSize = 0;
+    private int minGramSize = 0;
+    
+    /** Initializes the n-gram min and max sizes and the side from which one should start tokenizing. */
+    @Override
+    public void init(Map<String, String> args) {
+        super.init(args);
+        String maxArg = args.get("maxGramSize");
+        maxGramSize = (maxArg != null ? Integer.parseInt(maxArg) : NGramTokenizer.DEFAULT_MAX_NGRAM_SIZE);
+
+        String minArg = args.get("minGramSize");
+        minGramSize = (minArg != null ? Integer.parseInt(minArg) : NGramTokenizer.DEFAULT_MIN_NGRAM_SIZE);
+    }
+
+    /** Creates the {@link TokenStream} of n-grams from the given {@link Reader}. */
+    public NGramTokenizer create(Reader input) {
+        return new NGramTokenizer(input, minGramSize, maxGramSize);
+    }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java
new file mode 100644
index 0000000..840e726
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianLightStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.no.NorwegianLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link NorwegianLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.NorwegianLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class NorwegianLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new NorwegianLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..b8ec071
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/no/NorwegianMinimalStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.no.NorwegianMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link NorwegianMinimalStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.NorwegianMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ */
+public class NorwegianMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new NorwegianMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
new file mode 100644
index 0000000..6fd7f9e
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/path/PathHierarchyTokenizerFactory.java
@@ -0,0 +1,98 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.util.Map;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.path.PathHierarchyTokenizer;
+import org.apache.lucene.analysis.path.ReversePathHierarchyTokenizer;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+
+/**
+ * Factory for {@link PathHierarchyTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_path" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.PathHierarchyTokenizerFactory" delimiter="\" replace="/"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class PathHierarchyTokenizerFactory extends TokenizerFactory {
+  
+  private char delimiter;
+  private char replacement;
+  private boolean reverse = false;
+  private int skip =  PathHierarchyTokenizer.DEFAULT_SKIP;
+  
+  /**
+   * Require a configured pattern
+   */
+  @Override
+  public void init(Map<String,String> args){
+    super.init( args );
+    
+    String v = args.get( "delimiter" );
+    if( v != null ){
+      if( v.length() != 1 ){
+        throw new InitializationException("delimiter should be a char. \"" + v + "\" is invalid");
+      }
+      else{
+        delimiter = v.charAt(0);
+      }
+    }
+    else{
+      delimiter = PathHierarchyTokenizer.DEFAULT_DELIMITER;
+    }
+    
+    v = args.get( "replace" );
+    if( v != null ){
+      if( v.length() != 1 ){
+        throw new InitializationException("replace should be a char. \"" + v + "\" is invalid");
+      }
+      else{
+        replacement = v.charAt(0);
+      }
+    }
+    else{
+      replacement = delimiter;
+    }
+    
+    v = args.get( "reverse" );
+    if( v != null ){
+      reverse = "true".equals( v );
+    }
+
+    v = args.get( "skip" );
+    if( v != null ){
+      skip = Integer.parseInt( v );
+    }
+  }
+
+  public Tokenizer create(Reader input) {
+    if( reverse ) {
+      return new ReversePathHierarchyTokenizer(input, delimiter, replacement, skip);
+    }
+    return new PathHierarchyTokenizer(input, delimiter, replacement, skip);
+  }
+}
+
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java
new file mode 100644
index 0000000..ca6fe6a
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilterFactory.java
@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.Reader;
+import java.util.Map;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.CharFilter;
+import org.apache.lucene.analysis.pattern.PatternReplaceCharFilter;
+import org.apache.lucene.analysis.util.CharFilterFactory;
+
+/**
+ * Factory for {@link PatternReplaceCharFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptnreplace" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;charFilter class="solr.PatternReplaceCharFilterFactory" 
+ *                    pattern="([^a-z])" replacement=""/&gt;
+ *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ * 
+ *
+ * @since Solr 3.1
+ */
+public class PatternReplaceCharFilterFactory extends CharFilterFactory {
+  
+  private Pattern p;
+  private String replacement;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init( args );
+    p = getPattern("pattern");
+    replacement = args.get( "replacement" );
+    if( replacement == null )
+      replacement = "";
+    // TODO: throw exception if you set maxBlockChars or blockDelimiters ?
+  }
+
+  public CharFilter create(Reader input) {
+    return new PatternReplaceCharFilter( p, replacement, input );
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
new file mode 100644
index 0000000..c71b794
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceFilterFactory.java
@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.pattern.PatternReplaceFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+/**
+ * Factory for {@link PatternReplaceFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptnreplace" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])" replacement=""
+ *             replace="all"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ * @see PatternReplaceFilter
+ */
+public class PatternReplaceFilterFactory extends TokenFilterFactory {
+  Pattern p;
+  String replacement;
+  boolean all = true;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    p = getPattern("pattern");
+    replacement = args.get("replacement");
+    
+    String r = args.get("replace");
+    if (null != r) {
+      if (r.equals("all")) {
+        all = true;
+      } else {
+        if (r.equals("first")) {
+          all = false;
+        } else {
+          throw new InitializationException
+            ("Configuration Error: 'replace' must be 'first' or 'all' in "
+             + this.getClass().getName());
+        }
+      }
+    }
+
+  }
+  public PatternReplaceFilter create(TokenStream input) {
+    return new PatternReplaceFilter(input, p, replacement, all);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
new file mode 100644
index 0000000..a11e9fd
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Map;
+import java.util.regex.Pattern;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.pattern.PatternTokenizer;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+
+/**
+ * Factory for {@link PatternTokenizer}.
+ * This tokenizer uses regex pattern matching to construct distinct tokens
+ * for the input stream.  It takes two arguments:  "pattern" and "group".
+ * <p/>
+ * <ul>
+ * <li>"pattern" is the regular expression.</li>
+ * <li>"group" says which group to extract into tokens.</li>
+ *  </ul>
+ * <p>
+ * group=-1 (the default) is equivalent to "split".  In this case, the tokens will
+ * be equivalent to the output from (without empty tokens):
+ * {@link String#split(java.lang.String)}
+ * </p>
+ * <p>
+ * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
+ * <pre>
+ *  pattern = \'([^\']+)\'
+ *  group = 0
+ *  input = aaa 'bbb' 'ccc'
+ *</pre>
+ * the output will be two tokens: 'bbb' and 'ccc' (including the ' marks).  With the same input
+ * but using group=1, the output would be: bbb and ccc (no ' marks)
+ * </p>
+ * <p>NOTE: This Tokenizer does not output tokens that are of zero length.</p>
+ *
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptn" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.PatternTokenizerFactory" pattern="\'([^\']+)\'" group="1"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ * 
+ * @see PatternTokenizer
+ * @since solr1.2
+ *
+ */
+public class PatternTokenizerFactory extends TokenizerFactory
+{
+  public static final String PATTERN = "pattern";
+  public static final String GROUP = "group";
+ 
+  protected Pattern pattern;
+  protected int group;
+  
+  /**
+   * Require a configured pattern
+   */
+  @Override
+  public void init(Map<String,String> args) 
+  {
+    super.init(args);
+    pattern = getPattern( PATTERN );
+    
+    group = -1;  // use 'split'
+    String g = args.get( GROUP );
+    if( g != null ) {
+      try {
+        group = Integer.parseInt( g );
+      }
+      catch( Exception ex ) {
+        throw new InitializationException("invalid group argument: " + g);
+      }
+    }
+  }
+  
+  /**
+   * Split the input using configured pattern
+   */
+  public Tokenizer create(final Reader in) {
+    try {
+      return new PatternTokenizer(in, pattern, group);
+    } catch( IOException ex ) {
+      throw new InitializationException("IOException thrown creating PatternTokenizer instance", ex);
+    }
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
new file mode 100644
index 0000000..007b83d
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterFactory.java
@@ -0,0 +1,83 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.payloads.DelimitedPayloadTokenFilter;
+import org.apache.lucene.analysis.payloads.PayloadEncoder;
+import org.apache.lucene.analysis.payloads.FloatEncoder;
+import org.apache.lucene.analysis.payloads.IntegerEncoder;
+import org.apache.lucene.analysis.payloads.IdentityEncoder;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.lucene.analysis.util.ResourceLoaderAware;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+
+/**
+ *
+ * Factory for {@link DelimitedPayloadTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_dlmtd" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.DelimitedPayloadTokenFilterFactory" encoder="float" delimiter="|"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ * 
+ */
+public class DelimitedPayloadTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  public static final String ENCODER_ATTR = "encoder";
+  public static final String DELIMITER_ATTR = "delimiter";
+
+  private PayloadEncoder encoder;
+  private char delimiter = '|';
+
+  public DelimitedPayloadTokenFilter create(TokenStream input) {
+    return new DelimitedPayloadTokenFilter(input, delimiter, encoder);
+  }
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+  }
+
+  public void inform(ResourceLoader loader) {
+    String encoderClass = args.get(ENCODER_ATTR);
+    if (encoderClass.equals("float")){
+      encoder = new FloatEncoder();
+    } else if (encoderClass.equals("integer")){
+      encoder = new IntegerEncoder();
+    } else if (encoderClass.equals("identity")){
+      encoder = new IdentityEncoder();
+    } else {
+      encoder = loader.newInstance(encoderClass, PayloadEncoder.class);
+    }
+
+    String delim = args.get(DELIMITER_ATTR);
+    if (delim != null){
+      if (delim.length() == 1) {
+        delimiter = delim.charAt(0);
+      } else{
+        throw new InitializationException("Delimiter must be one character only");
+      }
+    }
+  }
+}
\ No newline at end of file
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java
new file mode 100644
index 0000000..605df3e
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterFactory.java
@@ -0,0 +1,51 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.payloads.NumericPayloadTokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+import java.util.Map;
+
+/** 
+ * Factory for {@link NumericPayloadTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_numpayload" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.NumericPayloadTokenFilterFactory" payload="24" typeMatch="word"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class NumericPayloadTokenFilterFactory extends TokenFilterFactory {
+  private float payload;
+  private String typeMatch;
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    payload = Float.parseFloat(args.get("payload"));
+    typeMatch = args.get("typeMatch");
+  }
+  public NumericPayloadTokenFilter create(TokenStream input) {
+    return new NumericPayloadTokenFilter(input,payload,typeMatch);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterFactory.java
new file mode 100644
index 0000000..6d866e1
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterFactory.java
@@ -0,0 +1,42 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.payloads.TokenOffsetPayloadTokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link TokenOffsetPayloadTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_tokenoffset" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.TokenOffsetPayloadTokenFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class TokenOffsetPayloadTokenFilterFactory extends TokenFilterFactory {
+  public TokenOffsetPayloadTokenFilter create(TokenStream input) {
+    return new TokenOffsetPayloadTokenFilter(input);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterFactory.java
new file mode 100644
index 0000000..9a67fa9
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterFactory.java
@@ -0,0 +1,42 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.payloads.TypeAsPayloadTokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link TypeAsPayloadTokenFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_typeaspayload" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.TypeAsPayloadTokenFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class TypeAsPayloadTokenFilterFactory extends TokenFilterFactory {
+  public TypeAsPayloadTokenFilter create(TokenStream input) {
+    return new TypeAsPayloadTokenFilter(input);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/position/PositionFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/position/PositionFilterFactory.java
new file mode 100644
index 0000000..1fcc294
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/position/PositionFilterFactory.java
@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.position.PositionFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link PositionFilter}.
+ * Set the positionIncrement of all tokens to the "positionIncrement", except the first return token which retains its
+ * original positionIncrement value. The default positionIncrement value is zero.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_position" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.PositionFilterFactory" positionIncrement="0"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ * @see org.apache.lucene.analysis.position.PositionFilter
+ * @since solr 1.4
+ */
+public class PositionFilterFactory extends TokenFilterFactory {
+  private int positionIncrement;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    positionIncrement = getInt("positionIncrement", 0);
+  }
+
+  public PositionFilter create(TokenStream input) {
+    return new PositionFilter(input, positionIncrement);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseLightStemFilterFactory.java
new file mode 100644
index 0000000..63f8902
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.pt.PortugueseLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link PortugueseLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.PortugueseLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PortugueseLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new PortugueseLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemFilterFactory.java
new file mode 100644
index 0000000..9148435
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.pt.PortugueseMinimalStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link PortugueseMinimalStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptminstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.PortugueseMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PortugueseMinimalStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new PortugueseMinimalStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseStemFilterFactory.java
new file mode 100644
index 0000000..4ddb7d9
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.pt.PortugueseStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link PortugueseStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_ptstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.PortugueseStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class PortugueseStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new PortugueseStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilterFactory.java
new file mode 100644
index 0000000..f090c9d
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilterFactory.java
@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.reverse.ReverseStringFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link ReverseStringFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_rvsstr" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ReverseStringFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ * @since solr 1.4
+ */
+public class ReverseStringFilterFactory extends TokenFilterFactory {
+  public ReverseStringFilter create(TokenStream in) {
+    assureMatchVersion();
+    return new ReverseStringFilter(luceneMatchVersion,in);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLightStemFilterFactory.java
new file mode 100644
index 0000000..6b0411b
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ru.RussianLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link RussianLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_rulgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.RussianLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class RussianLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new RussianLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java
new file mode 100644
index 0000000..ba329a0
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilterFactory.java
@@ -0,0 +1,82 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.shingle.ShingleFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+/** 
+ * Factory for {@link ShingleFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_shingle" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ShingleFilterFactory" minShingleSize="2" maxShingleSize="2"
+ *             outputUnigrams="true" outputUnigramsIfNoShingles="false" tokenSeparator=" "/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ShingleFilterFactory extends TokenFilterFactory {
+  private int minShingleSize;
+  private int maxShingleSize;
+  private boolean outputUnigrams;
+  private boolean outputUnigramsIfNoShingles;
+  private String tokenSeparator;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    maxShingleSize = getInt("maxShingleSize", 
+                            ShingleFilter.DEFAULT_MAX_SHINGLE_SIZE);
+    if (maxShingleSize < 2) {
+      throw new InitializationException("Invalid maxShingleSize (" + maxShingleSize
+                              + ") - must be at least 2");
+    }
+    minShingleSize = getInt("minShingleSize",
+                            ShingleFilter.DEFAULT_MIN_SHINGLE_SIZE);
+    if (minShingleSize < 2) {
+      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
+                              + ") - must be at least 2");
+    }
+    if (minShingleSize > maxShingleSize) {
+      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
+                              + ") - must be no greater than maxShingleSize ("
+                              + maxShingleSize + ")");
+    }
+    outputUnigrams = getBoolean("outputUnigrams", true);
+    outputUnigramsIfNoShingles = getBoolean("outputUnigramsIfNoShingles", false);
+    tokenSeparator = args.containsKey("tokenSeparator")
+                     ? args.get("tokenSeparator")
+                     : ShingleFilter.TOKEN_SEPARATOR;
+  }
+  public ShingleFilter create(TokenStream input) {
+    ShingleFilter r = new ShingleFilter(input, minShingleSize, maxShingleSize);
+    r.setOutputUnigrams(outputUnigrams);
+    r.setOutputUnigramsIfNoShingles(outputUnigramsIfNoShingles);
+    r.setTokenSeparator(tokenSeparator);
+    return r;
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
new file mode 100644
index 0000000..dc897cb
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballPorterFilterFactory.java
@@ -0,0 +1,90 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import java.util.Map;
+import java.io.IOException;
+
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.snowball.SnowballFilter;
+import org.apache.lucene.analysis.util.*;
+import org.tartarus.snowball.SnowballProgram;
+
+/**
+ * Factory for {@link SnowballFilter}, with configurable language
+ * <p>
+ * Note: Use of the "Lovins" stemmer is not recommended, as it is implemented with reflection.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_snowballstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.SnowballPorterFilterFactory" protected="protectedkeyword.txt" language="English"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ * 
+ *
+ */
+public class SnowballPorterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
+  public static final String PROTECTED_TOKENS = "protected";
+
+  private String language = "English";
+  private Class<?> stemClass;
+
+
+  public void inform(ResourceLoader loader) {
+    String wordFiles = args.get(PROTECTED_TOKENS);
+    if (wordFiles != null) {
+      try {
+        protectedWords = getWordSet(loader, wordFiles, false);
+      } catch (IOException e) {
+        throw new InitializationException("IOException thrown while loading protected words", e);
+      }
+    }
+  }
+
+  private CharArraySet protectedWords = null;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    final String cfgLanguage = args.get("language");
+    if(cfgLanguage!=null) language = cfgLanguage;
+
+    try {
+      stemClass = Class.forName("org.tartarus.snowball.ext." + language + "Stemmer");
+    } catch (ClassNotFoundException e) {
+      throw new InitializationException("Can't find class for stemmer language " + language, e);
+    }
+  }
+  
+  public TokenFilter create(TokenStream input) {
+    SnowballProgram program;
+    try {
+      program = (SnowballProgram)stemClass.newInstance();
+    } catch (Exception e) {
+      throw new InitializationException("Error instantiating stemmer for language " + language + "from class " + stemClass, e);
+    }
+
+    if (protectedWords != null)
+      input = new KeywordMarkerFilter(input, protectedWords);
+    return new SnowballFilter(input, program);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicFilterFactory.java
new file mode 100644
index 0000000..12ae66f
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicFilterFactory.java
@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+import org.apache.lucene.analysis.standard.ClassicFilter;
+
+/**
+ * Factory for {@link ClassicFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_clssc" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.ClassicTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ClassicFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ */
+public class ClassicFilterFactory extends TokenFilterFactory {
+  public TokenFilter create(TokenStream input) {
+    return new ClassicFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
new file mode 100644
index 0000000..4efe6e7
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerFactory.java
@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.standard.ClassicTokenizer;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link ClassicTokenizer}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_clssc" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.ClassicTokenizerFactory" maxTokenLength="120"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ *
+ */
+
+public class ClassicTokenizerFactory extends TokenizerFactory {
+
+  private int maxTokenLength;
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+    maxTokenLength = getInt("maxTokenLength", 
+                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+  }
+
+  public Tokenizer create(Reader input) {
+    ClassicTokenizer tokenizer = new ClassicTokenizer(luceneMatchVersion, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilterFactory.java
new file mode 100644
index 0000000..965eb08
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilterFactory.java
@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.standard.StandardFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link StandardFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_stndrd" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.StandardFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class StandardFilterFactory extends TokenFilterFactory {
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+  }
+  
+  public StandardFilter create(TokenStream input) {
+    return new StandardFilter(luceneMatchVersion, input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
new file mode 100644
index 0000000..4385057
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizerFactory.java
@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link StandardTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_stndrd" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory" maxTokenLength="255"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+
+public class StandardTokenizerFactory extends TokenizerFactory {
+  
+  private int maxTokenLength;
+  
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+    maxTokenLength = getInt("maxTokenLength", 
+                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+  }
+
+  public StandardTokenizer create(Reader input) {
+    StandardTokenizer tokenizer
+      = new StandardTokenizer(luceneMatchVersion, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
new file mode 100644
index 0000000..4c7076f
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailTokenizerFactory.java
@@ -0,0 +1,59 @@
+package org.apache.solr.analysis;
+
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+
+import java.io.Reader;
+import java.util.Map;
+
+/**
+ * Factory for {@link UAX29URLEmailTokenizer}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_urlemail" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.UAX29URLEmailTokenizerFactory" maxTokenLength="255"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ * 
+ */
+
+public class UAX29URLEmailTokenizerFactory extends TokenizerFactory {
+
+  private int maxTokenLength;
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init(args);
+    assureMatchVersion();
+    maxTokenLength = getInt("maxTokenLength",
+                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
+  }
+
+  public UAX29URLEmailTokenizer create(Reader input) {
+    UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(luceneMatchVersion, input); 
+    tokenizer.setMaxTokenLength(maxTokenLength);
+    return tokenizer;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemFilterFactory.java
new file mode 100644
index 0000000..78f65da
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/sv/SwedishLightStemFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.sv.SwedishLightStemFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link SwedishLightStemFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.SwedishLightStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class SwedishLightStemFilterFactory extends TokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new SwedishLightStemFilter(input);
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilterFactory.java
new file mode 100644
index 0000000..22d3953
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilterFactory.java
@@ -0,0 +1,43 @@
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.solr.analysis;
+import org.apache.lucene.analysis.th.ThaiWordFilter;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link ThaiWordFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_thai" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.ThaiWordFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class ThaiWordFilterFactory extends TokenFilterFactory {
+  public ThaiWordFilter create(TokenStream input) {
+    assureMatchVersion();
+    return new ThaiWordFilter(luceneMatchVersion, input);
+  }
+}
+
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishLowerCaseFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishLowerCaseFilterFactory.java
new file mode 100644
index 0000000..72fa83b
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/tr/TurkishLowerCaseFilterFactory.java
@@ -0,0 +1,46 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tr.TurkishLowerCaseFilter;
+import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
+import org.apache.lucene.analysis.util.MultiTermAwareComponent;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link TurkishLowerCaseFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_trlwr" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.TurkishLowerCaseFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class TurkishLowerCaseFilterFactory extends TokenFilterFactory  implements MultiTermAwareComponent {
+  public TokenStream create(TokenStream input) {
+    return new TurkishLowerCaseFilter(input);
+  }
+
+  @Override
+  public AbstractAnalysisFactory getMultiTermComponent() {
+    return this;
+  }
+}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java
new file mode 100644
index 0000000..e77b058
--- /dev/null
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerFactory.java
@@ -0,0 +1,41 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
+
+/** 
+ * Factory for {@link WikipediaTokenizer}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_wiki" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WikipediaTokenizerFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class WikipediaTokenizerFactory extends TokenizerFactory {
+  // TODO: add support for WikipediaTokenizer's advanced options.
+  public Tokenizer create(Reader input) {
+    return new WikipediaTokenizer(input);
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemFilterFactory.java
new file mode 100644
index 0000000..7be02eb
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/bg/TestBulgarianStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Bulgarian stem filter factory is working.
+ */
+public class TestBulgarianStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("???");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    BulgarianStemFilterFactory factory = new BulgarianStemFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "???" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemFilterFactory.java
new file mode 100644
index 0000000..0511265
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Brazilian stem filter factory is working.
+ */
+public class TestBrazilianStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems and normalizes text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("Braslia");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    BrazilianStemFilterFactory factory = new BrazilianStemFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "brasil" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestHTMLStripCharFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestHTMLStripCharFilterFactory.java
new file mode 100644
index 0000000..da7f390
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestHTMLStripCharFilterFactory.java
@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.*;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
+
+
+  public void testNothingChanged() throws IOException {
+    //                             11111111112
+    //                   012345678901234567890
+    final String text = "this is only a test.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("escapedTags", "a, Title");
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "only", "a", "test." },
+        new int[] { 0, 5,  8, 13, 15 },
+        new int[] { 4, 7, 12, 14, 20 });
+  }
+
+  public void testNoEscapedTags() throws IOException {
+    //                             11111111112222222222333333333344
+    //                   012345678901234567890123456789012345678901
+    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "only", "a", "test." },
+        new int[] {  3, 12, 18, 27, 32 },
+        new int[] { 11, 14, 26, 28, 41 });
+  }
+
+  public void testEscapedTags() throws IOException {
+    //                             11111111112222222222333333333344
+    //                   012345678901234567890123456789012345678901
+    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("escapedTags", "U i");
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "<u>this</u>", "is", "only", "a", "<I>test</I>." },
+        new int[] {  0, 12, 18, 27, 29 },
+        new int[] { 11, 14, 26, 28, 41 });
+  }
+
+  public void testSeparatorOnlyEscapedTags() throws IOException {
+    //                             11111111112222222222333333333344
+    //                   012345678901234567890123456789012345678901
+    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("escapedTags", ",, , ");
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "only", "a", "test." },
+        new int[] {  3, 12, 18, 27, 32 },
+        new int[] { 11, 14, 26, 28, 41 });
+  }
+
+  public void testEmptyEscapedTags() throws IOException {
+    //                             11111111112222222222333333333344
+    //                   012345678901234567890123456789012345678901
+    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("escapedTags", "");
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "only", "a", "test." },
+        new int[] {  3, 12, 18, 27, 32 },
+        new int[] { 11, 14, 26, 28, 41 });
+  }
+
+  public void testSingleEscapedTag() throws IOException {
+    //                             11111111112222222222333333333344
+    //                   012345678901234567890123456789012345678901
+    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
+    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("escapedTags", ", B\r\n\t");
+    factory.init(args);
+    CharFilter cs = factory.create(new StringReader(text));
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "<b>only</b>", "a", "test." },
+        new int[] {  3, 12, 15, 27, 32 },
+        new int[] { 11, 14, 26, 28, 41 });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java
new file mode 100644
index 0000000..c9db4aa
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilterFactory.java
@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestMappingCharFilterFactory extends LuceneTestCase {
+  public void testParseString() throws Exception {
+
+    MappingCharFilterFactory f = new MappingCharFilterFactory();
+
+    try {
+      f.parseString( "\\" );
+      fail( "escape character cannot be alone." );
+    }
+    catch (InitializationException expected) {}
+    
+    assertEquals( "unexpected escaped characters",
+        "\\\"\n\t\r\b\f", f.parseString( "\\\\\\\"\\n\\t\\r\\b\\f" ) );
+    assertEquals( "unexpected escaped characters",
+        "A", f.parseString( "\\u0041" ) );
+    assertEquals( "unexpected escaped characters",
+        "AB", f.parseString( "\\u0041\\u0042" ) );
+
+    try {
+      f.parseString( "\\u000" );
+      fail( "invalid length check." );
+    }
+    catch (InitializationException expected) {}
+
+    try {
+      f.parseString( "\\u123x" );
+      fail( "invalid hex number check." );
+    }
+    catch( NumberFormatException expected ){}
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKWidthFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKWidthFilterFactory.java
new file mode 100644
index 0000000..0de6588
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKWidthFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the CJKWidthFilterFactory is working
+ */
+public class TestCJKWidthFilterFactory extends BaseTokenStreamTestCase {
+  public void test() throws Exception {
+    Reader reader = new StringReader("??? ????");
+    CJKWidthFilterFactory factory = new CJKWidthFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "Test", "1234" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java
new file mode 100644
index 0000000..27841e7
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsFilterFactory.java
@@ -0,0 +1,106 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+import java.util.HashMap;
+
+/**
+ * Tests pretty much copied from StopFilterFactoryTest We use the test files
+ * used by the StopFilterFactoryTest TODO: consider creating separate test files
+ * so this won't break if stop filter test files change
+ **/
+public class CommonGramsFilterFactoryTest extends BaseTokenStreamTestCase {
+
+  public void testInform() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    CommonGramsFilterFactory factory = new CommonGramsFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("words", "stop-1.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 2,
+        words.size() == 2);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
+        .isIgnoreCase() == true);
+
+    factory = new CommonGramsFilterFactory();
+    args.put("words", "stop-1.txt, stop-2.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 4,
+        words.size() == 4);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
+        .isIgnoreCase() == true);
+
+    factory = new CommonGramsFilterFactory();
+    args.put("words", "stop-snowball.txt");
+    args.put("format", "snowball");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getCommonWords();
+    assertEquals(8, words.size());
+    assertTrue(words.contains("he"));
+    assertTrue(words.contains("him"));
+    assertTrue(words.contains("his"));
+    assertTrue(words.contains("himself"));
+    assertTrue(words.contains("she"));
+    assertTrue(words.contains("her"));
+    assertTrue(words.contains("hers"));
+    assertTrue(words.contains("herself"));
+  }
+  
+  /**
+   * If no words are provided, then a set of english default stopwords is used.
+   */
+  public void testDefaults() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    CommonGramsFilterFactory factory = new CommonGramsFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue(words.contains("the"));
+    Tokenizer tokenizer = new MockTokenizer(new StringReader("testing the factory"), MockTokenizer.WHITESPACE, false);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, 
+        new String[] { "testing", "testing_the", "the", "the_factory", "factory" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java
new file mode 100644
index 0000000..f648432
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/TestCommonGramsQueryFilterFactory.java
@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+import java.util.HashMap;
+
+/**
+ * Tests pretty much copied from StopFilterFactoryTest We use the test files
+ * used by the StopFilterFactoryTest TODO: consider creating separate test files
+ * so this won't break if stop filter test files change
+ **/
+public class CommonGramsQueryFilterFactoryTest extends BaseTokenStreamTestCase {
+
+  public void testInform() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    CommonGramsQueryFilterFactory factory = new CommonGramsQueryFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("words", "stop-1.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 2,
+        words.size() == 2);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
+        .isIgnoreCase() == true);
+
+    factory = new CommonGramsQueryFilterFactory();
+    args.put("words", "stop-1.txt, stop-2.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 4,
+        words.size() == 4);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
+        .isIgnoreCase() == true);
+
+    factory = new CommonGramsQueryFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    args.put("words", "stop-snowball.txt");
+    args.put("format", "snowball");
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getCommonWords();
+    assertEquals(8, words.size());
+    assertTrue(words.contains("he"));
+    assertTrue(words.contains("him"));
+    assertTrue(words.contains("his"));
+    assertTrue(words.contains("himself"));
+    assertTrue(words.contains("she"));
+    assertTrue(words.contains("her"));
+    assertTrue(words.contains("hers"));
+    assertTrue(words.contains("herself"));
+  }
+  
+  /**
+   * If no words are provided, then a set of english default stopwords is used.
+   */
+  public void testDefaults() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    CommonGramsQueryFilterFactory factory = new CommonGramsQueryFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getCommonWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue(words.contains("the"));
+    Tokenizer tokenizer = new MockTokenizer(new StringReader("testing the factory"), MockTokenizer.WHITESPACE, false);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, 
+        new String[] { "testing_the", "the_factory" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java
new file mode 100644
index 0000000..8b7832d
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestDictionaryCompoundWordTokenFilterFactory.java
@@ -0,0 +1,54 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests to ensure the Dictionary compound filter factory is working.
+ */
+public class TestDictionaryCompoundWordTokenFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually decompounds text.
+   */
+  public void testDecompounding() throws Exception {
+    Reader reader = new StringReader("I like to play softball");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    DictionaryCompoundWordTokenFilterFactory factory = new DictionaryCompoundWordTokenFilterFactory();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("dictionary", "compoundDictionary.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, 
+        new String[] { "I", "like", "to", "play", "softball", "soft", "ball" });
+  }
+  
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java
new file mode 100644
index 0000000..30a282c
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestHyphenationCompoundWordTokenFilterFactory.java
@@ -0,0 +1,81 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests to ensure the Hyphenation compound filter factory is working.
+ */
+public class TestHyphenationCompoundWordTokenFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the factory works with hyphenation grammar+dictionary: using default options.
+   */
+  public void testHyphenationWithDictionary() throws Exception {
+    Reader reader = new StringReader("min veninde som er lidt af en lsehest");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    HyphenationCompoundWordTokenFilterFactory factory = new HyphenationCompoundWordTokenFilterFactory();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("hyphenator", "da_UTF8.xml");
+    args.put("dictionary", "da_compoundDictionary.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    
+    assertTokenStreamContents(stream, 
+        new String[] { "min", "veninde", "som", "er", "lidt", "af", "en", "lsehest", "lse", "hest" },
+        new int[] { 1, 1, 1, 1, 1, 1, 1, 1, 0, 0 }
+    );
+  }
+
+  /**
+   * Ensure the factory works with no dictionary: using hyphenation grammar only.
+   * Also change the min/max subword sizes from the default. When using no dictionary,
+   * its generally necessary to tweak these, or you get lots of expansions.
+   */
+  public void testHyphenationOnly() throws Exception {
+    Reader reader = new StringReader("basketballkurv");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    HyphenationCompoundWordTokenFilterFactory factory = new HyphenationCompoundWordTokenFilterFactory();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("hyphenator", "da_UTF8.xml");
+    args.put("minSubwordSize", "2");
+    args.put("maxSubwordSize", "4");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    
+    assertTokenStreamContents(stream,
+        new String[] { "basketballkurv", "ba", "sket", "bal", "ball", "kurv" }
+    );
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java
new file mode 100644
index 0000000..4dc1f9e
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilterFactory.java
@@ -0,0 +1,76 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+import java.util.Map;
+import java.util.HashMap;
+
+/**
+ *
+ *
+ **/
+public class TestStopFilterFactory extends BaseTokenStreamTestCase {
+
+  public void testInform() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    StopFilterFactory factory = new StopFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("words", "stop-1.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getStopWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 2, words.size() == 2);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
+
+    factory = new StopFilterFactory();
+    args.put("words", "stop-1.txt, stop-2.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getStopWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 4, words.size() == 4);
+    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
+
+    factory = new StopFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    args.put("words", "stop-snowball.txt");
+    args.put("format", "snowball");
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getStopWords();
+    assertEquals(8, words.size());
+    assertTrue(words.contains("he"));
+    assertTrue(words.contains("him"));
+    assertTrue(words.contains("his"));
+    assertTrue(words.contains("himself"));
+    assertTrue(words.contains("she"));
+    assertTrue(words.contains("her"));
+    assertTrue(words.contains("hers"));
+    assertTrue(words.contains("herself"));
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
new file mode 100644
index 0000000..e8dee7c
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestTypeTokenFilterFactory.java
@@ -0,0 +1,105 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.NumericTokenStream;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+import org.junit.Test;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ * Testcase for {@link TypeTokenFilterFactory}
+ */
+public class TestTypeTokenFilterFactory extends BaseTokenStreamTestCase {
+
+  @Test
+  public void testInform() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    TypeTokenFilterFactory factory = new TypeTokenFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("types", "stoptypes-1.txt");
+    args.put("enablePositionIncrements", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    Set<String> types = factory.getStopTypes();
+    assertTrue("types is null and it shouldn't be", types != null);
+    assertTrue("types Size: " + types.size() + " is not: " + 2, types.size() == 2);
+    assertTrue("enablePositionIncrements was set to true but not correctly parsed", factory.isEnablePositionIncrements());
+
+    factory = new TypeTokenFilterFactory();
+    args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
+    args.put("enablePositionIncrements", "false");
+    args.put("useWhitelist","true");
+    factory.init(args);
+    factory.inform(loader);
+    types = factory.getStopTypes();
+    assertTrue("types is null and it shouldn't be", types != null);
+    assertTrue("types Size: " + types.size() + " is not: " + 4, types.size() == 4);
+    assertTrue("enablePositionIncrements was set to false but not correctly parsed", !factory.isEnablePositionIncrements());
+  }
+
+  @Test
+  public void testCreationWithBlackList() throws Exception {
+    TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
+    args.put("enablePositionIncrements", "false");
+    typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    typeTokenFilterFactory.init(args);
+    NumericTokenStream input = new NumericTokenStream();
+    input.setIntValue(123);
+    typeTokenFilterFactory.create(input);
+  }
+  
+  @Test
+    public void testCreationWithWhiteList() throws Exception {
+      TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
+      Map<String, String> args = new HashMap<String, String>();
+      args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
+      args.put("enablePositionIncrements", "false");
+      args.put("useWhitelist","true");
+      typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+      typeTokenFilterFactory.init(args);
+      NumericTokenStream input = new NumericTokenStream();
+      input.setIntValue(123);
+      typeTokenFilterFactory.create(input);
+    }
+
+  @Test
+  public void testMissingTypesParameter() throws Exception {
+    try {
+      TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
+      Map<String, String> args = new HashMap<String, String>();
+      args.put("enablePositionIncrements", "false");
+      typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+      typeTokenFilterFactory.init(args);
+      typeTokenFilterFactory.inform(new SolrResourceLoader(null, null));
+      fail("not supplying 'types' parameter should cause an InitializationException");
+    } catch (InitializationException e) {
+      // everything ok
+    }
+  }
+
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemFilterFactory.java
new file mode 100644
index 0000000..2893d46
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Czech stem filter factory is working.
+ */
+public class TestCzechStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("angli?t");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    CzechStemFilterFactory factory = new CzechStemFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "anglick" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilterFactory.java
new file mode 100644
index 0000000..6524b36
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the German light stem factory is working.
+ */
+public class TestGermanLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("huser");
+    GermanLightStemFilterFactory factory = new GermanLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "haus" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilterFactory.java
new file mode 100644
index 0000000..62f8a68
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the German minimal stem factory is working.
+ */
+public class TestGermanMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("bilder");
+    GermanMinimalStemFilterFactory factory = new GermanMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "bild" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilterFactory.java
new file mode 100644
index 0000000..ecfecc4
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the German normalization factory is working.
+ */
+public class TestGermanNormalizationFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("wei?bier");
+    GermanNormalizationFilterFactory factory = new GermanNormalizationFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "weissbier" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilterFactory.java
new file mode 100644
index 0000000..39b1d78
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the German stem filter factory is working.
+ */
+public class TestGermanStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("Tischen");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    GermanStemFilterFactory factory = new GermanStemFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "tisch" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekLowerCaseFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekLowerCaseFilterFactory.java
new file mode 100644
index 0000000..b33a6eb
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekLowerCaseFilterFactory.java
@@ -0,0 +1,47 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Greek lowercase filter factory is working.
+ */
+public class TestGreekLowerCaseFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually lowercases (and a bit more) greek text.
+   */
+  public void testNormalization() throws Exception {
+    Reader reader = new StringReader("??? ???");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    GreekLowerCaseFilterFactory factory = new GreekLowerCaseFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "?", "?" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekStemFilterFactory.java
new file mode 100644
index 0000000..82a7e38
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/el/TestGreekStemFilterFactory.java
@@ -0,0 +1,41 @@
+package org.apache.solr.analysis;
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.el.GreekLowerCaseFilter;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Simple tests to ensure the Greek stem filter factory is working.
+ */
+public class TestGreekStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("????");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    TokenStream normalized = new GreekLowerCaseFilter(TEST_VERSION_CURRENT, tokenizer);
+    GreekStemFilterFactory factory = new GreekStemFilterFactory();
+    TokenStream stream = factory.create(normalized);
+    assertTokenStreamContents(stream, new String[] { "???" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilterFactory.java
new file mode 100644
index 0000000..806d036
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestEnglishMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the English minimal stem factory is working.
+ */
+public class TestEnglishMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("bricks");
+    EnglishMinimalStemFilterFactory factory = new EnglishMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "brick" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemFilterFactory.java
new file mode 100644
index 0000000..c94fc0f
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestKStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Simple tests to ensure the kstem filter factory is working.
+ */
+public class TestKStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("bricks");
+    KStemFilterFactory factory = new KStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "brick" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilterFactory.java
new file mode 100644
index 0000000..bb3be89
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/en/TestPorterStemFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Porter stem filter factory is working.
+ */
+public class TestPorterStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("dogs");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    PorterStemFilterFactory factory = new PorterStemFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "dog" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilterFactory.java
new file mode 100644
index 0000000..deba80b
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/es/TestSpanishLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Spanish Light stem factory is working.
+ */
+public class TestSpanishLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("sociedades");
+    SpanishLightStemFilterFactory factory = new SpanishLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "sociedad" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilterFactory.java
new file mode 100644
index 0000000..a189d55
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Persian normalization factory is working.
+ */
+public class TestPersianNormalizationFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually normalizes persian text.
+   */
+  public void testNormalization() throws Exception {
+    Reader reader = new StringReader("??");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    PersianNormalizationFilterFactory factory = new PersianNormalizationFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "??" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilterFactory.java
new file mode 100644
index 0000000..c345f3f
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fi/TestFinnishLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Finnish light stem factory is working.
+ */
+public class TestFinnishLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("aseistettujen");
+    FinnishLightStemFilterFactory factory = new FinnishLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "aseistet" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java
new file mode 100644
index 0000000..95c061f
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestElisionFilterFactory.java
@@ -0,0 +1,88 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests to ensure the French elision filter factory is working.
+ */
+public class TestElisionFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually normalizes text.
+   */
+  public void testElision() throws Exception {
+    Reader reader = new StringReader("l'avion");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ElisionFilterFactory factory = new ElisionFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("articles", "frenchArticles.txt");
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "avion" });
+  }
+  
+  /**
+   * Test creating an elision filter without specifying any articles
+   */
+  public void testDefaultArticles() throws Exception {
+    Reader reader = new StringReader("l'avion");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ElisionFilterFactory factory = new ElisionFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "avion" });
+  }
+  
+  /**
+   * Test setting ignoreCase=true
+   */
+  public void testCaseInsensitive() throws Exception {
+    Reader reader = new StringReader("L'avion");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ElisionFilterFactory factory = new ElisionFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("articles", "frenchArticles.txt");
+    args.put("ignoreCase", "true");
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "avion" });
+  }
+  
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilterFactory.java
new file mode 100644
index 0000000..784bf13
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the French light stem factory is working.
+ */
+public class TestFrenchLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("administrativement");
+    FrenchLightStemFilterFactory factory = new FrenchLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "administratif" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilterFactory.java
new file mode 100644
index 0000000..db869c2
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the French minimal stem factory is working.
+ */
+public class TestFrenchMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("chevaux");
+    FrenchMinimalStemFilterFactory factory = new FrenchMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "cheval" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishLowerCaseFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishLowerCaseFilterFactory.java
new file mode 100644
index 0000000..e429d91
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ga/TestIrishLowerCaseFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Irish lowercase filter factory is working.
+ */
+public class TestIrishLowerCaseFilterFactory extends BaseTokenStreamTestCase {
+  public void testCasing() throws Exception {
+    Reader reader = new StringReader("nAthair tUISCE hARD");
+    IrishLowerCaseFilterFactory factory = new IrishLowerCaseFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "n-athair", "t-uisce", "hard" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..8cd0933
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Galician plural stem factory is working.
+ */
+public class TestGalicianMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("elefantes");
+    GalicianMinimalStemFilterFactory factory = new GalicianMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "elefante" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilterFactory.java
new file mode 100644
index 0000000..1eafa38
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Galician stem factory is working.
+ */
+public class TestGalicianStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("cariosa");
+    GalicianStemFilterFactory factory = new GalicianStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "cari" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiFilters.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiFilters.java
new file mode 100644
index 0000000..4c40a6f
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hi/TestHindiFilters.java
@@ -0,0 +1,89 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Hindi filter Factories are working.
+ */
+public class TestHindiFilters extends BaseTokenStreamTestCase {
+  /**
+   * Test IndicNormalizationFilterFactory
+   */
+  public void testIndicNormalizer() throws Exception {
+    Reader reader = new StringReader("??? ??");
+    StandardTokenizerFactory factory = new StandardTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    IndicNormalizationFilterFactory filterFactory = new IndicNormalizationFilterFactory();
+    filterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    filterFactory.init(args);
+    Tokenizer tokenizer = factory.create(reader);
+    TokenStream stream = filterFactory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "?", "?" });
+  }
+  
+  /**
+   * Test HindiNormalizationFilterFactory
+   */
+  public void testHindiNormalizer() throws Exception {
+    Reader reader = new StringReader("??");
+    StandardTokenizerFactory factory = new StandardTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    IndicNormalizationFilterFactory indicFilterFactory = new IndicNormalizationFilterFactory();
+    HindiNormalizationFilterFactory hindiFilterFactory = new HindiNormalizationFilterFactory();
+    hindiFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    hindiFilterFactory.init(args);
+    Tokenizer tokenizer = factory.create(reader);
+    TokenStream stream = indicFilterFactory.create(tokenizer);
+    stream = hindiFilterFactory.create(stream);
+    assertTokenStreamContents(stream, new String[] {"??"});
+  }
+  
+  /**
+   * Test HindiStemFilterFactory
+   */
+  public void testStemmer() throws Exception {
+    Reader reader = new StringReader("????");
+    StandardTokenizerFactory factory = new StandardTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    IndicNormalizationFilterFactory indicFilterFactory = new IndicNormalizationFilterFactory();
+    HindiNormalizationFilterFactory hindiFilterFactory = new HindiNormalizationFilterFactory();
+    HindiStemFilterFactory stemFactory = new HindiStemFilterFactory();
+    stemFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    stemFactory.init(args);
+    Tokenizer tokenizer = factory.create(reader);
+    TokenStream stream = indicFilterFactory.create(tokenizer);
+    stream = hindiFilterFactory.create(stream);
+    stream = stemFactory.create(stream);
+    assertTokenStreamContents(stream, new String[] {"??"});
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilterFactory.java
new file mode 100644
index 0000000..ae79afc
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hu/TestHungarianLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Hungarian light stem factory is working.
+ */
+public class TestHungarianLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("hzakat");
+    HungarianLightStemFilterFactory factory = new HungarianLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "haz" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java
new file mode 100644
index 0000000..b5f33b4
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilterFactory.java
@@ -0,0 +1,48 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.solr.core.SolrResourceLoader;
+import org.apache.solr.schema.IndexSchema;
+
+/**
+ * Simple tests to ensure the Hunspell stemmer loads from factory
+ */
+public class TestHunspellStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    HunspellStemFilterFactory factory = new HunspellStemFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("dictionary", "hunspell-test.dic");
+    args.put("affix", "hunspell-test.aff");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(new SolrResourceLoader("solr/collection1"));
+    
+    Reader reader = new StringReader("abc");
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "ab" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemFilterFactory.java
new file mode 100644
index 0000000..1233d6b
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/id/TestIndonesianStemFilterFactory.java
@@ -0,0 +1,60 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Indonesian stem filter factory is working.
+ */
+public class TestIndonesianStemFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually stems text.
+   */
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("dibukukannya");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    IndonesianStemFilterFactory factory = new IndonesianStemFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "buku" });
+  }
+  
+  /**
+   * Test inflectional-only mode
+   */
+  public void testStemmingInflectional() throws Exception {
+    Reader reader = new StringReader("dibukukannya");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    IndonesianStemFilterFactory factory = new IndonesianStemFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("stemDerivational", "false");
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "dibukukan" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilterFactory.java
new file mode 100644
index 0000000..7787e0b
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Italian light stem factory is working.
+ */
+public class TestItalianLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("ragazzo ragazzi");
+    ItalianLightStemFilterFactory factory = new ItalianLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "ragazz", "ragazz" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemFilterFactory.java
new file mode 100644
index 0000000..4415cde
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Latvian stem factory is working.
+ */
+public class TestLatvianStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("tirgiem tirgus");
+    LatvianStemFilterFactory factory = new LatvianStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "tirg", "tirg" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCapitalizationFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCapitalizationFilterFactory.java
new file mode 100644
index 0000000..55f3c9f
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestCapitalizationFilterFactory.java
@@ -0,0 +1,224 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+
+/**
+ * 
+ */
+public class TestCapitalizationFilterFactory extends BaseTokenStreamTestCase {
+  
+  public void testCapitalization() throws Exception 
+  {
+    Map<String,String> args = new HashMap<String, String>();
+    args.put( CapitalizationFilterFactory.KEEP, "and the it BIG" );
+    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, "true" );  
+    
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init( args );
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "Kitten" });
+    
+    factory.forceFirstLetter = true;
+
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("and"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "And" });
+
+    //first is forced, but it's not a keep word, either
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "And" });
+
+    factory.forceFirstLetter = false;
+
+    //first is not forced, but it's not a keep word, either
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "And" });
+
+    factory.forceFirstLetter = true;
+    
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("big"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "Big" });
+    
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("BIG"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "BIG" });
+
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.KEYWORD, false)),
+        new String[] { "Hello there my name is ryan" });
+        
+    // now each token
+    factory.onlyFirstWord = false;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "Hello", "There", "My", "Name", "Is", "Ryan" });
+    
+    // now only the long words
+    factory.minWordLength = 3;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "Hello", "There", "my", "Name", "is", "Ryan" });
+    
+    // without prefix
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "Mckinley" });
+    
+    // Now try some prefixes
+    factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    args.put( "okPrefix", "McK" );  // all words
+    factory.init( args );
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "McKinley" });
+    
+    // now try some stuff with numbers
+    factory.forceFirstLetter = false;
+    factory.onlyFirstWord = false;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("1st 2nd third"), MockTokenizer.WHITESPACE, false)),
+        new String[] { "1st", "2nd", "Third" });
+    
+    factory.forceFirstLetter = true;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("the The the"), MockTokenizer.KEYWORD, false)),
+        new String[] { "The The the" });
+  }
+
+  public void testKeepIgnoreCase() throws Exception {
+    Map<String,String> args = new HashMap<String, String>();
+    args.put( CapitalizationFilterFactory.KEEP, "kitten" );
+    args.put( CapitalizationFilterFactory.KEEP_IGNORE_CASE, "true" );
+    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, "true" );
+
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init( args );
+    factory.forceFirstLetter = true;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
+        new String[] { "KiTTEN" });
+
+    factory.forceFirstLetter = false;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
+        new String[] { "kiTTEN" });
+
+    factory.keep = null;
+    assertTokenStreamContents(factory.create(
+        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
+        new String[] { "Kitten" });
+  }
+  
+  /**
+   * Test CapitalizationFilterFactory's minWordLength option.
+   * 
+   * This is very weird when combined with ONLY_FIRST_WORD!!!
+   */
+  public void testMinWordLength() throws Exception {
+    Map<String,String> args = new HashMap<String,String>();
+    args.put(CapitalizationFilterFactory.ONLY_FIRST_WORD, "true");
+    args.put(CapitalizationFilterFactory.MIN_WORD_LENGTH, "5");
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer tokenizer = new MockTokenizer(new StringReader(
+        "helo testing"), MockTokenizer.WHITESPACE, false);
+    TokenStream ts = factory.create(tokenizer);
+    assertTokenStreamContents(ts, new String[] {"helo", "Testing"});
+  }
+  
+  /**
+   * Test CapitalizationFilterFactory's maxWordCount option with only words of 1
+   * in each token (it should do nothing)
+   */
+  public void testMaxWordCount() throws Exception {
+    Map<String,String> args = new HashMap<String,String>();
+    args.put(CapitalizationFilterFactory.MAX_WORD_COUNT, "2");
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer tokenizer = new MockTokenizer(new StringReader(
+        "one two three four"), MockTokenizer.WHITESPACE, false);
+    TokenStream ts = factory.create(tokenizer);
+    assertTokenStreamContents(ts, new String[] {"One", "Two", "Three", "Four"});
+  }
+  
+  /**
+   * Test CapitalizationFilterFactory's maxWordCount option when exceeded
+   */
+  public void testMaxWordCount2() throws Exception {
+    Map<String,String> args = new HashMap<String,String>();
+    args.put(CapitalizationFilterFactory.MAX_WORD_COUNT, "2");
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer tokenizer = new MockTokenizer(new StringReader(
+        "one two three four"), MockTokenizer.KEYWORD, false);
+    TokenStream ts = factory.create(tokenizer);
+    assertTokenStreamContents(ts, new String[] {"one two three four"});
+  }
+  
+  /**
+   * Test CapitalizationFilterFactory's maxTokenLength option when exceeded
+   * 
+   * This is weird, it is not really a max, but inclusive (look at 'is')
+   */
+  public void testMaxTokenLength() throws Exception {
+    Map<String,String> args = new HashMap<String,String>();
+    args.put(CapitalizationFilterFactory.MAX_TOKEN_LENGTH, "2");
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer tokenizer = new MockTokenizer(new StringReader(
+        "this is a test"), MockTokenizer.WHITESPACE, false);
+    TokenStream ts = factory.create(tokenizer);
+    assertTokenStreamContents(ts, new String[] {"this", "is", "A", "test"});
+  }
+  
+  /**
+   * Test CapitalizationFilterFactory's forceFirstLetter option
+   */
+  public void testForceFirstLetter() throws Exception {
+    Map<String,String> args = new HashMap<String,String>();
+    args.put(CapitalizationFilterFactory.KEEP, "kitten");
+    args.put(CapitalizationFilterFactory.FORCE_FIRST_LETTER, "true");
+    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer tokenizer = new MockTokenizer(new StringReader("kitten"), MockTokenizer.WHITESPACE, false);
+    TokenStream ts = factory.create(tokenizer);
+    assertTokenStreamContents(ts, new String[] {"Kitten"});
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java
new file mode 100644
index 0000000..1c10041
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepFilterFactory.java
@@ -0,0 +1,60 @@
+package org.apache.solr.analysis;
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+import java.util.Map;
+import java.util.HashMap;
+
+/**
+ *
+ *
+ **/
+public class TestKeepFilterFactory extends BaseTokenStreamTestCase {
+
+  public void testInform() throws Exception {
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    assertTrue("loader is null and it shouldn't be", loader != null);
+    KeepWordFilterFactory factory = new KeepWordFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("words", "keep-1.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    CharArraySet words = factory.getWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 2, words.size() == 2);
+
+
+    factory = new KeepWordFilterFactory();
+    args.put("words", "keep-1.txt, keep-2.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    words = factory.getWords();
+    assertTrue("words is null and it shouldn't be", words != null);
+    assertTrue("words Size: " + words.size() + " is not: " + 4, words.size() == 4);
+
+
+
+  }
+}
\ No newline at end of file
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeywordMarkerFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeywordMarkerFilterFactory.java
new file mode 100644
index 0000000..7994f68
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeywordMarkerFilterFactory.java
@@ -0,0 +1,68 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.en.PorterStemFilter;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests to ensure the keyword marker filter factory is working.
+ */
+public class TestKeywordMarkerFilterFactory extends BaseTokenStreamTestCase {
+  public void testKeywords() throws IOException {
+    Reader reader = new StringReader("dogs cats");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    KeywordMarkerFilterFactory factory = new KeywordMarkerFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    args.put("protected", "protwords.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    
+    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
+    assertTokenStreamContents(ts, new String[] { "dog", "cats" });
+  }
+  
+  public void testKeywordsCaseInsensitive() throws IOException {
+    Reader reader = new StringReader("dogs cats Cats");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    KeywordMarkerFilterFactory factory = new KeywordMarkerFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    args.put("protected", "protwords.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    
+    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
+    assertTokenStreamContents(ts, new String[] { "dog", "cats", "Cats" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilter2.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilter2.java
new file mode 100644
index 0000000..30f2f12
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestLengthFilter2.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/**
+ * Copyright 2004 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+public class LengthFilterTest extends BaseTokenStreamTestCase {
+
+  public void test() throws IOException {
+    LengthFilterFactory factory = new LengthFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put(LengthFilterFactory.MIN_KEY, String.valueOf(4));
+    args.put(LengthFilterFactory.MAX_KEY, String.valueOf(10));
+    // default: args.put("enablePositionIncrements", "false");
+    factory.init(args);
+    String test = "foo foobar super-duper-trooper";
+    TokenStream stream = factory.create(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "foobar" }, new int[] { 1 });
+
+    factory = new LengthFilterFactory();
+    args = new HashMap<String, String>();
+    args.put(LengthFilterFactory.MIN_KEY, String.valueOf(4));
+    args.put(LengthFilterFactory.MAX_KEY, String.valueOf(10));
+    args.put("enablePositionIncrements", "true");
+    factory.init(args);
+    stream = factory.create(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "foobar" }, new int[] { 2 });
+  }
+}
\ No newline at end of file
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilterFactory.java
new file mode 100644
index 0000000..d098b26
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestRemoveDuplicatesTokenFilterFactory.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+import java.util.Iterator;
+import java.util.Arrays;
+
+/** Simple tests to ensure this factory is working */
+public class TestRemoveDuplicatesTokenFilterFactory extends BaseTokenStreamTestCase {
+
+  public static Token tok(int pos, String t, int start, int end) {
+    Token tok = new Token(t,start,end);
+    tok.setPositionIncrement(pos);
+    return tok;
+  }
+  public static Token tok(int pos, String t) {
+    return tok(pos, t, 0,0);
+  }
+
+  public void testDups(final String expected, final Token... tokens)
+    throws Exception {
+
+    final Iterator<Token> toks = Arrays.asList(tokens).iterator();
+    RemoveDuplicatesTokenFilterFactory factory = new RemoveDuplicatesTokenFilterFactory();
+    final TokenStream ts = factory.create
+      (new TokenStream() {
+          CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+          PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+          @Override
+          public boolean incrementToken() {
+            if (toks.hasNext()) {
+              clearAttributes();
+              Token tok = toks.next();
+              termAtt.setEmpty().append(tok);
+              offsetAtt.setOffset(tok.startOffset(), tok.endOffset());
+              posIncAtt.setPositionIncrement(tok.getPositionIncrement());
+              return true;
+            } else {
+              return false;
+            }
+          }
+        });
+    
+    assertTokenStreamContents(ts, expected.split("\\s"));   
+  }
+ 
+  public void testSimpleDups() throws Exception {
+    testDups("A B C D E"
+             ,tok(1,"A", 0,  4)
+             ,tok(1,"B", 5, 10)
+             ,tok(0,"B",11, 15)
+             ,tok(1,"C",16, 20)
+             ,tok(0,"D",16, 20)
+             ,tok(1,"E",21, 25)
+             ); 
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilterFactory.java
new file mode 100644
index 0000000..74de226
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestStemmerOverrideFilterFactory.java
@@ -0,0 +1,69 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.en.PorterStemFilter;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests to ensure the stemmer override filter factory is working.
+ */
+public class TestStemmerOverrideFilterFactory extends BaseTokenStreamTestCase {
+  public void testKeywords() throws IOException {
+    // our stemdict stems dogs to 'cat'
+    Reader reader = new StringReader("testing dogs");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    StemmerOverrideFilterFactory factory = new StemmerOverrideFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    args.put("dictionary", "stemdict.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    
+    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
+    assertTokenStreamContents(ts, new String[] { "test", "cat" });
+  }
+  
+  public void testKeywordsCaseInsensitive() throws IOException {
+    Reader reader = new StringReader("testing DoGs");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    StemmerOverrideFilterFactory factory = new StemmerOverrideFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    args.put("dictionary", "stemdict.txt");
+    args.put("ignoreCase", "true");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    
+    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
+    assertTokenStreamContents(ts, new String[] { "test", "cat" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilterFactory.java
new file mode 100644
index 0000000..9376422
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilterFactory.java
@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestTrimFilterFactory extends BaseTokenStreamTestCase {
+  public void testTrimming() throws Exception {
+    TrimFilterFactory factory = new TrimFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("updateOffsets", "false");
+    factory.init(args);
+    TokenStream ts = factory.create(new MockTokenizer(new StringReader("trim me    "), MockTokenizer.KEYWORD, false));
+    assertTokenStreamContents(ts, new String[] { "trim me" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilterFactory.java
new file mode 100644
index 0000000..ed4d782
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilterFactory.java
@@ -0,0 +1,242 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+/**
+ * New WordDelimiterFilter tests... most of the tests are in ConvertedLegacyTest
+ */
+public class TestWordDelimiterFilterFactory extends SolrTestCaseJ4 {
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig.xml","schema.xml");
+  }
+
+  public void posTst(String v1, String v2, String s1, String s2) {
+    assertU(adoc("id",  "42",
+                 "subword", v1,
+                 "subword", v2));
+    assertU(commit());
+
+    // there is a positionIncrementGap of 100 between field values, so
+    // we test if that was maintained.
+    assertQ("position increment lost",
+            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~90")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("position increment lost",
+            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~110")
+            ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testRetainPositionIncrement() {
+    posTst("foo","bar","foo","bar");
+    posTst("-foo-","-bar-","foo","bar");
+    posTst("foo","bar","-foo-","-bar-");
+
+    posTst("123","456","123","456");
+    posTst("/123/","/456/","123","456");
+
+    posTst("/123/abc","qwe/456/","abc","qwe");
+
+    posTst("zoo-foo","bar-baz","foo","bar");
+    posTst("zoo-foo-123","456-bar-baz","foo","bar");
+  }
+
+  @Test
+  public void testNoGenerationEdgeCase() {
+    assertU(adoc("id", "222", "numberpartfail", "123.123.123.123"));
+    clearIndex();
+  }
+
+  @Test
+  public void testIgnoreCaseChange() {
+
+    assertU(adoc("id",  "43",
+                 "wdf_nocase", "HellO WilliAM",
+                 "subword", "GoodBye JonEs"));
+    assertU(commit());
+    
+    assertQ("no case change",
+            req("wdf_nocase:(hell o am)")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("case change",
+            req("subword:(good jon)")
+            ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testPreserveOrignalTrue() {
+
+    assertU(adoc("id",  "144",
+                 "wdf_preserve", "404-123"));
+    assertU(commit());
+    
+    assertQ("preserving original word",
+            req("wdf_preserve:404")
+            ,"//result[@numFound=1]"
+    );
+    
+    assertQ("preserving original word",
+        req("wdf_preserve:123")
+        ,"//result[@numFound=1]"
+    );
+
+    assertQ("preserving original word",
+        req("wdf_preserve:404-123*")
+        ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  /***
+  public void testPerformance() throws IOException {
+    String s = "now is the time-for all good men to come to-the aid of their country.";
+    Token tok = new Token();
+    long start = System.currentTimeMillis();
+    int ret=0;
+    for (int i=0; i<1000000; i++) {
+      StringReader r = new StringReader(s);
+      TokenStream ts = new WhitespaceTokenizer(r);
+      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);
+
+      while (ts.next(tok) != null) ret++;
+    }
+
+    System.out.println("ret="+ret+" time="+(System.currentTimeMillis()-start));
+  }
+  ***/
+
+  @Test
+  public void testAlphaNumericWords(){
+     assertU(adoc("id",  "68","numericsubword","Java/J2SE"));
+     assertU(commit());
+
+     assertQ("j2se found",
+            req("numericsubword:(J2SE)")
+            ,"//result[@numFound=1]"
+    );
+      assertQ("no j2 or se",
+            req("numericsubword:(J2 OR SE)")
+            ,"//result[@numFound=0]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testProtectedWords(){
+    assertU(adoc("id", "70","protectedsubword","c# c++ .net Java/J2SE"));
+    assertU(commit());
+
+    assertQ("java found",
+            req("protectedsubword:(java)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ(".net found",
+            req("protectedsubword:(.net)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c# found",
+            req("protectedsubword:(c#)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c++ found",
+            req("protectedsubword:(c++)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c found?",
+            req("protectedsubword:c")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("net found?",
+            req("protectedsubword:net")
+            ,"//result[@numFound=0]"
+    );
+    clearIndex();
+  }
+  
+  @Test
+  public void testCustomTypes() throws Exception {
+    String testText = "I borrowed $5,400.00 at 25% interest-rate";
+    WordDelimiterFilterFactory factoryDefault = new WordDelimiterFilterFactory();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("generateWordParts", "1");
+    args.put("generateNumberParts", "1");
+    args.put("catenateWords", "1");
+    args.put("catenateNumbers", "1");
+    args.put("catenateAll", "0");
+    args.put("splitOnCaseChange", "1");
+    
+    /* default behavior */
+    factoryDefault.init(args);
+    factoryDefault.inform(loader);
+    
+    TokenStream ts = factoryDefault.create(
+        new MockTokenizer(new StringReader(testText), MockTokenizer.WHITESPACE, false));
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
+        new String[] { "I", "borrowed", "5", "400", "00", "540000", "at", "25", "interest", "rate", "interestrate" });
+
+    ts = factoryDefault.create(
+        new MockTokenizer(new StringReader("foo\u200Dbar"), MockTokenizer.WHITESPACE, false));
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
+        new String[] { "foo", "bar", "foobar" });
+
+    
+    /* custom behavior */
+    WordDelimiterFilterFactory factoryCustom = new WordDelimiterFilterFactory();
+    // use a custom type mapping
+    args.put("types", "wdftypes.txt");
+    factoryCustom.init(args);
+    factoryCustom.inform(loader);
+    
+    ts = factoryCustom.create(
+        new MockTokenizer(new StringReader(testText), MockTokenizer.WHITESPACE, false));
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
+        new String[] { "I", "borrowed", "$5,400.00", "at", "25%", "interest", "rate", "interestrate" });
+    
+    /* test custom behavior with a char > 0x7F, because we had to make a larger byte[] */
+    ts = factoryCustom.create(
+        new MockTokenizer(new StringReader("foo\u200Dbar"), MockTokenizer.WHITESPACE, false));
+    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
+        new String[] { "foo\u200Dbar" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/TestNGramFilters.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/TestNGramFilters.java
new file mode 100644
index 0000000..3790250
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ngram/TestNGramFilters.java
@@ -0,0 +1,164 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the NGram filter factories are working.
+ */
+public class TestNGramFilters extends BaseTokenStreamTestCase {
+  /**
+   * Test NGramTokenizerFactory
+   */
+  public void testNGramTokenizer() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    NGramTokenizerFactory factory = new NGramTokenizerFactory();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { "t", "e", "s", "t", "te", "es", "st" });
+  }
+  /**
+   * Test NGramTokenizerFactory with min and max gram options
+   */
+  public void testNGramTokenizer2() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minGramSize", "2");
+    args.put("maxGramSize", "3");
+    NGramTokenizerFactory factory = new NGramTokenizerFactory();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { "te", "es", "st", "tes", "est" });
+  }
+  /**
+   * Test the NGramFilterFactory
+   */
+  public void testNGramFilter() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    NGramFilterFactory factory = new NGramFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "t", "e", "s", "t", "te", "es", "st" });
+  }
+  /**
+   * Test the NGramFilterFactory with min and max gram options
+   */
+  public void testNGramFilter2() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minGramSize", "2");
+    args.put("maxGramSize", "3");
+    NGramFilterFactory factory = new NGramFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "te", "es", "st", "tes", "est" });
+  }
+  /**
+   * Test EdgeNGramTokenizerFactory
+   */
+  public void testEdgeNGramTokenizer() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { "t" });
+  }
+  /**
+   * Test EdgeNGramTokenizerFactory with min and max gram size
+   */
+  public void testEdgeNGramTokenizer2() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minGramSize", "1");
+    args.put("maxGramSize", "2");
+    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { "t", "te" });
+  }
+  /**
+   * Test EdgeNGramTokenizerFactory with side option
+   */
+  public void testEdgeNGramTokenizer3() throws Exception {
+    Reader reader = new StringReader("ready");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("side", "back");
+    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { "y" });
+  }
+  /**
+   * Test EdgeNGramFilterFactory
+   */
+  public void testEdgeNGramFilter() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "t" });
+  }
+  /**
+   * Test EdgeNGramFilterFactory with min and max gram size
+   */
+  public void testEdgeNGramFilter2() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minGramSize", "1");
+    args.put("maxGramSize", "2");
+    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "t", "te" });
+  }
+  /**
+   * Test EdgeNGramFilterFactory with side option
+   */
+  public void testEdgeNGramFilter3() throws Exception {
+    Reader reader = new StringReader("ready");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("side", "back");
+    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "y" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianLightStemFilterFactory.java
new file mode 100644
index 0000000..f8cbb53
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Norwegian Light stem factory is working.
+ */
+public class TestNorwegianLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("epler eple");
+    NorwegianLightStemFilterFactory factory = new NorwegianLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "epl", "epl" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..fb86cf6
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/no/TestNorwegianMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Norwegian Minimal stem factory is working.
+ */
+public class TestNorwegianMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("eple eplet epler eplene eplets eplenes");
+    NorwegianMinimalStemFilterFactory factory = new NorwegianMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "epl", "epl", "epl", "epl", "epl", "epl" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilterFactory.java
new file mode 100644
index 0000000..80cac56
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilterFactory.java
@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.*;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestPatternReplaceCharFilterFactory extends BaseTokenStreamTestCase {
+  
+  //           1111
+  // 01234567890123
+  // this is test.
+  public void testNothingChange() throws IOException {
+    final String BLOCK = "this is test.";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    args.put("replacement", "$1$2$3");
+    factory.init(args);
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "this", "is", "test." },
+        new int[] { 0, 5, 8 },
+        new int[] { 4, 7, 13 });
+  }
+  
+  // 012345678
+  // aa bb cc
+  public void testReplaceByEmpty() throws IOException {
+    final String BLOCK = "aa bb cc";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    factory.init(args);
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    ts.reset();
+    assertFalse(ts.incrementToken());
+    ts.end();
+    ts.close();
+  }
+  
+  // 012345678
+  // aa bb cc
+  // aa#bb#cc
+  public void test1block1matchSameLength() throws IOException {
+    final String BLOCK = "aa bb cc";
+    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
+    args.put("replacement", "$1#$2#$3");
+    factory.init(args);
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
+    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
+    assertTokenStreamContents(ts,
+        new String[] { "aa#bb#cc" },
+        new int[] { 0 },
+        new int[] { 8 });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilterFactory.java
new file mode 100644
index 0000000..0311043
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceFilterFactory.java
@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Simple tests to ensure this factory is working
+ */
+public class TestPatternReplaceFilterFactory extends BaseTokenStreamTestCase {
+
+  public void testReplaceAll() throws Exception {
+    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
+    PatternReplaceFilterFactory factory = new PatternReplaceFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("pattern", "a*b");
+    args.put("replacement", "-");
+    factory.init(args);
+    TokenStream ts = factory.create
+            (new MockTokenizer(new StringReader(input), MockTokenizer.WHITESPACE, false));
+                   
+    assertTokenStreamContents(ts, 
+        new String[] { "-foo-foo-foo-", "-", "c-" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizerFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizerFactory.java
new file mode 100644
index 0000000..afe15d7
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizerFactory.java
@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+
+/** Simple Tests to ensure this factory is working */
+public class TestPatternTokenizerFactory extends BaseTokenStreamTestCase {
+  public void testFactory() throws Exception {
+    final String INPUT = "Gnther Gnther is here";
+
+    // create PatternTokenizer
+    Map<String,String> args = new HashMap<String, String>();
+    args.put( PatternTokenizerFactory.PATTERN, "[,;/\\s]+" );
+    PatternTokenizerFactory tokFactory = new PatternTokenizerFactory();
+    tokFactory.init( args );
+    TokenStream stream = tokFactory.create( new StringReader(INPUT) );
+    assertTokenStreamContents(stream,
+        new String[] { "Gnther", "Gnther", "is", "here" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TestDelimitedPayloadTokenFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TestDelimitedPayloadTokenFilterFactory.java
new file mode 100644
index 0000000..9644959
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/payloads/TestDelimitedPayloadTokenFilterFactory.java
@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.payloads.DelimitedPayloadTokenFilter;
+import org.apache.lucene.analysis.payloads.FloatEncoder;
+import org.apache.lucene.analysis.payloads.PayloadHelper;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.core.SolrResourceLoader;
+
+public class TestDelimitedPayloadTokenFilterFactory extends BaseTokenStreamTestCase {
+
+  public void testEncoder() throws Exception {
+    Map<String,String> args = new HashMap<String, String>();
+    args.put(DelimitedPayloadTokenFilterFactory.ENCODER_ATTR, "float");
+    DelimitedPayloadTokenFilterFactory factory = new DelimitedPayloadTokenFilterFactory();
+    factory.init(args);
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    factory.inform(loader);
+
+    TokenStream input = new MockTokenizer(new StringReader("the|0.1 quick|0.1 red|0.1"), MockTokenizer.WHITESPACE, false);
+    DelimitedPayloadTokenFilter tf = factory.create(input);
+    tf.reset();
+    while (tf.incrementToken()){
+      PayloadAttribute payAttr = tf.getAttribute(PayloadAttribute.class);
+      assertTrue("payAttr is null and it shouldn't be", payAttr != null);
+      byte[] payData = payAttr.getPayload().bytes;
+      assertTrue("payData is null and it shouldn't be", payData != null);
+      assertTrue("payData is null and it shouldn't be", payData != null);
+      float payFloat = PayloadHelper.decodeFloat(payData);
+      assertTrue(payFloat + " does not equal: " + 0.1f, payFloat == 0.1f);
+    }
+  }
+
+  public void testDelim() throws Exception {
+    Map<String,String> args = new HashMap<String, String>();
+    args.put(DelimitedPayloadTokenFilterFactory.ENCODER_ATTR, FloatEncoder.class.getName());
+    args.put(DelimitedPayloadTokenFilterFactory.DELIMITER_ATTR, "*");
+    DelimitedPayloadTokenFilterFactory factory = new DelimitedPayloadTokenFilterFactory();
+    factory.init(args);
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    factory.inform(loader);
+
+    TokenStream input = new MockTokenizer(new StringReader("the*0.1 quick*0.1 red*0.1"), MockTokenizer.WHITESPACE, false);
+    DelimitedPayloadTokenFilter tf = factory.create(input);
+    tf.reset();
+    while (tf.incrementToken()){
+      PayloadAttribute payAttr = tf.getAttribute(PayloadAttribute.class);
+      assertTrue("payAttr is null and it shouldn't be", payAttr != null);
+      byte[] payData = payAttr.getPayload().bytes;
+      assertTrue("payData is null and it shouldn't be", payData != null);
+      float payFloat = PayloadHelper.decodeFloat(payData);
+      assertTrue(payFloat + " does not equal: " + 0.1f, payFloat == 0.1f);
+    }
+  }
+}
+
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilterFactory.java
new file mode 100644
index 0000000..aa5c009
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Portuguese Light stem factory is working.
+ */
+public class TestPortugueseLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("evidentemente");
+    PortugueseLightStemFilterFactory factory = new PortugueseLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "evident" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilterFactory.java
new file mode 100644
index 0000000..695b54c
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseMinimalStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Portuguese Minimal stem factory is working.
+ */
+public class TestPortugueseMinimalStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("questes");
+    PortugueseMinimalStemFilterFactory factory = new PortugueseMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "questo" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilterFactory.java
new file mode 100644
index 0000000..13e9719
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Portuguese stem factory is working.
+ */
+public class TestPortugueseStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("maluquice");
+    PortugueseStemFilterFactory factory = new PortugueseStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "maluc" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilterFactory.java
new file mode 100644
index 0000000..20c6d4d
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilterFactory.java
@@ -0,0 +1,47 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Reverse string filter factory is working.
+ */
+public class TestReverseStringFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually reverses text.
+   */
+  public void testReversing() throws Exception {
+    Reader reader = new StringReader("simple test");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ReverseStringFilterFactory factory = new ReverseStringFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "elpmis", "tset" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilterFactory.java
new file mode 100644
index 0000000..810ffbd
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Russian light stem factory is working.
+ */
+public class TestRussianLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("???");
+    RussianLightStemFilterFactory factory = new RussianLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "??" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/TestShingleFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/TestShingleFilterFactory.java
new file mode 100644
index 0000000..ca85836
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/shingle/TestShingleFilterFactory.java
@@ -0,0 +1,239 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Shingle filter factory works.
+ */
+public class TestShingleFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Test the defaults
+   */
+  public void testDefaults() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] {"this", "this is", "is",
+        "is a", "a", "a test", "test"});
+  }
+  
+  /**
+   * Test with unigrams disabled
+   */
+  public void testNoUnigrams() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("outputUnigrams", "false");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream,
+        new String[] {"this is", "is a", "a test"});
+  }
+  
+  /**
+   * Test with a higher max shingle size
+   */
+  public void testMaxShingleSize() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("maxShingleSize", "3");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] {"this", "this is", "this is a", "is",
+        "is a", "is a test", "a", "a test", "test"});
+  }
+
+  /**
+   * Test with higher min (and max) shingle size
+   */
+  public void testMinShingleSize() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "4");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this", "this is a", "this is a test",
+        "is", "is a test", "a", "test" });
+  }
+
+  /**
+   * Test with higher min (and max) shingle size and with unigrams disabled
+   */
+  public void testMinShingleSizeNoUnigrams() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "4");
+    args.put("outputUnigrams", "false");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this is a", "this is a test", "is a test" });
+  }
+
+  /**
+   * Test with higher same min and max shingle size
+   */
+  public void testEqualMinAndMaxShingleSize() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "3");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+         new String[] { "this", "this is a", "is", "is a test", "a", "test" });
+  }
+
+  /**
+   * Test with higher same min and max shingle size and with unigrams disabled
+   */
+  public void testEqualMinAndMaxShingleSizeNoUnigrams() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "3");
+    args.put("outputUnigrams", "false");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream,
+        new String[] { "this is a", "is a test" });
+  }
+    
+  /**
+   * Test with a non-default token separator
+   */
+  public void testTokenSeparator() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("tokenSeparator", "=BLAH=");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this", "this=BLAH=is", "is", "is=BLAH=a", 
+        "a", "a=BLAH=test", "test" });
+  }
+
+  /**
+   * Test with a non-default token separator and with unigrams disabled
+   */
+  public void testTokenSeparatorNoUnigrams() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("tokenSeparator", "=BLAH=");
+    args.put("outputUnigrams", "false");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this=BLAH=is", "is=BLAH=a", "a=BLAH=test" });
+  }
+
+  /**
+   * Test with an empty token separator
+   */
+  public void testEmptyTokenSeparator() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("tokenSeparator", "");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this", "thisis", "is", "isa", "a", "atest", "test" });
+  }
+    
+  /**
+   * Test with higher min (and max) shingle size 
+   * and with a non-default token separator
+   */
+  public void testMinShingleSizeAndTokenSeparator() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "4");
+    args.put("tokenSeparator", "=BLAH=");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this", "this=BLAH=is=BLAH=a", 
+        "this=BLAH=is=BLAH=a=BLAH=test", "is", 
+        "is=BLAH=a=BLAH=test", "a", "test" });
+  }
+
+  /**
+   * Test with higher min (and max) shingle size 
+   * and with a non-default token separator
+   * and with unigrams disabled
+   */
+  public void testMinShingleSizeAndTokenSeparatorNoUnigrams() throws Exception {
+    Reader reader = new StringReader("this is a test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("minShingleSize", "3");
+    args.put("maxShingleSize", "4");
+    args.put("tokenSeparator", "=BLAH=");
+    args.put("outputUnigrams", "false");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, 
+        new String[] { "this=BLAH=is=BLAH=a", "this=BLAH=is=BLAH=a=BLAH=test", 
+        "is=BLAH=a=BLAH=test", });
+  }
+
+  /**
+   * Test with unigrams disabled except when there are no shingles, with
+   * a single input token. Using default min/max shingle sizes: 2/2.  No
+   * shingles will be created, since there are fewer input tokens than
+   * min shingle size.  However, because outputUnigramsIfNoShingles is
+   * set to true, even though outputUnigrams is set to false, one
+   * unigram should be output.
+   */
+  public void testOutputUnigramsIfNoShingles() throws Exception {
+    Reader reader = new StringReader("test");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("outputUnigrams", "false");
+    args.put("outputUnigramsIfNoShingles", "true");
+    ShingleFilterFactory factory = new ShingleFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "test" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballPorterFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballPorterFilterFactory.java
new file mode 100644
index 0000000..c906551
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowballPorterFilterFactory.java
@@ -0,0 +1,101 @@
+package org.apache.solr.analysis;
+
+/**
+ * Copyright 2004 The Apache Software Foundation
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.solr.common.util.StrUtils;
+import org.apache.solr.core.SolrResourceLoader;
+import org.tartarus.snowball.ext.EnglishStemmer;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.ArrayList;
+
+public class SnowballPorterFilterFactoryTest extends BaseTokenStreamTestCase {
+
+  public void test() throws IOException {
+    EnglishStemmer stemmer = new EnglishStemmer();
+    String[] test = {"The", "fledgling", "banks", "were", "counting", "on", "a", "big", "boom", "in", "banking"};
+    String[] gold = new String[test.length];
+    for (int i = 0; i < test.length; i++) {
+      stemmer.setCurrent(test[i]);
+      stemmer.stem();
+      gold[i] = stemmer.getCurrent();
+    }
+
+    SnowballPorterFilterFactory factory = new SnowballPorterFilterFactory();
+    Map<String, String> args = new HashMap<String, String>();
+    args.put("language", "English");
+
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(new LinesMockSolrResourceLoader(new ArrayList<String>()));
+    Tokenizer tokenizer = new MockTokenizer(
+        new StringReader(StrUtils.join(Arrays.asList(test), ' ')), MockTokenizer.WHITESPACE, false);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, gold);
+  }
+
+  class LinesMockSolrResourceLoader implements ResourceLoader {
+    List<String> lines;
+
+    LinesMockSolrResourceLoader(List<String> lines) {
+      this.lines = lines;
+    }
+
+    public List<String> getLines(String resource) throws IOException {
+      return lines;
+    }
+
+    public <T> T newInstance(String cname, Class<T> expectedType, String... subpackages) {
+      return null;
+    }
+
+    public InputStream openResource(String resource) throws IOException {
+      return null;
+    }
+  }
+  
+  /**
+   * Test the protected words mechanism of SnowballPorterFilterFactory
+   */
+  public void testProtected() throws Exception {
+    SnowballPorterFilterFactory factory = new SnowballPorterFilterFactory();
+    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("protected", "protwords.txt");
+    args.put("language", "English");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(loader);
+    Reader reader = new StringReader("ridding of some stemming");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "ridding", "of", "some", "stem" });
+  }
+}
+
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardFactories.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardFactories.java
new file mode 100644
index 0000000..cd3dcb0
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestStandardFactories.java
@@ -0,0 +1,186 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the standard lucene factories are working.
+ */
+public class TestStandardFactories extends BaseTokenStreamTestCase {
+  /**
+   * Test StandardTokenizerFactory
+   */
+  public void testStandardTokenizer() throws Exception {
+    Reader reader = new StringReader("Wha\u0301t's this thing do?");
+    StandardTokenizerFactory factory = new StandardTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"Wha\u0301t's", "this", "thing", "do" });
+  }
+  
+  public void testStandardTokenizerMaxTokenLength() throws Exception {
+    StringBuilder builder = new StringBuilder();
+    for (int i = 0 ; i < 100 ; ++i) {
+      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
+    }
+    String longWord = builder.toString();
+    String content = "one two three " + longWord + " four five six";
+    Reader reader = new StringReader(content);
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("maxTokenLength", "1000");
+    StandardTokenizerFactory factory = new StandardTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
+  }
+  
+  /**
+   * Test ClassicTokenizerFactory
+   */
+  public void testClassicTokenizer() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"What's", "this", "thing", "do" });
+  }
+  
+  public void testClassicTokenizerMaxTokenLength() throws Exception {
+    StringBuilder builder = new StringBuilder();
+    for (int i = 0 ; i < 100 ; ++i) {
+      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
+    }
+    String longWord = builder.toString();
+    String content = "one two three " + longWord + " four five six";
+    Reader reader = new StringReader(content);
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("maxTokenLength", "1000");
+    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
+  }
+  
+  /**
+   * Test ClassicFilterFactory
+   */
+  public void testStandardFilter() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    ClassicFilterFactory filterFactory = new ClassicFilterFactory();
+    filterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    filterFactory.init(args);
+    Tokenizer tokenizer = factory.create(reader);
+    TokenStream stream = filterFactory.create(tokenizer);
+    assertTokenStreamContents(stream, 
+        new String[] {"What", "this", "thing", "do"});
+  }
+  
+  /**
+   * Test KeywordTokenizerFactory
+   */
+  public void testKeywordTokenizer() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    KeywordTokenizerFactory factory = new KeywordTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"What's this thing do?"});
+  }
+  
+  /**
+   * Test WhitespaceTokenizerFactory
+   */
+  public void testWhitespaceTokenizer() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    WhitespaceTokenizerFactory factory = new WhitespaceTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"What's", "this", "thing", "do?"});
+  }
+  
+  /**
+   * Test LetterTokenizerFactory
+   */
+  public void testLetterTokenizer() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    LetterTokenizerFactory factory = new LetterTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"What", "s", "this", "thing", "do"});
+  }
+  
+  /**
+   * Test LowerCaseTokenizerFactory
+   */
+  public void testLowerCaseTokenizer() throws Exception {
+    Reader reader = new StringReader("What's this thing do?");
+    LowerCaseTokenizerFactory factory = new LowerCaseTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"what", "s", "this", "thing", "do"});
+  }
+  
+  /**
+   * Ensure the ASCIIFoldingFilterFactory works
+   */
+  public void testASCIIFolding() throws Exception {
+    Reader reader = new StringReader("?esk");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ASCIIFoldingFilterFactory factory = new ASCIIFoldingFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "Ceska" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizerFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizerFactory.java
new file mode 100644
index 0000000..d1a1c1c
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/standard/TestUAX29URLEmailTokenizerFactory.java
@@ -0,0 +1,193 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.Version;
+
+/**
+ * A few tests based on org.apache.lucene.analysis.TestUAX29URLEmailTokenizer
+ */
+
+public class TestUAX29URLEmailTokenizerFactory extends BaseTokenStreamTestCase {
+
+  public void testUAX29URLEmailTokenizer() throws Exception {
+    Reader reader = new StringReader("Wha\u0301t's this thing do?");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"Wha\u0301t's", "this", "thing", "do" });
+  }
+  
+  public void testArabic() throws Exception {
+    Reader reader = new StringReader("????? ???? ??? ? ?????? ??? \"???? ???: ? ??????\" (?????: Truth in Numbers: The Wikipedia Story)? ?? ??? ?? 2008.");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"?????", "????", "???", "?", "??????", "???", "????", "???", "?", "??????",
+        "?????", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "??", "???", "??", "2008"  });
+  }
+  
+  public void testChinese() throws Exception {
+    Reader reader = new StringReader("??????? ???? ???? ");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"??", "??", "?", "??", "?", "????", "????"});
+  }
+
+  public void testKorean() throws Exception {
+    Reader reader = new StringReader("???????? ????????");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"????????", "????????"});
+  }
+    
+  public void testHyphen() throws Exception {
+    Reader reader = new StringReader("some-dashed-phrase");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"some", "dashed", "phrase"});
+  }
+
+  // Test with some URLs from TestUAX29URLEmailTokenizer's 
+  // urls.from.random.text.with.urls.txt
+  public void testURLs() throws Exception {
+    String textWithURLs 
+      = "http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on\n"
+        + " some extra\nWords thrown in here. "
+        + "http://c5-3486.bisynxu.FR/aI.YnNms/"
+        + " samba Halta gamba "
+        + "ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R\n"
+        + "M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb\n"
+        + "Https://yu7v33rbt.vC6U3.XN--JXALPDLP/y%4fMSzkGFlm/wbDF4m"
+        + " inter Locutio "
+        + "[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/\n"
+        + "file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7"
+        + " blah Sirrah woof "
+        + "http://[a42:a7b6::]/qSmxSUU4z/%52qVl4\n";
+    Reader reader = new StringReader(textWithURLs);
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { 
+          "http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on",
+          "some", "extra", "Words", "thrown", "in", "here",
+          "http://c5-3486.bisynxu.FR/aI.YnNms/",
+          "samba", "Halta", "gamba",
+          "ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R",
+          "M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb",
+          "Https://yu7v33rbt.vC6U3.XN--JXALPDLP/y%4fMSzkGFlm/wbDF4m",
+          "inter", "Locutio",
+          "[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/",
+          "file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7",
+          "blah", "Sirrah", "woof",
+          "http://[a42:a7b6::]/qSmxSUU4z/%52qVl4"
+        }
+    );
+  }
+
+  // Test with some emails from TestUAX29URLEmailTokenizer's 
+  // email.addresses.from.random.text.with.email.addresses.txt
+  public void testEmails() throws Exception {
+    String textWithEmails 
+      =  " some extra\nWords thrown in here. "
+         + "dJ8ngFi@avz13m.CC\n"
+         + "kU-l6DS@[082.015.228.189]\n"
+         + "\"%U\u0012@?\\B\"@Fl2d.md"
+         + " samba Halta gamba "
+         + "Bvd#@tupjv.sn\n"
+         + "SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt\n"
+         + "~+Kdz@3mousnl.SE\n"
+         + " inter Locutio "
+         + "C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY\n"
+         + "}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM"
+         + " blah Sirrah woof "
+         + "lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae\n"
+         + "lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H\n";
+    Reader reader = new StringReader(textWithEmails);
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] { 
+          "some", "extra", "Words", "thrown", "in", "here",
+          "dJ8ngFi@avz13m.CC",
+          "kU-l6DS@[082.015.228.189]",
+          "\"%U\u0012@?\\B\"@Fl2d.md",
+          "samba", "Halta", "gamba",
+          "Bvd#@tupjv.sn",
+          "SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt",
+          "~+Kdz@3mousnl.SE",
+          "inter", "Locutio",
+          "C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY",
+          "}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM",
+          "blah", "Sirrah", "woof",
+          "lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae",
+          "lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H"
+        }
+    );
+  }
+
+  public void testMaxTokenLength() throws Exception {
+    StringBuilder builder = new StringBuilder();
+    for (int i = 0 ; i < 100 ; ++i) {
+      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
+    }
+    String longWord = builder.toString();
+    String content = "one two three " + longWord + " four five six";
+    Reader reader = new StringReader(content);
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("maxTokenLength", "1000");
+    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    Tokenizer stream = factory.create(reader);
+    assertTokenStreamContents(stream, 
+        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilterFactory.java
new file mode 100644
index 0000000..b059fc1
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/sv/TestSwedishLightStemFilterFactory.java
@@ -0,0 +1,37 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Swedish Light stem factory is working.
+ */
+public class TestSwedishLightStemFilterFactory extends BaseTokenStreamTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("pplen pple");
+    SwedishLightStemFilterFactory factory = new SwedishLightStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "ppl", "ppl" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiWordFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiWordFilterFactory.java
new file mode 100644
index 0000000..006d365
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiWordFilterFactory.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.th.ThaiWordFilter;
+
+/**
+ * Simple tests to ensure the Thai word filter factory is working.
+ */
+public class TestThaiWordFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually decomposes text.
+   */
+  public void testWordBreak() throws Exception {
+    assumeTrue("JRE does not support Thai dictionary-based BreakIterator", ThaiWordFilter.DBBI_AVAILABLE);
+    Reader reader = new StringReader("??????????????????");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ThaiWordFilterFactory factory = new ThaiWordFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] {"??", "??", "???",
+        "????", "???", "??", "??", "?"});
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishLowerCaseFilterFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishLowerCaseFilterFactory.java
new file mode 100644
index 0000000..b3d9305
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/tr/TestTurkishLowerCaseFilterFactory.java
@@ -0,0 +1,42 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests to ensure the Turkish lowercase filter factory is working.
+ */
+public class TestTurkishLowerCaseFilterFactory extends BaseTokenStreamTestCase {
+  /**
+   * Ensure the filter actually lowercases text.
+   */
+  public void testCasing() throws Exception {
+    Reader reader = new StringReader("A?ACI");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    TurkishLowerCaseFilterFactory factory = new TurkishLowerCaseFilterFactory();
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "a?ac" });
+  }
+}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/wikipedia/TestWikipediaTokenizerFactory.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/wikipedia/TestWikipediaTokenizerFactory.java
new file mode 100644
index 0000000..7dda1e3
--- /dev/null
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/wikipedia/TestWikipediaTokenizerFactory.java
@@ -0,0 +1,43 @@
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Simple tests to ensure the wikipedia tokenizer is working.
+ */
+public class TestWikipediaTokenizerFactory extends BaseTokenStreamTestCase {
+  public void testTokenizer() throws IOException {
+    Reader reader = new StringReader("This is a [[Category:foo]]");
+    WikipediaTokenizerFactory factory = new WikipediaTokenizerFactory();
+    Tokenizer tokenizer = factory.create(reader);
+    assertTokenStreamContents(tokenizer,
+        new String[] { "This", "is", "a", "foo" },
+        new int[] { 0, 5, 8, 21 },
+        new int[] { 4, 7, 9, 24 },
+        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", WikipediaTokenizer.CATEGORY },
+        new int[] { 1, 1, 1, 1, });
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilterFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilterFactory.java
new file mode 100644
index 0000000..600991f
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilterFactory.java
@@ -0,0 +1,41 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseBaseFormFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseBaseFormFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseBaseFormFilterFactory extends TokenFilterFactory {
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new JapaneseBaseFormFilter(input);
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java
new file mode 100644
index 0000000..602a5f1
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilterFactory.java
@@ -0,0 +1,55 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseKatakanaStemFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link JapaneseKatakanaStemFilterFactory}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseKatakanaStemFilterFactory"
+ *             minimumLength="4"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseKatakanaStemFilterFactory extends TokenFilterFactory {
+  private static final String MINIMUM_LENGTH_PARAM = "minimumLength";
+  private int minimumLength;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    minimumLength = getInt(MINIMUM_LENGTH_PARAM, JapaneseKatakanaStemFilter.DEFAULT_MINIMUM_LENGTH);
+    if (minimumLength < 2) {
+      throw new InitializationException("Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
+    }
+  }
+
+  public TokenStream create(TokenStream input) {
+    return new JapaneseKatakanaStemFilter(input, minimumLength);
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java
new file mode 100644
index 0000000..ce91b63
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilterFactory.java
@@ -0,0 +1,63 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter;
+import org.apache.lucene.analysis.util.*;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapanesePartOfSpeechStopFilterFactory"
+ *             tags="stopTags.txt" 
+ *             enablePositionIncrements="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapanesePartOfSpeechStopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware  {
+  private boolean enablePositionIncrements;
+  private Set<String> stopTags;
+
+  public void inform(ResourceLoader loader) {
+    String stopTagFiles = args.get("tags");
+    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
+    try {
+      CharArraySet cas = getWordSet(loader, stopTagFiles, false);
+      stopTags = new HashSet<String>();
+      for (Object element : cas) {
+        char chars[] = (char[]) element;
+        stopTags.add(new String(chars));
+      }
+    } catch (IOException e) {
+      throw new InitializationException("IOException thrown while loading tags", e);
+    }
+  }
+
+  public TokenStream create(TokenStream stream) {
+    return new JapanesePartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilterFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilterFactory.java
new file mode 100644
index 0000000..ba0c541
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilterFactory.java
@@ -0,0 +1,51 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseReadingFormFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseReadingFormFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseReadingFormFilterFactory"
+ *             useRomaji="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseReadingFormFilterFactory extends TokenFilterFactory {
+  private static final String ROMAJI_PARAM = "useRomaji";
+  private boolean useRomaji;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    useRomaji = getBoolean(ROMAJI_PARAM, false);
+  }
+
+  public TokenStream create(TokenStream input) {
+    return new JapaneseReadingFormFilter(input, useRomaji);
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
new file mode 100644
index 0000000..769d304
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizerFactory.java
@@ -0,0 +1,108 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
+import java.util.Locale;
+import java.util.Map;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.analysis.ja.dict.UserDictionary;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenizerFactory;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.analysis.util.ResourceLoader;
+import org.apache.lucene.analysis.util.ResourceLoaderAware;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseTokenizer}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"
+ *       mode="NORMAL"
+ *       userDictionary="user.txt"
+ *       userDictionaryEncoding="UTF-8"
+ *       discardPunctuation="true"
+ *     /&gt;
+ *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseTokenizerFactory extends TokenizerFactory implements ResourceLoaderAware {
+  private static final String MODE = "mode";
+  
+  private static final String USER_DICT_PATH = "userDictionary";
+  
+  private static final String USER_DICT_ENCODING = "userDictionaryEncoding";
+
+  private static final String DISCARD_PUNCTUATION = "discardPunctuation"; // Expert option
+
+  private UserDictionary userDictionary;
+
+  private Mode mode;
+
+  private boolean discardPunctuation;
+
+  @Override
+  public void inform(ResourceLoader loader) {
+    mode = getMode(args);
+    String userDictionaryPath = args.get(USER_DICT_PATH);
+    try {
+      if (userDictionaryPath != null) {
+        InputStream stream = loader.openResource(userDictionaryPath);
+        String encoding = args.get(USER_DICT_ENCODING);
+        if (encoding == null) {
+          encoding = IOUtils.UTF_8;
+        }
+        CharsetDecoder decoder = Charset.forName(encoding).newDecoder()
+            .onMalformedInput(CodingErrorAction.REPORT)
+            .onUnmappableCharacter(CodingErrorAction.REPORT);
+        Reader reader = new InputStreamReader(stream, decoder);
+        userDictionary = new UserDictionary(reader);
+      } else {
+        userDictionary = null;
+      }
+    } catch (Exception e) {
+      throw new InitializationException("Exception thrown while loading dictionary", e);
+    }
+    discardPunctuation = getBoolean(DISCARD_PUNCTUATION, true);
+  }
+  
+  @Override
+  public Tokenizer create(Reader input) {
+    return new JapaneseTokenizer(input, userDictionary, discardPunctuation, mode);
+  }
+  
+  private Mode getMode(Map<String, String> args) {
+    String mode = args.get(MODE);
+    if (mode != null) {
+      return Mode.valueOf(mode.toUpperCase(Locale.ROOT));
+    } else {
+      return JapaneseTokenizer.DEFAULT_MODE;
+    }
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilterFactory.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilterFactory.java
new file mode 100644
index 0000000..6bb5c26
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilterFactory.java
@@ -0,0 +1,46 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests for {@link JapaneseBaseFormFilterFactory}
+ */
+public class TestJapaneseBaseFormFilterFactory extends BaseTokenStreamTestCase {
+  public void testBasics() throws IOException {
+    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
+    tokenizerFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    tokenizerFactory.init(args);
+    tokenizerFactory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = tokenizerFactory.create(new StringReader("???????????????????"));
+    JapaneseBaseFormFilterFactory factory = new JapaneseBaseFormFilterFactory();
+    ts = factory.create(ts);
+    assertTokenStreamContents(ts,
+        new String[] { "???", "??", "??", "??", "?", "??", "???", "??"  }
+    );
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapanesePartOfSpeechStopFilterFactory.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapanesePartOfSpeechStopFilterFactory.java
new file mode 100644
index 0000000..2338c8c
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapanesePartOfSpeechStopFilterFactory.java
@@ -0,0 +1,56 @@
+package org.apache.solr.analysis;
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.solr.core.SolrResourceLoader;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Simple tests for {@link JapanesePartOfSpeechStopFilterFactory}
+ */
+public class TestJapanesePartOfSpeechStopFilterFactory extends BaseTokenStreamTestCase {
+  public void testBasics() throws IOException {
+    String tags = 
+        "#  verb-main:\n" +
+        "???-???\n";
+    
+    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
+    tokenizerFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> tokenizerArgs = Collections.emptyMap();
+    tokenizerFactory.init(tokenizerArgs);
+    tokenizerFactory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = tokenizerFactory.create(new StringReader("????????????????"));
+    JapanesePartOfSpeechStopFilterFactory factory = new JapanesePartOfSpeechStopFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("tags", "stoptags.txt");
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    factory.init(args);
+    factory.inform(new StringMockSolrResourceLoader(tags));
+    ts = factory.create(ts);
+    assertTokenStreamContents(ts,
+        new String[] { "?", "??", "??", "????", "??" }
+    );
+  }
+}
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizerFactory.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizerFactory.java
new file mode 100644
index 0000000..ae6b40b
--- /dev/null
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizerFactory.java
@@ -0,0 +1,119 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.solr.core.SolrResourceLoader;
+
+/**
+ * Simple tests for {@link JapaneseTokenizerFactory}
+ */
+public class TestJapaneseTokenizerFactory extends BaseTokenStreamTestCase {
+  public void testSimple() throws IOException {
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    factory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = factory.create(new StringReader("???????????"));
+    assertTokenStreamContents(ts,
+        new String[] { "???", "??", "??", "??", "??", "???" },
+        new int[] { 0, 2, 3, 4, 5, 6 },
+        new int[] { 2, 3, 4, 5, 6, 8 }
+    );
+  }
+  
+  /**
+   * Test that search mode is enabled and working by default
+   */
+  public void testDefaults() throws IOException {
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    factory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = factory.create(new StringReader("???????????????????"));
+    assertTokenStreamContents(ts,
+                              new String[] { "????", "???????????????????", "???????", "??????" }
+    );
+  }
+  
+  /**
+   * Test mode parameter: specifying normal mode
+   */
+  public void testMode() throws IOException {
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("mode", "normal");
+    factory.init(args);
+    factory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = factory.create(new StringReader("???????????????????"));
+    assertTokenStreamContents(ts,
+        new String[] { "???????????????????" }
+    );
+  }
+
+  /**
+   * Test user dictionary
+   */
+  public void testUserDict() throws IOException {
+    String userDict = 
+        "# Custom segmentation for long entries\n" +
+        "??????,?? ?? ??,????? ???? ?????,????????\n" +
+        "???,? ?? ,????? ???? ?????,???????n" +
+        "# Custom reading for sumo wrestler\n" +
+        "????,????,??????????,??????\n";
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("userDictionary", "userdict.txt");
+    factory.init(args);
+    factory.inform(new StringMockSolrResourceLoader(userDict));
+    TokenStream ts = factory.create(new StringReader("????????"));
+    assertTokenStreamContents(ts,
+        new String[] { "?", "??", "", "??",  "??",  "??" }
+    );
+  }
+
+  /**
+   * Test preserving punctuation
+   */
+  public void testPreservePunctuation() throws IOException {
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("discardPunctuation", "false");
+    factory.init(args);
+    factory.inform(new SolrResourceLoader(null, null));
+    TokenStream ts = factory.create(
+        new StringReader("???????????????????????????????????????????????????????????")
+    );
+    System.out.println(ts.toString());
+    assertTokenStreamContents(ts,
+        new String[] { "?", "????????", "??", "??", "??", "??", "??",
+            "???", "??", "??", "??", "??", "??", "??", "??",
+            "???", "??", "??", "??", "??", "??", "?",
+            "??", "?", "??", "??", "???", "??", "??", "??", "??"}
+    );
+  }
+}
diff --git a/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/BeiderMorseFilterFactory.java b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/BeiderMorseFilterFactory.java
new file mode 100644
index 0000000..82caa4a
--- /dev/null
+++ b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/BeiderMorseFilterFactory.java
@@ -0,0 +1,77 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Map;
+
+import org.apache.commons.codec.language.bm.Languages.LanguageSet;
+import org.apache.commons.codec.language.bm.NameType;
+import org.apache.commons.codec.language.bm.PhoneticEngine;
+import org.apache.commons.codec.language.bm.RuleType;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.phonetic.BeiderMorseFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/** 
+ * Factory for {@link BeiderMorseFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_bm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.BeiderMorseFilterFactory"
+ *        nameType="GENERIC" ruleType="APPROX" 
+ *        concat="true" languageSet="auto"
+ *     &lt;/filter&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class BeiderMorseFilterFactory extends TokenFilterFactory {
+  private PhoneticEngine engine;
+  private LanguageSet languageSet;
+  
+  public void init(Map<String,String> args) {
+    super.init(args);
+    
+    // PhoneticEngine = NameType + RuleType + concat
+    // we use common-codec's defaults: GENERIC + APPROX + true
+    String nameTypeArg = args.get("nameType");
+    NameType nameType = (nameTypeArg == null) ? NameType.GENERIC : NameType.valueOf(nameTypeArg);
+
+    String ruleTypeArg = args.get("ruleType");
+    RuleType ruleType = (ruleTypeArg == null) ? RuleType.APPROX : RuleType.valueOf(ruleTypeArg);
+    
+    boolean concat = getBoolean("concat", true);
+    engine = new PhoneticEngine(nameType, ruleType, concat);
+    
+    // LanguageSet: defaults to automagic, otherwise a comma-separated list.
+    String languageSetArg = args.get("languageSet");
+    if (languageSetArg == null || languageSetArg.equals("auto")) {
+      languageSet = null;
+    } else {
+      languageSet = LanguageSet.from(new HashSet<String>(Arrays.asList(languageSetArg.split(","))));
+    }
+  }
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new BeiderMorseFilter(input, engine, languageSet);
+  }
+}
diff --git a/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java
new file mode 100644
index 0000000..87042b9
--- /dev/null
+++ b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/DoubleMetaphoneFilterFactory.java
@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import java.util.Map;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link DoubleMetaphoneFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_dblmtphn" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.DoubleMetaphoneFilterFactory" inject="true" maxCodeLength="4"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ *
+ */
+public class DoubleMetaphoneFilterFactory extends TokenFilterFactory
+{
+  public static final String INJECT = "inject"; 
+  public static final String MAX_CODE_LENGTH = "maxCodeLength"; 
+
+  public static final int DEFAULT_MAX_CODE_LENGTH = 4;
+
+  private boolean inject = true;
+  private int maxCodeLength = DEFAULT_MAX_CODE_LENGTH;
+
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+
+    inject = getBoolean(INJECT, true);
+
+    if (args.get(MAX_CODE_LENGTH) != null) {
+      maxCodeLength = Integer.parseInt(args.get(MAX_CODE_LENGTH));
+    }
+  }
+
+  public DoubleMetaphoneFilter create(TokenStream input) {
+    return new DoubleMetaphoneFilter(input, maxCodeLength, inject);
+  }
+}
diff --git a/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
new file mode 100644
index 0000000..4df05a4
--- /dev/null
+++ b/lucene/analysis/phonetic/src/java/org/apache/lucene/analysis/phonetic/PhoneticFilterFactory.java
@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.lang.reflect.Method;
+import java.lang.reflect.InvocationTargetException;
+import java.util.HashMap;
+import java.util.Locale;
+import java.util.Map;
+
+import org.apache.commons.codec.Encoder;
+import org.apache.commons.codec.language.*;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.phonetic.PhoneticFilter;
+import org.apache.lucene.analysis.util.InitializationException;
+import org.apache.lucene.analysis.util.TokenFilterFactory;
+
+/**
+ * Factory for {@link PhoneticFilter}.
+ * 
+ * Create tokens based on phonetic encoders from <a href="
+ * http://commons.apache.org/codec/api-release/org/apache/commons/codec/language/package-summary.html
+ * ">Apache Commons Codec</a>.
+ * <p>
+ * This takes one required argument, "encoder", and the rest are optional:
+ * <dl>
+ *  <dt>encoder<dd> required, one of "DoubleMetaphone", "Metaphone", "Soundex", "RefinedSoundex", "Caverphone" (v2.0),
+ *  or "ColognePhonetic" (case insensitive). If encoder isn't one of these, it'll be resolved as a class name either by
+ *  itself if it already contains a '.' or otherwise as in the same package as these others.
+ *  <dt>inject<dd> (default=true) add tokens to the stream with the offset=0
+ *  <dt>maxCodeLength<dd>The maximum length of the phonetic codes, as defined by the encoder. If an encoder doesn't
+ *  support this then specifying this is an error.
+ * </dl>
+ *
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_phonetic" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre>
+ * 
+ * @see PhoneticFilter
+ */
+public class PhoneticFilterFactory extends TokenFilterFactory
+{
+  public static final String ENCODER = "encoder";
+  public static final String INJECT = "inject"; // boolean
+  public static final String MAX_CODE_LENGTH = "maxCodeLength";
+  private static final String PACKAGE_CONTAINING_ENCODERS = "org.apache.commons.codec.language.";
+
+  //Effectively constants; uppercase keys
+  private static final Map<String, Class<? extends Encoder>> registry = new HashMap<String, Class<? extends Encoder>>(6);
+
+  static {
+    registry.put("DoubleMetaphone".toUpperCase(Locale.ROOT), DoubleMetaphone.class);
+    registry.put("Metaphone".toUpperCase(Locale.ROOT), Metaphone.class);
+    registry.put("Soundex".toUpperCase(Locale.ROOT), Soundex.class);
+    registry.put("RefinedSoundex".toUpperCase(Locale.ROOT), RefinedSoundex.class);
+    registry.put("Caverphone".toUpperCase(Locale.ROOT), Caverphone2.class);
+    registry.put("ColognePhonetic".toUpperCase(Locale.ROOT), ColognePhonetic.class);
+  }
+
+  protected boolean inject = true;
+  protected String name = null;
+  protected Class<? extends Encoder> clazz = null;
+  protected Method setMaxCodeLenMethod = null;
+  protected Integer maxCodeLength = null;
+
+  @Override
+  public void init(Map<String,String> args) {
+    super.init( args );
+
+    inject = getBoolean(INJECT, true);
+    
+    String name = args.get( ENCODER );
+    if( name == null ) {
+      throw new InitializationException("Missing required parameter: " + ENCODER
+          + " [" + registry.keySet() + "]");
+    }
+    clazz = registry.get(name.toUpperCase(Locale.ROOT));
+    if( clazz == null ) {
+      clazz = resolveEncoder(name);
+    }
+
+    String v = args.get(MAX_CODE_LENGTH);
+    if (v != null) {
+      maxCodeLength = Integer.valueOf(v);
+      try {
+        setMaxCodeLenMethod = clazz.getMethod("setMaxCodeLen", int.class);
+      } catch (Exception e) {
+        throw new InitializationException("Encoder " + name + " / " + clazz + " does not support " + MAX_CODE_LENGTH, e);
+      }
+    }
+
+    getEncoder();//trigger initialization for potential problems to be thrown now
+  }
+
+  private Class<? extends Encoder> resolveEncoder(String name) {
+    String lookupName = name;
+    if (name.indexOf('.') == -1) {
+      lookupName = PACKAGE_CONTAINING_ENCODERS + name;
+    }
+    try {
+      return Class.forName(lookupName).asSubclass(Encoder.class);
+    } catch (ClassNotFoundException cnfe) {
+      throw new InitializationException("Unknown encoder: " + name + " must be full class name or one of " + registry.keySet(), cnfe);
+    } catch (ClassCastException e) {
+      throw new InitializationException("Not an encoder: " + name + " must be full class name or one of " + registry.keySet(), e);
+    }
+  }
+
+  /** Must be thread-safe. */
+  protected Encoder getEncoder() {
+    // Unfortunately, Commons-Codec doesn't offer any thread-safe guarantees so we must play it safe and instantiate
+    // every time.  A simple benchmark showed this as negligible.
+    try {
+      Encoder encoder = clazz.newInstance();
+      // Try to set the maxCodeLength
+      if(maxCodeLength != null && setMaxCodeLenMethod != null) {
+        setMaxCodeLenMethod.invoke(encoder, maxCodeLength);
+      }
+      return encoder;
+    } catch (Exception e) {
+      final Throwable t = (e instanceof InvocationTargetException) ? e.getCause() : e;
+      throw new InitializationException("Error initializing encoder: " + name + " / " + clazz, t);
+    }
+  }
+
+  public PhoneticFilter create(TokenStream input) {
+    return new PhoneticFilter(input, getEncoder(), inject);
+  }
+
+}
diff --git a/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestBeiderMorseFilterFactory.java b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestBeiderMorseFilterFactory.java
new file mode 100644
index 0000000..eaff03d
--- /dev/null
+++ b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestBeiderMorseFilterFactory.java
@@ -0,0 +1,70 @@
+package org.apache.solr.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.StringReader;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/** Simple tests for {@link BeiderMorseFilterFactory} */
+public class TestBeiderMorseFilterFactory extends BaseTokenStreamTestCase {
+  public void testBasics() throws Exception {
+    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
+    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
+    Map<String, String> args = Collections.emptyMap();
+    factory.init(args);
+    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(ts,
+        new String[] { "vDnbirk", "vanbirk", "vinbirk", "wDnbirk", "wanbirk", "winbirk" },
+        new int[] { 0, 0, 0, 0, 0, 0 },
+        new int[] { 8, 8, 8, 8, 8, 8 },
+        new int[] { 1, 0, 0, 0, 0, 0 });
+  }
+  
+  public void testLanguageSet() throws Exception {
+    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("languageSet", "polish");
+    factory.init(args);
+    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(ts,
+        new String[] { "vDmbYrk", "vDmbirk", "vambYrk", "vambirk", "vimbYrk", "vimbirk" },
+        new int[] { 0, 0, 0, 0, 0, 0 },
+        new int[] { 8, 8, 8, 8, 8, 8 },
+        new int[] { 1, 0, 0, 0, 0, 0 });
+  }
+  
+  public void testOptions() throws Exception {
+    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("nameType", "ASHKENAZI");
+    args.put("ruleType", "EXACT");
+    factory.init(args);
+    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(ts,
+        new String[] { "vajnberk" },
+        new int[] { 0 },
+        new int[] { 8 },
+        new int[] { 1 });
+  }
+}
diff --git a/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestDoubleMetaphoneFilterFactory.java b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestDoubleMetaphoneFilterFactory.java
new file mode 100644
index 0000000..7b08dbb
--- /dev/null
+++ b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestDoubleMetaphoneFilterFactory.java
@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+
+public class DoubleMetaphoneFilterFactoryTest extends BaseTokenStreamTestCase {
+
+  public void testDefaults() throws Exception {
+    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
+    factory.init(new HashMap<String, String>());
+    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
+
+    TokenStream filteredStream = factory.create(inputStream);
+    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
+    assertTokenStreamContents(filteredStream, new String[] { "international", "ANTR" });
+  }
+
+  public void testSettingSizeAndInject() throws Exception {
+    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
+    Map<String, String> parameters = new HashMap<String, String>();
+    parameters.put("inject", "false");
+    parameters.put("maxCodeLength", "8");
+    factory.init(parameters);
+
+    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
+
+    TokenStream filteredStream = factory.create(inputStream);
+    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
+    assertTokenStreamContents(filteredStream, new String[] { "ANTRNXNL" });
+  }
+  
+  /**
+   * Ensure that reset() removes any state (buffered tokens)
+   */
+  public void testReset() throws Exception {
+    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
+    factory.init(new HashMap<String, String>());
+    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
+
+    TokenStream filteredStream = factory.create(inputStream);
+    CharTermAttribute termAtt = filteredStream.addAttribute(CharTermAttribute.class);
+    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
+    
+    filteredStream.reset();
+    assertTrue(filteredStream.incrementToken());
+    assertEquals(13, termAtt.length());
+    assertEquals("international", termAtt.toString());
+    filteredStream.reset();
+    
+    // ensure there are no more tokens, such as ANTRNXNL
+    assertFalse(filteredStream.incrementToken());
+  }
+}
diff --git a/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestPhoneticFilterFactory.java b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestPhoneticFilterFactory.java
new file mode 100644
index 0000000..dc7809d
--- /dev/null
+++ b/lucene/analysis/phonetic/src/test/org/apache/lucene/analysis/phonetic/TestPhoneticFilterFactory.java
@@ -0,0 +1,185 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import java.io.StringReader;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.commons.codec.language.Metaphone;
+import org.apache.commons.codec.language.Caverphone2;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.util.LuceneTestCase.Slow;
+
+
+/**
+ *
+ */
+@Slow
+public class TestPhoneticFilterFactory extends BaseTokenStreamTestCase {
+  
+  private static final int REPEATS = 100000;
+
+  /**
+   * Case: default
+   */
+  public void testFactory()
+  {
+    Map<String,String> args = new HashMap<String, String>();
+    
+    PhoneticFilterFactory ff = new PhoneticFilterFactory();
+    
+    args.put( PhoneticFilterFactory.ENCODER, "Metaphone" );
+    ff.init( args );
+    assertTrue( ff.getEncoder() instanceof Metaphone );
+    assertTrue( ff.inject ); // default
+
+    args.put( PhoneticFilterFactory.INJECT, "false" );
+    ff.init( args );
+    assertFalse( ff.inject );
+
+    args.put( PhoneticFilterFactory.MAX_CODE_LENGTH, "2");
+    ff.init( args );
+    assertEquals(2,((Metaphone) ff.getEncoder()).getMaxCodeLen());
+  }
+  
+  /**
+   * Case: Failures and Exceptions
+   */
+  public void testFactoryCaseFailure()
+  {
+    Map<String,String> args = new HashMap<String, String>();
+    
+    PhoneticFilterFactory ff = new PhoneticFilterFactory();
+    try {
+      ff.init( args );
+      fail( "missing encoder parameter" );
+    }
+    catch( Exception ex ) {}
+    args.put( PhoneticFilterFactory.ENCODER, "XXX" );
+    try {
+      ff.init( args );
+      fail( "unknown encoder parameter" );
+    }
+    catch( Exception ex ) {}
+    args.put( PhoneticFilterFactory.ENCODER, "org.apache.commons.codec.language.NonExistence" );
+    try {
+      ff.init( args );
+      fail( "unknown encoder parameter" );
+    }
+    catch( Exception ex ) {}
+  }
+  
+  /**
+   * Case: Reflection
+   */
+  public void testFactoryCaseReflection()
+  {
+    Map<String,String> args = new HashMap<String, String>();
+    
+    PhoneticFilterFactory ff = new PhoneticFilterFactory();
+
+    args.put( PhoneticFilterFactory.ENCODER, "org.apache.commons.codec.language.Metaphone" );
+    ff.init( args );
+    assertTrue( ff.getEncoder() instanceof Metaphone );
+    assertTrue( ff.inject ); // default
+
+    // we use "Caverphone2" as it is registered in the REGISTRY as Caverphone,
+    // so this effectively tests reflection without package name
+    args.put( PhoneticFilterFactory.ENCODER, "Caverphone2" );
+    ff.init( args );
+    assertTrue( ff.getEncoder() instanceof Caverphone2 );
+    assertTrue( ff.inject ); // default
+    
+    // cross check with registry
+    args.put( PhoneticFilterFactory.ENCODER, "Caverphone" );
+    ff.init( args );
+    assertTrue( ff.getEncoder() instanceof Caverphone2 );
+    assertTrue( ff.inject ); // default
+  }
+  
+  public void testAlgorithms() throws Exception {
+    assertAlgorithm("Metaphone", "true", "aaa bbb ccc easgasg",
+        new String[] { "A", "aaa", "B", "bbb", "KKK", "ccc", "ESKS", "easgasg" });
+    assertAlgorithm("Metaphone", "false", "aaa bbb ccc easgasg",
+        new String[] { "A", "B", "KKK", "ESKS" });
+    
+    assertAlgorithm("DoubleMetaphone", "true", "aaa bbb ccc easgasg",
+        new String[] { "A", "aaa", "PP", "bbb", "KK", "ccc", "ASKS", "easgasg" });
+    assertAlgorithm("DoubleMetaphone", "false", "aaa bbb ccc easgasg",
+        new String[] { "A", "PP", "KK", "ASKS" });
+    
+    assertAlgorithm("Soundex", "true", "aaa bbb ccc easgasg",
+        new String[] { "A000", "aaa", "B000", "bbb", "C000", "ccc", "E220", "easgasg" });
+    assertAlgorithm("Soundex", "false", "aaa bbb ccc easgasg",
+        new String[] { "A000", "B000", "C000", "E220" });
+    
+    assertAlgorithm("RefinedSoundex", "true", "aaa bbb ccc easgasg",
+        new String[] { "A0", "aaa", "B1", "bbb", "C3", "ccc", "E034034", "easgasg" });
+    assertAlgorithm("RefinedSoundex", "false", "aaa bbb ccc easgasg",
+        new String[] { "A0", "B1", "C3", "E034034" });
+    
+    assertAlgorithm("Caverphone", "true", "Darda Karleen Datha Carlene",
+        new String[] { "TTA1111111", "Darda", "KLN1111111", "Karleen", 
+          "TTA1111111", "Datha", "KLN1111111", "Carlene" });
+    assertAlgorithm("Caverphone", "false", "Darda Karleen Datha Carlene",
+        new String[] { "TTA1111111", "KLN1111111", "TTA1111111", "KLN1111111" });
+    
+    assertAlgorithm("ColognePhonetic", "true", "Meier Schmitt Meir Schmidt",
+        new String[] { "67", "Meier", "862", "Schmitt", 
+          "67", "Meir", "862", "Schmidt" });
+    assertAlgorithm("ColognePhonetic", "false", "Meier Schmitt Meir Schmidt",
+        new String[] { "67", "862", "67", "862" });
+  }
+  
+  static void assertAlgorithm(String algName, String inject, String input,
+      String[] expected) throws Exception {
+    Tokenizer tokenizer = new MockTokenizer(new StringReader(input), MockTokenizer.WHITESPACE, false);
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("encoder", algName);
+    args.put("inject", inject);
+    PhoneticFilterFactory factory = new PhoneticFilterFactory();
+    factory.init(args);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, expected);
+  }
+  
+  public void testSpeed() throws Exception {
+	  checkSpeedEncoding("Metaphone", "easgasg", "ESKS");
+	  checkSpeedEncoding("DoubleMetaphone", "easgasg", "ASKS");
+	  checkSpeedEncoding("Soundex", "easgasg", "E220");
+	  checkSpeedEncoding("RefinedSoundex", "easgasg", "E034034");
+	  checkSpeedEncoding("Caverphone", "Carlene", "KLN1111111");
+	  checkSpeedEncoding("ColognePhonetic", "Schmitt", "862");
+  }
+  
+  private void checkSpeedEncoding(String encoder, String toBeEncoded, String estimated) throws Exception {
+	  long start = System.currentTimeMillis();
+	  for ( int i=0; i<REPEATS; i++) {
+		    assertAlgorithm(encoder, "false", toBeEncoded,
+		            new String[] { estimated });
+	  }
+	  long duration = System.currentTimeMillis()-start;
+	  if (VERBOSE)
+	    System.out.println(encoder + " encodings per msec: "+(REPEATS/duration));
+  }
+  
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ASCIIFoldingFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ASCIIFoldingFilterFactory.java
deleted file mode 100644
index da507d9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ASCIIFoldingFilterFactory.java
+++ /dev/null
@@ -1,49 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-import org.apache.lucene.analysis.miscellaneous.ASCIIFoldingFilter;
-import org.apache.lucene.analysis.TokenStream;
-
-/** 
- * Factory for {@link ASCIIFoldingFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ascii" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ASCIIFoldingFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ASCIIFoldingFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  public ASCIIFoldingFilter create(TokenStream input) {
-    return new ASCIIFoldingFilter(input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/ArabicNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ArabicNormalizationFilterFactory.java
deleted file mode 100644
index 97fc662..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ArabicNormalizationFilterFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-
-/**
- * Factory for {@link ArabicNormalizationFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_arnormal" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ArabicNormalizationFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ArabicNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-
-  public ArabicNormalizationFilter create(TokenStream input) {
-    return new ArabicNormalizationFilter(input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ArabicStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ArabicStemFilterFactory.java
deleted file mode 100644
index 0baa6b5..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ArabicStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ar.ArabicStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-
-/**
- * Factory for {@link ArabicStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_arstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ArabicNormalizationFilterFactory"/&gt;
- *     &lt;filter class="solr.ArabicStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ArabicStemFilterFactory extends TokenFilterFactory {
-
-
-  public ArabicStemFilter create(TokenStream input) {
-    return new ArabicStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/BeiderMorseFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/BeiderMorseFilterFactory.java
deleted file mode 100644
index 82caa4a..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/BeiderMorseFilterFactory.java
+++ /dev/null
@@ -1,77 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.Map;
-
-import org.apache.commons.codec.language.bm.Languages.LanguageSet;
-import org.apache.commons.codec.language.bm.NameType;
-import org.apache.commons.codec.language.bm.PhoneticEngine;
-import org.apache.commons.codec.language.bm.RuleType;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.phonetic.BeiderMorseFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link BeiderMorseFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_bm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.BeiderMorseFilterFactory"
- *        nameType="GENERIC" ruleType="APPROX" 
- *        concat="true" languageSet="auto"
- *     &lt;/filter&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class BeiderMorseFilterFactory extends TokenFilterFactory {
-  private PhoneticEngine engine;
-  private LanguageSet languageSet;
-  
-  public void init(Map<String,String> args) {
-    super.init(args);
-    
-    // PhoneticEngine = NameType + RuleType + concat
-    // we use common-codec's defaults: GENERIC + APPROX + true
-    String nameTypeArg = args.get("nameType");
-    NameType nameType = (nameTypeArg == null) ? NameType.GENERIC : NameType.valueOf(nameTypeArg);
-
-    String ruleTypeArg = args.get("ruleType");
-    RuleType ruleType = (ruleTypeArg == null) ? RuleType.APPROX : RuleType.valueOf(ruleTypeArg);
-    
-    boolean concat = getBoolean("concat", true);
-    engine = new PhoneticEngine(nameType, ruleType, concat);
-    
-    // LanguageSet: defaults to automagic, otherwise a comma-separated list.
-    String languageSetArg = args.get("languageSet");
-    if (languageSetArg == null || languageSetArg.equals("auto")) {
-      languageSet = null;
-    } else {
-      languageSet = LanguageSet.from(new HashSet<String>(Arrays.asList(languageSetArg.split(","))));
-    }
-  }
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new BeiderMorseFilter(input, engine, languageSet);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/BrazilianStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/BrazilianStemFilterFactory.java
deleted file mode 100644
index 8928d64..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/BrazilianStemFilterFactory.java
+++ /dev/null
@@ -1,43 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.br.BrazilianStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link BrazilianStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_brstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.BrazilianStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class BrazilianStemFilterFactory extends TokenFilterFactory {
-  public BrazilianStemFilter create(TokenStream in) {
-    return new BrazilianStemFilter(in);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/BulgarianStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/BulgarianStemFilterFactory.java
deleted file mode 100644
index 5c91995..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/BulgarianStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.bg.BulgarianStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link BulgarianStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_bgstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.BulgarianStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class BulgarianStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new BulgarianStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/CJKBigramFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CJKBigramFilterFactory.java
deleted file mode 100644
index bea0bff..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CJKBigramFilterFactory.java
+++ /dev/null
@@ -1,65 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.cjk.CJKBigramFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link CJKBigramFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_cjk" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.CJKWidthFilterFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.CJKBigramFilterFactory" 
- *       han="true" hiragana="true" 
- *       katakana="true" hangul="true" /&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class CJKBigramFilterFactory extends TokenFilterFactory {
-  int flags;
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    flags = 0;
-    if (getBoolean("han", true)) {
-      flags |= CJKBigramFilter.HAN;
-    }
-    if (getBoolean("hiragana", true)) {
-      flags |= CJKBigramFilter.HIRAGANA;
-    }
-    if (getBoolean("katakana", true)) {
-      flags |= CJKBigramFilter.KATAKANA;
-    }
-    if (getBoolean("hangul", true)) {
-      flags |= CJKBigramFilter.HANGUL;
-    }
-  }
-  
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new CJKBigramFilter(input, flags);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/CJKWidthFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CJKWidthFilterFactory.java
deleted file mode 100644
index 3213b3c..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CJKWidthFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.cjk.CJKWidthFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link CJKWidthFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_cjk" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.CJKWidthFilterFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.CJKBigramFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-
-public class CJKWidthFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new CJKWidthFilter(input);
-  }
-  
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/CapitalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CapitalizationFilterFactory.java
deleted file mode 100644
index e26bac2..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CapitalizationFilterFactory.java
+++ /dev/null
@@ -1,140 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.CapitalizationFilter;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Map;
-import java.util.StringTokenizer;
-
-/**
- * Factory for {@link CapitalizationFilter}.
- * <p/>
- * The factory takes parameters:<br/>
- * "onlyFirstWord" - should each word be capitalized or all of the words?<br/>
- * "keep" - a keep word list.  Each word that should be kept separated by whitespace.<br/>
- * "keepIgnoreCase - true or false.  If true, the keep list will be considered case-insensitive.<br/>
- * "forceFirstLetter" - Force the first letter to be capitalized even if it is in the keep list<br/>
- * "okPrefix" - do not change word capitalization if a word begins with something in this list.
- * for example if "McK" is on the okPrefix list, the word "McKinley" should not be changed to
- * "Mckinley"<br/>
- * "minWordLength" - how long the word needs to be to get capitalization applied.  If the
- * minWordLength is 3, "and" > "And" but "or" stays "or"<br/>
- * "maxWordCount" - if the token contains more then maxWordCount words, the capitalization is
- * assumed to be correct.<br/>
- *
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_cptlztn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.CapitalizationFilterFactory" onlyFirstWord="true"
- *     	     keep="java solr lucene" keepIgnoreCase="false"
- *     	     okPrefix="McK McD McA"/&gt;   
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- * @since solr 1.3
- */
-public class CapitalizationFilterFactory extends TokenFilterFactory {
-  public static final String KEEP = "keep";
-  public static final String KEEP_IGNORE_CASE = "keepIgnoreCase";
-  public static final String OK_PREFIX = "okPrefix";
-  public static final String MIN_WORD_LENGTH = "minWordLength";
-  public static final String MAX_WORD_COUNT = "maxWordCount";
-  public static final String MAX_TOKEN_LENGTH = "maxTokenLength";
-  public static final String ONLY_FIRST_WORD = "onlyFirstWord";
-  public static final String FORCE_FIRST_LETTER = "forceFirstLetter";
-
-  //Map<String,String> keep = new HashMap<String, String>(); // not synchronized because it is only initialized once
-  CharArraySet keep;
-
-  Collection<char[]> okPrefix = Collections.emptyList(); // for Example: McK
-
-  int minWordLength = 0;  // don't modify capitalization for words shorter then this
-  int maxWordCount = CapitalizationFilter.DEFAULT_MAX_WORD_COUNT;
-  int maxTokenLength = CapitalizationFilter.DEFAULT_MAX_TOKEN_LENGTH;
-  boolean onlyFirstWord = true;
-  boolean forceFirstLetter = true; // make sure the first letter is capitol even if it is in the keep list
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    assureMatchVersion();
-
-    String k = args.get(KEEP);
-    if (k != null) {
-      StringTokenizer st = new StringTokenizer(k);
-      boolean ignoreCase = false;
-      String ignoreStr = args.get(KEEP_IGNORE_CASE);
-      if ("true".equalsIgnoreCase(ignoreStr)) {
-        ignoreCase = true;
-      }
-      keep = new CharArraySet(luceneMatchVersion, 10, ignoreCase);
-      while (st.hasMoreTokens()) {
-        k = st.nextToken().trim();
-        keep.add(k.toCharArray());
-      }
-    }
-
-    k = args.get(OK_PREFIX);
-    if (k != null) {
-      okPrefix = new ArrayList<char[]>();
-      StringTokenizer st = new StringTokenizer(k);
-      while (st.hasMoreTokens()) {
-        okPrefix.add(st.nextToken().trim().toCharArray());
-      }
-    }
-
-    k = args.get(MIN_WORD_LENGTH);
-    if (k != null) {
-      minWordLength = Integer.valueOf(k);
-    }
-
-    k = args.get(MAX_WORD_COUNT);
-    if (k != null) {
-      maxWordCount = Integer.valueOf(k);
-    }
-
-    k = args.get(MAX_TOKEN_LENGTH);
-    if (k != null) {
-      maxTokenLength = Integer.valueOf(k);
-    }
-
-    k = args.get(ONLY_FIRST_WORD);
-    if (k != null) {
-      onlyFirstWord = Boolean.valueOf(k);
-    }
-
-    k = args.get(FORCE_FIRST_LETTER);
-    if (k != null) {
-      forceFirstLetter = Boolean.valueOf(k);
-    }
-  }
-
-  public CapitalizationFilter create(TokenStream input) {
-    return new CapitalizationFilter(input, onlyFirstWord, keep, 
-      forceFirstLetter, okPrefix, minWordLength, maxWordCount, maxTokenLength);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ClassicFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ClassicFilterFactory.java
deleted file mode 100644
index 12ae66f..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ClassicFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-import org.apache.lucene.analysis.standard.ClassicFilter;
-
-/**
- * Factory for {@link ClassicFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_clssc" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.ClassicTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ClassicFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- */
-public class ClassicFilterFactory extends TokenFilterFactory {
-  public TokenFilter create(TokenStream input) {
-    return new ClassicFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ClassicTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/ClassicTokenizerFactory.java
deleted file mode 100644
index 4efe6e7..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ClassicTokenizerFactory.java
+++ /dev/null
@@ -1,57 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.standard.ClassicTokenizer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link ClassicTokenizer}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_clssc" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.ClassicTokenizerFactory" maxTokenLength="120"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- */
-
-public class ClassicTokenizerFactory extends TokenizerFactory {
-
-  private int maxTokenLength;
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-    maxTokenLength = getInt("maxTokenLength", 
-                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
-  }
-
-  public Tokenizer create(Reader input) {
-    ClassicTokenizer tokenizer = new ClassicTokenizer(luceneMatchVersion, input); 
-    tokenizer.setMaxTokenLength(maxTokenLength);
-    return tokenizer;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java
deleted file mode 100644
index f32df81..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CommonGramsFilterFactory.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.util.*;
-
-/**
- * Constructs a {@link CommonGramsFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_cmmngrms" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.CommonGramsFilterFactory" words="commongramsstopwords.txt" ignoreCase="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-
-/*
- * This is pretty close to a straight copy from StopFilterFactory
- */
-public class CommonGramsFilterFactory extends TokenFilterFactory implements
-    ResourceLoaderAware {
-
-  public void inform(ResourceLoader loader) {
-    String commonWordFiles = args.get("words");
-    ignoreCase = getBoolean("ignoreCase", false);
-
-    if (commonWordFiles != null) {
-      try {
-        if ("snowball".equalsIgnoreCase(args.get("format"))) {
-          commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
-        } else {
-          commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
-        }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading common word file", e);
-      }
-    } else {
-      commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
-    }
-  }
-      
-    //Force the use of a char array set, as it is the most performant, although this may break things if Lucene ever goes away from it.  See SOLR-1095
-    private CharArraySet commonWords;
-    private boolean ignoreCase;
-
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public CharArraySet getCommonWords() {
-    return commonWords;
-  }
-
-  public CommonGramsFilter create(TokenStream input) {
-    CommonGramsFilter commonGrams = new CommonGramsFilter(luceneMatchVersion, input, commonWords);
-    return commonGrams;
-  }
-}
- 
-  
-  
\ No newline at end of file
diff --git a/solr/core/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java
deleted file mode 100644
index 38e407f..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CommonGramsQueryFilterFactory.java
+++ /dev/null
@@ -1,93 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.commongrams.CommonGramsFilter;
-import org.apache.lucene.analysis.commongrams.CommonGramsQueryFilter;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.util.*;
-
-/**
- * Construct {@link CommonGramsQueryFilter}.
- * 
- * This is pretty close to a straight copy from {@link StopFilterFactory}.
- * 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_cmmngrmsqry" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.CommonGramsQueryFilterFactory" words="commongramsquerystopwords.txt" ignoreCase="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class CommonGramsQueryFilterFactory extends TokenFilterFactory
-    implements ResourceLoaderAware {
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public void inform(ResourceLoader loader) {
-    String commonWordFiles = args.get("words");
-    ignoreCase = getBoolean("ignoreCase", false);
-
-    if (commonWordFiles != null) {
-      try {
-        if ("snowball".equalsIgnoreCase(args.get("format"))) {
-          commonWords = getSnowballWordSet(loader, commonWordFiles, ignoreCase);
-        } else {
-          commonWords = getWordSet(loader, commonWordFiles, ignoreCase);
-        }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading common word file", e);
-      }
-    } else {
-      commonWords = StopAnalyzer.ENGLISH_STOP_WORDS_SET;
-    }
-  }
-
-  // Force the use of a char array set, as it is the most performant, although
-  // this may break things if Lucene ever goes away from it. See SOLR-1095
-  private CharArraySet commonWords;
-
-  private boolean ignoreCase;
-
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public CharArraySet getCommonWords() {
-    return commonWords;
-  }
-
-  /**
-   * Create a CommonGramsFilter and wrap it with a CommonGramsQueryFilter
-   */
-  public CommonGramsQueryFilter create(TokenStream input) {
-    CommonGramsFilter commonGrams = new CommonGramsFilter(luceneMatchVersion, input, commonWords);
-    CommonGramsQueryFilter commonGramsQuery = new CommonGramsQueryFilter(
-        commonGrams);
-    return commonGramsQuery;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/CzechStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/CzechStemFilterFactory.java
deleted file mode 100644
index fd35534..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/CzechStemFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.cz.CzechStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- *  Factory for {@link CzechStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_czstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.CzechStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class CzechStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new CzechStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/DelimitedPayloadTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/DelimitedPayloadTokenFilterFactory.java
deleted file mode 100644
index 007b83d..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/DelimitedPayloadTokenFilterFactory.java
+++ /dev/null
@@ -1,83 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.payloads.DelimitedPayloadTokenFilter;
-import org.apache.lucene.analysis.payloads.PayloadEncoder;
-import org.apache.lucene.analysis.payloads.FloatEncoder;
-import org.apache.lucene.analysis.payloads.IntegerEncoder;
-import org.apache.lucene.analysis.payloads.IdentityEncoder;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoaderAware;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-
-/**
- *
- * Factory for {@link DelimitedPayloadTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_dlmtd" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.DelimitedPayloadTokenFilterFactory" encoder="float" delimiter="|"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- * 
- */
-public class DelimitedPayloadTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String ENCODER_ATTR = "encoder";
-  public static final String DELIMITER_ATTR = "delimiter";
-
-  private PayloadEncoder encoder;
-  private char delimiter = '|';
-
-  public DelimitedPayloadTokenFilter create(TokenStream input) {
-    return new DelimitedPayloadTokenFilter(input, delimiter, encoder);
-  }
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-  }
-
-  public void inform(ResourceLoader loader) {
-    String encoderClass = args.get(ENCODER_ATTR);
-    if (encoderClass.equals("float")){
-      encoder = new FloatEncoder();
-    } else if (encoderClass.equals("integer")){
-      encoder = new IntegerEncoder();
-    } else if (encoderClass.equals("identity")){
-      encoder = new IdentityEncoder();
-    } else {
-      encoder = loader.newInstance(encoderClass, PayloadEncoder.class);
-    }
-
-    String delim = args.get(DELIMITER_ATTR);
-    if (delim != null){
-      if (delim.length() == 1) {
-        delimiter = delim.charAt(0);
-      } else{
-        throw new InitializationException("Delimiter must be one character only");
-      }
-    }
-  }
-}
\ No newline at end of file
diff --git a/solr/core/src/java/org/apache/solr/analysis/DictionaryCompoundWordTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/DictionaryCompoundWordTokenFilterFactory.java
deleted file mode 100644
index 4664dc3..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/DictionaryCompoundWordTokenFilterFactory.java
+++ /dev/null
@@ -1,72 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-import org.apache.lucene.analysis.compound.*;
-import org.apache.lucene.analysis.util.*;
-import org.apache.lucene.analysis.TokenStream;
-
-import java.util.Map;
-import java.io.IOException;
-
-/** 
- * Factory for {@link DictionaryCompoundWordTokenFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_dictcomp" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.DictionaryCompoundWordTokenFilterFactory" dictionary="dictionary.txt"
- *     	     minWordSize="5" minSubwordSize="2" maxSubwordSize="15" onlyLongestMatch="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class DictionaryCompoundWordTokenFilterFactory extends TokenFilterFactory  implements ResourceLoaderAware {
-  private CharArraySet dictionary;
-  private String dictFile;
-  private int minWordSize;
-  private int minSubwordSize;
-  private int maxSubwordSize;
-  private boolean onlyLongestMatch;
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    assureMatchVersion();
-    dictFile = args.get("dictionary");
-    if (null == dictFile) {
-      throw new InitializationException("Missing required parameter: dictionary");
-    }
-
-    minWordSize= getInt("minWordSize",CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
-    minSubwordSize= getInt("minSubwordSize",CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE);
-    maxSubwordSize= getInt("maxSubwordSize",CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
-    onlyLongestMatch = getBoolean("onlyLongestMatch",true);
-  }
-  public void inform(ResourceLoader loader) {
-    try {
-      dictionary = super.getWordSet(loader, dictFile, false);
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while loading dictionary", e);
-    }
-  }
-  public DictionaryCompoundWordTokenFilter create(TokenStream input) {
-    return new DictionaryCompoundWordTokenFilter(luceneMatchVersion,input,dictionary,minWordSize,minSubwordSize,maxSubwordSize,onlyLongestMatch);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/DoubleMetaphoneFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/DoubleMetaphoneFilterFactory.java
deleted file mode 100644
index 87042b9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/DoubleMetaphoneFilterFactory.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link DoubleMetaphoneFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_dblmtphn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.DoubleMetaphoneFilterFactory" inject="true" maxCodeLength="4"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class DoubleMetaphoneFilterFactory extends TokenFilterFactory
-{
-  public static final String INJECT = "inject"; 
-  public static final String MAX_CODE_LENGTH = "maxCodeLength"; 
-
-  public static final int DEFAULT_MAX_CODE_LENGTH = 4;
-
-  private boolean inject = true;
-  private int maxCodeLength = DEFAULT_MAX_CODE_LENGTH;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-
-    inject = getBoolean(INJECT, true);
-
-    if (args.get(MAX_CODE_LENGTH) != null) {
-      maxCodeLength = Integer.parseInt(args.get(MAX_CODE_LENGTH));
-    }
-  }
-
-  public DoubleMetaphoneFilter create(TokenStream input) {
-    return new DoubleMetaphoneFilter(input, maxCodeLength, inject);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java
deleted file mode 100644
index 5ac1886..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/EdgeNGramFilterFactory.java
+++ /dev/null
@@ -1,63 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.EdgeNGramTokenFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Creates new instances of {@link EdgeNGramTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_edgngrm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.EdgeNGramFilterFactory" side="front" minGramSize="1" maxGramSize="1"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class EdgeNGramFilterFactory extends TokenFilterFactory {
-  private int maxGramSize = 0;
-
-  private int minGramSize = 0;
-
-  private String side;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    String maxArg = args.get("maxGramSize");
-    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
-        : EdgeNGramTokenFilter.DEFAULT_MAX_GRAM_SIZE);
-
-    String minArg = args.get("minGramSize");
-    minGramSize = (minArg != null ? Integer.parseInt(minArg)
-        : EdgeNGramTokenFilter.DEFAULT_MIN_GRAM_SIZE);
-
-    side = args.get("side");
-    if (side == null) {
-      side = EdgeNGramTokenFilter.Side.FRONT.getLabel();
-    }
-  }
-
-  public EdgeNGramTokenFilter create(TokenStream input) {
-    return new EdgeNGramTokenFilter(input, side, minGramSize, maxGramSize);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/EdgeNGramTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/EdgeNGramTokenizerFactory.java
deleted file mode 100755
index 83f39de..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/EdgeNGramTokenizerFactory.java
+++ /dev/null
@@ -1,61 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.ngram.EdgeNGramTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Creates new instances of {@link EdgeNGramTokenizer}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_edgngrm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.EdgeNGramTokenizerFactory" side="front" minGramSize="1" maxGramSize="1"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class EdgeNGramTokenizerFactory extends TokenizerFactory {
-    private int maxGramSize = 0;
-
-    private int minGramSize = 0;
-
-    private String side;
-
-    @Override
-    public void init(Map<String, String> args) {
-        super.init(args);
-        String maxArg = args.get("maxGramSize");
-        maxGramSize = (maxArg != null ? Integer.parseInt(maxArg) : EdgeNGramTokenizer.DEFAULT_MAX_GRAM_SIZE);
-
-        String minArg = args.get("minGramSize");
-        minGramSize = (minArg != null ? Integer.parseInt(minArg) : EdgeNGramTokenizer.DEFAULT_MIN_GRAM_SIZE);
-
-        side = args.get("side");
-        if (side == null) {
-            side = EdgeNGramTokenizer.Side.FRONT.getLabel();
-        }
-    }
-
-    public EdgeNGramTokenizer create(Reader input) {
-        return new EdgeNGramTokenizer(input, side, minGramSize, maxGramSize);
-    }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java
deleted file mode 100644
index c522ed4..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java
+++ /dev/null
@@ -1,64 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.util.*;
-import org.apache.lucene.analysis.fr.*;
-
-import java.io.IOException;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Factory for {@link ElisionFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_elsn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ElisionFilterFactory" 
- *       articles="stopwordarticles.txt" ignoreCase="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ElisionFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-
-  private CharArraySet articles;
-
-  public void inform(ResourceLoader loader) {
-    String articlesFile = args.get("articles");
-    boolean ignoreCase = getBoolean("ignoreCase", false);
-
-    if (articlesFile != null) {
-      try {
-        articles = getWordSet(loader, articlesFile, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading articles", e);
-      }
-    }
-  }
-
-  public ElisionFilter create(TokenStream input) {
-    assureMatchVersion();
-    return articles == null ? new ElisionFilter(luceneMatchVersion,input) : 
-        new ElisionFilter(luceneMatchVersion,input,articles);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/EnglishMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/EnglishMinimalStemFilterFactory.java
deleted file mode 100644
index ed31a86..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/EnglishMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.en.EnglishMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link EnglishMinimalStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_enminstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.EnglishMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class EnglishMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new EnglishMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/EnglishPossessiveFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/EnglishPossessiveFilterFactory.java
deleted file mode 100644
index 36d153d..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/EnglishPossessiveFilterFactory.java
+++ /dev/null
@@ -1,49 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.en.EnglishPossessiveFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link EnglishPossessiveFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_enpossessive" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.EnglishPossessiveFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class EnglishPossessiveFilterFactory extends TokenFilterFactory {
-  
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-  
-  public TokenStream create(TokenStream input) {
-    return new EnglishPossessiveFilter(luceneMatchVersion, input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/FinnishLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/FinnishLightStemFilterFactory.java
deleted file mode 100644
index 0e70606..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/FinnishLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.fi.FinnishLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link FinnishLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_filgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.FinnishLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class FinnishLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new FinnishLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/FrenchLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/FrenchLightStemFilterFactory.java
deleted file mode 100644
index 8b50110..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/FrenchLightStemFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.fr.FrenchLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link FrenchLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_frlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ElisionFilterFactory"/&gt;
- *     &lt;filter class="solr.FrenchLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class FrenchLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new FrenchLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/FrenchMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/FrenchMinimalStemFilterFactory.java
deleted file mode 100644
index d3d3bf9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/FrenchMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.fr.FrenchMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link FrenchMinimalStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_frminstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ElisionFilterFactory"/&gt;
- *     &lt;filter class="solr.FrenchMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class FrenchMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new FrenchMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java
deleted file mode 100644
index 4f838ab..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.gl.GalicianMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link GalicianMinimalStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_glplural" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GalicianMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GalicianMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new GalicianMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GalicianStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GalicianStemFilterFactory.java
deleted file mode 100644
index 824a521..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GalicianStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.gl.GalicianStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link GalicianStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_glstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GalicianStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GalicianStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new GalicianStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GermanLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GermanLightStemFilterFactory.java
deleted file mode 100644
index 60824ce..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GermanLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.de.GermanLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link GermanLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_delgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GermanLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GermanLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new GermanLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GermanMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GermanMinimalStemFilterFactory.java
deleted file mode 100644
index 08a89da..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GermanMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.de.GermanMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link GermanMinimalStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_deminstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GermanMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GermanMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new GermanMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java
deleted file mode 100644
index 27ac20b..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.de.GermanNormalizationFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link GermanNormalizationFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_denorm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GermanNormalizationFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- */
-public class GermanNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-
-  public TokenStream create(TokenStream input) {
-    return new GermanNormalizationFilter(input);
-  }
-  
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GermanStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GermanStemFilterFactory.java
deleted file mode 100644
index 1e7edbd..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GermanStemFilterFactory.java
+++ /dev/null
@@ -1,43 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.de.GermanStemFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link GermanStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_destem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GermanStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GermanStemFilterFactory extends TokenFilterFactory {
-  public GermanStemFilter create(TokenStream in) {
-    return new GermanStemFilter(in);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java
deleted file mode 100644
index 8889920..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.el.GreekLowerCaseFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link GreekLowerCaseFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_glc" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.GreekLowerCaseFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class GreekLowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
- 
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    assureMatchVersion();
-    if (args.containsKey("charset"))
-      throw new InitializationException(
-          "The charset parameter is no longer supported.  "
-          + "Please process your documents as Unicode instead.");
-  }
-
-  public GreekLowerCaseFilter create(TokenStream in) {
-    return new GreekLowerCaseFilter(luceneMatchVersion, in);
-  }
-
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/GreekStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GreekStemFilterFactory.java
deleted file mode 100644
index d8dae6d..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/GreekStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.el.GreekStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link GreekStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_gstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.GreekLowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.GreekStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class GreekStemFilterFactory extends TokenFilterFactory {
-
-  public TokenStream create(TokenStream input) {
-    return new GreekStemFilter(input);
-  }
-
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java
deleted file mode 100644
index 6e91a95..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java
+++ /dev/null
@@ -1,71 +0,0 @@
-package org.apache.solr.analysis;
-
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
-import org.apache.lucene.analysis.util.CharFilterFactory;
-
-import java.io.Reader;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-/**
-* Factory for {@link HTMLStripCharFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_html" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;charFilter class="solr.HTMLStripCharFilterFactory" escapedTags="a, title" /&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
- public class HTMLStripCharFilterFactory extends CharFilterFactory {
-  
-  Set<String> escapedTags = null;
-  Pattern TAG_NAME_PATTERN = Pattern.compile("[^\\s,]+");
-
-  public HTMLStripCharFilter create(Reader input) {
-    HTMLStripCharFilter charFilter;
-    if (null == escapedTags) {
-      charFilter = new HTMLStripCharFilter(input);
-    } else {
-      charFilter = new HTMLStripCharFilter(input, escapedTags);
-    }
-    return charFilter;
-  }
-  
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    String escapedTagsArg = args.get("escapedTags");
-    if (null != escapedTagsArg) {
-      Matcher matcher = TAG_NAME_PATTERN.matcher(escapedTagsArg);
-      while (matcher.find()) {
-        if (null == escapedTags) {
-          escapedTags = new HashSet<String>();
-        }
-        escapedTags.add(matcher.group(0));
-      }
-    }
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HindiNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HindiNormalizationFilterFactory.java
deleted file mode 100644
index 6a11b19..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HindiNormalizationFilterFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.hi.HindiNormalizationFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link HindiNormalizationFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_hinormal" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.HindiNormalizationFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class HindiNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  public TokenStream create(TokenStream input) {
-    return new HindiNormalizationFilter(input);
-  }
-  
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HindiStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HindiStemFilterFactory.java
deleted file mode 100644
index 2e495e4..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HindiStemFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.hi.HindiStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link HindiStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_histem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.HindiStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class HindiStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new HindiStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HungarianLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HungarianLightStemFilterFactory.java
deleted file mode 100644
index 10aea57..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HungarianLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.hu.HungarianLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link HungarianLightStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_hulgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.HungarianLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class HungarianLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new HungarianLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HunspellStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HunspellStemFilterFactory.java
deleted file mode 100644
index 38f6f59..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HunspellStemFilterFactory.java
+++ /dev/null
@@ -1,117 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.hunspell.HunspellDictionary;
-import org.apache.lucene.analysis.hunspell.HunspellStemFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoaderAware;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-import org.apache.lucene.util.IOUtils;
-
-/**
- * TokenFilterFactory that creates instances of {@link org.apache.lucene.analysis.hunspell.HunspellStemFilter}.
- * Example config for British English including a custom dictionary, case insensitive matching:
- * <pre class="prettyprint" >
- * &lt;filter class=&quot;solr.HunspellStemFilterFactory&quot;
- *    dictionary=&quot;en_GB.dic,my_custom.dic&quot;
- *    affix=&quot;en_GB.aff&quot;
- *    ignoreCase=&quot;true&quot; /&gt;</pre>
- * Both parameters dictionary and affix are mandatory.
- * <br/>
- * The parameter ignoreCase (true/false) controls whether matching is case sensitive or not. Default false.
- * <br/>
- * The parameter strictAffixParsing (true/false) controls whether the affix parsing is strict or not. Default true.
- * If strict an error while reading an affix rule causes a ParseException, otherwise is ignored.
- * <br/>
- * Dictionaries for many languages are available through the OpenOffice project.
- * 
- * See <a href="http://wiki.apache.org/solr/Hunspell">http://wiki.apache.org/solr/Hunspell</a>
- */
-public class HunspellStemFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  
-  private static final String PARAM_DICTIONARY = "dictionary";
-  private static final String PARAM_AFFIX = "affix";
-  private static final String PARAM_IGNORE_CASE = "ignoreCase";
-  private static final String PARAM_STRICT_AFFIX_PARSING = "strictAffixParsing";
-  private static final String TRUE = "true";
-  private static final String FALSE = "false";
-  
-  private HunspellDictionary dictionary;
-  private boolean ignoreCase = false;
-
-  /**
-   * Loads the hunspell dictionary and affix files defined in the configuration
-   *  
-   * @param loader ResourceLoader used to load the files
-   */
-  public void inform(ResourceLoader loader) {
-    assureMatchVersion();
-    String dictionaryFiles[] = args.get(PARAM_DICTIONARY).split(",");
-    String affixFile = args.get(PARAM_AFFIX);
-    String pic = args.get(PARAM_IGNORE_CASE);
-    if(pic != null) {
-      if(pic.equalsIgnoreCase(TRUE)) ignoreCase = true;
-      else if(pic.equalsIgnoreCase(FALSE)) ignoreCase = false;
-      else throw new InitializationException("Unknown value for " + PARAM_IGNORE_CASE + ": " + pic + ". Must be true or false");
-    }
-
-    String strictAffixParsingParam = args.get(PARAM_STRICT_AFFIX_PARSING);
-    boolean strictAffixParsing = true;
-    if(strictAffixParsingParam != null) {
-      if(strictAffixParsingParam.equalsIgnoreCase(FALSE)) strictAffixParsing = false;
-      else if(strictAffixParsingParam.equalsIgnoreCase(TRUE)) strictAffixParsing = true;
-      else throw new InitializationException("Unknown value for " + PARAM_STRICT_AFFIX_PARSING + ": " + strictAffixParsingParam + ". Must be true or false");
-    }
-
-    InputStream affix = null;
-    List<InputStream> dictionaries = new ArrayList<InputStream>();
-
-    try {
-      dictionaries = new ArrayList<InputStream>();
-      for (String file : dictionaryFiles) {
-        dictionaries.add(loader.openResource(file));
-      }
-      affix = loader.openResource(affixFile);
-
-      this.dictionary = new HunspellDictionary(affix, dictionaries, luceneMatchVersion, ignoreCase, strictAffixParsing);
-    } catch (Exception e) {
-      throw new InitializationException("Unable to load hunspell data! [dictionary=" + args.get("dictionary") + ",affix=" + affixFile + "]", e);
-    } finally {
-      IOUtils.closeWhileHandlingException(affix);
-      IOUtils.closeWhileHandlingException(dictionaries);
-    }
-  }
-
-  /**
-   * Creates an instance of {@link org.apache.lucene.analysis.hunspell.HunspellStemFilter} that will filter the given
-   * TokenStream
-   *
-   * @param tokenStream TokenStream that will be filtered
-   * @return HunspellStemFilter that filters the TokenStream 
-   */
-  public TokenStream create(TokenStream tokenStream) {
-    return new HunspellStemFilter(tokenStream, dictionary);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java
deleted file mode 100755
index 91faf90..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HyphenatedWordsFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.HyphenatedWordsFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link HyphenatedWordsFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_hyphn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.HyphenatedWordsFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class HyphenatedWordsFilterFactory extends TokenFilterFactory {
-	public HyphenatedWordsFilter create(TokenStream input) {
-		return new HyphenatedWordsFilter(input);
-	}
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/HyphenationCompoundWordTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HyphenationCompoundWordTokenFilterFactory.java
deleted file mode 100644
index d4a0da3..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/HyphenationCompoundWordTokenFilterFactory.java
+++ /dev/null
@@ -1,109 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.commons.io.IOUtils;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.compound.CompoundWordTokenFilterBase;
-import org.apache.lucene.analysis.compound.HyphenationCompoundWordTokenFilter;
-import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree;
-import org.apache.lucene.analysis.util.*;
-
-import java.util.Map;
-import java.io.InputStream;
-import org.xml.sax.InputSource;
-
-/**
- * Factory for {@link HyphenationCompoundWordTokenFilter}.
- * <p>
- * This factory accepts the following parameters:
- * <ul>
- *  <li><code>hyphenator</code> (mandatory): path to the FOP xml hyphenation pattern. 
- *  See <a href="http://offo.sourceforge.net/hyphenation/">http://offo.sourceforge.net/hyphenation/</a>.
- *  <li><code>encoding</code> (optional): encoding of the xml hyphenation file. defaults to UTF-8.
- *  <li><code>dictionary</code> (optional): dictionary of words. defaults to no dictionary.
- *  <li><code>minWordSize</code> (optional): minimal word length that gets decomposed. defaults to 5.
- *  <li><code>minSubwordSize</code> (optional): minimum length of subwords. defaults to 2.
- *  <li><code>maxSubwordSize</code> (optional): maximum length of subwords. defaults to 15.
- *  <li><code>onlyLongestMatch</code> (optional): if true, adds only the longest matching subword 
- *    to the stream. defaults to false.
- * </ul>
- * <p>
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_hyphncomp" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.HyphenationCompoundWordTokenFilterFactory" hyphenator="hyphenator.xml" encoding="UTF-8"
- *     	     dictionary="dictionary.txt" minWordSize="5" minSubwordSize="2" maxSubwordSize="15" onlyLongestMatch="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- * @see HyphenationCompoundWordTokenFilter
- */
-public class HyphenationCompoundWordTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  private CharArraySet dictionary;
-  private HyphenationTree hyphenator;
-  private String dictFile;
-  private String hypFile;
-  private String encoding;
-  private int minWordSize;
-  private int minSubwordSize;
-  private int maxSubwordSize;
-  private boolean onlyLongestMatch;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    assureMatchVersion();
-    dictFile = args.get("dictionary");
-    if (args.containsKey("encoding"))
-      encoding = args.get("encoding");
-    hypFile = args.get("hyphenator");
-    if (null == hypFile) {
-      throw new InitializationException("Missing required parameter: hyphenator");
-    }
-
-    minWordSize = getInt("minWordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_WORD_SIZE);
-    minSubwordSize = getInt("minSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE);
-    maxSubwordSize = getInt("maxSubwordSize", CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE);
-    onlyLongestMatch = getBoolean("onlyLongestMatch", false);
-  }
-  
-  public void inform(ResourceLoader loader) {
-    InputStream stream = null;
-    try {
-      if (dictFile != null) // the dictionary can be empty.
-        dictionary = getWordSet(loader, dictFile, false);
-      // TODO: Broken, because we cannot resolve real system id
-      // ResourceLoader should also supply method like ClassLoader to get resource URL
-      stream = loader.openResource(hypFile);
-      final InputSource is = new InputSource(stream);
-      is.setEncoding(encoding); // if it's null let xml parser decide
-      is.setSystemId(hypFile);
-      hyphenator = HyphenationCompoundWordTokenFilter.getHyphenationTree(is);
-    } catch (Exception e) { // TODO: getHyphenationTree really shouldn't throw "Exception"
-      throw new InitializationException("Exception thrown while loading dictionary and hyphenation file", e);
-    } finally {
-      IOUtils.closeQuietly(stream);
-    }
-  }
-  
-  public HyphenationCompoundWordTokenFilter create(TokenStream input) {
-    return new HyphenationCompoundWordTokenFilter(luceneMatchVersion, input, hyphenator, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/IndicNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/IndicNormalizationFilterFactory.java
deleted file mode 100644
index 2709e75..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/IndicNormalizationFilterFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.in.IndicNormalizationFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link IndicNormalizationFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_innormal" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.IndicNormalizationFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class IndicNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  public TokenStream create(TokenStream input) {
-    return new IndicNormalizationFilter(input);
-  }
-  
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/IndonesianStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/IndonesianStemFilterFactory.java
deleted file mode 100644
index 92b1d46..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/IndonesianStemFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.id.IndonesianStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link IndonesianStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_idstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.IndonesianStemFilterFactory" stemDerivational="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class IndonesianStemFilterFactory extends TokenFilterFactory {
-  private boolean stemDerivational = true;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    stemDerivational = getBoolean("stemDerivational", true);
-  }
-
-  public TokenStream create(TokenStream input) {
-    return new IndonesianStemFilter(input, stemDerivational);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/IrishLowerCaseFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/IrishLowerCaseFilterFactory.java
deleted file mode 100644
index e5f1d85..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/IrishLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,49 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ga.IrishLowerCaseFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link IrishLowerCaseFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ga" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.IrishLowerCaseFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class IrishLowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new IrishLowerCaseFilter(input);
-  }
-
-  // this will 'mostly work', except for special cases, just like most other filters
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ItalianLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ItalianLightStemFilterFactory.java
deleted file mode 100644
index 7e79479..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ItalianLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.it.ItalianLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link ItalianLightStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_itlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ItalianLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class ItalianLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new ItalianLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java
deleted file mode 100644
index 600991f..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ja.JapaneseBaseFormFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link org.apache.lucene.analysis.ja.JapaneseBaseFormFilter}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
- *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class JapaneseBaseFormFilterFactory extends TokenFilterFactory {
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new JapaneseBaseFormFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java
deleted file mode 100644
index 602a5f1..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java
+++ /dev/null
@@ -1,55 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ja.JapaneseKatakanaStemFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-/**
- * Factory for {@link JapaneseKatakanaStemFilterFactory}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
- *     &lt;filter class="solr.JapaneseKatakanaStemFilterFactory"
- *             minimumLength="4"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class JapaneseKatakanaStemFilterFactory extends TokenFilterFactory {
-  private static final String MINIMUM_LENGTH_PARAM = "minimumLength";
-  private int minimumLength;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    minimumLength = getInt(MINIMUM_LENGTH_PARAM, JapaneseKatakanaStemFilter.DEFAULT_MINIMUM_LENGTH);
-    if (minimumLength < 2) {
-      throw new InitializationException("Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
-    }
-  }
-
-  public TokenStream create(TokenStream input) {
-    return new JapaneseKatakanaStemFilter(input, minimumLength);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java
deleted file mode 100644
index ce91b63..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java
+++ /dev/null
@@ -1,63 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter;
-import org.apache.lucene.analysis.util.*;
-
-/**
- * Factory for {@link org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
- *     &lt;filter class="solr.JapanesePartOfSpeechStopFilterFactory"
- *             tags="stopTags.txt" 
- *             enablePositionIncrements="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class JapanesePartOfSpeechStopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware  {
-  private boolean enablePositionIncrements;
-  private Set<String> stopTags;
-
-  public void inform(ResourceLoader loader) {
-    String stopTagFiles = args.get("tags");
-    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
-    try {
-      CharArraySet cas = getWordSet(loader, stopTagFiles, false);
-      stopTags = new HashSet<String>();
-      for (Object element : cas) {
-        char chars[] = (char[]) element;
-        stopTags.add(new String(chars));
-      }
-    } catch (IOException e) {
-      throw new InitializationException("IOException thrown while loading tags", e);
-    }
-  }
-
-  public TokenStream create(TokenStream stream) {
-    return new JapanesePartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java
deleted file mode 100644
index ba0c541..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java
+++ /dev/null
@@ -1,51 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ja.JapaneseReadingFormFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-/**
- * Factory for {@link org.apache.lucene.analysis.ja.JapaneseReadingFormFilter}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
- *     &lt;filter class="solr.JapaneseReadingFormFilterFactory"
- *             useRomaji="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class JapaneseReadingFormFilterFactory extends TokenFilterFactory {
-  private static final String ROMAJI_PARAM = "useRomaji";
-  private boolean useRomaji;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    useRomaji = getBoolean(ROMAJI_PARAM, false);
-  }
-
-  public TokenStream create(TokenStream input) {
-    return new JapaneseReadingFormFilter(input, useRomaji);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java
deleted file mode 100644
index 769d304..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java
+++ /dev/null
@@ -1,108 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.nio.charset.Charset;
-import java.nio.charset.CharsetDecoder;
-import java.nio.charset.CodingErrorAction;
-import java.util.Locale;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.ja.JapaneseTokenizer;
-import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
-import org.apache.lucene.analysis.ja.dict.UserDictionary;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.lucene.analysis.util.ResourceLoaderAware;
-
-/**
- * Factory for {@link org.apache.lucene.analysis.ja.JapaneseTokenizer}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"
- *       mode="NORMAL"
- *       userDictionary="user.txt"
- *       userDictionaryEncoding="UTF-8"
- *       discardPunctuation="true"
- *     /&gt;
- *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class JapaneseTokenizerFactory extends TokenizerFactory implements ResourceLoaderAware {
-  private static final String MODE = "mode";
-  
-  private static final String USER_DICT_PATH = "userDictionary";
-  
-  private static final String USER_DICT_ENCODING = "userDictionaryEncoding";
-
-  private static final String DISCARD_PUNCTUATION = "discardPunctuation"; // Expert option
-
-  private UserDictionary userDictionary;
-
-  private Mode mode;
-
-  private boolean discardPunctuation;
-
-  @Override
-  public void inform(ResourceLoader loader) {
-    mode = getMode(args);
-    String userDictionaryPath = args.get(USER_DICT_PATH);
-    try {
-      if (userDictionaryPath != null) {
-        InputStream stream = loader.openResource(userDictionaryPath);
-        String encoding = args.get(USER_DICT_ENCODING);
-        if (encoding == null) {
-          encoding = IOUtils.UTF_8;
-        }
-        CharsetDecoder decoder = Charset.forName(encoding).newDecoder()
-            .onMalformedInput(CodingErrorAction.REPORT)
-            .onUnmappableCharacter(CodingErrorAction.REPORT);
-        Reader reader = new InputStreamReader(stream, decoder);
-        userDictionary = new UserDictionary(reader);
-      } else {
-        userDictionary = null;
-      }
-    } catch (Exception e) {
-      throw new InitializationException("Exception thrown while loading dictionary", e);
-    }
-    discardPunctuation = getBoolean(DISCARD_PUNCTUATION, true);
-  }
-  
-  @Override
-  public Tokenizer create(Reader input) {
-    return new JapaneseTokenizer(input, userDictionary, discardPunctuation, mode);
-  }
-  
-  private Mode getMode(Map<String, String> args) {
-    String mode = args.get(MODE);
-    if (mode != null) {
-      return Mode.valueOf(mode.toUpperCase(Locale.ROOT));
-    } else {
-      return JapaneseTokenizer.DEFAULT_MODE;
-    }
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KStemFilterFactory.java
deleted file mode 100644
index f8f4057..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KStemFilterFactory.java
+++ /dev/null
@@ -1,33 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.en.KStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link KStemFilter}
- */
-public class KStemFilterFactory extends TokenFilterFactory {
-
-  public TokenFilter create(TokenStream input) {
-    return new KStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java
deleted file mode 100644
index 86a5ed1..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KeepWordFilterFactory.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.util.*;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.KeepWordFilter;
-
-import java.util.Map;
-import java.util.Set;
-import java.io.IOException;
-
-/**
- * Factory for {@link KeepWordFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_keepword" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KeepWordFilterFactory" words="keepwords.txt" ignoreCase="false" enablePositionIncrements="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class KeepWordFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public void inform(ResourceLoader loader) {
-    String wordFiles = args.get("words");
-    ignoreCase = getBoolean("ignoreCase", false);
-    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
-
-    if (wordFiles != null) {
-      try {
-        words = getWordSet(loader, wordFiles, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading words", e);
-      }
-    }
-  }
-
-  private CharArraySet words;
-  private boolean ignoreCase;
-  private boolean enablePositionIncrements;
-
-  /**
-   * Set the keep word list.
-   * NOTE: if ignoreCase==true, the words are expected to be lowercase
-   */
-  public void setWords(Set<String> words) {
-    this.words = new CharArraySet(luceneMatchVersion, words, ignoreCase);
-  }
-
-  public void setIgnoreCase(boolean ignoreCase) {    
-    if (words != null && this.ignoreCase != ignoreCase) {
-      words = new CharArraySet(luceneMatchVersion, words, ignoreCase);
-    }
-    this.ignoreCase = ignoreCase;
-  }
-
-  public boolean isEnablePositionIncrements() {
-    return enablePositionIncrements;
-  }
-
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public CharArraySet getWords() {
-    return words;
-  }
-
-  public KeepWordFilter create(TokenStream input) {
-    return new KeepWordFilter(enablePositionIncrements, input, words);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KeywordMarkerFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KeywordMarkerFilterFactory.java
deleted file mode 100644
index 3274a43..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KeywordMarkerFilterFactory.java
+++ /dev/null
@@ -1,61 +0,0 @@
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
-import org.apache.lucene.analysis.util.*;
-import org.apache.lucene.analysis.TokenStream;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Factory for {@link KeywordMarkerFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_keyword" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KeywordMarkerFilterFactory" protected="protectedkeyword.txt" ignoreCase="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class KeywordMarkerFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-  private CharArraySet protectedWords;
-  private boolean ignoreCase;
-  
-  public void inform(ResourceLoader loader) {
-    String wordFiles = args.get(PROTECTED_TOKENS);
-    ignoreCase = getBoolean("ignoreCase", false);
-    if (wordFiles != null) {  
-      try {
-        protectedWords = getWordSet(loader, wordFiles, ignoreCase);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
-    }
-  }
-  
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public TokenStream create(TokenStream input) {
-    return protectedWords == null ? input : new KeywordMarkerFilter(input, protectedWords);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KeywordTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/KeywordTokenizerFactory.java
deleted file mode 100644
index 678dda5..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KeywordTokenizerFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-
-/**
- * Factory for {@link KeywordTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_keyword" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class KeywordTokenizerFactory extends TokenizerFactory {
-  public KeywordTokenizer create(Reader input) {
-    return new KeywordTokenizer(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LatvianStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/LatvianStemFilterFactory.java
deleted file mode 100644
index 3fb4b26..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LatvianStemFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.lv.LatvianStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link LatvianStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_lvstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.LatvianStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class LatvianStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new LatvianStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LengthFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/LengthFilterFactory.java
deleted file mode 100644
index 756b202..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LengthFilterFactory.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.LengthFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-/**
- * Factory for {@link LengthFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_lngth" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LengthFilterFactory" min="0" max="1" enablePositionIncrements="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class LengthFilterFactory extends TokenFilterFactory {
-  int min,max;
-  boolean enablePositionIncrements;
-  public static final String MIN_KEY = "min";
-  public static final String MAX_KEY = "max";
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    min=Integer.parseInt(args.get(MIN_KEY));
-    max=Integer.parseInt(args.get(MAX_KEY));
-    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
-  }
-  
-  public LengthFilter create(TokenStream input) {
-    return new LengthFilter(enablePositionIncrements, input,min,max);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LetterTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/LetterTokenizerFactory.java
deleted file mode 100644
index fcd5691..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LetterTokenizerFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.core.LetterTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link LetterTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_letter" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.LetterTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class LetterTokenizerFactory extends TokenizerFactory {
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public LetterTokenizer create(Reader input) {
-    return new LetterTokenizer(luceneMatchVersion, input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LimitTokenCountFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/LimitTokenCountFilterFactory.java
deleted file mode 100644
index 0dfe9f9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LimitTokenCountFilterFactory.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.LimitTokenCountFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link LimitTokenCountFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_lngthcnt" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LimitTokenCountFilterFactory" maxTokenCount="10"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class LimitTokenCountFilterFactory extends TokenFilterFactory {
-
-  int maxTokenCount;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init( args );
-    maxTokenCount = Integer.parseInt( args.get( "maxTokenCount" ) );
-  }
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new LimitTokenCountFilter( input, maxTokenCount );
-  }
-
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LowerCaseFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/LowerCaseFilterFactory.java
deleted file mode 100644
index f49e557..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LowerCaseFilterFactory.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link LowerCaseFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_lwrcase" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class LowerCaseFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public LowerCaseFilter create(TokenStream input) {
-    return new LowerCaseFilter(luceneMatchVersion,input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/LowerCaseTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/LowerCaseTokenizerFactory.java
deleted file mode 100644
index 253d1ee..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/LowerCaseTokenizerFactory.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.core.LowerCaseTokenizer;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link LowerCaseTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_lwrcase" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.LowerCaseTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class LowerCaseTokenizerFactory extends TokenizerFactory implements MultiTermAwareComponent {
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public LowerCaseTokenizer create(Reader input) {
-    return new LowerCaseTokenizer(luceneMatchVersion,input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    LowerCaseFilterFactory filt = new LowerCaseFilterFactory();
-    filt.setLuceneMatchVersion(luceneMatchVersion);
-    filt.init(args);
-    return filt;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java
deleted file mode 100644
index a518e4a..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java
+++ /dev/null
@@ -1,135 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.File;
-import java.io.IOException;
-import java.io.Reader;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.analysis.CharFilter;
-import org.apache.lucene.analysis.charfilter.MappingCharFilter;
-import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
-import org.apache.lucene.analysis.util.*;
-import org.apache.solr.common.util.StrUtils;
-
-/**
- * Factory for {@link MappingCharFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_map" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;charFilter class="solr.MappingCharFilterFactory" mapping="mapping.txt"/&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- * @since Solr 1.4
- *
- */
-public class MappingCharFilterFactory extends CharFilterFactory implements
-    ResourceLoaderAware, MultiTermAwareComponent {
-
-  protected NormalizeCharMap normMap;
-  private String mapping;
-
-  public void inform(ResourceLoader loader) {
-    mapping = args.get( "mapping" );
-
-    if( mapping != null ){
-      List<String> wlist = null;
-      try{
-        File mappingFile = new File( mapping );
-        if( mappingFile.exists() ){
-          wlist = loader.getLines( mapping );
-        }
-        else{
-          List<String> files = StrUtils.splitFileNames( mapping );
-          wlist = new ArrayList<String>();
-          for( String file : files ){
-            List<String> lines = loader.getLines( file.trim() );
-            wlist.addAll( lines );
-          }
-        }
-      }
-      catch( IOException e ){
-        throw new InitializationException("IOException thrown while loading mappings", e);
-      }
-      final NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
-      parseRules( wlist, builder );
-      normMap = builder.build();
-    }
-  }
-
-  public CharFilter create(Reader input) {
-    return new MappingCharFilter(normMap,input);
-  }
-
-  // "source" => "target"
-  static Pattern p = Pattern.compile( "\"(.*)\"\\s*=>\\s*\"(.*)\"\\s*$" );
-
-  protected void parseRules( List<String> rules, NormalizeCharMap.Builder builder ){
-    for( String rule : rules ){
-      Matcher m = p.matcher( rule );
-      if( !m.find() )
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "], file = " + mapping);
-      builder.add( parseString( m.group( 1 ) ), parseString( m.group( 2 ) ) );
-    }
-  }
-
-  char[] out = new char[256];
-  
-  protected String parseString( String s ){
-    int readPos = 0;
-    int len = s.length();
-    int writePos = 0;
-    while( readPos < len ){
-      char c = s.charAt( readPos++ );
-      if( c == '\\' ){
-        if( readPos >= len )
-          throw new InitializationException("Invalid escaped char in [" + s + "]");
-        c = s.charAt( readPos++ );
-        switch( c ) {
-          case '\\' : c = '\\'; break;
-          case '"' : c = '"'; break;
-          case 'n' : c = '\n'; break;
-          case 't' : c = '\t'; break;
-          case 'r' : c = '\r'; break;
-          case 'b' : c = '\b'; break;
-          case 'f' : c = '\f'; break;
-          case 'u' :
-            if( readPos + 3 >= len )
-              throw new InitializationException("Invalid escaped char in [" + s + "]");
-            c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
-            readPos += 4;
-            break;
-        }
-      }
-      out[writePos++] = c;
-    }
-    return new String( out, 0, writePos );
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/NGramFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/NGramFilterFactory.java
deleted file mode 100644
index d21708b..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/NGramFilterFactory.java
+++ /dev/null
@@ -1,57 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.NGramTokenFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link NGramTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ngrm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.NGramFilterFactory" minGramSize="1" maxGramSize="2"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class NGramFilterFactory extends TokenFilterFactory {
-  private int maxGramSize = 0;
-
-  private int minGramSize = 0;
-
-  /** Initialize the n-gram min and max sizes and the side from which one should start tokenizing. */
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    String maxArg = args.get("maxGramSize");
-    maxGramSize = (maxArg != null ? Integer.parseInt(maxArg)
-        : NGramTokenFilter.DEFAULT_MAX_NGRAM_SIZE);
-
-    String minArg = args.get("minGramSize");
-    minGramSize = (minArg != null ? Integer.parseInt(minArg)
-        : NGramTokenFilter.DEFAULT_MIN_NGRAM_SIZE);
-  }
-
-  public NGramTokenFilter create(TokenStream input) {
-    return new NGramTokenFilter(input, minGramSize, maxGramSize);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/NGramTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/NGramTokenizerFactory.java
deleted file mode 100755
index c2ed40d..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/NGramTokenizerFactory.java
+++ /dev/null
@@ -1,56 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ngram.NGramTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link NGramTokenizer}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ngrm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.NGramTokenizerFactory" minGramSize="1" maxGramSize="2"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class NGramTokenizerFactory extends TokenizerFactory {
-    private int maxGramSize = 0;
-    private int minGramSize = 0;
-    
-    /** Initializes the n-gram min and max sizes and the side from which one should start tokenizing. */
-    @Override
-    public void init(Map<String, String> args) {
-        super.init(args);
-        String maxArg = args.get("maxGramSize");
-        maxGramSize = (maxArg != null ? Integer.parseInt(maxArg) : NGramTokenizer.DEFAULT_MAX_NGRAM_SIZE);
-
-        String minArg = args.get("minGramSize");
-        minGramSize = (minArg != null ? Integer.parseInt(minArg) : NGramTokenizer.DEFAULT_MIN_NGRAM_SIZE);
-    }
-
-    /** Creates the {@link TokenStream} of n-grams from the given {@link Reader}. */
-    public NGramTokenizer create(Reader input) {
-        return new NGramTokenizer(input, minGramSize, maxGramSize);
-    }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/NorwegianLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/NorwegianLightStemFilterFactory.java
deleted file mode 100644
index 840e726..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/NorwegianLightStemFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.no.NorwegianLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link NorwegianLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.NorwegianLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class NorwegianLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new NorwegianLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/NorwegianMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/NorwegianMinimalStemFilterFactory.java
deleted file mode 100644
index b8ec071..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/NorwegianMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.no.NorwegianMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link NorwegianMinimalStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.NorwegianMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class NorwegianMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new NorwegianMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/NumericPayloadTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/NumericPayloadTokenFilterFactory.java
deleted file mode 100644
index 605df3e..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/NumericPayloadTokenFilterFactory.java
+++ /dev/null
@@ -1,51 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.payloads.NumericPayloadTokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-import java.util.Map;
-
-/** 
- * Factory for {@link NumericPayloadTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_numpayload" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.NumericPayloadTokenFilterFactory" payload="24" typeMatch="word"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class NumericPayloadTokenFilterFactory extends TokenFilterFactory {
-  private float payload;
-  private String typeMatch;
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    payload = Float.parseFloat(args.get("payload"));
-    typeMatch = args.get("typeMatch");
-  }
-  public NumericPayloadTokenFilter create(TokenStream input) {
-    return new NumericPayloadTokenFilter(input,payload,typeMatch);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/PathHierarchyTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/PathHierarchyTokenizerFactory.java
deleted file mode 100644
index 6fd7f9e..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PathHierarchyTokenizerFactory.java
+++ /dev/null
@@ -1,98 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.path.PathHierarchyTokenizer;
-import org.apache.lucene.analysis.path.ReversePathHierarchyTokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-
-/**
- * Factory for {@link PathHierarchyTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_path" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.PathHierarchyTokenizerFactory" delimiter="\" replace="/"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class PathHierarchyTokenizerFactory extends TokenizerFactory {
-  
-  private char delimiter;
-  private char replacement;
-  private boolean reverse = false;
-  private int skip =  PathHierarchyTokenizer.DEFAULT_SKIP;
-  
-  /**
-   * Require a configured pattern
-   */
-  @Override
-  public void init(Map<String,String> args){
-    super.init( args );
-    
-    String v = args.get( "delimiter" );
-    if( v != null ){
-      if( v.length() != 1 ){
-        throw new InitializationException("delimiter should be a char. \"" + v + "\" is invalid");
-      }
-      else{
-        delimiter = v.charAt(0);
-      }
-    }
-    else{
-      delimiter = PathHierarchyTokenizer.DEFAULT_DELIMITER;
-    }
-    
-    v = args.get( "replace" );
-    if( v != null ){
-      if( v.length() != 1 ){
-        throw new InitializationException("replace should be a char. \"" + v + "\" is invalid");
-      }
-      else{
-        replacement = v.charAt(0);
-      }
-    }
-    else{
-      replacement = delimiter;
-    }
-    
-    v = args.get( "reverse" );
-    if( v != null ){
-      reverse = "true".equals( v );
-    }
-
-    v = args.get( "skip" );
-    if( v != null ){
-      skip = Integer.parseInt( v );
-    }
-  }
-
-  public Tokenizer create(Reader input) {
-    if( reverse ) {
-      return new ReversePathHierarchyTokenizer(input, delimiter, replacement, skip);
-    }
-    return new PathHierarchyTokenizer(input, delimiter, replacement, skip);
-  }
-}
-
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
deleted file mode 100644
index ca6fe6a..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.Reader;
-import java.util.Map;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.analysis.CharFilter;
-import org.apache.lucene.analysis.pattern.PatternReplaceCharFilter;
-import org.apache.lucene.analysis.util.CharFilterFactory;
-
-/**
- * Factory for {@link PatternReplaceCharFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptnreplace" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;charFilter class="solr.PatternReplaceCharFilterFactory" 
- *                    pattern="([^a-z])" replacement=""/&gt;
- *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- * 
- *
- * @since Solr 3.1
- */
-public class PatternReplaceCharFilterFactory extends CharFilterFactory {
-  
-  private Pattern p;
-  private String replacement;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init( args );
-    p = getPattern("pattern");
-    replacement = args.get( "replacement" );
-    if( replacement == null )
-      replacement = "";
-    // TODO: throw exception if you set maxBlockChars or blockDelimiters ?
-  }
-
-  public CharFilter create(Reader input) {
-    return new PatternReplaceCharFilter( p, replacement, input );
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java
deleted file mode 100644
index c71b794..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceFilterFactory.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.pattern.PatternReplaceFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-
-/**
- * Factory for {@link PatternReplaceFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptnreplace" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KeywordTokenizerFactory"/&gt;
- *     &lt;filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])" replacement=""
- *             replace="all"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- * @see PatternReplaceFilter
- */
-public class PatternReplaceFilterFactory extends TokenFilterFactory {
-  Pattern p;
-  String replacement;
-  boolean all = true;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    p = getPattern("pattern");
-    replacement = args.get("replacement");
-    
-    String r = args.get("replace");
-    if (null != r) {
-      if (r.equals("all")) {
-        all = true;
-      } else {
-        if (r.equals("first")) {
-          all = false;
-        } else {
-          throw new InitializationException
-            ("Configuration Error: 'replace' must be 'first' or 'all' in "
-             + this.getClass().getName());
-        }
-      }
-    }
-
-  }
-  public PatternReplaceFilter create(TokenStream input) {
-    return new PatternReplaceFilter(input, p, replacement, all);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java
deleted file mode 100644
index a11e9fd..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PatternTokenizerFactory.java
+++ /dev/null
@@ -1,107 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.util.Map;
-import java.util.regex.Pattern;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.pattern.PatternTokenizer;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-
-/**
- * Factory for {@link PatternTokenizer}.
- * This tokenizer uses regex pattern matching to construct distinct tokens
- * for the input stream.  It takes two arguments:  "pattern" and "group".
- * <p/>
- * <ul>
- * <li>"pattern" is the regular expression.</li>
- * <li>"group" says which group to extract into tokens.</li>
- *  </ul>
- * <p>
- * group=-1 (the default) is equivalent to "split".  In this case, the tokens will
- * be equivalent to the output from (without empty tokens):
- * {@link String#split(java.lang.String)}
- * </p>
- * <p>
- * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
- * <pre>
- *  pattern = \'([^\']+)\'
- *  group = 0
- *  input = aaa 'bbb' 'ccc'
- *</pre>
- * the output will be two tokens: 'bbb' and 'ccc' (including the ' marks).  With the same input
- * but using group=1, the output would be: bbb and ccc (no ' marks)
- * </p>
- * <p>NOTE: This Tokenizer does not output tokens that are of zero length.</p>
- *
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptn" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.PatternTokenizerFactory" pattern="\'([^\']+)\'" group="1"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- * 
- * @see PatternTokenizer
- * @since solr1.2
- *
- */
-public class PatternTokenizerFactory extends TokenizerFactory
-{
-  public static final String PATTERN = "pattern";
-  public static final String GROUP = "group";
- 
-  protected Pattern pattern;
-  protected int group;
-  
-  /**
-   * Require a configured pattern
-   */
-  @Override
-  public void init(Map<String,String> args) 
-  {
-    super.init(args);
-    pattern = getPattern( PATTERN );
-    
-    group = -1;  // use 'split'
-    String g = args.get( GROUP );
-    if( g != null ) {
-      try {
-        group = Integer.parseInt( g );
-      }
-      catch( Exception ex ) {
-        throw new InitializationException("invalid group argument: " + g);
-      }
-    }
-  }
-  
-  /**
-   * Split the input using configured pattern
-   */
-  public Tokenizer create(final Reader in) {
-    try {
-      return new PatternTokenizer(in, pattern, group);
-    } catch( IOException ex ) {
-      throw new InitializationException("IOException thrown creating PatternTokenizer instance", ex);
-    }
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java
deleted file mode 100644
index a0ae871..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-
-import org.apache.lucene.analysis.CharFilter;
-import org.apache.lucene.analysis.fa.PersianCharFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.CharFilterFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-
-/**
- * Factory for {@link PersianCharFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_fa" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;charFilter class="solr.PersianCharFilterFactory"/&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PersianCharFilterFactory extends CharFilterFactory implements MultiTermAwareComponent {
-
-  @Override
-  public CharFilter create(Reader input) {
-    return new PersianCharFilter(input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PersianNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PersianNormalizationFilterFactory.java
deleted file mode 100644
index a0ccd43..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PersianNormalizationFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.fa.PersianNormalizationFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link PersianNormalizationFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_fanormal" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;charFilter class="solr.PersianCharFilterFactory"/&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.PersianNormalizationFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PersianNormalizationFilterFactory extends TokenFilterFactory implements MultiTermAwareComponent {
-  public PersianNormalizationFilter create(TokenStream input) {
-    return new PersianNormalizationFilter(input);
-  }
-  
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/PhoneticFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PhoneticFilterFactory.java
deleted file mode 100644
index 4df05a4..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PhoneticFilterFactory.java
+++ /dev/null
@@ -1,149 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.lang.reflect.Method;
-import java.lang.reflect.InvocationTargetException;
-import java.util.HashMap;
-import java.util.Locale;
-import java.util.Map;
-
-import org.apache.commons.codec.Encoder;
-import org.apache.commons.codec.language.*;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.phonetic.PhoneticFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link PhoneticFilter}.
- * 
- * Create tokens based on phonetic encoders from <a href="
- * http://commons.apache.org/codec/api-release/org/apache/commons/codec/language/package-summary.html
- * ">Apache Commons Codec</a>.
- * <p>
- * This takes one required argument, "encoder", and the rest are optional:
- * <dl>
- *  <dt>encoder<dd> required, one of "DoubleMetaphone", "Metaphone", "Soundex", "RefinedSoundex", "Caverphone" (v2.0),
- *  or "ColognePhonetic" (case insensitive). If encoder isn't one of these, it'll be resolved as a class name either by
- *  itself if it already contains a '.' or otherwise as in the same package as these others.
- *  <dt>inject<dd> (default=true) add tokens to the stream with the offset=0
- *  <dt>maxCodeLength<dd>The maximum length of the phonetic codes, as defined by the encoder. If an encoder doesn't
- *  support this then specifying this is an error.
- * </dl>
- *
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_phonetic" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.PhoneticFilterFactory" encoder="DoubleMetaphone" inject="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- * 
- * @see PhoneticFilter
- */
-public class PhoneticFilterFactory extends TokenFilterFactory
-{
-  public static final String ENCODER = "encoder";
-  public static final String INJECT = "inject"; // boolean
-  public static final String MAX_CODE_LENGTH = "maxCodeLength";
-  private static final String PACKAGE_CONTAINING_ENCODERS = "org.apache.commons.codec.language.";
-
-  //Effectively constants; uppercase keys
-  private static final Map<String, Class<? extends Encoder>> registry = new HashMap<String, Class<? extends Encoder>>(6);
-
-  static {
-    registry.put("DoubleMetaphone".toUpperCase(Locale.ROOT), DoubleMetaphone.class);
-    registry.put("Metaphone".toUpperCase(Locale.ROOT), Metaphone.class);
-    registry.put("Soundex".toUpperCase(Locale.ROOT), Soundex.class);
-    registry.put("RefinedSoundex".toUpperCase(Locale.ROOT), RefinedSoundex.class);
-    registry.put("Caverphone".toUpperCase(Locale.ROOT), Caverphone2.class);
-    registry.put("ColognePhonetic".toUpperCase(Locale.ROOT), ColognePhonetic.class);
-  }
-
-  protected boolean inject = true;
-  protected String name = null;
-  protected Class<? extends Encoder> clazz = null;
-  protected Method setMaxCodeLenMethod = null;
-  protected Integer maxCodeLength = null;
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init( args );
-
-    inject = getBoolean(INJECT, true);
-    
-    String name = args.get( ENCODER );
-    if( name == null ) {
-      throw new InitializationException("Missing required parameter: " + ENCODER
-          + " [" + registry.keySet() + "]");
-    }
-    clazz = registry.get(name.toUpperCase(Locale.ROOT));
-    if( clazz == null ) {
-      clazz = resolveEncoder(name);
-    }
-
-    String v = args.get(MAX_CODE_LENGTH);
-    if (v != null) {
-      maxCodeLength = Integer.valueOf(v);
-      try {
-        setMaxCodeLenMethod = clazz.getMethod("setMaxCodeLen", int.class);
-      } catch (Exception e) {
-        throw new InitializationException("Encoder " + name + " / " + clazz + " does not support " + MAX_CODE_LENGTH, e);
-      }
-    }
-
-    getEncoder();//trigger initialization for potential problems to be thrown now
-  }
-
-  private Class<? extends Encoder> resolveEncoder(String name) {
-    String lookupName = name;
-    if (name.indexOf('.') == -1) {
-      lookupName = PACKAGE_CONTAINING_ENCODERS + name;
-    }
-    try {
-      return Class.forName(lookupName).asSubclass(Encoder.class);
-    } catch (ClassNotFoundException cnfe) {
-      throw new InitializationException("Unknown encoder: " + name + " must be full class name or one of " + registry.keySet(), cnfe);
-    } catch (ClassCastException e) {
-      throw new InitializationException("Not an encoder: " + name + " must be full class name or one of " + registry.keySet(), e);
-    }
-  }
-
-  /** Must be thread-safe. */
-  protected Encoder getEncoder() {
-    // Unfortunately, Commons-Codec doesn't offer any thread-safe guarantees so we must play it safe and instantiate
-    // every time.  A simple benchmark showed this as negligible.
-    try {
-      Encoder encoder = clazz.newInstance();
-      // Try to set the maxCodeLength
-      if(maxCodeLength != null && setMaxCodeLenMethod != null) {
-        setMaxCodeLenMethod.invoke(encoder, maxCodeLength);
-      }
-      return encoder;
-    } catch (Exception e) {
-      final Throwable t = (e instanceof InvocationTargetException) ? e.getCause() : e;
-      throw new InitializationException("Error initializing encoder: " + name + " / " + clazz, t);
-    }
-  }
-
-  public PhoneticFilter create(TokenStream input) {
-    return new PhoneticFilter(input, getEncoder(), inject);
-  }
-
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PorterStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PorterStemFilterFactory.java
deleted file mode 100644
index c6dea10..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PorterStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.en.PorterStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link PorterStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_porterstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.PorterStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PorterStemFilterFactory extends TokenFilterFactory {
-  public PorterStemFilter create(TokenStream input) {
-    return new PorterStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PortugueseLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PortugueseLightStemFilterFactory.java
deleted file mode 100644
index 63f8902..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PortugueseLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.pt.PortugueseLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link PortugueseLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.PortugueseLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PortugueseLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new PortugueseLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PortugueseMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PortugueseMinimalStemFilterFactory.java
deleted file mode 100644
index 9148435..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PortugueseMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.pt.PortugueseMinimalStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link PortugueseMinimalStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptminstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.PortugueseMinimalStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PortugueseMinimalStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new PortugueseMinimalStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PortugueseStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PortugueseStemFilterFactory.java
deleted file mode 100644
index 4ddb7d9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PortugueseStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.pt.PortugueseStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link PortugueseStemFilter}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ptstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.PortugueseStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class PortugueseStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new PortugueseStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/PositionFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PositionFilterFactory.java
deleted file mode 100644
index 1fcc294..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/PositionFilterFactory.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.position.PositionFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-/**
- * Factory for {@link PositionFilter}.
- * Set the positionIncrement of all tokens to the "positionIncrement", except the first return token which retains its
- * original positionIncrement value. The default positionIncrement value is zero.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_position" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.PositionFilterFactory" positionIncrement="0"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- * @see org.apache.lucene.analysis.position.PositionFilter
- * @since solr 1.4
- */
-public class PositionFilterFactory extends TokenFilterFactory {
-  private int positionIncrement;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    positionIncrement = getInt("positionIncrement", 0);
-  }
-
-  public PositionFilter create(TokenStream input) {
-    return new PositionFilter(input, positionIncrement);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/RemoveDuplicatesTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/RemoveDuplicatesTokenFilterFactory.java
deleted file mode 100644
index 30d51bb..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/RemoveDuplicatesTokenFilterFactory.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.RemoveDuplicatesTokenFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link RemoveDuplicatesTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_rmdup" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.RemoveDuplicatesTokenFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class RemoveDuplicatesTokenFilterFactory extends TokenFilterFactory {
-  public RemoveDuplicatesTokenFilter create(TokenStream input) {
-    return new RemoveDuplicatesTokenFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ReverseStringFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ReverseStringFilterFactory.java
deleted file mode 100644
index f090c9d..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ReverseStringFilterFactory.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.reverse.ReverseStringFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link ReverseStringFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_rvsstr" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ReverseStringFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- *
- * @since solr 1.4
- */
-public class ReverseStringFilterFactory extends TokenFilterFactory {
-  public ReverseStringFilter create(TokenStream in) {
-    assureMatchVersion();
-    return new ReverseStringFilter(luceneMatchVersion,in);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/RussianLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/RussianLightStemFilterFactory.java
deleted file mode 100644
index 6b0411b..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/RussianLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.ru.RussianLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link RussianLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_rulgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.RussianLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class RussianLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new RussianLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ShingleFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ShingleFilterFactory.java
deleted file mode 100644
index ba329a0..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ShingleFilterFactory.java
+++ /dev/null
@@ -1,82 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.shingle.ShingleFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.util.Map;
-
-/** 
- * Factory for {@link ShingleFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_shingle" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ShingleFilterFactory" minShingleSize="2" maxShingleSize="2"
- *             outputUnigrams="true" outputUnigramsIfNoShingles="false" tokenSeparator=" "/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ShingleFilterFactory extends TokenFilterFactory {
-  private int minShingleSize;
-  private int maxShingleSize;
-  private boolean outputUnigrams;
-  private boolean outputUnigramsIfNoShingles;
-  private String tokenSeparator;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    maxShingleSize = getInt("maxShingleSize", 
-                            ShingleFilter.DEFAULT_MAX_SHINGLE_SIZE);
-    if (maxShingleSize < 2) {
-      throw new InitializationException("Invalid maxShingleSize (" + maxShingleSize
-                              + ") - must be at least 2");
-    }
-    minShingleSize = getInt("minShingleSize",
-                            ShingleFilter.DEFAULT_MIN_SHINGLE_SIZE);
-    if (minShingleSize < 2) {
-      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
-                              + ") - must be at least 2");
-    }
-    if (minShingleSize > maxShingleSize) {
-      throw new InitializationException("Invalid minShingleSize (" + minShingleSize
-                              + ") - must be no greater than maxShingleSize ("
-                              + maxShingleSize + ")");
-    }
-    outputUnigrams = getBoolean("outputUnigrams", true);
-    outputUnigramsIfNoShingles = getBoolean("outputUnigramsIfNoShingles", false);
-    tokenSeparator = args.containsKey("tokenSeparator")
-                     ? args.get("tokenSeparator")
-                     : ShingleFilter.TOKEN_SEPARATOR;
-  }
-  public ShingleFilter create(TokenStream input) {
-    ShingleFilter r = new ShingleFilter(input, minShingleSize, maxShingleSize);
-    r.setOutputUnigrams(outputUnigrams);
-    r.setOutputUnigramsIfNoShingles(outputUnigramsIfNoShingles);
-    r.setTokenSeparator(tokenSeparator);
-    return r;
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/SnowballPorterFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/SnowballPorterFilterFactory.java
deleted file mode 100644
index dc897cb..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/SnowballPorterFilterFactory.java
+++ /dev/null
@@ -1,90 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.util.Map;
-import java.io.IOException;
-
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.snowball.SnowballFilter;
-import org.apache.lucene.analysis.util.*;
-import org.tartarus.snowball.SnowballProgram;
-
-/**
- * Factory for {@link SnowballFilter}, with configurable language
- * <p>
- * Note: Use of the "Lovins" stemmer is not recommended, as it is implemented with reflection.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_snowballstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.SnowballPorterFilterFactory" protected="protectedkeyword.txt" language="English"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- * 
- *
- */
-public class SnowballPorterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-
-  private String language = "English";
-  private Class<?> stemClass;
-
-
-  public void inform(ResourceLoader loader) {
-    String wordFiles = args.get(PROTECTED_TOKENS);
-    if (wordFiles != null) {
-      try {
-        protectedWords = getWordSet(loader, wordFiles, false);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
-    }
-  }
-
-  private CharArraySet protectedWords = null;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    final String cfgLanguage = args.get("language");
-    if(cfgLanguage!=null) language = cfgLanguage;
-
-    try {
-      stemClass = Class.forName("org.tartarus.snowball.ext." + language + "Stemmer");
-    } catch (ClassNotFoundException e) {
-      throw new InitializationException("Can't find class for stemmer language " + language, e);
-    }
-  }
-  
-  public TokenFilter create(TokenStream input) {
-    SnowballProgram program;
-    try {
-      program = (SnowballProgram)stemClass.newInstance();
-    } catch (Exception e) {
-      throw new InitializationException("Error instantiating stemmer for language " + language + "from class " + stemClass, e);
-    }
-
-    if (protectedWords != null)
-      input = new KeywordMarkerFilter(input, protectedWords);
-    return new SnowballFilter(input, program);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/SpanishLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/SpanishLightStemFilterFactory.java
deleted file mode 100644
index 61c883b..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/SpanishLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.es.SpanishLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link SpanishLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_eslgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.SpanishLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class SpanishLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new SpanishLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/StandardFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/StandardFilterFactory.java
deleted file mode 100644
index 965eb08..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/StandardFilterFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.standard.StandardFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link StandardFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_stndrd" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.StandardFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class StandardFilterFactory extends TokenFilterFactory {
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-  
-  public StandardFilter create(TokenStream input) {
-    return new StandardFilter(luceneMatchVersion, input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/StandardTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/StandardTokenizerFactory.java
deleted file mode 100644
index 4385057..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/StandardTokenizerFactory.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link StandardTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_stndrd" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory" maxTokenLength="255"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-
-public class StandardTokenizerFactory extends TokenizerFactory {
-  
-  private int maxTokenLength;
-  
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-    maxTokenLength = getInt("maxTokenLength", 
-                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
-  }
-
-  public StandardTokenizer create(Reader input) {
-    StandardTokenizer tokenizer
-      = new StandardTokenizer(luceneMatchVersion, input); 
-    tokenizer.setMaxTokenLength(maxTokenLength);
-    return tokenizer;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/StemmerOverrideFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/StemmerOverrideFilterFactory.java
deleted file mode 100644
index c9bec3f..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/StemmerOverrideFilterFactory.java
+++ /dev/null
@@ -1,74 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.List;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.StemmerOverrideFilter;
-import org.apache.lucene.analysis.util.*;
-import org.apache.solr.common.util.StrUtils;
-
-/**
- * Factory for {@link StemmerOverrideFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_dicstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.StemmerOverrideFilterFactory" dictionary="dictionary.txt" ignoreCase="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class StemmerOverrideFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  private CharArrayMap<String> dictionary = null;
-  private boolean ignoreCase;
-
-  public void inform(ResourceLoader loader) {
-    String dictionaryFiles = args.get("dictionary");
-    ignoreCase = getBoolean("ignoreCase", false);
-    if (dictionaryFiles != null) {
-      assureMatchVersion();
-      List<String> files = StrUtils.splitFileNames(dictionaryFiles);
-      try {
-        if (files.size() > 0) {
-          dictionary = new CharArrayMap<String>(luceneMatchVersion, 
-              files.size() * 10, ignoreCase);
-          for (String file : files) {
-            List<String> list = loader.getLines(file.trim());
-            for (String line : list) {
-              String[] mapping = line.split("\t", 2);
-              dictionary.put(mapping[0], mapping[1]);
-            }
-          }
-        }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading dictionary", e);
-      }
-    }
-  }
-
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public TokenStream create(TokenStream input) {
-    return dictionary == null ? input : new StemmerOverrideFilter(luceneMatchVersion, input, dictionary);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/StopFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/StopFilterFactory.java
deleted file mode 100644
index 7e49e39..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/StopFilterFactory.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.util.*;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.core.StopFilter;
-
-import java.util.Map;
-import java.io.IOException;
-
-/**
- * Factory for {@link StopFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_stop" class="solr.TextField" positionIncrementGap="100" autoGeneratePhraseQueries="true"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.StopFilterFactory" ignoreCase="true"
- *             words="stopwords.txt" enablePositionIncrements="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class StopFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  @Override
-  public void inform(ResourceLoader loader) {
-    String stopWordFiles = args.get("words");
-    ignoreCase = getBoolean("ignoreCase",false);
-    enablePositionIncrements = getBoolean("enablePositionIncrements",false);
-
-    if (stopWordFiles != null) {
-      try {
-        if ("snowball".equalsIgnoreCase(args.get("format"))) {
-          stopWords = getSnowballWordSet(loader, stopWordFiles, ignoreCase);
-        } else {
-          stopWords = getWordSet(loader, stopWordFiles, ignoreCase);
-        }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading stopwords", e);
-      }
-    } else {
-      stopWords = new CharArraySet(luceneMatchVersion, StopAnalyzer.ENGLISH_STOP_WORDS_SET, ignoreCase);
-    }
-  }
-
-  private CharArraySet stopWords;
-  private boolean ignoreCase;
-  private boolean enablePositionIncrements;
-
-  public boolean isEnablePositionIncrements() {
-    return enablePositionIncrements;
-  }
-
-  public boolean isIgnoreCase() {
-    return ignoreCase;
-  }
-
-  public CharArraySet getStopWords() {
-    return stopWords;
-  }
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    StopFilter stopFilter = new StopFilter(luceneMatchVersion,input,stopWords);
-    stopFilter.setEnablePositionIncrements(enablePositionIncrements);
-    return stopFilter;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/SwedishLightStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/SwedishLightStemFilterFactory.java
deleted file mode 100644
index 78f65da..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/SwedishLightStemFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.sv.SwedishLightStemFilter;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link SwedishLightStemFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_svlgtstem" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.SwedishLightStemFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class SwedishLightStemFilterFactory extends TokenFilterFactory {
-  public TokenStream create(TokenStream input) {
-    return new SwedishLightStemFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/ThaiWordFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ThaiWordFilterFactory.java
deleted file mode 100644
index 22d3953..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/ThaiWordFilterFactory.java
+++ /dev/null
@@ -1,43 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-import org.apache.lucene.analysis.th.ThaiWordFilter;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link ThaiWordFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_thai" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.ThaiWordFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class ThaiWordFilterFactory extends TokenFilterFactory {
-  public ThaiWordFilter create(TokenStream input) {
-    assureMatchVersion();
-    return new ThaiWordFilter(luceneMatchVersion, input);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/TokenOffsetPayloadTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/TokenOffsetPayloadTokenFilterFactory.java
deleted file mode 100644
index 6d866e1..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/TokenOffsetPayloadTokenFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.payloads.TokenOffsetPayloadTokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link TokenOffsetPayloadTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_tokenoffset" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.TokenOffsetPayloadTokenFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- */
-public class TokenOffsetPayloadTokenFilterFactory extends TokenFilterFactory {
-  public TokenOffsetPayloadTokenFilter create(TokenStream input) {
-    return new TokenOffsetPayloadTokenFilter(input);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/TrimFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/TrimFilterFactory.java
deleted file mode 100644
index ef7fbae..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/TrimFilterFactory.java
+++ /dev/null
@@ -1,61 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.TrimFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/**
- * Factory for {@link TrimFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_trm" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.NGramTokenizerFactory"/&gt;
- *     &lt;filter class="solr.TrimFilterFactory" updateOffsets="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- *
- * @see TrimFilter
- */
-public class TrimFilterFactory extends TokenFilterFactory {
-  
-  protected boolean updateOffsets = false;
-  
-  @Override
-  public void init(Map<String,String> args) {
-    super.init( args );
-    
-    String v = args.get( "updateOffsets" );
-    if( v != null ) {
-      try {
-        updateOffsets = Boolean.valueOf( v );
-      }
-      catch( Exception ex ) {
-        throw new InitializationException("Error reading updateOffsets value.  Must be true or false.", ex);
-      }
-    }
-  }
-  
-  public TrimFilter create(TokenStream input) {
-    return new TrimFilter(input, updateOffsets);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/TurkishLowerCaseFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/TurkishLowerCaseFilterFactory.java
deleted file mode 100644
index 72fa83b..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/TurkishLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tr.TurkishLowerCaseFilter;
-import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
-import org.apache.lucene.analysis.util.MultiTermAwareComponent;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link TurkishLowerCaseFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_trlwr" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.TurkishLowerCaseFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class TurkishLowerCaseFilterFactory extends TokenFilterFactory  implements MultiTermAwareComponent {
-  public TokenStream create(TokenStream input) {
-    return new TurkishLowerCaseFilter(input);
-  }
-
-  @Override
-  public AbstractAnalysisFactory getMultiTermComponent() {
-    return this;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/TypeAsPayloadTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/TypeAsPayloadTokenFilterFactory.java
deleted file mode 100644
index 9a67fa9..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/TypeAsPayloadTokenFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.payloads.TypeAsPayloadTokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-/** 
- * Factory for {@link TypeAsPayloadTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_typeaspayload" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.TypeAsPayloadTokenFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class TypeAsPayloadTokenFilterFactory extends TokenFilterFactory {
-  public TypeAsPayloadTokenFilter create(TokenStream input) {
-    return new TypeAsPayloadTokenFilter(input);
-  }
-}
-
diff --git a/solr/core/src/java/org/apache/solr/analysis/TypeTokenFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/TypeTokenFilterFactory.java
deleted file mode 100644
index 62c7912..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/TypeTokenFilterFactory.java
+++ /dev/null
@@ -1,85 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.TypeTokenFilter;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.common.util.StrUtils;
-import org.apache.lucene.analysis.util.ResourceLoaderAware;
-import org.apache.lucene.analysis.util.TokenFilterFactory;
-
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-/**
- * Factory class for {@link TypeTokenFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="chars" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
- *     &lt;filter class="solr.TypeTokenFilterFactory" types="stoptypes.txt"
- *                   enablePositionIncrements="true" useWhiteList="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre>
- */
-public class TypeTokenFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-
-  @Override
-  public void inform(ResourceLoader loader) {
-    String stopTypesFiles = args.get("types");
-    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
-    useWhitelist = getBoolean("useWhitelist", false);
-    if (stopTypesFiles != null) {
-      try {
-        List<String> files = StrUtils.splitFileNames(stopTypesFiles);
-        if (files.size() > 0) {
-          stopTypes = new HashSet<String>();
-          for (String file : files) {
-            List<String> typesLines = loader.getLines(file.trim());
-            stopTypes.addAll(typesLines);
-          }
-        }
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading types", e);
-      }
-    } else {
-      throw new InitializationException("Missing required parameter: types.");
-    }
-  }
-
-  private boolean useWhitelist;
-  private Set<String> stopTypes;
-  private boolean enablePositionIncrements;
-
-  public boolean isEnablePositionIncrements() {
-    return enablePositionIncrements;
-  }
-
-  public Set<String> getStopTypes() {
-    return stopTypes;
-  }
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new TypeTokenFilter(enablePositionIncrements, input, stopTypes, useWhitelist);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/UAX29URLEmailTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/UAX29URLEmailTokenizerFactory.java
deleted file mode 100644
index 4c7076f..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/UAX29URLEmailTokenizerFactory.java
+++ /dev/null
@@ -1,59 +0,0 @@
-package org.apache.solr.analysis;
-
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.standard.UAX29URLEmailTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link UAX29URLEmailTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_urlemail" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.UAX29URLEmailTokenizerFactory" maxTokenLength="255"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- * 
- */
-
-public class UAX29URLEmailTokenizerFactory extends TokenizerFactory {
-
-  private int maxTokenLength;
-
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-    maxTokenLength = getInt("maxTokenLength",
-                            StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH);
-  }
-
-  public UAX29URLEmailTokenizer create(Reader input) {
-    UAX29URLEmailTokenizer tokenizer = new UAX29URLEmailTokenizer(luceneMatchVersion, input); 
-    tokenizer.setMaxTokenLength(maxTokenLength);
-    return tokenizer;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/WhitespaceTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/WhitespaceTokenizerFactory.java
deleted file mode 100644
index 47bf213..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/WhitespaceTokenizerFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-
-import java.io.Reader;
-import java.util.Map;
-
-/**
- * Factory for {@link WhitespaceTokenizer}. 
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class WhitespaceTokenizerFactory extends TokenizerFactory {
-  @Override
-  public void init(Map<String,String> args) {
-    super.init(args);
-    assureMatchVersion();
-  }
-
-  public WhitespaceTokenizer create(Reader input) {
-    return new WhitespaceTokenizer(luceneMatchVersion,input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/WikipediaTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/WikipediaTokenizerFactory.java
deleted file mode 100644
index e77b058..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/WikipediaTokenizerFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.TokenizerFactory;
-import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
-
-/** 
- * Factory for {@link WikipediaTokenizer}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_wiki" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WikipediaTokenizerFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class WikipediaTokenizerFactory extends TokenizerFactory {
-  // TODO: add support for WikipediaTokenizer's advanced options.
-  public Tokenizer create(Reader input) {
-    return new WikipediaTokenizer(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java
deleted file mode 100644
index 86239eb..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java
+++ /dev/null
@@ -1,200 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter;
-import org.apache.lucene.analysis.miscellaneous.WordDelimiterIterator;
-import org.apache.lucene.analysis.util.*;
-
-import org.apache.solr.common.util.StrUtils;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.SortedMap;
-import java.util.TreeMap;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import java.io.IOException;
-
-import static org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter.*;
-
-
-/**
- * Factory for {@link WordDelimiterFilter}.
- * <pre class="prettyprint" >
- * &lt;fieldType name="text_wd" class="solr.TextField" positionIncrementGap="100"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.WhitespaceTokenizerFactory"/&gt;
- *     &lt;filter class="solr.WordDelimiterFilterFactory" protected="protectedword.txt"
- *             preserveOriginal="0" splitOnNumerics="1" splitOnCaseChange="1"
- *             catenateWords="0" catenateNumbers="0" catenateAll="0"
- *             generateWordParts="1" generateNumberParts="1" stemEnglishPossessive="1"
- *             types="wdfftypes.txt" /&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;</pre> 
- *
- */
-public class WordDelimiterFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {
-  public static final String PROTECTED_TOKENS = "protected";
-  public static final String TYPES = "types";
-  
-  public void inform(ResourceLoader loader) {
-    String wordFiles = args.get(PROTECTED_TOKENS);
-    if (wordFiles != null) {  
-      try {
-        protectedWords = getWordSet(loader, wordFiles, false);
-      } catch (IOException e) {
-        throw new InitializationException("IOException thrown while loading protected words", e);
-      }
-    }
-    String types = args.get(TYPES);
-    if (types != null) {
-      try {
-        List<String> files = StrUtils.splitFileNames( types );
-        List<String> wlist = new ArrayList<String>();
-        for( String file : files ){
-          List<String> lines = loader.getLines( file.trim() );
-          wlist.addAll( lines );
-        }
-      typeTable = parseTypes(wlist);
-      } catch (IOException e) {
-        throw new InitializationException("IOException while loading types", e);
-      }
-    }
-  }
-
-  private CharArraySet protectedWords = null;
-  private int flags;
-  byte[] typeTable = null;
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    if (getInt("generateWordParts", 1) != 0) {
-      flags |= GENERATE_WORD_PARTS;
-    }
-    if (getInt("generateNumberParts", 1) != 0) {
-      flags |= GENERATE_NUMBER_PARTS;
-    }
-    if (getInt("catenateWords", 0) != 0) {
-      flags |= CATENATE_WORDS;
-    }
-    if (getInt("catenateNumbers", 0) != 0) {
-      flags |= CATENATE_NUMBERS;
-    }
-    if (getInt("catenateAll", 0) != 0) {
-      flags |= CATENATE_ALL;
-    }
-    if (getInt("splitOnCaseChange", 1) != 0) {
-      flags |= SPLIT_ON_CASE_CHANGE;
-    }
-    if (getInt("splitOnNumerics", 1) != 0) {
-      flags |= SPLIT_ON_NUMERICS;
-    }
-    if (getInt("preserveOriginal", 0) != 0) {
-      flags |= PRESERVE_ORIGINAL;
-    }
-    if (getInt("stemEnglishPossessive", 1) != 0) {
-      flags |= STEM_ENGLISH_POSSESSIVE;
-    }
-  }
-
-  public WordDelimiterFilter create(TokenStream input) {
-    return new WordDelimiterFilter(input, typeTable == null ? WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE : typeTable,
-                                   flags, protectedWords);
-  }
-  
-  // source => type
-  private static Pattern typePattern = Pattern.compile( "(.*)\\s*=>\\s*(.*)\\s*$" );
-  
-  // parses a list of MappingCharFilter style rules into a custom byte[] type table
-  private byte[] parseTypes(List<String> rules) {
-    SortedMap<Character,Byte> typeMap = new TreeMap<Character,Byte>();
-    for( String rule : rules ){
-      Matcher m = typePattern.matcher(rule);
-      if( !m.find() )
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]");
-      String lhs = parseString(m.group(1).trim());
-      Byte rhs = parseType(m.group(2).trim());
-      if (lhs.length() != 1)
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Only a single character is allowed.");
-      if (rhs == null)
-        throw new InitializationException("Invalid Mapping Rule : [" + rule + "]. Illegal type.");
-      typeMap.put(lhs.charAt(0), rhs);
-    }
-    
-    // ensure the table is always at least as big as DEFAULT_WORD_DELIM_TABLE for performance
-    byte types[] = new byte[Math.max(typeMap.lastKey()+1, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE.length)];
-    for (int i = 0; i < types.length; i++)
-      types[i] = WordDelimiterIterator.getType(i);
-    for (Map.Entry<Character,Byte> mapping : typeMap.entrySet())
-      types[mapping.getKey()] = mapping.getValue();
-    return types;
-  }
-  
-  private Byte parseType(String s) {
-    if (s.equals("LOWER"))
-      return LOWER;
-    else if (s.equals("UPPER"))
-      return UPPER;
-    else if (s.equals("ALPHA"))
-      return ALPHA;
-    else if (s.equals("DIGIT"))
-      return DIGIT;
-    else if (s.equals("ALPHANUM"))
-      return ALPHANUM;
-    else if (s.equals("SUBWORD_DELIM"))
-      return SUBWORD_DELIM;
-    else
-      return null;
-  }
-  
-  char[] out = new char[256];
-  
-  private String parseString(String s){
-    int readPos = 0;
-    int len = s.length();
-    int writePos = 0;
-    while( readPos < len ){
-      char c = s.charAt( readPos++ );
-      if( c == '\\' ){
-        if( readPos >= len )
-          throw new InitializationException("Invalid escaped char in [" + s + "]");
-        c = s.charAt( readPos++ );
-        switch( c ) {
-          case '\\' : c = '\\'; break;
-          case 'n' : c = '\n'; break;
-          case 't' : c = '\t'; break;
-          case 'r' : c = '\r'; break;
-          case 'b' : c = '\b'; break;
-          case 'f' : c = '\f'; break;
-          case 'u' :
-            if( readPos + 3 >= len )
-              throw new InitializationException("Invalid escaped char in [" + s + "]");
-            c = (char)Integer.parseInt( s.substring( readPos, readPos + 4 ), 16 );
-            readPos += 4;
-            break;
-        }
-      }
-      out[writePos++] = c;
-    }
-    return new String( out, 0, writePos );
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/CommonGramsFilterFactoryTest.java b/solr/core/src/test/org/apache/solr/analysis/CommonGramsFilterFactoryTest.java
deleted file mode 100644
index 27841e7..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/CommonGramsFilterFactoryTest.java
+++ /dev/null
@@ -1,106 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-import java.util.HashMap;
-
-/**
- * Tests pretty much copied from StopFilterFactoryTest We use the test files
- * used by the StopFilterFactoryTest TODO: consider creating separate test files
- * so this won't break if stop filter test files change
- **/
-public class CommonGramsFilterFactoryTest extends BaseTokenStreamTestCase {
-
-  public void testInform() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    CommonGramsFilterFactory factory = new CommonGramsFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("words", "stop-1.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 2,
-        words.size() == 2);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
-        .isIgnoreCase() == true);
-
-    factory = new CommonGramsFilterFactory();
-    args.put("words", "stop-1.txt, stop-2.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 4,
-        words.size() == 4);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
-        .isIgnoreCase() == true);
-
-    factory = new CommonGramsFilterFactory();
-    args.put("words", "stop-snowball.txt");
-    args.put("format", "snowball");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getCommonWords();
-    assertEquals(8, words.size());
-    assertTrue(words.contains("he"));
-    assertTrue(words.contains("him"));
-    assertTrue(words.contains("his"));
-    assertTrue(words.contains("himself"));
-    assertTrue(words.contains("she"));
-    assertTrue(words.contains("her"));
-    assertTrue(words.contains("hers"));
-    assertTrue(words.contains("herself"));
-  }
-  
-  /**
-   * If no words are provided, then a set of english default stopwords is used.
-   */
-  public void testDefaults() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    CommonGramsFilterFactory factory = new CommonGramsFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue(words.contains("the"));
-    Tokenizer tokenizer = new MockTokenizer(new StringReader("testing the factory"), MockTokenizer.WHITESPACE, false);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, 
-        new String[] { "testing", "testing_the", "the", "the_factory", "factory" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/CommonGramsQueryFilterFactoryTest.java b/solr/core/src/test/org/apache/solr/analysis/CommonGramsQueryFilterFactoryTest.java
deleted file mode 100644
index f648432..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/CommonGramsQueryFilterFactoryTest.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-import java.util.HashMap;
-
-/**
- * Tests pretty much copied from StopFilterFactoryTest We use the test files
- * used by the StopFilterFactoryTest TODO: consider creating separate test files
- * so this won't break if stop filter test files change
- **/
-public class CommonGramsQueryFilterFactoryTest extends BaseTokenStreamTestCase {
-
-  public void testInform() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    CommonGramsQueryFilterFactory factory = new CommonGramsQueryFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("words", "stop-1.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 2,
-        words.size() == 2);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
-        .isIgnoreCase() == true);
-
-    factory = new CommonGramsQueryFilterFactory();
-    args.put("words", "stop-1.txt, stop-2.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 4,
-        words.size() == 4);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory
-        .isIgnoreCase() == true);
-
-    factory = new CommonGramsQueryFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    args.put("words", "stop-snowball.txt");
-    args.put("format", "snowball");
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getCommonWords();
-    assertEquals(8, words.size());
-    assertTrue(words.contains("he"));
-    assertTrue(words.contains("him"));
-    assertTrue(words.contains("his"));
-    assertTrue(words.contains("himself"));
-    assertTrue(words.contains("she"));
-    assertTrue(words.contains("her"));
-    assertTrue(words.contains("hers"));
-    assertTrue(words.contains("herself"));
-  }
-  
-  /**
-   * If no words are provided, then a set of english default stopwords is used.
-   */
-  public void testDefaults() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    CommonGramsQueryFilterFactory factory = new CommonGramsQueryFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getCommonWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue(words.contains("the"));
-    Tokenizer tokenizer = new MockTokenizer(new StringReader("testing the factory"), MockTokenizer.WHITESPACE, false);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, 
-        new String[] { "testing_the", "the_factory" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/DoubleMetaphoneFilterFactoryTest.java b/solr/core/src/test/org/apache/solr/analysis/DoubleMetaphoneFilterFactoryTest.java
deleted file mode 100644
index 7b08dbb..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/DoubleMetaphoneFilterFactoryTest.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.phonetic.DoubleMetaphoneFilter;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-public class DoubleMetaphoneFilterFactoryTest extends BaseTokenStreamTestCase {
-
-  public void testDefaults() throws Exception {
-    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
-    factory.init(new HashMap<String, String>());
-    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
-
-    TokenStream filteredStream = factory.create(inputStream);
-    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
-    assertTokenStreamContents(filteredStream, new String[] { "international", "ANTR" });
-  }
-
-  public void testSettingSizeAndInject() throws Exception {
-    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
-    Map<String, String> parameters = new HashMap<String, String>();
-    parameters.put("inject", "false");
-    parameters.put("maxCodeLength", "8");
-    factory.init(parameters);
-
-    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
-
-    TokenStream filteredStream = factory.create(inputStream);
-    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
-    assertTokenStreamContents(filteredStream, new String[] { "ANTRNXNL" });
-  }
-  
-  /**
-   * Ensure that reset() removes any state (buffered tokens)
-   */
-  public void testReset() throws Exception {
-    DoubleMetaphoneFilterFactory factory = new DoubleMetaphoneFilterFactory();
-    factory.init(new HashMap<String, String>());
-    TokenStream inputStream = new MockTokenizer(new StringReader("international"), MockTokenizer.WHITESPACE, false);
-
-    TokenStream filteredStream = factory.create(inputStream);
-    CharTermAttribute termAtt = filteredStream.addAttribute(CharTermAttribute.class);
-    assertEquals(DoubleMetaphoneFilter.class, filteredStream.getClass());
-    
-    filteredStream.reset();
-    assertTrue(filteredStream.incrementToken());
-    assertEquals(13, termAtt.length());
-    assertEquals("international", termAtt.toString());
-    filteredStream.reset();
-    
-    // ensure there are no more tokens, such as ANTRNXNL
-    assertFalse(filteredStream.incrementToken());
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/LengthFilterTest.java b/solr/core/src/test/org/apache/solr/analysis/LengthFilterTest.java
deleted file mode 100644
index 30f2f12..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/LengthFilterTest.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Copyright 2004 The Apache Software Foundation
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-public class LengthFilterTest extends BaseTokenStreamTestCase {
-
-  public void test() throws IOException {
-    LengthFilterFactory factory = new LengthFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put(LengthFilterFactory.MIN_KEY, String.valueOf(4));
-    args.put(LengthFilterFactory.MAX_KEY, String.valueOf(10));
-    // default: args.put("enablePositionIncrements", "false");
-    factory.init(args);
-    String test = "foo foobar super-duper-trooper";
-    TokenStream stream = factory.create(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "foobar" }, new int[] { 1 });
-
-    factory = new LengthFilterFactory();
-    args = new HashMap<String, String>();
-    args.put(LengthFilterFactory.MIN_KEY, String.valueOf(4));
-    args.put(LengthFilterFactory.MAX_KEY, String.valueOf(10));
-    args.put("enablePositionIncrements", "true");
-    factory.init(args);
-    stream = factory.create(new MockTokenizer(new StringReader(test), MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "foobar" }, new int[] { 2 });
-  }
-}
\ No newline at end of file
diff --git a/solr/core/src/test/org/apache/solr/analysis/SnowballPorterFilterFactoryTest.java b/solr/core/src/test/org/apache/solr/analysis/SnowballPorterFilterFactoryTest.java
deleted file mode 100644
index c906551..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/SnowballPorterFilterFactoryTest.java
+++ /dev/null
@@ -1,101 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Copyright 2004 The Apache Software Foundation
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.common.util.StrUtils;
-import org.apache.solr.core.SolrResourceLoader;
-import org.tartarus.snowball.ext.EnglishStemmer;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.ArrayList;
-
-public class SnowballPorterFilterFactoryTest extends BaseTokenStreamTestCase {
-
-  public void test() throws IOException {
-    EnglishStemmer stemmer = new EnglishStemmer();
-    String[] test = {"The", "fledgling", "banks", "were", "counting", "on", "a", "big", "boom", "in", "banking"};
-    String[] gold = new String[test.length];
-    for (int i = 0; i < test.length; i++) {
-      stemmer.setCurrent(test[i]);
-      stemmer.stem();
-      gold[i] = stemmer.getCurrent();
-    }
-
-    SnowballPorterFilterFactory factory = new SnowballPorterFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("language", "English");
-
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(new LinesMockSolrResourceLoader(new ArrayList<String>()));
-    Tokenizer tokenizer = new MockTokenizer(
-        new StringReader(StrUtils.join(Arrays.asList(test), ' ')), MockTokenizer.WHITESPACE, false);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, gold);
-  }
-
-  class LinesMockSolrResourceLoader implements ResourceLoader {
-    List<String> lines;
-
-    LinesMockSolrResourceLoader(List<String> lines) {
-      this.lines = lines;
-    }
-
-    public List<String> getLines(String resource) throws IOException {
-      return lines;
-    }
-
-    public <T> T newInstance(String cname, Class<T> expectedType, String... subpackages) {
-      return null;
-    }
-
-    public InputStream openResource(String resource) throws IOException {
-      return null;
-    }
-  }
-  
-  /**
-   * Test the protected words mechanism of SnowballPorterFilterFactory
-   */
-  public void testProtected() throws Exception {
-    SnowballPorterFilterFactory factory = new SnowballPorterFilterFactory();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("protected", "protwords.txt");
-    args.put("language", "English");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    Reader reader = new StringReader("ridding of some stemming");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "ridding", "of", "some", "stem" });
-  }
-}
-
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestBeiderMorseFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestBeiderMorseFilterFactory.java
deleted file mode 100644
index eaff03d..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestBeiderMorseFilterFactory.java
+++ /dev/null
@@ -1,70 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/** Simple tests for {@link BeiderMorseFilterFactory} */
-public class TestBeiderMorseFilterFactory extends BaseTokenStreamTestCase {
-  public void testBasics() throws Exception {
-    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(ts,
-        new String[] { "vDnbirk", "vanbirk", "vinbirk", "wDnbirk", "wanbirk", "winbirk" },
-        new int[] { 0, 0, 0, 0, 0, 0 },
-        new int[] { 8, 8, 8, 8, 8, 8 },
-        new int[] { 1, 0, 0, 0, 0, 0 });
-  }
-  
-  public void testLanguageSet() throws Exception {
-    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("languageSet", "polish");
-    factory.init(args);
-    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(ts,
-        new String[] { "vDmbYrk", "vDmbirk", "vambYrk", "vambirk", "vimbYrk", "vimbirk" },
-        new int[] { 0, 0, 0, 0, 0, 0 },
-        new int[] { 8, 8, 8, 8, 8, 8 },
-        new int[] { 1, 0, 0, 0, 0, 0 });
-  }
-  
-  public void testOptions() throws Exception {
-    BeiderMorseFilterFactory factory = new BeiderMorseFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("nameType", "ASHKENAZI");
-    args.put("ruleType", "EXACT");
-    factory.init(args);
-    TokenStream ts = factory.create(new MockTokenizer(new StringReader("Weinberg"), MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(ts,
-        new String[] { "vajnberk" },
-        new int[] { 0 },
-        new int[] { 8 },
-        new int[] { 1 });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestBrazilianStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestBrazilianStemFilterFactory.java
deleted file mode 100644
index 0511265..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestBrazilianStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Brazilian stem filter factory is working.
- */
-public class TestBrazilianStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems and normalizes text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("Braslia");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    BrazilianStemFilterFactory factory = new BrazilianStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "brasil" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestBulgarianStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestBulgarianStemFilterFactory.java
deleted file mode 100644
index 7be02eb..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestBulgarianStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Bulgarian stem filter factory is working.
- */
-public class TestBulgarianStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("???");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    BulgarianStemFilterFactory factory = new BulgarianStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "???" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestCJKWidthFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestCJKWidthFilterFactory.java
deleted file mode 100644
index 0de6588..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestCJKWidthFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the CJKWidthFilterFactory is working
- */
-public class TestCJKWidthFilterFactory extends BaseTokenStreamTestCase {
-  public void test() throws Exception {
-    Reader reader = new StringReader("??? ????");
-    CJKWidthFilterFactory factory = new CJKWidthFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "Test", "1234" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory.java
deleted file mode 100644
index 55f3c9f..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestCapitalizationFilterFactory.java
+++ /dev/null
@@ -1,224 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-
-/**
- * 
- */
-public class TestCapitalizationFilterFactory extends BaseTokenStreamTestCase {
-  
-  public void testCapitalization() throws Exception 
-  {
-    Map<String,String> args = new HashMap<String, String>();
-    args.put( CapitalizationFilterFactory.KEEP, "and the it BIG" );
-    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, "true" );  
-    
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init( args );
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "Kitten" });
-    
-    factory.forceFirstLetter = true;
-
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("and"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "And" });
-
-    //first is forced, but it's not a keep word, either
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "And" });
-
-    factory.forceFirstLetter = false;
-
-    //first is not forced, but it's not a keep word, either
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("AnD"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "And" });
-
-    factory.forceFirstLetter = true;
-    
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("big"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "Big" });
-    
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("BIG"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "BIG" });
-
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.KEYWORD, false)),
-        new String[] { "Hello there my name is ryan" });
-        
-    // now each token
-    factory.onlyFirstWord = false;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "Hello", "There", "My", "Name", "Is", "Ryan" });
-    
-    // now only the long words
-    factory.minWordLength = 3;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("Hello thEre my Name is Ryan"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "Hello", "There", "my", "Name", "is", "Ryan" });
-    
-    // without prefix
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "Mckinley" });
-    
-    // Now try some prefixes
-    factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    args.put( "okPrefix", "McK" );  // all words
-    factory.init( args );
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("McKinley"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "McKinley" });
-    
-    // now try some stuff with numbers
-    factory.forceFirstLetter = false;
-    factory.onlyFirstWord = false;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("1st 2nd third"), MockTokenizer.WHITESPACE, false)),
-        new String[] { "1st", "2nd", "Third" });
-    
-    factory.forceFirstLetter = true;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("the The the"), MockTokenizer.KEYWORD, false)),
-        new String[] { "The The the" });
-  }
-
-  public void testKeepIgnoreCase() throws Exception {
-    Map<String,String> args = new HashMap<String, String>();
-    args.put( CapitalizationFilterFactory.KEEP, "kitten" );
-    args.put( CapitalizationFilterFactory.KEEP_IGNORE_CASE, "true" );
-    args.put( CapitalizationFilterFactory.ONLY_FIRST_WORD, "true" );
-
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init( args );
-    factory.forceFirstLetter = true;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
-        new String[] { "KiTTEN" });
-
-    factory.forceFirstLetter = false;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
-        new String[] { "kiTTEN" });
-
-    factory.keep = null;
-    assertTokenStreamContents(factory.create(
-        new MockTokenizer(new StringReader("kiTTEN"), MockTokenizer.KEYWORD, false)),
-        new String[] { "Kitten" });
-  }
-  
-  /**
-   * Test CapitalizationFilterFactory's minWordLength option.
-   * 
-   * This is very weird when combined with ONLY_FIRST_WORD!!!
-   */
-  public void testMinWordLength() throws Exception {
-    Map<String,String> args = new HashMap<String,String>();
-    args.put(CapitalizationFilterFactory.ONLY_FIRST_WORD, "true");
-    args.put(CapitalizationFilterFactory.MIN_WORD_LENGTH, "5");
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer tokenizer = new MockTokenizer(new StringReader(
-        "helo testing"), MockTokenizer.WHITESPACE, false);
-    TokenStream ts = factory.create(tokenizer);
-    assertTokenStreamContents(ts, new String[] {"helo", "Testing"});
-  }
-  
-  /**
-   * Test CapitalizationFilterFactory's maxWordCount option with only words of 1
-   * in each token (it should do nothing)
-   */
-  public void testMaxWordCount() throws Exception {
-    Map<String,String> args = new HashMap<String,String>();
-    args.put(CapitalizationFilterFactory.MAX_WORD_COUNT, "2");
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer tokenizer = new MockTokenizer(new StringReader(
-        "one two three four"), MockTokenizer.WHITESPACE, false);
-    TokenStream ts = factory.create(tokenizer);
-    assertTokenStreamContents(ts, new String[] {"One", "Two", "Three", "Four"});
-  }
-  
-  /**
-   * Test CapitalizationFilterFactory's maxWordCount option when exceeded
-   */
-  public void testMaxWordCount2() throws Exception {
-    Map<String,String> args = new HashMap<String,String>();
-    args.put(CapitalizationFilterFactory.MAX_WORD_COUNT, "2");
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer tokenizer = new MockTokenizer(new StringReader(
-        "one two three four"), MockTokenizer.KEYWORD, false);
-    TokenStream ts = factory.create(tokenizer);
-    assertTokenStreamContents(ts, new String[] {"one two three four"});
-  }
-  
-  /**
-   * Test CapitalizationFilterFactory's maxTokenLength option when exceeded
-   * 
-   * This is weird, it is not really a max, but inclusive (look at 'is')
-   */
-  public void testMaxTokenLength() throws Exception {
-    Map<String,String> args = new HashMap<String,String>();
-    args.put(CapitalizationFilterFactory.MAX_TOKEN_LENGTH, "2");
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer tokenizer = new MockTokenizer(new StringReader(
-        "this is a test"), MockTokenizer.WHITESPACE, false);
-    TokenStream ts = factory.create(tokenizer);
-    assertTokenStreamContents(ts, new String[] {"this", "is", "A", "test"});
-  }
-  
-  /**
-   * Test CapitalizationFilterFactory's forceFirstLetter option
-   */
-  public void testForceFirstLetter() throws Exception {
-    Map<String,String> args = new HashMap<String,String>();
-    args.put(CapitalizationFilterFactory.KEEP, "kitten");
-    args.put(CapitalizationFilterFactory.FORCE_FIRST_LETTER, "true");
-    CapitalizationFilterFactory factory = new CapitalizationFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer tokenizer = new MockTokenizer(new StringReader("kitten"), MockTokenizer.WHITESPACE, false);
-    TokenStream ts = factory.create(tokenizer);
-    assertTokenStreamContents(ts, new String[] {"Kitten"});
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestCzechStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestCzechStemFilterFactory.java
deleted file mode 100644
index 2893d46..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestCzechStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Czech stem filter factory is working.
- */
-public class TestCzechStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("angli?t");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    CzechStemFilterFactory factory = new CzechStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "anglick" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestDelimitedPayloadTokenFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestDelimitedPayloadTokenFilterFactory.java
deleted file mode 100644
index 9644959..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestDelimitedPayloadTokenFilterFactory.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.payloads.DelimitedPayloadTokenFilter;
-import org.apache.lucene.analysis.payloads.FloatEncoder;
-import org.apache.lucene.analysis.payloads.PayloadHelper;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-public class TestDelimitedPayloadTokenFilterFactory extends BaseTokenStreamTestCase {
-
-  public void testEncoder() throws Exception {
-    Map<String,String> args = new HashMap<String, String>();
-    args.put(DelimitedPayloadTokenFilterFactory.ENCODER_ATTR, "float");
-    DelimitedPayloadTokenFilterFactory factory = new DelimitedPayloadTokenFilterFactory();
-    factory.init(args);
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    factory.inform(loader);
-
-    TokenStream input = new MockTokenizer(new StringReader("the|0.1 quick|0.1 red|0.1"), MockTokenizer.WHITESPACE, false);
-    DelimitedPayloadTokenFilter tf = factory.create(input);
-    tf.reset();
-    while (tf.incrementToken()){
-      PayloadAttribute payAttr = tf.getAttribute(PayloadAttribute.class);
-      assertTrue("payAttr is null and it shouldn't be", payAttr != null);
-      byte[] payData = payAttr.getPayload().bytes;
-      assertTrue("payData is null and it shouldn't be", payData != null);
-      assertTrue("payData is null and it shouldn't be", payData != null);
-      float payFloat = PayloadHelper.decodeFloat(payData);
-      assertTrue(payFloat + " does not equal: " + 0.1f, payFloat == 0.1f);
-    }
-  }
-
-  public void testDelim() throws Exception {
-    Map<String,String> args = new HashMap<String, String>();
-    args.put(DelimitedPayloadTokenFilterFactory.ENCODER_ATTR, FloatEncoder.class.getName());
-    args.put(DelimitedPayloadTokenFilterFactory.DELIMITER_ATTR, "*");
-    DelimitedPayloadTokenFilterFactory factory = new DelimitedPayloadTokenFilterFactory();
-    factory.init(args);
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    factory.inform(loader);
-
-    TokenStream input = new MockTokenizer(new StringReader("the*0.1 quick*0.1 red*0.1"), MockTokenizer.WHITESPACE, false);
-    DelimitedPayloadTokenFilter tf = factory.create(input);
-    tf.reset();
-    while (tf.incrementToken()){
-      PayloadAttribute payAttr = tf.getAttribute(PayloadAttribute.class);
-      assertTrue("payAttr is null and it shouldn't be", payAttr != null);
-      byte[] payData = payAttr.getPayload().bytes;
-      assertTrue("payData is null and it shouldn't be", payData != null);
-      float payFloat = PayloadHelper.decodeFloat(payData);
-      assertTrue(payFloat + " does not equal: " + 0.1f, payFloat == 0.1f);
-    }
-  }
-}
-
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestDictionaryCompoundWordTokenFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestDictionaryCompoundWordTokenFilterFactory.java
deleted file mode 100644
index 8b7832d..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestDictionaryCompoundWordTokenFilterFactory.java
+++ /dev/null
@@ -1,54 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests to ensure the Dictionary compound filter factory is working.
- */
-public class TestDictionaryCompoundWordTokenFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually decompounds text.
-   */
-  public void testDecompounding() throws Exception {
-    Reader reader = new StringReader("I like to play softball");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    DictionaryCompoundWordTokenFilterFactory factory = new DictionaryCompoundWordTokenFilterFactory();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("dictionary", "compoundDictionary.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, 
-        new String[] { "I", "like", "to", "play", "softball", "soft", "ball" });
-  }
-  
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java
deleted file mode 100644
index 95c061f..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java
+++ /dev/null
@@ -1,88 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests to ensure the French elision filter factory is working.
- */
-public class TestElisionFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually normalizes text.
-   */
-  public void testElision() throws Exception {
-    Reader reader = new StringReader("l'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("articles", "frenchArticles.txt");
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-  /**
-   * Test creating an elision filter without specifying any articles
-   */
-  public void testDefaultArticles() throws Exception {
-    Reader reader = new StringReader("l'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-  /**
-   * Test setting ignoreCase=true
-   */
-  public void testCaseInsensitive() throws Exception {
-    Reader reader = new StringReader("L'avion");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ElisionFilterFactory factory = new ElisionFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("articles", "frenchArticles.txt");
-    args.put("ignoreCase", "true");
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "avion" });
-  }
-  
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestEnglishMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestEnglishMinimalStemFilterFactory.java
deleted file mode 100644
index 806d036..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestEnglishMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the English minimal stem factory is working.
- */
-public class TestEnglishMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("bricks");
-    EnglishMinimalStemFilterFactory factory = new EnglishMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "brick" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestFinnishLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestFinnishLightStemFilterFactory.java
deleted file mode 100644
index c345f3f..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestFinnishLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Finnish light stem factory is working.
- */
-public class TestFinnishLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("aseistettujen");
-    FinnishLightStemFilterFactory factory = new FinnishLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "aseistet" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestFrenchLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestFrenchLightStemFilterFactory.java
deleted file mode 100644
index 784bf13..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestFrenchLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the French light stem factory is working.
- */
-public class TestFrenchLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("administrativement");
-    FrenchLightStemFilterFactory factory = new FrenchLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "administratif" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestFrenchMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestFrenchMinimalStemFilterFactory.java
deleted file mode 100644
index db869c2..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestFrenchMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the French minimal stem factory is working.
- */
-public class TestFrenchMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("chevaux");
-    FrenchMinimalStemFilterFactory factory = new FrenchMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "cheval" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java
deleted file mode 100644
index 8cd0933..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Galician plural stem factory is working.
- */
-public class TestGalicianMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("elefantes");
-    GalicianMinimalStemFilterFactory factory = new GalicianMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "elefante" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGalicianStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGalicianStemFilterFactory.java
deleted file mode 100644
index 1eafa38..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGalicianStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Galician stem factory is working.
- */
-public class TestGalicianStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("cariosa");
-    GalicianStemFilterFactory factory = new GalicianStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "cari" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGermanLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGermanLightStemFilterFactory.java
deleted file mode 100644
index 6524b36..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGermanLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the German light stem factory is working.
- */
-public class TestGermanLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("huser");
-    GermanLightStemFilterFactory factory = new GermanLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "haus" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGermanMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGermanMinimalStemFilterFactory.java
deleted file mode 100644
index 62f8a68..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGermanMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the German minimal stem factory is working.
- */
-public class TestGermanMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("bilder");
-    GermanMinimalStemFilterFactory factory = new GermanMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "bild" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java
deleted file mode 100644
index ecfecc4..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the German normalization factory is working.
- */
-public class TestGermanNormalizationFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("wei?bier");
-    GermanNormalizationFilterFactory factory = new GermanNormalizationFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "weissbier" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGermanStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGermanStemFilterFactory.java
deleted file mode 100644
index 39b1d78..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGermanStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the German stem filter factory is working.
- */
-public class TestGermanStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("Tischen");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    GermanStemFilterFactory factory = new GermanStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "tisch" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGreekLowerCaseFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGreekLowerCaseFilterFactory.java
deleted file mode 100644
index b33a6eb..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGreekLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Greek lowercase filter factory is working.
- */
-public class TestGreekLowerCaseFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually lowercases (and a bit more) greek text.
-   */
-  public void testNormalization() throws Exception {
-    Reader reader = new StringReader("??? ???");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    GreekLowerCaseFilterFactory factory = new GreekLowerCaseFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "?", "?" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGreekStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGreekStemFilterFactory.java
deleted file mode 100644
index 82a7e38..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestGreekStemFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.el.GreekLowerCaseFilter;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Simple tests to ensure the Greek stem filter factory is working.
- */
-public class TestGreekStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("????");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    TokenStream normalized = new GreekLowerCaseFilter(TEST_VERSION_CURRENT, tokenizer);
-    GreekStemFilterFactory factory = new GreekStemFilterFactory();
-    TokenStream stream = factory.create(normalized);
-    assertTokenStreamContents(stream, new String[] { "???" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java
deleted file mode 100644
index da7f390..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java
+++ /dev/null
@@ -1,127 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.*;
-
-/**
- * Simple tests to ensure this factory is working
- */
-public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
-
-
-  public void testNothingChanged() throws IOException {
-    //                             11111111112
-    //                   012345678901234567890
-    final String text = "this is only a test.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("escapedTags", "a, Title");
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "only", "a", "test." },
-        new int[] { 0, 5,  8, 13, 15 },
-        new int[] { 4, 7, 12, 14, 20 });
-  }
-
-  public void testNoEscapedTags() throws IOException {
-    //                             11111111112222222222333333333344
-    //                   012345678901234567890123456789012345678901
-    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "only", "a", "test." },
-        new int[] {  3, 12, 18, 27, 32 },
-        new int[] { 11, 14, 26, 28, 41 });
-  }
-
-  public void testEscapedTags() throws IOException {
-    //                             11111111112222222222333333333344
-    //                   012345678901234567890123456789012345678901
-    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("escapedTags", "U i");
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "<u>this</u>", "is", "only", "a", "<I>test</I>." },
-        new int[] {  0, 12, 18, 27, 29 },
-        new int[] { 11, 14, 26, 28, 41 });
-  }
-
-  public void testSeparatorOnlyEscapedTags() throws IOException {
-    //                             11111111112222222222333333333344
-    //                   012345678901234567890123456789012345678901
-    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("escapedTags", ",, , ");
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "only", "a", "test." },
-        new int[] {  3, 12, 18, 27, 32 },
-        new int[] { 11, 14, 26, 28, 41 });
-  }
-
-  public void testEmptyEscapedTags() throws IOException {
-    //                             11111111112222222222333333333344
-    //                   012345678901234567890123456789012345678901
-    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("escapedTags", "");
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "only", "a", "test." },
-        new int[] {  3, 12, 18, 27, 32 },
-        new int[] { 11, 14, 26, 28, 41 });
-  }
-
-  public void testSingleEscapedTag() throws IOException {
-    //                             11111111112222222222333333333344
-    //                   012345678901234567890123456789012345678901
-    final String text = "<u>this</u> is <b>only</b> a <I>test</I>.";
-    HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("escapedTags", ", B\r\n\t");
-    factory.init(args);
-    CharFilter cs = factory.create(new StringReader(text));
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "<b>only</b>", "a", "test." },
-        new int[] {  3, 12, 15, 27, 32 },
-        new int[] { 11, 14, 26, 28, 41 });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHindiFilters.java b/solr/core/src/test/org/apache/solr/analysis/TestHindiFilters.java
deleted file mode 100644
index 4c40a6f..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestHindiFilters.java
+++ /dev/null
@@ -1,89 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Hindi filter Factories are working.
- */
-public class TestHindiFilters extends BaseTokenStreamTestCase {
-  /**
-   * Test IndicNormalizationFilterFactory
-   */
-  public void testIndicNormalizer() throws Exception {
-    Reader reader = new StringReader("??? ??");
-    StandardTokenizerFactory factory = new StandardTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    IndicNormalizationFilterFactory filterFactory = new IndicNormalizationFilterFactory();
-    filterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    filterFactory.init(args);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = filterFactory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "?", "?" });
-  }
-  
-  /**
-   * Test HindiNormalizationFilterFactory
-   */
-  public void testHindiNormalizer() throws Exception {
-    Reader reader = new StringReader("??");
-    StandardTokenizerFactory factory = new StandardTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    IndicNormalizationFilterFactory indicFilterFactory = new IndicNormalizationFilterFactory();
-    HindiNormalizationFilterFactory hindiFilterFactory = new HindiNormalizationFilterFactory();
-    hindiFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    hindiFilterFactory.init(args);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = indicFilterFactory.create(tokenizer);
-    stream = hindiFilterFactory.create(stream);
-    assertTokenStreamContents(stream, new String[] {"??"});
-  }
-  
-  /**
-   * Test HindiStemFilterFactory
-   */
-  public void testStemmer() throws Exception {
-    Reader reader = new StringReader("????");
-    StandardTokenizerFactory factory = new StandardTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    IndicNormalizationFilterFactory indicFilterFactory = new IndicNormalizationFilterFactory();
-    HindiNormalizationFilterFactory hindiFilterFactory = new HindiNormalizationFilterFactory();
-    HindiStemFilterFactory stemFactory = new HindiStemFilterFactory();
-    stemFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    stemFactory.init(args);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = indicFilterFactory.create(tokenizer);
-    stream = hindiFilterFactory.create(stream);
-    stream = stemFactory.create(stream);
-    assertTokenStreamContents(stream, new String[] {"??"});
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHungarianLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestHungarianLightStemFilterFactory.java
deleted file mode 100644
index ae79afc..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestHungarianLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Hungarian light stem factory is working.
- */
-public class TestHungarianLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("hzakat");
-    HungarianLightStemFilterFactory factory = new HungarianLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "haz" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHunspellStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestHunspellStemFilterFactory.java
deleted file mode 100644
index b5f33b4..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestHunspellStemFilterFactory.java
+++ /dev/null
@@ -1,48 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.solr.core.SolrResourceLoader;
-import org.apache.solr.schema.IndexSchema;
-
-/**
- * Simple tests to ensure the Hunspell stemmer loads from factory
- */
-public class TestHunspellStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    HunspellStemFilterFactory factory = new HunspellStemFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("dictionary", "hunspell-test.dic");
-    args.put("affix", "hunspell-test.aff");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(new SolrResourceLoader("solr/collection1"));
-    
-    Reader reader = new StringReader("abc");
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "ab" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHyphenationCompoundWordTokenFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestHyphenationCompoundWordTokenFilterFactory.java
deleted file mode 100644
index 30a282c..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestHyphenationCompoundWordTokenFilterFactory.java
+++ /dev/null
@@ -1,81 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests to ensure the Hyphenation compound filter factory is working.
- */
-public class TestHyphenationCompoundWordTokenFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the factory works with hyphenation grammar+dictionary: using default options.
-   */
-  public void testHyphenationWithDictionary() throws Exception {
-    Reader reader = new StringReader("min veninde som er lidt af en lsehest");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    HyphenationCompoundWordTokenFilterFactory factory = new HyphenationCompoundWordTokenFilterFactory();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("hyphenator", "da_UTF8.xml");
-    args.put("dictionary", "da_compoundDictionary.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    
-    assertTokenStreamContents(stream, 
-        new String[] { "min", "veninde", "som", "er", "lidt", "af", "en", "lsehest", "lse", "hest" },
-        new int[] { 1, 1, 1, 1, 1, 1, 1, 1, 0, 0 }
-    );
-  }
-
-  /**
-   * Ensure the factory works with no dictionary: using hyphenation grammar only.
-   * Also change the min/max subword sizes from the default. When using no dictionary,
-   * its generally necessary to tweak these, or you get lots of expansions.
-   */
-  public void testHyphenationOnly() throws Exception {
-    Reader reader = new StringReader("basketballkurv");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    HyphenationCompoundWordTokenFilterFactory factory = new HyphenationCompoundWordTokenFilterFactory();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("hyphenator", "da_UTF8.xml");
-    args.put("minSubwordSize", "2");
-    args.put("maxSubwordSize", "4");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    TokenStream stream = factory.create(tokenizer);
-    
-    assertTokenStreamContents(stream,
-        new String[] { "basketballkurv", "ba", "sket", "bal", "ball", "kurv" }
-    );
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestIndonesianStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestIndonesianStemFilterFactory.java
deleted file mode 100644
index 1233d6b..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestIndonesianStemFilterFactory.java
+++ /dev/null
@@ -1,60 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Indonesian stem filter factory is working.
- */
-public class TestIndonesianStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("dibukukannya");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    IndonesianStemFilterFactory factory = new IndonesianStemFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "buku" });
-  }
-  
-  /**
-   * Test inflectional-only mode
-   */
-  public void testStemmingInflectional() throws Exception {
-    Reader reader = new StringReader("dibukukannya");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    IndonesianStemFilterFactory factory = new IndonesianStemFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("stemDerivational", "false");
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "dibukukan" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestIrishLowerCaseFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestIrishLowerCaseFilterFactory.java
deleted file mode 100644
index e429d91..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestIrishLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Irish lowercase filter factory is working.
- */
-public class TestIrishLowerCaseFilterFactory extends BaseTokenStreamTestCase {
-  public void testCasing() throws Exception {
-    Reader reader = new StringReader("nAthair tUISCE hARD");
-    IrishLowerCaseFilterFactory factory = new IrishLowerCaseFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "n-athair", "t-uisce", "hard" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestItalianLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestItalianLightStemFilterFactory.java
deleted file mode 100644
index 7787e0b..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestItalianLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Italian light stem factory is working.
- */
-public class TestItalianLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("ragazzo ragazzi");
-    ItalianLightStemFilterFactory factory = new ItalianLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "ragazz", "ragazz" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseBaseFormFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestJapaneseBaseFormFilterFactory.java
deleted file mode 100644
index 6bb5c26..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseBaseFormFilterFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests for {@link JapaneseBaseFormFilterFactory}
- */
-public class TestJapaneseBaseFormFilterFactory extends BaseTokenStreamTestCase {
-  public void testBasics() throws IOException {
-    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
-    tokenizerFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    tokenizerFactory.init(args);
-    tokenizerFactory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = tokenizerFactory.create(new StringReader("???????????????????"));
-    JapaneseBaseFormFilterFactory factory = new JapaneseBaseFormFilterFactory();
-    ts = factory.create(ts);
-    assertTokenStreamContents(ts,
-        new String[] { "???", "??", "??", "??", "?", "??", "???", "??"  }
-    );
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestJapanesePartOfSpeechStopFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestJapanesePartOfSpeechStopFilterFactory.java
deleted file mode 100644
index 2338c8c..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestJapanesePartOfSpeechStopFilterFactory.java
+++ /dev/null
@@ -1,56 +0,0 @@
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.solr.core.SolrResourceLoader;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Simple tests for {@link JapanesePartOfSpeechStopFilterFactory}
- */
-public class TestJapanesePartOfSpeechStopFilterFactory extends BaseTokenStreamTestCase {
-  public void testBasics() throws IOException {
-    String tags = 
-        "#  verb-main:\n" +
-        "???-???\n";
-    
-    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
-    tokenizerFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> tokenizerArgs = Collections.emptyMap();
-    tokenizerFactory.init(tokenizerArgs);
-    tokenizerFactory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = tokenizerFactory.create(new StringReader("????????????????"));
-    JapanesePartOfSpeechStopFilterFactory factory = new JapanesePartOfSpeechStopFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("tags", "stoptags.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(new StringMockSolrResourceLoader(tags));
-    ts = factory.create(ts);
-    assertTokenStreamContents(ts,
-        new String[] { "?", "??", "??", "????", "??" }
-    );
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseTokenizerFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestJapaneseTokenizerFactory.java
deleted file mode 100644
index ae6b40b..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseTokenizerFactory.java
+++ /dev/null
@@ -1,119 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests for {@link JapaneseTokenizerFactory}
- */
-public class TestJapaneseTokenizerFactory extends BaseTokenStreamTestCase {
-  public void testSimple() throws IOException {
-    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    factory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = factory.create(new StringReader("???????????"));
-    assertTokenStreamContents(ts,
-        new String[] { "???", "??", "??", "??", "??", "???" },
-        new int[] { 0, 2, 3, 4, 5, 6 },
-        new int[] { 2, 3, 4, 5, 6, 8 }
-    );
-  }
-  
-  /**
-   * Test that search mode is enabled and working by default
-   */
-  public void testDefaults() throws IOException {
-    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    factory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = factory.create(new StringReader("???????????????????"));
-    assertTokenStreamContents(ts,
-                              new String[] { "????", "???????????????????", "???????", "??????" }
-    );
-  }
-  
-  /**
-   * Test mode parameter: specifying normal mode
-   */
-  public void testMode() throws IOException {
-    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("mode", "normal");
-    factory.init(args);
-    factory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = factory.create(new StringReader("???????????????????"));
-    assertTokenStreamContents(ts,
-        new String[] { "???????????????????" }
-    );
-  }
-
-  /**
-   * Test user dictionary
-   */
-  public void testUserDict() throws IOException {
-    String userDict = 
-        "# Custom segmentation for long entries\n" +
-        "??????,?? ?? ??,????? ???? ?????,????????\n" +
-        "???,? ?? ,????? ???? ?????,???????n" +
-        "# Custom reading for sumo wrestler\n" +
-        "????,????,??????????,??????\n";
-    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("userDictionary", "userdict.txt");
-    factory.init(args);
-    factory.inform(new StringMockSolrResourceLoader(userDict));
-    TokenStream ts = factory.create(new StringReader("????????"));
-    assertTokenStreamContents(ts,
-        new String[] { "?", "??", "", "??",  "??",  "??" }
-    );
-  }
-
-  /**
-   * Test preserving punctuation
-   */
-  public void testPreservePunctuation() throws IOException {
-    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("discardPunctuation", "false");
-    factory.init(args);
-    factory.inform(new SolrResourceLoader(null, null));
-    TokenStream ts = factory.create(
-        new StringReader("???????????????????????????????????????????????????????????")
-    );
-    System.out.println(ts.toString());
-    assertTokenStreamContents(ts,
-        new String[] { "?", "????????", "??", "??", "??", "??", "??",
-            "???", "??", "??", "??", "??", "??", "??", "??",
-            "???", "??", "??", "??", "??", "??", "?",
-            "??", "?", "??", "??", "???", "??", "??", "??", "??"}
-    );
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKStemFilterFactory.java
deleted file mode 100644
index c94fc0f..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestKStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Simple tests to ensure the kstem filter factory is working.
- */
-public class TestKStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("bricks");
-    KStemFilterFactory factory = new KStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "brick" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKeepFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKeepFilterFactory.java
deleted file mode 100644
index 1c10041..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestKeepFilterFactory.java
+++ /dev/null
@@ -1,60 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-import java.util.Map;
-import java.util.HashMap;
-
-/**
- *
- *
- **/
-public class TestKeepFilterFactory extends BaseTokenStreamTestCase {
-
-  public void testInform() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    KeepWordFilterFactory factory = new KeepWordFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("words", "keep-1.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 2, words.size() == 2);
-
-
-    factory = new KeepWordFilterFactory();
-    args.put("words", "keep-1.txt, keep-2.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 4, words.size() == 4);
-
-
-
-  }
-}
\ No newline at end of file
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKeywordMarkerFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKeywordMarkerFilterFactory.java
deleted file mode 100644
index 7994f68..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestKeywordMarkerFilterFactory.java
+++ /dev/null
@@ -1,68 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.en.PorterStemFilter;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests to ensure the keyword marker filter factory is working.
- */
-public class TestKeywordMarkerFilterFactory extends BaseTokenStreamTestCase {
-  public void testKeywords() throws IOException {
-    Reader reader = new StringReader("dogs cats");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    KeywordMarkerFilterFactory factory = new KeywordMarkerFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    args.put("protected", "protwords.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    
-    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
-    assertTokenStreamContents(ts, new String[] { "dog", "cats" });
-  }
-  
-  public void testKeywordsCaseInsensitive() throws IOException {
-    Reader reader = new StringReader("dogs cats Cats");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    KeywordMarkerFilterFactory factory = new KeywordMarkerFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    args.put("protected", "protwords.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    
-    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
-    assertTokenStreamContents(ts, new String[] { "dog", "cats", "Cats" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestLatvianStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestLatvianStemFilterFactory.java
deleted file mode 100644
index 4415cde..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestLatvianStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Latvian stem factory is working.
- */
-public class TestLatvianStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("tirgiem tirgus");
-    LatvianStemFilterFactory factory = new LatvianStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "tirg", "tirg" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestMappingCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestMappingCharFilterFactory.java
deleted file mode 100644
index c9db4aa..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestMappingCharFilterFactory.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestMappingCharFilterFactory extends LuceneTestCase {
-  public void testParseString() throws Exception {
-
-    MappingCharFilterFactory f = new MappingCharFilterFactory();
-
-    try {
-      f.parseString( "\\" );
-      fail( "escape character cannot be alone." );
-    }
-    catch (InitializationException expected) {}
-    
-    assertEquals( "unexpected escaped characters",
-        "\\\"\n\t\r\b\f", f.parseString( "\\\\\\\"\\n\\t\\r\\b\\f" ) );
-    assertEquals( "unexpected escaped characters",
-        "A", f.parseString( "\\u0041" ) );
-    assertEquals( "unexpected escaped characters",
-        "AB", f.parseString( "\\u0041\\u0042" ) );
-
-    try {
-      f.parseString( "\\u000" );
-      fail( "invalid length check." );
-    }
-    catch (InitializationException expected) {}
-
-    try {
-      f.parseString( "\\u123x" );
-      fail( "invalid hex number check." );
-    }
-    catch( NumberFormatException expected ){}
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestNGramFilters.java b/solr/core/src/test/org/apache/solr/analysis/TestNGramFilters.java
deleted file mode 100644
index 3790250..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestNGramFilters.java
+++ /dev/null
@@ -1,164 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the NGram filter factories are working.
- */
-public class TestNGramFilters extends BaseTokenStreamTestCase {
-  /**
-   * Test NGramTokenizerFactory
-   */
-  public void testNGramTokenizer() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    NGramTokenizerFactory factory = new NGramTokenizerFactory();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { "t", "e", "s", "t", "te", "es", "st" });
-  }
-  /**
-   * Test NGramTokenizerFactory with min and max gram options
-   */
-  public void testNGramTokenizer2() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minGramSize", "2");
-    args.put("maxGramSize", "3");
-    NGramTokenizerFactory factory = new NGramTokenizerFactory();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { "te", "es", "st", "tes", "est" });
-  }
-  /**
-   * Test the NGramFilterFactory
-   */
-  public void testNGramFilter() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    NGramFilterFactory factory = new NGramFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "t", "e", "s", "t", "te", "es", "st" });
-  }
-  /**
-   * Test the NGramFilterFactory with min and max gram options
-   */
-  public void testNGramFilter2() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minGramSize", "2");
-    args.put("maxGramSize", "3");
-    NGramFilterFactory factory = new NGramFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "te", "es", "st", "tes", "est" });
-  }
-  /**
-   * Test EdgeNGramTokenizerFactory
-   */
-  public void testEdgeNGramTokenizer() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { "t" });
-  }
-  /**
-   * Test EdgeNGramTokenizerFactory with min and max gram size
-   */
-  public void testEdgeNGramTokenizer2() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minGramSize", "1");
-    args.put("maxGramSize", "2");
-    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { "t", "te" });
-  }
-  /**
-   * Test EdgeNGramTokenizerFactory with side option
-   */
-  public void testEdgeNGramTokenizer3() throws Exception {
-    Reader reader = new StringReader("ready");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("side", "back");
-    EdgeNGramTokenizerFactory factory = new EdgeNGramTokenizerFactory();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { "y" });
-  }
-  /**
-   * Test EdgeNGramFilterFactory
-   */
-  public void testEdgeNGramFilter() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "t" });
-  }
-  /**
-   * Test EdgeNGramFilterFactory with min and max gram size
-   */
-  public void testEdgeNGramFilter2() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minGramSize", "1");
-    args.put("maxGramSize", "2");
-    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "t", "te" });
-  }
-  /**
-   * Test EdgeNGramFilterFactory with side option
-   */
-  public void testEdgeNGramFilter3() throws Exception {
-    Reader reader = new StringReader("ready");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("side", "back");
-    EdgeNGramFilterFactory factory = new EdgeNGramFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "y" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestNorwegianLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestNorwegianLightStemFilterFactory.java
deleted file mode 100644
index f8cbb53..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestNorwegianLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Norwegian Light stem factory is working.
- */
-public class TestNorwegianLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("epler eple");
-    NorwegianLightStemFilterFactory factory = new NorwegianLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "epl", "epl" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestNorwegianMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestNorwegianMinimalStemFilterFactory.java
deleted file mode 100644
index fb86cf6..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestNorwegianMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Norwegian Minimal stem factory is working.
- */
-public class TestNorwegianMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("eple eplet epler eplene eplets eplenes");
-    NorwegianMinimalStemFilterFactory factory = new NorwegianMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "epl", "epl", "epl", "epl", "epl", "epl" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
deleted file mode 100644
index 80cac56..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.*;
-
-/**
- * Simple tests to ensure this factory is working
- */
-public class TestPatternReplaceCharFilterFactory extends BaseTokenStreamTestCase {
-  
-  //           1111
-  // 01234567890123
-  // this is test.
-  public void testNothingChange() throws IOException {
-    final String BLOCK = "this is test.";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    args.put("replacement", "$1$2$3");
-    factory.init(args);
-    CharFilter cs = factory.create(
-          new StringReader( BLOCK ) );
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "this", "is", "test." },
-        new int[] { 0, 5, 8 },
-        new int[] { 4, 7, 13 });
-  }
-  
-  // 012345678
-  // aa bb cc
-  public void testReplaceByEmpty() throws IOException {
-    final String BLOCK = "aa bb cc";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    factory.init(args);
-    CharFilter cs = factory.create(
-          new StringReader( BLOCK ) );
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    ts.reset();
-    assertFalse(ts.incrementToken());
-    ts.end();
-    ts.close();
-  }
-  
-  // 012345678
-  // aa bb cc
-  // aa#bb#cc
-  public void test1block1matchSameLength() throws IOException {
-    final String BLOCK = "aa bb cc";
-    PatternReplaceCharFilterFactory factory = new PatternReplaceCharFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
-    args.put("replacement", "$1#$2#$3");
-    factory.init(args);
-    CharFilter cs = factory.create(
-          new StringReader( BLOCK ) );
-    TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
-    assertTokenStreamContents(ts,
-        new String[] { "aa#bb#cc" },
-        new int[] { 0 },
-        new int[] { 8 });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java
deleted file mode 100644
index 0311043..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceFilterFactory.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-/**
- * Simple tests to ensure this factory is working
- */
-public class TestPatternReplaceFilterFactory extends BaseTokenStreamTestCase {
-
-  public void testReplaceAll() throws Exception {
-    String input = "aabfooaabfooabfoob ab caaaaaaaaab";
-    PatternReplaceFilterFactory factory = new PatternReplaceFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("pattern", "a*b");
-    args.put("replacement", "-");
-    factory.init(args);
-    TokenStream ts = factory.create
-            (new MockTokenizer(new StringReader(input), MockTokenizer.WHITESPACE, false));
-                   
-    assertTokenStreamContents(ts, 
-        new String[] { "-foo-foo-foo-", "-", "c-" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java
deleted file mode 100644
index afe15d7..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPatternTokenizerFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-
-/** Simple Tests to ensure this factory is working */
-public class TestPatternTokenizerFactory extends BaseTokenStreamTestCase {
-  public void testFactory() throws Exception {
-    final String INPUT = "Gnther Gnther is here";
-
-    // create PatternTokenizer
-    Map<String,String> args = new HashMap<String, String>();
-    args.put( PatternTokenizerFactory.PATTERN, "[,;/\\s]+" );
-    PatternTokenizerFactory tokFactory = new PatternTokenizerFactory();
-    tokFactory.init( args );
-    TokenStream stream = tokFactory.create( new StringReader(INPUT) );
-    assertTokenStreamContents(stream,
-        new String[] { "Gnther", "Gnther", "is", "here" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPersianNormalizationFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPersianNormalizationFilterFactory.java
deleted file mode 100644
index a189d55..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPersianNormalizationFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Persian normalization factory is working.
- */
-public class TestPersianNormalizationFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually normalizes persian text.
-   */
-  public void testNormalization() throws Exception {
-    Reader reader = new StringReader("??");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    PersianNormalizationFilterFactory factory = new PersianNormalizationFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "??" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPhoneticFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPhoneticFilterFactory.java
deleted file mode 100644
index dc7809d..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPhoneticFilterFactory.java
+++ /dev/null
@@ -1,185 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.commons.codec.language.Metaphone;
-import org.apache.commons.codec.language.Caverphone2;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util.LuceneTestCase.Slow;
-
-
-/**
- *
- */
-@Slow
-public class TestPhoneticFilterFactory extends BaseTokenStreamTestCase {
-  
-  private static final int REPEATS = 100000;
-
-  /**
-   * Case: default
-   */
-  public void testFactory()
-  {
-    Map<String,String> args = new HashMap<String, String>();
-    
-    PhoneticFilterFactory ff = new PhoneticFilterFactory();
-    
-    args.put( PhoneticFilterFactory.ENCODER, "Metaphone" );
-    ff.init( args );
-    assertTrue( ff.getEncoder() instanceof Metaphone );
-    assertTrue( ff.inject ); // default
-
-    args.put( PhoneticFilterFactory.INJECT, "false" );
-    ff.init( args );
-    assertFalse( ff.inject );
-
-    args.put( PhoneticFilterFactory.MAX_CODE_LENGTH, "2");
-    ff.init( args );
-    assertEquals(2,((Metaphone) ff.getEncoder()).getMaxCodeLen());
-  }
-  
-  /**
-   * Case: Failures and Exceptions
-   */
-  public void testFactoryCaseFailure()
-  {
-    Map<String,String> args = new HashMap<String, String>();
-    
-    PhoneticFilterFactory ff = new PhoneticFilterFactory();
-    try {
-      ff.init( args );
-      fail( "missing encoder parameter" );
-    }
-    catch( Exception ex ) {}
-    args.put( PhoneticFilterFactory.ENCODER, "XXX" );
-    try {
-      ff.init( args );
-      fail( "unknown encoder parameter" );
-    }
-    catch( Exception ex ) {}
-    args.put( PhoneticFilterFactory.ENCODER, "org.apache.commons.codec.language.NonExistence" );
-    try {
-      ff.init( args );
-      fail( "unknown encoder parameter" );
-    }
-    catch( Exception ex ) {}
-  }
-  
-  /**
-   * Case: Reflection
-   */
-  public void testFactoryCaseReflection()
-  {
-    Map<String,String> args = new HashMap<String, String>();
-    
-    PhoneticFilterFactory ff = new PhoneticFilterFactory();
-
-    args.put( PhoneticFilterFactory.ENCODER, "org.apache.commons.codec.language.Metaphone" );
-    ff.init( args );
-    assertTrue( ff.getEncoder() instanceof Metaphone );
-    assertTrue( ff.inject ); // default
-
-    // we use "Caverphone2" as it is registered in the REGISTRY as Caverphone,
-    // so this effectively tests reflection without package name
-    args.put( PhoneticFilterFactory.ENCODER, "Caverphone2" );
-    ff.init( args );
-    assertTrue( ff.getEncoder() instanceof Caverphone2 );
-    assertTrue( ff.inject ); // default
-    
-    // cross check with registry
-    args.put( PhoneticFilterFactory.ENCODER, "Caverphone" );
-    ff.init( args );
-    assertTrue( ff.getEncoder() instanceof Caverphone2 );
-    assertTrue( ff.inject ); // default
-  }
-  
-  public void testAlgorithms() throws Exception {
-    assertAlgorithm("Metaphone", "true", "aaa bbb ccc easgasg",
-        new String[] { "A", "aaa", "B", "bbb", "KKK", "ccc", "ESKS", "easgasg" });
-    assertAlgorithm("Metaphone", "false", "aaa bbb ccc easgasg",
-        new String[] { "A", "B", "KKK", "ESKS" });
-    
-    assertAlgorithm("DoubleMetaphone", "true", "aaa bbb ccc easgasg",
-        new String[] { "A", "aaa", "PP", "bbb", "KK", "ccc", "ASKS", "easgasg" });
-    assertAlgorithm("DoubleMetaphone", "false", "aaa bbb ccc easgasg",
-        new String[] { "A", "PP", "KK", "ASKS" });
-    
-    assertAlgorithm("Soundex", "true", "aaa bbb ccc easgasg",
-        new String[] { "A000", "aaa", "B000", "bbb", "C000", "ccc", "E220", "easgasg" });
-    assertAlgorithm("Soundex", "false", "aaa bbb ccc easgasg",
-        new String[] { "A000", "B000", "C000", "E220" });
-    
-    assertAlgorithm("RefinedSoundex", "true", "aaa bbb ccc easgasg",
-        new String[] { "A0", "aaa", "B1", "bbb", "C3", "ccc", "E034034", "easgasg" });
-    assertAlgorithm("RefinedSoundex", "false", "aaa bbb ccc easgasg",
-        new String[] { "A0", "B1", "C3", "E034034" });
-    
-    assertAlgorithm("Caverphone", "true", "Darda Karleen Datha Carlene",
-        new String[] { "TTA1111111", "Darda", "KLN1111111", "Karleen", 
-          "TTA1111111", "Datha", "KLN1111111", "Carlene" });
-    assertAlgorithm("Caverphone", "false", "Darda Karleen Datha Carlene",
-        new String[] { "TTA1111111", "KLN1111111", "TTA1111111", "KLN1111111" });
-    
-    assertAlgorithm("ColognePhonetic", "true", "Meier Schmitt Meir Schmidt",
-        new String[] { "67", "Meier", "862", "Schmitt", 
-          "67", "Meir", "862", "Schmidt" });
-    assertAlgorithm("ColognePhonetic", "false", "Meier Schmitt Meir Schmidt",
-        new String[] { "67", "862", "67", "862" });
-  }
-  
-  static void assertAlgorithm(String algName, String inject, String input,
-      String[] expected) throws Exception {
-    Tokenizer tokenizer = new MockTokenizer(new StringReader(input), MockTokenizer.WHITESPACE, false);
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("encoder", algName);
-    args.put("inject", inject);
-    PhoneticFilterFactory factory = new PhoneticFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, expected);
-  }
-  
-  public void testSpeed() throws Exception {
-	  checkSpeedEncoding("Metaphone", "easgasg", "ESKS");
-	  checkSpeedEncoding("DoubleMetaphone", "easgasg", "ASKS");
-	  checkSpeedEncoding("Soundex", "easgasg", "E220");
-	  checkSpeedEncoding("RefinedSoundex", "easgasg", "E034034");
-	  checkSpeedEncoding("Caverphone", "Carlene", "KLN1111111");
-	  checkSpeedEncoding("ColognePhonetic", "Schmitt", "862");
-  }
-  
-  private void checkSpeedEncoding(String encoder, String toBeEncoded, String estimated) throws Exception {
-	  long start = System.currentTimeMillis();
-	  for ( int i=0; i<REPEATS; i++) {
-		    assertAlgorithm(encoder, "false", toBeEncoded,
-		            new String[] { estimated });
-	  }
-	  long duration = System.currentTimeMillis()-start;
-	  if (VERBOSE)
-	    System.out.println(encoder + " encodings per msec: "+(REPEATS/duration));
-  }
-  
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPorterStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPorterStemFilterFactory.java
deleted file mode 100644
index bb3be89..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPorterStemFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Porter stem filter factory is working.
- */
-public class TestPorterStemFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("dogs");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    PorterStemFilterFactory factory = new PorterStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "dog" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPortugueseLightStemFilterFactory.java
deleted file mode 100644
index aa5c009..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Portuguese Light stem factory is working.
- */
-public class TestPortugueseLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("evidentemente");
-    PortugueseLightStemFilterFactory factory = new PortugueseLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "evident" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPortugueseMinimalStemFilterFactory.java
deleted file mode 100644
index 695b54c..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseMinimalStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Portuguese Minimal stem factory is working.
- */
-public class TestPortugueseMinimalStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("questes");
-    PortugueseMinimalStemFilterFactory factory = new PortugueseMinimalStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "questo" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPortugueseStemFilterFactory.java
deleted file mode 100644
index 13e9719..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestPortugueseStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Portuguese stem factory is working.
- */
-public class TestPortugueseStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("maluquice");
-    PortugueseStemFilterFactory factory = new PortugueseStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "maluc" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestRemoveDuplicatesTokenFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestRemoveDuplicatesTokenFilterFactory.java
deleted file mode 100644
index d098b26..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestRemoveDuplicatesTokenFilterFactory.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-import java.util.Iterator;
-import java.util.Arrays;
-
-/** Simple tests to ensure this factory is working */
-public class TestRemoveDuplicatesTokenFilterFactory extends BaseTokenStreamTestCase {
-
-  public static Token tok(int pos, String t, int start, int end) {
-    Token tok = new Token(t,start,end);
-    tok.setPositionIncrement(pos);
-    return tok;
-  }
-  public static Token tok(int pos, String t) {
-    return tok(pos, t, 0,0);
-  }
-
-  public void testDups(final String expected, final Token... tokens)
-    throws Exception {
-
-    final Iterator<Token> toks = Arrays.asList(tokens).iterator();
-    RemoveDuplicatesTokenFilterFactory factory = new RemoveDuplicatesTokenFilterFactory();
-    final TokenStream ts = factory.create
-      (new TokenStream() {
-          CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-          PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-          @Override
-          public boolean incrementToken() {
-            if (toks.hasNext()) {
-              clearAttributes();
-              Token tok = toks.next();
-              termAtt.setEmpty().append(tok);
-              offsetAtt.setOffset(tok.startOffset(), tok.endOffset());
-              posIncAtt.setPositionIncrement(tok.getPositionIncrement());
-              return true;
-            } else {
-              return false;
-            }
-          }
-        });
-    
-    assertTokenStreamContents(ts, expected.split("\\s"));   
-  }
- 
-  public void testSimpleDups() throws Exception {
-    testDups("A B C D E"
-             ,tok(1,"A", 0,  4)
-             ,tok(1,"B", 5, 10)
-             ,tok(0,"B",11, 15)
-             ,tok(1,"C",16, 20)
-             ,tok(0,"D",16, 20)
-             ,tok(1,"E",21, 25)
-             ); 
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestReverseStringFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestReverseStringFilterFactory.java
deleted file mode 100644
index 20c6d4d..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestReverseStringFilterFactory.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Reverse string filter factory is working.
- */
-public class TestReverseStringFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually reverses text.
-   */
-  public void testReversing() throws Exception {
-    Reader reader = new StringReader("simple test");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ReverseStringFilterFactory factory = new ReverseStringFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "elpmis", "tset" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestRussianLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestRussianLightStemFilterFactory.java
deleted file mode 100644
index 810ffbd..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestRussianLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Russian light stem factory is working.
- */
-public class TestRussianLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("???");
-    RussianLightStemFilterFactory factory = new RussianLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "??" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestShingleFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestShingleFilterFactory.java
deleted file mode 100644
index ca85836..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestShingleFilterFactory.java
+++ /dev/null
@@ -1,239 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Shingle filter factory works.
- */
-public class TestShingleFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Test the defaults
-   */
-  public void testDefaults() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] {"this", "this is", "is",
-        "is a", "a", "a test", "test"});
-  }
-  
-  /**
-   * Test with unigrams disabled
-   */
-  public void testNoUnigrams() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("outputUnigrams", "false");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream,
-        new String[] {"this is", "is a", "a test"});
-  }
-  
-  /**
-   * Test with a higher max shingle size
-   */
-  public void testMaxShingleSize() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("maxShingleSize", "3");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] {"this", "this is", "this is a", "is",
-        "is a", "is a test", "a", "a test", "test"});
-  }
-
-  /**
-   * Test with higher min (and max) shingle size
-   */
-  public void testMinShingleSize() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "4");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this", "this is a", "this is a test",
-        "is", "is a test", "a", "test" });
-  }
-
-  /**
-   * Test with higher min (and max) shingle size and with unigrams disabled
-   */
-  public void testMinShingleSizeNoUnigrams() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "4");
-    args.put("outputUnigrams", "false");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this is a", "this is a test", "is a test" });
-  }
-
-  /**
-   * Test with higher same min and max shingle size
-   */
-  public void testEqualMinAndMaxShingleSize() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "3");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-         new String[] { "this", "this is a", "is", "is a test", "a", "test" });
-  }
-
-  /**
-   * Test with higher same min and max shingle size and with unigrams disabled
-   */
-  public void testEqualMinAndMaxShingleSizeNoUnigrams() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "3");
-    args.put("outputUnigrams", "false");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream,
-        new String[] { "this is a", "is a test" });
-  }
-    
-  /**
-   * Test with a non-default token separator
-   */
-  public void testTokenSeparator() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("tokenSeparator", "=BLAH=");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this", "this=BLAH=is", "is", "is=BLAH=a", 
-        "a", "a=BLAH=test", "test" });
-  }
-
-  /**
-   * Test with a non-default token separator and with unigrams disabled
-   */
-  public void testTokenSeparatorNoUnigrams() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("tokenSeparator", "=BLAH=");
-    args.put("outputUnigrams", "false");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this=BLAH=is", "is=BLAH=a", "a=BLAH=test" });
-  }
-
-  /**
-   * Test with an empty token separator
-   */
-  public void testEmptyTokenSeparator() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("tokenSeparator", "");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this", "thisis", "is", "isa", "a", "atest", "test" });
-  }
-    
-  /**
-   * Test with higher min (and max) shingle size 
-   * and with a non-default token separator
-   */
-  public void testMinShingleSizeAndTokenSeparator() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "4");
-    args.put("tokenSeparator", "=BLAH=");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this", "this=BLAH=is=BLAH=a", 
-        "this=BLAH=is=BLAH=a=BLAH=test", "is", 
-        "is=BLAH=a=BLAH=test", "a", "test" });
-  }
-
-  /**
-   * Test with higher min (and max) shingle size 
-   * and with a non-default token separator
-   * and with unigrams disabled
-   */
-  public void testMinShingleSizeAndTokenSeparatorNoUnigrams() throws Exception {
-    Reader reader = new StringReader("this is a test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("minShingleSize", "3");
-    args.put("maxShingleSize", "4");
-    args.put("tokenSeparator", "=BLAH=");
-    args.put("outputUnigrams", "false");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, 
-        new String[] { "this=BLAH=is=BLAH=a", "this=BLAH=is=BLAH=a=BLAH=test", 
-        "is=BLAH=a=BLAH=test", });
-  }
-
-  /**
-   * Test with unigrams disabled except when there are no shingles, with
-   * a single input token. Using default min/max shingle sizes: 2/2.  No
-   * shingles will be created, since there are fewer input tokens than
-   * min shingle size.  However, because outputUnigramsIfNoShingles is
-   * set to true, even though outputUnigrams is set to false, one
-   * unigram should be output.
-   */
-  public void testOutputUnigramsIfNoShingles() throws Exception {
-    Reader reader = new StringReader("test");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("outputUnigrams", "false");
-    args.put("outputUnigramsIfNoShingles", "true");
-    ShingleFilterFactory factory = new ShingleFilterFactory();
-    factory.init(args);
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "test" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestSpanishLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestSpanishLightStemFilterFactory.java
deleted file mode 100644
index deba80b..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestSpanishLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Spanish Light stem factory is working.
- */
-public class TestSpanishLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("sociedades");
-    SpanishLightStemFilterFactory factory = new SpanishLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "sociedad" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestStandardFactories.java b/solr/core/src/test/org/apache/solr/analysis/TestStandardFactories.java
deleted file mode 100644
index cd3dcb0..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestStandardFactories.java
+++ /dev/null
@@ -1,186 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the standard lucene factories are working.
- */
-public class TestStandardFactories extends BaseTokenStreamTestCase {
-  /**
-   * Test StandardTokenizerFactory
-   */
-  public void testStandardTokenizer() throws Exception {
-    Reader reader = new StringReader("Wha\u0301t's this thing do?");
-    StandardTokenizerFactory factory = new StandardTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"Wha\u0301t's", "this", "thing", "do" });
-  }
-  
-  public void testStandardTokenizerMaxTokenLength() throws Exception {
-    StringBuilder builder = new StringBuilder();
-    for (int i = 0 ; i < 100 ; ++i) {
-      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
-    }
-    String longWord = builder.toString();
-    String content = "one two three " + longWord + " four five six";
-    Reader reader = new StringReader(content);
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("maxTokenLength", "1000");
-    StandardTokenizerFactory factory = new StandardTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
-  }
-  
-  /**
-   * Test ClassicTokenizerFactory
-   */
-  public void testClassicTokenizer() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"What's", "this", "thing", "do" });
-  }
-  
-  public void testClassicTokenizerMaxTokenLength() throws Exception {
-    StringBuilder builder = new StringBuilder();
-    for (int i = 0 ; i < 100 ; ++i) {
-      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
-    }
-    String longWord = builder.toString();
-    String content = "one two three " + longWord + " four five six";
-    Reader reader = new StringReader(content);
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("maxTokenLength", "1000");
-    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
-  }
-  
-  /**
-   * Test ClassicFilterFactory
-   */
-  public void testStandardFilter() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    ClassicTokenizerFactory factory = new ClassicTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    ClassicFilterFactory filterFactory = new ClassicFilterFactory();
-    filterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    filterFactory.init(args);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = filterFactory.create(tokenizer);
-    assertTokenStreamContents(stream, 
-        new String[] {"What", "this", "thing", "do"});
-  }
-  
-  /**
-   * Test KeywordTokenizerFactory
-   */
-  public void testKeywordTokenizer() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    KeywordTokenizerFactory factory = new KeywordTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"What's this thing do?"});
-  }
-  
-  /**
-   * Test WhitespaceTokenizerFactory
-   */
-  public void testWhitespaceTokenizer() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    WhitespaceTokenizerFactory factory = new WhitespaceTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"What's", "this", "thing", "do?"});
-  }
-  
-  /**
-   * Test LetterTokenizerFactory
-   */
-  public void testLetterTokenizer() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    LetterTokenizerFactory factory = new LetterTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"What", "s", "this", "thing", "do"});
-  }
-  
-  /**
-   * Test LowerCaseTokenizerFactory
-   */
-  public void testLowerCaseTokenizer() throws Exception {
-    Reader reader = new StringReader("What's this thing do?");
-    LowerCaseTokenizerFactory factory = new LowerCaseTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"what", "s", "this", "thing", "do"});
-  }
-  
-  /**
-   * Ensure the ASCIIFoldingFilterFactory works
-   */
-  public void testASCIIFolding() throws Exception {
-    Reader reader = new StringReader("?esk");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ASCIIFoldingFilterFactory factory = new ASCIIFoldingFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "Ceska" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestStemmerOverrideFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestStemmerOverrideFilterFactory.java
deleted file mode 100644
index 74de226..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestStemmerOverrideFilterFactory.java
+++ /dev/null
@@ -1,69 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.en.PorterStemFilter;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-/**
- * Simple tests to ensure the stemmer override filter factory is working.
- */
-public class TestStemmerOverrideFilterFactory extends BaseTokenStreamTestCase {
-  public void testKeywords() throws IOException {
-    // our stemdict stems dogs to 'cat'
-    Reader reader = new StringReader("testing dogs");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    StemmerOverrideFilterFactory factory = new StemmerOverrideFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    args.put("dictionary", "stemdict.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    
-    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
-    assertTokenStreamContents(ts, new String[] { "test", "cat" });
-  }
-  
-  public void testKeywordsCaseInsensitive() throws IOException {
-    Reader reader = new StringReader("testing DoGs");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    StemmerOverrideFilterFactory factory = new StemmerOverrideFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    args.put("dictionary", "stemdict.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    
-    TokenStream ts = new PorterStemFilter(factory.create(tokenizer));
-    assertTokenStreamContents(ts, new String[] { "test", "cat" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestStopFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestStopFilterFactory.java
deleted file mode 100644
index 4dc1f9e..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestStopFilterFactory.java
+++ /dev/null
@@ -1,76 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-
-import java.util.Map;
-import java.util.HashMap;
-
-/**
- *
- *
- **/
-public class TestStopFilterFactory extends BaseTokenStreamTestCase {
-
-  public void testInform() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    assertTrue("loader is null and it shouldn't be", loader != null);
-    StopFilterFactory factory = new StopFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("words", "stop-1.txt");
-    args.put("ignoreCase", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    CharArraySet words = factory.getStopWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 2, words.size() == 2);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
-
-    factory = new StopFilterFactory();
-    args.put("words", "stop-1.txt, stop-2.txt");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getStopWords();
-    assertTrue("words is null and it shouldn't be", words != null);
-    assertTrue("words Size: " + words.size() + " is not: " + 4, words.size() == 4);
-    assertTrue(factory.isIgnoreCase() + " does not equal: " + true, factory.isIgnoreCase() == true);
-
-    factory = new StopFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    args.put("words", "stop-snowball.txt");
-    args.put("format", "snowball");
-    factory.init(args);
-    factory.inform(loader);
-    words = factory.getStopWords();
-    assertEquals(8, words.size());
-    assertTrue(words.contains("he"));
-    assertTrue(words.contains("him"));
-    assertTrue(words.contains("his"));
-    assertTrue(words.contains("himself"));
-    assertTrue(words.contains("she"));
-    assertTrue(words.contains("her"));
-    assertTrue(words.contains("hers"));
-    assertTrue(words.contains("herself"));
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestSwedishLightStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestSwedishLightStemFilterFactory.java
deleted file mode 100644
index b059fc1..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestSwedishLightStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure the Swedish Light stem factory is working.
- */
-public class TestSwedishLightStemFilterFactory extends BaseTokenStreamTestCase {
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("pplen pple");
-    SwedishLightStemFilterFactory factory = new SwedishLightStemFilterFactory();
-    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
-    assertTokenStreamContents(stream, new String[] { "ppl", "ppl" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestThaiWordFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestThaiWordFilterFactory.java
deleted file mode 100644
index 006d365..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestThaiWordFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.th.ThaiWordFilter;
-
-/**
- * Simple tests to ensure the Thai word filter factory is working.
- */
-public class TestThaiWordFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually decomposes text.
-   */
-  public void testWordBreak() throws Exception {
-    assumeTrue("JRE does not support Thai dictionary-based BreakIterator", ThaiWordFilter.DBBI_AVAILABLE);
-    Reader reader = new StringReader("??????????????????");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    ThaiWordFilterFactory factory = new ThaiWordFilterFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] {"??", "??", "???",
-        "????", "???", "??", "??", "?"});
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java
deleted file mode 100644
index 9376422..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestTrimFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Simple tests to ensure this factory is working
- */
-public class TestTrimFilterFactory extends BaseTokenStreamTestCase {
-  public void testTrimming() throws Exception {
-    TrimFilterFactory factory = new TrimFilterFactory();
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("updateOffsets", "false");
-    factory.init(args);
-    TokenStream ts = factory.create(new MockTokenizer(new StringReader("trim me    "), MockTokenizer.KEYWORD, false));
-    assertTokenStreamContents(ts, new String[] { "trim me" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestTurkishLowerCaseFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestTurkishLowerCaseFilterFactory.java
deleted file mode 100644
index b3d9305..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestTurkishLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,42 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Simple tests to ensure the Turkish lowercase filter factory is working.
- */
-public class TestTurkishLowerCaseFilterFactory extends BaseTokenStreamTestCase {
-  /**
-   * Ensure the filter actually lowercases text.
-   */
-  public void testCasing() throws Exception {
-    Reader reader = new StringReader("A?ACI");
-    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-    TurkishLowerCaseFilterFactory factory = new TurkishLowerCaseFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "a?ac" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestTypeTokenFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestTypeTokenFilterFactory.java
deleted file mode 100644
index e8dee7c..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestTypeTokenFilterFactory.java
+++ /dev/null
@@ -1,105 +0,0 @@
-package org.apache.solr.analysis;
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.NumericTokenStream;
-import org.apache.lucene.analysis.util.InitializationException;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-import org.junit.Test;
-
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-
-/**
- * Testcase for {@link TypeTokenFilterFactory}
- */
-public class TestTypeTokenFilterFactory extends BaseTokenStreamTestCase {
-
-  @Test
-  public void testInform() throws Exception {
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    TypeTokenFilterFactory factory = new TypeTokenFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("types", "stoptypes-1.txt");
-    args.put("enablePositionIncrements", "true");
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    factory.inform(loader);
-    Set<String> types = factory.getStopTypes();
-    assertTrue("types is null and it shouldn't be", types != null);
-    assertTrue("types Size: " + types.size() + " is not: " + 2, types.size() == 2);
-    assertTrue("enablePositionIncrements was set to true but not correctly parsed", factory.isEnablePositionIncrements());
-
-    factory = new TypeTokenFilterFactory();
-    args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
-    args.put("enablePositionIncrements", "false");
-    args.put("useWhitelist","true");
-    factory.init(args);
-    factory.inform(loader);
-    types = factory.getStopTypes();
-    assertTrue("types is null and it shouldn't be", types != null);
-    assertTrue("types Size: " + types.size() + " is not: " + 4, types.size() == 4);
-    assertTrue("enablePositionIncrements was set to false but not correctly parsed", !factory.isEnablePositionIncrements());
-  }
-
-  @Test
-  public void testCreationWithBlackList() throws Exception {
-    TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
-    Map<String, String> args = new HashMap<String, String>();
-    args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
-    args.put("enablePositionIncrements", "false");
-    typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    typeTokenFilterFactory.init(args);
-    NumericTokenStream input = new NumericTokenStream();
-    input.setIntValue(123);
-    typeTokenFilterFactory.create(input);
-  }
-  
-  @Test
-    public void testCreationWithWhiteList() throws Exception {
-      TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
-      Map<String, String> args = new HashMap<String, String>();
-      args.put("types", "stoptypes-1.txt, stoptypes-2.txt");
-      args.put("enablePositionIncrements", "false");
-      args.put("useWhitelist","true");
-      typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-      typeTokenFilterFactory.init(args);
-      NumericTokenStream input = new NumericTokenStream();
-      input.setIntValue(123);
-      typeTokenFilterFactory.create(input);
-    }
-
-  @Test
-  public void testMissingTypesParameter() throws Exception {
-    try {
-      TypeTokenFilterFactory typeTokenFilterFactory = new TypeTokenFilterFactory();
-      Map<String, String> args = new HashMap<String, String>();
-      args.put("enablePositionIncrements", "false");
-      typeTokenFilterFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-      typeTokenFilterFactory.init(args);
-      typeTokenFilterFactory.inform(new SolrResourceLoader(null, null));
-      fail("not supplying 'types' parameter should cause an InitializationException");
-    } catch (InitializationException e) {
-      // everything ok
-    }
-  }
-
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestUAX29URLEmailTokenizerFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestUAX29URLEmailTokenizerFactory.java
deleted file mode 100644
index d1a1c1c..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestUAX29URLEmailTokenizerFactory.java
+++ /dev/null
@@ -1,193 +0,0 @@
-package org.apache.solr.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.util.Version;
-
-/**
- * A few tests based on org.apache.lucene.analysis.TestUAX29URLEmailTokenizer
- */
-
-public class TestUAX29URLEmailTokenizerFactory extends BaseTokenStreamTestCase {
-
-  public void testUAX29URLEmailTokenizer() throws Exception {
-    Reader reader = new StringReader("Wha\u0301t's this thing do?");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"Wha\u0301t's", "this", "thing", "do" });
-  }
-  
-  public void testArabic() throws Exception {
-    Reader reader = new StringReader("????? ???? ??? ? ?????? ??? \"???? ???: ? ??????\" (?????: Truth in Numbers: The Wikipedia Story)? ?? ??? ?? 2008.");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"?????", "????", "???", "?", "??????", "???", "????", "???", "?", "??????",
-        "?????", "Truth", "in", "Numbers", "The", "Wikipedia", "Story", "??", "???", "??", "2008"  });
-  }
-  
-  public void testChinese() throws Exception {
-    Reader reader = new StringReader("??????? ???? ???? ");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"??", "??", "?", "??", "?", "????", "????"});
-  }
-
-  public void testKorean() throws Exception {
-    Reader reader = new StringReader("???????? ????????");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"????????", "????????"});
-  }
-    
-  public void testHyphen() throws Exception {
-    Reader reader = new StringReader("some-dashed-phrase");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"some", "dashed", "phrase"});
-  }
-
-  // Test with some URLs from TestUAX29URLEmailTokenizer's 
-  // urls.from.random.text.with.urls.txt
-  public void testURLs() throws Exception {
-    String textWithURLs 
-      = "http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on\n"
-        + " some extra\nWords thrown in here. "
-        + "http://c5-3486.bisynxu.FR/aI.YnNms/"
-        + " samba Halta gamba "
-        + "ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R\n"
-        + "M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb\n"
-        + "Https://yu7v33rbt.vC6U3.XN--JXALPDLP/y%4fMSzkGFlm/wbDF4m"
-        + " inter Locutio "
-        + "[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/\n"
-        + "file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7"
-        + " blah Sirrah woof "
-        + "http://[a42:a7b6::]/qSmxSUU4z/%52qVl4\n";
-    Reader reader = new StringReader(textWithURLs);
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { 
-          "http://johno.jsmf.net/knowhow/ngrams/index.php?table=en-dickens-word-2gram&paragraphs=50&length=200&no-ads=on",
-          "some", "extra", "Words", "thrown", "in", "here",
-          "http://c5-3486.bisynxu.FR/aI.YnNms/",
-          "samba", "Halta", "gamba",
-          "ftp://119.220.152.185/JgJgdZ/31aW5c/viWlfQSTs5/1c8U5T/ih5rXx/YfUJ/xBW1uHrQo6.R",
-          "M19nq.0URV4A.Me.CC/mj0kgt6hue/dRXv8YVLOw9v/CIOqb",
-          "Https://yu7v33rbt.vC6U3.XN--JXALPDLP/y%4fMSzkGFlm/wbDF4m",
-          "inter", "Locutio",
-          "[c2d4::]/%471j5l/j3KFN%AAAn/Fip-NisKH/",
-          "file:///aXvSZS34is/eIgM8s~U5dU4Ifd%c7",
-          "blah", "Sirrah", "woof",
-          "http://[a42:a7b6::]/qSmxSUU4z/%52qVl4"
-        }
-    );
-  }
-
-  // Test with some emails from TestUAX29URLEmailTokenizer's 
-  // email.addresses.from.random.text.with.email.addresses.txt
-  public void testEmails() throws Exception {
-    String textWithEmails 
-      =  " some extra\nWords thrown in here. "
-         + "dJ8ngFi@avz13m.CC\n"
-         + "kU-l6DS@[082.015.228.189]\n"
-         + "\"%U\u0012@?\\B\"@Fl2d.md"
-         + " samba Halta gamba "
-         + "Bvd#@tupjv.sn\n"
-         + "SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt\n"
-         + "~+Kdz@3mousnl.SE\n"
-         + " inter Locutio "
-         + "C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY\n"
-         + "}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM"
-         + " blah Sirrah woof "
-         + "lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae\n"
-         + "lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H\n";
-    Reader reader = new StringReader(textWithEmails);
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    Map<String, String> args = Collections.emptyMap();
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] { 
-          "some", "extra", "Words", "thrown", "in", "here",
-          "dJ8ngFi@avz13m.CC",
-          "kU-l6DS@[082.015.228.189]",
-          "\"%U\u0012@?\\B\"@Fl2d.md",
-          "samba", "Halta", "gamba",
-          "Bvd#@tupjv.sn",
-          "SBMm0Nm.oyk70.rMNdd8k.#ru3LI.gMMLBI.0dZRD4d.RVK2nY@au58t.B13albgy4u.mt",
-          "~+Kdz@3mousnl.SE",
-          "inter", "Locutio",
-          "C'ts`@Vh4zk.uoafcft-dr753x4odt04q.UY",
-          "}0tzWYDBuy@cSRQAABB9B.7c8xawf75-cyo.PM",
-          "blah", "Sirrah", "woof",
-          "lMahAA.j/5.RqUjS745.DtkcYdi@d2-4gb-l6.ae",
-          "lv'p@tqk.vj5s0tgl.0dlu7su3iyiaz.dqso.494.3hb76.XN--MGBAAM7A8H"
-        }
-    );
-  }
-
-  public void testMaxTokenLength() throws Exception {
-    StringBuilder builder = new StringBuilder();
-    for (int i = 0 ; i < 100 ; ++i) {
-      builder.append("abcdefg"); // 7 * 100 = 700 char "word"
-    }
-    String longWord = builder.toString();
-    String content = "one two three " + longWord + " four five six";
-    Reader reader = new StringReader(content);
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("maxTokenLength", "1000");
-    UAX29URLEmailTokenizerFactory factory = new UAX29URLEmailTokenizerFactory();
-    factory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
-    factory.init(args);
-    Tokenizer stream = factory.create(reader);
-    assertTokenStreamContents(stream, 
-        new String[] {"one", "two", "three", longWord, "four", "five", "six" });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestWikipediaTokenizerFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestWikipediaTokenizerFactory.java
deleted file mode 100644
index 7dda1e3..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestWikipediaTokenizerFactory.java
+++ /dev/null
@@ -1,43 +0,0 @@
-package org.apache.solr.analysis;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.wikipedia.WikipediaTokenizer;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Simple tests to ensure the wikipedia tokenizer is working.
- */
-public class TestWikipediaTokenizerFactory extends BaseTokenStreamTestCase {
-  public void testTokenizer() throws IOException {
-    Reader reader = new StringReader("This is a [[Category:foo]]");
-    WikipediaTokenizerFactory factory = new WikipediaTokenizerFactory();
-    Tokenizer tokenizer = factory.create(reader);
-    assertTokenStreamContents(tokenizer,
-        new String[] { "This", "is", "a", "foo" },
-        new int[] { 0, 5, 8, 21 },
-        new int[] { 4, 7, 9, 24 },
-        new String[] { "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>", WikipediaTokenizer.CATEGORY },
-        new int[] { 1, 1, 1, 1, });
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java
deleted file mode 100644
index ed4d782..0000000
--- a/solr/core/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java
+++ /dev/null
@@ -1,242 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.io.StringReader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.lucene.analysis.util.ResourceLoader;
-import org.apache.solr.core.SolrResourceLoader;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-/**
- * New WordDelimiterFilter tests... most of the tests are in ConvertedLegacyTest
- */
-public class TestWordDelimiterFilterFactory extends SolrTestCaseJ4 {
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml","schema.xml");
-  }
-
-  public void posTst(String v1, String v2, String s1, String s2) {
-    assertU(adoc("id",  "42",
-                 "subword", v1,
-                 "subword", v2));
-    assertU(commit());
-
-    // there is a positionIncrementGap of 100 between field values, so
-    // we test if that was maintained.
-    assertQ("position increment lost",
-            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~90")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("position increment lost",
-            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~110")
-            ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testRetainPositionIncrement() {
-    posTst("foo","bar","foo","bar");
-    posTst("-foo-","-bar-","foo","bar");
-    posTst("foo","bar","-foo-","-bar-");
-
-    posTst("123","456","123","456");
-    posTst("/123/","/456/","123","456");
-
-    posTst("/123/abc","qwe/456/","abc","qwe");
-
-    posTst("zoo-foo","bar-baz","foo","bar");
-    posTst("zoo-foo-123","456-bar-baz","foo","bar");
-  }
-
-  @Test
-  public void testNoGenerationEdgeCase() {
-    assertU(adoc("id", "222", "numberpartfail", "123.123.123.123"));
-    clearIndex();
-  }
-
-  @Test
-  public void testIgnoreCaseChange() {
-
-    assertU(adoc("id",  "43",
-                 "wdf_nocase", "HellO WilliAM",
-                 "subword", "GoodBye JonEs"));
-    assertU(commit());
-    
-    assertQ("no case change",
-            req("wdf_nocase:(hell o am)")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("case change",
-            req("subword:(good jon)")
-            ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testPreserveOrignalTrue() {
-
-    assertU(adoc("id",  "144",
-                 "wdf_preserve", "404-123"));
-    assertU(commit());
-    
-    assertQ("preserving original word",
-            req("wdf_preserve:404")
-            ,"//result[@numFound=1]"
-    );
-    
-    assertQ("preserving original word",
-        req("wdf_preserve:123")
-        ,"//result[@numFound=1]"
-    );
-
-    assertQ("preserving original word",
-        req("wdf_preserve:404-123*")
-        ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  /***
-  public void testPerformance() throws IOException {
-    String s = "now is the time-for all good men to come to-the aid of their country.";
-    Token tok = new Token();
-    long start = System.currentTimeMillis();
-    int ret=0;
-    for (int i=0; i<1000000; i++) {
-      StringReader r = new StringReader(s);
-      TokenStream ts = new WhitespaceTokenizer(r);
-      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);
-
-      while (ts.next(tok) != null) ret++;
-    }
-
-    System.out.println("ret="+ret+" time="+(System.currentTimeMillis()-start));
-  }
-  ***/
-
-  @Test
-  public void testAlphaNumericWords(){
-     assertU(adoc("id",  "68","numericsubword","Java/J2SE"));
-     assertU(commit());
-
-     assertQ("j2se found",
-            req("numericsubword:(J2SE)")
-            ,"//result[@numFound=1]"
-    );
-      assertQ("no j2 or se",
-            req("numericsubword:(J2 OR SE)")
-            ,"//result[@numFound=0]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testProtectedWords(){
-    assertU(adoc("id", "70","protectedsubword","c# c++ .net Java/J2SE"));
-    assertU(commit());
-
-    assertQ("java found",
-            req("protectedsubword:(java)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ(".net found",
-            req("protectedsubword:(.net)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c# found",
-            req("protectedsubword:(c#)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c++ found",
-            req("protectedsubword:(c++)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c found?",
-            req("protectedsubword:c")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("net found?",
-            req("protectedsubword:net")
-            ,"//result[@numFound=0]"
-    );
-    clearIndex();
-  }
-  
-  @Test
-  public void testCustomTypes() throws Exception {
-    String testText = "I borrowed $5,400.00 at 25% interest-rate";
-    WordDelimiterFilterFactory factoryDefault = new WordDelimiterFilterFactory();
-    ResourceLoader loader = new SolrResourceLoader("solr/collection1");
-    Map<String,String> args = new HashMap<String,String>();
-    args.put("generateWordParts", "1");
-    args.put("generateNumberParts", "1");
-    args.put("catenateWords", "1");
-    args.put("catenateNumbers", "1");
-    args.put("catenateAll", "0");
-    args.put("splitOnCaseChange", "1");
-    
-    /* default behavior */
-    factoryDefault.init(args);
-    factoryDefault.inform(loader);
-    
-    TokenStream ts = factoryDefault.create(
-        new MockTokenizer(new StringReader(testText), MockTokenizer.WHITESPACE, false));
-    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
-        new String[] { "I", "borrowed", "5", "400", "00", "540000", "at", "25", "interest", "rate", "interestrate" });
-
-    ts = factoryDefault.create(
-        new MockTokenizer(new StringReader("foo\u200Dbar"), MockTokenizer.WHITESPACE, false));
-    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
-        new String[] { "foo", "bar", "foobar" });
-
-    
-    /* custom behavior */
-    WordDelimiterFilterFactory factoryCustom = new WordDelimiterFilterFactory();
-    // use a custom type mapping
-    args.put("types", "wdftypes.txt");
-    factoryCustom.init(args);
-    factoryCustom.inform(loader);
-    
-    ts = factoryCustom.create(
-        new MockTokenizer(new StringReader(testText), MockTokenizer.WHITESPACE, false));
-    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
-        new String[] { "I", "borrowed", "$5,400.00", "at", "25%", "interest", "rate", "interestrate" });
-    
-    /* test custom behavior with a char > 0x7F, because we had to make a larger byte[] */
-    ts = factoryCustom.create(
-        new MockTokenizer(new StringReader("foo\u200Dbar"), MockTokenizer.WHITESPACE, false));
-    BaseTokenStreamTestCase.assertTokenStreamContents(ts, 
-        new String[] { "foo\u200Dbar" });
-  }
-}

