GitDiffStart: 9238c5f5ca22721a65cc6ea5261c773438c67a9d | Tue May 4 09:11:05 2010 +0000
diff --git a/lucene/contrib/CHANGES.txt b/lucene/contrib/CHANGES.txt
index af8fa4f..ec3914b 100644
--- a/lucene/contrib/CHANGES.txt
+++ b/lucene/contrib/CHANGES.txt
@@ -161,6 +161,8 @@ New features
      and phrases. 
    - o.a.l.analysis.charfilter.HTMLStripCharFilter: CharFilter that strips HTML 
      constructs.
+   - o.a.l.analysis.miscellaneous.WordDelimiterFilter: TokenFilter that splits words 
+     into subwords and performs optional transformations on subword groups.
    (... in progress)
 
 Build
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
new file mode 100644
index 0000000..df6faa6
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
@@ -0,0 +1,687 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ 
+package org.apache.lucene.analysis.miscellaneous;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.RamUsageEstimator;
+
+import java.io.IOException;
+
+/**
+ * Splits words into subwords and performs optional transformations on subword groups.
+ * Words are split into subwords with the following rules:
+ *  - split on intra-word delimiters (by default, all non alpha-numeric characters).
+ *     - "Wi-Fi" -> "Wi", "Fi"
+ *  - split on case transitions
+ *     - "PowerShot" -> "Power", "Shot"
+ *  - split on letter-number transitions
+ *     - "SD500" -> "SD", "500"
+ *  - leading and trailing intra-word delimiters on each subword are ignored
+ *     - "//hello---there, 'dude'" -> "hello", "there", "dude"
+ *  - trailing "'s" are removed for each subword
+ *     - "O'Neil's" -> "O", "Neil"
+ *     - Note: this step isn't performed in a separate filter because of possible subword combinations.
+ *
+ * The <b>combinations</b> parameter affects how subwords are combined:
+ *  - combinations="0" causes no subword combinations.
+ *     - "PowerShot" -> 0:"Power", 1:"Shot"  (0 and 1 are the token positions)
+ *  - combinations="1" means that in addition to the subwords, maximum runs of non-numeric subwords are catenated and produced at the same position of the last subword in the run.
+ *     - "PowerShot" -> 0:"Power", 1:"Shot" 1:"PowerShot"
+ *     - "A's+B's&C's" -> 0:"A", 1:"B", 2:"C", 2:"ABC"
+ *     - "Super-Duper-XL500-42-AutoCoder!" -> 0:"Super", 1:"Duper", 2:"XL", 2:"SuperDuperXL", 3:"500" 4:"42", 5:"Auto", 6:"Coder", 6:"AutoCoder"
+ *
+ *  One use for WordDelimiterFilter is to help match words with different subword delimiters.
+ *  For example, if the source text contained "wi-fi" one may want "wifi" "WiFi" "wi-fi" "wi+fi" queries to all match.
+ *  One way of doing so is to specify combinations="1" in the analyzer used for indexing, and combinations="0" (the default)
+ *  in the analyzer used for querying.  Given that the current StandardTokenizer immediately removes many intra-word
+ *  delimiters, it is recommended that this filter be used after a tokenizer that does not do this (such as WhitespaceTokenizer).
+ *
+ */
+
+public final class WordDelimiterFilter extends TokenFilter {
+  
+  public static final int LOWER = 0x01;
+  public static final int UPPER = 0x02;
+  public static final int DIGIT = 0x04;
+  public static final int SUBWORD_DELIM = 0x08;
+
+  // combinations: for testing, not for setting bits
+  public static final int ALPHA = 0x03;
+  public static final int ALPHANUM = 0x07;
+
+  /**
+   * If true, causes parts of words to be generated:
+   * <p/>
+   * "PowerShot" => "Power" "Shot"
+   */
+  final boolean generateWordParts;
+
+  /**
+   * If true, causes number subwords to be generated:
+   * <p/>
+   * "500-42" => "500" "42"
+   */
+  final boolean generateNumberParts;
+
+  /**
+   * If true, causes maximum runs of word parts to be catenated:
+   * <p/>
+   * "wi-fi" => "wifi"
+   */
+  final boolean catenateWords;
+
+  /**
+   * If true, causes maximum runs of number parts to be catenated:
+   * <p/>
+   * "500-42" => "50042"
+   */
+  final boolean catenateNumbers;
+
+  /**
+   * If true, causes all subword parts to be catenated:
+   * <p/>
+   * "wi-fi-4000" => "wifi4000"
+   */
+  final boolean catenateAll;
+
+  /**
+   * If true, original words are preserved and added to the subword list (Defaults to false)
+   * <p/>
+   * "500-42" => "500" "42" "500-42"
+   */
+  final boolean preserveOriginal;
+  
+  /**
+   * If not null is the set of tokens to protect from being delimited
+   *
+   */
+  final CharArraySet protWords;
+    
+  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
+  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
+  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
+
+  // used for iterating word delimiter breaks
+  private final WordDelimiterIterator iterator;
+
+  // used for concatenating runs of similar typed subwords (word,number)
+  private final WordDelimiterConcatenation concat = new WordDelimiterConcatenation();
+  // number of subwords last output by concat.
+  private int lastConcatCount = 0;
+
+  // used for catenate all
+  private final WordDelimiterConcatenation concatAll = new WordDelimiterConcatenation();
+
+  // used for accumulating position increment gaps
+  private int accumPosInc = 0;
+
+  private char savedBuffer[] = new char[1024];
+  private int savedStartOffset;
+  private int savedEndOffset;
+  private String savedType;
+  private boolean hasSavedState = false;
+  // if length by start + end offsets doesn't match the term text then assume
+  // this is a synonym and don't adjust the offsets.
+  private boolean hasIllegalOffsets = false;
+
+  // for a run of the same subword type within a word, have we output anything?
+  private boolean hasOutputToken = false;
+  // when preserve original is on, have we output any token following it?
+  // this token must have posInc=0!
+  private boolean hasOutputFollowingOriginal = false;
+
+  /**
+   * @param in Token stream to be filtered.
+   * @param charTypeTable
+   * @param generateWordParts If 1, causes parts of words to be generated: "PowerShot" => "Power" "Shot"
+   * @param generateNumberParts If 1, causes number subwords to be generated: "500-42" => "500" "42"
+   * @param catenateWords  1, causes maximum runs of word parts to be catenated: "wi-fi" => "wifi"
+   * @param catenateNumbers If 1, causes maximum runs of number parts to be catenated: "500-42" => "50042"
+   * @param catenateAll If 1, causes all subword parts to be catenated: "wi-fi-4000" => "wifi4000"
+   * @param splitOnCaseChange 1, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
+   * @param preserveOriginal If 1, includes original words in subwords: "500-42" => "500" "42" "500-42"
+   * @param splitOnNumerics 1, causes "j2se" to be three tokens; "j" "2" "se"
+   * @param stemEnglishPossessive If 1, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
+   * @param protWords If not null is the set of tokens to protect from being delimited
+   */
+  public WordDelimiterFilter(TokenStream in,
+                             byte[] charTypeTable,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal,
+                             int splitOnNumerics,
+                             int stemEnglishPossessive,
+                             CharArraySet protWords) {
+    super(in);
+    this.generateWordParts = generateWordParts != 0;
+    this.generateNumberParts = generateNumberParts != 0;
+    this.catenateWords = catenateWords != 0;
+    this.catenateNumbers = catenateNumbers != 0;
+    this.catenateAll = catenateAll != 0;
+    this.preserveOriginal = preserveOriginal != 0;
+    this.protWords = protWords;
+    this.iterator = new WordDelimiterIterator(charTypeTable, splitOnCaseChange != 0, splitOnNumerics != 0, stemEnglishPossessive != 0);
+  }
+  
+  /**
+   * Compatibility constructor
+   * 
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             byte[] charTypeTable,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal,
+                             int splitOnNumerics,
+                             CharArraySet protWords) {
+    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, 1, null);
+  }
+
+  /**
+   * Compatibility constructor
+   * 
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             byte[] charTypeTable,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal) {
+    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, null);
+  }
+
+  /**
+   * @param in Token stream to be filtered.
+   * @param generateWordParts If 1, causes parts of words to be generated: "PowerShot", "Power-Shot" => "Power" "Shot"
+   * @param generateNumberParts If 1, causes number subwords to be generated: "500-42" => "500" "42"
+   * @param catenateWords  1, causes maximum runs of word parts to be catenated: "wi-fi" => "wifi"
+   * @param catenateNumbers If 1, causes maximum runs of number parts to be catenated: "500-42" => "50042"
+   * @param catenateAll If 1, causes all subword parts to be catenated: "wi-fi-4000" => "wifi4000"
+   * @param splitOnCaseChange 1, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
+   * @param preserveOriginal If 1, includes original words in subwords: "500-42" => "500" "42" "500-42"
+   * @param splitOnNumerics 1, causes "j2se" to be three tokens; "j" "2" "se"
+   * @param stemEnglishPossessive If 1, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
+   * @param protWords If not null is the set of tokens to protect from being delimited
+   */
+  public WordDelimiterFilter(TokenStream in,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal,
+                             int splitOnNumerics,
+                             int stemEnglishPossessive,
+                             CharArraySet protWords) {
+    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, stemEnglishPossessive, protWords);
+  }
+  
+  /**
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal,
+                             int splitOnNumerics,
+                             CharArraySet protWords) {
+    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, 1, protWords);
+  }
+
+  /**   * Compatibility constructor
+   * 
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll,
+                             int splitOnCaseChange,
+                             int preserveOriginal) {
+    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal);
+  }
+  /**
+   * Compatibility constructor
+   * 
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             byte[] charTypeTable,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll) {
+    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
+  }
+  /**
+   * Compatibility constructor
+   * 
+   * @deprecated Use
+   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
+   *             instead.
+   */
+  @Deprecated
+  public WordDelimiterFilter(TokenStream in,
+                             int generateWordParts,
+                             int generateNumberParts,
+                             int catenateWords,
+                             int catenateNumbers,
+                             int catenateAll) {
+    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
+  }
+  
+  public boolean incrementToken() throws IOException {
+    while (true) {
+      if (!hasSavedState) {
+        // process a new input word
+        if (!input.incrementToken()) {
+          return false;
+        }
+
+        int termLength = termAttribute.length();
+        char[] termBuffer = termAttribute.buffer();
+        
+        accumPosInc += posIncAttribute.getPositionIncrement();
+
+        iterator.setText(termBuffer, termLength);
+        iterator.next();
+
+        // word of no delimiters, or protected word: just return it
+        if ((iterator.current == 0 && iterator.end == termLength) ||
+            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {
+          posIncAttribute.setPositionIncrement(accumPosInc);
+          accumPosInc = 0;
+          return true;
+        }
+        
+        // word of simply delimiters
+        if (iterator.end == WordDelimiterIterator.DONE && !preserveOriginal) {
+          // if the posInc is 1, simply ignore it in the accumulation
+          if (posIncAttribute.getPositionIncrement() == 1) {
+            accumPosInc--;
+          }
+          continue;
+        }
+
+        saveState();
+
+        hasOutputToken = false;
+        hasOutputFollowingOriginal = !preserveOriginal;
+        lastConcatCount = 0;
+        
+        if (preserveOriginal) {
+          posIncAttribute.setPositionIncrement(accumPosInc);
+          accumPosInc = 0;
+          return true;
+        }
+      }
+      
+      // at the end of the string, output any concatenations
+      if (iterator.end == WordDelimiterIterator.DONE) {
+        if (!concat.isEmpty()) {
+          if (flushConcatenation(concat)) {
+            return true;
+          }
+        }
+        
+        if (!concatAll.isEmpty()) {
+          // only if we haven't output this same combo above!
+          if (concatAll.subwordCount > lastConcatCount) {
+            concatAll.writeAndClear();
+            return true;
+          }
+          concatAll.clear();
+        }
+        
+        // no saved concatenations, on to the next input word
+        hasSavedState = false;
+        continue;
+      }
+      
+      // word surrounded by delimiters: always output
+      if (iterator.isSingleWord()) {
+        generatePart(true);
+        iterator.next();
+        return true;
+      }
+      
+      int wordType = iterator.type();
+      
+      // do we already have queued up incompatible concatenations?
+      if (!concat.isEmpty() && (concat.type & wordType) == 0) {
+        if (flushConcatenation(concat)) {
+          hasOutputToken = false;
+          return true;
+        }
+        hasOutputToken = false;
+      }
+      
+      // add subwords depending upon options
+      if (shouldConcatenate(wordType)) {
+        if (concat.isEmpty()) {
+          concat.type = wordType;
+        }
+        concatenate(concat);
+      }
+      
+      // add all subwords (catenateAll)
+      if (catenateAll) {
+        concatenate(concatAll);
+      }
+      
+      // if we should output the word or number part
+      if (shouldGenerateParts(wordType)) {
+        generatePart(false);
+        iterator.next();
+        return true;
+      }
+        
+      iterator.next();
+    }
+  }
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    hasSavedState = false;
+    concat.clear();
+    concatAll.clear();
+    accumPosInc = 0;
+  }
+
+  // ================================================= Helper Methods ================================================
+
+  /**
+   * Saves the existing attribute states
+   */
+  private void saveState() {
+    // otherwise, we have delimiters, save state
+    savedStartOffset = offsetAttribute.startOffset();
+    savedEndOffset = offsetAttribute.endOffset();
+    // if length by start + end offsets doesn't match the term text then assume this is a synonym and don't adjust the offsets.
+    hasIllegalOffsets = (savedEndOffset - savedStartOffset != termAttribute.length());
+    savedType = typeAttribute.type();
+
+    if (savedBuffer.length < termAttribute.length()) {
+      savedBuffer = new char[ArrayUtil.oversize(termAttribute.length(), RamUsageEstimator.NUM_BYTES_CHAR)];
+    }
+
+    System.arraycopy(termAttribute.buffer(), 0, savedBuffer, 0, termAttribute.length());
+    iterator.text = savedBuffer;
+
+    hasSavedState = true;
+  }
+
+  /**
+   * Flushes the given WordDelimiterConcatenation by either writing its concat and then clearing, or just clearing.
+   *
+   * @param concatenation WordDelimiterConcatenation that will be flushed
+   * @return {@code true} if the concatenation was written before it was cleared, {@code} false otherwise
+   */
+  private boolean flushConcatenation(WordDelimiterConcatenation concatenation) {
+    lastConcatCount = concatenation.subwordCount;
+    if (concatenation.subwordCount != 1 || !shouldGenerateParts(concatenation.type)) {
+      concatenation.writeAndClear();
+      return true;
+    }
+    concatenation.clear();
+    return false;
+  }
+
+  /**
+   * Determines whether to concatenate a word or number if the current word is the given type
+   *
+   * @param wordType Type of the current word used to determine if it should be concatenated
+   * @return {@code true} if concatenation should occur, {@code false} otherwise
+   */
+  private boolean shouldConcatenate(int wordType) {
+    return (catenateWords && isAlpha(wordType)) || (catenateNumbers && isDigit(wordType));
+  }
+
+  /**
+   * Determines whether a word/number part should be generated for a word of the given type
+   *
+   * @param wordType Type of the word used to determine if a word/number part should be generated
+   * @return {@code true} if a word/number part should be generated, {@code false} otherwise
+   */
+  private boolean shouldGenerateParts(int wordType) {
+    return (generateWordParts && isAlpha(wordType)) || (generateNumberParts && isDigit(wordType));
+  }
+
+  /**
+   * Concatenates the saved buffer to the given WordDelimiterConcatenation
+   *
+   * @param concatenation WordDelimiterConcatenation to concatenate the buffer to
+   */
+  private void concatenate(WordDelimiterConcatenation concatenation) {
+    if (concatenation.isEmpty()) {
+      concatenation.startOffset = savedStartOffset + iterator.current;
+    }
+    concatenation.append(savedBuffer, iterator.current, iterator.end - iterator.current);
+    concatenation.endOffset = savedStartOffset + iterator.end;
+  }
+
+  /**
+   * Generates a word/number part, updating the appropriate attributes
+   *
+   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise
+   */
+  private void generatePart(boolean isSingleWord) {
+    clearAttributes();
+    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);
+
+    int startOffSet = (isSingleWord || !hasIllegalOffsets) ? savedStartOffset + iterator.current : savedStartOffset;
+    int endOffSet = (hasIllegalOffsets) ? savedEndOffset : savedStartOffset + iterator.end;
+
+    offsetAttribute.setOffset(startOffSet, endOffSet);
+    posIncAttribute.setPositionIncrement(position(false));
+    typeAttribute.setType(savedType);
+  }
+
+  /**
+   * Get the position increment gap for a subword or concatenation
+   *
+   * @param inject true if this token wants to be injected
+   * @return position increment gap
+   */
+  private int position(boolean inject) {
+    int posInc = accumPosInc;
+
+    if (hasOutputToken) {
+      accumPosInc = 0;
+      return inject ? 0 : Math.max(1, posInc);
+    }
+
+    hasOutputToken = true;
+    
+    if (!hasOutputFollowingOriginal) {
+      // the first token following the original is 0 regardless
+      hasOutputFollowingOriginal = true;
+      return 0;
+    }
+    // clear the accumulated position increment
+    accumPosInc = 0;
+    return Math.max(1, posInc);
+  }
+
+  /**
+   * Checks if the given word type includes {@link #ALPHA}
+   *
+   * @param type Word type to check
+   * @return {@code true} if the type contains ALPHA, {@code false} otherwise
+   */
+  static boolean isAlpha(int type) {
+    return (type & ALPHA) != 0;
+  }
+
+  /**
+   * Checks if the given word type includes {@link #DIGIT}
+   *
+   * @param type Word type to check
+   * @return {@code true} if the type contains DIGIT, {@code false} otherwise
+   */
+  static boolean isDigit(int type) {
+    return (type & DIGIT) != 0;
+  }
+
+  /**
+   * Checks if the given word type includes {@link #SUBWORD_DELIM}
+   *
+   * @param type Word type to check
+   * @return {@code true} if the type contains SUBWORD_DELIM, {@code false} otherwise
+   */
+  static boolean isSubwordDelim(int type) {
+    return (type & SUBWORD_DELIM) != 0;
+  }
+
+  /**
+   * Checks if the given word type includes {@link #UPPER}
+   *
+   * @param type Word type to check
+   * @return {@code true} if the type contains UPPER, {@code false} otherwise
+   */
+  static boolean isUpper(int type) {
+    return (type & UPPER) != 0;
+  }
+
+  // ================================================= Inner Classes =================================================
+
+  /**
+   * A WDF concatenated 'run'
+   */
+  final class WordDelimiterConcatenation {
+    final StringBuilder buffer = new StringBuilder();
+    int startOffset;
+    int endOffset;
+    int type;
+    int subwordCount;
+
+    /**
+     * Appends the given text of the given length, to the concetenation at the given offset
+     *
+     * @param text Text to append
+     * @param offset Offset in the concetenation to add the text
+     * @param length Length of the text to append
+     */
+    void append(char text[], int offset, int length) {
+      buffer.append(text, offset, length);
+      subwordCount++;
+    }
+
+    /**
+     * Writes the concatenation to the attributes
+     */
+    void write() {
+      clearAttributes();
+      if (termAttribute.length() < buffer.length()) {
+        termAttribute.resizeBuffer(buffer.length());
+      }
+      char termbuffer[] = termAttribute.buffer();
+      
+      buffer.getChars(0, buffer.length(), termbuffer, 0);
+      termAttribute.setLength(buffer.length());
+        
+      if (hasIllegalOffsets) {
+        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);
+      }
+      else {
+        offsetAttribute.setOffset(startOffset, endOffset);
+      }
+      posIncAttribute.setPositionIncrement(position(true));
+      typeAttribute.setType(savedType);
+      accumPosInc = 0;
+    }
+
+    /**
+     * Determines if the concatenation is empty
+     *
+     * @return {@code true} if the concatenation is empty, {@code false} otherwise
+     */
+    boolean isEmpty() {
+      return buffer.length() == 0;
+    }
+
+    /**
+     * Clears the concatenation and resets its state
+     */
+    void clear() {
+      buffer.setLength(0);
+      startOffset = endOffset = type = subwordCount = 0;
+    }
+
+    /**
+     * Convenience method for the common scenario of having to write the concetenation and then clearing its state
+     */
+    void writeAndClear() {
+      write();
+      clear();
+    }
+  }
+  // questions:
+  // negative numbers?  -42 indexed as just 42?
+  // dollar sign?  $42
+  // percent sign?  33%
+  // downsides:  if source text is "powershot" then a query of "PowerShot" won't match!
+}
diff --git a/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java
new file mode 100644
index 0000000..d53ea0a
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java
@@ -0,0 +1,315 @@
+package org.apache.lucene.analysis.miscellaneous;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import static org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter.*;
+
+/**
+ * A BreakIterator-like API for iterating over subwords in text, according to WordDelimiterFilter rules.
+ */
+final class WordDelimiterIterator {
+
+  /** Indicates the end of iteration */
+  public static final int DONE = -1;
+  
+  public static final byte[] DEFAULT_WORD_DELIM_TABLE;
+
+  char text[];
+  int length;
+  
+  /** start position of text, excluding leading delimiters */
+  int startBounds;
+  /** end position of text, excluding trailing delimiters */
+  int endBounds;
+  
+  /** Beginning of subword */
+  int current;
+  /** End of subword */
+  int end;
+  
+  /* does this string end with a possessive such as 's */
+  private boolean hasFinalPossessive = false;
+  
+  /**
+   * If false, causes case changes to be ignored (subwords will only be generated
+   * given SUBWORD_DELIM tokens). (Defaults to true)
+   */
+  final boolean splitOnCaseChange;
+  
+  /**
+   * If false, causes numeric changes to be ignored (subwords will only be generated
+   * given SUBWORD_DELIM tokens). (Defaults to true)
+   */
+  final boolean splitOnNumerics;
+
+  /**
+   * If true, causes trailing "'s" to be removed for each subword. (Defaults to true)
+   * <p/>
+   * "O'Neil's" => "O", "Neil"
+   */
+  final boolean stemEnglishPossessive;
+  
+  private final byte[] charTypeTable;
+  
+  /** if true, need to skip over a possessive found in the last call to next() */
+  private boolean skipPossessive = false;
+
+  // TODO: should there be a WORD_DELIM category for chars that only separate words (no catenation of subwords will be
+  // done if separated by these chars?) "," would be an obvious candidate...
+  static {
+    byte[] tab = new byte[256];
+    for (int i = 0; i < 256; i++) {
+      byte code = 0;
+      if (Character.isLowerCase(i)) {
+        code |= LOWER;
+      }
+      else if (Character.isUpperCase(i)) {
+        code |= UPPER;
+      }
+      else if (Character.isDigit(i)) {
+        code |= DIGIT;
+      }
+      if (code == 0) {
+        code = SUBWORD_DELIM;
+      }
+      tab[i] = code;
+    }
+    DEFAULT_WORD_DELIM_TABLE = tab;
+  }
+
+  /**
+   * Create a new WordDelimiterIterator operating with the supplied rules.
+   * 
+   * @param charTypeTable table containing character types
+   * @param splitOnCaseChange if true, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
+   * @param splitOnNumerics if true, causes "j2se" to be three tokens; "j" "2" "se"
+   * @param stemEnglishPossessive if true, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
+   */
+  WordDelimiterIterator(byte[] charTypeTable, boolean splitOnCaseChange, boolean splitOnNumerics, boolean stemEnglishPossessive) {
+    this.charTypeTable = charTypeTable;
+    this.splitOnCaseChange = splitOnCaseChange;
+    this.splitOnNumerics = splitOnNumerics;
+    this.stemEnglishPossessive = stemEnglishPossessive;
+  }
+  
+  /**
+   * Advance to the next subword in the string.
+   *
+   * @return index of the next subword, or {@link #DONE} if all subwords have been returned
+   */
+  int next() {
+    current = end;
+    if (current == DONE) {
+      return DONE;
+    }
+    
+    if (skipPossessive) {
+      current += 2;
+      skipPossessive = false;
+    }
+
+    int lastType = 0;
+    
+    while (current < endBounds && (isSubwordDelim(lastType = charType(text[current])))) {
+      current++;
+    }
+
+    if (current >= endBounds) {
+      return end = DONE;
+    }
+    
+    for (end = current + 1; end < endBounds; end++) {
+      int type = charType(text[end]);
+      if (isBreak(lastType, type)) {
+        break;
+      }
+      lastType = type;
+    }
+    
+    if (end < endBounds - 1 && endsWithPossessive(end + 2)) {
+      skipPossessive = true;
+    }
+    
+    return end;
+  }
+
+
+  /**
+   * Return the type of the current subword.
+   * This currently uses the type of the first character in the subword.
+   *
+   * @return type of the current word
+   */
+  int type() {
+    if (end == DONE) {
+      return 0;
+    }
+    
+    int type = charType(text[current]);
+    switch (type) {
+      // return ALPHA word type for both lower and upper
+      case LOWER:
+      case UPPER:
+        return ALPHA;
+      default:
+        return type;
+    }
+  }
+
+  /**
+   * Reset the text to a new value, and reset all state
+   *
+   * @param text New text
+   * @param length length of the text
+   */
+  void setText(char text[], int length) {
+    this.text = text;
+    this.length = this.endBounds = length;
+    current = startBounds = end = 0;
+    skipPossessive = hasFinalPossessive = false;
+    setBounds();
+  }
+
+  // ================================================= Helper Methods ================================================
+
+  /**
+   * Determines whether the transition from lastType to type indicates a break
+   *
+   * @param lastType Last subword type
+   * @param type Current subword type
+   * @return {@code true} if the transition indicates a break, {@code false} otherwise
+   */
+  private boolean isBreak(int lastType, int type) {
+    if ((type & lastType) != 0) {
+      return false;
+    }
+    
+    if (!splitOnCaseChange && isAlpha(lastType) && isAlpha(type)) {
+      // ALPHA->ALPHA: always ignore if case isn't considered.
+      return false;
+    } else if (isUpper(lastType) && isAlpha(type)) {
+      // UPPER->letter: Don't split
+      return false;
+    } else if (!splitOnNumerics && ((isAlpha(lastType) && isDigit(type)) || (isDigit(lastType) && isAlpha(type)))) {
+      // ALPHA->NUMERIC, NUMERIC->ALPHA :Don't split
+      return false;
+    }
+
+    return true;
+  }
+  
+  /**
+   * Determines if the current word contains only one subword.  Note, it could be potentially surrounded by delimiters
+   *
+   * @return {@code true} if the current word contains only one subword, {@code false} otherwise
+   */
+  boolean isSingleWord() {
+    if (hasFinalPossessive) {
+      return current == startBounds && end == endBounds - 2;
+    }
+    else {
+      return current == startBounds && end == endBounds;
+    }
+  }
+   
+  /**
+   * Set the internal word bounds (remove leading and trailing delimiters). Note, if a possessive is found, don't remove
+   * it yet, simply note it.
+   */
+  private void setBounds() {
+    while (startBounds < length && (isSubwordDelim(charType(text[startBounds])))) {
+      startBounds++;
+    }
+    
+    while (endBounds > startBounds && (isSubwordDelim(charType(text[endBounds - 1])))) {
+      endBounds--;
+    }
+    if (endsWithPossessive(endBounds)) {
+      hasFinalPossessive = true;
+    }
+    current = startBounds;
+  }
+  
+  /**
+   * Determines if the text at the given position indicates an English possessive which should be removed
+   *
+   * @param pos Position in the text to check if it indicates an English possessive
+   * @return {@code true} if the text at the position indicates an English posessive, {@code false} otherwise
+   */
+  private boolean endsWithPossessive(int pos) {
+    return (stemEnglishPossessive &&
+            pos > 2 &&
+            text[pos - 2] == '\'' &&
+            (text[pos - 1] == 's' || text[pos - 1] == 'S') &&
+            isAlpha(charType(text[pos - 3])) &&
+            (pos == endBounds || isSubwordDelim(charType(text[pos]))));
+  }
+
+  /**
+   * Determines the type of the given character
+   *
+   * @param ch Character whose type is to be determined
+   * @return Type of the character
+   */
+  private int charType(int ch) {
+    if (ch < charTypeTable.length) {
+      return charTypeTable[ch];
+    }
+    switch (Character.getType(ch)) {
+      case Character.UPPERCASE_LETTER: return UPPER;
+      case Character.LOWERCASE_LETTER: return LOWER;
+
+      case Character.TITLECASE_LETTER:
+      case Character.MODIFIER_LETTER:
+      case Character.OTHER_LETTER:
+      case Character.NON_SPACING_MARK:
+      case Character.ENCLOSING_MARK:  // depends what it encloses?
+      case Character.COMBINING_SPACING_MARK:
+        return ALPHA; 
+
+      case Character.DECIMAL_DIGIT_NUMBER:
+      case Character.LETTER_NUMBER:
+      case Character.OTHER_NUMBER:
+        return DIGIT;
+
+      // case Character.SPACE_SEPARATOR:
+      // case Character.LINE_SEPARATOR:
+      // case Character.PARAGRAPH_SEPARATOR:
+      // case Character.CONTROL:
+      // case Character.FORMAT:
+      // case Character.PRIVATE_USE:
+
+      case Character.SURROGATE:  // prevent splitting
+        return ALPHA|DIGIT;  
+
+      // case Character.DASH_PUNCTUATION:
+      // case Character.START_PUNCTUATION:
+      // case Character.END_PUNCTUATION:
+      // case Character.CONNECTOR_PUNCTUATION:
+      // case Character.OTHER_PUNCTUATION:
+      // case Character.MATH_SYMBOL:
+      // case Character.CURRENCY_SYMBOL:
+      // case Character.MODIFIER_SYMBOL:
+      // case Character.OTHER_SYMBOL:
+      // case Character.INITIAL_QUOTE_PUNCTUATION:
+      // case Character.FINAL_QUOTE_PUNCTUATION:
+
+      default: return SUBWORD_DELIM;
+    }
+  }
+}
\ No newline at end of file
diff --git a/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
new file mode 100644
index 0000000..e04a469
--- /dev/null
+++ b/lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
@@ -0,0 +1,313 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.lucene.analysis.miscellaneous;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.KeywordTokenizer;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.WhitespaceTokenizer;
+import org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Arrays;
+import java.util.HashSet;
+
+/**
+ * New WordDelimiterFilter tests... most of the tests are in ConvertedLegacyTest
+ * TODO: should explicitly test things like protWords and not rely on
+ * the factory tests in Solr.
+ */
+public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
+
+  /***
+  public void testPerformance() throws IOException {
+    String s = "now is the time-for all good men to come to-the aid of their country.";
+    Token tok = new Token();
+    long start = System.currentTimeMillis();
+    int ret=0;
+    for (int i=0; i<1000000; i++) {
+      StringReader r = new StringReader(s);
+      TokenStream ts = new WhitespaceTokenizer(r);
+      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);
+
+      while (ts.next(tok) != null) ret++;
+    }
+
+    System.out.println("ret="+ret+" time="+(System.currentTimeMillis()-start));
+  }
+  ***/
+
+  @Test
+  public void testOffsets() throws IOException {
+
+    // test that subwords and catenated subwords have
+    // the correct offsets.
+    WordDelimiterFilter wdf = new WordDelimiterFilter(
+            new SingleTokenTokenStream(new Token("foo-bar", 5, 12)),
+    1,1,0,0,1,1,0);
+
+    assertTokenStreamContents(wdf, 
+        new String[] { "foo", "bar", "foobar" },
+        new int[] { 5, 9, 5 }, 
+        new int[] { 8, 12, 12 });
+
+    wdf = new WordDelimiterFilter(
+            new SingleTokenTokenStream(new Token("foo-bar", 5, 6)),
+    1,1,0,0,1,1,0);
+    
+    assertTokenStreamContents(wdf,
+        new String[] { "foo", "bar", "foobar" },
+        new int[] { 5, 5, 5 },
+        new int[] { 6, 6, 6 });
+  }
+  
+  @Test
+  public void testOffsetChange() throws Exception
+  {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(
+      new SingleTokenTokenStream(new Token("Ã¼belkeit)", 7, 16)),
+      1,1,0,0,1,1,0
+    );
+    
+    assertTokenStreamContents(wdf,
+        new String[] { "Ã¼belkeit" },
+        new int[] { 7 },
+        new int[] { 15 });
+  }
+  
+  @Test
+  public void testOffsetChange2() throws Exception
+  {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(
+      new SingleTokenTokenStream(new Token("(Ã¼belkeit", 7, 17)),
+      1,1,0,0,1,1,0
+    );
+    
+    assertTokenStreamContents(wdf,
+        new String[] { "Ã¼belkeit" },
+        new int[] { 8 },
+        new int[] { 17 });
+  }
+  
+  @Test
+  public void testOffsetChange3() throws Exception
+  {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(
+      new SingleTokenTokenStream(new Token("(Ã¼belkeit", 7, 16)),
+      1,1,0,0,1,1,0
+    );
+    
+    assertTokenStreamContents(wdf,
+        new String[] { "Ã¼belkeit" },
+        new int[] { 8 },
+        new int[] { 16 });
+  }
+  
+  @Test
+  public void testOffsetChange4() throws Exception
+  {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(
+      new SingleTokenTokenStream(new Token("(foo,bar)", 7, 16)),
+      1,1,0,0,1,1,0
+    );
+    
+    assertTokenStreamContents(wdf,
+        new String[] { "foo", "bar", "foobar"},
+        new int[] { 8, 12, 8 },
+        new int[] { 11, 15, 15 });
+  }
+
+  public void doSplit(final String input, String... output) throws Exception {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(
+        new StringReader(input)), 1, 1, 0, 0, 0);
+    
+    assertTokenStreamContents(wdf, output);
+  }
+
+  @Test
+  public void testSplits() throws Exception {
+    doSplit("basic-split","basic","split");
+    doSplit("camelCase","camel","Case");
+
+    // non-space marking symbol shouldn't cause split
+    // this is an example in Thai    
+    doSplit("\u0e1a\u0e49\u0e32\u0e19","\u0e1a\u0e49\u0e32\u0e19");
+    // possessive followed by delimiter
+    doSplit("test's'", "test");
+
+    // some russian upper and lowercase
+    doSplit("?Ð¾Ð±Ðµ??", "?Ð¾Ð±Ðµ??");
+    // now cause a split (russian camelCase)
+    doSplit("?Ð¾Ð±???", "?Ð¾Ð±", "???");
+
+    // a composed titlecase character, don't split
+    doSplit("a?ungla", "a?ungla");
+    
+    // a modifier letter, don't split
+    doSplit("Ø³??????????????????Ø§?", "Ø³??????????????????Ø§?");
+    
+    // enclosing mark, don't split
+    doSplit("?test", "?test");
+    
+    // combining spacing mark (the virama), don't split
+    doSplit("à¤¹à¤¿à¤¨à?à¤??", "à¤¹à¤¿à¤¨à?à¤??");
+    
+    // don't split non-ascii digits
+    doSplit("Ù¡Ù¢Ù£Ù¤", "Ù¡Ù¢Ù£Ù¤");
+    
+    // don't split supplementaries into unpaired surrogates
+    doSplit("??????", "??????");
+  }
+  
+  public void doSplitPossessive(int stemPossessive, final String input, final String... output) throws Exception {
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(
+        new StringReader(input)), 1,1,0,0,0,1,0,1,stemPossessive, null);
+
+    assertTokenStreamContents(wdf, output);
+  }
+  
+  /*
+   * Test option that allows disabling the special "'s" stemming, instead treating the single quote like other delimiters. 
+   */
+  @Test
+  public void testPossessives() throws Exception {
+    doSplitPossessive(1, "ra's", "ra");
+    doSplitPossessive(0, "ra's", "ra", "s");
+  }
+  
+  /*
+   * Set a large position increment gap of 10 if the token is "largegap" or "/"
+   */
+  private final class LargePosIncTokenFilter extends TokenFilter {
+    private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    private PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+    
+    protected LargePosIncTokenFilter(TokenStream input) {
+      super(input);
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      if (input.incrementToken()) {
+        if (termAtt.toString().equals("largegap") || termAtt.toString().equals("/"))
+          posIncAtt.setPositionIncrement(10);
+        return true;
+      } else {
+        return false;
+      }
+    }  
+  }
+  
+  @Test
+  public void testPositionIncrements() throws Exception {
+    final CharArraySet protWords = new CharArraySet(TEST_VERSION_CURRENT, new HashSet<String>(Arrays.asList("NUTCH")), false);
+    
+    /* analyzer that uses whitespace + wdf */
+    Analyzer a = new Analyzer() {
+      public TokenStream tokenStream(String field, Reader reader) {
+        return new WordDelimiterFilter(
+            new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader),
+            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
+      }
+    };
+
+    /* in this case, works as expected. */
+    assertAnalyzesTo(a, "LUCENE / SOLR", new String[] { "LUCENE", "SOLR" },
+        new int[] { 0, 9 },
+        new int[] { 6, 13 },
+        new int[] { 1, 1 });
+    
+    /* only in this case, posInc of 2 ?! */
+    assertAnalyzesTo(a, "LUCENE / solR", new String[] { "LUCENE", "sol", "R", "solR" },
+        new int[] { 0, 9, 12, 9 },
+        new int[] { 6, 12, 13, 13 },
+        new int[] { 1, 1, 1, 0 });
+    
+    assertAnalyzesTo(a, "LUCENE / NUTCH SOLR", new String[] { "LUCENE", "NUTCH", "SOLR" },
+        new int[] { 0, 9, 15 },
+        new int[] { 6, 14, 19 },
+        new int[] { 1, 1, 1 });
+    
+    /* analyzer that will consume tokens with large position increments */
+    Analyzer a2 = new Analyzer() {
+      public TokenStream tokenStream(String field, Reader reader) {
+        return new WordDelimiterFilter(
+            new LargePosIncTokenFilter(
+            new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader)),
+            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
+      }
+    };
+    
+    /* increment of "largegap" is preserved */
+    assertAnalyzesTo(a2, "LUCENE largegap SOLR", new String[] { "LUCENE", "largegap", "SOLR" },
+        new int[] { 0, 7, 16 },
+        new int[] { 6, 15, 20 },
+        new int[] { 1, 10, 1 });
+    
+    /* the "/" had a position increment of 10, where did it go?!?!! */
+    assertAnalyzesTo(a2, "LUCENE / SOLR", new String[] { "LUCENE", "SOLR" },
+        new int[] { 0, 9 },
+        new int[] { 6, 13 },
+        new int[] { 1, 11 });
+    
+    /* in this case, the increment of 10 from the "/" is carried over */
+    assertAnalyzesTo(a2, "LUCENE / solR", new String[] { "LUCENE", "sol", "R", "solR" },
+        new int[] { 0, 9, 12, 9 },
+        new int[] { 6, 12, 13, 13 },
+        new int[] { 1, 11, 1, 0 });
+    
+    assertAnalyzesTo(a2, "LUCENE / NUTCH SOLR", new String[] { "LUCENE", "NUTCH", "SOLR" },
+        new int[] { 0, 9, 15 },
+        new int[] { 6, 14, 19 },
+        new int[] { 1, 11, 1 });
+
+    Analyzer a3 = new Analyzer() {
+      public TokenStream tokenStream(String field, Reader reader) {
+        StopFilter filter = new StopFilter(TEST_VERSION_CURRENT,
+            new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader), StandardAnalyzer.STOP_WORDS_SET);
+        filter.setEnablePositionIncrements(true);
+        return new WordDelimiterFilter(filter, 
+            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
+      }
+    };
+
+    assertAnalyzesTo(a3, "lucene.solr", 
+        new String[] { "lucene", "solr", "lucenesolr" },
+        new int[] { 0, 7, 0 },
+        new int[] { 6, 11, 11 },
+        new int[] { 1, 1, 0 });
+
+    /* the stopword should add a gap here */
+    assertAnalyzesTo(a3, "the lucene.solr", 
+        new String[] { "lucene", "solr", "lucenesolr" }, 
+        new int[] { 4, 11, 4 }, 
+        new int[] { 10, 15, 15 },
+        new int[] { 2, 1, 0 });
+  }
+}
diff --git a/solr/src/java/org/apache/solr/analysis/WordDelimiterFilter.java b/solr/src/java/org/apache/solr/analysis/WordDelimiterFilter.java
deleted file mode 100644
index cf65608..0000000
--- a/solr/src/java/org/apache/solr/analysis/WordDelimiterFilter.java
+++ /dev/null
@@ -1,688 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
- 
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.RamUsageEstimator;
-
-import java.io.IOException;
-
-/**
- * Splits words into subwords and performs optional transformations on subword groups.
- * Words are split into subwords with the following rules:
- *  - split on intra-word delimiters (by default, all non alpha-numeric characters).
- *     - "Wi-Fi" -> "Wi", "Fi"
- *  - split on case transitions
- *     - "PowerShot" -> "Power", "Shot"
- *  - split on letter-number transitions
- *     - "SD500" -> "SD", "500"
- *  - leading and trailing intra-word delimiters on each subword are ignored
- *     - "//hello---there, 'dude'" -> "hello", "there", "dude"
- *  - trailing "'s" are removed for each subword
- *     - "O'Neil's" -> "O", "Neil"
- *     - Note: this step isn't performed in a separate filter because of possible subword combinations.
- *
- * The <b>combinations</b> parameter affects how subwords are combined:
- *  - combinations="0" causes no subword combinations.
- *     - "PowerShot" -> 0:"Power", 1:"Shot"  (0 and 1 are the token positions)
- *  - combinations="1" means that in addition to the subwords, maximum runs of non-numeric subwords are catenated and produced at the same position of the last subword in the run.
- *     - "PowerShot" -> 0:"Power", 1:"Shot" 1:"PowerShot"
- *     - "A's+B's&C's" -> 0:"A", 1:"B", 2:"C", 2:"ABC"
- *     - "Super-Duper-XL500-42-AutoCoder!" -> 0:"Super", 1:"Duper", 2:"XL", 2:"SuperDuperXL", 3:"500" 4:"42", 5:"Auto", 6:"Coder", 6:"AutoCoder"
- *
- *  One use for WordDelimiterFilter is to help match words with different subword delimiters.
- *  For example, if the source text contained "wi-fi" one may want "wifi" "WiFi" "wi-fi" "wi+fi" queries to all match.
- *  One way of doing so is to specify combinations="1" in the analyzer used for indexing, and combinations="0" (the default)
- *  in the analyzer used for querying.  Given that the current StandardTokenizer immediately removes many intra-word
- *  delimiters, it is recommended that this filter be used after a tokenizer that does not do this (such as WhitespaceTokenizer).
- *
- *  @version $Id$
- */
-
-final class WordDelimiterFilter extends TokenFilter {
-  
-  public static final int LOWER = 0x01;
-  public static final int UPPER = 0x02;
-  public static final int DIGIT = 0x04;
-  public static final int SUBWORD_DELIM = 0x08;
-
-  // combinations: for testing, not for setting bits
-  public static final int ALPHA = 0x03;
-  public static final int ALPHANUM = 0x07;
-
-  /**
-   * If true, causes parts of words to be generated:
-   * <p/>
-   * "PowerShot" => "Power" "Shot"
-   */
-  final boolean generateWordParts;
-
-  /**
-   * If true, causes number subwords to be generated:
-   * <p/>
-   * "500-42" => "500" "42"
-   */
-  final boolean generateNumberParts;
-
-  /**
-   * If true, causes maximum runs of word parts to be catenated:
-   * <p/>
-   * "wi-fi" => "wifi"
-   */
-  final boolean catenateWords;
-
-  /**
-   * If true, causes maximum runs of number parts to be catenated:
-   * <p/>
-   * "500-42" => "50042"
-   */
-  final boolean catenateNumbers;
-
-  /**
-   * If true, causes all subword parts to be catenated:
-   * <p/>
-   * "wi-fi-4000" => "wifi4000"
-   */
-  final boolean catenateAll;
-
-  /**
-   * If true, original words are preserved and added to the subword list (Defaults to false)
-   * <p/>
-   * "500-42" => "500" "42" "500-42"
-   */
-  final boolean preserveOriginal;
-  
-  /**
-   * If not null is the set of tokens to protect from being delimited
-   *
-   */
-  final CharArraySet protWords;
-    
-  private final CharTermAttribute termAttribute = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAttribute = addAttribute(OffsetAttribute.class);
-  private final PositionIncrementAttribute posIncAttribute = addAttribute(PositionIncrementAttribute.class);
-  private final TypeAttribute typeAttribute = addAttribute(TypeAttribute.class);
-
-  // used for iterating word delimiter breaks
-  private final WordDelimiterIterator iterator;
-
-  // used for concatenating runs of similar typed subwords (word,number)
-  private final WordDelimiterConcatenation concat = new WordDelimiterConcatenation();
-  // number of subwords last output by concat.
-  private int lastConcatCount = 0;
-
-  // used for catenate all
-  private final WordDelimiterConcatenation concatAll = new WordDelimiterConcatenation();
-
-  // used for accumulating position increment gaps
-  private int accumPosInc = 0;
-
-  private char savedBuffer[] = new char[1024];
-  private int savedStartOffset;
-  private int savedEndOffset;
-  private String savedType;
-  private boolean hasSavedState = false;
-  // if length by start + end offsets doesn't match the term text then assume
-  // this is a synonym and don't adjust the offsets.
-  private boolean hasIllegalOffsets = false;
-
-  // for a run of the same subword type within a word, have we output anything?
-  private boolean hasOutputToken = false;
-  // when preserve original is on, have we output any token following it?
-  // this token must have posInc=0!
-  private boolean hasOutputFollowingOriginal = false;
-
-  /**
-   * @param in Token stream to be filtered.
-   * @param charTypeTable
-   * @param generateWordParts If 1, causes parts of words to be generated: "PowerShot" => "Power" "Shot"
-   * @param generateNumberParts If 1, causes number subwords to be generated: "500-42" => "500" "42"
-   * @param catenateWords  1, causes maximum runs of word parts to be catenated: "wi-fi" => "wifi"
-   * @param catenateNumbers If 1, causes maximum runs of number parts to be catenated: "500-42" => "50042"
-   * @param catenateAll If 1, causes all subword parts to be catenated: "wi-fi-4000" => "wifi4000"
-   * @param splitOnCaseChange 1, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
-   * @param preserveOriginal If 1, includes original words in subwords: "500-42" => "500" "42" "500-42"
-   * @param splitOnNumerics 1, causes "j2se" to be three tokens; "j" "2" "se"
-   * @param stemEnglishPossessive If 1, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
-   * @param protWords If not null is the set of tokens to protect from being delimited
-   */
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             int stemEnglishPossessive,
-                             CharArraySet protWords) {
-    super(in);
-    this.generateWordParts = generateWordParts != 0;
-    this.generateNumberParts = generateNumberParts != 0;
-    this.catenateWords = catenateWords != 0;
-    this.catenateNumbers = catenateNumbers != 0;
-    this.catenateAll = catenateAll != 0;
-    this.preserveOriginal = preserveOriginal != 0;
-    this.protWords = protWords;
-    this.iterator = new WordDelimiterIterator(charTypeTable, splitOnCaseChange != 0, splitOnNumerics != 0, stemEnglishPossessive != 0);
-  }
-  
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             CharArraySet protWords) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, 1, null);
-  }
-
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, null);
-  }
-
-  /**
-   * @param in Token stream to be filtered.
-   * @param generateWordParts If 1, causes parts of words to be generated: "PowerShot", "Power-Shot" => "Power" "Shot"
-   * @param generateNumberParts If 1, causes number subwords to be generated: "500-42" => "500" "42"
-   * @param catenateWords  1, causes maximum runs of word parts to be catenated: "wi-fi" => "wifi"
-   * @param catenateNumbers If 1, causes maximum runs of number parts to be catenated: "500-42" => "50042"
-   * @param catenateAll If 1, causes all subword parts to be catenated: "wi-fi-4000" => "wifi4000"
-   * @param splitOnCaseChange 1, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
-   * @param preserveOriginal If 1, includes original words in subwords: "500-42" => "500" "42" "500-42"
-   * @param splitOnNumerics 1, causes "j2se" to be three tokens; "j" "2" "se"
-   * @param stemEnglishPossessive If 1, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
-   * @param protWords If not null is the set of tokens to protect from being delimited
-   */
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             int stemEnglishPossessive,
-                             CharArraySet protWords) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, stemEnglishPossessive, protWords);
-  }
-  
-  /**
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             CharArraySet protWords) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, 1, protWords);
-  }
-
-  /**   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal);
-  }
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
-  }
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
-  }
-  
-  public boolean incrementToken() throws IOException {
-    while (true) {
-      if (!hasSavedState) {
-        // process a new input word
-        if (!input.incrementToken()) {
-          return false;
-        }
-
-        int termLength = termAttribute.length();
-        char[] termBuffer = termAttribute.buffer();
-        
-        accumPosInc += posIncAttribute.getPositionIncrement();
-
-        iterator.setText(termBuffer, termLength);
-        iterator.next();
-
-        // word of no delimiters, or protected word: just return it
-        if ((iterator.current == 0 && iterator.end == termLength) ||
-            (protWords != null && protWords.contains(termBuffer, 0, termLength))) {
-          posIncAttribute.setPositionIncrement(accumPosInc);
-          accumPosInc = 0;
-          return true;
-        }
-        
-        // word of simply delimiters
-        if (iterator.end == WordDelimiterIterator.DONE && !preserveOriginal) {
-          // if the posInc is 1, simply ignore it in the accumulation
-          if (posIncAttribute.getPositionIncrement() == 1) {
-            accumPosInc--;
-          }
-          continue;
-        }
-
-        saveState();
-
-        hasOutputToken = false;
-        hasOutputFollowingOriginal = !preserveOriginal;
-        lastConcatCount = 0;
-        
-        if (preserveOriginal) {
-          posIncAttribute.setPositionIncrement(accumPosInc);
-          accumPosInc = 0;
-          return true;
-        }
-      }
-      
-      // at the end of the string, output any concatenations
-      if (iterator.end == WordDelimiterIterator.DONE) {
-        if (!concat.isEmpty()) {
-          if (flushConcatenation(concat)) {
-            return true;
-          }
-        }
-        
-        if (!concatAll.isEmpty()) {
-          // only if we haven't output this same combo above!
-          if (concatAll.subwordCount > lastConcatCount) {
-            concatAll.writeAndClear();
-            return true;
-          }
-          concatAll.clear();
-        }
-        
-        // no saved concatenations, on to the next input word
-        hasSavedState = false;
-        continue;
-      }
-      
-      // word surrounded by delimiters: always output
-      if (iterator.isSingleWord()) {
-        generatePart(true);
-        iterator.next();
-        return true;
-      }
-      
-      int wordType = iterator.type();
-      
-      // do we already have queued up incompatible concatenations?
-      if (!concat.isEmpty() && (concat.type & wordType) == 0) {
-        if (flushConcatenation(concat)) {
-          hasOutputToken = false;
-          return true;
-        }
-        hasOutputToken = false;
-      }
-      
-      // add subwords depending upon options
-      if (shouldConcatenate(wordType)) {
-        if (concat.isEmpty()) {
-          concat.type = wordType;
-        }
-        concatenate(concat);
-      }
-      
-      // add all subwords (catenateAll)
-      if (catenateAll) {
-        concatenate(concatAll);
-      }
-      
-      // if we should output the word or number part
-      if (shouldGenerateParts(wordType)) {
-        generatePart(false);
-        iterator.next();
-        return true;
-      }
-        
-      iterator.next();
-    }
-  }
-
-  /**
-   * {@inheritDoc}
-   */
-  @Override
-  public void reset() throws IOException {
-    super.reset();
-    hasSavedState = false;
-    concat.clear();
-    concatAll.clear();
-    accumPosInc = 0;
-  }
-
-  // ================================================= Helper Methods ================================================
-
-  /**
-   * Saves the existing attribute states
-   */
-  private void saveState() {
-    // otherwise, we have delimiters, save state
-    savedStartOffset = offsetAttribute.startOffset();
-    savedEndOffset = offsetAttribute.endOffset();
-    // if length by start + end offsets doesn't match the term text then assume this is a synonym and don't adjust the offsets.
-    hasIllegalOffsets = (savedEndOffset - savedStartOffset != termAttribute.length());
-    savedType = typeAttribute.type();
-
-    if (savedBuffer.length < termAttribute.length()) {
-      savedBuffer = new char[ArrayUtil.oversize(termAttribute.length(), RamUsageEstimator.NUM_BYTES_CHAR)];
-    }
-
-    System.arraycopy(termAttribute.buffer(), 0, savedBuffer, 0, termAttribute.length());
-    iterator.text = savedBuffer;
-
-    hasSavedState = true;
-  }
-
-  /**
-   * Flushes the given WordDelimiterConcatenation by either writing its concat and then clearing, or just clearing.
-   *
-   * @param concatenation WordDelimiterConcatenation that will be flushed
-   * @return {@code true} if the concatenation was written before it was cleared, {@code} false otherwise
-   */
-  private boolean flushConcatenation(WordDelimiterConcatenation concatenation) {
-    lastConcatCount = concatenation.subwordCount;
-    if (concatenation.subwordCount != 1 || !shouldGenerateParts(concatenation.type)) {
-      concatenation.writeAndClear();
-      return true;
-    }
-    concatenation.clear();
-    return false;
-  }
-
-  /**
-   * Determines whether to concatenate a word or number if the current word is the given type
-   *
-   * @param wordType Type of the current word used to determine if it should be concatenated
-   * @return {@code true} if concatenation should occur, {@code false} otherwise
-   */
-  private boolean shouldConcatenate(int wordType) {
-    return (catenateWords && isAlpha(wordType)) || (catenateNumbers && isDigit(wordType));
-  }
-
-  /**
-   * Determines whether a word/number part should be generated for a word of the given type
-   *
-   * @param wordType Type of the word used to determine if a word/number part should be generated
-   * @return {@code true} if a word/number part should be generated, {@code false} otherwise
-   */
-  private boolean shouldGenerateParts(int wordType) {
-    return (generateWordParts && isAlpha(wordType)) || (generateNumberParts && isDigit(wordType));
-  }
-
-  /**
-   * Concatenates the saved buffer to the given WordDelimiterConcatenation
-   *
-   * @param concatenation WordDelimiterConcatenation to concatenate the buffer to
-   */
-  private void concatenate(WordDelimiterConcatenation concatenation) {
-    if (concatenation.isEmpty()) {
-      concatenation.startOffset = savedStartOffset + iterator.current;
-    }
-    concatenation.append(savedBuffer, iterator.current, iterator.end - iterator.current);
-    concatenation.endOffset = savedStartOffset + iterator.end;
-  }
-
-  /**
-   * Generates a word/number part, updating the appropriate attributes
-   *
-   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise
-   */
-  private void generatePart(boolean isSingleWord) {
-    clearAttributes();
-    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);
-
-    int startOffSet = (isSingleWord || !hasIllegalOffsets) ? savedStartOffset + iterator.current : savedStartOffset;
-    int endOffSet = (hasIllegalOffsets) ? savedEndOffset : savedStartOffset + iterator.end;
-
-    offsetAttribute.setOffset(startOffSet, endOffSet);
-    posIncAttribute.setPositionIncrement(position(false));
-    typeAttribute.setType(savedType);
-  }
-
-  /**
-   * Get the position increment gap for a subword or concatenation
-   *
-   * @param inject true if this token wants to be injected
-   * @return position increment gap
-   */
-  private int position(boolean inject) {
-    int posInc = accumPosInc;
-
-    if (hasOutputToken) {
-      accumPosInc = 0;
-      return inject ? 0 : Math.max(1, posInc);
-    }
-
-    hasOutputToken = true;
-    
-    if (!hasOutputFollowingOriginal) {
-      // the first token following the original is 0 regardless
-      hasOutputFollowingOriginal = true;
-      return 0;
-    }
-    // clear the accumulated position increment
-    accumPosInc = 0;
-    return Math.max(1, posInc);
-  }
-
-  /**
-   * Checks if the given word type includes {@link #ALPHA}
-   *
-   * @param type Word type to check
-   * @return {@code true} if the type contains ALPHA, {@code false} otherwise
-   */
-  static boolean isAlpha(int type) {
-    return (type & ALPHA) != 0;
-  }
-
-  /**
-   * Checks if the given word type includes {@link #DIGIT}
-   *
-   * @param type Word type to check
-   * @return {@code true} if the type contains DIGIT, {@code false} otherwise
-   */
-  static boolean isDigit(int type) {
-    return (type & DIGIT) != 0;
-  }
-
-  /**
-   * Checks if the given word type includes {@link #SUBWORD_DELIM}
-   *
-   * @param type Word type to check
-   * @return {@code true} if the type contains SUBWORD_DELIM, {@code false} otherwise
-   */
-  static boolean isSubwordDelim(int type) {
-    return (type & SUBWORD_DELIM) != 0;
-  }
-
-  /**
-   * Checks if the given word type includes {@link #UPPER}
-   *
-   * @param type Word type to check
-   * @return {@code true} if the type contains UPPER, {@code false} otherwise
-   */
-  static boolean isUpper(int type) {
-    return (type & UPPER) != 0;
-  }
-
-  // ================================================= Inner Classes =================================================
-
-  /**
-   * A WDF concatenated 'run'
-   */
-  final class WordDelimiterConcatenation {
-    final StringBuilder buffer = new StringBuilder();
-    int startOffset;
-    int endOffset;
-    int type;
-    int subwordCount;
-
-    /**
-     * Appends the given text of the given length, to the concetenation at the given offset
-     *
-     * @param text Text to append
-     * @param offset Offset in the concetenation to add the text
-     * @param length Length of the text to append
-     */
-    void append(char text[], int offset, int length) {
-      buffer.append(text, offset, length);
-      subwordCount++;
-    }
-
-    /**
-     * Writes the concatenation to the attributes
-     */
-    void write() {
-      clearAttributes();
-      if (termAttribute.length() < buffer.length()) {
-        termAttribute.resizeBuffer(buffer.length());
-      }
-      char termbuffer[] = termAttribute.buffer();
-      
-      buffer.getChars(0, buffer.length(), termbuffer, 0);
-      termAttribute.setLength(buffer.length());
-        
-      if (hasIllegalOffsets) {
-        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);
-      }
-      else {
-        offsetAttribute.setOffset(startOffset, endOffset);
-      }
-      posIncAttribute.setPositionIncrement(position(true));
-      typeAttribute.setType(savedType);
-      accumPosInc = 0;
-    }
-
-    /**
-     * Determines if the concatenation is empty
-     *
-     * @return {@code true} if the concatenation is empty, {@code false} otherwise
-     */
-    boolean isEmpty() {
-      return buffer.length() == 0;
-    }
-
-    /**
-     * Clears the concatenation and resets its state
-     */
-    void clear() {
-      buffer.setLength(0);
-      startOffset = endOffset = type = subwordCount = 0;
-    }
-
-    /**
-     * Convenience method for the common scenario of having to write the concetenation and then clearing its state
-     */
-    void writeAndClear() {
-      write();
-      clear();
-    }
-  }
-  // questions:
-  // negative numbers?  -42 indexed as just 42?
-  // dollar sign?  $42
-  // percent sign?  33%
-  // downsides:  if source text is "powershot" then a query of "PowerShot" won't match!
-}
diff --git a/solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java b/solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java
index 19dfc36..879dc54 100644
--- a/solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/WordDelimiterFilterFactory.java
@@ -18,6 +18,7 @@
 package org.apache.solr.analysis;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.CharArraySet;
+import org.apache.lucene.analysis.miscellaneous.WordDelimiterFilter;
 
 import org.apache.solr.util.plugin.ResourceLoaderAware;
 import org.apache.solr.common.ResourceLoader;
diff --git a/solr/src/java/org/apache/solr/analysis/WordDelimiterIterator.java b/solr/src/java/org/apache/solr/analysis/WordDelimiterIterator.java
deleted file mode 100644
index 0af9cde..0000000
--- a/solr/src/java/org/apache/solr/analysis/WordDelimiterIterator.java
+++ /dev/null
@@ -1,315 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import static org.apache.solr.analysis.WordDelimiterFilter.*;
-
-/**
- * A BreakIterator-like API for iterating over subwords in text, according to WordDelimiterFilter rules.
- */
-final class WordDelimiterIterator {
-
-  /** Indicates the end of iteration */
-  public static final int DONE = -1;
-  
-  public static final byte[] DEFAULT_WORD_DELIM_TABLE;
-
-  char text[];
-  int length;
-  
-  /** start position of text, excluding leading delimiters */
-  int startBounds;
-  /** end position of text, excluding trailing delimiters */
-  int endBounds;
-  
-  /** Beginning of subword */
-  int current;
-  /** End of subword */
-  int end;
-  
-  /* does this string end with a possessive such as 's */
-  private boolean hasFinalPossessive = false;
-  
-  /**
-   * If false, causes case changes to be ignored (subwords will only be generated
-   * given SUBWORD_DELIM tokens). (Defaults to true)
-   */
-  final boolean splitOnCaseChange;
-  
-  /**
-   * If false, causes numeric changes to be ignored (subwords will only be generated
-   * given SUBWORD_DELIM tokens). (Defaults to true)
-   */
-  final boolean splitOnNumerics;
-
-  /**
-   * If true, causes trailing "'s" to be removed for each subword. (Defaults to true)
-   * <p/>
-   * "O'Neil's" => "O", "Neil"
-   */
-  final boolean stemEnglishPossessive;
-  
-  private final byte[] charTypeTable;
-  
-  /** if true, need to skip over a possessive found in the last call to next() */
-  private boolean skipPossessive = false;
-
-  // TODO: should there be a WORD_DELIM category for chars that only separate words (no catenation of subwords will be
-  // done if separated by these chars?) "," would be an obvious candidate...
-  static {
-    byte[] tab = new byte[256];
-    for (int i = 0; i < 256; i++) {
-      byte code = 0;
-      if (Character.isLowerCase(i)) {
-        code |= LOWER;
-      }
-      else if (Character.isUpperCase(i)) {
-        code |= UPPER;
-      }
-      else if (Character.isDigit(i)) {
-        code |= DIGIT;
-      }
-      if (code == 0) {
-        code = SUBWORD_DELIM;
-      }
-      tab[i] = code;
-    }
-    DEFAULT_WORD_DELIM_TABLE = tab;
-  }
-
-  /**
-   * Create a new WordDelimiterIterator operating with the supplied rules.
-   * 
-   * @param charTypeTable table containing character types
-   * @param splitOnCaseChange if true, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
-   * @param splitOnNumerics if true, causes "j2se" to be three tokens; "j" "2" "se"
-   * @param stemEnglishPossessive if true, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
-   */
-  WordDelimiterIterator(byte[] charTypeTable, boolean splitOnCaseChange, boolean splitOnNumerics, boolean stemEnglishPossessive) {
-    this.charTypeTable = charTypeTable;
-    this.splitOnCaseChange = splitOnCaseChange;
-    this.splitOnNumerics = splitOnNumerics;
-    this.stemEnglishPossessive = stemEnglishPossessive;
-  }
-  
-  /**
-   * Advance to the next subword in the string.
-   *
-   * @return index of the next subword, or {@link #DONE} if all subwords have been returned
-   */
-  int next() {
-    current = end;
-    if (current == DONE) {
-      return DONE;
-    }
-    
-    if (skipPossessive) {
-      current += 2;
-      skipPossessive = false;
-    }
-
-    int lastType = 0;
-    
-    while (current < endBounds && (isSubwordDelim(lastType = charType(text[current])))) {
-      current++;
-    }
-
-    if (current >= endBounds) {
-      return end = DONE;
-    }
-    
-    for (end = current + 1; end < endBounds; end++) {
-      int type = charType(text[end]);
-      if (isBreak(lastType, type)) {
-        break;
-      }
-      lastType = type;
-    }
-    
-    if (end < endBounds - 1 && endsWithPossessive(end + 2)) {
-      skipPossessive = true;
-    }
-    
-    return end;
-  }
-
-
-  /**
-   * Return the type of the current subword.
-   * This currently uses the type of the first character in the subword.
-   *
-   * @return type of the current word
-   */
-  int type() {
-    if (end == DONE) {
-      return 0;
-    }
-    
-    int type = charType(text[current]);
-    switch (type) {
-      // return ALPHA word type for both lower and upper
-      case LOWER:
-      case UPPER:
-        return ALPHA;
-      default:
-        return type;
-    }
-  }
-
-  /**
-   * Reset the text to a new value, and reset all state
-   *
-   * @param text New text
-   * @param length length of the text
-   */
-  void setText(char text[], int length) {
-    this.text = text;
-    this.length = this.endBounds = length;
-    current = startBounds = end = 0;
-    skipPossessive = hasFinalPossessive = false;
-    setBounds();
-  }
-
-  // ================================================= Helper Methods ================================================
-
-  /**
-   * Determines whether the transition from lastType to type indicates a break
-   *
-   * @param lastType Last subword type
-   * @param type Current subword type
-   * @return {@code true} if the transition indicates a break, {@code false} otherwise
-   */
-  private boolean isBreak(int lastType, int type) {
-    if ((type & lastType) != 0) {
-      return false;
-    }
-    
-    if (!splitOnCaseChange && isAlpha(lastType) && isAlpha(type)) {
-      // ALPHA->ALPHA: always ignore if case isn't considered.
-      return false;
-    } else if (isUpper(lastType) && isAlpha(type)) {
-      // UPPER->letter: Don't split
-      return false;
-    } else if (!splitOnNumerics && ((isAlpha(lastType) && isDigit(type)) || (isDigit(lastType) && isAlpha(type)))) {
-      // ALPHA->NUMERIC, NUMERIC->ALPHA :Don't split
-      return false;
-    }
-
-    return true;
-  }
-  
-  /**
-   * Determines if the current word contains only one subword.  Note, it could be potentially surrounded by delimiters
-   *
-   * @return {@code true} if the current word contains only one subword, {@code false} otherwise
-   */
-  boolean isSingleWord() {
-    if (hasFinalPossessive) {
-      return current == startBounds && end == endBounds - 2;
-    }
-    else {
-      return current == startBounds && end == endBounds;
-    }
-  }
-   
-  /**
-   * Set the internal word bounds (remove leading and trailing delimiters). Note, if a possessive is found, don't remove
-   * it yet, simply note it.
-   */
-  private void setBounds() {
-    while (startBounds < length && (isSubwordDelim(charType(text[startBounds])))) {
-      startBounds++;
-    }
-    
-    while (endBounds > startBounds && (isSubwordDelim(charType(text[endBounds - 1])))) {
-      endBounds--;
-    }
-    if (endsWithPossessive(endBounds)) {
-      hasFinalPossessive = true;
-    }
-    current = startBounds;
-  }
-  
-  /**
-   * Determines if the text at the given position indicates an English possessive which should be removed
-   *
-   * @param pos Position in the text to check if it indicates an English possessive
-   * @return {@code true} if the text at the position indicates an English posessive, {@code false} otherwise
-   */
-  private boolean endsWithPossessive(int pos) {
-    return (stemEnglishPossessive &&
-            pos > 2 &&
-            text[pos - 2] == '\'' &&
-            (text[pos - 1] == 's' || text[pos - 1] == 'S') &&
-            isAlpha(charType(text[pos - 3])) &&
-            (pos == endBounds || isSubwordDelim(charType(text[pos]))));
-  }
-
-  /**
-   * Determines the type of the given character
-   *
-   * @param ch Character whose type is to be determined
-   * @return Type of the character
-   */
-  private int charType(int ch) {
-    if (ch < charTypeTable.length) {
-      return charTypeTable[ch];
-    }
-    switch (Character.getType(ch)) {
-      case Character.UPPERCASE_LETTER: return UPPER;
-      case Character.LOWERCASE_LETTER: return LOWER;
-
-      case Character.TITLECASE_LETTER:
-      case Character.MODIFIER_LETTER:
-      case Character.OTHER_LETTER:
-      case Character.NON_SPACING_MARK:
-      case Character.ENCLOSING_MARK:  // depends what it encloses?
-      case Character.COMBINING_SPACING_MARK:
-        return ALPHA; 
-
-      case Character.DECIMAL_DIGIT_NUMBER:
-      case Character.LETTER_NUMBER:
-      case Character.OTHER_NUMBER:
-        return DIGIT;
-
-      // case Character.SPACE_SEPARATOR:
-      // case Character.LINE_SEPARATOR:
-      // case Character.PARAGRAPH_SEPARATOR:
-      // case Character.CONTROL:
-      // case Character.FORMAT:
-      // case Character.PRIVATE_USE:
-
-      case Character.SURROGATE:  // prevent splitting
-        return ALPHA|DIGIT;  
-
-      // case Character.DASH_PUNCTUATION:
-      // case Character.START_PUNCTUATION:
-      // case Character.END_PUNCTUATION:
-      // case Character.CONNECTOR_PUNCTUATION:
-      // case Character.OTHER_PUNCTUATION:
-      // case Character.MATH_SYMBOL:
-      // case Character.CURRENCY_SYMBOL:
-      // case Character.MODIFIER_SYMBOL:
-      // case Character.OTHER_SYMBOL:
-      // case Character.INITIAL_QUOTE_PUNCTUATION:
-      // case Character.FINAL_QUOTE_PUNCTUATION:
-
-      default: return SUBWORD_DELIM;
-    }
-  }
-}
\ No newline at end of file
diff --git a/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java b/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java
deleted file mode 100644
index fa3ba01..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilter.java
+++ /dev/null
@@ -1,455 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.CharArraySet;
-import org.apache.lucene.analysis.KeywordTokenizer;
-import org.apache.lucene.analysis.StopFilter;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.WhitespaceTokenizer;
-import org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.solr.SolrTestCaseJ4;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import static org.apache.solr.analysis.BaseTokenTestCase.*;
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Arrays;
-import java.util.HashSet;
-
-/**
- * New WordDelimiterFilter tests... most of the tests are in ConvertedLegacyTest
- */
-public class TestWordDelimiterFilter extends SolrTestCaseJ4 {
-
-  @BeforeClass
-  public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml","schema.xml");
-  }
-
-  public void posTst(String v1, String v2, String s1, String s2) {
-    assertU(adoc("id",  "42",
-                 "subword", v1,
-                 "subword", v2));
-    assertU(commit());
-
-    // there is a positionIncrementGap of 100 between field values, so
-    // we test if that was maintained.
-    assertQ("position increment lost",
-            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~90")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("position increment lost",
-            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~110")
-            ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testRetainPositionIncrement() {
-    posTst("foo","bar","foo","bar");
-    posTst("-foo-","-bar-","foo","bar");
-    posTst("foo","bar","-foo-","-bar-");
-
-    posTst("123","456","123","456");
-    posTst("/123/","/456/","123","456");
-
-    posTst("/123/abc","qwe/456/","abc","qwe");
-
-    posTst("zoo-foo","bar-baz","foo","bar");
-    posTst("zoo-foo-123","456-bar-baz","foo","bar");
-  }
-
-  @Test
-  public void testNoGenerationEdgeCase() {
-    assertU(adoc("id", "222", "numberpartfail", "123.123.123.123"));
-    clearIndex();
-  }
-
-  @Test
-  public void testIgnoreCaseChange() {
-
-    assertU(adoc("id",  "43",
-                 "wdf_nocase", "HellO WilliAM",
-                 "subword", "GoodBye JonEs"));
-    assertU(commit());
-    
-    assertQ("no case change",
-            req("wdf_nocase:(hell o am)")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("case change",
-            req("subword:(good jon)")
-            ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testPreserveOrignalTrue() {
-
-    assertU(adoc("id",  "144",
-                 "wdf_preserve", "404-123"));
-    assertU(commit());
-    
-    assertQ("preserving original word",
-            req("wdf_preserve:404")
-            ,"//result[@numFound=1]"
-    );
-    
-    assertQ("preserving original word",
-        req("wdf_preserve:123")
-        ,"//result[@numFound=1]"
-    );
-
-    assertQ("preserving original word",
-        req("wdf_preserve:404-123*")
-        ,"//result[@numFound=1]"
-    );
-    clearIndex();
-  }
-
-  /***
-  public void testPerformance() throws IOException {
-    String s = "now is the time-for all good men to come to-the aid of their country.";
-    Token tok = new Token();
-    long start = System.currentTimeMillis();
-    int ret=0;
-    for (int i=0; i<1000000; i++) {
-      StringReader r = new StringReader(s);
-      TokenStream ts = new WhitespaceTokenizer(r);
-      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);
-
-      while (ts.next(tok) != null) ret++;
-    }
-
-    System.out.println("ret="+ret+" time="+(System.currentTimeMillis()-start));
-  }
-  ***/
-
-  @Test
-  public void testOffsets() throws IOException {
-
-    // test that subwords and catenated subwords have
-    // the correct offsets.
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-            new SingleTokenTokenStream(new Token("foo-bar", 5, 12)),
-    1,1,0,0,1,1,0);
-
-    assertTokenStreamContents(wdf, 
-        new String[] { "foo", "bar", "foobar" },
-        new int[] { 5, 9, 5 }, 
-        new int[] { 8, 12, 12 });
-
-    wdf = new WordDelimiterFilter(
-            new SingleTokenTokenStream(new Token("foo-bar", 5, 6)),
-    1,1,0,0,1,1,0);
-    
-    assertTokenStreamContents(wdf,
-        new String[] { "foo", "bar", "foobar" },
-        new int[] { 5, 5, 5 },
-        new int[] { 6, 6, 6 });
-  }
-  
-  @Test
-  public void testOffsetChange() throws Exception
-  {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("Ã¼belkeit)", 7, 16)),
-      1,1,0,0,1,1,0
-    );
-    
-    assertTokenStreamContents(wdf,
-        new String[] { "Ã¼belkeit" },
-        new int[] { 7 },
-        new int[] { 15 });
-  }
-  
-  @Test
-  public void testOffsetChange2() throws Exception
-  {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(Ã¼belkeit", 7, 17)),
-      1,1,0,0,1,1,0
-    );
-    
-    assertTokenStreamContents(wdf,
-        new String[] { "Ã¼belkeit" },
-        new int[] { 8 },
-        new int[] { 17 });
-  }
-  
-  @Test
-  public void testOffsetChange3() throws Exception
-  {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(Ã¼belkeit", 7, 16)),
-      1,1,0,0,1,1,0
-    );
-    
-    assertTokenStreamContents(wdf,
-        new String[] { "Ã¼belkeit" },
-        new int[] { 8 },
-        new int[] { 16 });
-  }
-  
-  @Test
-  public void testOffsetChange4() throws Exception
-  {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(foo,bar)", 7, 16)),
-      1,1,0,0,1,1,0
-    );
-    
-    assertTokenStreamContents(wdf,
-        new String[] { "foo", "bar", "foobar"},
-        new int[] { 8, 12, 8 },
-        new int[] { 11, 15, 15 });
-  }
-
-  @Test
-  public void testAlphaNumericWords(){
-     assertU(adoc("id",  "68","numericsubword","Java/J2SE"));
-     assertU(commit());
-
-     assertQ("j2se found",
-            req("numericsubword:(J2SE)")
-            ,"//result[@numFound=1]"
-    );
-      assertQ("no j2 or se",
-            req("numericsubword:(J2 OR SE)")
-            ,"//result[@numFound=0]"
-    );
-    clearIndex();
-  }
-
-  @Test
-  public void testProtectedWords(){
-    assertU(adoc("id", "70","protectedsubword","c# c++ .net Java/J2SE"));
-    assertU(commit());
-
-    assertQ("java found",
-            req("protectedsubword:(java)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ(".net found",
-            req("protectedsubword:(.net)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c# found",
-            req("protectedsubword:(c#)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c++ found",
-            req("protectedsubword:(c++)")
-            ,"//result[@numFound=1]"
-    );
-
-    assertQ("c found?",
-            req("protectedsubword:c")
-            ,"//result[@numFound=0]"
-    );
-    assertQ("net found?",
-            req("protectedsubword:net")
-            ,"//result[@numFound=0]"
-    );
-    clearIndex();
-  }
-
-
-  public void doSplit(final String input, String... output) throws Exception {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(
-        new StringReader(input)), 1, 1, 0, 0, 0);
-    
-    assertTokenStreamContents(wdf, output);
-  }
-
-  @Test
-  public void testSplits() throws Exception {
-    doSplit("basic-split","basic","split");
-    doSplit("camelCase","camel","Case");
-
-    // non-space marking symbol shouldn't cause split
-    // this is an example in Thai    
-    doSplit("\u0e1a\u0e49\u0e32\u0e19","\u0e1a\u0e49\u0e32\u0e19");
-    // possessive followed by delimiter
-    doSplit("test's'", "test");
-
-    // some russian upper and lowercase
-    doSplit("?Ð¾Ð±Ðµ??", "?Ð¾Ð±Ðµ??");
-    // now cause a split (russian camelCase)
-    doSplit("?Ð¾Ð±???", "?Ð¾Ð±", "???");
-
-    // a composed titlecase character, don't split
-    doSplit("a?ungla", "a?ungla");
-    
-    // a modifier letter, don't split
-    doSplit("Ø³??????????????????Ø§?", "Ø³??????????????????Ø§?");
-    
-    // enclosing mark, don't split
-    doSplit("?test", "?test");
-    
-    // combining spacing mark (the virama), don't split
-    doSplit("à¤¹à¤¿à¤¨à?à¤??", "à¤¹à¤¿à¤¨à?à¤??");
-    
-    // don't split non-ascii digits
-    doSplit("Ù¡Ù¢Ù£Ù¤", "Ù¡Ù¢Ù£Ù¤");
-    
-    // don't split supplementaries into unpaired surrogates
-    doSplit("??????", "??????");
-  }
-  
-  public void doSplitPossessive(int stemPossessive, final String input, final String... output) throws Exception {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(
-        new StringReader(input)), 1,1,0,0,0,1,0,1,stemPossessive, null);
-
-    assertTokenStreamContents(wdf, output);
-  }
-  
-  /*
-   * Test option that allows disabling the special "'s" stemming, instead treating the single quote like other delimiters. 
-   */
-  @Test
-  public void testPossessives() throws Exception {
-    doSplitPossessive(1, "ra's", "ra");
-    doSplitPossessive(0, "ra's", "ra", "s");
-  }
-  
-  /*
-   * Set a large position increment gap of 10 if the token is "largegap" or "/"
-   */
-  private final class LargePosIncTokenFilter extends TokenFilter {
-    private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-    
-    protected LargePosIncTokenFilter(TokenStream input) {
-      super(input);
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (input.incrementToken()) {
-        if (termAtt.toString().equals("largegap") || termAtt.toString().equals("/"))
-          posIncAtt.setPositionIncrement(10);
-        return true;
-      } else {
-        return false;
-      }
-    }  
-  }
-  
-  @Test
-  public void testPositionIncrements() throws Exception {
-    final CharArraySet protWords = new CharArraySet(DEFAULT_VERSION, new HashSet<String>(Arrays.asList("NUTCH")), false);
-    
-    /* analyzer that uses whitespace + wdf */
-    Analyzer a = new Analyzer() {
-      public TokenStream tokenStream(String field, Reader reader) {
-        return new WordDelimiterFilter(
-            new WhitespaceTokenizer(DEFAULT_VERSION, reader),
-            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
-      }
-    };
-
-    /* in this case, works as expected. */
-    assertAnalyzesTo(a, "LUCENE / SOLR", new String[] { "LUCENE", "SOLR" },
-        new int[] { 0, 9 },
-        new int[] { 6, 13 },
-        new int[] { 1, 1 });
-    
-    /* only in this case, posInc of 2 ?! */
-    assertAnalyzesTo(a, "LUCENE / solR", new String[] { "LUCENE", "sol", "R", "solR" },
-        new int[] { 0, 9, 12, 9 },
-        new int[] { 6, 12, 13, 13 },
-        new int[] { 1, 1, 1, 0 });
-    
-    assertAnalyzesTo(a, "LUCENE / NUTCH SOLR", new String[] { "LUCENE", "NUTCH", "SOLR" },
-        new int[] { 0, 9, 15 },
-        new int[] { 6, 14, 19 },
-        new int[] { 1, 1, 1 });
-    
-    /* analyzer that will consume tokens with large position increments */
-    Analyzer a2 = new Analyzer() {
-      public TokenStream tokenStream(String field, Reader reader) {
-        return new WordDelimiterFilter(
-            new LargePosIncTokenFilter(
-            new WhitespaceTokenizer(DEFAULT_VERSION, reader)),
-            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
-      }
-    };
-    
-    /* increment of "largegap" is preserved */
-    assertAnalyzesTo(a2, "LUCENE largegap SOLR", new String[] { "LUCENE", "largegap", "SOLR" },
-        new int[] { 0, 7, 16 },
-        new int[] { 6, 15, 20 },
-        new int[] { 1, 10, 1 });
-    
-    /* the "/" had a position increment of 10, where did it go?!?!! */
-    assertAnalyzesTo(a2, "LUCENE / SOLR", new String[] { "LUCENE", "SOLR" },
-        new int[] { 0, 9 },
-        new int[] { 6, 13 },
-        new int[] { 1, 11 });
-    
-    /* in this case, the increment of 10 from the "/" is carried over */
-    assertAnalyzesTo(a2, "LUCENE / solR", new String[] { "LUCENE", "sol", "R", "solR" },
-        new int[] { 0, 9, 12, 9 },
-        new int[] { 6, 12, 13, 13 },
-        new int[] { 1, 11, 1, 0 });
-    
-    assertAnalyzesTo(a2, "LUCENE / NUTCH SOLR", new String[] { "LUCENE", "NUTCH", "SOLR" },
-        new int[] { 0, 9, 15 },
-        new int[] { 6, 14, 19 },
-        new int[] { 1, 11, 1 });
-
-    Analyzer a3 = new Analyzer() {
-      public TokenStream tokenStream(String field, Reader reader) {
-        StopFilter filter = new StopFilter(DEFAULT_VERSION,
-            new WhitespaceTokenizer(DEFAULT_VERSION, reader), StandardAnalyzer.STOP_WORDS_SET);
-        filter.setEnablePositionIncrements(true);
-        return new WordDelimiterFilter(filter, 
-            1, 1, 0, 0, 1, 1, 0, 1, 1, protWords);
-      }
-    };
-
-    assertAnalyzesTo(a3, "lucene.solr", 
-        new String[] { "lucene", "solr", "lucenesolr" },
-        new int[] { 0, 7, 0 },
-        new int[] { 6, 11, 11 },
-        new int[] { 1, 1, 0 });
-
-    /* the stopword should add a gap here */
-    assertAnalyzesTo(a3, "the lucene.solr", 
-        new String[] { "lucene", "solr", "lucenesolr" }, 
-        new int[] { 4, 11, 4 }, 
-        new int[] { 10, 15, 15 },
-        new int[] { 2, 1, 0 });
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java
new file mode 100644
index 0000000..9759372
--- /dev/null
+++ b/solr/src/test/org/apache/solr/analysis/TestWordDelimiterFilterFactory.java
@@ -0,0 +1,186 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.analysis;
+
+import org.apache.solr.SolrTestCaseJ4;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+/**
+ * New WordDelimiterFilter tests... most of the tests are in ConvertedLegacyTest
+ */
+public class TestWordDelimiterFilterFactory extends SolrTestCaseJ4 {
+
+  @BeforeClass
+  public static void beforeClass() throws Exception {
+    initCore("solrconfig.xml","schema.xml");
+  }
+
+  public void posTst(String v1, String v2, String s1, String s2) {
+    assertU(adoc("id",  "42",
+                 "subword", v1,
+                 "subword", v2));
+    assertU(commit());
+
+    // there is a positionIncrementGap of 100 between field values, so
+    // we test if that was maintained.
+    assertQ("position increment lost",
+            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~90")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("position increment lost",
+            req("+id:42 +subword:\"" + s1 + ' ' + s2 + "\"~110")
+            ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testRetainPositionIncrement() {
+    posTst("foo","bar","foo","bar");
+    posTst("-foo-","-bar-","foo","bar");
+    posTst("foo","bar","-foo-","-bar-");
+
+    posTst("123","456","123","456");
+    posTst("/123/","/456/","123","456");
+
+    posTst("/123/abc","qwe/456/","abc","qwe");
+
+    posTst("zoo-foo","bar-baz","foo","bar");
+    posTst("zoo-foo-123","456-bar-baz","foo","bar");
+  }
+
+  @Test
+  public void testNoGenerationEdgeCase() {
+    assertU(adoc("id", "222", "numberpartfail", "123.123.123.123"));
+    clearIndex();
+  }
+
+  @Test
+  public void testIgnoreCaseChange() {
+
+    assertU(adoc("id",  "43",
+                 "wdf_nocase", "HellO WilliAM",
+                 "subword", "GoodBye JonEs"));
+    assertU(commit());
+    
+    assertQ("no case change",
+            req("wdf_nocase:(hell o am)")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("case change",
+            req("subword:(good jon)")
+            ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testPreserveOrignalTrue() {
+
+    assertU(adoc("id",  "144",
+                 "wdf_preserve", "404-123"));
+    assertU(commit());
+    
+    assertQ("preserving original word",
+            req("wdf_preserve:404")
+            ,"//result[@numFound=1]"
+    );
+    
+    assertQ("preserving original word",
+        req("wdf_preserve:123")
+        ,"//result[@numFound=1]"
+    );
+
+    assertQ("preserving original word",
+        req("wdf_preserve:404-123*")
+        ,"//result[@numFound=1]"
+    );
+    clearIndex();
+  }
+
+  /***
+  public void testPerformance() throws IOException {
+    String s = "now is the time-for all good men to come to-the aid of their country.";
+    Token tok = new Token();
+    long start = System.currentTimeMillis();
+    int ret=0;
+    for (int i=0; i<1000000; i++) {
+      StringReader r = new StringReader(s);
+      TokenStream ts = new WhitespaceTokenizer(r);
+      ts = new WordDelimiterFilter(ts, 1,1,1,1,0);
+
+      while (ts.next(tok) != null) ret++;
+    }
+
+    System.out.println("ret="+ret+" time="+(System.currentTimeMillis()-start));
+  }
+  ***/
+
+  @Test
+  public void testAlphaNumericWords(){
+     assertU(adoc("id",  "68","numericsubword","Java/J2SE"));
+     assertU(commit());
+
+     assertQ("j2se found",
+            req("numericsubword:(J2SE)")
+            ,"//result[@numFound=1]"
+    );
+      assertQ("no j2 or se",
+            req("numericsubword:(J2 OR SE)")
+            ,"//result[@numFound=0]"
+    );
+    clearIndex();
+  }
+
+  @Test
+  public void testProtectedWords(){
+    assertU(adoc("id", "70","protectedsubword","c# c++ .net Java/J2SE"));
+    assertU(commit());
+
+    assertQ("java found",
+            req("protectedsubword:(java)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ(".net found",
+            req("protectedsubword:(.net)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c# found",
+            req("protectedsubword:(c#)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c++ found",
+            req("protectedsubword:(c++)")
+            ,"//result[@numFound=1]"
+    );
+
+    assertQ("c found?",
+            req("protectedsubword:c")
+            ,"//result[@numFound=0]"
+    );
+    assertQ("net found?",
+            req("protectedsubword:net")
+            ,"//result[@numFound=0]"
+    );
+    clearIndex();
+  }
+}

