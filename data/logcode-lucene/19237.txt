GitDiffStart: ec90bc2202ef501e257eaf235be5ca15239c03c2 | Thu Oct 1 07:53:43 2009 +0000
diff --git a/CHANGES.txt b/CHANGES.txt
index 8e5b7e2..c6d14a0 100644
--- a/CHANGES.txt
+++ b/CHANGES.txt
@@ -13,6 +13,11 @@ API Changes
   protected; add expert ctor to directly specify reader, subReaders
   and docStarts.  (John Wang, Tim Smith via Mike McCandless)
 
+* LUCENE-1855: Convert TokenStream/AttributeSource API to Generics.
+  Now addAttribute()/getAttribute() return an instance of the requested
+  attribute interface and no cast needed anymore.  (Uwe Schindler,
+  Michael Busch, Robert Muir, Adriano Crestani)
+
 Bug fixes
 
 New features
diff --git a/contrib/analyzers/common/build.xml b/contrib/analyzers/common/build.xml
index c013e98..a59f32d 100644
--- a/contrib/analyzers/common/build.xml
+++ b/contrib/analyzers/common/build.xml
@@ -22,9 +22,6 @@
   <description>
     Additional Analyzers
   </description>
-
-  <property name="javac.source" value="1.4" />
-  <property name="javac.target" value="1.4" />
 	
   <property name="build.dir" location="../../../build/contrib/analyzers/common" />
   <property name="dist.dir" location="../../../dist/contrib/analyzers/common" />
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java
index 75bd09e..2c27cf4 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicNormalizationFilter.java
@@ -36,7 +36,7 @@ public final class ArabicNormalizationFilter extends TokenFilter {
   public ArabicNormalizationFilter(TokenStream input) {
     super(input);
     normalizer = new ArabicNormalizer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java
index e07756b..75c14b5 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ar/ArabicStemFilter.java
@@ -36,7 +36,7 @@ public final class ArabicStemFilter extends TokenFilter {
   public ArabicStemFilter(TokenStream input) {
     super(input);
     stemmer = new ArabicStemmer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
index c6ed0b5..5d07629 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
@@ -40,7 +40,7 @@ public final class BrazilianStemFilter extends TokenFilter {
   public BrazilianStemFilter(TokenStream in) {
     super(in);
     stemmer = new BrazilianStemmer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public BrazilianStemFilter(TokenStream in, Set exclusiontable) {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java
index a1489eb..fad8cb7 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cjk/CJKTokenizer.java
@@ -127,9 +127,9 @@ public final class CJKTokenizer extends Tokenizer {
     }
     
     private void init() {
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
     }
     
     //~ Methods ----------------------------------------------------------------
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
index 7e847fb..6666eaa 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
@@ -66,7 +66,7 @@ public final class ChineseFilter extends TokenFilter {
         stopTable = new HashMap(STOP_WORDS.length);
         for (int i = 0; i < STOP_WORDS.length; i++)
             stopTable.put(STOP_WORDS[i], STOP_WORDS[i]);
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
     }
 
     public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
index 2507cac..aa43a8d 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
@@ -74,8 +74,8 @@ public final class ChineseTokenizer extends Tokenizer {
     }
     
     private void init() {
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
     }
     
     private int offset = 0, bufferIndex=0, dataLen=0;
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
index 3c7c13c..f0ff84b 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
@@ -106,12 +106,12 @@ public abstract class CompoundWordTokenFilterBase extends TokenFilter {
       addAllLowerCase(this.dictionary, dictionary);
     }
     
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
-    posIncAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    flagsAtt = addAttribute(FlagsAttribute.class);
+    posIncAtt = addAttribute(PositionIncrementAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
index c142965..df71c8c 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
@@ -48,7 +48,7 @@ public final class GermanStemFilter extends TokenFilter
     {
       super(in);
       stemmer = new GermanStemmer();
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
     }
 
     /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
index 03c46bd..367c06e 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
@@ -42,7 +42,7 @@ public final class GreekLowerCaseFilter extends TokenFilter
     {
         super(in);
         this.charset = charset;
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
     }
     
     public GreekLowerCaseFilter(TokenStream in)
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java
index e9eb308..0033e80 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java
@@ -37,7 +37,7 @@ public final class PersianNormalizationFilter extends TokenFilter {
   public PersianNormalizationFilter(TokenStream input) {
     super(input);
     normalizer = new PersianNormalizer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
index 82e8b3f..0c99590 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
@@ -57,7 +57,7 @@ public class ElisionFilter extends TokenFilter {
     super(input);
     this.articles = new HashSet(Arrays.asList(new String[] { "l", "m", "t",
         "qu", "n", "s", "j" }));
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /**
@@ -66,7 +66,7 @@ public class ElisionFilter extends TokenFilter {
   public ElisionFilter(TokenStream input, Set articles) {
     super(input);
     setArticles(articles);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /**
@@ -75,7 +75,7 @@ public class ElisionFilter extends TokenFilter {
   public ElisionFilter(TokenStream input, String[] articles) {
     super(input);
     setArticles(new HashSet(Arrays.asList(articles)));
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
index 8ea51c5..fb5817a 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
@@ -47,7 +47,7 @@ public final class FrenchStemFilter extends TokenFilter {
 	public FrenchStemFilter( TokenStream in ) {
           super(in);
 		stemmer = new FrenchStemmer();
-		termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+		termAtt = addAttribute(TermAttribute.class);
 	}
 
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PrefixAwareTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PrefixAwareTokenFilter.java
index 39dbf13..c5e7214 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PrefixAwareTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/miscellaneous/PrefixAwareTokenFilter.java
@@ -64,19 +64,19 @@ public class PrefixAwareTokenFilter extends TokenStream {
     this.prefix = prefix;
     prefixExhausted = false;
     
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
-
-    p_termAtt = (TermAttribute) prefix.addAttribute(TermAttribute.class);
-    p_posIncrAtt = (PositionIncrementAttribute) prefix.addAttribute(PositionIncrementAttribute.class);
-    p_payloadAtt = (PayloadAttribute) prefix.addAttribute(PayloadAttribute.class);
-    p_offsetAtt = (OffsetAttribute) prefix.addAttribute(OffsetAttribute.class);
-    p_typeAtt = (TypeAttribute) prefix.addAttribute(TypeAttribute.class);
-    p_flagsAtt = (FlagsAttribute) prefix.addAttribute(FlagsAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
+    flagsAtt = addAttribute(FlagsAttribute.class);
+
+    p_termAtt = prefix.addAttribute(TermAttribute.class);
+    p_posIncrAtt = prefix.addAttribute(PositionIncrementAttribute.class);
+    p_payloadAtt = prefix.addAttribute(PayloadAttribute.class);
+    p_offsetAtt = prefix.addAttribute(OffsetAttribute.class);
+    p_typeAtt = prefix.addAttribute(TypeAttribute.class);
+    p_flagsAtt = prefix.addAttribute(FlagsAttribute.class);
   }
 
   private Token previousPrefixToken = new Token();
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
index a1d1b76..9e0bfe7 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenFilter.java
@@ -77,8 +77,8 @@ public class EdgeNGramTokenFilter extends TokenFilter {
 
   protected EdgeNGramTokenFilter(TokenStream input) {
     super(input);
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
   }
 
   /**
@@ -107,8 +107,8 @@ public class EdgeNGramTokenFilter extends TokenFilter {
     this.minGram = minGram;
     this.maxGram = maxGram;
     this.side = side;
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
index 47e5995..5b7e8a7 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.java
@@ -175,8 +175,8 @@ public class EdgeNGramTokenizer extends Tokenizer {
     this.maxGram = maxGram;
     this.side = side;
     
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
 
   }
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
index e0d849b..dab77a9 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenFilter.java
@@ -59,8 +59,8 @@ public class NGramTokenFilter extends TokenFilter {
     this.minGram = minGram;
     this.maxGram = maxGram;
     
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
index ce2acb9..a958f81 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
@@ -96,8 +96,8 @@ public class NGramTokenizer extends Tokenizer {
     this.minGram = minGram;
     this.maxGram = maxGram;
     
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);    
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);    
   }
 
   /** Returns the next token in the stream, or null at EOS. */
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
index 4f9ae66..a7c5644 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
@@ -47,7 +47,7 @@ public final class DutchStemFilter extends TokenFilter {
   public DutchStemFilter(TokenStream _in) {
     super(_in);
     stemmer = new DutchStemmer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java
index ab022c2..49bc9e9 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilter.java
@@ -53,8 +53,8 @@ public final class DelimitedPayloadTokenFilter extends TokenFilter {
 
   public DelimitedPayloadTokenFilter(TokenStream input, char delimiter, PayloadEncoder encoder) {
     super(input);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    payAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    payAtt = addAttribute(PayloadAttribute.class);
     this.delimiter = delimiter;
     this.encoder = encoder;
   }
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilter.java
index 7999ca0..d47f0ef0 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilter.java
@@ -44,8 +44,8 @@ public class NumericPayloadTokenFilter extends TokenFilter {
     //Need to encode the payload
     thePayload = new Payload(PayloadHelper.encodeFloat(payload));
     this.typeMatch = typeMatch;
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
   }
 
   public final boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilter.java
index 76add35..2d54090 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilter.java
@@ -39,8 +39,8 @@ public class TokenOffsetPayloadTokenFilter extends TokenFilter {
 
   public TokenOffsetPayloadTokenFilter(TokenStream input) {
     super(input);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    payAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    payAtt = addAttribute(PayloadAttribute.class);
   }
 
   public final boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilter.java
index bd26e53..3c4de3d 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilter.java
@@ -39,8 +39,8 @@ public class TypeAsPayloadTokenFilter extends TokenFilter {
 
   public TypeAsPayloadTokenFilter(TokenStream input) {
     super(input);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
   }
 
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/position/PositionFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/position/PositionFilter.java
index 6eb6637..6ce473b 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/position/PositionFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/position/PositionFilter.java
@@ -46,7 +46,7 @@ public class PositionFilter extends TokenFilter {
    */
   public PositionFilter(final TokenStream input) {
     super(input);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
index 45a0562..12a55e9 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
@@ -87,7 +87,7 @@ public final class ReverseStringFilter extends TokenFilter {
   public ReverseStringFilter(TokenStream in, char marker) {
     super(in);
     this.marker = marker;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java
index 1407f08..600ae68 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java
@@ -45,7 +45,7 @@ public final class RussianLowerCaseFilter extends TokenFilter
     {
         super(in);
         this.charset = charset;
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
     }
     
     public RussianLowerCaseFilter(TokenStream in)
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
index 5b5e921..a030504 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
@@ -50,7 +50,7 @@ public final class RussianStemFilter extends TokenFilter
     {
         super(in);
         stemmer = new RussianStemmer(charset);
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
     }
 
     public RussianStemFilter(TokenStream in)
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
index 29c9dab..ff1b3b8 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
@@ -84,10 +84,10 @@ public class ShingleFilter extends TokenFilter {
   public ShingleFilter(TokenStream input, int maxShingleSize) {
     super(input);
     setMaxShingleSize(maxShingleSize);
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
+    this.posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    this.typeAtt = addAttribute(TypeAttribute.class);
   }
 
   /**
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
index 799548d..f9d3d17 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/shingle/ShingleMatrixFilter.java
@@ -228,22 +228,22 @@ public class ShingleMatrixFilter extends TokenStream {
     this.ignoringSinglePrefixOrSuffixShingle = ignoringSinglePrefixOrSuffixShingle;
     this.settingsCodec = settingsCodec;
 
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
+    flagsAtt = addAttribute(FlagsAttribute.class);
 
     // set the input to be an empty token stream, we already have the data.
     this.input = new EmptyTokenStream();
     
-    in_termAtt = (TermAttribute) input.addAttribute(TermAttribute.class);
-    in_posIncrAtt = (PositionIncrementAttribute) input.addAttribute(PositionIncrementAttribute.class);
-    in_payloadAtt = (PayloadAttribute) input.addAttribute(PayloadAttribute.class);
-    in_offsetAtt = (OffsetAttribute) input.addAttribute(OffsetAttribute.class);
-    in_typeAtt = (TypeAttribute) input.addAttribute(TypeAttribute.class);
-    in_flagsAtt = (FlagsAttribute) input.addAttribute(FlagsAttribute.class);
+    in_termAtt = input.addAttribute(TermAttribute.class);
+    in_posIncrAtt = input.addAttribute(PositionIncrementAttribute.class);
+    in_payloadAtt = input.addAttribute(PayloadAttribute.class);
+    in_offsetAtt = input.addAttribute(OffsetAttribute.class);
+    in_typeAtt = input.addAttribute(TypeAttribute.class);
+    in_flagsAtt = input.addAttribute(FlagsAttribute.class);
   }
 
   /**
@@ -310,19 +310,19 @@ public class ShingleMatrixFilter extends TokenStream {
     this.spacerCharacter = spacerCharacter;
     this.ignoringSinglePrefixOrSuffixShingle = ignoringSinglePrefixOrSuffixShingle;
     this.settingsCodec = settingsCodec;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
+    flagsAtt = addAttribute(FlagsAttribute.class);
     
-    in_termAtt = (TermAttribute) input.addAttribute(TermAttribute.class);
-    in_posIncrAtt = (PositionIncrementAttribute) input.addAttribute(PositionIncrementAttribute.class);
-    in_payloadAtt = (PayloadAttribute) input.addAttribute(PayloadAttribute.class);
-    in_offsetAtt = (OffsetAttribute) input.addAttribute(OffsetAttribute.class);
-    in_typeAtt = (TypeAttribute) input.addAttribute(TypeAttribute.class);
-    in_flagsAtt = (FlagsAttribute) input.addAttribute(FlagsAttribute.class);
+    in_termAtt = input.addAttribute(TermAttribute.class);
+    in_posIncrAtt = input.addAttribute(PositionIncrementAttribute.class);
+    in_payloadAtt = input.addAttribute(PayloadAttribute.class);
+    in_offsetAtt = input.addAttribute(OffsetAttribute.class);
+    in_typeAtt = input.addAttribute(TypeAttribute.class);
+    in_flagsAtt = input.addAttribute(FlagsAttribute.class);
   }
 
   // internal filter instance variables
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java
index d997abc..34ad7bf 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/DateRecognizerSinkFilter.java
@@ -51,7 +51,7 @@ public class DateRecognizerSinkFilter extends SinkFilter {
 
   public boolean accept(AttributeSource source) {
     if (termAtt == null) {
-      termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+      termAtt = source.addAttribute(TermAttribute.class);
     }
     try {
       Date date = dateFormat.parse(termAtt.term());//We don't care about the date, just that we can parse it as a date
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java
index bff4ac8..69a7093 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/sinks/TokenTypeSinkFilter.java
@@ -31,7 +31,7 @@ public class TokenTypeSinkFilter extends SinkFilter {
 
   public boolean accept(AttributeSource source) {
     if (typeAtt == null) {
-      typeAtt = (TypeAttribute) source.addAttribute(TypeAttribute.class);
+      typeAtt = source.addAttribute(TypeAttribute.class);
     }
     
     //check to see if this is a Category
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
index aa0d062..ac30aca 100644
--- a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
@@ -44,8 +44,8 @@ public class ThaiWordFilter extends TokenFilter {
   public ThaiWordFilter(TokenStream input) {
     super(input);
     breaker = BreakIterator.getWordInstance(new Locale("th"));
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
   }
   
   public final boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer.java
index 92f187f..b37095e 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cjk/TestCJKTokenizer.java
@@ -48,9 +48,9 @@ public class TestCJKTokenizer extends BaseTokenStreamTestCase {
 
   public void checkCJKToken(final String str, final TestToken[] out_tokens) throws IOException {
     CJKTokenizer tokenizer = new CJKTokenizer(new StringReader(str));
-    TermAttribute termAtt = (TermAttribute) tokenizer.getAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) tokenizer.getAttribute(OffsetAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) tokenizer.getAttribute(TypeAttribute.class);
+    TermAttribute termAtt = tokenizer.getAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = tokenizer.getAttribute(OffsetAttribute.class);
+    TypeAttribute typeAtt = tokenizer.getAttribute(TypeAttribute.class);
     for (int i = 0; i < out_tokens.length; i++) {
       assertTrue(tokenizer.incrementToken());
       assertEquals(termAtt.term(), out_tokens[i].termText);
@@ -63,9 +63,9 @@ public class TestCJKTokenizer extends BaseTokenStreamTestCase {
   
   public void checkCJKTokenReusable(final Analyzer a, final String str, final TestToken[] out_tokens) throws IOException {
     TokenStream ts = a.reusableTokenStream("dummy", new StringReader(str));
-    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);
+    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = ts.getAttribute(OffsetAttribute.class);
+    TypeAttribute typeAtt = ts.getAttribute(TypeAttribute.class);
     for (int i = 0; i < out_tokens.length; i++) {
       assertTrue(ts.incrementToken());
       assertEquals(termAtt.term(), out_tokens[i].termText);
@@ -220,7 +220,7 @@ public class TestCJKTokenizer extends BaseTokenStreamTestCase {
   public void testTokenStream() throws Exception {
     Analyzer analyzer = new CJKAnalyzer();
     TokenStream ts = analyzer.tokenStream("dummy", new StringReader("\u4e00\u4e01\u4e02"));
-    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);
     assertTrue(ts.incrementToken());
     assertEquals("\u4e00\u4e01", termAtt.term());
     assertTrue(ts.incrementToken());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
index d19d2ca..160227c 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/cn/TestChineseTokenizer.java
@@ -38,7 +38,7 @@ public class TestChineseTokenizer extends BaseTokenStreamTestCase
 
         int correctStartOffset = 0;
         int correctEndOffset = 1;
-        OffsetAttribute offsetAtt = (OffsetAttribute) tokenizer.getAttribute(OffsetAttribute.class);
+        OffsetAttribute offsetAtt = tokenizer.getAttribute(OffsetAttribute.class);
         while (tokenizer.incrementToken()) {
           assertEquals(correctStartOffset, offsetAtt.startOffset());
           assertEquals(correctEndOffset, offsetAtt.endOffset());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
index 2a1150b..448d30e 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
@@ -173,7 +173,7 @@ public class TestCompoundWordTokenFilter extends BaseTokenStreamTestCase {
         CompoundWordTokenFilterBase.DEFAULT_MIN_SUBWORD_SIZE,
         CompoundWordTokenFilterBase.DEFAULT_MAX_SUBWORD_SIZE, false);
     
-    TermAttribute termAtt = (TermAttribute) tf.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = tf.getAttribute(TermAttribute.class);
     assertTrue(tf.incrementToken());
     assertEquals("RindfleischÃ¼berwachungsgesetz", termAtt.term());
     assertTrue(tf.incrementToken());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestElision.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestElision.java
index 4b988b3..26bbb88 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestElision.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fr/TestElision.java
@@ -50,7 +50,7 @@ public class TestElision extends BaseTokenStreamTestCase {
 
   private List filtre(TokenFilter filter) throws IOException {
     List tas = new ArrayList();
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
     while (filter.incrementToken()) {
       tas.add(termAtt.term());
     }
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAndSuffixAwareTokenFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAndSuffixAwareTokenFilter.java
index 0f0197e..80d3aa8 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAndSuffixAwareTokenFilter.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAndSuffixAwareTokenFilter.java
@@ -45,8 +45,8 @@ public class TestPrefixAndSuffixAwareTokenFilter extends BaseTokenStreamTestCase
 
 
   private void assertNext(TokenStream ts, String text, int startOffset, int endOffset) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
 
     assertTrue(ts.incrementToken());
     assertEquals(text, termAtt.term());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAwareTokenFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAwareTokenFilter.java
index bf27102..9b03e29 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAwareTokenFilter.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPrefixAwareTokenFilter.java
@@ -54,8 +54,8 @@ public class TestPrefixAwareTokenFilter extends BaseTokenStreamTestCase {
 
 
   private void assertNext(TokenStream ts, String text, int startOffset, int endOffset) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
 
     assertTrue(ts.incrementToken());
     assertEquals(text, termAtt.term());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java
index 34a574f..e96316b 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/DelimitedPayloadTokenFilterTest.java
@@ -35,8 +35,8 @@ public class DelimitedPayloadTokenFilterTest extends LuceneTestCase {
   public void testPayloads() throws Exception {
     String test = "The quick|JJ red|JJ fox|NN jumped|VB over the lazy|JJ brown|JJ dogs|NN";
     DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)));
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
-    PayloadAttribute payAtt = (PayloadAttribute) filter.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
+    PayloadAttribute payAtt = filter.getAttribute(PayloadAttribute.class);
     assertTermEquals("The", filter, termAtt, payAtt, null);
     assertTermEquals("quick", filter, termAtt, payAtt, "JJ".getBytes("UTF-8"));
     assertTermEquals("red", filter, termAtt, payAtt, "JJ".getBytes("UTF-8"));
@@ -71,8 +71,8 @@ public class DelimitedPayloadTokenFilterTest extends LuceneTestCase {
   public void testFloatEncoding() throws Exception {
     String test = "The quick|1.0 red|2.0 fox|3.5 jumped|0.5 over the lazy|5 brown|99.3 dogs|83.7";
     DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)), '|', new FloatEncoder());
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
-    PayloadAttribute payAtt = (PayloadAttribute) filter.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
+    PayloadAttribute payAtt = filter.getAttribute(PayloadAttribute.class);
     assertTermEquals("The", filter, termAtt, payAtt, null);
     assertTermEquals("quick", filter, termAtt, payAtt, PayloadHelper.encodeFloat(1.0f));
     assertTermEquals("red", filter, termAtt, payAtt, PayloadHelper.encodeFloat(2.0f));
@@ -89,8 +89,8 @@ public class DelimitedPayloadTokenFilterTest extends LuceneTestCase {
   public void testIntEncoding() throws Exception {
     String test = "The quick|1 red|2 fox|3 jumped over the lazy|5 brown|99 dogs|83";
     DelimitedPayloadTokenFilter filter = new DelimitedPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)), '|', new IntegerEncoder());
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
-    PayloadAttribute payAtt = (PayloadAttribute) filter.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
+    PayloadAttribute payAtt = filter.getAttribute(PayloadAttribute.class);
     assertTermEquals("The", filter, termAtt, payAtt, null);
     assertTermEquals("quick", filter, termAtt, payAtt, PayloadHelper.encodeInt(1));
     assertTermEquals("red", filter, termAtt, payAtt, PayloadHelper.encodeInt(2));
@@ -105,8 +105,8 @@ public class DelimitedPayloadTokenFilterTest extends LuceneTestCase {
   }
 
   void assertTermEquals(String expected, TokenStream stream, byte[] expectPay) throws Exception {
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) stream.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
+    PayloadAttribute payloadAtt = stream.getAttribute(PayloadAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals(expected, termAtt.term());
     Payload payload = payloadAtt.getPayload();
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterTest.java
index c24e768..1ab3315 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/NumericPayloadTokenFilterTest.java
@@ -39,9 +39,9 @@ public class NumericPayloadTokenFilterTest extends BaseTokenStreamTestCase {
 
     NumericPayloadTokenFilter nptf = new NumericPayloadTokenFilter(new WordTokenFilter(new WhitespaceTokenizer(new StringReader(test))), 3, "D");
     boolean seenDogs = false;
-    TermAttribute termAtt = (TermAttribute) nptf.getAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) nptf.getAttribute(TypeAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) nptf.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = nptf.getAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = nptf.getAttribute(TypeAttribute.class);
+    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);
     while (nptf.incrementToken()) {
       if (termAtt.term().equals("dogs")) {
         seenDogs = true;
@@ -65,8 +65,8 @@ public class NumericPayloadTokenFilterTest extends BaseTokenStreamTestCase {
     
     private WordTokenFilter(TokenStream input) {
       super(input);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
     }
     
     public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest.java
index 2ee83b1..032da62 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TokenOffsetPayloadTokenFilterTest.java
@@ -37,8 +37,8 @@ public class TokenOffsetPayloadTokenFilterTest extends BaseTokenStreamTestCase {
 
     TokenOffsetPayloadTokenFilter nptf = new TokenOffsetPayloadTokenFilter(new WhitespaceTokenizer(new StringReader(test)));
     int count = 0;
-    PayloadAttribute payloadAtt = (PayloadAttribute) nptf.getAttribute(PayloadAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) nptf.getAttribute(OffsetAttribute.class);
+    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);
+    OffsetAttribute offsetAtt = nptf.getAttribute(OffsetAttribute.class);
     
     while (nptf.incrementToken()) {
       Payload pay = payloadAtt.getPayload();
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterTest.java
index ad397de..14f9269 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/payloads/TypeAsPayloadTokenFilterTest.java
@@ -39,9 +39,9 @@ public class TypeAsPayloadTokenFilterTest extends BaseTokenStreamTestCase {
 
     TypeAsPayloadTokenFilter nptf = new TypeAsPayloadTokenFilter(new WordTokenFilter(new WhitespaceTokenizer(new StringReader(test))));
     int count = 0;
-    TermAttribute termAtt = (TermAttribute) nptf.getAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) nptf.getAttribute(TypeAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) nptf.getAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = nptf.getAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = nptf.getAttribute(TypeAttribute.class);
+    PayloadAttribute payloadAtt = nptf.getAttribute(PayloadAttribute.class);
     
     while (nptf.incrementToken()) {
       assertTrue(typeAtt.type() + " is not null and it should be", typeAtt.type().equals(String.valueOf(Character.toUpperCase(termAtt.termBuffer()[0]))));
@@ -61,8 +61,8 @@ public class TypeAsPayloadTokenFilterTest extends BaseTokenStreamTestCase {
     
     private WordTokenFilter(TokenStream input) {
       super(input);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
     }
 
     public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/position/PositionFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/position/PositionFilterTest.java
index 49baa3f..a2ffd8e 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/position/PositionFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/position/PositionFilterTest.java
@@ -35,7 +35,7 @@ public class PositionFilterTest extends BaseTokenStreamTestCase {
     public TestTokenStream(String[] testToken) {
       super();
       this.testToken = testToken;
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
     }
 
     public final boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java
index 37a265b..374fc29 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/query/QueryAutoStopWordAnalyzerTest.java
@@ -193,7 +193,7 @@ public class QueryAutoStopWordAnalyzerTest extends BaseTokenStreamTestCase {
     QueryAutoStopWordAnalyzer a = new QueryAutoStopWordAnalyzer(new WhitespaceAnalyzer());
     a.addStopWords(reader, 10);
     TokenStream ts = a.tokenStream("repetitiveField", new StringReader("this boring"));
-    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);
     assertTrue(ts.incrementToken());
     assertEquals("this", termAtt.term());
     assertFalse(ts.incrementToken());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
index f181e55..6c503ab 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
@@ -29,7 +29,7 @@ public class TestReverseStringFilter extends BaseTokenStreamTestCase {
     TokenStream stream = new WhitespaceTokenizer(
         new StringReader("Do have a nice day"));     // 1-4 length string
     ReverseStringFilter filter = new ReverseStringFilter(stream);
-    TermAttribute text = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute text = filter.getAttribute(TermAttribute.class);
     assertTrue(filter.incrementToken());
     assertEquals("oD", text.term());
     assertTrue(filter.incrementToken());
@@ -47,7 +47,7 @@ public class TestReverseStringFilter extends BaseTokenStreamTestCase {
     TokenStream stream = new WhitespaceTokenizer(new StringReader(
         "Do have a nice day")); // 1-4 length string
     ReverseStringFilter filter = new ReverseStringFilter(stream, '\u0001');
-    TermAttribute text = (TermAttribute) filter
+    TermAttribute text = filter
         .getAttribute(TermAttribute.class);
     assertTrue(filter.incrementToken());
     assertEquals("\u0001oD", text.term());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
index 77bca28..b8979ab 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
@@ -77,8 +77,8 @@ public class TestRussianAnalyzer extends BaseTokenStreamTestCase
             new RussianLetterTokenizer(
                 sampleUnicode);
 
-        TermAttribute text = (TermAttribute) in.getAttribute(TermAttribute.class);
-        TermAttribute sampleText = (TermAttribute) sample.getAttribute(TermAttribute.class);
+        TermAttribute text = in.getAttribute(TermAttribute.class);
+        TermAttribute sampleText = sample.getAttribute(TermAttribute.class);
 
         for (;;)
         {
@@ -113,8 +113,8 @@ public class TestRussianAnalyzer extends BaseTokenStreamTestCase
                 sampleKOI8,
                 RussianCharsets.KOI8);
 
-        TermAttribute text = (TermAttribute) in.getAttribute(TermAttribute.class);
-        TermAttribute sampleText = (TermAttribute) sample.getAttribute(TermAttribute.class);
+        TermAttribute text = in.getAttribute(TermAttribute.class);
+        TermAttribute sampleText = sample.getAttribute(TermAttribute.class);
 
         for (;;)
         {
@@ -147,8 +147,8 @@ public class TestRussianAnalyzer extends BaseTokenStreamTestCase
                 sample1251,
                 RussianCharsets.CP1251);
 
-        TermAttribute text = (TermAttribute) in.getAttribute(TermAttribute.class);
-        TermAttribute sampleText = (TermAttribute) sample.getAttribute(TermAttribute.class);
+        TermAttribute text = in.getAttribute(TermAttribute.class);
+        TermAttribute sampleText = sample.getAttribute(TermAttribute.class);
 
         for (;;)
         {
@@ -174,7 +174,7 @@ public class TestRussianAnalyzer extends BaseTokenStreamTestCase
         RussianAnalyzer ra = new RussianAnalyzer();
         TokenStream stream = ra.tokenStream("", reader);
 
-        TermAttribute termText = (TermAttribute) stream.getAttribute(TermAttribute.class);
+        TermAttribute termText = stream.getAttribute(TermAttribute.class);
         try {
             assertTrue(stream.incrementToken());
             assertEquals("text", termText.term());
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java
index 8df472b..f0978d8 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleAnalyzerWrapperTest.java
@@ -157,8 +157,8 @@ public class ShingleAnalyzerWrapperTest extends BaseTokenStreamTestCase {
                                           new StringReader("this sentence"));
     int j = -1;
     
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = ts.addAttribute(PositionIncrementAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
     
     while (ts.incrementToken()) {
       j += posIncrAtt.getPositionIncrement();
@@ -185,7 +185,7 @@ public class ShingleAnalyzerWrapperTest extends BaseTokenStreamTestCase {
     TokenStream ts = analyzer.tokenStream("content",
                                           new StringReader("test sentence"));
     
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
     
     while (ts.incrementToken()) {
       String termText =  termAtt.term();
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java
index c8f9d61..bda48c6 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/ShingleFilterTest.java
@@ -42,10 +42,10 @@ public class ShingleFilterTest extends BaseTokenStreamTestCase {
     public TestTokenStream(Token[] testToken) {
       super();
       this.testToken = testToken;
-      this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      this.termAtt = addAttribute(TermAttribute.class);
+      this.offsetAtt = addAttribute(OffsetAttribute.class);
+      this.posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      this.typeAtt = addAttribute(TypeAttribute.class);
     }
 
     public final boolean incrementToken() throws IOException {
@@ -299,10 +299,10 @@ public class ShingleFilterTest extends BaseTokenStreamTestCase {
     ShingleFilter filter = new ShingleFilter(new TestTokenStream(tokensToShingle), maxSize);
     filter.setOutputUnigrams(outputUnigrams);
 
-    TermAttribute termAtt = (TermAttribute) filter.addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) filter.addAttribute(OffsetAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) filter.addAttribute(PositionIncrementAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) filter.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = filter.addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = filter.addAttribute(OffsetAttribute.class);
+    PositionIncrementAttribute posIncrAtt = filter.addAttribute(PositionIncrementAttribute.class);
+    TypeAttribute typeAtt = filter.addAttribute(TypeAttribute.class);
 
     int i = 0;
     while (filter.incrementToken()) {
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter.java
index 5312e8e..bcab4b8 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/shingle/TestShingleMatrixFilter.java
@@ -454,16 +454,16 @@ public class TestShingleMatrixFilter extends BaseTokenStreamTestCase {
   // assert-methods start here
 
   private void assertNext(TokenStream ts, String text) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 
     assertTrue(ts.incrementToken());
     assertEquals(text, termAtt.term());
   }
 
   private void assertNext(TokenStream ts, String text, int positionIncrement, float boost) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = ts.addAttribute(PositionIncrementAttribute.class);
+    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);
     
     assertTrue(ts.incrementToken());    
     assertEquals(text, termAtt.term());
@@ -472,10 +472,10 @@ public class TestShingleMatrixFilter extends BaseTokenStreamTestCase {
   }
 
   private void assertNext(TokenStream ts, String text, int positionIncrement, float boost, int startOffset, int endOffset) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) ts.addAttribute(PositionIncrementAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) ts.addAttribute(PayloadAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = ts.addAttribute(PositionIncrementAttribute.class);
+    PayloadAttribute payloadAtt = ts.addAttribute(PayloadAttribute.class);
+    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
     
     assertTrue(ts.incrementToken());
     assertEquals(text, termAtt.term());
@@ -486,8 +486,8 @@ public class TestShingleMatrixFilter extends BaseTokenStreamTestCase {
   }
   
   private void assertNext(TokenStream ts, String text, int startOffset, int endOffset) throws IOException {
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) ts.addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
 
     assertTrue(ts.incrementToken());
     assertEquals(text, termAtt.term());
@@ -515,12 +515,12 @@ public class TestShingleMatrixFilter extends BaseTokenStreamTestCase {
     
     public TokenListStream(Collection tokens) {
       this.tokens = tokens;
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-      flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
+      flagsAtt = addAttribute(FlagsAttribute.class);
     }
 
     private Iterator iterator;
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java
index eb9d6f6..6ba2790 100644
--- a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/sinks/TokenTypeSinkTokenizerTest.java
@@ -44,8 +44,8 @@ public class TokenTypeSinkTokenizerTest extends BaseTokenStreamTestCase {
     
     boolean seenDogs = false;
 
-    TermAttribute termAtt = (TermAttribute) ttf.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) ttf.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = ttf.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = ttf.addAttribute(TypeAttribute.class);
     ttf.reset();
     while (ttf.incrementToken()) {
       if (termAtt.term().equals("dogs")) {
@@ -72,8 +72,8 @@ public class TokenTypeSinkTokenizerTest extends BaseTokenStreamTestCase {
     
     private WordTokenFilter(TokenStream input) {
       super(input);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
     }
 
     public final boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/smartcn/build.xml b/contrib/analyzers/smartcn/build.xml
index 0bb8644..401523e 100644
--- a/contrib/analyzers/smartcn/build.xml
+++ b/contrib/analyzers/smartcn/build.xml
@@ -22,9 +22,6 @@
   <description>
     Smart Chinese Analyzer
   </description>
-
-  <property name="javac.source" value="1.4" />
-  <property name="javac.target" value="1.4" />
 	
   <property name="build.dir" location="../../../build/contrib/analyzers/smartcn" />
   <property name="dist.dir" location="../../../dist/contrib/analyzers/smartcn" />
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
index dea0317..5581d97 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/SentenceTokenizer.java
@@ -68,9 +68,9 @@ public final class SentenceTokenizer extends Tokenizer {
   }
   
   private void init() {
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);    
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);    
   }
   
   public boolean incrementToken() throws IOException {
diff --git a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
index 91f23ee..1e15724 100644
--- a/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
+++ b/contrib/analyzers/smartcn/src/java/org/apache/lucene/analysis/cn/smart/WordTokenFilter.java
@@ -56,9 +56,9 @@ public final class WordTokenFilter extends TokenFilter {
   public WordTokenFilter(TokenStream in) {
     super(in);
     this.wordSegmenter = new WordSegmenter();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
   }
   
   public boolean incrementToken() throws IOException {   
diff --git a/contrib/collation/src/java/org/apache/lucene/collation/CollationKeyFilter.java b/contrib/collation/src/java/org/apache/lucene/collation/CollationKeyFilter.java
index 54d9bc3..c183a75 100644
--- a/contrib/collation/src/java/org/apache/lucene/collation/CollationKeyFilter.java
+++ b/contrib/collation/src/java/org/apache/lucene/collation/CollationKeyFilter.java
@@ -85,7 +85,7 @@ public final class CollationKeyFilter extends TokenFilter {
   public CollationKeyFilter(TokenStream input, Collator collator) {
     super(input);
     this.collator = collator;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/collation/src/java/org/apache/lucene/collation/ICUCollationKeyFilter.java b/contrib/collation/src/java/org/apache/lucene/collation/ICUCollationKeyFilter.java
index 1bd4a51..01dbb0b 100644
--- a/contrib/collation/src/java/org/apache/lucene/collation/ICUCollationKeyFilter.java
+++ b/contrib/collation/src/java/org/apache/lucene/collation/ICUCollationKeyFilter.java
@@ -83,7 +83,7 @@ public final class ICUCollationKeyFilter extends TokenFilter {
   public ICUCollationKeyFilter(TokenStream input, Collator collator) {
     super(input);
     this.collator = collator;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/fast-vector-highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java b/contrib/fast-vector-highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java
index 7356a31..aaedfc0 100644
--- a/contrib/fast-vector-highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java
+++ b/contrib/fast-vector-highlighter/src/test/org/apache/lucene/search/vectorhighlight/AbstractTestCase.java
@@ -195,8 +195,8 @@ public abstract class AbstractTestCase extends TestCase {
       ch = 0;
     }
 
-    TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
     public boolean incrementToken() throws IOException {
       if( !getNextPartialSnippet() )
         return false;
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
index 8f7cc98..a792d72 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/Highlighter.java
@@ -217,8 +217,8 @@ public class Highlighter
 		ArrayList docFrags = new ArrayList();
 		StringBuffer newText=new StringBuffer();
 		
-	    TermAttribute termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);
-	    OffsetAttribute offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);
+	    TermAttribute termAtt = tokenStream.addAttribute(TermAttribute.class);
+	    OffsetAttribute offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);
 	    tokenStream.addAttribute(PositionIncrementAttribute.class);
 	    tokenStream.reset();
 	    
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
index 24a3efe..8899a98 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryScorer.java
@@ -175,8 +175,8 @@ public class QueryScorer implements Scorer {
    */
   public TokenStream init(TokenStream tokenStream) throws IOException {
     position = -1;
-    termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);
-    posIncAtt = (PositionIncrementAttribute) tokenStream.addAttribute(PositionIncrementAttribute.class);
+    termAtt = tokenStream.addAttribute(TermAttribute.class);
+    posIncAtt = tokenStream.addAttribute(PositionIncrementAttribute.class);
     if(!skipInitExtractor) {
       if(fieldWeightedSpanTerms != null) {
         fieldWeightedSpanTerms.clear();
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermScorer.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermScorer.java
index be992ac..2a5d562 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermScorer.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/QueryTermScorer.java
@@ -95,7 +95,7 @@ public class QueryTermScorer implements Scorer {
    * @see org.apache.lucene.search.highlight.Scorer#init(org.apache.lucene.analysis.TokenStream)
    */
   public TokenStream init(TokenStream tokenStream) {
-    termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);
+    termAtt = tokenStream.addAttribute(TermAttribute.class);
     return null;
   }
 
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleFragmenter.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleFragmenter.java
index 285cb79..7be917e4 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleFragmenter.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleFragmenter.java
@@ -47,7 +47,7 @@ public class SimpleFragmenter implements Fragmenter {
    * @see org.apache.lucene.search.highlight.Fragmenter#start(java.lang.String, org.apache.lucene.analysis.TokenStream)
    */
   public void start(String originalText, TokenStream stream) {
-    offsetAtt = (OffsetAttribute) stream.addAttribute(OffsetAttribute.class);
+    offsetAtt = stream.addAttribute(OffsetAttribute.class);
     currentNumFrags = 1;
   }
 
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleSpanFragmenter.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleSpanFragmenter.java
index 05feb2e..b6aa329 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleSpanFragmenter.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/SimpleSpanFragmenter.java
@@ -101,8 +101,8 @@ public class SimpleSpanFragmenter implements Fragmenter {
     position = -1;
     currentNumFrags = 1;
     textSize = originalText.length();
-    termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);
-    posIncAtt = (PositionIncrementAttribute) tokenStream.addAttribute(PositionIncrementAttribute.class);
-    offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);
+    termAtt = tokenStream.addAttribute(TermAttribute.class);
+    posIncAtt = tokenStream.addAttribute(PositionIncrementAttribute.class);
+    offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);
   }
 }
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenGroup.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenGroup.java
index 5843deb..57355e5 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenGroup.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenGroup.java
@@ -41,8 +41,8 @@ public class TokenGroup {
   private TermAttribute termAtt;
 
   public TokenGroup(TokenStream tokenStream) {
-    offsetAtt = (OffsetAttribute) tokenStream.addAttribute(OffsetAttribute.class);
-    termAtt = (TermAttribute) tokenStream.addAttribute(TermAttribute.class);
+    offsetAtt = tokenStream.addAttribute(OffsetAttribute.class);
+    termAtt = tokenStream.addAttribute(TermAttribute.class);
   }
 
   void addToken(float score) {
diff --git a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
index b56b90a..ebbaef7 100644
--- a/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
+++ b/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources.java
@@ -147,8 +147,8 @@ public class TokenSources
     
           StoredTokenStream(Token tokens[]) {
             this.tokens = tokens;
-            termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-            offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+            termAtt = addAttribute(TermAttribute.class);
+            offsetAtt = addAttribute(OffsetAttribute.class);
           }
     
           public boolean incrementToken() throws IOException {
diff --git a/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index 2f3aace..80617a9 100644
--- a/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -1316,9 +1316,9 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       private PositionIncrementAttribute posIncrAtt;
       private OffsetAttribute offsetAtt;
       {
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-        posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-        offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
+        posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+        offsetAtt = addAttribute(OffsetAttribute.class);
         lst = new ArrayList();
         Token t;
         t = createToken("hi", 0, 2);
@@ -1363,9 +1363,9 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       private PositionIncrementAttribute posIncrAtt;
       private OffsetAttribute offsetAtt;
       {
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-        posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-        offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
+        posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+        offsetAtt = addAttribute(OffsetAttribute.class);
         lst = new ArrayList();
         Token t;
         t = createToken("hispeed", 0, 8);
@@ -1686,13 +1686,13 @@ class SynonymTokenizer extends TokenStream {
   public SynonymTokenizer(TokenStream realStream, Map synonyms) {
     this.realStream = realStream;
     this.synonyms = synonyms;
-    realTermAtt = (TermAttribute) realStream.addAttribute(TermAttribute.class);
-    realPosIncrAtt = (PositionIncrementAttribute) realStream.addAttribute(PositionIncrementAttribute.class);
-    realOffsetAtt = (OffsetAttribute) realStream.addAttribute(OffsetAttribute.class);
+    realTermAtt = realStream.addAttribute(TermAttribute.class);
+    realPosIncrAtt = realStream.addAttribute(PositionIncrementAttribute.class);
+    realOffsetAtt = realStream.addAttribute(OffsetAttribute.class);
 
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/contrib/lucli/src/java/lucli/LuceneMethods.java b/contrib/lucli/src/java/lucli/LuceneMethods.java
index 731ae7a..21ecf05 100644
--- a/contrib/lucli/src/java/lucli/LuceneMethods.java
+++ b/contrib/lucli/src/java/lucli/LuceneMethods.java
@@ -282,8 +282,8 @@ class LuceneMethods {
           int position = 0;
           // Tokenize field and add to postingTable
           TokenStream stream = analyzer.tokenStream(fieldName, reader);
-          TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
+          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
+          PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);
           
           try {
             while (stream.incrementToken()) {
diff --git a/contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java b/contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java
index 0ec2bca..d3a5810 100644
--- a/contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java
+++ b/contrib/memory/src/java/org/apache/lucene/index/memory/AnalyzerUtil.java
@@ -75,10 +75,10 @@ public class AnalyzerUtil {
       public TokenStream tokenStream(final String fieldName, Reader reader) {
         return new TokenFilter(child.tokenStream(fieldName, reader)) {
           private int position = -1;
-          private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-          private PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-          private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-          private TypeAttribute typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+          private TermAttribute termAtt = addAttribute(TermAttribute.class);
+          private PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+          private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+          private TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
          
           public boolean incrementToken() throws IOException {
             boolean hasNext = input.incrementToken();
@@ -307,7 +307,7 @@ public class AnalyzerUtil {
     // compute frequencies of distinct terms
     HashMap map = new HashMap();
     TokenStream stream = analyzer.tokenStream("", new StringReader(text));
-    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
     try {
       while (stream.incrementToken()) {
         MutableInteger freq = (MutableInteger) map.get(termAtt.term());
diff --git a/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java b/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
index 1f53195..2cedc64 100644
--- a/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
+++ b/contrib/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
@@ -276,8 +276,8 @@ public class MemoryIndex implements Serializable {
     return new TokenStream() {
       private Iterator iter = keywords.iterator();
       private int start = 0;
-      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      private TermAttribute termAtt = addAttribute(TermAttribute.class);
+      private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
       
       public boolean incrementToken() {
         if (!iter.hasNext()) return false;
@@ -338,9 +338,9 @@ public class MemoryIndex implements Serializable {
       int numOverlapTokens = 0;
       int pos = -1;
       
-      TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
-      PositionIncrementAttribute posIncrAttribute = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
-      OffsetAttribute offsetAtt = (OffsetAttribute) stream.addAttribute(OffsetAttribute.class);
+      TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
+      PositionIncrementAttribute posIncrAttribute = stream.addAttribute(PositionIncrementAttribute.class);
+      OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);
       
       stream.reset();
       while (stream.incrementToken()) {
diff --git a/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java b/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
index a88429f..024adcb 100644
--- a/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
+++ b/contrib/memory/src/java/org/apache/lucene/index/memory/PatternAnalyzer.java
@@ -332,8 +332,8 @@ public class PatternAnalyzer extends Analyzer {
     private Matcher matcher;
     private int pos = 0;
     private static final Locale locale = Locale.getDefault();
-    private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    private TermAttribute termAtt = addAttribute(TermAttribute.class);
+    private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
     
     public PatternTokenizer(String str, Pattern pattern, boolean toLowerCase) {
       this.str = str;
@@ -390,8 +390,8 @@ public class PatternAnalyzer extends Analyzer {
     private final boolean toLowerCase;
     private final Set stopWords;
     private static final Locale locale = Locale.getDefault();
-    private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    private TermAttribute termAtt = addAttribute(TermAttribute.class);
+    private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
     
     public FastStringTokenizer(String str, boolean isLetter, boolean toLowerCase, Set stopWords) {
       this.str = str;
diff --git a/contrib/memory/src/java/org/apache/lucene/index/memory/SynonymTokenFilter.java b/contrib/memory/src/java/org/apache/lucene/index/memory/SynonymTokenFilter.java
index 818bd7e..1b84101 100644
--- a/contrib/memory/src/java/org/apache/lucene/index/memory/SynonymTokenFilter.java
+++ b/contrib/memory/src/java/org/apache/lucene/index/memory/SynonymTokenFilter.java
@@ -72,9 +72,9 @@ public class SynonymTokenFilter extends TokenFilter {
     this.synonyms = synonyms;
     this.maxSynonyms = maxSynonyms;
     
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.typeAtt = addAttribute(TypeAttribute.class);
+    this.posIncrAtt = addAttribute(PositionIncrementAttribute.class);
   }
   
   /** Returns the next token in the stream, or null at EOS. */
diff --git a/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java b/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java
index c3f686a..f52e8ee 100644
--- a/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java
+++ b/contrib/misc/src/java/org/apache/lucene/queryParser/analyzing/AnalyzingQueryParser.java
@@ -106,7 +106,7 @@ public class AnalyzingQueryParser extends org.apache.lucene.queryParser.QueryPar
 
     // get Analyzer from superclass and tokenize the term
     TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));
-    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = source.addAttribute(TermAttribute.class);
     
     int countTokens = 0;
     while (true) {
@@ -188,7 +188,7 @@ public class AnalyzingQueryParser extends org.apache.lucene.queryParser.QueryPar
     // get Analyzer from superclass and tokenize the term
     TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));
     List tlist = new ArrayList();
-    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = source.addAttribute(TermAttribute.class);
     
     while (true) {
       try {
@@ -234,7 +234,7 @@ public class AnalyzingQueryParser extends org.apache.lucene.queryParser.QueryPar
       throws ParseException {
     // get Analyzer from superclass and tokenize the term
     TokenStream source = getAnalyzer().tokenStream(field, new StringReader(termStr));
-    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = source.addAttribute(TermAttribute.class);
     String nextToken = null;
     boolean multipleTokens = false;
     
@@ -269,7 +269,7 @@ public class AnalyzingQueryParser extends org.apache.lucene.queryParser.QueryPar
       throws ParseException {
     // get Analyzer from superclass and tokenize the terms
     TokenStream source = getAnalyzer().tokenStream(field, new StringReader(part1));
-    TermAttribute termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = source.addAttribute(TermAttribute.class);
     boolean multipleTokens = false;
 
     // part1
@@ -293,7 +293,7 @@ public class AnalyzingQueryParser extends org.apache.lucene.queryParser.QueryPar
 
     // part2
     source = getAnalyzer().tokenStream(field, new StringReader(part2));
-    termAtt = (TermAttribute) source.addAttribute(TermAttribute.class);
+    termAtt = source.addAttribute(TermAttribute.class);
     
     try {
       if (source.incrementToken()) {
diff --git a/contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java b/contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
index 5925354..360ffee 100644
--- a/contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
+++ b/contrib/misc/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
@@ -67,8 +67,8 @@ public class TestPrecedenceQueryParser extends LocalizedTestCase {
     boolean inPhrase = false;
     int savedStart = 0, savedEnd = 0;
 
-    TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = addAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
     
     public boolean incrementToken() throws IOException {
       if (inPhrase) {
diff --git a/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java b/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java
index b6e9446f..37a937d 100644
--- a/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java
+++ b/contrib/queries/src/java/org/apache/lucene/search/FuzzyLikeThisQuery.java
@@ -182,7 +182,7 @@ public class FuzzyLikeThisQuery extends Query
     {
         if(f.queryString==null) return;
         TokenStream ts=analyzer.tokenStream(f.fieldName,new StringReader(f.queryString));
-        TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+        TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
         
         int corpusNumDocs=reader.numDocs();
         Term internSavingTemplateTerm =new Term(f.fieldName); //optimization to avoid constructing new Term() objects
diff --git a/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java b/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
index 098ec74..6622998 100644
--- a/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
+++ b/contrib/queries/src/java/org/apache/lucene/search/similar/MoreLikeThis.java
@@ -829,7 +829,7 @@ public final class MoreLikeThis {
 		   TokenStream ts = analyzer.tokenStream(fieldName, r);
 			int tokenCount=0;
 			// for every token
-			TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+			TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 			
 			while (ts.incrementToken()) {
 				String word = termAtt.term();
diff --git a/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java b/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
index 9b6d4ce..62e53a2 100644
--- a/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
+++ b/contrib/queries/src/java/org/apache/lucene/search/similar/SimilarityQueries.java
@@ -86,7 +86,7 @@ public final class SimilarityQueries
 										  throws IOException
 	{	
 		TokenStream ts = a.tokenStream( field, new StringReader( body));
-		TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+		TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 		
 		BooleanQuery tmp = new BooleanQuery();
 		Set already = new HashSet(); // ignore dups
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
index dcdc6d0..e5aafbc 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
@@ -55,11 +55,11 @@ import org.apache.lucene.search.Query;
 import org.apache.lucene.util.Parameter;
 
 /**
- * This class performs the query parsing using the new query parser implementation, but
- * keeps the old {@link QueryParser} API. <br/>
+ * This class performs the query parsing using the new query parser
+ * implementation, but keeps the old {@link QueryParser} API. <br/>
  * <br/>
- * This class should be used when the new query parser features are and
- * the old {@link QueryParser} API are needed at the same time. <br/>
+ * This class should be used when the new query parser features are and the old
+ * {@link QueryParser} API are needed at the same time. <br/>
  * 
  * @deprecated this class will be removed soon, it's a temporary class to be
  *             used along the transition from the old query parser to the new
@@ -79,12 +79,14 @@ public class QueryParserWrapper {
     }
 
     static public final Operator OR = new Operator("OR");
+
     static public final Operator AND = new Operator("AND");
   }
 
   // the nested class:
   /** Alternative form of QueryParser.Operator.AND */
   public static final Operator AND_OPERATOR = Operator.AND;
+
   /** Alternative form of QueryParser.Operator.OR */
   public static final Operator OR_OPERATOR = Operator.OR;
 
@@ -111,6 +113,7 @@ public class QueryParserWrapper {
   private SyntaxParser syntaxParser = new StandardSyntaxParser();
 
   private StandardQueryConfigHandler config;
+
   private StandardQueryParser qpHelper;
 
   private QueryNodeProcessor processorPipeline;
@@ -121,9 +124,9 @@ public class QueryParserWrapper {
 
   public QueryParserWrapper(String defaultField, Analyzer analyzer) {
     this.defaultField = defaultField;
-    
+
     this.qpHelper = new StandardQueryParser();
-    
+
     this.config = (StandardQueryConfigHandler) qpHelper.getQueryConfigHandler();
 
     this.qpHelper.setAnalyzer(analyzer);
@@ -135,7 +138,7 @@ public class QueryParserWrapper {
   StandardQueryParser getQueryParserHelper() {
     return qpHelper;
   }
-  
+
   public String getField() {
     return this.defaultField;
   }
@@ -144,8 +147,9 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(AnalyzerAttribute.class)) {
-      return ((AnalyzerAttribute) this.config
-          .getAttribute(AnalyzerAttribute.class)).getAnalyzer();
+
+      return this.config.getAttribute(AnalyzerAttribute.class).getAnalyzer();
+
     }
 
     return null;
@@ -153,11 +157,10 @@ public class QueryParserWrapper {
   }
 
   /**
-   * Sets the {@link StandardQueryBuilder} used to generate a {@link Query} object
-   * from the parsed and processed query node tree.
+   * Sets the {@link StandardQueryBuilder} used to generate a {@link Query}
+   * object from the parsed and processed query node tree.
    * 
-   * @param builder
-   *          the builder
+   * @param builder the builder
    */
   public void setQueryBuilder(StandardQueryBuilder builder) {
     this.builder = builder;
@@ -168,8 +171,7 @@ public class QueryParserWrapper {
    * generated by the
    * {@link org.apache.lucene.queryParser.standard.parser.StandardSyntaxParser}.
    * 
-   * @param processor
-   *          the processor
+   * @param processor the processor
    */
   public void setQueryProcessor(QueryNodeProcessor processor) {
     this.processorPipeline = processor;
@@ -181,8 +183,7 @@ public class QueryParserWrapper {
    * Sets the {@link QueryConfigHandler} used by the {@link QueryNodeProcessor}
    * set to this object.
    * 
-   * @param queryConfig
-   *          the query config handler
+   * @param queryConfig the query config handler
    */
   public void setQueryConfig(StandardQueryConfigHandler queryConfig) {
     this.config = queryConfig;
@@ -221,9 +222,10 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(AllowLeadingWildcardAttribute.class)) {
-      return ((AllowLeadingWildcardAttribute) this.config
-          .getAttribute(AllowLeadingWildcardAttribute.class))
+
+      return this.config.getAttribute(AllowLeadingWildcardAttribute.class)
           .isAllowLeadingWildcard();
+
     }
 
     return false;
@@ -231,11 +233,13 @@ public class QueryParserWrapper {
   }
 
   public MultiTermQuery.RewriteMethod getMultiTermRewriteMethod() {
+
     if (this.config != null
         && this.config.hasAttribute(MultiTermRewriteMethodAttribute.class)) {
-      return ((MultiTermRewriteMethodAttribute) this.config
-          .getAttribute(MultiTermRewriteMethodAttribute.class))
+
+      return this.config.getAttribute(MultiTermRewriteMethodAttribute.class)
           .getMultiTermRewriteMethod();
+
     }
 
     return MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT;
@@ -250,8 +254,10 @@ public class QueryParserWrapper {
       if (fieldConfig != null) {
 
         if (this.config.hasAttribute(DateResolutionAttribute.class)) {
-          return ((DateResolutionAttribute) this.config
-              .getAttribute(DateResolutionAttribute.class)).getDateResolution();
+
+          return this.config.getAttribute(DateResolutionAttribute.class)
+              .getDateResolution();
+
         }
 
       }
@@ -266,9 +272,10 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(PositionIncrementsAttribute.class)) {
-      return ((PositionIncrementsAttribute) this.config
-          .getAttribute(PositionIncrementsAttribute.class))
+
+      return this.config.getAttribute(PositionIncrementsAttribute.class)
           .isPositionIncrementsEnabled();
+
     }
 
     return false;
@@ -286,8 +293,7 @@ public class QueryParserWrapper {
   public Locale getLocale() {
 
     if (this.config != null && this.config.hasAttribute(LocaleAttribute.class)) {
-      return ((LocaleAttribute) this.config.getAttribute(LocaleAttribute.class))
-          .getLocale();
+      return this.config.getAttribute(LocaleAttribute.class).getLocale();
     }
 
     return Locale.getDefault();
@@ -298,9 +304,10 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(LowercaseExpandedTermsAttribute.class)) {
-      return ((LowercaseExpandedTermsAttribute) this.config
-          .getAttribute(LowercaseExpandedTermsAttribute.class))
+
+      return this.config.getAttribute(LowercaseExpandedTermsAttribute.class)
           .isLowercaseExpandedTerms();
+
     }
 
     return true;
@@ -311,9 +318,10 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(AllowLeadingWildcardAttribute.class)) {
-      return ((DefaultPhraseSlopAttribute) this.config
-          .getAttribute(DefaultPhraseSlopAttribute.class))
+
+      return this.config.getAttribute(DefaultPhraseSlopAttribute.class)
           .getDefaultPhraseSlop();
+
     }
 
     return 0;
@@ -324,8 +332,10 @@ public class QueryParserWrapper {
 
     if (this.config != null
         && this.config.hasAttribute(RangeCollatorAttribute.class)) {
-      return ((RangeCollatorAttribute) this.config
-          .getAttribute(RangeCollatorAttribute.class)).getRangeCollator();
+
+      return this.config.getAttribute(RangeCollatorAttribute.class)
+          .getRangeCollator();
+
     }
 
     return null;
@@ -357,7 +367,7 @@ public class QueryParserWrapper {
     this.qpHelper.setAllowLeadingWildcard(allowLeadingWildcard);
   }
 
-  public void setMultiTermRewriteMethod(MultiTermQuery.RewriteMethod method) {  
+  public void setMultiTermRewriteMethod(MultiTermQuery.RewriteMethod method) {
     this.qpHelper.setMultiTermRewriteMethod(method);
   }
 
@@ -365,8 +375,8 @@ public class QueryParserWrapper {
     this.qpHelper.setDateResolution(dateResolution);
   }
 
-  private Map<CharSequence, DateTools.Resolution> dateRes =  new HashMap<CharSequence, DateTools.Resolution>();
-  
+  private Map<CharSequence, DateTools.Resolution> dateRes = new HashMap<CharSequence, DateTools.Resolution>();
+
   public void setDateResolution(String fieldName, Resolution dateResolution) {
     dateRes.put(fieldName, dateResolution);
     this.qpHelper.setDateResolution(dateRes);
@@ -385,8 +395,8 @@ public class QueryParserWrapper {
     if (this.config != null
         && this.config.hasAttribute(DefaultOperatorAttribute.class)) {
 
-      return (((DefaultOperatorAttribute) this.config
-          .getAttribute(DefaultOperatorAttribute.class)).getOperator() == org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute.Operator.AND) ? AND_OPERATOR
+      return (this.config.getAttribute(DefaultOperatorAttribute.class)
+          .getOperator() == org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute.Operator.AND) ? AND_OPERATOR
           : OR_OPERATOR;
 
     }
@@ -449,8 +459,7 @@ public class QueryParserWrapper {
   }
 
   /**
-   * @exception ParseException
-   *              throw in overridden method to disallow
+   * @exception ParseException throw in overridden method to disallow
    */
   protected Query getFieldQuery(String field, String queryText)
       throws ParseException {
@@ -458,7 +467,7 @@ public class QueryParserWrapper {
   }
 
   @SuppressWarnings("unchecked")
-protected Query getBooleanQuery(List clauses, boolean disableCoord)
+  protected Query getBooleanQuery(List clauses, boolean disableCoord)
       throws ParseException {
     throw new UnsupportedOperationException();
   }
@@ -468,8 +477,7 @@ protected Query getBooleanQuery(List clauses, boolean disableCoord)
    * This method may be overridden, for example, to return a SpanNearQuery
    * instead of a PhraseQuery.
    * 
-   * @exception ParseException
-   *              throw in overridden method to disallow
+   * @exception ParseException throw in overridden method to disallow
    */
   protected Query getFieldQuery(String field, String queryText, int slop)
       throws ParseException {
@@ -477,8 +485,7 @@ protected Query getBooleanQuery(List clauses, boolean disableCoord)
   }
 
   /**
-   * @exception ParseException
-   *              throw in overridden method to disallow
+   * @exception ParseException throw in overridden method to disallow
    */
   protected Query getRangeQuery(String field, String part1, String part2,
       boolean inclusive) throws ParseException {
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/StandardQueryParser.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/StandardQueryParser.java
index 3640548..e737dc3 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/StandardQueryParser.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/StandardQueryParser.java
@@ -182,7 +182,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * or {@link Operator#OR}.
    */
   public Operator getDefaultOperator() {
-    DefaultOperatorAttribute attr = (DefaultOperatorAttribute) getQueryConfigHandler().getAttribute(DefaultOperatorAttribute.class);
+    DefaultOperatorAttribute attr = getQueryConfigHandler().getAttribute(DefaultOperatorAttribute.class);
     return attr.getOperator();
   }
 
@@ -199,7 +199,7 @@ public class StandardQueryParser extends QueryParserHelper {
    *          the collator to use when constructing {@link RangeQueryNode}s
    */
   public void setRangeCollator(Collator collator) {
-    RangeCollatorAttribute attr = (RangeCollatorAttribute) getQueryConfigHandler().getAttribute(RangeCollatorAttribute.class);
+    RangeCollatorAttribute attr = getQueryConfigHandler().getAttribute(RangeCollatorAttribute.class);
     attr.setDateResolution(collator);
   }
 
@@ -208,7 +208,7 @@ public class StandardQueryParser extends QueryParserHelper {
    *         RangeQuerys.
    */
   public Collator getRangeCollator() {
-    RangeCollatorAttribute attr = (RangeCollatorAttribute) getQueryConfigHandler().getAttribute(RangeCollatorAttribute.class);
+    RangeCollatorAttribute attr = getQueryConfigHandler().getAttribute(RangeCollatorAttribute.class);
     return attr.getRangeCollator();
   }
 
@@ -221,7 +221,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * above mentioned query is parsed as <code>capital AND of AND Hungary</code>
    */
   public void setDefaultOperator(Operator operator) {
-    DefaultOperatorAttribute attr = (DefaultOperatorAttribute) getQueryConfigHandler().getAttribute(DefaultOperatorAttribute.class);
+    DefaultOperatorAttribute attr = getQueryConfigHandler().getAttribute(DefaultOperatorAttribute.class);
     attr.setOperator(operator);
   }
 
@@ -235,7 +235,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Default: false.
    */
   public void setLowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
-    LowercaseExpandedTermsAttribute attr= (LowercaseExpandedTermsAttribute) getQueryConfigHandler().getAttribute(LowercaseExpandedTermsAttribute.class);
+    LowercaseExpandedTermsAttribute attr = getQueryConfigHandler().getAttribute(LowercaseExpandedTermsAttribute.class);
     attr.setLowercaseExpandedTerms(lowercaseExpandedTerms);
   }
 
@@ -243,7 +243,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * @see #setLowercaseExpandedTerms(boolean)
    */
   public boolean getLowercaseExpandedTerms() {
-    LowercaseExpandedTermsAttribute attr = (LowercaseExpandedTermsAttribute) getQueryConfigHandler().getAttribute(LowercaseExpandedTermsAttribute.class);
+    LowercaseExpandedTermsAttribute attr = getQueryConfigHandler().getAttribute(LowercaseExpandedTermsAttribute.class);
     return attr.isLowercaseExpandedTerms();
   }
 
@@ -257,7 +257,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Default: false.
    */
   public void setAllowLeadingWildcard(boolean allowLeadingWildcard) {
-    AllowLeadingWildcardAttribute attr = (AllowLeadingWildcardAttribute) getQueryConfigHandler().getAttribute(AllowLeadingWildcardAttribute.class);
+    AllowLeadingWildcardAttribute attr = getQueryConfigHandler().getAttribute(AllowLeadingWildcardAttribute.class);
     attr.setAllowLeadingWildcard(allowLeadingWildcard);
   }
 
@@ -271,7 +271,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Default: false.
    */
   public void setEnablePositionIncrements(boolean enabled) {
-    PositionIncrementsAttribute attr = (PositionIncrementsAttribute) getQueryConfigHandler().getAttribute(PositionIncrementsAttribute.class);
+    PositionIncrementsAttribute attr = getQueryConfigHandler().getAttribute(PositionIncrementsAttribute.class);
     attr.setPositionIncrementsEnabled(enabled);
   }
 
@@ -279,7 +279,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * @see #setEnablePositionIncrements(boolean)
    */
   public boolean getEnablePositionIncrements() {
-    PositionIncrementsAttribute attr = (PositionIncrementsAttribute) getQueryConfigHandler().getAttribute(PositionIncrementsAttribute.class);
+    PositionIncrementsAttribute attr = getQueryConfigHandler().getAttribute(PositionIncrementsAttribute.class);
     return attr.isPositionIncrementsEnabled();
   }
 
@@ -294,7 +294,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * not relevant then use this change the rewrite method.
    */
   public void setMultiTermRewriteMethod(MultiTermQuery.RewriteMethod method) {
-    MultiTermRewriteMethodAttribute attr = (MultiTermRewriteMethodAttribute) getQueryConfigHandler().getAttribute(MultiTermRewriteMethodAttribute.class);
+    MultiTermRewriteMethodAttribute attr = getQueryConfigHandler().getAttribute(MultiTermRewriteMethodAttribute.class);
     attr.setMultiTermRewriteMethod(method);
   }
 
@@ -302,7 +302,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * @see #setMultiTermRewriteMethod(org.apache.lucene.search.MultiTermQuery.RewriteMethod)
    */
   public MultiTermQuery.RewriteMethod getMultiTermRewriteMethod() {
-    MultiTermRewriteMethodAttribute attr =(MultiTermRewriteMethodAttribute) getQueryConfigHandler().getAttribute(MultiTermRewriteMethodAttribute.class);    
+    MultiTermRewriteMethodAttribute attr = getQueryConfigHandler().getAttribute(MultiTermRewriteMethodAttribute.class);    
     return attr.getMultiTermRewriteMethod();
   }
 
@@ -312,7 +312,7 @@ public class StandardQueryParser extends QueryParserHelper {
       fields = new CharSequence[0];
     }
 
-    MultiFieldAttribute attr = (MultiFieldAttribute) getQueryConfigHandler().addAttribute(MultiFieldAttribute.class);
+    MultiFieldAttribute attr = getQueryConfigHandler().addAttribute(MultiFieldAttribute.class);
     attr.setFields(fields);
 
   }
@@ -324,7 +324,7 @@ public class StandardQueryParser extends QueryParserHelper {
    *          The fuzzyPrefixLength to set.
    */
   public void setFuzzyPrefixLength(int fuzzyPrefixLength) {
-    FuzzyAttribute attr = (FuzzyAttribute) getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
+    FuzzyAttribute attr = getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
     attr.setPrefixLength(fuzzyPrefixLength);
   }
 
@@ -332,7 +332,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Set locale used by date range parsing.
    */
   public void setLocale(Locale locale) {
-    LocaleAttribute attr = (LocaleAttribute) getQueryConfigHandler().addAttribute(LocaleAttribute.class);
+    LocaleAttribute attr = getQueryConfigHandler().addAttribute(LocaleAttribute.class);
     attr.setLocale(locale);
   }
 
@@ -340,7 +340,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Returns current locale, allowing access by subclasses.
    */
   public Locale getLocale() {
-    LocaleAttribute attr = (LocaleAttribute) getQueryConfigHandler().addAttribute(LocaleAttribute.class);
+    LocaleAttribute attr = getQueryConfigHandler().addAttribute(LocaleAttribute.class);
     return attr.getLocale();
   }
 
@@ -349,12 +349,12 @@ public class StandardQueryParser extends QueryParserHelper {
    * required. Default value is zero.
    */
   public void setDefaultPhraseSlop(int defaultPhraseSlop) {
-    DefaultPhraseSlopAttribute attr = (DefaultPhraseSlopAttribute) getQueryConfigHandler().addAttribute(DefaultPhraseSlopAttribute.class);
+    DefaultPhraseSlopAttribute attr = getQueryConfigHandler().addAttribute(DefaultPhraseSlopAttribute.class);
     attr.setDefaultPhraseSlop(defaultPhraseSlop);
   }
 
   public void setAnalyzer(Analyzer analyzer) {
-    AnalyzerAttribute attr= (AnalyzerAttribute) getQueryConfigHandler().getAttribute(AnalyzerAttribute.class);
+    AnalyzerAttribute attr = getQueryConfigHandler().getAttribute(AnalyzerAttribute.class);
     attr.setAnalyzer(analyzer);
   }
   
@@ -362,7 +362,7 @@ public class StandardQueryParser extends QueryParserHelper {
     QueryConfigHandler config = this.getQueryConfigHandler();
 
     if ( config.hasAttribute(AnalyzerAttribute.class)) {
-      AnalyzerAttribute attr= (AnalyzerAttribute) config.getAttribute(AnalyzerAttribute.class);
+      AnalyzerAttribute attr = config.getAttribute(AnalyzerAttribute.class);
       return attr.getAnalyzer();
     }
 
@@ -373,7 +373,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * @see #setAllowLeadingWildcard(boolean)
    */
   public boolean getAllowLeadingWildcard() {
-    AllowLeadingWildcardAttribute attr = (AllowLeadingWildcardAttribute) getQueryConfigHandler().addAttribute(AllowLeadingWildcardAttribute.class);
+    AllowLeadingWildcardAttribute attr = getQueryConfigHandler().addAttribute(AllowLeadingWildcardAttribute.class);
     return attr.isAllowLeadingWildcard();
   }
 
@@ -381,7 +381,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Get the minimal similarity for fuzzy queries.
    */
   public float getFuzzyMinSim() {
-    FuzzyAttribute attr = (FuzzyAttribute) getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
+    FuzzyAttribute attr = getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
     return attr.getFuzzyMinSimilarity();
   }
 
@@ -391,7 +391,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * @return Returns the fuzzyPrefixLength.
    */
   public int getFuzzyPrefixLength() {
-    FuzzyAttribute attr = (FuzzyAttribute) getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
+    FuzzyAttribute attr = getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
     return attr.getPrefixLength();
   }
 
@@ -399,7 +399,7 @@ public class StandardQueryParser extends QueryParserHelper {
    * Gets the default slop for phrases.
    */
   public int getPhraseSlop() {
-    DefaultPhraseSlopAttribute attr = (DefaultPhraseSlopAttribute) getQueryConfigHandler().addAttribute(DefaultPhraseSlopAttribute.class);
+    DefaultPhraseSlopAttribute attr = getQueryConfigHandler().addAttribute(DefaultPhraseSlopAttribute.class);
     return attr.getDefaultPhraseSlop();
   }
 
@@ -408,22 +408,22 @@ public class StandardQueryParser extends QueryParserHelper {
    * {@link FuzzyQuery#defaultMinSimilarity}.
    */
   public void setFuzzyMinSim(float fuzzyMinSim) {
-    FuzzyAttribute attr = (FuzzyAttribute) getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
+    FuzzyAttribute attr = getQueryConfigHandler().addAttribute(FuzzyAttribute.class);
     attr.setFuzzyMinSimilarity(fuzzyMinSim);
   }
   
   public void setFieldsBoost(Map<CharSequence, Float> boosts) {
-    FieldBoostMapAttribute attr = (FieldBoostMapAttribute) getQueryConfigHandler().addAttribute(FieldBoostMapAttribute.class);
+    FieldBoostMapAttribute attr = getQueryConfigHandler().addAttribute(FieldBoostMapAttribute.class);
     attr.setFieldBoostMap(boosts);
   }
 
   public void setDateResolution(DateTools.Resolution dateResolution) {
-    DateResolutionAttribute attr = (DateResolutionAttribute) getQueryConfigHandler().addAttribute(DateResolutionAttribute.class);
+    DateResolutionAttribute attr = getQueryConfigHandler().addAttribute(DateResolutionAttribute.class);
     attr.setDateResolution(dateResolution);
   }
 
   public void setDateResolution(Map<CharSequence, DateTools.Resolution> dateRes) {
-    FieldDateResolutionMapAttribute attr = (FieldDateResolutionMapAttribute) getQueryConfigHandler().addAttribute(FieldDateResolutionMapAttribute.class);
+    FieldDateResolutionMapAttribute attr = getQueryConfigHandler().addAttribute(FieldDateResolutionMapAttribute.class);
     attr.setFieldDateResolutionMap(dateRes);
   }
   
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldBoostMapFCListener.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldBoostMapFCListener.java
index 9b715b5..5e8399e 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldBoostMapFCListener.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldBoostMapFCListener.java
@@ -44,8 +44,8 @@ public class FieldBoostMapFCListener implements FieldConfigListener {
 
   public void buildFieldConfig(FieldConfig fieldConfig) {    
     if (this.config.hasAttribute(FieldBoostMapAttribute.class)) {
-      FieldBoostMapAttribute fieldBoostMapAttr = (FieldBoostMapAttribute) this.config.getAttribute(FieldBoostMapAttribute.class);
-      BoostAttribute boostAttr = (BoostAttribute) fieldConfig.addAttribute(BoostAttribute.class);
+      FieldBoostMapAttribute fieldBoostMapAttr = this.config.getAttribute(FieldBoostMapAttribute.class);
+      BoostAttribute boostAttr = fieldConfig.addAttribute(BoostAttribute.class);
       
       Float boost = fieldBoostMapAttr.getFieldBoostMap().get(fieldConfig.getFieldName());
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldDateResolutionFCListener.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldDateResolutionFCListener.java
index 28e95c8..7d6b66c 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldDateResolutionFCListener.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/config/FieldDateResolutionFCListener.java
@@ -24,9 +24,10 @@ import org.apache.lucene.queryParser.core.config.QueryConfigHandler;
 
 /**
  * This listener listens for every field configuration request and assign a
- * {@link DateResolutionAttribute} to the equivalent {@link FieldConfig} based on a
- * defined map: fieldName -> DateTools.Resolution stored in {@link FieldDateResolutionMapAttribute}
- * in the {@link DateResolutionAttribute}.
+ * {@link DateResolutionAttribute} to the equivalent {@link FieldConfig} based
+ * on a defined map: fieldName -> DateTools.Resolution stored in
+ * {@link FieldDateResolutionMapAttribute} in the
+ * {@link DateResolutionAttribute}.
  * 
  * @see DateResolutionAttribute
  * @see FieldDateResolutionMapAttribute
@@ -38,27 +39,27 @@ public class FieldDateResolutionFCListener implements FieldConfigListener {
   private static final long serialVersionUID = -5929802948798314067L;
 
   private QueryConfigHandler config = null;
-  
+
   public FieldDateResolutionFCListener(QueryConfigHandler config) {
     this.config = config;
   }
-  
+
   public void buildFieldConfig(FieldConfig fieldConfig) {
-    DateResolutionAttribute fieldDateResAttr = (DateResolutionAttribute) fieldConfig
+    DateResolutionAttribute fieldDateResAttr = fieldConfig
         .addAttribute(DateResolutionAttribute.class);
     DateTools.Resolution dateRes = null;
 
     if (this.config.hasAttribute(FieldDateResolutionMapAttribute.class)) {
-      FieldDateResolutionMapAttribute dateResMapAttr = (FieldDateResolutionMapAttribute) this.config
+      FieldDateResolutionMapAttribute dateResMapAttr = this.config
           .addAttribute(FieldDateResolutionMapAttribute.class);
       dateRes = dateResMapAttr.getFieldDateResolutionMap().get(
           fieldConfig.getFieldName().toString());
     }
 
     if (dateRes == null) {
-      
+
       if (this.config.hasAttribute(DateResolutionAttribute.class)) {
-        DateResolutionAttribute dateResAttr = (DateResolutionAttribute) this.config
+        DateResolutionAttribute dateResAttr = this.config
             .addAttribute(DateResolutionAttribute.class);
         dateRes = dateResAttr.getDateResolution();
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AllowLeadingWildcardProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AllowLeadingWildcardProcessor.java
index 1d78451..3814aa8 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AllowLeadingWildcardProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AllowLeadingWildcardProcessor.java
@@ -49,7 +49,7 @@ public class AllowLeadingWildcardProcessor extends QueryNodeProcessorImpl {
 
     if (getQueryConfigHandler().hasAttribute(AllowLeadingWildcardAttribute.class)) {
 
-      AllowLeadingWildcardAttribute alwAttr= (AllowLeadingWildcardAttribute) getQueryConfigHandler().getAttribute(AllowLeadingWildcardAttribute.class);
+      AllowLeadingWildcardAttribute alwAttr= getQueryConfigHandler().getAttribute(AllowLeadingWildcardAttribute.class);
       if (!alwAttr.isAllowLeadingWildcard()) {
         return super.process(queryTree);
       }
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AnalyzerQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AnalyzerQueryNodeProcessor.java
index 63a8ebe..14d28a7 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AnalyzerQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/AnalyzerQueryNodeProcessor.java
@@ -80,17 +80,16 @@ public class AnalyzerQueryNodeProcessor extends QueryNodeProcessorImpl {
 
     if (getQueryConfigHandler().hasAttribute(AnalyzerAttribute.class)) {
 
-      this.analyzer = ((AnalyzerAttribute) getQueryConfigHandler()
-          .getAttribute(AnalyzerAttribute.class)).getAnalyzer();
+      this.analyzer = getQueryConfigHandler().getAttribute(
+          AnalyzerAttribute.class).getAnalyzer();
 
       this.positionIncrementsEnabled = false;
 
       if (getQueryConfigHandler().hasAttribute(
           PositionIncrementsAttribute.class)) {
 
-        if (((PositionIncrementsAttribute) getQueryConfigHandler()
-            .getAttribute(PositionIncrementsAttribute.class))
-            .isPositionIncrementsEnabled()) {
+        if (getQueryConfigHandler().getAttribute(
+            PositionIncrementsAttribute.class).isPositionIncrementsEnabled()) {
 
           this.positionIncrementsEnabled = true;
 
@@ -130,8 +129,7 @@ public class AnalyzerQueryNodeProcessor extends QueryNodeProcessorImpl {
       boolean severalTokensAtSamePosition = false;
 
       if (buffer.hasAttribute(PositionIncrementAttribute.class)) {
-        posIncrAtt = (PositionIncrementAttribute) buffer
-            .getAttribute(PositionIncrementAttribute.class);
+        posIncrAtt = buffer.getAttribute(PositionIncrementAttribute.class);
       }
 
       try {
@@ -167,8 +165,7 @@ public class AnalyzerQueryNodeProcessor extends QueryNodeProcessorImpl {
         return new NoTokenFoundQueryNode();
       }
 
-      TermAttribute termAtt = (TermAttribute) buffer
-          .getAttribute(TermAttribute.class);
+      TermAttribute termAtt = buffer.getAttribute(TermAttribute.class);
 
       if (numTokens == 0) {
         return new NoTokenFoundQueryNode();
@@ -209,7 +206,8 @@ public class AnalyzerQueryNodeProcessor extends QueryNodeProcessorImpl {
 
           }
 
-          return new GroupQueryNode(new StandardBooleanQueryNode(children, true));
+          return new GroupQueryNode(
+              new StandardBooleanQueryNode(children, true));
 
         } else {
           // phrase query:
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/BoostQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/BoostQueryNodeProcessor.java
index ba2173c..57f0cc5 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/BoostQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/BoostQueryNodeProcessor.java
@@ -52,7 +52,7 @@ public class BoostQueryNodeProcessor extends QueryNodeProcessorImpl {
         FieldConfig fieldConfig = config.getFieldConfig(fieldNode.getField());
 
         if (fieldConfig != null && fieldConfig.hasAttribute(BoostAttribute.class)) {
-          BoostAttribute boostAttr = (BoostAttribute) fieldConfig.getAttribute(BoostAttribute.class);
+          BoostAttribute boostAttr = fieldConfig.getAttribute(BoostAttribute.class);
 
           return new BoostQueryNode(node, boostAttr.getBoost());
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/DefaultPhraseSlopQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/DefaultPhraseSlopQueryNodeProcessor.java
index ff99eb9..7834eaa 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/DefaultPhraseSlopQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/DefaultPhraseSlopQueryNodeProcessor.java
@@ -55,9 +55,8 @@ public class DefaultPhraseSlopQueryNodeProcessor extends QueryNodeProcessorImpl
     if (queryConfig != null) {
 
       if (queryConfig.hasAttribute(DefaultPhraseSlopAttribute.class)) {
-        this.defaultPhraseSlop = ((DefaultPhraseSlopAttribute) queryConfig
-            .getAttribute(DefaultPhraseSlopAttribute.class))
-            .getDefaultPhraseSlop();
+        this.defaultPhraseSlop = queryConfig.getAttribute(
+            DefaultPhraseSlopAttribute.class).getDefaultPhraseSlop();
 
         return super.process(queryTree);
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/FuzzyQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/FuzzyQueryNodeProcessor.java
index 8f29449..1973299 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/FuzzyQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/FuzzyQueryNodeProcessor.java
@@ -55,8 +55,7 @@ public class FuzzyQueryNodeProcessor extends QueryNodeProcessorImpl {
       QueryConfigHandler config = getQueryConfigHandler();
 
       if (config != null && config.hasAttribute(FuzzyAttribute.class)) {
-        FuzzyAttribute fuzzyAttr = (FuzzyAttribute) config
-            .getAttribute(FuzzyAttribute.class);
+        FuzzyAttribute fuzzyAttr = config.getAttribute(FuzzyAttribute.class);
         fuzzyNode.setPrefixLength(fuzzyAttr.getPrefixLength());
 
         if (fuzzyNode.getSimilarity() < 0) {
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/GroupQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/GroupQueryNodeProcessor.java
index 5b50634..41182a9 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/GroupQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/GroupQueryNodeProcessor.java
@@ -70,8 +70,8 @@ public class GroupQueryNodeProcessor implements QueryNodeProcessor {
           "DefaultOperatorAttribute should be set on the QueryConfigHandler");
     }
 
-    usingAnd = Operator.AND == ((DefaultOperatorAttribute) getQueryConfigHandler()
-        .getAttribute(DefaultOperatorAttribute.class)).getOperator();
+    this.usingAnd = Operator.AND == getQueryConfigHandler()
+        .getAttribute(DefaultOperatorAttribute.class).getOperator();
 
     if (queryTree instanceof GroupQueryNode) {
       queryTree = ((GroupQueryNode) queryTree).getChild();
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/LowercaseExpandedTermsQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/LowercaseExpandedTermsQueryNodeProcessor.java
index c81532a..ff4623c 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/LowercaseExpandedTermsQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/LowercaseExpandedTermsQueryNodeProcessor.java
@@ -52,10 +52,11 @@ public class LowercaseExpandedTermsQueryNodeProcessor extends
     if (getQueryConfigHandler().hasAttribute(
         LowercaseExpandedTermsAttribute.class)) {
 
-      if (((LowercaseExpandedTermsAttribute) getQueryConfigHandler()
-          .getAttribute(LowercaseExpandedTermsAttribute.class))
-          .isLowercaseExpandedTerms()) {
+      if (getQueryConfigHandler().getAttribute(
+          LowercaseExpandedTermsAttribute.class).isLowercaseExpandedTerms()) {
+        
         return super.process(queryTree);
+        
       }
 
     }
@@ -69,7 +70,7 @@ public class LowercaseExpandedTermsQueryNodeProcessor extends
     if (node instanceof WildcardQueryNode || node instanceof FuzzyQueryNode
         || node instanceof ParametricQueryNode) {
 
-      FieldQueryNode fieldNode = (FieldQueryNode) node;      
+      FieldQueryNode fieldNode = (FieldQueryNode) node;
       fieldNode.setText(UnescapedCharSequence.toLowerCase(fieldNode.getText()));
     }
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiFieldQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiFieldQueryNodeProcessor.java
index b8debe9..4efa98e 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiFieldQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiFieldQueryNodeProcessor.java
@@ -81,8 +81,8 @@ public class MultiFieldQueryNodeProcessor extends QueryNodeProcessorImpl {
               "MultiFieldAttribute should be set on the QueryConfigHandler");
         }
 
-        CharSequence[] fields = ((MultiFieldAttribute) getQueryConfigHandler()
-            .getAttribute(MultiFieldAttribute.class)).getFields();
+        CharSequence[] fields = getQueryConfigHandler().getAttribute(
+            MultiFieldAttribute.class).getFields();
 
         if (fields != null && fields.length > 0) {
           fieldNode.setField(fields[0]);
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiTermRewriteMethodProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiTermRewriteMethodProcessor.java
index 648ac2c..af10caf 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiTermRewriteMethodProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/MultiTermRewriteMethodProcessor.java
@@ -27,31 +27,37 @@ import org.apache.lucene.queryParser.standard.nodes.WildcardQueryNode;
 import org.apache.lucene.search.MultiTermQuery;
 
 /**
- * This processor instates the default {@link
- * org.apache.lucene.search.MultiTermQuery.RewriteMethod}, {@link
- * MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}, for
- * multi-term query nodes.
+ * This processor instates the default
+ * {@link org.apache.lucene.search.MultiTermQuery.RewriteMethod},
+ * {@link MultiTermQuery#CONSTANT_SCORE_AUTO_REWRITE_DEFAULT}, for multi-term
+ * query nodes.
  */
-public class MultiTermRewriteMethodProcessor extends QueryNodeProcessorImpl {  
+public class MultiTermRewriteMethodProcessor extends QueryNodeProcessorImpl {
 
   protected QueryNode postProcessNode(QueryNode node) {
-    
-    // set setMultiTermRewriteMethod for WildcardQueryNode and PrefixWildcardQueryNode
-    if (node instanceof WildcardQueryNode || node instanceof  ParametricRangeQueryNode) {
-      
-      if (!getQueryConfigHandler().hasAttribute(MultiTermRewriteMethodAttribute.class)) {
-        // This should not happen, this attribute is created in the StandardQueryConfigHandler
-        throw new IllegalArgumentException("MultiTermRewriteMethodAttribute should be set on the QueryConfigHandler");
+
+    // set setMultiTermRewriteMethod for WildcardQueryNode and
+    // PrefixWildcardQueryNode
+    if (node instanceof WildcardQueryNode
+        || node instanceof ParametricRangeQueryNode) {
+
+      if (!getQueryConfigHandler().hasAttribute(
+          MultiTermRewriteMethodAttribute.class)) {
+        // This should not happen, this attribute is created in the
+        // StandardQueryConfigHandler
+        throw new IllegalArgumentException(
+            "MultiTermRewriteMethodAttribute should be set on the QueryConfigHandler");
       }
 
-      //read the attribute value and use a TAG to take the value to the Builder
-      MultiTermQuery.RewriteMethod rewriteMethod = ((MultiTermRewriteMethodAttribute) getQueryConfigHandler()
-          .getAttribute(MultiTermRewriteMethodAttribute.class))
+      // read the attribute value and use a TAG to take the value to the Builder
+      MultiTermQuery.RewriteMethod rewriteMethod = getQueryConfigHandler()
+          .getAttribute(MultiTermRewriteMethodAttribute.class)
           .getMultiTermRewriteMethod();
 
       node.setTag(MultiTermRewriteMethodAttribute.TAG_ID, rewriteMethod);
+
     }
-    
+
     return node;
   }
 
diff --git a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
index 4c2277e..2f66c50 100644
--- a/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
+++ b/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
@@ -84,13 +84,17 @@ public class ParametricRangeQueryNodeProcessor extends QueryNodeProcessorImpl {
       boolean inclusive = false;
 
       if (getQueryConfigHandler().hasAttribute(RangeCollatorAttribute.class)) {
-        collator = ((RangeCollatorAttribute) getQueryConfigHandler()
-            .getAttribute(RangeCollatorAttribute.class)).getRangeCollator();
+
+        collator = getQueryConfigHandler().getAttribute(
+            RangeCollatorAttribute.class).getRangeCollator();
+
       }
 
       if (getQueryConfigHandler().hasAttribute(LocaleAttribute.class)) {
-        locale = ((LocaleAttribute) getQueryConfigHandler().getAttribute(
-            LocaleAttribute.class)).getLocale();
+
+        locale = getQueryConfigHandler().getAttribute(LocaleAttribute.class)
+            .getLocale();
+
       }
 
       FieldConfig fieldConfig = getQueryConfigHandler().getFieldConfig(
@@ -99,8 +103,10 @@ public class ParametricRangeQueryNodeProcessor extends QueryNodeProcessorImpl {
       if (fieldConfig != null) {
 
         if (fieldConfig.hasAttribute(DateResolutionAttribute.class)) {
-          dateRes = ((DateResolutionAttribute) fieldConfig
-              .getAttribute(DateResolutionAttribute.class)).getDateResolution();
+
+          dateRes = fieldConfig.getAttribute(DateResolutionAttribute.class)
+              .getDateResolution();
+
         }
 
       }
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParser.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParser.java
index 36628c2..42580c7 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParser.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParser.java
@@ -116,11 +116,14 @@ public class TestSpanQueryParser extends TestCase {
     this.spansQueryTreeBuilder = new SpansQueryTreeBuilder();
 
     // set up the processor pipeline
-    this.spanProcessorPipeline.setQueryConfigHandler(this.spanQueryConfigHandler);
+    this.spanProcessorPipeline
+        .setQueryConfigHandler(this.spanQueryConfigHandler);
 
     this.spanProcessorPipeline.addProcessor(new WildcardQueryNodeProcessor());
-    this.spanProcessorPipeline.addProcessor(new SpansValidatorQueryNodeProcessor());
-    this.spanProcessorPipeline.addProcessor(new UniqueFieldQueryNodeProcessor());
+    this.spanProcessorPipeline
+        .addProcessor(new SpansValidatorQueryNodeProcessor());
+    this.spanProcessorPipeline
+        .addProcessor(new UniqueFieldQueryNodeProcessor());
 
   }
 
@@ -130,7 +133,7 @@ public class TestSpanQueryParser extends TestCase {
 
   public SpanQuery getSpanQuery(CharSequence uniqueField, CharSequence query)
       throws QueryNodeException {
-    UniqueFieldAttribute uniqueFieldAtt = (UniqueFieldAttribute) this.spanQueryConfigHandler
+    UniqueFieldAttribute uniqueFieldAtt = this.spanQueryConfigHandler
         .getAttribute(UniqueFieldAttribute.class);
     uniqueFieldAtt.setUniqueField(uniqueField);
 
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParserSimpleSample.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParserSimpleSample.java
index e7c5f8f..1e31a62 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParserSimpleSample.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/TestSpanQueryParserSimpleSample.java
@@ -119,7 +119,7 @@ public class TestSpanQueryParserSimpleSample extends TestCase {
     // create a config handler with a attribute used in
     // UniqueFieldQueryNodeProcessor
     QueryConfigHandler spanQueryConfigHandler = new SpansQueryConfigHandler();
-    UniqueFieldAttribute uniqueFieldAtt = (UniqueFieldAttribute) spanQueryConfigHandler
+    UniqueFieldAttribute uniqueFieldAtt = spanQueryConfigHandler
         .getAttribute(UniqueFieldAttribute.class);
     uniqueFieldAtt.setUniqueField("index");
 
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/UniqueFieldQueryNodeProcessor.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/UniqueFieldQueryNodeProcessor.java
index c20b104..57b0ba9 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/UniqueFieldQueryNodeProcessor.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/spans/UniqueFieldQueryNodeProcessor.java
@@ -62,8 +62,8 @@ public class UniqueFieldQueryNodeProcessor extends QueryNodeProcessorImpl {
             "UniqueFieldAttribute should be defined in the config handler!");
       }
 
-      CharSequence uniqueField = ((UniqueFieldAttribute) queryConfig
-          .getAttribute(UniqueFieldAttribute.class)).getUniqueField();
+      CharSequence uniqueField = queryConfig.getAttribute(
+          UniqueFieldAttribute.class).getUniqueField();
 
       fieldNode.setField(uniqueField);
 
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerQPHelper.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerQPHelper.java
index 7b6c375..7ff0fa1 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerQPHelper.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerQPHelper.java
@@ -174,10 +174,10 @@ public class TestMultiAnalyzerQPHelper extends LuceneTestCase {
 
     public TestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
 
     }
 
@@ -278,8 +278,8 @@ public class TestMultiAnalyzerQPHelper extends LuceneTestCase {
 
     public TestPosIncrementFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
     }
 
     private Token token = new Token();
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java
index a118220..0fdd584 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java
@@ -168,10 +168,10 @@ public class TestMultiAnalyzerWrapper extends LuceneTestCase {
 
     public TestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
 
     }
 
@@ -272,8 +272,8 @@ public class TestMultiAnalyzerWrapper extends LuceneTestCase {
 
     public TestPosIncrementFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
     }
 
     private Token token = new Token();
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
index ac84d20..6628355 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
@@ -106,8 +106,8 @@ public class TestQPHelper extends LocalizedTestCase {
      */
     public QPTestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
     }
 
     boolean inPhrase = false;
@@ -1189,8 +1189,8 @@ public class TestQPHelper extends LocalizedTestCase {
       if (upto == 4) {
         return false;
       }
-      PositionIncrementAttribute posIncr = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      TermAttribute term = (TermAttribute) addAttribute(TermAttribute.class);
+      PositionIncrementAttribute posIncr = addAttribute(PositionIncrementAttribute.class);
+      TermAttribute term = addAttribute(TermAttribute.class);
       if (upto == 0) {
         posIncr.setPositionIncrement(1);
         term.setTermBuffer("a");
diff --git a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
index 412eb01..f4f87b7 100644
--- a/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
+++ b/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
@@ -101,8 +101,8 @@ public class TestQueryParserWrapper extends LocalizedTestCase {
      */
     public QPTestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
     }
 
     boolean inPhrase = false;
diff --git a/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballFilter.java b/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballFilter.java
index c404774..b64d52e 100644
--- a/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballFilter.java
+++ b/contrib/snowball/src/java/org/apache/lucene/analysis/snowball/SnowballFilter.java
@@ -39,7 +39,7 @@ public class SnowballFilter extends TokenFilter {
   public SnowballFilter(TokenStream input, SnowballProgram stemmer) {
     super(input);
     this.stemmer = stemmer;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /**
@@ -60,7 +60,7 @@ public class SnowballFilter extends TokenFilter {
     } catch (Exception e) {
       throw new RuntimeException(e.toString());
     }
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   /** Returns the next input Token, after being stemmed */
diff --git a/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java b/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
index 2b2e393..e9ab51f 100644
--- a/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
+++ b/contrib/snowball/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
@@ -69,12 +69,12 @@ public class TestSnowball extends BaseTokenStreamTestCase {
   
   public void testFilterTokens() throws Exception {
     SnowballFilter filter = new SnowballFilter(new TestTokenStream(), "English");
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) filter.getAttribute(OffsetAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) filter.getAttribute(TypeAttribute.class);
-    PayloadAttribute payloadAtt = (PayloadAttribute) filter.getAttribute(PayloadAttribute.class);
-    PositionIncrementAttribute posIncAtt = (PositionIncrementAttribute) filter.getAttribute(PositionIncrementAttribute.class);
-    FlagsAttribute flagsAtt = (FlagsAttribute) filter.getAttribute(FlagsAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
+    OffsetAttribute offsetAtt = filter.getAttribute(OffsetAttribute.class);
+    TypeAttribute typeAtt = filter.getAttribute(TypeAttribute.class);
+    PayloadAttribute payloadAtt = filter.getAttribute(PayloadAttribute.class);
+    PositionIncrementAttribute posIncAtt = filter.getAttribute(PositionIncrementAttribute.class);
+    FlagsAttribute flagsAtt = filter.getAttribute(FlagsAttribute.class);
     
     filter.incrementToken();
 
@@ -97,12 +97,12 @@ public class TestSnowball extends BaseTokenStreamTestCase {
     
     TestTokenStream() {
       super();
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-      posIncAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
+      posIncAtt = addAttribute(PositionIncrementAttribute.class);
+      flagsAtt = addAttribute(FlagsAttribute.class);
     }
     
     public boolean incrementToken() {
diff --git a/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java b/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
index e02aa19..91aa494 100644
--- a/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
+++ b/contrib/wikipedia/src/java/org/apache/lucene/wikipedia/analysis/WikipediaTokenizer.java
@@ -181,11 +181,11 @@ public class WikipediaTokenizer extends Tokenizer {
   private void init(int tokenOutput, Set untokenizedTypes) {
     this.tokenOutput = tokenOutput;
     this.untokenizedTypes = untokenizedTypes;
-    this.offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    this.typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-    this.posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    this.flagsAtt = (FlagsAttribute) addAttribute(FlagsAttribute.class);    
+    this.offsetAtt = addAttribute(OffsetAttribute.class);
+    this.typeAtt = addAttribute(TypeAttribute.class);
+    this.posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    this.termAtt = addAttribute(TermAttribute.class);
+    this.flagsAtt = addAttribute(FlagsAttribute.class);    
   }
 
   /** @deprecated Will be removed in Lucene 3.0. This method is final, as it should
diff --git a/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java b/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java
index 5720edd..f6bd330 100644
--- a/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java
+++ b/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest.java
@@ -128,8 +128,8 @@ public class WikipediaTokenizerTest extends BaseTokenStreamTestCase {
     int numBoldItalics = 0;
     int numCategory = 0;
     int numCitation = 0;
-    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) tf.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);
     
     while (tf.incrementToken()) {
       String tokText = termAtt.term();
@@ -164,8 +164,8 @@ public class WikipediaTokenizerTest extends BaseTokenStreamTestCase {
   }
 
   private void checkLinkPhrases(WikipediaTokenizer tf) throws IOException {
-    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) tf.addAttribute(PositionIncrementAttribute.class);
+    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);
     
     assertTrue(tf.incrementToken());
     assertTrue(termAtt.term() + " is not equal to " + "click", termAtt.term().equals("click") == true);
@@ -229,8 +229,8 @@ public class WikipediaTokenizerTest extends BaseTokenStreamTestCase {
   public void testLinks() throws Exception {
     String test = "[http://lucene.apache.org/java/docs/index.html#news here] [http://lucene.apache.org/java/docs/index.html?b=c here] [https://lucene.apache.org/java/docs/index.html?b=c here]";
     WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test));
-    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) tf.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);
     
     assertTrue(tf.incrementToken());
     assertTrue(termAtt.term() + " is not equal to " + "http://lucene.apache.org/java/docs/index.html#news",
@@ -262,9 +262,9 @@ public class WikipediaTokenizerTest extends BaseTokenStreamTestCase {
     checkLinkPhrases(tf);
     String test = "[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]";
     tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.UNTOKENIZED_ONLY, untoks);
-    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) tf.addAttribute(PositionIncrementAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) tf.addAttribute(OffsetAttribute.class);
+    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);
+    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);
     
     assertTrue(tf.incrementToken());
     assertTrue(termAtt.term() + " is not equal to " + "a b c d",
@@ -338,11 +338,11 @@ public class WikipediaTokenizerTest extends BaseTokenStreamTestCase {
     String test = "[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]";
     //should output all the indivual tokens plus the untokenized tokens as well.  Untokenized tokens
     WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.BOTH, untoks);
-    TermAttribute termAtt = (TermAttribute) tf.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) tf.addAttribute(TypeAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) tf.addAttribute(PositionIncrementAttribute.class);
-    OffsetAttribute offsetAtt = (OffsetAttribute) tf.addAttribute(OffsetAttribute.class);
-    FlagsAttribute flagsAtt = (FlagsAttribute) tf.addAttribute(FlagsAttribute.class);
+    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = tf.addAttribute(TypeAttribute.class);
+    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);
+    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);
+    FlagsAttribute flagsAtt = tf.addAttribute(FlagsAttribute.class);
     
     assertTrue(tf.incrementToken());
     assertTrue(termAtt.term() + " is not equal to " + "a b c d",
diff --git a/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java b/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java
index e393254..5c9c118 100755
--- a/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java
+++ b/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynExpand.java
@@ -114,7 +114,7 @@ public final class SynExpand {
 
 		// [1] Parse query into separate words so that when we expand we can avoid dups
 		TokenStream ts = a.tokenStream( field, new StringReader( query));
-		TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+		TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 		
 		while (ts.incrementToken()) {
 		  String word = termAtt.term();
diff --git a/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java b/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java
index 0872122..92d2d72 100644
--- a/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java
+++ b/contrib/wordnet/src/java/org/apache/lucene/wordnet/SynLookup.java
@@ -101,7 +101,7 @@ public class SynLookup {
 
 		// [1] Parse query into separate words so that when we expand we can avoid dups
 		TokenStream ts = a.tokenStream( field, new StringReader( query));
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
     
 		while (ts.incrementToken()) {
 			String word = termAtt.term();
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
index d04c221..e5a4212 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/LikeThisQueryBuilder.java
@@ -77,7 +77,7 @@ public class LikeThisQueryBuilder implements QueryBuilder {
 		    for (int i = 0; i < fields.length; i++)
             {
                 TokenStream ts = analyzer.tokenStream(fields[i],new StringReader(stopWords));
-                TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+                TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
                 try
                 {
 	                while(ts.incrementToken()) {
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
index 2a0bad7..8d601f6 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/SpanOrTermsBuilder.java
@@ -56,7 +56,7 @@ public class SpanOrTermsBuilder extends SpanBuilderBase
 		{
 			ArrayList clausesList=new ArrayList();
 			TokenStream ts=analyzer.tokenStream(fieldName,new StringReader(value));
-			TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+			TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 			
 	    while (ts.incrementToken()) {
 			    SpanTermQuery stq=new SpanTermQuery(new Term(fieldName, termAtt.term()));
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
index 1761d10..7373a95 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsFilterBuilder.java
@@ -57,7 +57,7 @@ public class TermsFilterBuilder implements FilterBuilder
 		String text = DOMUtils.getNonBlankTextOrFail(e);
 		String fieldName = DOMUtils.getAttributeWithInheritanceOrFail(e, "fieldName");
 		TokenStream ts = analyzer.tokenStream(fieldName, new StringReader(text));
-    TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
     
 		try
 		{
diff --git a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsQueryBuilder.java b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsQueryBuilder.java
index 7a6d1e5..83e6bb3 100644
--- a/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsQueryBuilder.java
+++ b/contrib/xml-query-parser/src/java/org/apache/lucene/xmlparser/builders/TermsQueryBuilder.java
@@ -57,7 +57,7 @@ public class TermsQueryBuilder implements QueryBuilder {
 		TokenStream ts = analyzer.tokenStream(fieldName, new StringReader(text));
 		try
 		{
-		  TermAttribute termAtt = (TermAttribute) ts.addAttribute(TermAttribute.class);
+		  TermAttribute termAtt = ts.addAttribute(TermAttribute.class);
 			Term term = null;
 			while (ts.incrementToken()) {
 				if (term == null)
diff --git a/src/java/org/apache/lucene/analysis/ASCIIFoldingFilter.java b/src/java/org/apache/lucene/analysis/ASCIIFoldingFilter.java
index 65e1d65..7d320a0 100644
--- a/src/java/org/apache/lucene/analysis/ASCIIFoldingFilter.java
+++ b/src/java/org/apache/lucene/analysis/ASCIIFoldingFilter.java
@@ -60,7 +60,7 @@ public final class ASCIIFoldingFilter extends TokenFilter {
   public ASCIIFoldingFilter(TokenStream input)
   {
     super(input);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   private char[] output = new char[512];
diff --git a/src/java/org/apache/lucene/analysis/CharTokenizer.java b/src/java/org/apache/lucene/analysis/CharTokenizer.java
index 1689585..bf21f21 100644
--- a/src/java/org/apache/lucene/analysis/CharTokenizer.java
+++ b/src/java/org/apache/lucene/analysis/CharTokenizer.java
@@ -28,20 +28,20 @@ import org.apache.lucene.util.AttributeSource;
 public abstract class CharTokenizer extends Tokenizer {
   public CharTokenizer(Reader input) {
     super(input);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public CharTokenizer(AttributeSource source, Reader input) {
     super(source, input);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public CharTokenizer(AttributeFactory factory, Reader input) {
     super(factory, input);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
   
   private int offset = 0, bufferIndex = 0, dataLen = 0;
diff --git a/src/java/org/apache/lucene/analysis/ISOLatin1AccentFilter.java b/src/java/org/apache/lucene/analysis/ISOLatin1AccentFilter.java
index 119f54f..c1de389 100644
--- a/src/java/org/apache/lucene/analysis/ISOLatin1AccentFilter.java
+++ b/src/java/org/apache/lucene/analysis/ISOLatin1AccentFilter.java
@@ -32,7 +32,7 @@ import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 public class ISOLatin1AccentFilter extends TokenFilter {
   public ISOLatin1AccentFilter(TokenStream input) {
     super(input);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   private char[] output = new char[256];
diff --git a/src/java/org/apache/lucene/analysis/KeywordTokenizer.java b/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
index 2363bb8..33d063a 100644
--- a/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
+++ b/src/java/org/apache/lucene/analysis/KeywordTokenizer.java
@@ -57,8 +57,8 @@ public class KeywordTokenizer extends Tokenizer {
   
   private void init(int bufferSize) {
     this.done = false;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
     termAtt.resizeTermBuffer(bufferSize);    
   }
   
diff --git a/src/java/org/apache/lucene/analysis/LengthFilter.java b/src/java/org/apache/lucene/analysis/LengthFilter.java
index 68387a1..f111650 100644
--- a/src/java/org/apache/lucene/analysis/LengthFilter.java
+++ b/src/java/org/apache/lucene/analysis/LengthFilter.java
@@ -43,7 +43,7 @@ public final class LengthFilter extends TokenFilter {
     super(in);
     this.min = min;
     this.max = max;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
   
   /**
@@ -58,7 +58,7 @@ public final class LengthFilter extends TokenFilter {
       }
       // note: else we ignore it but should we index each part of it?
     }
-    // reached EOS -- return null
+    // reached EOS -- return false
     return false;
   }
 }
diff --git a/src/java/org/apache/lucene/analysis/LowerCaseFilter.java b/src/java/org/apache/lucene/analysis/LowerCaseFilter.java
index 9774726..91f89d7 100644
--- a/src/java/org/apache/lucene/analysis/LowerCaseFilter.java
+++ b/src/java/org/apache/lucene/analysis/LowerCaseFilter.java
@@ -29,7 +29,7 @@ import org.apache.lucene.analysis.tokenattributes.TermAttribute;
 public final class LowerCaseFilter extends TokenFilter {
   public LowerCaseFilter(TokenStream in) {
     super(in);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   private TermAttribute termAtt;
diff --git a/src/java/org/apache/lucene/analysis/NumericTokenStream.java b/src/java/org/apache/lucene/analysis/NumericTokenStream.java
index 1de39ed..4fb15a9 100644
--- a/src/java/org/apache/lucene/analysis/NumericTokenStream.java
+++ b/src/java/org/apache/lucene/analysis/NumericTokenStream.java
@@ -241,9 +241,9 @@ public final class NumericTokenStream extends TokenStream {
   }
 
   // members
-  private final TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-  private final TypeAttribute typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
-  private final PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+  private final TermAttribute termAtt = addAttribute(TermAttribute.class);
+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
+  private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
   
   private int shift = 0, valSize = 0; // valSize==0 means not initialized
   private final int precisionStep;
diff --git a/src/java/org/apache/lucene/analysis/PorterStemFilter.java b/src/java/org/apache/lucene/analysis/PorterStemFilter.java
index 59f638f..c70e779 100644
--- a/src/java/org/apache/lucene/analysis/PorterStemFilter.java
+++ b/src/java/org/apache/lucene/analysis/PorterStemFilter.java
@@ -46,7 +46,7 @@ public final class PorterStemFilter extends TokenFilter {
   public PorterStemFilter(TokenStream in) {
     super(in);
     stemmer = new PorterStemmer();
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
 
   public final boolean incrementToken() throws IOException {
diff --git a/src/java/org/apache/lucene/analysis/StopFilter.java b/src/java/org/apache/lucene/analysis/StopFilter.java
index 5e98f2a..2377175 100644
--- a/src/java/org/apache/lucene/analysis/StopFilter.java
+++ b/src/java/org/apache/lucene/analysis/StopFilter.java
@@ -163,8 +163,8 @@ public final class StopFilter extends TokenFilter {
   }
   
   public void init() {
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
   }
 
   /**
diff --git a/src/java/org/apache/lucene/analysis/TokenStream.java b/src/java/org/apache/lucene/analysis/TokenStream.java
index a9860ce..ea40869 100644
--- a/src/java/org/apache/lucene/analysis/TokenStream.java
+++ b/src/java/org/apache/lucene/analysis/TokenStream.java
@@ -103,13 +103,13 @@ public abstract class TokenStream extends AttributeSource {
   private static final class MethodSupport {
     final boolean hasIncrementToken, hasReusableNext, hasNext;
 
-    MethodSupport(Class clazz) {
-      hasIncrementToken = isMethodOverridden(clazz, "incrementToken", METHOD_NO_PARAMS);
-      hasReusableNext = isMethodOverridden(clazz, "next", METHOD_TOKEN_PARAM);
-      hasNext = isMethodOverridden(clazz, "next", METHOD_NO_PARAMS);
+    MethodSupport(Class<? extends TokenStream> clazz) {
+      hasIncrementToken = isMethodOverridden(clazz, "incrementToken");
+      hasReusableNext = isMethodOverridden(clazz, "next", Token.class);
+      hasNext = isMethodOverridden(clazz, "next");
     }
     
-    private static boolean isMethodOverridden(Class clazz, String name, Class[] params) {
+    private static boolean isMethodOverridden(Class<? extends TokenStream> clazz, String name, Class... params) {
       try {
         return clazz.getMethod(name, params).getDeclaringClass() != TokenStream.class;
       } catch (NoSuchMethodException e) {
@@ -117,19 +117,17 @@ public abstract class TokenStream extends AttributeSource {
         throw new RuntimeException(e);
       }
     }
-    
-    private static final Class[] METHOD_NO_PARAMS = new Class[0];
-    private static final Class[] METHOD_TOKEN_PARAM = new Class[]{Token.class};
   }
       
   /** @deprecated Remove this when old API is removed! */
-  private static final IdentityHashMap/*<Class<? extends TokenStream>,MethodSupport>*/ knownMethodSupport = new IdentityHashMap();
+  private static final IdentityHashMap<Class<? extends TokenStream>,MethodSupport> knownMethodSupport =
+    new IdentityHashMap<Class<? extends TokenStream>,MethodSupport>();
   
   /** @deprecated Remove this when old API is removed! */
-  private static MethodSupport getSupportedMethods(Class clazz) {
+  private static MethodSupport getSupportedMethods(Class<? extends TokenStream> clazz) {
     MethodSupport supportedMethods;
     synchronized(knownMethodSupport) {
-      supportedMethods = (MethodSupport) knownMethodSupport.get(clazz);
+      supportedMethods = knownMethodSupport.get(clazz);
       if (supportedMethods == null) {
         knownMethodSupport.put(clazz, supportedMethods = new MethodSupport(clazz));
       }
@@ -145,7 +143,7 @@ public abstract class TokenStream extends AttributeSource {
       this.delegate = delegate;
     }
   
-    public AttributeImpl createAttributeInstance(Class attClass) {
+    public AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass) {
       return attClass.isAssignableFrom(TokenWrapper.class)
         ? new TokenWrapper()
         : delegate.createAttributeInstance(attClass);
diff --git a/src/java/org/apache/lucene/analysis/package.html b/src/java/org/apache/lucene/analysis/package.html
index 41c4a9c..490101d 100644
--- a/src/java/org/apache/lucene/analysis/package.html
+++ b/src/java/org/apache/lucene/analysis/package.html
@@ -230,8 +230,8 @@ the source code of any one of the many samples located in this package.
       public TokenStream tokenStream(final String fieldName, Reader reader) {
         final TokenStream ts = someAnalyzer.tokenStream(fieldName, reader);
         TokenStream res = new TokenStream() {
-          TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+          TermAttribute termAtt = addAttribute(TermAttribute.class);
+          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
         
           public boolean incrementToken() throws IOException {
             int extraIncrement = 0;
@@ -319,7 +319,7 @@ the Attribute instances.
 <li>
 For performance reasons a TokenStream/-Filter should add/get Attributes during instantiation; i.e., create an attribute in the
 constructor and store references to it in an instance variable.  Using an instance variable instead of calling addAttribute()/getAttribute() 
-in incrementToken() will avoid expensive casting and attribute lookups for every token in the document.
+in incrementToken() will avoid attribute lookups for every token in the document.
 </li>
 <br>
 <li>
@@ -356,7 +356,7 @@ public class MyAnalyzer extends Analyzer {
     TokenStream stream = analyzer.tokenStream("field", new StringReader(text));
     
     // get the TermAttribute from the TokenStream
-    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
 
     stream.reset();
     
@@ -421,7 +421,7 @@ public final class LengthFilter extends TokenFilter {
     super(in);
     this.min = min;
     this.max = max;
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
   }
   
   /**
@@ -448,7 +448,7 @@ Remember that there can only be a single instance of TermAttribute in the chain,
 <code>addAttribute()</code> call in LengthFilter returns the TermAttribute that the WhitespaceTokenizer already added. The tokens
 are retrieved from the input stream in the <code>incrementToken()</code> method. By looking at the term text
 in the TermAttribute the length of the term can be determined and too short or too long tokens are skipped. 
-Note how <code>incrementToken()</code> can efficiently access the instance variable; no attribute lookup or downcasting
+Note how <code>incrementToken()</code> can efficiently access the instance variable; no attribute lookup
 is neccessary. The same is true for the consumer, which can simply use local references to the Attributes.
 
 <h4>Adding a custom Attribute</h4>
@@ -526,8 +526,8 @@ that tags every word with a leading upper-case letter as a 'Noun' and all other
     
     protected PartOfSpeechTaggingFilter(TokenStream input) {
       super(input);
-      posAtt = (PartOfSpeechAttribute) addAttribute(PartOfSpeechAttribute.class);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+      posAtt = addAttribute(PartOfSpeechAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
     }
     
     public boolean incrementToken() throws IOException {
@@ -579,10 +579,10 @@ to make use of the new PartOfSpeechAttribute and print it out:
     TokenStream stream = analyzer.tokenStream("field", new StringReader(text));
     
     // get the TermAttribute from the TokenStream
-    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
     
     // get the PartOfSpeechAttribute from the TokenStream
-    PartOfSpeechAttribute posAtt = (PartOfSpeechAttribute) stream.addAttribute(PartOfSpeechAttribute.class);
+    PartOfSpeechAttribute posAtt = stream.addAttribute(PartOfSpeechAttribute.class);
     
     stream.reset();
 
diff --git a/src/java/org/apache/lucene/analysis/standard/StandardFilter.java b/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
index 5c5b596..2a8879f 100644
--- a/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
+++ b/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
@@ -31,8 +31,8 @@ public final class StandardFilter extends TokenFilter {
   /** Construct filtering <i>in</i>. */
   public StandardFilter(TokenStream in) {
     super(in);
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
   }
 
   private static final String APOSTROPHE_TYPE = StandardTokenizerImpl.TOKEN_TYPES[StandardTokenizerImpl.APOSTROPHE];
diff --git a/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index c0e3bdc..a9998e4 100644
--- a/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -148,10 +148,10 @@ public class StandardTokenizer extends Tokenizer {
   private void init(Reader input, boolean replaceInvalidAcronym) {
     this.replaceInvalidAcronym = replaceInvalidAcronym;
     this.input = input;    
-    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-    offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-    posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-    typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+    termAtt = addAttribute(TermAttribute.class);
+    offsetAtt = addAttribute(OffsetAttribute.class);
+    posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    typeAtt = addAttribute(TypeAttribute.class);
   }
   
   // this tokenizer generates three attributes:
diff --git a/src/java/org/apache/lucene/index/DocInverterPerField.java b/src/java/org/apache/lucene/index/DocInverterPerField.java
index d3407b0..09fa054 100644
--- a/src/java/org/apache/lucene/index/DocInverterPerField.java
+++ b/src/java/org/apache/lucene/index/DocInverterPerField.java
@@ -139,8 +139,8 @@ final class DocInverterPerField extends DocFieldConsumerPerField {
 
             fieldState.attributeSource = stream;
 
-            OffsetAttribute offsetAttribute = (OffsetAttribute) fieldState.attributeSource.addAttribute(OffsetAttribute.class);
-            PositionIncrementAttribute posIncrAttribute = (PositionIncrementAttribute) fieldState.attributeSource.addAttribute(PositionIncrementAttribute.class);
+            OffsetAttribute offsetAttribute = fieldState.attributeSource.addAttribute(OffsetAttribute.class);
+            PositionIncrementAttribute posIncrAttribute = fieldState.attributeSource.addAttribute(PositionIncrementAttribute.class);
             
             consumer.start(field);
             
diff --git a/src/java/org/apache/lucene/index/DocInverterPerThread.java b/src/java/org/apache/lucene/index/DocInverterPerThread.java
index 0a85be5..e0c94ff 100644
--- a/src/java/org/apache/lucene/index/DocInverterPerThread.java
+++ b/src/java/org/apache/lucene/index/DocInverterPerThread.java
@@ -39,8 +39,8 @@ final class DocInverterPerThread extends DocFieldConsumerPerThread {
     OffsetAttribute offsetAttribute;
     
     SingleTokenTokenStream() {
-      termAttribute = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAttribute = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAttribute = addAttribute(TermAttribute.class);
+      offsetAttribute = addAttribute(OffsetAttribute.class);
     }
     
     public void reinit(String stringValue, int startOffset,  int endOffset) {
diff --git a/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java b/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
index 15c2827..3863fdc 100644
--- a/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
+++ b/src/java/org/apache/lucene/index/FreqProxTermsWriterPerField.java
@@ -77,7 +77,7 @@ final class FreqProxTermsWriterPerField extends TermsHashConsumerPerField implem
   
   void start(Fieldable f) {
     if (fieldState.attributeSource.hasAttribute(PayloadAttribute.class)) {
-      payloadAttribute = (PayloadAttribute) fieldState.attributeSource.getAttribute(PayloadAttribute.class);
+      payloadAttribute = fieldState.attributeSource.getAttribute(PayloadAttribute.class);
     } else {
       payloadAttribute = null;
     }
diff --git a/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java b/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
index 50d694c..3f14ca6 100644
--- a/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
+++ b/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField.java
@@ -196,7 +196,7 @@ final class TermVectorsTermsWriterPerField extends TermsHashConsumerPerField {
   
   void start(Fieldable f) {
     if (doVectorOffsets) {
-      offsetAttribute = (OffsetAttribute) fieldState.attributeSource.addAttribute(OffsetAttribute.class);
+      offsetAttribute = fieldState.attributeSource.addAttribute(OffsetAttribute.class);
     } else {
       offsetAttribute = null;
     }
diff --git a/src/java/org/apache/lucene/index/TermsHashPerField.java b/src/java/org/apache/lucene/index/TermsHashPerField.java
index 1c49d4f..4534938 100644
--- a/src/java/org/apache/lucene/index/TermsHashPerField.java
+++ b/src/java/org/apache/lucene/index/TermsHashPerField.java
@@ -249,7 +249,7 @@ final class TermsHashPerField extends InvertedDocConsumerPerField {
   private boolean doNextCall;
 
   void start(Fieldable f) {
-    termAtt = (TermAttribute) fieldState.attributeSource.addAttribute(TermAttribute.class);
+    termAtt = fieldState.attributeSource.addAttribute(TermAttribute.class);
     consumer.start(f);
     if (nextPerField != null) {
       nextPerField.start(f);
diff --git a/src/java/org/apache/lucene/queryParser/QueryParser.java b/src/java/org/apache/lucene/queryParser/QueryParser.java
index 369e59c..e26e033 100644
--- a/src/java/org/apache/lucene/queryParser/QueryParser.java
+++ b/src/java/org/apache/lucene/queryParser/QueryParser.java
@@ -559,10 +559,10 @@ public class QueryParser implements QueryParserConstants {
     }
     if (success) {
       if (buffer.hasAttribute(TermAttribute.class)) {
-        termAtt = (TermAttribute) buffer.getAttribute(TermAttribute.class);
+        termAtt = buffer.getAttribute(TermAttribute.class);
       }
       if (buffer.hasAttribute(PositionIncrementAttribute.class)) {
-        posIncrAtt = (PositionIncrementAttribute) buffer.getAttribute(PositionIncrementAttribute.class);
+        posIncrAtt = buffer.getAttribute(PositionIncrementAttribute.class);
       }
     }
 
@@ -759,7 +759,7 @@ public class QueryParser implements QueryParserConstants {
       DateTools.Resolution resolution = getDateResolution(field);
       if (resolution == null) {
         // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibilty with
+        // use deprecated DateField to maintain compatibility with
         // pre-1.9 Lucene versions.
         part1 = DateField.dateToString(d1);
         part2 = DateField.dateToString(d2);
@@ -1591,16 +1591,6 @@ public class QueryParser implements QueryParserConstants {
     finally { jj_save(0, xla); }
   }
 
-  private boolean jj_3_1() {
-    Token xsp;
-    xsp = jj_scanpos;
-    if (jj_3R_2()) {
-    jj_scanpos = xsp;
-    if (jj_3R_3()) return true;
-    }
-    return false;
-  }
-
   private boolean jj_3R_3() {
     if (jj_scan_token(STAR)) return true;
     if (jj_scan_token(COLON)) return true;
@@ -1613,6 +1603,16 @@ public class QueryParser implements QueryParserConstants {
     return false;
   }
 
+  private boolean jj_3_1() {
+    Token xsp;
+    xsp = jj_scanpos;
+    if (jj_3R_2()) {
+    jj_scanpos = xsp;
+    if (jj_3R_3()) return true;
+    }
+    return false;
+  }
+
   /** Generated Token Manager. */
   public QueryParserTokenManager token_source;
   /** Current token. */
diff --git a/src/java/org/apache/lucene/queryParser/QueryParser.jj b/src/java/org/apache/lucene/queryParser/QueryParser.jj
index 099752f..c74f06e 100644
--- a/src/java/org/apache/lucene/queryParser/QueryParser.jj
+++ b/src/java/org/apache/lucene/queryParser/QueryParser.jj
@@ -583,10 +583,10 @@ public class QueryParser {
     }
     if (success) {
       if (buffer.hasAttribute(TermAttribute.class)) {
-        termAtt = (TermAttribute) buffer.getAttribute(TermAttribute.class);
+        termAtt = buffer.getAttribute(TermAttribute.class);
       }
       if (buffer.hasAttribute(PositionIncrementAttribute.class)) {
-        posIncrAtt = (PositionIncrementAttribute) buffer.getAttribute(PositionIncrementAttribute.class);
+        posIncrAtt = buffer.getAttribute(PositionIncrementAttribute.class);
       }
     }
 
diff --git a/src/java/org/apache/lucene/search/QueryTermVector.java b/src/java/org/apache/lucene/search/QueryTermVector.java
index ef92f94..2258d87 100644
--- a/src/java/org/apache/lucene/search/QueryTermVector.java
+++ b/src/java/org/apache/lucene/search/QueryTermVector.java
@@ -61,7 +61,7 @@ public class QueryTermVector implements TermFreqVector {
           boolean hasMoreTokens = false;
           
           stream.reset(); 
-          TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
+          TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
 
           hasMoreTokens = stream.incrementToken();
           while (hasMoreTokens) {
diff --git a/src/java/org/apache/lucene/util/AttributeImpl.java b/src/java/org/apache/lucene/util/AttributeImpl.java
index d8f456f..1790bfd 100644
--- a/src/java/org/apache/lucene/util/AttributeImpl.java
+++ b/src/java/org/apache/lucene/util/AttributeImpl.java
@@ -49,7 +49,7 @@ public abstract class AttributeImpl implements Cloneable, Serializable, Attribut
    * This method may be overridden by subclasses.
    */
   public String toString() {
-    StringBuffer buffer = new StringBuffer();
+    StringBuilder buffer = new StringBuilder();
     Class clazz = this.getClass();
     Field[] fields = clazz.getDeclaredFields();
     try {
diff --git a/src/java/org/apache/lucene/util/AttributeSource.java b/src/java/org/apache/lucene/util/AttributeSource.java
index a92716c..2dd0017 100644
--- a/src/java/org/apache/lucene/util/AttributeSource.java
+++ b/src/java/org/apache/lucene/util/AttributeSource.java
@@ -44,9 +44,8 @@ public class AttributeSource {
   public static abstract class AttributeFactory {
     /**
      * returns an {@link AttributeImpl} for the supplied {@link Attribute} interface class.
-     * <p>Signature for Java 1.5: <code>public AttributeImpl createAttributeInstance(Class%lt;? extends Attribute&gt; attClass)</code>
      */
-    public abstract AttributeImpl createAttributeInstance(Class attClass);
+    public abstract AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass);
     
     /**
      * This is the default factory that creates {@link AttributeImpl}s using the
@@ -55,13 +54,14 @@ public class AttributeSource {
     public static final AttributeFactory DEFAULT_ATTRIBUTE_FACTORY = new DefaultAttributeFactory();
     
     private static final class DefaultAttributeFactory extends AttributeFactory {
-      private static final IdentityHashMap/*<Class<? extends Attribute>,Class<? extends AttributeImpl>>*/ attClassImplMap = new IdentityHashMap();
+      private static final IdentityHashMap<Class<? extends Attribute>, Class<? extends AttributeImpl>> attClassImplMap =
+        new IdentityHashMap<Class<? extends Attribute>, Class<? extends AttributeImpl>>();
       
       private DefaultAttributeFactory() {}
     
-      public AttributeImpl createAttributeInstance(Class attClass) {
+      public AttributeImpl createAttributeInstance(Class<? extends Attribute> attClass) {
         try {
-          return (AttributeImpl) getClassForInterface(attClass).newInstance();
+          return getClassForInterface(attClass).newInstance();
         } catch (InstantiationException e) {
           throw new IllegalArgumentException("Could not instantiate class " + attClass.getName());
         } catch (IllegalAccessException e) {
@@ -69,12 +69,12 @@ public class AttributeSource {
         }
       }
       
-      private static Class getClassForInterface(Class attClass) {
+      private static Class<? extends AttributeImpl> getClassForInterface(Class<? extends Attribute> attClass) {
         synchronized(attClassImplMap) {
-          Class clazz = (Class) attClassImplMap.get(attClass);
+          Class<? extends AttributeImpl> clazz = attClassImplMap.get(attClass);
           if (clazz == null) {
             try {
-              attClassImplMap.put(attClass, clazz = Class.forName(attClass.getName() + "Impl"));
+              attClassImplMap.put(attClass, clazz = Class.forName(attClass.getName() + "Impl").asSubclass(AttributeImpl.class));
             } catch (ClassNotFoundException e) {
               throw new IllegalArgumentException("Could not find implementing class for " + attClass.getName());
             }
@@ -87,8 +87,8 @@ public class AttributeSource {
       
   // These two maps must always be in sync!!!
   // So they are private, final and read-only from the outside (read-only iterators)
-  private final Map/*<Class<Attribute>,AttributeImpl>*/ attributes;
-  private final Map/*<Class<AttributeImpl>,AttributeImpl>*/ attributeImpls;
+  private final Map<Class<? extends Attribute>, AttributeImpl> attributes;
+  private final Map<Class<? extends AttributeImpl>, AttributeImpl> attributeImpls;
 
   private AttributeFactory factory;
   
@@ -115,8 +115,8 @@ public class AttributeSource {
    * An AttributeSource using the supplied {@link AttributeFactory} for creating new {@link Attribute} instances.
    */
   public AttributeSource(AttributeFactory factory) {
-    this.attributes = new LinkedHashMap();
-    this.attributeImpls = new LinkedHashMap();
+    this.attributes = new LinkedHashMap<Class<? extends Attribute>, AttributeImpl>();
+    this.attributeImpls = new LinkedHashMap<Class<? extends AttributeImpl>, AttributeImpl>();
     this.factory = factory;
   }
   
@@ -129,31 +129,29 @@ public class AttributeSource {
   
   /** Returns a new iterator that iterates the attribute classes
    * in the same order they were added in.
-   * <p>Signature for Java 1.5: <code>public Iterator&lt;Class&lt;? extends Attribute&gt;&gt; getAttributeClassesIterator()</code>
    */
-  public Iterator getAttributeClassesIterator() {
+  public Iterator<Class<? extends Attribute>> getAttributeClassesIterator() {
     return Collections.unmodifiableSet(attributes.keySet()).iterator();
   }
   
   /** Returns a new iterator that iterates all unique Attribute implementations.
    * This iterator may contain less entries that {@link #getAttributeClassesIterator},
    * if one instance implements more than one Attribute interface.
-   * <p>Signature for Java 1.5: <code>public Iterator&lt;AttributeImpl&gt; getAttributeImplsIterator()</code>
    */
-  public Iterator getAttributeImplsIterator() {
+  public Iterator<AttributeImpl> getAttributeImplsIterator() {
     if (hasAttributes()) {
       if (currentState == null) {
         computeCurrentState();
       }
       final State initState = currentState;
-      return new Iterator() {
+      return new Iterator<AttributeImpl>() {
         private State state = initState;
       
         public void remove() {
           throw new UnsupportedOperationException();
         }
         
-        public Object next() {
+        public AttributeImpl next() {
           if (state == null)
             throw new NoSuchElementException();
           final AttributeImpl att = state.attribute;
@@ -166,31 +164,30 @@ public class AttributeSource {
         }
       };
     } else {
-      return Collections.EMPTY_SET.iterator();
+      return Collections.<AttributeImpl>emptySet().iterator();
     }
   }
   
   /** a cache that stores all interfaces for known implementation classes for performance (slow reflection) */
-  private static final IdentityHashMap/*<Class<? extends AttributeImpl>,LinkedList<Class<? extends Attribute>>>*/ knownImplClasses = new IdentityHashMap();
+  private static final IdentityHashMap<Class<? extends AttributeImpl>,LinkedList<Class<? extends Attribute>>> knownImplClasses =
+    new IdentityHashMap<Class<? extends AttributeImpl>,LinkedList<Class<? extends Attribute>>>();
   
   /** Adds a custom AttributeImpl instance with one or more Attribute interfaces. */
   public void addAttributeImpl(final AttributeImpl att) {
-    final Class clazz = att.getClass();
+    final Class<? extends AttributeImpl> clazz = att.getClass();
     if (attributeImpls.containsKey(clazz)) return;
-    LinkedList foundInterfaces;
+    LinkedList<Class<? extends Attribute>> foundInterfaces;
     synchronized(knownImplClasses) {
-      foundInterfaces = (LinkedList) knownImplClasses.get(clazz);
+      foundInterfaces = knownImplClasses.get(clazz);
       if (foundInterfaces == null) {
-        knownImplClasses.put(clazz, foundInterfaces=new LinkedList());
+        knownImplClasses.put(clazz, foundInterfaces = new LinkedList<Class<? extends Attribute>>());
         // find all interfaces that this attribute instance implements
         // and that extend the Attribute interface
-        Class actClazz = clazz;
+        Class<?> actClazz = clazz;
         do {
-          Class[] interfaces = actClazz.getInterfaces();
-          for (int i = 0; i < interfaces.length; i++) {
-            final Class curInterface = interfaces[i];
+          for (Class<?> curInterface : actClazz.getInterfaces()) {
             if (curInterface != Attribute.class && Attribute.class.isAssignableFrom(curInterface)) {
-              foundInterfaces.add(curInterface);
+              foundInterfaces.add(curInterface.asSubclass(Attribute.class));
             }
           }
           actClazz = actClazz.getSuperclass();
@@ -199,8 +196,7 @@ public class AttributeSource {
     }
     
     // add all interfaces of this AttributeImpl to the maps
-    for (Iterator it = foundInterfaces.iterator(); it.hasNext(); ) {
-      final Class curInterface = (Class) it.next();
+    for (Class<? extends Attribute> curInterface : foundInterfaces) {
       // Attribute is a superclass of this interface
       if (!attributes.containsKey(curInterface)) {
         // invalidate state to force recomputation in captureState()
@@ -216,17 +212,13 @@ public class AttributeSource {
    * This method first checks if an instance of that class is 
    * already in this AttributeSource and returns it. Otherwise a
    * new instance is created, added to this AttributeSource and returned. 
-   * <p>Signature for Java 1.5: <code>public &lt;T extends Attribute&gt; T addAttribute(Class&lt;T&gt;)</code>
    */
-  public Attribute addAttribute(Class attClass) {
-    final Attribute att = (Attribute) attributes.get(attClass);
-    if (att == null) {
-      final AttributeImpl attImpl = this.factory.createAttributeInstance(attClass);
-      addAttributeImpl(attImpl);
-      return attImpl;
-    } else {
-      return att;
+  public <A extends Attribute> A addAttribute(Class<A> attClass) {
+    AttributeImpl attImpl = attributes.get(attClass);
+    if (attImpl == null) {
+      addAttributeImpl(attImpl = this.factory.createAttributeInstance(attClass));
     }
+    return attClass.cast(attImpl);
   }
   
   /** Returns true, iff this AttributeSource has any attributes */
@@ -237,16 +229,14 @@ public class AttributeSource {
   /**
    * The caller must pass in a Class&lt;? extends Attribute&gt; value. 
    * Returns true, iff this AttributeSource contains the passed-in Attribute.
-   * <p>Signature for Java 1.5: <code>public boolean hasAttribute(Class&lt;? extends Attribute&gt;)</code>
    */
-  public boolean hasAttribute(Class attClass) {
+  public boolean hasAttribute(Class<? extends Attribute> attClass) {
     return this.attributes.containsKey(attClass);
   }
 
   /**
    * The caller must pass in a Class&lt;? extends Attribute&gt; value. 
    * Returns the instance of the passed in Attribute contained in this AttributeSource
-   * <p>Signature for Java 1.5: <code>public &lt;T extends Attribute&gt; T getAttribute(Class&lt;T&gt;)</code>
    * 
    * @throws IllegalArgumentException if this AttributeSource does not contain the
    *         Attribute. It is recommended to always use {@link #addAttribute} even in consumers
@@ -255,13 +245,12 @@ public class AttributeSource {
    *         available. If you want to only use the attribute, if it is available (to optimize
    *         consuming), use {@link #hasAttribute}.
    */
-  public Attribute getAttribute(Class attClass) {
-    final Attribute att = (Attribute) this.attributes.get(attClass);
-    if (att == null) {
+  public <A extends Attribute> A getAttribute(Class<A> attClass) {
+    AttributeImpl attImpl = attributes.get(attClass);
+    if (attImpl == null) {
       throw new IllegalArgumentException("This AttributeSource does not have the attribute '" + attClass.getName() + "'.");
     }
-
-    return att;
+    return attClass.cast(attImpl);
   }
   
   /**
@@ -290,12 +279,12 @@ public class AttributeSource {
   private void computeCurrentState() {
     currentState = new State();
     State c = currentState;
-    Iterator it = attributeImpls.values().iterator();
-    c.attribute = (AttributeImpl) it.next();
+    final Iterator<AttributeImpl> it = attributeImpls.values().iterator();
+    c.attribute = it.next();
     while (it.hasNext()) {
       c.next = new State();
       c = c.next;
-      c.attribute = (AttributeImpl) it.next();
+      c.attribute = it.next();
     }        
   }
   
@@ -348,7 +337,7 @@ public class AttributeSource {
     if (state == null)  return;
     
     do {
-      AttributeImpl targetImpl = (AttributeImpl) attributeImpls.get(state.attribute.getClass());
+      AttributeImpl targetImpl = attributeImpls.get(state.attribute.getClass());
       if (targetImpl == null)
         throw new IllegalArgumentException("State contains an AttributeImpl that is not in this AttributeSource");
       state.attribute.copyTo(targetImpl);
@@ -412,9 +401,7 @@ public class AttributeSource {
   }
   
   public String toString() {
-    StringBuffer sb = new StringBuffer();
-    sb.append('(');
-    
+    StringBuilder sb = new StringBuilder().append('(');
     if (hasAttributes()) {
       if (currentState == null) {
         computeCurrentState();
@@ -424,8 +411,7 @@ public class AttributeSource {
         sb.append(state.attribute.toString());
       }
     }
-    sb.append(')');
-    return sb.toString();
+    return sb.append(')').toString();
   }
   
   /**
@@ -442,14 +428,12 @@ public class AttributeSource {
         computeCurrentState();
       }
       for (State state = currentState; state != null; state = state.next) {
-        clone.attributeImpls.put(state.attribute.getClass(), state.attribute.clone());
+        clone.attributeImpls.put(state.attribute.getClass(), (AttributeImpl) state.attribute.clone());
       }
     }
     
     // now the interfaces
-    Iterator/*<Entry<Class<Attribute>, AttributeImpl>>*/ attIt = this.attributes.entrySet().iterator(); 
-    while (attIt.hasNext()) {
-      Entry/*<Class<Attribute>, AttributeImpl>*/ entry = (Entry/*<Class<Attribute>, AttributeImpl>*/) attIt.next();
+    for (Entry<Class<? extends Attribute>, AttributeImpl> entry : this.attributes.entrySet()) {
       clone.attributes.put(entry.getKey(), clone.attributeImpls.get(entry.getValue().getClass()));
     }
     
diff --git a/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase.java b/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
index f505372..08d1485 100644
--- a/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
+++ b/src/test/org/apache/lucene/analysis/BaseTokenStreamTestCase.java
@@ -89,24 +89,24 @@ public abstract class BaseTokenStreamTestCase extends LuceneTestCase {
   public static void assertTokenStreamContents(TokenStream ts, String[] output, int startOffsets[], int endOffsets[], String types[], int posIncrements[]) throws IOException {
     assertNotNull(output);
     assertTrue("has TermAttribute", ts.hasAttribute(TermAttribute.class));
-    TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = ts.getAttribute(TermAttribute.class);
     
     OffsetAttribute offsetAtt = null;
     if (startOffsets != null || endOffsets != null) {
       assertTrue("has OffsetAttribute", ts.hasAttribute(OffsetAttribute.class));
-      offsetAtt = (OffsetAttribute) ts.getAttribute(OffsetAttribute.class);
+      offsetAtt = ts.getAttribute(OffsetAttribute.class);
     }
     
     TypeAttribute typeAtt = null;
     if (types != null) {
       assertTrue("has TypeAttribute", ts.hasAttribute(TypeAttribute.class));
-      typeAtt = (TypeAttribute) ts.getAttribute(TypeAttribute.class);
+      typeAtt = ts.getAttribute(TypeAttribute.class);
     }
     
     PositionIncrementAttribute posIncrAtt = null;
     if (posIncrements != null) {
       assertTrue("has PositionIncrementAttribute", ts.hasAttribute(PositionIncrementAttribute.class));
-      posIncrAtt = (PositionIncrementAttribute) ts.getAttribute(PositionIncrementAttribute.class);
+      posIncrAtt = ts.getAttribute(PositionIncrementAttribute.class);
     }
     
     ts.reset();
diff --git a/src/test/org/apache/lucene/analysis/TestASCIIFoldingFilter.java b/src/test/org/apache/lucene/analysis/TestASCIIFoldingFilter.java
index 2f16d96..fb1fc77 100644
--- a/src/test/org/apache/lucene/analysis/TestASCIIFoldingFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestASCIIFoldingFilter.java
@@ -34,7 +34,7 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
       +" Ã° Ã± Ã² Ã³ Ã´ Ãµ Ã¶ Ã¸ ? ? Ã¾ Ã¹ Ãº Ã» Ã¼ Ã½ Ã¿ ï¬? ï¬?"));
     ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream);
 
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
 
     assertTermEquals("Des", filter, termAtt);
     assertTermEquals("mot", filter, termAtt);
@@ -1891,7 +1891,7 @@ public class TestASCIIFoldingFilter extends BaseTokenStreamTestCase {
 
     TokenStream stream = new WhitespaceTokenizer(new StringReader(inputText.toString()));
     ASCIIFoldingFilter filter = new ASCIIFoldingFilter(stream);
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
     Iterator expectedIter = expectedOutputTokens.iterator();
     while (expectedIter.hasNext()) {;
       assertTermEquals((String)expectedIter.next(), filter, termAtt);
diff --git a/src/test/org/apache/lucene/analysis/TestAnalyzers.java b/src/test/org/apache/lucene/analysis/TestAnalyzers.java
index 447b614..d005809 100644
--- a/src/test/org/apache/lucene/analysis/TestAnalyzers.java
+++ b/src/test/org/apache/lucene/analysis/TestAnalyzers.java
@@ -82,7 +82,7 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
   }
 
   void verifyPayload(TokenStream ts) throws IOException {
-    PayloadAttribute payloadAtt = (PayloadAttribute) ts.getAttribute(PayloadAttribute.class);
+    PayloadAttribute payloadAtt = ts.getAttribute(PayloadAttribute.class);
     for(byte b=1;;b++) {
       boolean hasNext = ts.incrementToken();
       if (!hasNext) break;
@@ -139,7 +139,7 @@ class PayloadSetter extends TokenFilter {
   PayloadAttribute payloadAtt;
   public  PayloadSetter(TokenStream input) {
     super(input);
-    payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+    payloadAtt = addAttribute(PayloadAttribute.class);
   }
 
   byte[] data = new byte[1];
diff --git a/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java b/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
index 22aa382..0065e97 100644
--- a/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestCachingTokenFilter.java
@@ -41,8 +41,8 @@ public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
     Document doc = new Document();
     TokenStream stream = new TokenStream() {
       private int index = 0;
-      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      private OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      private TermAttribute termAtt = addAttribute(TermAttribute.class);
+      private OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
       
       public boolean incrementToken() throws IOException {
         if (index == tokens.length) {
@@ -96,7 +96,7 @@ public class TestCachingTokenFilter extends BaseTokenStreamTestCase {
   private void checkTokens(TokenStream stream) throws IOException {
     int count = 0;
     
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     assertNotNull(termAtt);
     while (stream.incrementToken()) {
       assertTrue(count < tokens.length);
diff --git a/src/test/org/apache/lucene/analysis/TestISOLatin1AccentFilter.java b/src/test/org/apache/lucene/analysis/TestISOLatin1AccentFilter.java
index 8a6b7c6..ec15644 100644
--- a/src/test/org/apache/lucene/analysis/TestISOLatin1AccentFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestISOLatin1AccentFilter.java
@@ -25,7 +25,7 @@ public class TestISOLatin1AccentFilter extends BaseTokenStreamTestCase {
   public void testU() throws Exception {
     TokenStream stream = new WhitespaceTokenizer(new StringReader("Des mot clÃ©s ? LA CHA?NE ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Ä² ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Å¸ ? Ã¡ Ã¢ Ã£ Ã¤ Ã¥ Ã¦ Ã§ Ã¨ Ã© Ãª Ã« Ã¬ Ã­ Ã® Ã¯ Ä³ Ã° Ã± Ã² Ã³ Ã´ Ãµ Ã¶ Ã¸ ? ? Ã¾ Ã¹ Ãº Ã» Ã¼ Ã½ Ã¿ ï¬? ï¬?"));
     ISOLatin1AccentFilter filter = new ISOLatin1AccentFilter(stream);
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
     assertTermEquals("Des", filter, termAtt);
     assertTermEquals("mot", filter, termAtt);
     assertTermEquals("cles", filter, termAtt);
diff --git a/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java b/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
index e19ab4f..d9212cd 100644
--- a/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
+++ b/src/test/org/apache/lucene/analysis/TestKeywordAnalyzer.java
@@ -88,7 +88,7 @@ public class TestKeywordAnalyzer extends BaseTokenStreamTestCase {
   // LUCENE-1441
   public void testOffsets() throws Exception {
     TokenStream stream = new KeywordAnalyzer().tokenStream("field", new StringReader("abcd"));
-    OffsetAttribute offsetAtt = (OffsetAttribute) stream.addAttribute(OffsetAttribute.class);
+    OffsetAttribute offsetAtt = stream.addAttribute(OffsetAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals(0, offsetAtt.startOffset());
     assertEquals(4, offsetAtt.endOffset());
diff --git a/src/test/org/apache/lucene/analysis/TestLengthFilter.java b/src/test/org/apache/lucene/analysis/TestLengthFilter.java
index eb0c0b2..f6c8bba 100644
--- a/src/test/org/apache/lucene/analysis/TestLengthFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestLengthFilter.java
@@ -27,7 +27,7 @@ public class TestLengthFilter extends BaseTokenStreamTestCase {
     TokenStream stream = new WhitespaceTokenizer(
         new StringReader("short toolong evenmuchlongertext a ab toolong foo"));
     LengthFilter filter = new LengthFilter(stream, 2, 6);
-    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = filter.getAttribute(TermAttribute.class);
 
     assertTrue(filter.incrementToken());
     assertEquals("short", termAtt.term());
diff --git a/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java b/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
index a6d2c98..9a48a07 100644
--- a/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
+++ b/src/test/org/apache/lucene/analysis/TestNumericTokenStream.java
@@ -29,8 +29,8 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
   public void testLongStream() throws Exception {
     final NumericTokenStream stream=new NumericTokenStream().setLongValue(lvalue);
     // use getAttribute to test if attributes really exist, if not an IAE will be throwed
-    final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-    final TypeAttribute typeAtt = (TypeAttribute) stream.getAttribute(TypeAttribute.class);
+    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
+    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);
     for (int shift=0; shift<64; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {
       assertTrue("New token is available", stream.incrementToken());
       assertEquals("Term is correctly encoded", NumericUtils.longToPrefixCoded(lvalue, shift), termAtt.term());
@@ -42,8 +42,8 @@ public class TestNumericTokenStream extends BaseTokenStreamTestCase {
   public void testIntStream() throws Exception {
     final NumericTokenStream stream=new NumericTokenStream().setIntValue(ivalue);
     // use getAttribute to test if attributes really exist, if not an IAE will be throwed
-    final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-    final TypeAttribute typeAtt = (TypeAttribute) stream.getAttribute(TypeAttribute.class);
+    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
+    final TypeAttribute typeAtt = stream.getAttribute(TypeAttribute.class);
     for (int shift=0; shift<32; shift+=NumericUtils.PRECISION_STEP_DEFAULT) {
       assertTrue("New token is available", stream.incrementToken());
       assertEquals("Term is correctly encoded", NumericUtils.intToPrefixCoded(ivalue, shift), termAtt.term());
diff --git a/src/test/org/apache/lucene/analysis/TestPerFieldAnalzyerWrapper.java b/src/test/org/apache/lucene/analysis/TestPerFieldAnalzyerWrapper.java
index 92f3fba..3072290 100644
--- a/src/test/org/apache/lucene/analysis/TestPerFieldAnalzyerWrapper.java
+++ b/src/test/org/apache/lucene/analysis/TestPerFieldAnalzyerWrapper.java
@@ -30,7 +30,7 @@ public class TestPerFieldAnalzyerWrapper extends BaseTokenStreamTestCase {
 
     TokenStream tokenStream = analyzer.tokenStream("field",
                                             new StringReader(text));
-    TermAttribute termAtt = (TermAttribute) tokenStream.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = tokenStream.getAttribute(TermAttribute.class);
 
     assertTrue(tokenStream.incrementToken());
     assertEquals("WhitespaceAnalyzer does not lowercase",
@@ -39,7 +39,7 @@ public class TestPerFieldAnalzyerWrapper extends BaseTokenStreamTestCase {
 
     tokenStream = analyzer.tokenStream("special",
                                             new StringReader(text));
-    termAtt = (TermAttribute) tokenStream.getAttribute(TermAttribute.class);
+    termAtt = tokenStream.getAttribute(TermAttribute.class);
     assertTrue(tokenStream.incrementToken());
     assertEquals("SimpleAnalyzer lowercases",
                  "qwerty",
diff --git a/src/test/org/apache/lucene/analysis/TestStopAnalyzer.java b/src/test/org/apache/lucene/analysis/TestStopAnalyzer.java
index 2677eb2..f52e128 100644
--- a/src/test/org/apache/lucene/analysis/TestStopAnalyzer.java
+++ b/src/test/org/apache/lucene/analysis/TestStopAnalyzer.java
@@ -49,7 +49,7 @@ public class TestStopAnalyzer extends BaseTokenStreamTestCase {
     StringReader reader = new StringReader("This is a test of the english stop analyzer");
     TokenStream stream = stop.tokenStream("test", reader);
     assertTrue(stream != null);
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     
     while (stream.incrementToken()) {
       assertFalse(inValidTokens.contains(termAtt.term()));
@@ -65,8 +65,8 @@ public class TestStopAnalyzer extends BaseTokenStreamTestCase {
     StringReader reader = new StringReader("This is a good test of the english stop analyzer");
     TokenStream stream = newStop.tokenStream("test", reader);
     assertNotNull(stream);
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);
     
     while (stream.incrementToken()) {
       String text = termAtt.term();
@@ -89,8 +89,8 @@ public class TestStopAnalyzer extends BaseTokenStreamTestCase {
       TokenStream stream = newStop.tokenStream("test", reader);
       assertNotNull(stream);
       int i = 0;
-      TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
-      PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.addAttribute(PositionIncrementAttribute.class);
+      TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
+      PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);
 
       while (stream.incrementToken()) {
         String text = termAtt.term();
diff --git a/src/test/org/apache/lucene/analysis/TestStopFilter.java b/src/test/org/apache/lucene/analysis/TestStopFilter.java
index 98675f4..967fd45 100644
--- a/src/test/org/apache/lucene/analysis/TestStopFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestStopFilter.java
@@ -36,7 +36,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
     StringReader reader = new StringReader("Now is The Time");
     String[] stopWords = new String[] { "is", "the", "Time" };
     TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopWords);
-    final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals("Now", termAtt.term());
     assertTrue(stream.incrementToken());
@@ -48,7 +48,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
     StringReader reader = new StringReader("Now is The Time");
     String[] stopWords = new String[] { "is", "the", "Time" };
     TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopWords, true);
-    final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals("Now", termAtt.term());
     assertFalse(stream.incrementToken());
@@ -59,7 +59,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
     String[] stopWords = new String[] { "is", "the", "Time" };
     Set stopSet = StopFilter.makeStopSet(stopWords);
     TokenStream stream = new StopFilter(false, new WhitespaceTokenizer(reader), stopSet);
-    final TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    final TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals("Now", termAtt.term());
     assertTrue(stream.incrementToken());
@@ -116,8 +116,8 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
   private void doTestStopPositons(StopFilter stpf, boolean enableIcrements) throws IOException {
     log("---> test with enable-increments-"+(enableIcrements?"enabled":"disabled"));
     stpf.setEnablePositionIncrements(enableIcrements);
-    TermAttribute termAtt = (TermAttribute) stpf.getAttribute(TermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stpf.getAttribute(PositionIncrementAttribute.class);
+    TermAttribute termAtt = stpf.getAttribute(TermAttribute.class);
+    PositionIncrementAttribute posIncrAtt = stpf.getAttribute(PositionIncrementAttribute.class);
     for (int i=0; i<20; i+=3) {
       assertTrue(stpf.incrementToken());
       log("Token "+i+": "+stpf);
diff --git a/src/test/org/apache/lucene/analysis/TestTeeSinkTokenFilter.java b/src/test/org/apache/lucene/analysis/TestTeeSinkTokenFilter.java
index 5d6a4e1..3514b0e 100644
--- a/src/test/org/apache/lucene/analysis/TestTeeSinkTokenFilter.java
+++ b/src/test/org/apache/lucene/analysis/TestTeeSinkTokenFilter.java
@@ -59,14 +59,14 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
 
   static final TeeSinkTokenFilter.SinkFilter theFilter = new TeeSinkTokenFilter.SinkFilter() {
     public boolean accept(AttributeSource a) {
-      TermAttribute termAtt = (TermAttribute) a.getAttribute(TermAttribute.class);
+      TermAttribute termAtt = a.getAttribute(TermAttribute.class);
       return termAtt.term().equalsIgnoreCase("The");
     }
   };
 
   static final TeeSinkTokenFilter.SinkFilter dogFilter = new TeeSinkTokenFilter.SinkFilter() {
     public boolean accept(AttributeSource a) {
-      TermAttribute termAtt = (TermAttribute) a.getAttribute(TermAttribute.class);
+      TermAttribute termAtt = a.getAttribute(TermAttribute.class);
       return termAtt.term().equalsIgnoreCase("Dogs");
     }
   };
@@ -77,7 +77,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     final TokenStream sink1 = source.newSinkTokenStream();
     final TokenStream sink2 = source.newSinkTokenStream(theFilter);
     int i = 0;
-    TermAttribute termAtt = (TermAttribute) source.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = source.getAttribute(TermAttribute.class);
     while (source.incrementToken()) {
       assertEquals(tokens1[i], termAtt.term());
       i++;
@@ -85,7 +85,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     assertEquals(tokens1.length, i);
     
     i = 0;
-    termAtt = (TermAttribute) sink1.getAttribute(TermAttribute.class);
+    termAtt = sink1.getAttribute(TermAttribute.class);
     while (sink1.incrementToken()) {
       assertEquals(tokens1[i], termAtt.term());
       i++;
@@ -93,7 +93,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     assertEquals(tokens1.length, i);
     
     i = 0;
-    termAtt = (TermAttribute) sink2.getAttribute(TermAttribute.class);
+    termAtt = sink2.getAttribute(TermAttribute.class);
     while (sink2.incrementToken()) {
       assertTrue(termAtt.term().equalsIgnoreCase("The"));
       i++;
@@ -113,28 +113,28 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     final TokenStream source2 = tee2;
 
     int i = 0;
-    TermAttribute termAtt = (TermAttribute) source1.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = source1.getAttribute(TermAttribute.class);
     while (source1.incrementToken()) {
       assertEquals(tokens1[i], termAtt.term());
       i++;
     }
     assertEquals(tokens1.length, i);
     i = 0;
-    termAtt = (TermAttribute) source2.getAttribute(TermAttribute.class);
+    termAtt = source2.getAttribute(TermAttribute.class);
     while (source2.incrementToken()) {
       assertEquals(tokens2[i], termAtt.term());
       i++;
     }
     assertEquals(tokens2.length, i);
     i = 0;
-    termAtt = (TermAttribute) theDetector.getAttribute(TermAttribute.class);
+    termAtt = theDetector.getAttribute(TermAttribute.class);
     while (theDetector.incrementToken()) {
       assertTrue("'" + termAtt.term() + "' is not equal to 'The'", termAtt.term().equalsIgnoreCase("The"));
       i++;
     }
     assertEquals("there must be 4 times 'The' in the stream", 4, i);
     i = 0;
-    termAtt = (TermAttribute) dogDetector.getAttribute(TermAttribute.class);
+    termAtt = dogDetector.getAttribute(TermAttribute.class);
     while (dogDetector.incrementToken()) {
       assertTrue("'" + termAtt.term() + "' is not equal to 'Dogs'", termAtt.term().equalsIgnoreCase("Dogs"));
       i++;
@@ -144,7 +144,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
     source1.reset();
     TokenStream lowerCasing = new LowerCaseFilter(source1);
     i = 0;
-    termAtt = (TermAttribute) lowerCasing.getAttribute(TermAttribute.class);
+    termAtt = lowerCasing.getAttribute(TermAttribute.class);
     while (lowerCasing.incrementToken()) {
       assertEquals(tokens1[i].toLowerCase(), termAtt.term());
       i++;
@@ -171,8 +171,8 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
       TokenStream sink = teeStream.newSinkTokenStream(new ModuloSinkFilter(100));
       teeStream.consumeAllTokens();
       TokenStream stream = new ModuloTokenFilter(new StandardFilter(new StandardTokenizer(new StringReader(buffer.toString()))), 100);
-      TermAttribute tfTok = (TermAttribute) stream.addAttribute(TermAttribute.class);
-      TermAttribute sinkTok = (TermAttribute) sink.addAttribute(TermAttribute.class);
+      TermAttribute tfTok = stream.addAttribute(TermAttribute.class);
+      TermAttribute sinkTok = sink.addAttribute(TermAttribute.class);
       for (int i=0; stream.incrementToken(); i++) {
         assertTrue(sink.incrementToken());
         assertTrue(tfTok + " is not equal to " + sinkTok + " at token: " + i, tfTok.equals(sinkTok) == true);
@@ -184,12 +184,12 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
         long start = System.currentTimeMillis();
         for (int i = 0; i < 20; i++) {
           stream = new StandardFilter(new StandardTokenizer(new StringReader(buffer.toString())));
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) stream.getAttribute(PositionIncrementAttribute.class);
+          PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);
           while (stream.incrementToken()) {
             tfPos += posIncrAtt.getPositionIncrement();
           }
           stream = new ModuloTokenFilter(new StandardFilter(new StandardTokenizer(new StringReader(buffer.toString()))), modCounts[j]);
-          posIncrAtt = (PositionIncrementAttribute) stream.getAttribute(PositionIncrementAttribute.class);
+          posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);
           while (stream.incrementToken()) {
             tfPos += posIncrAtt.getPositionIncrement();
           }
@@ -202,12 +202,12 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
         for (int i = 0; i < 20; i++) {
           teeStream = new TeeSinkTokenFilter(new StandardFilter(new StandardTokenizer(new StringReader(buffer.toString()))));
           sink = teeStream.newSinkTokenStream(new ModuloSinkFilter(modCounts[j]));
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) teeStream.getAttribute(PositionIncrementAttribute.class);
+          PositionIncrementAttribute posIncrAtt = teeStream.getAttribute(PositionIncrementAttribute.class);
           while (teeStream.incrementToken()) {
             sinkPos += posIncrAtt.getPositionIncrement();
           }
           //System.out.println("Modulo--------");
-          posIncrAtt = (PositionIncrementAttribute) sink.getAttribute(PositionIncrementAttribute.class);
+          posIncrAtt = sink.getAttribute(PositionIncrementAttribute.class);
           while (sink.incrementToken()) {
             sinkPos += posIncrAtt.getPositionIncrement();
           }
diff --git a/src/test/org/apache/lucene/analysis/TestTokenStreamBWComp.java b/src/test/org/apache/lucene/analysis/TestTokenStreamBWComp.java
index 67d13d9..6471922 100644
--- a/src/test/org/apache/lucene/analysis/TestTokenStreamBWComp.java
+++ b/src/test/org/apache/lucene/analysis/TestTokenStreamBWComp.java
@@ -188,8 +188,8 @@ public class TestTokenStreamBWComp extends LuceneTestCase {
 
   private static void consumeStreamNewAPI(TokenStream stream) throws IOException {
     stream.reset();
-    PayloadAttribute payloadAtt = (PayloadAttribute) stream.addAttribute(PayloadAttribute.class);
-    TermAttribute termAtt = (TermAttribute) stream.addAttribute(TermAttribute.class);
+    PayloadAttribute payloadAtt = stream.addAttribute(PayloadAttribute.class);
+    TermAttribute termAtt = stream.addAttribute(TermAttribute.class);
     
     int i=0;
     while (stream.incrementToken()) {
@@ -350,7 +350,7 @@ public class TestTokenStreamBWComp extends LuceneTestCase {
     assertEquals("private 'bar' term should still be valid", "bar", bar.term());
     
     // and now we also use incrementToken()... (very bad, but should work)
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     assertTrue(stream.incrementToken());
     assertEquals("maeh", termAtt.term());    
     assertEquals("private 'bar' term should still be valid", "bar", bar.term());    
@@ -373,7 +373,7 @@ public class TestTokenStreamBWComp extends LuceneTestCase {
   public void testMixedOldApiConsumer2() throws Exception {
     // RoundRobinOldAPI is using TokenStream(next)
     TokenStream stream = new RoundRobinOldAPI();
-    TermAttribute termAtt = (TermAttribute) stream.getAttribute(TermAttribute.class);
+    TermAttribute termAtt = stream.getAttribute(TermAttribute.class);
     
     assertTrue(stream.incrementToken());
     Token bar = stream.next();
diff --git a/src/test/org/apache/lucene/index/TestDocumentWriter.java b/src/test/org/apache/lucene/index/TestDocumentWriter.java
index 394f126..cba54cd 100644
--- a/src/test/org/apache/lucene/index/TestDocumentWriter.java
+++ b/src/test/org/apache/lucene/index/TestDocumentWriter.java
@@ -170,9 +170,9 @@ public class TestDocumentWriter extends BaseTokenStreamTestCase {
 
           }
 
-          TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-          PayloadAttribute payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);          
+          TermAttribute termAtt = addAttribute(TermAttribute.class);
+          PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
+          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);          
         };
       }
     };
@@ -209,7 +209,7 @@ public class TestDocumentWriter extends BaseTokenStreamTestCase {
       private String[] tokens = new String[] {"term1", "term2", "term3", "term2"};
       private int index = 0;
       
-      private TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+      private TermAttribute termAtt = addAttribute(TermAttribute.class);
       
       public boolean incrementToken() throws IOException {
         if (index == tokens.length) {
diff --git a/src/test/org/apache/lucene/index/TestIndexWriter.java b/src/test/org/apache/lucene/index/TestIndexWriter.java
index aa1c019..b557beb 100644
--- a/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -3540,8 +3540,8 @@ public class TestIndexWriter extends BaseTokenStreamTestCase {
   // LUCENE-1255
   public void testNegativePositions() throws Throwable {
     final TokenStream tokens = new TokenStream() {
-      final TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      final PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+      final TermAttribute termAtt = addAttribute(TermAttribute.class);
+      final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
       
       final Iterator tokens = Arrays.asList(new String[]{"a","b","c"}).iterator();
       boolean first = true;
diff --git a/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java b/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
index 1c86be4..d341c51 100644
--- a/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
+++ b/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
@@ -102,7 +102,7 @@ public class TestMultiLevelSkipList extends LuceneTestCase {
     
     protected PayloadFilter(TokenStream input) {
       super(input);
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
     }
 
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/index/TestPayloads.java b/src/test/org/apache/lucene/index/TestPayloads.java
index 9a844b0..034fa45 100644
--- a/src/test/org/apache/lucene/index/TestPayloads.java
+++ b/src/test/org/apache/lucene/index/TestPayloads.java
@@ -436,7 +436,7 @@ public class TestPayloads extends LuceneTestCase {
             this.data = data;
             this.length = length;
             this.offset = offset;
-            payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+            payloadAtt = addAttribute(PayloadAttribute.class);
         }
         
         public boolean incrementToken() throws IOException {
@@ -526,8 +526,8 @@ public class TestPayloads extends LuceneTestCase {
             generateRandomData(payload);
             term = pool.bytesToString(payload);
             first = true;
-            payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
-            termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+            payloadAtt = addAttribute(PayloadAttribute.class);
+            termAtt = addAttribute(TermAttribute.class);
         }
         
         public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/index/TestTermVectorsReader.java b/src/test/org/apache/lucene/index/TestTermVectorsReader.java
index 8d2b914..f107d3e 100644
--- a/src/test/org/apache/lucene/index/TestTermVectorsReader.java
+++ b/src/test/org/apache/lucene/index/TestTermVectorsReader.java
@@ -126,9 +126,9 @@ public class TestTermVectorsReader extends LuceneTestCase {
     OffsetAttribute offsetAtt;
     
     public MyTokenStream() {
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
     }
     
     public boolean incrementToken() {
diff --git a/src/test/org/apache/lucene/index/TestTermdocPerf.java b/src/test/org/apache/lucene/index/TestTermdocPerf.java
index 806e8f1..804fa34 100644
--- a/src/test/org/apache/lucene/index/TestTermdocPerf.java
+++ b/src/test/org/apache/lucene/index/TestTermdocPerf.java
@@ -41,7 +41,7 @@ class RepeatingTokenStream extends TokenStream {
 
    public RepeatingTokenStream(String val) {
      this.value = val;
-     this.termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+     this.termAtt = addAttribute(TermAttribute.class);
    }
 
    public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java b/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
index a48721c..7ac3b1e 100644
--- a/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
+++ b/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
@@ -154,10 +154,10 @@ public class TestMultiAnalyzer extends BaseTokenStreamTestCase {
     
     public TestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
-      typeAtt = (TypeAttribute) addAttribute(TypeAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
+      typeAtt = addAttribute(TypeAttribute.class);
     }
 
     public final boolean incrementToken() throws java.io.IOException {
@@ -214,8 +214,8 @@ public class TestMultiAnalyzer extends BaseTokenStreamTestCase {
     
     public TestPosIncrementFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
     }
 
     public final boolean incrementToken () throws java.io.IOException {
diff --git a/src/test/org/apache/lucene/queryParser/TestQueryParser.java b/src/test/org/apache/lucene/queryParser/TestQueryParser.java
index 1bd4f23..6297da1 100644
--- a/src/test/org/apache/lucene/queryParser/TestQueryParser.java
+++ b/src/test/org/apache/lucene/queryParser/TestQueryParser.java
@@ -87,8 +87,8 @@ public class TestQueryParser extends LocalizedTestCase {
      */
     public QPTestFilter(TokenStream in) {
       super(in);
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      offsetAtt = addAttribute(OffsetAttribute.class);
     }
 
     boolean inPhrase = false;
diff --git a/src/test/org/apache/lucene/search/TestPositionIncrement.java b/src/test/org/apache/lucene/search/TestPositionIncrement.java
index df2ed36..ea2d4b9 100644
--- a/src/test/org/apache/lucene/search/TestPositionIncrement.java
+++ b/src/test/org/apache/lucene/search/TestPositionIncrement.java
@@ -66,9 +66,9 @@ public class TestPositionIncrement extends BaseTokenStreamTestCase {
           private final int[] INCREMENTS = {0, 2, 1, 0, 1};
           private int i = 0;
 
-          PositionIncrementAttribute posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-          TermAttribute termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-          OffsetAttribute offsetAtt = (OffsetAttribute) addAttribute(OffsetAttribute.class);
+          PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+          TermAttribute termAtt = addAttribute(TermAttribute.class);
+          OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
           
           public boolean incrementToken() {
             if (i == TOKENS.length)
@@ -348,9 +348,9 @@ class PayloadFilter extends TokenFilter {
     this.fieldName = fieldName;
     pos = 0;
     i = 0;
-    posIncrAttr = (PositionIncrementAttribute) input.addAttribute(PositionIncrementAttribute.class);
-    payloadAttr = (PayloadAttribute) input.addAttribute(PayloadAttribute.class);
-    termAttr = (TermAttribute) input.addAttribute(TermAttribute.class);
+    posIncrAttr = input.addAttribute(PositionIncrementAttribute.class);
+    payloadAttr = input.addAttribute(PayloadAttribute.class);
+    termAttr = input.addAttribute(TermAttribute.class);
   }
 
   public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/TestTermRangeQuery.java b/src/test/org/apache/lucene/search/TestTermRangeQuery.java
index 383a715..8862edd 100644
--- a/src/test/org/apache/lucene/search/TestTermRangeQuery.java
+++ b/src/test/org/apache/lucene/search/TestTermRangeQuery.java
@@ -244,7 +244,7 @@ public class TestTermRangeQuery extends LuceneTestCase {
       
       public SingleCharTokenizer(Reader r) {
         super(r);
-        termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+        termAtt = addAttribute(TermAttribute.class);
       }
 
       public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/payloads/PayloadHelper.java b/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
index c5f27b7..721d676 100644
--- a/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
+++ b/src/test/org/apache/lucene/search/payloads/PayloadHelper.java
@@ -63,7 +63,7 @@ public class PayloadHelper {
     public PayloadFilter(TokenStream input, String fieldName) {
       super(input);
       this.fieldName = fieldName;
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
     }
 
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery.java b/src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery.java
index 1c0b1bc..dd97be5 100644
--- a/src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery.java
+++ b/src/test/org/apache/lucene/search/payloads/TestBoostingTermQuery.java
@@ -72,7 +72,7 @@ public class TestBoostingTermQuery extends LuceneTestCase {
     public PayloadFilter(TokenStream input, String fieldName) {
       super(input);
       this.fieldName = fieldName;
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
     }
     
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java b/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
index 1a7770c..e02195e 100644
--- a/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
+++ b/src/test/org/apache/lucene/search/payloads/TestPayloadNearQuery.java
@@ -68,7 +68,7 @@ public class TestPayloadNearQuery extends LuceneTestCase {
 		public PayloadFilter(TokenStream input, String fieldName) {
 			super(input);
 			this.fieldName = fieldName;
-      payAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      payAtt = addAttribute(PayloadAttribute.class);
 		}
 
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java b/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
index 6c98ecc..3ffd960 100644
--- a/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
+++ b/src/test/org/apache/lucene/search/payloads/TestPayloadTermQuery.java
@@ -80,7 +80,7 @@ public class TestPayloadTermQuery extends LuceneTestCase {
     public PayloadFilter(TokenStream input, String fieldName) {
       super(input);
       this.fieldName = fieldName;
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
     }
     
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java b/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
index d2f7611..3437f87 100644
--- a/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
+++ b/src/test/org/apache/lucene/search/spans/TestPayloadSpans.java
@@ -498,9 +498,9 @@ public class TestPayloadSpans extends LuceneTestCase {
       entities.add("one");
       nopayload.add("nopayload");
       nopayload.add("np");
-      termAtt = (TermAttribute) addAttribute(TermAttribute.class);
-      posIncrAtt = (PositionIncrementAttribute) addAttribute(PositionIncrementAttribute.class);
-      payloadAtt = (PayloadAttribute) addAttribute(PayloadAttribute.class);
+      termAtt = addAttribute(TermAttribute.class);
+      posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+      payloadAtt = addAttribute(PayloadAttribute.class);
     }
 
     public boolean incrementToken() throws IOException {
diff --git a/src/test/org/apache/lucene/util/TestAttributeSource.java b/src/test/org/apache/lucene/util/TestAttributeSource.java
index 1b02df2..b9ee8c1 100644
--- a/src/test/org/apache/lucene/util/TestAttributeSource.java
+++ b/src/test/org/apache/lucene/util/TestAttributeSource.java
@@ -27,8 +27,8 @@ public class TestAttributeSource extends LuceneTestCase {
   public void testCaptureState() {
     // init a first instance
     AttributeSource src = new AttributeSource();
-    TermAttribute termAtt = (TermAttribute) src.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) src.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
     termAtt.setTermBuffer("TestTerm");
     typeAtt.setType("TestType");
     final int hashCode = src.hashCode();
@@ -55,9 +55,9 @@ public class TestAttributeSource extends LuceneTestCase {
     
     // init a second instance (with attributes in different order and one additional attribute)
     AttributeSource src2 = new AttributeSource();
-    typeAtt = (TypeAttribute) src2.addAttribute(TypeAttribute.class);
-    FlagsAttribute flagsAtt = (FlagsAttribute) src2.addAttribute(FlagsAttribute.class);
-    termAtt = (TermAttribute) src2.addAttribute(TermAttribute.class);
+    typeAtt = src2.addAttribute(TypeAttribute.class);
+    FlagsAttribute flagsAtt = src2.addAttribute(FlagsAttribute.class);
+    termAtt = src2.addAttribute(TermAttribute.class);
     flagsAtt.setFlags(12345);
 
     src2.restoreState(state);
@@ -67,7 +67,7 @@ public class TestAttributeSource extends LuceneTestCase {
 
     // init a third instance missing one Attribute
     AttributeSource src3 = new AttributeSource();
-    termAtt = (TermAttribute) src3.addAttribute(TermAttribute.class);
+    termAtt = src3.addAttribute(TermAttribute.class);
     try {
       src3.restoreState(state);
       fail("The third instance is missing the TypeAttribute, so restoreState() should throw IllegalArgumentException");
@@ -78,19 +78,19 @@ public class TestAttributeSource extends LuceneTestCase {
   
   public void testCloneAttributes() {
     final AttributeSource src = new AttributeSource();
-    final TermAttribute termAtt = (TermAttribute) src.addAttribute(TermAttribute.class);
-    final TypeAttribute typeAtt = (TypeAttribute) src.addAttribute(TypeAttribute.class);
+    final TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    final TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
     termAtt.setTermBuffer("TestTerm");
     typeAtt.setType("TestType");
     
     final AttributeSource clone = src.cloneAttributes();
-    final Iterator it = clone.getAttributeClassesIterator();
+    final Iterator<Class<? extends Attribute>> it = clone.getAttributeClassesIterator();
     assertEquals("TermAttribute must be the first attribute", TermAttribute.class, it.next());
     assertEquals("TypeAttribute must be the second attribute", TypeAttribute.class, it.next());
     assertFalse("No more attributes", it.hasNext());
     
-    final TermAttribute termAtt2 = (TermAttribute) clone.getAttribute(TermAttribute.class);
-    final TypeAttribute typeAtt2 = (TypeAttribute) clone.getAttribute(TypeAttribute.class);
+    final TermAttribute termAtt2 = clone.getAttribute(TermAttribute.class);
+    final TypeAttribute typeAtt2 = clone.getAttribute(TypeAttribute.class);
     assertNotSame("TermAttribute of original and clone must be different instances", termAtt2, termAtt);
     assertNotSame("TypeAttribute of original and clone must be different instances", typeAtt2, typeAtt);
     assertEquals("TermAttribute of original and clone must be equal", termAtt2, termAtt);
@@ -99,12 +99,12 @@ public class TestAttributeSource extends LuceneTestCase {
   
   public void testToStringAndMultiAttributeImplementations() {
     AttributeSource src = new AttributeSource();
-    TermAttribute termAtt = (TermAttribute) src.addAttribute(TermAttribute.class);
-    TypeAttribute typeAtt = (TypeAttribute) src.addAttribute(TypeAttribute.class);
+    TermAttribute termAtt = src.addAttribute(TermAttribute.class);
+    TypeAttribute typeAtt = src.addAttribute(TypeAttribute.class);
     termAtt.setTermBuffer("TestTerm");
     typeAtt.setType("TestType");    
     assertEquals("Attributes should appear in original order", "("+termAtt.toString()+","+typeAtt.toString()+")", src.toString());
-    Iterator it = src.getAttributeImplsIterator();
+    Iterator<AttributeImpl> it = src.getAttributeImplsIterator();
     assertTrue("Iterator should have 2 attributes left", it.hasNext());
     assertSame("First AttributeImpl from iterator should be termAtt", termAtt, it.next());
     assertTrue("Iterator should have 1 attributes left", it.hasNext());
@@ -114,7 +114,7 @@ public class TestAttributeSource extends LuceneTestCase {
     src = new AttributeSource();
     src.addAttributeImpl(new Token());
     // this should not add a new attribute as Token implements TermAttribute, too
-    termAtt = (TermAttribute) src.addAttribute(TermAttribute.class);
+    termAtt = src.addAttribute(TermAttribute.class);
     assertTrue("TermAttribute should be implemented by Token", termAtt instanceof Token);
     // get the Token attribute and check, that it is the only one
     it = src.getAttributeImplsIterator();

