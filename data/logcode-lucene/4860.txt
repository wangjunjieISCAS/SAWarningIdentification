GitDiffStart: bab0b4633710f050886ab940095fd04cac824820 | Fri Nov 28 01:16:37 2014 +0000
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
index 0038bdb..3362939 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemmer.java
@@ -232,8 +232,8 @@ public class BrazilianStemmer {
   /**
    * 1) Turn to lowercase
    * 2) Remove accents
-   * 3) 칚 -> a ; 칫 -> o
-   * 4) 칞 -> c
+   * 3) 칚 -&gt; a ; 칫 -&gt; o
+   * 4) 칞 -&gt; c
    *
    * @return null or a string transformed
    */
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java
index dc98909..734b7a3 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKBigramFilter.java
@@ -294,7 +294,7 @@ public final class CJKBigramFilter extends TokenFilter {
 
   /** 
    * Flushes a bigram token to output from our buffer 
-   * This is the normal case, e.g. ABC -> AB BC
+   * This is the normal case, e.g. ABC -&gt; AB BC
    */
   private void flushBigram() {
     clearAttributes();
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
index e8f49ef..426663a 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -108,7 +108,7 @@ public final class CzechAnalyzer extends StopwordAnalyzerBase {
    * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
-   *         , and {@link CzechStemFilter} (only if version is >= LUCENE_31). If
+   *         , and {@link CzechStemFilter} (only if version is &gt;= LUCENE_31). If
    *         a stem exclusion set is provided via
    *         {@link #CzechAnalyzer(CharArraySet, CharArraySet)} a
    *         {@link SetKeywordMarkerFilter} is added before
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemmer.java
index 805437c..db9d92d 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemmer.java
@@ -161,12 +161,12 @@ public class GermanStemmer
     /**
      * Do some substitutions for the term to reduce overstemming:
      *
-     * - Substitute Umlauts with their corresponding vowel: 칛칬칲 -> aou,
+     * - Substitute Umlauts with their corresponding vowel:{@code 칛칬칲 -> aou},
      *   "?" is substituted by "ss"
      * - Substitute a second char of a pair of equal characters with
-     *   an asterisk: ?? -> ?*
+     *   an asterisk: {@code ?? -> ?*}
      * - Substitute some common character combinations with a token:
-     *   sch/ch/ei/ie/ig/st -> $/춶/%/&/#/!
+     *   {@code sch/ch/ei/ie/ig/st -> $/춶/%/&/#/!}
      */
     private void substitute( StringBuilder buffer )
     {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
index b4d68a5..204eaab 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/en/KStemmer.java
@@ -248,7 +248,7 @@ public class KStemmer {
                   * word, use the method wordLength, which returns (k+1).
                   */
   
-  /***
+  /*
    * private void initializeStemHash() { if (maxCacheSize > 0) cache = new
    * CharArrayMap<String>(maxCacheSize,false); }
    ***/
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java
index 480382d..84746c9 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary.java
@@ -447,7 +447,7 @@ public class Dictionary {
    * @param reader BufferedReader to read the content of the rule from
    * @param conditionPattern {@link String#format(String, Object...)} pattern to be used to generate the condition regex
    *                         pattern
-   * @param seenPatterns map from condition -> index of patterns, for deduplication.
+   * @param seenPatterns map from condition -&gt; index of patterns, for deduplication.
    * @throws IOException Can be thrown while reading the rule
    */
   private void parseAffix(TreeMap<String,List<Integer>> affixes,
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemmer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemmer.java
index 7b24926..efee85b 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemmer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/lv/LatvianStemmer.java
@@ -87,10 +87,10 @@ public class LatvianStemmer {
   /**
    * Most cases are handled except for the ambiguous ones:
    * <ul>
-   *  <li> s -> 코
-   *  <li> t -> 코
-   *  <li> d -> 
-   *  <li> z -> 
+   *  <li> s -&gt; 코
+   *  <li> t -&gt; 코
+   *  <li> d -&gt; 
+   *  <li> z -&gt; 
    * </ul>
    */
   private int unpalatalize(char s[], int len) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
index 4afe735..e289a5b 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
@@ -153,7 +153,7 @@ public final class ASCIIFoldingFilter extends TokenFilter {
    * accents are removed from accented characters.
    * @param input     The characters to fold
    * @param inputPos  Index of the first character to fold
-   * @param output    The result of the folding. Should be of size >= {@code length * 4}.
+   * @param output    The result of the folding. Should be of size &gt;= {@code length * 4}.
    * @param outputPos Index of output where to put the result of the folding
    * @param length    The number of characters to fold
    * @return length of output
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilter.java
index f762cc4..af2a2f3 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilter.java
@@ -65,7 +65,7 @@ public final class CapitalizationFilter extends TokenFilter {
    * @param forceFirstLetter Force the first letter to be capitalized even if it is in the keep list.
    * @param okPrefix do not change word capitalization if a word begins with something in this list.
    * @param minWordLength how long the word needs to be to get capitalization applied.  If the
-   *                      minWordLength is 3, "and" > "And" but "or" stays "or".
+   *                      minWordLength is 3, "and" &gt; "And" but "or" stays "or".
    * @param maxWordCount if the token contains more then maxWordCount words, the capitalization is
    *                     assumed to be correct.
    * @param maxTokenLength ???
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
index 986994e..8159d8a 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/CapitalizationFilterFactory.java
@@ -39,7 +39,7 @@ import java.util.Set;
  * for example if "McK" is on the okPrefix list, the word "McKinley" should not be changed to
  * "Mckinley"<br/>
  * "minWordLength" - how long the word needs to be to get capitalization applied.  If the
- * minWordLength is 3, "and" > "And" but "or" stays "or"<br/>
+ * minWordLength is 3, "and" &gt; "And" but "or" stays "or"<br/>
  * "maxWordCount" - if the token contains more then maxWordCount words, the capitalization is
  * assumed to be correct.<br/>
  *
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.java
index 05a5f5a..26ab2d3 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.java
@@ -25,7 +25,7 @@ import org.apache.lucene.analysis.util.StemmerUtil;
 import java.io.IOException;
 
 /**
- * This filter folds Scandinavian characters 친?칛칝??->a and 칬?칮?->o.
+ * This filter folds Scandinavian characters 친?칛칝??-&gt;a and 칬?칮?-&gt;o.
  * It also discriminate against use of double vowels aa, ae, ao, oe and oo, leaving just the first one.
  * <p/>
  * It's is a semantically more destructive solution than {@link ScandinavianNormalizationFilter} but
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
index e158910..aa69863 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
@@ -66,7 +66,7 @@ import java.util.Arrays;
  * <ul>
  * <li><code>"PowerShot"</code> &#8594;
  * <code>0:"Power", 1:"Shot" 1:"PowerShot"</code></li>
- * <li><code>"A's+B's&C's"</code> -gt; <code>0:"A", 1:"B", 2:"C", 2:"ABC"</code>
+ * <li><code>"A's+B's&amp;C's"</code> &gt; <code>0:"A", 1:"B", 2:"C", 2:"ABC"</code>
  * </li>
  * <li><code>"Super-Duper-XL500-42-AutoCoder!"</code> &#8594;
  * <code>0:"Super", 1:"Duper", 2:"XL", 2:"SuperDuperXL", 3:"500" 4:"42", 5:"Auto", 6:"Coder", 6:"AutoCoder"</code>
@@ -97,42 +97,42 @@ public final class WordDelimiterFilter extends TokenFilter {
   /**
    * Causes parts of words to be generated:
    * <p/>
-   * "PowerShot" => "Power" "Shot"
+   * "PowerShot" =&gt; "Power" "Shot"
    */
   public static final int GENERATE_WORD_PARTS = 1;
 
   /**
    * Causes number subwords to be generated:
    * <p/>
-   * "500-42" => "500" "42"
+   * "500-42" =&gt; "500" "42"
    */
   public static final int GENERATE_NUMBER_PARTS = 2;
 
   /**
    * Causes maximum runs of word parts to be catenated:
    * <p/>
-   * "wi-fi" => "wifi"
+   * "wi-fi" =&gt; "wifi"
    */
   public static final int CATENATE_WORDS = 4;
 
   /**
    * Causes maximum runs of word parts to be catenated:
    * <p/>
-   * "wi-fi" => "wifi"
+   * "wi-fi" =&gt; "wifi"
    */
   public static final int CATENATE_NUMBERS = 8;
 
   /**
    * Causes all subword parts to be catenated:
    * <p/>
-   * "wi-fi-4000" => "wifi4000"
+   * "wi-fi-4000" =&gt; "wifi4000"
    */
   public static final int CATENATE_ALL = 16;
 
   /**
    * Causes original words are preserved and added to the subword list (Defaults to false)
    * <p/>
-   * "500-42" => "500" "42" "500-42"
+   * "500-42" =&gt; "500" "42" "500-42"
    */
   public static final int PRESERVE_ORIGINAL = 32;
 
@@ -151,7 +151,7 @@ public final class WordDelimiterFilter extends TokenFilter {
   /**
    * Causes trailing "'s" to be removed for each subword
    * <p/>
-   * "O'Neil's" => "O", "Neil"
+   * "O'Neil's" =&gt; "O", "Neil"
    */
   public static final int STEM_ENGLISH_POSSESSIVE = 256;
   
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java
index b5c242b..faa8b4c 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterIterator.java
@@ -61,7 +61,7 @@ public final class WordDelimiterIterator {
   /**
    * If true, causes trailing "'s" to be removed for each subword. (Defaults to true)
    * <p/>
-   * "O'Neil's" => "O", "Neil"
+   * "O'Neil's" =&gt; "O", "Neil"
    */
   final boolean stemEnglishPossessive;
 
@@ -99,7 +99,7 @@ public final class WordDelimiterIterator {
    * @param charTypeTable table containing character types
    * @param splitOnCaseChange if true, causes "PowerShot" to be two tokens; ("Power-Shot" remains two parts regards)
    * @param splitOnNumerics if true, causes "j2se" to be three tokens; "j" "2" "se"
-   * @param stemEnglishPossessive if true, causes trailing "'s" to be removed for each subword: "O'Neil's" => "O", "Neil"
+   * @param stemEnglishPossessive if true, causes trailing "'s" to be removed for each subword: "O'Neil's" =&gt; "O", "Neil"
    */
   WordDelimiterIterator(byte[] charTypeTable, boolean splitOnCaseChange, boolean splitOnNumerics, boolean stemEnglishPossessive) {
     this.charTypeTable = charTypeTable;
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
index 2e24147..40ba69e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/ngram/NGramTokenizer.java
@@ -33,7 +33,7 @@ import org.apache.lucene.util.AttributeFactory;
  * that characters between startOffset and endOffset in the original stream are
  * the same as the term chars.
  * <p>For example, "abcde" would be tokenized as (minGram=2, maxGram=3):
- * <table>
+ * <table summary="ngram tokens example">
  * <tr><th>Term</th><td>ab</td><td>abc</td><td>bc</td><td>bcd</td><td>cd</td><td>cde</td><td>de</td></tr>
  * <tr><th>Position increment</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
  * <tr><th>Position length</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java
index 0c1c01f..038a99e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizer.java
@@ -41,7 +41,7 @@ import org.apache.lucene.util.AttributeFactory;
  * {@link String#split(java.lang.String)}
  * </p>
  * <p>
- * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
+ * Using group &gt;= 0 selects the matching group as the token.  For example, if you have:<br/>
  * <pre>
  *  pattern = \'([^\']+)\'
  *  group = 0
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
index 15ef4c3..f48d4c8 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTokenizerFactory.java
@@ -38,7 +38,7 @@ import org.apache.lucene.util.AttributeFactory;
  * {@link String#split(java.lang.String)}
  * </p>
  * <p>
- * Using group >= 0 selects the matching group as the token.  For example, if you have:<br/>
+ * Using group &gt;= 0 selects the matching group as the token.  For example, if you have:<br/>
  * <pre>
  *  pattern = \'([^\']+)\'
  *  group = 0
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
index c9dee41..9e3e3d5 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
@@ -24,10 +24,10 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import java.io.IOException;
 
 /**
- * Reverse token string, for example "country" => "yrtnuoc".
+ * Reverse token string, for example "country" =&gt; "yrtnuoc".
  * <p>
  * If <code>marker</code> is supplied, then tokens will be also prepended by
- * that character. For example, with a marker of &#x5C;u0001, "country" =>
+ * that character. For example, with a marker of &#x5C;u0001, "country" =&gt;
  * "&#x5C;u0001yrtnuoc". This is useful when implementing efficient leading
  * wildcards search.
  */
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
index fb105f5..c5de5e6 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/shingle/ShingleFilter.java
@@ -39,7 +39,7 @@ import org.apache.lucene.util.AttributeSource;
  * might be tokenized into shingles "please divide", "divide this",
  * "this sentence", "sentence into", and "into shingles".
  *
- * <p>This filter handles position increments > 1 by inserting filler tokens
+ * <p>This filter handles position increments &gt; 1 by inserting filler tokens
  * (tokens with termtext "_"). It does not handle a position increment of 0.
  */
 public final class ShingleFilter extends TokenFilter {
@@ -356,7 +356,7 @@ public final class ShingleFilter extends TokenFilter {
 
   /**
    * <p>Get the next token from the input stream.
-   * <p>If the next token has <code>positionIncrement > 1</code>,
+   * <p>If the next token has <code>positionIncrement &gt; 1</code>,
    * <code>positionIncrement - 1</code> {@link #fillerToken}s are
    * inserted first.
    * @param target Where to put the new token; if null, a new instance is created.
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java
index 860ef98..f74c1ff 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SolrSynonymParser.java
@@ -32,11 +32,11 @@ import org.apache.lucene.util.CharsRefBuilder;
  * Parser for the Solr synonyms format.
  * <ol>
  *   <li> Blank lines and lines starting with '#' are comments.
- *   <li> Explicit mappings match any token sequence on the LHS of "=>"
+ *   <li> Explicit mappings match any token sequence on the LHS of "=&gt;"
  *        and replace with all alternatives on the RHS.  These types of mappings
  *        ignore the expand parameter in the constructor.
  *        Example:
- *        <blockquote>i-pod, i pod => ipod</blockquote>
+ *        <blockquote>i-pod, i pod =&gt; ipod</blockquote>
  *   <li> Equivalent synonyms may be separated with commas and give
  *        no explicit mapping.  In this case the mapping behavior will
  *        be taken from the expand parameter in the constructor.  This allows
@@ -47,10 +47,10 @@ import org.apache.lucene.util.CharsRefBuilder;
  *   <li> Multiple synonym mapping entries are merged.
  *        Example:
  *        <blockquote>
- *         foo => foo bar<br>
- *         foo => baz<br><br>
+ *         foo =&gt; foo bar<br>
+ *         foo =&gt; baz<br><br>
  *         is equivalent to<br><br>
- *         foo => foo bar, baz
+ *         foo =&gt; foo bar, baz
  *        </blockquote>
  *  </ol>
  * @lucene.experimental
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
index 0da2090..cf49bc5 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymFilter.java
@@ -50,9 +50,9 @@ import org.apache.lucene.util.fst.FST;
  * For example if you have these rules:
  *      
  * <pre>
- *   a -> x
- *   a b -> y
- *   b c d -> z
+ *   a -&gt; x
+ *   a b -&gt; y
+ *   b c d -&gt; z
  * </pre>
  *
  * Then input <code>a b c d e</code> parses to <code>y b c
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
index 7c5799c..0fedd4e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
@@ -192,7 +192,7 @@ public class SynonymMap {
     }
     
     /**
-     * Add a phrase->phrase synonym mapping.
+     * Add a phrase-&gt;phrase synonym mapping.
      * Phrases are character sequences where words are
      * separated with character zero (U+0000).  Empty words
      * (two U+0000s in a row) are not allowed in the input nor
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
index 105f214..e8afb5e 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
@@ -84,7 +84,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
    * unigram or a bigram It also will not return a token for the final position
    * if the final word is already in the preceding bigram Example:(three
    * tokens/positions in)
-   * "foo bar the"=>"foo:1|bar:2,bar-the:2|the:3=> "foo" "bar-the" (2 tokens
+   * "foo bar the"=&gt;"foo:1|bar:2,bar-the:2|the:3=&gt; "foo" "bar-the" (2 tokens
    * out)
    * 
    */
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/Test64kAffixes.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/Test64kAffixes.java
index f585f9f..f36209c 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/Test64kAffixes.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/Test64kAffixes.java
@@ -27,7 +27,7 @@ import java.util.List;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.LuceneTestCase;
 
-/** Tests that > 64k affixes actually works and doesnt overflow some internal int */
+/** Tests that &gt; 64k affixes actually works and doesnt overflow some internal int */
 public class Test64kAffixes extends LuceneTestCase {
   
   public void test() throws Exception {
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java
index 41747ee..6c0cd47 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/lv/TestLatvianStemmer.java
@@ -55,7 +55,7 @@ public class TestLatvianStemmer extends BaseTokenStreamTestCase {
   }
   
   /**
-   * decl II nouns with (s,t) -> 코 and (d,z) -> 
+   * decl II nouns with (s,t) -&gt; 코 and (d,z) -&gt; 
    * palatalization will generally conflate to two stems
    * due to the ambiguity (plural and singular).
    */
@@ -151,7 +151,7 @@ public class TestLatvianStemmer extends BaseTokenStreamTestCase {
   }
   
   /**
-   * Genitive plural forms with (s,t) -> 코 and (d,z) -> 
+   * Genitive plural forms with (s,t) -&gt; 코 and (d,z) -&gt; 
    * will not conflate due to ambiguity.
    */
   public void testNouns5() throws IOException {
@@ -240,7 +240,7 @@ public class TestLatvianStemmer extends BaseTokenStreamTestCase {
   
   /**
    * Note: we intentionally don't handle the ambiguous
-   * (s,t) -> 코 and (d,z) -> 
+   * (s,t) -&gt; 코 and (d,z) -&gt; 
    */
   public void testPalatalization() throws IOException {
     checkOneTerm(a, "kr?sns", "kr?sn"); // nom. sing.
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
index d2d9711..12974f5 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
@@ -39,7 +39,7 @@ import static org.apache.lucene.analysis.miscellaneous.WordDelimiterIterator.DEF
  */
 public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
 
-  /***
+  /*
   public void testPerformance() throws IOException {
     String s = "now is the time-for all good men to come to-the aid of their country.";
     Token tok = new Token();
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
index f3cf4b8..1dd88d8 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
@@ -281,7 +281,7 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
    * A demonstration of how backtracking regular expressions can lead to relatively 
    * easy DoS attacks.
    * 
-   * @see "http://swtch.com/~rsc/regexp/regexp1.html"
+   * @see <a href="http://swtch.com/~rsc/regexp/regexp1.html">"http://swtch.com/~rsc/regexp/regexp1.html"</a>
    */
   @Ignore
   public void testNastyPattern() throws Exception {
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
index 79da29f..222b5ce 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
@@ -28,8 +28,8 @@ import java.io.Reader;
  * <p>
  * Sequences of iteration marks are supported.  In case an illegal sequence of iteration
  * marks is encountered, the implementation emits the illegal source character as-is
- * without considering its script.  For example, with input "&#x003f;&#x309d", we get
- * "&#x003f;&#x003f" even though "&#x003f;" isn't hiragana.
+ * without considering its script.  For example, with input "&#x003f;&#x309d;", we get
+ * "&#x003f;&#x003f;" even though "&#x003f;" isn't hiragana.
  * </p>
  * <p>
  * Note that a full stop punctuation character "&#x3002;" (U+3002) can not be iterated
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
index 8fe2dd1..614c739 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
@@ -62,8 +62,8 @@ import org.apache.lucene.util.fst.FST;
  * <p>
  * This tokenizer uses a rolling Viterbi search to find the 
  * least cost segmentation (path) of the incoming characters.  
- * For tokens that appear to be compound (> length 2 for all
- * Kanji, or > length 7 for non-Kanji), we see if there is a
+ * For tokens that appear to be compound (&gt; length 2 for all
+ * Kanji, or &gt; length 7 for non-Kanji), we see if there is a
  * 2nd best segmentation of that token after applying
  * penalties to the long tokens.  If so, and the Mode is
  * {@link Mode#SEARCH}, we output the alternate segmentation 
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
index 9c18391..ad3bcc0 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
@@ -158,7 +158,7 @@ public class Token {
 
   /**
    * Set the position length (in tokens) of this token.  For normal
-   * tokens this is 1; for compound tokens it's > 1.
+   * tokens this is 1; for compound tokens it's &gt; 1.
    */
   public void setPositionLength(int positionLength) {
     this.positionLength = positionLength;
@@ -166,7 +166,7 @@ public class Token {
   
   /**
    * Get the length (in tokens) of this token.  For normal
-   * tokens this is 1; for compound tokens it's > 1.
+   * tokens this is 1; for compound tokens it's &gt; 1.
    * @return position length of token
    */
   public int getPositionLength() {
diff --git a/lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java b/lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java
index a6b04fc..568ad5a 100644
--- a/lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java
+++ b/lucene/analysis/morfologik/src/java/org/apache/lucene/analysis/morfologik/MorfologikAnalyzer.java
@@ -40,7 +40,7 @@ public class MorfologikAnalyzer extends Analyzer {
    * and have an associated <code>.info</code> metadata file. See the Morfologik project
    * for details.
    * 
-   * @see "http://morfologik.blogspot.com/"
+   * @see <a href="http://morfologik.blogspot.com/">http://morfologik.blogspot.com/</a>
    */
   public MorfologikAnalyzer(final String dictionaryResource) {
     this.dictionary = dictionaryResource;
diff --git a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
index 401a22b..bd1b006 100644
--- a/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
+++ b/lucene/analysis/smartcn/src/java/org/apache/lucene/analysis/cn/smart/Utility.java
@@ -58,7 +58,7 @@ public class Utility {
    * @param lstartIndex start offset into larray
    * @param rarray right array
    * @param rstartIndex start offset into rarray
-   * @return 0 if the arrays are equal庸?1 if larray > rarray, -1 if larray < rarray
+   * @return 0 if the arrays are equal庸?1 if larray &gt; rarray, -1 if larray &lt; rarray
    */
   public static int compareArray(char[] larray, int lstartIndex, char[] rarray,
       int rstartIndex) {
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/QueryMaker.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/QueryMaker.java
index 749136b..f4b4668 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/QueryMaker.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/QueryMaker.java
@@ -30,7 +30,7 @@ public interface QueryMaker {
   /** 
    * Create the next query, of the given size.
    * @param size the size of the query - number of terms, etc.
-   * @exception Exception if cannot make the query, or if size>0 was specified but this feature is not supported.
+   * @exception Exception if cannot make the query, or if size &gt; 0 was specified but this feature is not supported.
    */ 
   public Query makeQuery (int size) throws Exception;
 
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SpatialFileQueryMaker.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SpatialFileQueryMaker.java
index 4497b28..498e839 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SpatialFileQueryMaker.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/SpatialFileQueryMaker.java
@@ -39,7 +39,7 @@ import java.util.Properties;
  * It's parsed by {@link com.spatial4j.core.context.SpatialContext#readShapeFromWkt(String)} (String)} and then
  * further manipulated via a configurable {@link SpatialDocMaker.ShapeConverter}. When using point
  * data, it's likely you'll want to configure the shape converter so that the query shapes actually
- * cover a region. The queries are all created & cached in advance. This query maker works in
+ * cover a region. The queries are all created and cached in advance. This query maker works in
  * conjunction with {@link SpatialDocMaker}.  See spatial.alg for a listing of options, in
  * particular the options starting with "query.".
  */
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask.java
index 1d7cdf0..b96b33e 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/AnalyzerFactoryTask.java
@@ -393,7 +393,7 @@ public class AnalyzerFactoryTask extends PerfTask {
   /**
    * This method looks up a class with its fully qualified name (FQN), or a short-name
    * class-simplename, or with a package suffix, assuming "org.apache.lucene.analysis."
-   * as the package prefix (e.g. "standard.ClassicTokenizerFactory" ->
+   * as the package prefix (e.g. "standard.ClassicTokenizerFactory" -&gt;
    * "org.apache.lucene.analysis.standard.ClassicTokenizerFactory").
    *
    * If className contains a period, the class is first looked up as-is, assuming that it
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewAnalyzerTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewAnalyzerTask.java
index c3e02e3..b83aa9a 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewAnalyzerTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/NewAnalyzerTask.java
@@ -99,7 +99,7 @@ public class NewAnalyzerTask extends PerfTask {
    * <p/>
    * Analyzer names may also refer to previously defined AnalyzerFactory's.
    * <p/>
-   * Example Declaration: {"NewAnalyzer" NewAnalyzer(WhitespaceAnalyzer, SimpleAnalyzer, StopAnalyzer, standard.StandardAnalyzer) >
+   * Example Declaration: {"NewAnalyzer" NewAnalyzer(WhitespaceAnalyzer, SimpleAnalyzer, StopAnalyzer, standard.StandardAnalyzer) &gt;
    * <p/>
    * Example AnalyzerFactory usage:
    * <pre>
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
index 4480f1c..74f8bcd 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/ReadTask.java
@@ -268,7 +268,7 @@ public abstract class ReadTask extends PerfTask {
   }
 
   /**
-   * Return true if, with search & results traversing, docs should be retrieved.
+   * Return true if, with search and results traversing, docs should be retrieved.
    */
   public abstract boolean withRetrieve();
 
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java
index 63c5f33..f18ce10 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetHighlightTask.java
@@ -53,7 +53,7 @@ import java.util.Collections;
  * <li>fields - The fields to highlight.  If not specified all fields will be highlighted (or at least attempted)</li>
  * </ul>
  * Example:
- * <pre>"SearchHlgtSameRdr" SearchTravRetHighlight(size[10],highlight[10],mergeContiguous[true],maxFrags[3],fields[body]) > : 1000
+ * <pre>"SearchHlgtSameRdr" SearchTravRetHighlight(size[10],highlight[10],mergeContiguous[true],maxFrags[3],fields[body]) &gt; : 1000
  * </pre>
  *
  * Documents must be stored in order for this task to work.  Additionally, term vector positions can be used as well.
diff --git a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java
index 6d9eeb3..8559030 100644
--- a/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java
+++ b/lucene/benchmark/src/java/org/apache/lucene/benchmark/byTask/tasks/SearchTravRetVectorHighlightTask.java
@@ -47,7 +47,7 @@ import java.util.Collections;
  * <li>fields - The fields to highlight.  If not specified all fields will be highlighted (or at least attempted)</li>
  * </ul>
  * Example:
- * <pre>"SearchVecHlgtSameRdr" SearchTravRetVectorHighlight(size[10],highlight[10],maxFrags[3],fields[body]) > : 1000
+ * <pre>"SearchVecHlgtSameRdr" SearchTravRetVectorHighlight(size[10],highlight[10],maxFrags[3],fields[body]) &gt; : 1000
  * </pre>
  *
  * Fields must be stored and term vector offsets and positions in order must be true for this task to work.
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/TermsIndexReaderBase.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/TermsIndexReaderBase.java
index e34dedb..42698dd 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/TermsIndexReaderBase.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/TermsIndexReaderBase.java
@@ -55,7 +55,7 @@ public abstract class TermsIndexReaderBase implements Closeable, Accountable {
    */
   public static abstract class FieldIndexEnum {
 
-    /** Seeks to "largest" indexed term that's <=
+    /** Seeks to "largest" indexed term that's &lt;=
      *  term; returns file pointer index (into the main
      *  terms index file) for that term */
     public abstract long seek(BytesRef term) throws IOException;
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexWriter.java
index b213558..ec12623 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blockterms/VariableGapTermsIndexWriter.java
@@ -109,7 +109,7 @@ public class VariableGapTermsIndexWriter extends TermsIndexWriterBase {
     }
   }
 
-  /** Sets an index term when docFreq >= docFreqThresh, or
+  /** Sets an index term when docFreq &gt;= docFreqThresh, or
    *  every interval terms.  This should reduce seek time
    *  to high docFreq terms.  */
   public static final class EveryNOrDocFreqTermSelector extends IndexTermSelector {
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsWriter.java b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsWriter.java
index 649a1e5..8ea40c1 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsWriter.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/blocktreeords/OrdsBlockTreeTermsWriter.java
@@ -82,7 +82,7 @@ import org.apache.lucene.util.packed.PackedInts;
 
 /**
  * This is just like {@link BlockTreeTermsWriter}, except it also stores a version per term, and adds a method to its TermsEnum
- * implementation to seekExact only if the version is >= the specified version.  The version is added to the terms index to avoid seeking if
+ * implementation to seekExact only if the version is &gt;= the specified version.  The version is added to the terms index to avoid seeking if
  * no term in the block has a high enough version.  The term blocks file is .tiv and the terms index extension is .tipv.
  *
  * @lucene.experimental
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
index 0e5e45c..7136b42 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/DirectPostingsFormat.java
@@ -56,7 +56,7 @@ import org.apache.lucene.util.automaton.Transition;
 
 /** Wraps {@link Lucene50PostingsFormat} format for on-disk
  *  storage, but then at read time loads and stores all
- *  terms & postings directly in RAM as byte[], int[].
+ *  terms and postings directly in RAM as byte[], int[].
  *
  *  <p><b><font color=red>WARNING</font></b>: This is
  *  exceptionally RAM intensive: it makes no effort to
@@ -91,7 +91,7 @@ public final class DirectPostingsFormat extends PostingsFormat {
   
   /** minSkipCount is how many terms in a row must have the
    *  same prefix before we put a skip pointer down.  Terms
-   *  with docFreq <= lowFreqCutoff will use a single int[]
+   *  with docFreq &lt;= lowFreqCutoff will use a single int[]
    *  to hold all docs, freqs, position and offsets; terms
    *  with higher docFreq will use separate arrays. */
   public DirectPostingsFormat(int minSkipCount, int lowFreqCutoff) {
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
index 62c31c2..90c3525 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTOrdTermsReader.java
@@ -753,7 +753,7 @@ public class FSTOrdTermsReader extends FieldsProducer {
       }
 
       /** Load frame for target arc(node) on fst, so that 
-       *  arc.label >= label and !fsa.reject(arc.label) */
+       *  arc.label &gt;= label and !fsa.reject(arc.label) */
       Frame loadCeilFrame(int label, Frame top, Frame frame) throws IOException {
         FST.Arc<Long> arc = frame.arc;
         arc = Util.readCeilArc(label, fst, top.arc, arc, fstReader);
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
index 3cbd2ec..ee8629c 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/FSTTermsReader.java
@@ -650,7 +650,7 @@ public class FSTTermsReader extends FieldsProducer {
       }
 
       /** Load frame for target arc(node) on fst, so that 
-       *  arc.label >= label and !fsa.reject(arc.label) */
+       *  arc.label &gt;= label and !fsa.reject(arc.label) */
       Frame loadCeilFrame(int label, Frame top, Frame frame) throws IOException {
         FST.Arc<FSTTermOutputs.TermData> arc = frame.fstArc;
         arc = Util.readCeilArc(label, fst, top.fstArc, arc, fstReader);
diff --git a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
index 32f21e2..1c96d9d 100644
--- a/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
+++ b/lucene/codecs/src/java/org/apache/lucene/codecs/memory/MemoryPostingsFormat.java
@@ -69,7 +69,7 @@ import org.apache.lucene.util.packed.PackedInts;
 // it pulls the FST directly from what you wrote w/o going
 // to disk.
 
-/** Stores terms & postings (docs, positions, payloads) in
+/** Stores terms and postings (docs, positions, payloads) in
  *  RAM, using an FST.
  *
  * <p>Note that this codec implements advance as a linear
diff --git a/lucene/common-build.xml b/lucene/common-build.xml
index a5c7092..7ee1bfd 100644
--- a/lucene/common-build.xml
+++ b/lucene/common-build.xml
@@ -164,7 +164,7 @@
   <property name="javac.debug" value="on"/>
   <property name="javac.source" value="1.8"/>
   <property name="javac.target" value="1.8"/>
-  <property name="javac.args" value="-Xlint -Xlint:-deprecation -Xlint:-serial -Xlint:-options"/>
+  <property name="javac.args" value="-Xlint -Xlint:-deprecation -Xlint:-serial -Xlint:-options -Xdoclint:all/protected -Xdoclint:-html -Xdoclint:-missing"/>
   <property name="javadoc.link" value="http://download.oracle.com/javase/8/docs/api/"/>
   <property name="javadoc.link.junit" value="http://junit.sourceforge.net/javadoc/"/>
   <property name="javadoc.packagelist.dir" location="${common.dir}/tools/javadoc"/>
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Token.java b/lucene/core/src/java/org/apache/lucene/analysis/Token.java
index c3bfecb..f0a66f5 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Token.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Token.java
@@ -79,8 +79,8 @@ public class Token extends PackedTokenAttributeImpl implements FlagsAttribute, P
   public Token() {
   }
 
-  /** Constructs a Token with the given term text, and start
-   *  & end offsets.  The type defaults to "word."
+  /** Constructs a Token with the given term text, start
+   *  and end offsets.  The type defaults to "word."
    *  <b>NOTE:</b> for better indexing speed you should
    *  instead use the char[] termBuffer methods to set the
    *  term text.
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton.java b/lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton.java
index aedaa43..5899e99 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/TokenStreamToAutomaton.java
@@ -78,7 +78,7 @@ public class TokenStreamToAutomaton {
     }
   }
 
-  /** Subclass & implement this if you need to change the
+  /** Subclass and implement this if you need to change the
    *  token (such as escaping certain bytes) before it's
    *  turned into a graph. */ 
   protected BytesRef changeToken(BytesRef in) {
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
index a8f5b9c..f9ec8ea 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/tokenattributes/CharTermAttribute.java
@@ -48,7 +48,7 @@ public interface CharTermAttribute extends Attribute, CharSequence, Appendable {
   /** Grows the termBuffer to at least size newSize, preserving the
    *  existing content.
    *  @param newSize minimum size of the new termBuffer
-   *  @return newly created termBuffer with length >= newSize
+   *  @return newly created termBuffer with {@code length >= newSize}
    */
   public char[] resizeBuffer(int newSize);
 
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/CodecUtil.java b/lucene/core/src/java/org/apache/lucene/codecs/CodecUtil.java
index 269d48d..fc85a23 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/CodecUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/CodecUtil.java
@@ -178,7 +178,7 @@ public final class CodecUtil {
    * @param maxVersion The maximum supported expected version number.
    * @return The actual version found, when a valid header is found 
    *         that matches <code>codec</code>, with an actual version 
-   *         where <code>minVersion <= actual <= maxVersion</code>.
+   *         where {@code minVersion <= actual <= maxVersion}.
    *         Otherwise an exception is thrown.
    * @throws CorruptIndexException If the first four bytes are not
    *         {@link #CODEC_MAGIC}, or if the actual codec found is
@@ -238,7 +238,7 @@ public final class CodecUtil {
    * @param expectedSuffix The expected auxiliary suffix for this file.
    * @return The actual version found, when a valid header is found 
    *         that matches <code>codec</code>, with an actual version 
-   *         where <code>minVersion <= actual <= maxVersion</code>, 
+   *         where {@code minVersion <= actual <= maxVersion}, 
    *         and matching <code>expectedID</code> and <code>expectedSuffix</code>
    *         Otherwise an exception is thrown.
    * @throws CorruptIndexException If the first four bytes are not
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListWriter.java b/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListWriter.java
index a90ee4a..5fbb820 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/MultiLevelSkipListWriter.java
@@ -42,7 +42,7 @@ import org.apache.lucene.util.MathUtil;
  * Skip level i contains every skipInterval-th entry from skip level i-1.
  * Therefore the number of entries on level i is: floor(df / ((skipInterval ^ (i + 1))).
  * 
- * Each skip entry on a level i>0 contains a pointer to the corresponding skip entry in list i-1.
+ * Each skip entry on a level {@code i>0} contains a pointer to the corresponding skip entry in list i-1.
  * This guarantees a logarithmic amount of skips to find the target document.
  * 
  * While this class takes care of writing the different skip levels,
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
index 73d1659..35ebba1 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/PushPostingsWriterBase.java
@@ -183,7 +183,7 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
    * for the field. */
   public abstract void startDoc(int docID, int freq) throws IOException;
 
-  /** Add a new position & payload, and start/end offset.  A
+  /** Add a new position and payload, and start/end offset.  A
    *  null payload means no payload; a non-null payload with
    *  zero length also means no payload.  Caller may reuse
    *  the {@link BytesRef} for the payload between calls
@@ -191,7 +191,7 @@ public abstract class PushPostingsWriterBase extends PostingsWriterBase {
    *  and <code>endOffset</code> will be -1 when offsets are not indexed. */
   public abstract void addPosition(int position, BytesRef payload, int startOffset, int endOffset) throws IOException;
 
-  /** Called when we are done adding positions & payloads
+  /** Called when we are done adding positions and payloads
    *  for each doc. */
   public abstract void finishDoc() throws IOException;
 }
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders.java b/lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders.java
index c980690..b784694 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/compressing/MatchingReaders.java
@@ -22,7 +22,7 @@ import org.apache.lucene.index.MergeState;
 import org.apache.lucene.index.SegmentReader;
 
 /** 
- * Computes which segments have identical field name->number mappings,
+ * Computes which segments have identical field name to number mappings,
  * which allows stored fields and term vectors in this codec to be bulk-merged.
  */
 class MatchingReaders {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/ForUtil.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/ForUtil.java
index 97b9998..10cbadc 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/ForUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/ForUtil.java
@@ -50,7 +50,7 @@ final class ForUtil {
    * Upper limit of the number of values that might be decoded in a single call to
    * {@link #readBlock(IndexInput, byte[], int[])}. Although values after
    * <code>BLOCK_SIZE</code> are garbage, it is necessary to allocate value buffers
-   * whose size is >= MAX_DATA_SIZE to avoid {@link ArrayIndexOutOfBoundsException}s.
+   * whose size is {@code >= MAX_DATA_SIZE} to avoid {@link ArrayIndexOutOfBoundsException}s.
    */
   static final int MAX_DATA_SIZE;
   static {
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer.java
index f0120c9..0a8b979 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesConsumer.java
@@ -81,10 +81,10 @@ class Lucene50DocValuesConsumer extends DocValuesConsumer implements Closeable {
   public static final int BINARY_PREFIX_COMPRESSED = 2;
 
   /** Standard storage for sorted set values with 1 level of indirection:
-   *  docId -> address -> ord. */
+   *  {@code docId -> address -> ord}. */
   public static final int SORTED_WITH_ADDRESSES = 0;
   /** Single-valued sorted set values, encoded as sorted values, so no level
-   *  of indirection: docId -> ord. */
+   *  of indirection: {@code docId -> ord}. */
   public static final int SORTED_SINGLE_VALUED = 1;
   
   /** placeholder for missing offset that means there are no missing values */
diff --git a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesFormat.java b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesFormat.java
index 5027b29..02aa211 100644
--- a/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesFormat.java
+++ b/lucene/core/src/java/org/apache/lucene/codecs/lucene50/Lucene50DocValuesFormat.java
@@ -131,7 +131,7 @@ import org.apache.lucene.util.packed.MonotonicBlockPackedWriter;
  *      <ul>
  *         <li>0 --&gt; delta-compressed. For each block of 16k integers, every integer is delta-encoded
  *             from the minimum value within the block. 
- *         <li>1 --&gt, gcd-compressed. When all integers share a common divisor, only quotients are stored
+ *         <li>1 --&gt; gcd-compressed. When all integers share a common divisor, only quotients are stored
  *             using blocks of delta-encoded ints.
  *         <li>2 --&gt; table-compressed. When the number of unique numeric values is small and it would save space,
  *             a lookup table of unique values is written, followed by the ordinal for each document.
@@ -141,7 +141,7 @@ import org.apache.lucene.util.packed.MonotonicBlockPackedWriter;
  *   <p>BinaryType indicates how Binary values will be stored:
  *      <ul>
  *         <li>0 --&gt; fixed-width. All values have the same length, addressing by multiplication. 
- *         <li>1 --&gt, variable-width. An address for each value is stored.
+ *         <li>1 --&gt; variable-width. An address for each value is stored.
  *         <li>2 --&gt; prefix-compressed. An address to the start of every interval'th value is stored.
  *      </ul>
  *   <p>MinLength and MaxLength represent the min and max byte[] value lengths for Binary values.
diff --git a/lucene/core/src/java/org/apache/lucene/index/AutomatonTermsEnum.java b/lucene/core/src/java/org/apache/lucene/index/AutomatonTermsEnum.java
index 94044a6..9ab40b8 100644
--- a/lucene/core/src/java/org/apache/lucene/index/AutomatonTermsEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/index/AutomatonTermsEnum.java
@@ -305,7 +305,7 @@ class AutomatonTermsEnum extends FilteredTermsEnum {
    * can match.
    * 
    * @param position current position in the input String
-   * @return position >=0 if more possible solutions exist for the DFA
+   * @return {@code position >= 0} if more possible solutions exist for the DFA
    */
   private int backtrack(int position) {
     while (position-- > 0) {
diff --git a/lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java b/lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java
index 256002a..a5d7f85 100644
--- a/lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java
+++ b/lucene/core/src/java/org/apache/lucene/index/ConcurrentMergeScheduler.java
@@ -162,7 +162,7 @@ public class ConcurrentMergeScheduler extends MergeScheduler {
   };
 
   /**
-   * Called whenever the running merges have changed, to pause & unpause
+   * Called whenever the running merges have changed, to pause and unpause
    * threads. This method sorts the merge threads by their merge size in
    * descending order and then pauses/unpauses threads from first to last --
    * that way, smaller merges are guaranteed to run before larger ones.
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocValuesType.java b/lucene/core/src/java/org/apache/lucene/index/DocValuesType.java
index 014d479..74ad33a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocValuesType.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocValuesType.java
@@ -40,7 +40,7 @@ public enum DocValuesType {
    * A pre-sorted byte[]. Fields with this type only store distinct byte values 
    * and store an additional offset pointer per document to dereference the shared 
    * byte[]. The stored byte[] is presorted and allows access via document id, 
-   * ordinal and by-value.  Values must be <= 32766 bytes.
+   * ordinal and by-value.  Values must be {@code <= 32766} bytes.
    */
   SORTED,
   /** 
@@ -52,7 +52,7 @@ public enum DocValuesType {
    * A pre-sorted Set&lt;byte[]&gt;. Fields with this type only store distinct byte values 
    * and store additional offset pointers per document to dereference the shared 
    * byte[]s. The stored byte[] is presorted and allows access via document id, 
-   * ordinal and by-value.  Values must be <= 32766 bytes.
+   * ordinal and by-value.  Values must be {@code <= 32766} bytes.
    */
   SORTED_SET,
 }
diff --git a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
index 898f2cd..b2ef272 100644
--- a/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
+++ b/lucene/core/src/java/org/apache/lucene/index/DocumentsWriterFlushQueue.java
@@ -178,7 +178,7 @@ class DocumentsWriterFlushQueue {
     /**
      * Publishes the flushed segment, segment private deletes (if any) and its
      * associated global delete (if present) to IndexWriter.  The actual
-     * publishing operation is synced on IW -> BDS so that the {@link SegmentInfo}'s
+     * publishing operation is synced on {@code IW -> BDS} so that the {@link SegmentInfo}'s
      * delete generation is always GlobalPacket_deleteGeneration + 1
      */
     protected final void publishFlushedSegment(IndexWriter indexWriter, FlushedSegment newSegment, FrozenBufferedUpdates globalPacket)
diff --git a/lucene/core/src/java/org/apache/lucene/index/FlushByRamOrCountsPolicy.java b/lucene/core/src/java/org/apache/lucene/index/FlushByRamOrCountsPolicy.java
index eb1aea1..547d63c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/FlushByRamOrCountsPolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/index/FlushByRamOrCountsPolicy.java
@@ -53,7 +53,7 @@ import org.apache.lucene.index.DocumentsWriterPerThreadPool.ThreadState;
  * <p>
  * If {@link IndexWriterConfig#setRAMBufferSizeMB(double)} is enabled, the
  * largest ram consuming {@link DocumentsWriterPerThread} will be marked as
- * pending iff the global active RAM consumption is >= the configured max RAM
+ * pending iff the global active RAM consumption is {@code >=} the configured max RAM
  * buffer.
  */
 class FlushByRamOrCountsPolicy extends FlushPolicy {
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexCommit.java b/lucene/core/src/java/org/apache/lucene/index/IndexCommit.java
index 115f218..b2ac396 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexCommit.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexCommit.java
@@ -108,7 +108,7 @@ public abstract class IndexCommit implements Comparable<IndexCommit> {
 
   /** Returns userData, previously passed to {@link
    *  IndexWriter#setCommitData(Map)} for this commit.  Map is
-   *  String -> String. */
+   *  {@code String -> String}. */
   public abstract Map<String,String> getUserData() throws IOException;
   
   @Override
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java b/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java
index a0859d1..5ba1079 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexFileNames.java
@@ -56,7 +56,7 @@ public final class IndexFileNames {
   /**
    * Computes the full file name from base, extension and generation. If the
    * generation is -1, the file name is null. If it's 0, the file name is
-   * &lt;base&gt;.&lt;ext&gt;. If it's > 0, the file name is
+   * &lt;base&gt;.&lt;ext&gt;. If it's &gt; 0, the file name is
    * &lt;base&gt;_&lt;gen&gt;.&lt;ext&gt;.<br>
    * <b>NOTE:</b> .&lt;ext&gt; is added to the name only if <code>ext</code> is
    * not an empty string.
diff --git a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
index 595a85c..e53793a 100644
--- a/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/index/IndexWriter.java
@@ -1575,8 +1575,8 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
   final InfoStream infoStream;
 
   /**
-   * Forces merge policy to merge segments until there are <=
-   * maxNumSegments.  The actual merges to be
+   * Forces merge policy to merge segments until there are
+   * {@code <= maxNumSegments}.  The actual merges to be
    * executed are determined by the {@link MergePolicy}.
    *
    * <p>This is a horribly costly operation, especially when
@@ -1595,7 +1595,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
    * afterwards, to allow IndexWriter to free up disk space.</p>
    *
    * <p>If some but not all readers re-open while merging
-   * is underway, this will cause > 2X temporary
+   * is underway, this will cause {@code > 2X} temporary
    * space to be consumed as those new readers will then
    * hold open the temporary segments at that time.  It is
    * best not to re-open readers while merging is running.</p>
@@ -2818,7 +2818,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
   private final Object commitLock = new Object();
 
   /**
-   * <p>Commits all pending changes (added & deleted
+   * <p>Commits all pending changes (added and deleted
    * documents, segment merges, added
    * indexes, etc.) to the index, and syncs all referenced
    * index files, such that a reader will see the changes
@@ -2830,7 +2830,7 @@ public class IndexWriter implements Closeable, TwoPhaseCommit, Accountable {
    *
    * <p> Note that this operation calls Directory.sync on
    * the index files.  That call should not return until the
-   * file contents & metadata are on stable storage.  For
+   * file contents and metadata are on stable storage.  For
    * FSDirectory, this calls the OS's fsync.  But, beware:
    * some hardware devices may in fact cache writes even
    * during fsync, and return before the bits are actually
diff --git a/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java b/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
index b5638db..1172d5c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/index/LogMergePolicy.java
@@ -60,7 +60,7 @@ public abstract class LogMergePolicy extends MergePolicy {
    *  or larger will never be merged.  @see setMaxMergeDocs */
   public static final int DEFAULT_MAX_MERGE_DOCS = Integer.MAX_VALUE;
 
-  /** Default noCFSRatio.  If a merge's size is >= 10% of
+  /** Default noCFSRatio.  If a merge's size is {@code >= 10%} of
    *  the index, then we disable compound file for it.
    *  @see MergePolicy#setNoCFSRatio */
   public static final double DEFAULT_NO_CFS_RATIO = 0.1;
@@ -124,8 +124,8 @@ public abstract class LogMergePolicy extends MergePolicy {
    * faster, but indexing speed is slower.  With larger
    * values, more RAM is used during indexing, and while
    * searches is slower, indexing is
-   * faster.  Thus larger values (> 10) are best for batch
-   * index creation, and smaller values (< 10) for indices
+   * faster.  Thus larger values ({@code > 10}) are best for batch
+   * index creation, and smaller values ({@code < 10}) for indices
    * that are interactively maintained. */
   public void setMergeFactor(int mergeFactor) {
     if (mergeFactor < 2)
diff --git a/lucene/core/src/java/org/apache/lucene/index/MergePolicy.java b/lucene/core/src/java/org/apache/lucene/index/MergePolicy.java
index 8c1d830..30fedad 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MergePolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MergePolicy.java
@@ -420,7 +420,7 @@ public abstract class MergePolicy {
 
   /**
    * Determine what set of merge operations is necessary in
-   * order to merge to <= the specified segment count. {@link IndexWriter} calls this when its
+   * order to merge to {@code <=} the specified segment count. {@link IndexWriter} calls this when its
    * {@link IndexWriter#forceMerge} method is called. This call is always
    * synchronized on the {@link IndexWriter} instance so only one thread at a
    * time will call this method.
diff --git a/lucene/core/src/java/org/apache/lucene/index/MultiFields.java b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
index fc2179a..8a6dd0c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
+++ b/lucene/core/src/java/org/apache/lucene/index/MultiFields.java
@@ -120,14 +120,14 @@ public final class MultiFields extends Fields {
     return getFields(r).terms(field);
   }
   
-  /** Returns {@link DocsEnum} for the specified field &
+  /** Returns {@link DocsEnum} for the specified field and
    *  term.  This will return null if the field or term does
    *  not exist. */
   public static DocsEnum getTermDocsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
     return getTermDocsEnum(r, liveDocs, field, term, DocsEnum.FLAG_FREQS);
   }
   
-  /** Returns {@link DocsEnum} for the specified field &
+  /** Returns {@link DocsEnum} for the specified field and
    *  term, with control over whether freqs are required.
    *  Some codecs may be able to optimize their
    *  implementation when freqs are not required.  This will
@@ -147,7 +147,7 @@ public final class MultiFields extends Fields {
   }
 
   /** Returns {@link DocsAndPositionsEnum} for the specified
-   *  field & term.  This will return null if the field or
+   *  field and term.  This will return null if the field or
    *  term does not exist or positions were not indexed. 
    *  @see #getTermPositionsEnum(IndexReader, Bits, String, BytesRef, int) */
   public static DocsAndPositionsEnum getTermPositionsEnum(IndexReader r, Bits liveDocs, String field, BytesRef term) throws IOException {
@@ -155,7 +155,7 @@ public final class MultiFields extends Fields {
   }
 
   /** Returns {@link DocsAndPositionsEnum} for the specified
-   *  field & term, with control over whether offsets and payloads are
+   *  field and term, with control over whether offsets and payloads are
    *  required.  Some codecs may be able to optimize
    *  their implementation when offsets and/or payloads are not
    *  required. This will return null if the field or term does not
diff --git a/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java b/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
index 58abc36..7549be2 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SegmentInfos.java
@@ -676,7 +676,7 @@ public final class SegmentInfos implements Cloneable, Iterable<SegmentCommitInfo
     return dest;
   }
 
-  /** Writes & syncs to the Directory dir, taking care to
+  /** Writes and syncs to the Directory dir, taking care to
    *  remove the segments file on exception
    *  <p>
    *  Note: {@link #changed()} should be called prior to this
diff --git a/lucene/core/src/java/org/apache/lucene/index/SortedDocValues.java b/lucene/core/src/java/org/apache/lucene/index/SortedDocValues.java
index b789742..774180d 100644
--- a/lucene/core/src/java/org/apache/lucene/index/SortedDocValues.java
+++ b/lucene/core/src/java/org/apache/lucene/index/SortedDocValues.java
@@ -46,7 +46,7 @@ public abstract class SortedDocValues extends BinaryDocValues {
    * {@link BytesRef} may be re-used across calls to {@link #lookupOrd(int)}
    * so make sure to {@link BytesRef#deepCopyOf(BytesRef) copy it} if you want
    * to keep it around.
-   * @param ord ordinal to lookup (must be &gt;= 0 and &lt {@link #getValueCount()})
+   * @param ord ordinal to lookup (must be &gt;= 0 and &lt; {@link #getValueCount()})
    * @see #getOrd(int) 
    */
   public abstract BytesRef lookupOrd(int ord);
diff --git a/lucene/core/src/java/org/apache/lucene/index/Terms.java b/lucene/core/src/java/org/apache/lucene/index/Terms.java
index 9169bd8..613debb 100644
--- a/lucene/core/src/java/org/apache/lucene/index/Terms.java
+++ b/lucene/core/src/java/org/apache/lucene/index/Terms.java
@@ -46,7 +46,7 @@ public abstract class Terms {
    *  are accepted by the provided {@link
    *  CompiledAutomaton}.  If the <code>startTerm</code> is
    *  provided then the returned enum will only accept terms
-   *  > <code>startTerm</code>, but you still must call
+   *  {@code > startTerm}, but you still must call
    *  next() first to get to the first term.  Note that the
    *  provided <code>startTerm</code> must be accepted by
    *  the automaton.
diff --git a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
index a0856f3..4c51e5c 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TermsHashPerField.java
@@ -91,7 +91,7 @@ abstract class TermsHashPerField implements Comparable<TermsHashPerField> {
 
   int[] sortedTermIDs;
 
-  /** Collapse the hash table & sort in-place; also sets
+  /** Collapse the hash table and sort in-place; also sets
    * this.sortedTermIDs to the results */
   public int[] sortPostings() {
     sortedTermIDs = bytesHash.sort(BytesRef.getUTF8SortedAsUnicodeComparator());
diff --git a/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java b/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
index 049c067..d6a691e 100644
--- a/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
+++ b/lucene/core/src/java/org/apache/lucene/index/TieredMergePolicy.java
@@ -73,7 +73,7 @@ import java.util.Map;
 //     maybe CMS should do so)
 
 public class TieredMergePolicy extends MergePolicy {
-  /** Default noCFSRatio.  If a merge's size is >= 10% of
+  /** Default noCFSRatio.  If a merge's size is {@code >= 10%} of
    *  the index, then we disable compound file for it.
    *  @see MergePolicy#setNoCFSRatio */
   public static final double DEFAULT_NO_CFS_RATIO = 0.1;
@@ -215,7 +215,7 @@ public class TieredMergePolicy extends MergePolicy {
   /** Sets the allowed number of segments per tier.  Smaller
    *  values mean more merging but fewer segments.
    *
-   *  <p><b>NOTE</b>: this value should be >= the {@link
+   *  <p><b>NOTE</b>: this value should be {@code >=} the {@link
    *  #setMaxMergeAtOnce} otherwise you'll force too much
    *  merging to occur.</p>
    *
diff --git a/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java b/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java
index dd9e171..9951d19 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java
@@ -98,9 +98,9 @@ public abstract class FieldComparator<T> {
    * 
    * @param slot1 first slot to compare
    * @param slot2 second slot to compare
-   * @return any N < 0 if slot2's value is sorted after
-   * slot1, any N > 0 if the slot2's value is sorted before
-   * slot1 and 0 if they are equal
+   * @return any {@code N < 0} if slot2's value is sorted after
+   * slot1, any {@code N > 0} if the slot2's value is sorted before
+   * slot1 and {@code 0} if they are equal
    */
   public abstract int compare(int slot1, int slot2);
 
@@ -134,9 +134,9 @@ public abstract class FieldComparator<T> {
    * frequently).</p>
    * 
    * @param doc that was hit
-   * @return any N < 0 if the doc's value is sorted after
-   * the bottom entry (not competitive), any N > 0 if the
-   * doc's value is sorted before the bottom entry and 0 if
+   * @return any {@code N < 0} if the doc's value is sorted after
+   * the bottom entry (not competitive), any {@code N > 0} if the
+   * doc's value is sorted before the bottom entry and {@code 0} if
    * they are equal.
    */
   public abstract int compareBottom(int doc) throws IOException;
@@ -150,9 +150,9 @@ public abstract class FieldComparator<T> {
    * use searchAfter (deep paging).
    *    
    * @param doc that was hit
-   * @return any N < 0 if the doc's value is sorted after
-   * the bottom entry (not competitive), any N > 0 if the
-   * doc's value is sorted before the bottom entry and 0 if
+   * @return any {@code N < 0} if the doc's value is sorted after
+   * the bottom entry (not competitive), any {@code N > 0} if the
+   * doc's value is sorted before the bottom entry and {@code 0} if
    * they are equal.
    */
   public abstract int compareTop(int doc) throws IOException;
diff --git a/lucene/core/src/java/org/apache/lucene/search/FuzzyQuery.java b/lucene/core/src/java/org/apache/lucene/search/FuzzyQuery.java
index 89413ce..0d9f608 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FuzzyQuery.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FuzzyQuery.java
@@ -71,7 +71,7 @@ public class FuzzyQuery extends MultiTermQuery {
    * of that length is also required.
    * 
    * @param term the term to search for
-   * @param maxEdits must be >= 0 and <= {@link LevenshteinAutomata#MAXIMUM_SUPPORTED_DISTANCE}.
+   * @param maxEdits must be {@code >= 0} and {@code <=} {@link LevenshteinAutomata#MAXIMUM_SUPPORTED_DISTANCE}.
    * @param prefixLength length of common (non-fuzzy) prefix
    * @param maxExpansions the maximum number of terms to match. If this number is
    *  greater than {@link BooleanQuery#getMaxClauseCount} when the query is rewritten, 
diff --git a/lucene/core/src/java/org/apache/lucene/search/LiveFieldValues.java b/lucene/core/src/java/org/apache/lucene/search/LiveFieldValues.java
index bed6533..16cfb66 100644
--- a/lucene/core/src/java/org/apache/lucene/search/LiveFieldValues.java
+++ b/lucene/core/src/java/org/apache/lucene/search/LiveFieldValues.java
@@ -126,7 +126,7 @@ public abstract class LiveFieldValues<S,T> implements ReferenceManager.RefreshLi
     }
   }
 
-  /** This is called when the id/value was already flushed & opened
+  /** This is called when the id/value was already flushed and opened
    *  in an NRT IndexSearcher.  You must implement this to
    *  go look up the value (eg, via doc values, field cache,
    *  stored fields, etc.). */
diff --git a/lucene/core/src/java/org/apache/lucene/search/TopDocsCollector.java b/lucene/core/src/java/org/apache/lucene/search/TopDocsCollector.java
index bd0687e..cbef3b3 100644
--- a/lucene/core/src/java/org/apache/lucene/search/TopDocsCollector.java
+++ b/lucene/core/src/java/org/apache/lucene/search/TopDocsCollector.java
@@ -94,8 +94,8 @@ public abstract class TopDocsCollector<T extends ScoreDoc> extends SimpleCollect
   }
 
   /**
-   * Returns the documents in the rage [start .. pq.size()) that were collected
-   * by this collector. Note that if start >= pq.size(), an empty TopDocs is
+   * Returns the documents in the range [start .. pq.size()) that were collected
+   * by this collector. Note that if {@code start >= pq.size()}, an empty TopDocs is
    * returned.<br>
    * This method is convenient to call if the application always asks for the
    * last results, starting from the last 'page'.<br>
@@ -113,8 +113,8 @@ public abstract class TopDocsCollector<T extends ScoreDoc> extends SimpleCollect
   }
 
   /**
-   * Returns the documents in the rage [start .. start+howMany) that were
-   * collected by this collector. Note that if start >= pq.size(), an empty
+   * Returns the documents in the range [start .. start+howMany) that were
+   * collected by this collector. Note that if {@code start >= pq.size()}, an empty
    * TopDocs is returned, and if pq.size() - start &lt; howMany, then only the
    * available documents in [start .. pq.size()) are returned.<br>
    * This method is useful to call in case pagination of search results is
diff --git a/lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBase.java b/lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBase.java
index 4e99e1c..37f63e2 100644
--- a/lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBase.java
+++ b/lucene/core/src/java/org/apache/lucene/search/similarities/SimilarityBase.java
@@ -216,7 +216,7 @@ public abstract class SimilarityBase extends Similarity {
 
   // ------------------------------ Norm handling ------------------------------
   
-  /** Norm -> document length map. */
+  /** Norm to document length map. */
   private static final float[] NORM_TABLE = new float[256];
 
   static {
diff --git a/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java b/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
index 4e914e3..d56c7d3 100644
--- a/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
+++ b/lucene/core/src/java/org/apache/lucene/search/similarities/TFIDFSimilarity.java
@@ -80,17 +80,17 @@ import org.apache.lucene.util.BytesRef;
  * of the weighted query vectors <i>V(q)</i> and <i>V(d)</i>:
  *
  *  <br>&nbsp;<br>
- *  <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto">
+ *  <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto" summary="formatting only">
  *    <tr><td>
- *    <table cellpadding="1" cellspacing="0" border="1" align="center">
+ *    <table cellpadding="1" cellspacing="0" border="1" align="center" summary="formatting only">
  *      <tr><td>
- *      <table cellpadding="2" cellspacing="2" border="0" align="center">
+ *      <table cellpadding="2" cellspacing="2" border="0" align="center" summary="cosine similarity formula">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            cosine-similarity(q,d) &nbsp; = &nbsp;
  *          </td>
  *          <td valign="middle" align="center">
- *            <table>
+ *            <table summary="cosine similarity formula">
  *               <tr><td align="center" style="text-align: center"><small>V(q)&nbsp;&middot;&nbsp;V(d)</small></td></tr>
  *               <tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>
  *               <tr><td align="center" style="text-align: center"><small>|V(q)|&nbsp;|V(d)|</small></td></tr>
@@ -165,11 +165,11 @@ import org.apache.lucene.util.BytesRef;
  * we get <i>Lucene's Conceptual scoring formula</i>:
  *
  *  <br>&nbsp;<br>
- *  <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto">
+ *  <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto" summary="formatting only">
  *    <tr><td>
- *    <table cellpadding="1" cellspacing="0" border="1" align="center">
+ *    <table cellpadding="1" cellspacing="0" border="1" align="center" summary="formatting only">
  *      <tr><td>
- *      <table cellpadding="2" cellspacing="2" border="0" align="center">
+ *      <table cellpadding="2" cellspacing="2" border="0" align="center" summary="formatting only">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            score(q,d) &nbsp; = &nbsp;
@@ -177,7 +177,7 @@ import org.apache.lucene.util.BytesRef;
  *            <font color="#CCCC00">query-boost(q)</font> &middot; &nbsp;
  *          </td>
  *          <td valign="middle" align="center">
- *            <table>
+ *            <table summary="Lucene conceptual scoring formula">
  *               <tr><td align="center" style="text-align: center"><small><font color="#993399">V(q)&nbsp;&middot;&nbsp;V(d)</font></small></td></tr>
  *               <tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>
  *               <tr><td align="center" style="text-align: center"><small><font color="#FF33CC">|V(q)|</font></small></td></tr>
@@ -257,11 +257,11 @@ import org.apache.lucene.util.BytesRef;
  * to those of the <i>conceptual</i> formula:
  *
  * <P>
- * <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto">
+ * <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto" summary="formatting only">
  *  <tr><td>
- *  <table cellpadding="" cellspacing="2" border="2" align="center">
+ *  <table cellpadding="" cellspacing="2" border="2" align="center" summary="formatting only">
  *  <tr><td>
- *   <table cellpadding="2" cellspacing="2" border="0" align="center">
+ *   <table cellpadding="2" cellspacing="2" border="0" align="center" summary="Lucene conceptual scoring formula">
  *   <tr>
  *     <td valign="middle" align="right" rowspan="1">
  *       score(q,d) &nbsp; = &nbsp;
@@ -310,7 +310,7 @@ import org.apache.lucene.util.BytesRef;
  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#tf(float) DefaultSimilarity} is:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto">
+ *      <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto" summary="term frequency computation">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            {@link org.apache.lucene.search.similarities.DefaultSimilarity#tf(float) tf(t in d)} &nbsp; = &nbsp;
@@ -335,7 +335,7 @@ import org.apache.lucene.util.BytesRef;
  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#idf(long, long) DefaultSimilarity} is:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto">
+ *      <table cellpadding="2" cellspacing="2" border="0" align="center" style="width:auto" summary="inverse document frequency computation">
  *        <tr>
  *          <td valign="middle" align="right">
  *            {@link org.apache.lucene.search.similarities.DefaultSimilarity#idf(long, long) idf(t)}&nbsp; = &nbsp;
@@ -344,7 +344,7 @@ import org.apache.lucene.util.BytesRef;
  *            1 + log <big>(</big>
  *          </td>
  *          <td valign="middle" align="center">
- *            <table>
+ *            <table summary="inverse document frequency computation">
  *               <tr><td align="center" style="text-align: center"><small>numDocs</small></td></tr>
  *               <tr><td align="center" style="text-align: center">&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;</td></tr>
  *               <tr><td align="center" style="text-align: center"><small>docFreq+1</small></td></tr>
@@ -383,7 +383,7 @@ import org.apache.lucene.util.BytesRef;
  *      {@link org.apache.lucene.search.similarities.DefaultSimilarity#queryNorm(float) DefaultSimilarity}
  *      produces a <a href="http://en.wikipedia.org/wiki/Euclidean_norm#Euclidean_norm">Euclidean norm</a>:
  *      <br>&nbsp;<br>
- *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto">
+ *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto" summary="query normalization computation">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            queryNorm(q)  &nbsp; = &nbsp;
@@ -391,7 +391,7 @@ import org.apache.lucene.util.BytesRef;
  *            &nbsp; = &nbsp;
  *          </td>
  *          <td valign="middle" align="center" rowspan="1">
- *            <table>
+ *            <table summary="query normalization computation">
  *               <tr><td align="center" style="text-align: center"><big>1</big></td></tr>
  *               <tr><td align="center" style="text-align: center"><big>
  *                  &ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;&ndash;
@@ -409,7 +409,7 @@ import org.apache.lucene.util.BytesRef;
  *      computes this value as:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto">
+ *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto" summary="sum of squared weights computation">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            {@link org.apache.lucene.search.Weight#getValueForNormalization() sumOfSquaredWeights} &nbsp; = &nbsp;
@@ -475,7 +475,7 @@ import org.apache.lucene.util.BytesRef;
  *      If the document has multiple fields with the same name, all their boosts are multiplied together:
  *
  *      <br>&nbsp;<br>
- *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto">
+ *      <table cellpadding="1" cellspacing="0" border="0" align="center" style="width:auto" summary="index-time normalization">
  *        <tr>
  *          <td valign="middle" align="right" rowspan="1">
  *            norm(t,d) &nbsp; = &nbsp;
diff --git a/lucene/core/src/java/org/apache/lucene/search/spans/Spans.java b/lucene/core/src/java/org/apache/lucene/search/spans/Spans.java
index d177abb..8bb6ed9 100644
--- a/lucene/core/src/java/org/apache/lucene/search/spans/Spans.java
+++ b/lucene/core/src/java/org/apache/lucene/search/spans/Spans.java
@@ -34,12 +34,13 @@ public abstract class Spans {
    * <code> target &le; current</code>, or after the iterator has exhausted.
    * Both cases may result in unpredicted behavior.
    * <p>Returns true iff there is such
-   * a match.  <p>Behaves as if written: <pre class="prettyprint">
+   * a match.  <p>Behaves as if written: 
+   * <pre class="prettyprint">
    *   boolean skipTo(int target) {
    *     do {
    *       if (!next())
    *         return false;
-   *     } while (target > doc());
+   *     } while (target &gt; doc());
    *     return true;
    *   }
    * </pre>
diff --git a/lucene/core/src/java/org/apache/lucene/store/DataOutput.java b/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
index 724e586..f1f8c0b 100644
--- a/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
+++ b/lucene/core/src/java/org/apache/lucene/store/DataOutput.java
@@ -91,7 +91,7 @@ public abstract class DataOutput {
    * resulting integer value. Thus values from zero to 127 may be stored in a single
    * byte, values from 128 to 16,383 may be stored in two bytes, and so on.</p>
    * <p>VByte Encoding Example</p>
-   * <table cellspacing="0" cellpadding="2" border="0">
+   * <table cellspacing="0" cellpadding="2" border="0" summary="variable length encoding examples">
    * <col width="64*">
    * <col width="64*">
    * <col width="64*">
diff --git a/lucene/core/src/java/org/apache/lucene/store/LockStressTest.java b/lucene/core/src/java/org/apache/lucene/store/LockStressTest.java
index 59a1c6a..d4156b2 100644
--- a/lucene/core/src/java/org/apache/lucene/store/LockStressTest.java
+++ b/lucene/core/src/java/org/apache/lucene/store/LockStressTest.java
@@ -27,7 +27,7 @@ import java.nio.file.Paths;
 import java.util.Random;
 
 /**
- * Simple standalone tool that forever acquires & releases a
+ * Simple standalone tool that forever acquires and releases a
  * lock using a specific LockFactory.  Run without any args
  * to see usage.
  *
diff --git a/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java b/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
index 25742e4..e4ecd70 100644
--- a/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
+++ b/lucene/core/src/java/org/apache/lucene/store/NRTCachingDirectory.java
@@ -58,7 +58,7 @@ import org.apache.lucene.util.IOUtils;
  * </pre>
  *
  * <p>This will cache all newly flushed segments, all merges
- * whose expected segment size is <= 5 MB, unless the net
+ * whose expected segment size is {@code <= 5 MB}, unless the net
  * cached bytes exceeds 60 MB at which point all writes will
  * not be cached (until the net bytes falls below 60 MB).</p>
  *
@@ -77,9 +77,9 @@ public class NRTCachingDirectory extends FilterDirectory implements Accountable
 
   /**
    *  We will cache a newly created output if 1) it's a
-   *  flush or a merge and the estimated size of the merged segment is <=
-   *  maxMergeSizeMB, and 2) the total cached bytes is <=
-   *  maxCachedMB */
+   *  flush or a merge and the estimated size of the merged segment is 
+   *  {@code <= maxMergeSizeMB}, and 2) the total cached bytes is 
+   *  {@code <= maxCachedMB} */
   public NRTCachingDirectory(Directory delegate, double maxMergeSizeMB, double maxCachedMB) {
     super(delegate);
     maxMergeSizeBytes = (long) (maxMergeSizeMB*1024*1024);
diff --git a/lucene/core/src/java/org/apache/lucene/store/RateLimiter.java b/lucene/core/src/java/org/apache/lucene/store/RateLimiter.java
index e028ed9..b5759f6 100644
--- a/lucene/core/src/java/org/apache/lucene/store/RateLimiter.java
+++ b/lucene/core/src/java/org/apache/lucene/store/RateLimiter.java
@@ -93,7 +93,7 @@ public abstract class RateLimiter {
     
     /** Pauses, if necessary, to keep the instantaneous IO
      *  rate at or below the target.  Be sure to only call
-     *  this method when bytes > {@link #getMinPauseCheckBytes},
+     *  this method when bytes &gt; {@link #getMinPauseCheckBytes},
      *  otherwise it will pause way too long!
      *
      *  @return the pause time in nano seconds */  
diff --git a/lucene/core/src/java/org/apache/lucene/store/VerifyingLockFactory.java b/lucene/core/src/java/org/apache/lucene/store/VerifyingLockFactory.java
index 7039181..2dafe9a 100644
--- a/lucene/core/src/java/org/apache/lucene/store/VerifyingLockFactory.java
+++ b/lucene/core/src/java/org/apache/lucene/store/VerifyingLockFactory.java
@@ -29,7 +29,7 @@ import java.io.OutputStream;
  * external server ({@link LockVerifyServer}) to assert that
  * at most one process holds the lock at a time.  To use
  * this, you should also run {@link LockVerifyServer} on the
- * host & port matching what you pass to the constructor.
+ * host and port matching what you pass to the constructor.
  *
  * @see LockVerifyServer
  * @see LockStressTest
diff --git a/lucene/core/src/java/org/apache/lucene/util/ArrayUtil.java b/lucene/core/src/java/org/apache/lucene/util/ArrayUtil.java
index c750138..e52a568 100644
--- a/lucene/core/src/java/org/apache/lucene/util/ArrayUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/util/ArrayUtil.java
@@ -134,7 +134,7 @@ public final class ArrayUtil {
  END APACHE HARMONY CODE
   */
 
-  /** Returns an array size >= minTargetSize, generally
+  /** Returns an array size &gt;= minTargetSize, generally
    *  over-allocating exponentially to achieve amortized
    *  linear-time cost as the array grows.
    *
diff --git a/lucene/core/src/java/org/apache/lucene/util/BitUtil.java b/lucene/core/src/java/org/apache/lucene/util/BitUtil.java
index f6c2622..a6439e1 100644
--- a/lucene/core/src/java/org/apache/lucene/util/BitUtil.java
+++ b/lucene/core/src/java/org/apache/lucene/util/BitUtil.java
@@ -46,7 +46,7 @@ public final class BitUtil {
   // packed inside a 32 bit integer (8 4 bit numbers).  That
   // should be faster than accessing an array for each index, and
   // the total array size is kept smaller (256*sizeof(int))=1K
-  /***** the python code that generated bitlist
+  /* the python code that generated bitlist
   def bits2int(val):
   arr=0
   for shift in range(8,0,-1):
@@ -58,7 +58,7 @@ public final class BitUtil {
   def int_table():
     tbl = [ hex(bits2int(val)).strip('L') for val in range(256) ]
     return ','.join(tbl)
-  ******/
+  */
   private static final int[] BIT_LISTS = {
     0x0, 0x1, 0x2, 0x21, 0x3, 0x31, 0x32, 0x321, 0x4, 0x41, 0x42, 0x421, 0x43, 
     0x431, 0x432, 0x4321, 0x5, 0x51, 0x52, 0x521, 0x53, 0x531, 0x532, 0x5321, 
@@ -98,12 +98,12 @@ public final class BitUtil {
   }
 
   /** Return the list of bits which are set in b encoded as followed:
-   * <code>(i >>> (4 * n)) & 0x0F</code> is the offset of the n-th set bit of
+   * {@code (i >>> (4 * n)) & 0x0F} is the offset of the n-th set bit of
    * the given byte plus one, or 0 if there are n or less bits set in the given
    * byte. For example <code>bitList(12)</code> returns 0x43:<ul>
-   * <li><code>0x43 & 0x0F</code> is 3, meaning the the first bit set is at offset 3-1 = 2,</li>
-   * <li><code>(0x43 >>> 4) & 0x0F</code> is 4, meaning there is a second bit set at offset 4-1=3,</li>
-   * <li><code>(0x43 >>> 8) & 0x0F</code> is 0, meaning there is no more bit set in this byte.</li>
+   * <li>{@code 0x43 & 0x0F} is 3, meaning the the first bit set is at offset 3-1 = 2,</li>
+   * <li>{@code (0x43 >>> 4) & 0x0F} is 4, meaning there is a second bit set at offset 4-1=3,</li>
+   * <li>{@code (0x43 >>> 8) & 0x0F} is 0, meaning there is no more bit set in this byte.</li>
    * </ul>*/
   public static int bitList(byte b) {
     return BIT_LISTS[b & 0xFF];
@@ -142,7 +142,7 @@ public final class BitUtil {
      return popCount;
    }
 
-  /** Returns the popcount or cardinality of A & ~B.
+  /** Returns the popcount or cardinality of {@code A & ~B}.
    *  Neither array is modified. */
   public static long pop_andnot(long[] arr1, long[] arr2, int wordOffset, int numWords) {
     long popCount = 0;
diff --git a/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java b/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
index f02e1d0..ec5c4cf 100644
--- a/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
+++ b/lucene/core/src/java/org/apache/lucene/util/BytesRefHash.java
@@ -266,7 +266,7 @@ public final class BytesRefHash {
    *         haven't been hashed before.
    * 
    * @throws MaxBytesLengthExceededException
-   *           if the given bytes are > 2 +
+   *           if the given bytes are {@code > 2 +}
    *           {@link ByteBlockPool#BYTE_BLOCK_SIZE}
    */
   public int add(BytesRef bytes) {
@@ -403,7 +403,7 @@ public final class BytesRefHash {
   }
 
   /**
-   * Called when hash is too small (> 50% occupied) or too large (< 20%
+   * Called when hash is too small ({@code > 50%} occupied) or too large ({@code < 20%}
    * occupied).
    */
   private void rehash(final int newSize, boolean hashOnData) {
diff --git a/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java b/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
index f26bdb5..d0ff941 100644
--- a/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
+++ b/lucene/core/src/java/org/apache/lucene/util/PagedBytes.java
@@ -186,7 +186,7 @@ public final class PagedBytes implements Accountable {
 
   /** Copy BytesRef in, setting BytesRef out to the result.
    * Do not use this if you will use freeze(true).
-   * This only supports bytes.length <= blockSize */
+   * This only supports bytes.length &lt;= blockSize */
   public void copy(BytesRef bytes, BytesRef out) {
     int left = blockSize - upto;
     if (bytes.length > left || currentBlock==null) {
diff --git a/lucene/core/src/java/org/apache/lucene/util/SentinelIntSet.java b/lucene/core/src/java/org/apache/lucene/util/SentinelIntSet.java
index a32148f..3be7890 100644
--- a/lucene/core/src/java/org/apache/lucene/util/SentinelIntSet.java
+++ b/lucene/core/src/java/org/apache/lucene/util/SentinelIntSet.java
@@ -22,7 +22,7 @@ import java.util.Arrays;
 /**
  * A native int hash-based set where one value is reserved to mean "EMPTY" internally. The space overhead is fairly low
  * as there is only one power-of-two sized int[] to hold the values.  The set is re-hashed when adding a value that
- * would make it >= 75% full.  Consider extending and over-riding {@link #hash(int)} if the values might be poor
+ * would make it &gt;= 75% full.  Consider extending and over-riding {@link #hash(int)} if the values might be poor
  * hash keys; Lucene docids should be fine.
  * The internal fields are exposed publicly to enable more efficient use at the expense of better O-O principles.
  * <p/>
diff --git a/lucene/core/src/java/org/apache/lucene/util/VirtualMethod.java b/lucene/core/src/java/org/apache/lucene/util/VirtualMethod.java
index 7c54c3d..10d2be7 100644
--- a/lucene/core/src/java/org/apache/lucene/util/VirtualMethod.java
+++ b/lucene/core/src/java/org/apache/lucene/util/VirtualMethod.java
@@ -43,11 +43,11 @@ import java.util.Set;
  * instance's class, use a <strong>non-static</strong> field:</p>
  * <pre class="prettyprint">
  *  final boolean isDeprecatedMethodOverridden =
- *   oldMethod.getImplementationDistance(this.getClass()) > newMethod.getImplementationDistance(this.getClass());
+ *   oldMethod.getImplementationDistance(this.getClass()) &gt; newMethod.getImplementationDistance(this.getClass());
  *
  *  <em>// alternatively (more readable):</em>
  *  final boolean isDeprecatedMethodOverridden =
- *   VirtualMethod.compareImplementationDistance(this.getClass(), oldMethod, newMethod) > 0
+ *   VirtualMethod.compareImplementationDistance(this.getClass(), oldMethod, newMethod) &gt; 0
  * </pre> 
  * <p>{@link #getImplementationDistance} returns the distance of the subclass that overrides this method.
  * The one with the larger distance should be used preferable.
diff --git a/lucene/core/src/java/org/apache/lucene/util/automaton/Automata.java b/lucene/core/src/java/org/apache/lucene/util/automaton/Automata.java
index 2d327cf..76523e8 100644
--- a/lucene/core/src/java/org/apache/lucene/util/automaton/Automata.java
+++ b/lucene/core/src/java/org/apache/lucene/util/automaton/Automata.java
@@ -211,10 +211,10 @@ final public class Automata {
    * @param min minimal value of interval
    * @param max maximal value of interval (both end points are included in the
    *          interval)
-   * @param digits if >0, use fixed number of digits (strings must be prefixed
+   * @param digits if &gt; 0, use fixed number of digits (strings must be prefixed
    *          by 0's to obtain the right length) - otherwise, the number of
    *          digits is not fixed (any number of leading 0s is accepted)
-   * @exception IllegalArgumentException if min>max or if numbers in the
+   * @exception IllegalArgumentException if min &gt; max or if numbers in the
    *              interval cannot be expressed with the given fixed number of
    *              digits
    */
diff --git a/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java b/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
index 79fb518..f5c93c9 100644
--- a/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
+++ b/lucene/core/src/java/org/apache/lucene/util/automaton/CompiledAutomaton.java
@@ -297,7 +297,7 @@ public class CompiledAutomaton {
   }
 
   /** Finds largest term accepted by this Automaton, that's
-   *  <= the provided input term.  The result is placed in
+   *  &lt;= the provided input term.  The result is placed in
    *  output; it's fine for output and input to point to
    *  the same bytes.  The returned result is either the
    *  provided output, or null if there is no floor term
diff --git a/lucene/core/src/java/org/apache/lucene/util/automaton/RegExp.java b/lucene/core/src/java/org/apache/lucene/util/automaton/RegExp.java
index da07fc3..ebea907 100644
--- a/lucene/core/src/java/org/apache/lucene/util/automaton/RegExp.java
+++ b/lucene/core/src/java/org/apache/lucene/util/automaton/RegExp.java
@@ -41,7 +41,7 @@ import java.util.Set;
  * <p>
  * Regular expressions are built from the following abstract syntax:
  * <p>
- * <table border=0>
+ * <table border=0 summary="description of regular expression grammar">
  * <tr>
  * <td><i>regexp</i></td>
  * <td>::=</td>
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java b/lucene/core/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java
index 53f3585..9fc1ee1 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java
@@ -58,7 +58,7 @@ public final class BytesRefFSTEnum<T> extends FSTEnum<T> {
     return setResult();
   }
 
-  /** Seeks to smallest term that's >= target. */
+  /** Seeks to smallest term that's &gt;= target. */
   public InputOutput<T> seekCeil(BytesRef target) throws IOException {
     this.target = target;
     targetLength = target.length;
@@ -66,7 +66,7 @@ public final class BytesRefFSTEnum<T> extends FSTEnum<T> {
     return setResult();
   }
 
-  /** Seeks to biggest term that's <= target. */
+  /** Seeks to biggest term that's &lt;= target. */
   public InputOutput<T> seekFloor(BytesRef target) throws IOException {
     this.target = target;
     targetLength = target.length;
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java b/lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
index 0c089af..8a5176c 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/BytesStore.java
@@ -75,7 +75,7 @@ class BytesStore extends DataOutput implements Accountable {
     nextWrite = blocks.get(blocks.size()-1).length;
   }
 
-  /** Absolute write byte; you must ensure dest is < max
+  /** Absolute write byte; you must ensure dest is &lt; max
    *  position written so far. */
   public void writeByte(int dest, byte b) {
     int blockIndex = dest >> blockBits;
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java b/lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java
index 60ab642..d1f7a1a 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/FSTEnum.java
@@ -114,7 +114,7 @@ abstract class FSTEnum<T> {
   // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
   // SEEK_END)?  saves the eq check above?
 
-  /** Seeks to smallest term that's >= target. */
+  /** Seeks to smallest term that's &gt;= target. */
   protected void doSeekCeil() throws IOException {
 
     //System.out.println("    advance len=" + target.length + " curlen=" + current.length);
@@ -256,7 +256,7 @@ abstract class FSTEnum<T> {
 
   // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
   // SEEK_END)?  saves the eq check above?
-  /** Seeks to largest term that's <= target. */
+  /** Seeks to largest term that's &lt;= target. */
   protected void doSeekFloor() throws IOException {
 
     // TODO: possibly caller could/should provide common
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java b/lucene/core/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java
index d45f5a6..1a3efa9 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java
@@ -58,7 +58,7 @@ public final class IntsRefFSTEnum<T> extends FSTEnum<T> {
     return setResult();
   }
 
-  /** Seeks to smallest term that's >= target. */
+  /** Seeks to smallest term that's &gt;= target. */
   public InputOutput<T> seekCeil(IntsRef target) throws IOException {
     this.target = target;
     targetLength = target.length;
@@ -66,7 +66,7 @@ public final class IntsRefFSTEnum<T> extends FSTEnum<T> {
     return setResult();
   }
 
-  /** Seeks to biggest term that's <= target. */
+  /** Seeks to biggest term that's &lt;= target. */
   public InputOutput<T> seekFloor(IntsRef target) throws IOException {
     this.target = target;
     targetLength = target.length;
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/Outputs.java b/lucene/core/src/java/org/apache/lucene/util/fst/Outputs.java
index ac69300..fad2b6c 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/Outputs.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/Outputs.java
@@ -41,13 +41,13 @@ public abstract class Outputs<T> {
   // (new object per byte/char/int) if eg used during
   // analysis
 
-  /** Eg common("foobar", "food") -> "foo" */
+  /** Eg common("foobar", "food") -&gt; "foo" */
   public abstract T common(T output1, T output2);
 
-  /** Eg subtract("foobar", "foo") -> "bar" */
+  /** Eg subtract("foobar", "foo") -&gt; "bar" */
   public abstract T subtract(T output, T inc);
 
-  /** Eg add("foo", "bar") -> "foobar" */
+  /** Eg add("foo", "bar") -&gt; "foobar" */
   public abstract T add(T prefix, T output);
 
   /** Encode an output value into a {@link DataOutput}. */
diff --git a/lucene/core/src/java/org/apache/lucene/util/fst/Util.java b/lucene/core/src/java/org/apache/lucene/util/fst/Util.java
index 0033eaf..ebee4f2 100644
--- a/lucene/core/src/java/org/apache/lucene/util/fst/Util.java
+++ b/lucene/core/src/java/org/apache/lucene/util/fst/Util.java
@@ -588,7 +588,7 @@ public final class Util {
    * 
    * <p>
    * Note: larger FSTs (a few thousand nodes) won't even
-   * render, don't bother.  If the FST is > 2.1 GB in size
+   * render, don't bother.  If the FST is &gt; 2.1 GB in size
    * then this method will throw strange exceptions.
    * 
    * @param sameRank
@@ -600,7 +600,7 @@ public final class Util {
    *          If <code>true</code> states will have labels equal to their offsets in their
    *          binary format. Expands the graph considerably. 
    * 
-   * @see "http://www.graphviz.org/"
+   * @see <a href="http://www.graphviz.org/">graphviz project</a>
    */
   public static <T> void toDot(FST<T> fst, Writer out, boolean sameRank, boolean labelStates) 
     throws IOException {    
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/BulkOperation.java b/lucene/core/src/java/org/apache/lucene/util/packed/BulkOperation.java
index de4977a..9e5c3de 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/BulkOperation.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/BulkOperation.java
@@ -152,16 +152,16 @@ abstract class BulkOperation implements PackedInts.Decoder, PackedInts.Encoder {
    * For every number of bits per value, there is a minimum number of
    * blocks (b) / values (v) you need to write in order to reach the next block
    * boundary:
-   *  - 16 bits per value -> b=2, v=1
-   *  - 24 bits per value -> b=3, v=1
-   *  - 50 bits per value -> b=25, v=4
-   *  - 63 bits per value -> b=63, v=8
+   *  - 16 bits per value -&gt; b=2, v=1
+   *  - 24 bits per value -&gt; b=3, v=1
+   *  - 50 bits per value -&gt; b=25, v=4
+   *  - 63 bits per value -&gt; b=63, v=8
    *  - ...
    *
    * A bulk read consists in copying <code>iterations*v</code> values that are
    * contained in <code>iterations*b</code> blocks into a <code>long[]</code>
    * (higher values of <code>iterations</code> are likely to yield a better
-   * throughput) => this requires n * (b + 8v) bytes of memory.
+   * throughput): this requires n * (b + 8v) bytes of memory.
    *
    * This method computes <code>iterations</code> as
    * <code>ramBudget / (b + 8v)</code> (since a long is 8 bytes).
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/DirectReader.java b/lucene/core/src/java/org/apache/lucene/util/packed/DirectReader.java
index 999cc24..e370108 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/DirectReader.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/DirectReader.java
@@ -30,7 +30,7 @@ import org.apache.lucene.util.LongValues;
  *   int bitsPerValue = 100;
  *   IndexInput in = dir.openInput("packed", IOContext.DEFAULT);
  *   LongValues values = DirectReader.getInstance(in.randomAccessSlice(start, end), bitsPerValue);
- *   for (int i = 0; i < numValues; i++) {
+ *   for (int i = 0; i &lt; numValues; i++) {
  *     long value = values.get(i);
  *   }
  * </pre>
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/DirectWriter.java b/lucene/core/src/java/org/apache/lucene/util/packed/DirectWriter.java
index aabee78..85c7c47 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/DirectWriter.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/DirectWriter.java
@@ -27,13 +27,13 @@ import org.apache.lucene.store.IndexOutput;
  * Class for writing packed integers to be directly read from Directory.
  * Integers can be read on-the-fly via {@link DirectReader}.
  * <p>
- * Unlike PackedInts, it optimizes for read i/o operations and supports > 2B values.
+ * Unlike PackedInts, it optimizes for read i/o operations and supports &gt; 2B values.
  * Example usage:
  * <pre class="prettyprint">
  *   int bitsPerValue = DirectWriter.bitsRequired(100); // values up to and including 100
  *   IndexOutput output = dir.createOutput("packed", IOContext.DEFAULT);
  *   DirectWriter writer = DirectWriter.getInstance(output, numberOfValues, bitsPerValue);
- *   for (int i = 0; i < numberOfValues; i++) {
+ *   for (int i = 0; i &lt; numberOfValues; i++) {
  *     writer.add(value);
  *   }
  *   writer.finish();
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoDecoder.java b/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoDecoder.java
index 1fe7fcd..dfdbce8 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoDecoder.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoDecoder.java
@@ -375,7 +375,7 @@ public class EliasFanoDecoder {
 
   /** Decrement efindex and setBitForIndex and
    * shift curHighLong so that it does not contain the high bits after setBitForIndex.
-   * @return true iff efindex still >= 0
+   * @return true iff efindex still {@code >= 0}
    */
   private boolean toBeforeCurrentHighBit() {
     efIndex -= 1;
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java b/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
index 20fa78d..7a3866d 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/EliasFanoEncoder.java
@@ -29,11 +29,11 @@ import org.apache.lucene.util.ToStringUtils;
  * that was introduced in the 1970's by Peter Elias and Robert Fano.
  * <p>
  * The Elias-Fano encoding is a high bits / low bits representation of
- * a monotonically increasing sequence of <code>numValues > 0</code> natural numbers <code>x[i]</code>
+ * a monotonically increasing sequence of {@code numValues > 0} natural numbers <code>x[i]</code>
  * <p>
- * <code>0 <= x[0] <= x[1] <= ... <= x[numValues-2] <= x[numValues-1] <= upperBound</code>
+ * {@code 0 <= x[0] <= x[1] <= ... <= x[numValues-2] <= x[numValues-1] <= upperBound}
  * <p>
- * where <code>upperBound > 0</code> is an upper bound on the last value.
+ * where {@code upperBound > 0} is an upper bound on the last value.
  * <br>
  * The Elias-Fano encoding uses less than half a bit per encoded number more
  * than the smallest representation
@@ -52,7 +52,7 @@ import org.apache.lucene.util.ToStringUtils;
  * <code>0...01</code>. <br>
  * In the upper bits the total the number of 1 bits is <code>numValues</code>
  * and the total number of 0 bits is:<p>
- * <code>floor(x[numValues-1]/2**L) <= upperBound/(2**max(0, floor(log(upperBound/numValues)))) <= 2*numValues</code>
+ * {@code floor(x[numValues-1]/2**L) <= upperBound/(2**max(0, floor(log(upperBound/numValues)))) <= 2*numValues}
  * <p>
  * The Elias-Fano encoding uses at most
  * <p>
@@ -60,7 +60,7 @@ import org.apache.lucene.util.ToStringUtils;
  * <p>
  * bits per encoded number. With <code>upperBound</code> in these bounds (<code>p</code> is an integer):
  * <p>
- * <code>2**p < x[numValues-1] <= upperBound <= 2**(p+1)</code>
+ * {@code 2**p < x[numValues-1] <= upperBound <= 2**(p+1)}
  * <p>
  * the number of bits per encoded number is minimized.
  * <p>
@@ -120,7 +120,7 @@ public class EliasFanoEncoder implements Accountable {
    * @param upperBound  At least the highest value that will be encoded.
    *                For space efficiency this should not exceed the power of two that equals
    *                or is the first higher than the actual maximum.
-   *                <br>When <code>numValues >= (upperBound/3)</code>
+   *                <br>When {@code numValues >= (upperBound/3)}
    *                a {@link FixedBitSet} will take less space.
    * @param indexInterval The number of high zero bits for which a single index entry is built.
    *                The index will have at most <code>2 * numValues / indexInterval</code> entries
@@ -131,12 +131,12 @@ public class EliasFanoEncoder implements Accountable {
    *         <li><code>numValues</code> is negative, or
    *         <li><code>numValues</code> is non negative and <code>upperBound</code> is negative, or
    *         <li>the low bits do not fit in a <code>long[]</code>:
-   *             <code>(L * numValues / 64) > Integer.MAX_VALUE</code>, or
+   *             {@code (L * numValues / 64) > Integer.MAX_VALUE}, or
    *         <li>the high bits do not fit in a <code>long[]</code>:
-   *             <code>(2 * numValues / 64) > Integer.MAX_VALUE</code>, or
-   *         <li><code>indexInterval < 2</code>,
+   *             {@code (2 * numValues / 64) > Integer.MAX_VALUE}, or
+   *         <li>{@code indexInterval < 2},
    *         <li>the index bits do not fit in a <code>long[]</code>:
-   *             <code>(numValues / indexInterval * ceil(2log(3 * numValues)) / 64) > Integer.MAX_VALUE</code>.
+   *             {@code (numValues / indexInterval * ceil(2log(3 * numValues)) / 64) > Integer.MAX_VALUE}.
    *         </ul>
    */
   public EliasFanoEncoder(long numValues, long upperBound, long indexInterval) {
@@ -266,7 +266,7 @@ public class EliasFanoEncoder implements Accountable {
    *  (including some space for its index) is at most about 5/6 of the size of the FixedBitSet,
    *  this is the same as comparing estimates of the number of bits accessed by a pair of FixedBitSets and
    *  by a pair of non indexed EliasFanoDocIdSets when determining the intersections of the pairs.
-   *  <br>A bit set is preferred when <code>upperbound <= 256</code>.
+   *  <br>A bit set is preferred when {@code upperbound <= 256}.
    *  <br>It is assumed that {@link #DEFAULT_INDEX_INTERVAL} is used.
    *  @param numValues The number of document identifiers that is to be encoded. Should be non negative.
    *  @param upperBound The maximum possible value for a document identifier. Should be at least <code>numValues</code>.
diff --git a/lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java b/lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
index 1a29818..4c15e91 100644
--- a/lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
+++ b/lucene/core/src/java/org/apache/lucene/util/packed/PackedInts.java
@@ -31,7 +31,7 @@ import org.apache.lucene.util.RamUsageEstimator;
 
 /**
  * Simplistic compression for array of unsigned long values.
- * Each value is >= 0 and <= a specified maximum value.  The
+ * Each value is {@code >= 0} and {@code <=} a specified maximum value.  The
  * values are stored as packed ints, with each value
  * consuming a fixed number of bits.
  *
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
index 6036de3..a4a7504 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPositions.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
 
 /**
- * Test indexes ~82M docs with 52 positions each, so you get > Integer.MAX_VALUE positions
+ * Test indexes ~82M docs with 52 positions each, so you get &gt; Integer.MAX_VALUE positions
  * @lucene.experimental
  */
 @SuppressCodecs({ "SimpleText", "Memory", "Direct" })
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
index 2617f0f..e4fb303 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPostings.java
@@ -32,7 +32,7 @@ import org.apache.lucene.util.TimeUnits;
 import com.carrotsearch.randomizedtesting.annotations.TimeoutSuite;
 
 /**
- * Test indexes ~82M docs with 26 terms each, so you get > Integer.MAX_VALUE terms/docs pairs
+ * Test indexes ~82M docs with 26 terms each, so you get &gt; Integer.MAX_VALUE terms/docs pairs
  * @lucene.experimental
  */
 @SuppressCodecs({ "SimpleText", "Memory", "Direct", "Compressing" })
diff --git a/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java b/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
index fa41731..9e55181 100644
--- a/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
+++ b/lucene/core/src/test/org/apache/lucene/index/Test2BPostingsBytes.java
@@ -35,7 +35,7 @@ import org.apache.lucene.util.LuceneTestCase.SuppressCodecs;
 
 /**
  * Test indexes 2B docs with 65k freqs each, 
- * so you get > Integer.MAX_VALUE postings data for the term
+ * so you get &gt; Integer.MAX_VALUE postings data for the term
  * @lucene.experimental
  */
 @SuppressCodecs({ "SimpleText", "Memory", "Direct" })
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
index 371dfb1..5b97ade2 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSloppyPhraseQuery.java
@@ -55,7 +55,7 @@ public class TestSloppyPhraseQuery extends LuceneTestCase {
 
   /**
    * Test DOC_4 and QUERY_4.
-   * QUERY_4 has a fuzzy (len=1) match to DOC_4, so all slop values > 0 should succeed.
+   * QUERY_4 has a fuzzy (len=1) match to DOC_4, so all slop values &gt; 0 should succeed.
    * But only the 3rd sequence of A's in DOC_4 will do.
    */
   public void testDoc4_Query4_All_Slops_Should_match() throws Exception {
diff --git a/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java b/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
index 6c29159..068964a 100644
--- a/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
+++ b/lucene/core/src/test/org/apache/lucene/search/spans/TestBasics.java
@@ -664,7 +664,7 @@ public class TestBasics extends LuceneTestCase {
     boolean hasMore = true;
 
     do {
-      hasMore = skipToAccoringToJavaDocs(s1, s1.doc() + 1);
+      hasMore = skipToAccordingToJavaDocs(s1, s1.doc() + 1);
       assertEquals(hasMore, s2.skipTo(s2.doc() + 1));
       assertEquals(s1.doc(), s2.doc());
     } while (hasMore);
@@ -677,12 +677,12 @@ public class TestBasics extends LuceneTestCase {
    *     do {
    *       if (!next())
    *       return false;
-   *     } while (target > doc());
+   *     } while (target &gt; doc());
    *     return true;
    *   }
    * </pre>
    */
-  private boolean skipToAccoringToJavaDocs(Spans s, int target)
+  private boolean skipToAccordingToJavaDocs(Spans s, int target)
       throws Exception {
     do {
       if (!s.next())
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java b/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
index ec4593c..bfff86f 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestMultiMMap.java
@@ -33,7 +33,7 @@ import org.apache.lucene.util.TestUtil;
  * Tests MMapDirectory's MultiMMapIndexInput
  * <p>
  * Because Java's ByteBuffer uses an int to address the
- * values, it's necessary to access a file >
+ * values, it's necessary to access a file &gt;
  * Integer.MAX_VALUE in size using multiple byte buffers.
  */
 public class TestMultiMMap extends BaseDirectoryTestCase {
diff --git a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
index 49b7e7a..3e91f5d 100644
--- a/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
+++ b/lucene/core/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -1033,7 +1033,7 @@ public class TestFSTs extends LuceneTestCase {
    * Test state expansion (array format) on close-to-root states. Creates
    * synthetic input that has one expanded state on each level.
    *
-   * @see "https://issues.apache.org/jira/browse/LUCENE-2933"
+   * @see <a href="https://issues.apache.org/jira/browse/LUCENE-2933">LUCENE-2933</a>
    */
   public void testExpandedCloseToRoot() throws Exception {
     class SyntheticData {
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/DrillSideways.java b/lucene/facet/src/java/org/apache/lucene/facet/DrillSideways.java
index c8614f3..c855de6 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/DrillSideways.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/DrillSideways.java
@@ -249,7 +249,7 @@ public class DrillSideways {
   /** Result of a drill sideways search, including the
    *  {@link Facets} and {@link TopDocs}. */
   public static class DrillSidewaysResult {
-    /** Combined drill down & sideways results. */
+    /** Combined drill down and sideways results. */
     public final Facets facets;
 
     /** Hits. */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java b/lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java
index 345544b..be7d4b2 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/FacetsConfig.java
@@ -120,7 +120,7 @@ public class FacetsConfig {
   }
 
   /** Pass {@code true} if this dimension is hierarchical
-   *  (has depth > 1 paths). */
+   *  (has depth &gt; 1 paths). */
   public synchronized void setHierarchical(String dimName, boolean v) {
     DimConfig ft = fieldTypes.get(dimName);
     if (ft == null) {
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
index 587c68c..6610851 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/DoubleRangeFacetCounts.java
@@ -42,7 +42,7 @@ import org.apache.lucene.util.NumericUtils;
  *  this for dimensions that change in real-time (e.g. a
  *  relative time based dimension like "Past day", "Past 2
  *  days", etc.) or that change for each request (e.g.
- *  distance from the user's location, "< 1 km", "< 2 km",
+ *  distance from the user's location, "&lt; 1 km", "&lt; 2 km",
  *  etc.).
  *
  *  <p> If you had indexed your field using {@link
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java b/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
index 78cc719..649ba41 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/range/LongRangeFacetCounts.java
@@ -38,7 +38,7 @@ import org.apache.lucene.search.DocIdSetIterator;
  *  this for dimensions that change in real-time (e.g. a
  *  relative time based dimension like "Past day", "Past 2
  *  days", etc.) or that change for each request (e.g. 
- *  distance from the user's location, "< 1 km", "< 2 km",
+ *  distance from the user's location, "&lt; 1 km", "&lt; 2 km",
  *  etc.).
  *
  *  @lucene.experimental */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java
index 8205132..941b575 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/DocValuesOrdinalsReader.java
@@ -65,7 +65,7 @@ public class DocValuesOrdinalsReader extends OrdinalsReader {
     return field;
   }
 
-  /** Subclass & override if you change the encoding. */
+  /** Subclass and override if you change the encoding. */
   protected void decode(BytesRef buf, IntsRef ordinals) {
 
     // grow the buffer up front, even if by a large number of values (buf.length)
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalMappingLeafReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalMappingLeafReader.java
index 38589a7..a0fef04 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalMappingLeafReader.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/OrdinalMappingLeafReader.java
@@ -53,7 +53,7 @@ import org.apache.lucene.util.IntsRef;
  * IndexWriter writer = new IndexWriter(newDir, conf);
  * List&lt;LeafReaderContext&gt; leaves = reader.leaves();
  * LeafReader wrappedLeaves[] = new LeafReader[leaves.size()];
- * for (int i = 0; i < leaves.size(); i++) {
+ * for (int i = 0; i &lt; leaves.size(); i++) {
  *   wrappedLeaves[i] = new OrdinalMappingLeafReader(leaves.get(i).reader(), ordmap);
  * }
  * writer.addIndexes(new MultiReader(wrappedLeaves));
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
index a084278..a216bb9 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/directory/DirectoryTaxonomyReader.java
@@ -346,7 +346,7 @@ public class DirectoryTaxonomyReader extends TaxonomyReader {
     }
   }
 
-  /** Returns ordinal -> label mapping, up to the provided
+  /** Returns ordinal -&gt; label mapping, up to the provided
    *  max ordinal or number of ordinals, whichever is
    *  smaller. */
   public String toString(int max) {
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/LabelToOrdinal.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/LabelToOrdinal.java
index 49473be..6332621 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/LabelToOrdinal.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/LabelToOrdinal.java
@@ -20,7 +20,7 @@ import org.apache.lucene.facet.taxonomy.FacetLabel;
  */
 
 /**
- * Abstract class for storing Label->Ordinal mappings in a taxonomy. 
+ * Abstract class for storing Label-&gt;Ordinal mappings in a taxonomy. 
  * 
  * @lucene.experimental
  */
diff --git a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/TaxonomyWriterCache.java b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/TaxonomyWriterCache.java
index 5e7ffda..d5e5b40 100644
--- a/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/TaxonomyWriterCache.java
+++ b/lucene/facet/src/java/org/apache/lucene/facet/taxonomy/writercache/TaxonomyWriterCache.java
@@ -22,7 +22,7 @@ import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
 
 /**
  * TaxonomyWriterCache is a relatively simple interface for a cache of
- * category->ordinal mappings, used in TaxonomyWriter implementations (such as
+ * category-&gt;ordinal mappings, used in TaxonomyWriter implementations (such as
  * {@link DirectoryTaxonomyWriter}).
  * <p>
  * It basically has put() methods for adding a mapping, and get() for looking a
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyCombined.java b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyCombined.java
index c33a198..3af66f9 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyCombined.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/taxonomy/TestTaxonomyCombined.java
@@ -327,7 +327,7 @@ public class TestTaxonomyCombined extends FacetTestCase {
     indexDir.close();
   }
 
-  /**  Basic tests for TaxonomyReader's category <=> ordinal transformations
+  /**  Basic tests for TaxonomyReader's category &lt;=&gt; ordinal transformations
     (getSize(), getCategory() and getOrdinal()).
     We test that after writing the index, it can be read and all the
     categories and ordinals are there just as we expected them to be.
@@ -383,7 +383,7 @@ public class TestTaxonomyCombined extends FacetTestCase {
     We check it by comparing its results to those we could have gotten by
     looking at the category string paths (where the parentage is obvious).
     Note that after testReaderBasic(), we already know we can trust the
-    ordinal <=> category conversions.
+    ordinal &lt;=&gt; category conversions.
     
     Note: At the moment, the parent methods in the reader are deprecated,
     but this does not mean they should not be tested! Until they are
@@ -429,7 +429,7 @@ public class TestTaxonomyCombined extends FacetTestCase {
    * its results to those we could have gotten by looking at the category
    * string paths using a TaxonomyReader (where the parentage is obvious).
    * Note that after testReaderBasic(), we already know we can trust the
-   * ordinal <=> category conversions from TaxonomyReader.
+   * ordinal &lt;=&gt; category conversions from TaxonomyReader.
    *
    * The difference between testWriterParent1 and testWriterParent2 is that
    * the former closes the taxonomy writer before reopening it, while the
diff --git a/lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java b/lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java
index ce64abd..c383042 100644
--- a/lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java
+++ b/lucene/grouping/src/java/org/apache/lucene/search/grouping/AbstractFirstPassGroupingCollector.java
@@ -91,7 +91,7 @@ abstract public class AbstractFirstPassGroupingCollector<GROUP_VALUE_TYPE> exten
   /**
    * Returns top groups, starting from offset.  This may
    * return null, if no groups were collected, or if the
-   * number of unique groups collected is <= offset.
+   * number of unique groups collected is &lt;= offset.
    *
    * @param groupOffset The offset in the collected groups
    * @param fillFields Whether to fill to {@link SearchGroup#sortValues}
diff --git a/lucene/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java b/lucene/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
index 503ffbe..4c0c6b5 100644
--- a/lucene/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
+++ b/lucene/grouping/src/java/org/apache/lucene/search/grouping/BlockGroupingCollector.java
@@ -293,7 +293,7 @@ public class BlockGroupingCollector extends SimpleCollector {
   // in the UI?
 
   /** Returns the grouped results.  Returns null if the
-   *  number of groups collected is <= groupOffset.
+   *  number of groups collected is &lt;= groupOffset.
    *
    *  <p><b>NOTE</b>: This collector is unable to compute
    *  the groupValue per group so it will always be null.
diff --git a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
index bb0c2dc..2f5fe0a 100644
--- a/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
+++ b/lucene/highlighter/src/java/org/apache/lucene/search/highlight/WeightedSpanTermExtractor.java
@@ -84,7 +84,7 @@ public class WeightedSpanTermExtractor {
   }
 
   /**
-   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>Query</code>.
+   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>Query</code>.
    * 
    * @param query
    *          Query to extract Terms from
@@ -237,7 +237,7 @@ public class WeightedSpanTermExtractor {
   }
 
   /**
-   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>SpanQuery</code>.
+   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>SpanQuery</code>.
    * 
    * @param terms
    *          Map to place created WeightedSpanTerms in
@@ -325,7 +325,7 @@ public class WeightedSpanTermExtractor {
   }
 
   /**
-   * Fills a <code>Map</code> with <@link WeightedSpanTerm>s using the terms from the supplied <code>Query</code>.
+   * Fills a <code>Map</code> with {@link WeightedSpanTerm}s using the terms from the supplied <code>Query</code>.
    * 
    * @param terms
    *          Map to place created WeightedSpanTerms in
diff --git a/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
index 4b0644e..2958ade 100644
--- a/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
+++ b/lucene/memory/src/java/org/apache/lucene/index/memory/MemoryIndex.java
@@ -74,9 +74,9 @@ import org.apache.lucene.util.RecyclingIntBlockAllocator;
 
 /**
  * High-performance single-document main memory Apache Lucene fulltext search index. 
- * 
- * <h4>Overview</h4>
- * 
+ * <p>
+ * <b>Overview</b>
+ * <p>
  * This class is a replacement/substitute for a large subset of
  * {@link RAMDirectory} functionality. It is designed to
  * enable maximum efficiency for on-the-fly matchmaking combining structured and 
@@ -121,9 +121,9 @@ import org.apache.lucene.util.RecyclingIntBlockAllocator;
  * <a target="_blank" 
  * href="http://www.tbray.org/ongoing/When/200x/2003/07/30/OnSearchTOC">On Search, the Series</a>.
  * 
- * 
- * <h4>Example Usage</h4> 
- * 
+ * <p>
+ * <b>Example Usage</b> 
+ * <p>
  * <pre class="prettyprint">
  * Analyzer analyzer = new SimpleAnalyzer(version);
  * MemoryIndex index = new MemoryIndex();
@@ -139,29 +139,29 @@ import org.apache.lucene.util.RecyclingIntBlockAllocator;
  * System.out.println("indexData=" + index.toString());
  * </pre>
  * 
- * 
- * <h4>Example XQuery Usage</h4> 
+ * <p>
+ * <b>Example XQuery Usage</b> 
  * 
  * <pre class="prettyprint">
  * (: An XQuery that finds all books authored by James that have something to do with "salmon fishing manuals", sorted by relevance :)
  * declare namespace lucene = "java:nux.xom.pool.FullTextUtil";
  * declare variable $query := "+salmon~ +fish* manual~"; (: any arbitrary Lucene query can go here :)
  * 
- * for $book in /books/book[author="James" and lucene:match(abstract, $query) > 0.0]
+ * for $book in /books/book[author="James" and lucene:match(abstract, $query) &gt; 0.0]
  * let $score := lucene:match($book/abstract, $query)
  * order by $score descending
  * return $book
  * </pre>
  * 
- * 
- * <h4>Thread safety guarantees</h4>
- *
+ * <p>
+ * <b>Thread safety guarantees</b>
+ * <p>
  * MemoryIndex is not normally thread-safe for adds or queries.  However, queries
  * are thread-safe after {@code freeze()} has been called.
  *
- *
- * <h4>Performance Notes</h4>
- * 
+ * <p>
+ * <b>Performance Notes</b>
+ * <p>
  * Internally there's a new data structure geared towards efficient indexing 
  * and searching, plus the necessary support code to seamlessly plug into the Lucene 
  * framework.
diff --git a/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java b/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
index d6838dd..f6acd5f 100644
--- a/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
+++ b/lucene/misc/src/java/org/apache/lucene/uninverting/DocTermOrds.java
@@ -195,14 +195,14 @@ public class DocTermOrds implements Accountable {
 
   /** Inverts only terms starting w/ prefix, and only terms
    *  whose docFreq (not taking deletions into account) is
-   *  <=  maxTermDocFreq */
+   *  &lt;=  maxTermDocFreq */
   public DocTermOrds(LeafReader reader, Bits liveDocs, String field, BytesRef termPrefix, int maxTermDocFreq) throws IOException {
     this(reader, liveDocs, field, termPrefix, maxTermDocFreq, DEFAULT_INDEX_INTERVAL_BITS);
   }
 
   /** Inverts only terms starting w/ prefix, and only terms
    *  whose docFreq (not taking deletions into account) is
-   *  <=  maxTermDocFreq, with a custom indexing interval
+   *  &lt;=  maxTermDocFreq, with a custom indexing interval
    *  (default is every 128nd term). */
   public DocTermOrds(LeafReader reader, Bits liveDocs, String field, BytesRef termPrefix, int maxTermDocFreq, int indexIntervalBits) throws IOException {
     this(field, maxTermDocFreq, indexIntervalBits);
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
index 404b7a1..bff42a6 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/BoostingQuery.java
@@ -34,7 +34,8 @@ import org.apache.lucene.search.*;
  * multiplied by the supplied "boost" parameter, so this should be less than 1 to achieve a 
  * demoting effect
  * 
- * This code was originally made available here: [WWW] http://marc.theaimsgroup.com/?l=lucene-user&m=108058407130459&w=2
+ * This code was originally made available here: 
+ *   <a href="http://marc.theaimsgroup.com/?l=lucene-user&m=108058407130459&w=2">http://marc.theaimsgroup.com/?l=lucene-user&amp;m=108058407130459&amp;w=2</a>
  * and is documented here: http://wiki.apache.org/lucene-java/CommunityContributions
  */
 public class BoostingQuery extends Query {
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/CommonTermsQuery.java b/lucene/queries/src/java/org/apache/lucene/queries/CommonTermsQuery.java
index a391746..01b8b20 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/CommonTermsQuery.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/CommonTermsQuery.java
@@ -85,7 +85,7 @@ public class CommonTermsQuery extends Query {
    * @param lowFreqOccur
    *          {@link Occur} used for low frequency terms
    * @param maxTermFrequency
-   *          a value in [0..1) (or absolute number >=1) representing the
+   *          a value in [0..1) (or absolute number &gt;=1) representing the
    *          maximum threshold of a terms document frequency to be considered a
    *          low frequency term.
    * @throws IllegalArgumentException
@@ -105,7 +105,7 @@ public class CommonTermsQuery extends Query {
    * @param lowFreqOccur
    *          {@link Occur} used for low frequency terms
    * @param maxTermFrequency
-   *          a value in [0..1) (or absolute number >=1) representing the
+   *          a value in [0..1) (or absolute number &gt;=1) representing the
    *          maximum threshold of a terms document frequency to be considered a
    *          low frequency term.
    * @param disableCoord
diff --git a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/ReciprocalFloatFunction.java b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/ReciprocalFloatFunction.java
index 9c876b3..0c33bf7 100644
--- a/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/ReciprocalFloatFunction.java
+++ b/lucene/queries/src/java/org/apache/lucene/queries/function/valuesource/ReciprocalFloatFunction.java
@@ -31,7 +31,7 @@ import java.util.Map;
  * the float value of a field or function as exported by {@link org.apache.lucene.queries.function.ValueSource}.
  * <br>
  *
- * When a and b are equal, and x>=0, this function has a maximum value of 1 that drops as x increases.
+ * When a and b are equal, and x&gt;=0, this function has a maximum value of 1 that drops as x increases.
  * Increasing the value of a and b together results in a movement of the entire function to a flatter part of the curve.
  * <p>These properties make this an idea function for boosting more recent documents.
  * <p>Example:<code>  recip(ms(NOW,mydatefield),3.16e-11,1,1)</code>
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/MultiFieldQueryParser.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/MultiFieldQueryParser.java
index 10f0828..44da1d1 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/MultiFieldQueryParser.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/classic/MultiFieldQueryParser.java
@@ -55,7 +55,7 @@ public class MultiFieldQueryParser extends QueryParser
    * +(title:term1 body:term1) +(title:term2 body:term2)
    * </code>
    * 
-   * <p>When you pass a boost (title=>5 body=>10) you can get </p>
+   * <p>When you pass a boost (title=&gt;5 body=&gt;10) you can get </p>
    * 
    * <code>
    * +(title:term1^5.0 body:term1^10.0) +(title:term2^5.0 body:term2^10.0)
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/core/config/AbstractQueryConfig.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/core/config/AbstractQueryConfig.java
index f3f6c7e..520b6b8 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/core/config/AbstractQueryConfig.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/core/config/AbstractQueryConfig.java
@@ -25,7 +25,7 @@ import java.util.HashMap;
  * It has operations to set, unset and get configuration values.
  * </p>
  * <p>
- * Each configuration is is a key->value pair. The key should be an unique
+ * Each configuration is is a key-&gt;value pair. The key should be an unique
  * {@link ConfigurationKey} instance and it also holds the value's type.
  * </p>
  * 
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldBoostMapFCListener.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldBoostMapFCListener.java
index 89a6d11..4f845c6 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldBoostMapFCListener.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldBoostMapFCListener.java
@@ -27,7 +27,7 @@ import org.apache.lucene.queryparser.flexible.core.config.QueryConfigHandler;
 /**
  * This listener listens for every field configuration request and assign a
  * {@link ConfigurationKeys#BOOST} to the
- * equivalent {@link FieldConfig} based on a defined map: fieldName -> boostValue stored in
+ * equivalent {@link FieldConfig} based on a defined map: fieldName -&gt; boostValue stored in
  * {@link ConfigurationKeys#FIELD_BOOST_MAP}.
  * 
  * @see ConfigurationKeys#FIELD_BOOST_MAP
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldDateResolutionFCListener.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldDateResolutionFCListener.java
index 8ac9cf5..8111b91 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldDateResolutionFCListener.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/flexible/standard/config/FieldDateResolutionFCListener.java
@@ -29,7 +29,7 @@ import org.apache.lucene.queryparser.flexible.core.config.QueryConfigHandler;
 /**
  * This listener listens for every field configuration request and assign a
  * {@link ConfigurationKeys#DATE_RESOLUTION} to the equivalent {@link FieldConfig} based
- * on a defined map: fieldName -> {@link Resolution} stored in
+ * on a defined map: fieldName -&gt; {@link Resolution} stored in
  * {@link ConfigurationKeys#FIELD_DATE_RESOLUTION_MAP}.
  * 
  * @see ConfigurationKeys#DATE_RESOLUTION
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser.java
index 49d4c51..5dff236 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/simple/SimpleQueryParser.java
@@ -43,7 +43,8 @@ import java.util.Map;
  * <p>
  * Any errors in query syntax will be ignored and the parser will attempt
  * to decipher what it can; however, this may mean odd or unexpected results.
- * <h4>Query Operators</h4>
+ * <p>
+ * <b>Query Operators</b>
  * <ul>
  *  <li>'{@code +}' specifies {@code AND} operation: <tt>token1+token2</tt>
  *  <li>'{@code |}' specifies {@code OR} operation: <tt>token1|token2</tt>
@@ -63,7 +64,7 @@ import java.util.Map;
  * For example, the following will evaluate {@code token1 OR token2} first,
  * then {@code AND} with {@code token3}:
  * <blockquote>token1 | token2 + token3</blockquote>
- * <h4>Escaping</h4>
+ * <b>Escaping</b>
  * <p>
  * An individual term may contain any possible character with certain characters
  * requiring escaping using a '{@code \}'.  The following characters will need to be escaped in
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeFilterBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeFilterBuilder.java
index 8f962c8..8c70b9d 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeFilterBuilder.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeFilterBuilder.java
@@ -35,7 +35,7 @@ import java.io.IOException;
  * attributes and the defaults if optional attributes are omitted. For more
  * detail on what each of the attributes actually do, consult the documentation
  * for {@link NumericRangeFilter}:
- * <table>
+ * <table summary="supported attributes">
  * <tr>
  * <th>Attribute name</th>
  * <th>Values</th>
diff --git a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java
index f4909d1..877e4d9 100644
--- a/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java
+++ b/lucene/queryparser/src/java/org/apache/lucene/queryparser/xml/builders/NumericRangeQueryBuilder.java
@@ -30,7 +30,7 @@ import org.w3c.dom.Element;
  * attributes and the defaults if optional attributes are omitted. For more
  * detail on what each of the attributes actually do, consult the documentation
  * for {@link NumericRangeQuery}:
- * <table>
+ * <table summary="supported attributes">
  * <tr>
  * <th>Attribute name</th>
  * <th>Values</th>
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsFormat.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsFormat.java
index 2523c7f..01cb00a 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsFormat.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/IDVersionPostingsFormat.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.IOUtils;
  *  created by {@link #longToBytes} during indexing.  At search time,
  *  the TermsEnum implementation {@link IDVersionSegmentTermsEnum}
  *  enables fast (using only the terms index when possible) lookup for
- *  whether a given ID was previously indexed with version > N (see
+ *  whether a given ID was previously indexed with version &gt; N (see
  *  {@link IDVersionSegmentTermsEnum#seekExact(BytesRef,long)}.
  *
  *  <p>This is most effective if the app assigns monotonically
@@ -58,12 +58,12 @@ import org.apache.lucene.util.IOUtils;
 
 public class IDVersionPostingsFormat extends PostingsFormat {
 
-  /** version must be >= this. */
+  /** version must be &gt;= this. */
   public static final long MIN_VERSION = 0;
 
   // TODO: we could delta encode instead, and keep the last bit:
 
-  /** version must be <= this, because we encode with ZigZag. */
+  /** version must be &lt;= this, because we encode with ZigZag. */
   public static final long MAX_VERSION = 0x3fffffffffffffffL;
 
   private final int minTermsInBlock;
diff --git a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsWriter.java b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsWriter.java
index 6bdf7b1..e138fb7 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsWriter.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/codecs/idversion/VersionBlockTreeTermsWriter.java
@@ -85,7 +85,7 @@ import org.apache.lucene.util.packed.PackedInts;
 
 /**
  * This is just like {@link BlockTreeTermsWriter}, except it also stores a version per term, and adds a method to its TermsEnum
- * implementation to seekExact only if the version is >= the specified version.  The version is added to the terms index to avoid seeking if
+ * implementation to seekExact only if the version is &gt;= the specified version.  The version is added to the terms index to avoid seeking if
  * no term in the block has a high enough version.  The term blocks file is .tiv and the terms index extension is .tipv.
  *
  * @lucene.experimental
diff --git a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowFuzzyQuery.java b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowFuzzyQuery.java
index b09b045..61bf741 100644
--- a/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowFuzzyQuery.java
+++ b/lucene/sandbox/src/java/org/apache/lucene/sandbox/queries/SlowFuzzyQuery.java
@@ -65,7 +65,7 @@ public class SlowFuzzyQuery extends MultiTermQuery {
    *  as the query term is considered similar to the query term if the edit distance
    *  between both terms is less than <code>length(term)*0.5</code>
    *  <p>
-   *  Alternatively, if <code>minimumSimilarity</code> is >= 1f, it is interpreted 
+   *  Alternatively, if <code>minimumSimilarity</code> is &gt;= 1f, it is interpreted 
    *  as a pure Levenshtein edit distance. For example, a value of <code>2f</code>
    *  will match all terms within an edit distance of <code>2</code> from the 
    *  query term. Edit distances specified in this way may not be fractional.
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/SpatialStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/SpatialStrategy.java
index 267fb0e..c20fb8f 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/SpatialStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/SpatialStrategy.java
@@ -48,7 +48,7 @@ import org.apache.lucene.spatial.query.SpatialArgs;
  * be coerced into compatibility.
  * <p/>
  * Note that a SpatialStrategy is not involved with the Lucene stored field
- * values of shapes, which is immaterial to indexing & search.
+ * values of shapes, which is immaterial to indexing and search.
  * <p/>
  * Thread-safe.
  *
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxSimilarityValueSource.java b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxSimilarityValueSource.java
index 28062f6..ffc379f 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxSimilarityValueSource.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxSimilarityValueSource.java
@@ -33,7 +33,7 @@ import java.util.Map;
  * {@link ValueSource} in which {@link FunctionValues#objectVal(int)} returns a {@link
  * com.spatial4j.core.shape.Rectangle}.
  * <p/>
- * Implementers: remember to implement equals & hashCode if you have
+ * Implementers: remember to implement equals and hashCode if you have
  * fields!
  *
  * @lucene.experimental
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
index c9a1230..1ac7037 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/bbox/BBoxStrategy.java
@@ -51,8 +51,9 @@ import com.spatial4j.core.shape.Shape;
  * coordinates in numeric fields. It supports all {@link SpatialOperation}s and
  * has a custom overlap relevancy. It is based on GeoPortal's <a
  * href="http://geoportal.svn.sourceforge.net/svnroot/geoportal/Geoportal/trunk/src/com/esri/gpt/catalog/lucene/SpatialClauseAdapter.java">SpatialClauseAdapter</a>.
- *
- * <h4>Characteristics:</h4>
+ * <p>
+ * <b>Characteristics:</b>
+ * <p>
  * <ul>
  * <li>Only indexes Rectangles; just one per field value. Other shapes can be provided
  * and the bounding box will be used.</li>
@@ -60,8 +61,9 @@ import com.spatial4j.core.shape.Shape;
  * <li>Supports most {@link SpatialOperation}s but not Overlaps.</li>
  * <li>Uses the DocValues API for any sorting / relevancy.</li>
  * </ul>
- *
- * <h4>Implementation:</h4>
+ * <p>
+ * <b>Implementation:</b>
+ * <p>
  * This uses 4 double fields for minX, maxX, minY, maxY
  * and a boolean to mark a dateline cross. Depending on the particular {@link
  * SpatialOperation}s, there are a variety of {@link NumericRangeQuery}s to be
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractVisitingPrefixTreeFilter.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractVisitingPrefixTreeFilter.java
index 56e282a..5063860 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractVisitingPrefixTreeFilter.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/AbstractVisitingPrefixTreeFilter.java
@@ -31,7 +31,7 @@ import java.io.IOException;
 import java.util.Iterator;
 
 /**
- * Traverses a {@link SpatialPrefixTree} indexed field, using the template &
+ * Traverses a {@link SpatialPrefixTree} indexed field, using the template and
  * visitor design patterns for subclasses to guide the traversal and collect
  * matching documents.
  * <p/>
@@ -257,7 +257,7 @@ public abstract class AbstractVisitingPrefixTreeFilter extends AbstractPrefixTre
     }
 
     /**
-     * Called when doing a divide & conquer to find the next intersecting cells
+     * Called when doing a divide and conquer to find the next intersecting cells
      * of the query shape that are beneath {@code cell}. {@code cell} is
      * guaranteed to have an intersection and thus this must return some number
      * of nodes.
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeStrategy.java
index 8be6855..f5b41d6 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/PrefixTreeStrategy.java
@@ -40,8 +40,9 @@ import com.spatial4j.core.shape.Shape;
  * subclasses are {@link RecursivePrefixTreeStrategy} and {@link
  * TermQueryPrefixTreeStrategy}.  This strategy is most effective as a fast
  * approximate spatial search filter.
- *
- * <h4>Characteristics:</h4>
+ * <p>
+ * <b>Characteristics:</b>
+ * <p>
  * <ul>
  * <li>Can index any shape; however only {@link RecursivePrefixTreeStrategy}
  * can effectively search non-point shapes.</li>
@@ -64,8 +65,9 @@ import com.spatial4j.core.shape.Shape;
  * it doesn't scale to large numbers of points nor is it real-time-search
  * friendly.</li>
  * </ul>
- *
- * <h4>Implementation:</h4>
+ * <p>
+ * <b>Implementation:</b>
+ * <p>
  * The {@link SpatialPrefixTree} does most of the work, for example returning
  * a list of terms representing grids of various sizes for a supplied shape.
  * An important
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/CellIterator.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/CellIterator.java
index a6c17c0..4539c8e 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/CellIterator.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/CellIterator.java
@@ -43,7 +43,7 @@ public abstract class CellIterator implements Iterator<Cell> {
   //public SpatialRelation getShapeRel()
 
   /**
-   * Gets the next cell that is >= {@code fromCell}, compared using non-leaf bytes. If it returns null then
+   * Gets the next cell that is &gt;= {@code fromCell}, compared using non-leaf bytes. If it returns null then
    * the iterator is exhausted.
    */
   public Cell nextFrom(Cell fromCell) {
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/GeohashPrefixTree.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/GeohashPrefixTree.java
index 20c1d98..d15893d 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/GeohashPrefixTree.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/GeohashPrefixTree.java
@@ -65,7 +65,7 @@ public class GeohashPrefixTree extends LegacyPrefixTree {
       throw new IllegalArgumentException("maxLen must be [1-"+MAXP+"] but got "+ maxLevels);
   }
 
-  /** Any more than this and there's no point (double lat & lon are the same). */
+  /** Any more than this and there's no point (double lat and lon are the same). */
   public static int getMaxLevelsPossible() {
     return GeohashUtils.MAX_PRECISION;
   }
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/LegacyCell.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/LegacyCell.java
index e1357b9..03b4c05 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/LegacyCell.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/LegacyCell.java
@@ -25,7 +25,7 @@ import org.apache.lucene.util.StringHelper;
 
 import java.util.Collection;
 
-/** The base for the original two SPT's: Geohash & Quad. Don't subclass this for new SPTs.
+/** The base for the original two SPT's: Geohash and Quad. Don't subclass this for new SPTs.
  * @lucene.internal */
 //public for RPT pruneLeafyBranches code
 public abstract class LegacyCell implements Cell {
@@ -169,7 +169,7 @@ public abstract class LegacyCell implements Cell {
   protected abstract Collection<Cell> getSubCells();
 
   /**
-   * {@link #getSubCells()}.size() -- usually a constant. Should be >=2
+   * {@link #getSubCells()}.size() -- usually a constant. Should be &gt;=2
    */
   public abstract int getSubCellsSize();
 
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTree.java b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTree.java
index 1de862e..f264bb6 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTree.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTree.java
@@ -64,7 +64,7 @@ public abstract class SpatialPrefixTree {
    * grid, such that you can get a grid with just the right amount of
    * precision.
    *
-   * @param dist >= 0
+   * @param dist {@code >= 0}
    * @return level [1 to maxLevels]
    */
   public abstract int getLevelForDistance(double dist);
@@ -75,7 +75,7 @@ public abstract class SpatialPrefixTree {
    * may over-estimate.
    *
    * @param level [1 to maxLevels]
-   * @return > 0
+   * @return {@code > 0}
    */
   public abstract double getDistanceForLevel(int level);
 
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/query/SpatialArgs.java b/lucene/spatial/src/java/org/apache/lucene/spatial/query/SpatialArgs.java
index fec254b..5501d5c 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/query/SpatialArgs.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/query/SpatialArgs.java
@@ -76,7 +76,7 @@ public class SpatialArgs {
    * looks at {@link #getDistErr()}, {@link #getDistErrPct()}, and {@code
    * defaultDistErrPct}.
    * @param defaultDistErrPct 0 to 0.5
-   * @return >= 0
+   * @return {@code >= 0}
    */
   public double resolveDistErr(SpatialContext ctx, double defaultDistErrPct) {
     if (distErr != null)
@@ -137,7 +137,7 @@ public class SpatialArgs {
    * The acceptable error of the shape.  This effectively inflates the
    * size of the shape but should not shrink it.
    *
-   * @return >= 0
+   * @return {@code >= 0}
    */
   public Double getDistErr() {
     return distErr;
diff --git a/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java b/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
index 5ef2769..5721ed6 100644
--- a/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
+++ b/lucene/spatial/src/java/org/apache/lucene/spatial/vector/PointVectorStrategy.java
@@ -47,7 +47,9 @@ import org.apache.lucene.spatial.util.ValueSourceFilter;
  * Simple {@link SpatialStrategy} which represents Points in two numeric {@link
  * DoubleField}s.  The Strategy's best feature is decent distance sort.
  *
- * <h4>Characteristics:</h4>
+ * <p>
+ * <b>Characteristics:</b>
+ * <p>
  * <ul>
  * <li>Only indexes points; just one per field value.</li>
  * <li>Can query by a rectangle or circle.</li>
@@ -59,9 +61,11 @@ import org.apache.lucene.spatial.util.ValueSourceFilter;
  * searching with a Circle.</li>
  * </ul>
  *
- * <h4>Implementation:</h4>
+ * <p>
+ * <b>Implementation:</b>
+ * <p>
  * This is a simple Strategy.  Search works with {@link NumericRangeQuery}s on
- * an x & y pair of fields.  A Circle query does the same bbox query but adds a
+ * an x and y pair of fields.  A Circle query does the same bbox query but adds a
  * ValueSource filter on
  * {@link #makeDistanceValueSource(com.spatial4j.core.shape.Point)}.
  * <p />
diff --git a/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/JtsPolygonTest.java b/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/JtsPolygonTest.java
index 6dbaa9b..87b0511 100644
--- a/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/JtsPolygonTest.java
+++ b/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/JtsPolygonTest.java
@@ -82,7 +82,7 @@ public class JtsPolygonTest extends StrategyTestCase {
 
   /**
    * A PrefixTree pruning optimization gone bad.
-   * See <a href="https://issues.apache.org/jira/browse/LUCENE-4770>LUCENE-4770</a>.
+   * See <a href="https://issues.apache.org/jira/browse/LUCENE-4770">LUCENE-4770</a>.
    */
   @Test
   public void testBadPrefixTreePrune() throws Exception {
diff --git a/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTreeTest.java b/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTreeTest.java
index 9f53546..89b0c72 100644
--- a/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTreeTest.java
+++ b/lucene/spatial/src/test/org/apache/lucene/spatial/prefix/tree/SpatialPrefixTreeTest.java
@@ -78,7 +78,7 @@ public class SpatialPrefixTreeTest extends SpatialTestCase {
   }
   /**
    * A PrefixTree pruning optimization gone bad, applicable when optimize=true.
-   * See <a href="https://issues.apache.org/jira/browse/LUCENE-4770>LUCENE-4770</a>.
+   * See <a href="https://issues.apache.org/jira/browse/LUCENE-4770">LUCENE-4770</a>.
    */
   @Test
   public void testBadPrefixTreePrune() throws Exception {
diff --git a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FuzzySuggester.java b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FuzzySuggester.java
index 3bd7caf..bd207eb 100644
--- a/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FuzzySuggester.java
+++ b/lucene/suggest/src/java/org/apache/lucene/search/suggest/analyzing/FuzzySuggester.java
@@ -118,7 +118,7 @@ public final class FuzzySuggester extends AnalyzingSuggester {
   }
   
   /**
-   * Creates a {@link FuzzySuggester} instance with an index & a query analyzer initialized with default values.
+   * Creates a {@link FuzzySuggester} instance with an index and query analyzer initialized with default values.
    * 
    * @param indexAnalyzer
    *           Analyzer that will be used for analyzing suggestions while building the index.
@@ -146,7 +146,7 @@ public final class FuzzySuggester extends AnalyzingSuggester {
    *        to expand from the analyzed form.  Set this to -1 for
    *        no limit.
    * @param preservePositionIncrements Whether position holes should appear in the automaton
-   * @param maxEdits must be >= 0 and <= {@link LevenshteinAutomata#MAXIMUM_SUPPORTED_DISTANCE} .
+   * @param maxEdits must be &gt;= 0 and &lt;= {@link LevenshteinAutomata#MAXIMUM_SUPPORTED_DISTANCE} .
    * @param transpositions <code>true</code> if transpositions should be treated as a primitive 
    *        edit operation. If this is false, comparisons will implement the classic
    *        Levenshtein algorithm.
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
index ecf4f3f..4dbb7b0 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockGraphTokenFilter.java
@@ -26,7 +26,7 @@ import org.apache.lucene.util.TestUtil;
 // TODO: sometimes remove tokens too...?
 
 /** Randomly inserts overlapped (posInc=0) tokens with
- *  posLength sometimes > 1.  The chain must have
+ *  posLength sometimes &gt; 1.  The chain must have
  *  an OffsetAttribute.  */
 
 public final class MockGraphTokenFilter extends LookaheadTokenFilter<LookaheadTokenFilter.Position> {
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase.java
index 5fd8462..ec13885 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/BaseNormsFormatTestCase.java
@@ -347,7 +347,7 @@ public abstract class BaseNormsFormatTestCase extends BaseIndexFileFormatTestCas
   
   // TODO: test thread safety (e.g. across different fields) explicitly here
 
-  /** 
+  /*
    * LUCENE-6006: Tests undead norms.
    *                                 .....            
    *                             C C  /            
diff --git a/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
index fd94dc2..0234022 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/index/RandomCodec.java
@@ -73,7 +73,7 @@ public class RandomCodec extends AssertingCodec {
 
   public final Set<String> avoidCodecs;
 
-  /** memorized field->postingsformat mappings */
+  /** memorized field to postingsformat mappings */
   // note: we have to sync this map even though its just for debugging/toString, 
   // otherwise DWPT's .toString() calls that iterate over the map can 
   // cause concurrentmodificationexception if indexwriter's infostream is on
diff --git a/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
index 525d846..45b8a7d 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/search/BaseExplanationTestCase.java
@@ -46,7 +46,6 @@ import org.junit.BeforeClass;
  * then anything that rewrites to a primitive will work well also.
  * </p>
  *
- * @see "Subclasses for actual tests"
  */
 public abstract class BaseExplanationTestCase extends LuceneTestCase {
   protected static IndexSearcher searcher;
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
index f581522..b877aaf 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/LuceneTestCase.java
@@ -1475,7 +1475,7 @@ public abstract class LuceneTestCase extends Assert {
 
   /** 
    * Return a random Locale from the available locales on the system.
-   * @see "https://issues.apache.org/jira/browse/LUCENE-4020"
+   * @see <a href="https://issues.apache.org/jira/browse/LUCENE-4020">LUCENE-4020</a>
    */
   public static Locale randomLocale(Random random) {
     Locale locales[] = Locale.getAvailableLocales();
@@ -1484,7 +1484,7 @@ public abstract class LuceneTestCase extends Assert {
 
   /** 
    * Return a random TimeZone from the available timezones on the system
-   * @see "https://issues.apache.org/jira/browse/LUCENE-4020" 
+   * @see <a href="https://issues.apache.org/jira/browse/LUCENE-4020">LUCENE-4020</a>
    */
   public static TimeZone randomTimeZone(Random random) {
     String tzIds[] = TimeZone.getAvailableIDs();
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/RamUsageTester.java b/lucene/test-framework/src/java/org/apache/lucene/util/RamUsageTester.java
index ffd6710..2286882 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/RamUsageTester.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/RamUsageTester.java
@@ -324,7 +324,7 @@ public final class RamUsageTester {
      * finalization step from Austin Appleby's
      * <code>MurmurHash3</code>.
      * 
-     * @see "http://sites.google.com/site/murmurhash/"
+     * @see <a href="http://sites.google.com/site/murmurhash/">http://sites.google.com/site/murmurhash/</a>
      */
     private static int rehash(Object o) {
       int k = System.identityHashCode(o);
diff --git a/lucene/test-framework/src/java/org/apache/lucene/util/Rethrow.java b/lucene/test-framework/src/java/org/apache/lucene/util/Rethrow.java
index 2ae9be1..f2fb568 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/util/Rethrow.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/util/Rethrow.java
@@ -22,7 +22,7 @@ package org.apache.lucene.util;
  * ones. Eh, it is sometimes useful...
  *
  * <p>Pulled from <a href="http://www.javapuzzlers.com">Java Puzzlers</a>.</p>
- * @see "http://www.amazon.com/Java-Puzzlers-Traps-Pitfalls-Corner/dp/032133678X"
+ * @see <a href="http://www.amazon.com/Java-Puzzlers-Traps-Pitfalls-Corner/dp/032133678X">http://www.amazon.com/Java-Puzzlers-Traps-Pitfalls-Corner/dp/032133678X</a>
  */
 @SuppressWarnings({"unchecked","rawtypes"})
 public final class Rethrow {

