GitDiffStart: 43a5bd6c19ee989b6955fe028878ce53f469337c | Mon Aug 10 23:29:27 2009 +0000
diff --git a/contrib/CHANGES.txt b/contrib/CHANGES.txt
index 741558f..7686ca8 100644
--- a/contrib/CHANGES.txt
+++ b/contrib/CHANGES.txt
@@ -142,6 +142,7 @@ New features
 
 15. LUCENE-1406: Added Arabic analyzer.  (Robert Muir via Grant Ingersoll)
 
+16. LUCENE-1628: Added Persian analyzer.  (Robert Muir)
 
 Optimizations
 
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
new file mode 100644
index 0000000..4c21276
--- /dev/null
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -0,0 +1,165 @@
+package org.apache.lucene.analysis.fa;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.util.HashSet;
+import java.util.Hashtable;
+import java.util.Set;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.LowerCaseFilter;
+import org.apache.lucene.analysis.StopFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.WordlistLoader;
+import org.apache.lucene.analysis.ar.ArabicLetterTokenizer;
+import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
+
+/**
+ * Analyzer for Persian.
+ * 
+ * Analyzer uses {@link ArabicLetterTokenizer} which implies tokenizing around
+ * ZWNJ in addition to space. Some persian-specific variant forms (such as farsi
+ * yeh and keheh) are standardized. "Stemming" is accomplished via stopwords.
+ * 
+ */
+public final class PersianAnalyzer extends Analyzer {
+
+  /**
+   * File containing default Persian stopwords.
+   * 
+   * Default stopword list is from
+   * http://members.unine.ch/jacques.savoy/clef/index.html The stopword list is
+   * BSD-Licensed.
+   * 
+   */
+  public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
+
+  /**
+   * Contains the stopwords used with the StopFilter.
+   */
+  private Set stoptable = new HashSet();
+
+  /**
+   * The comment character in the stopwords file. All lines prefixed with this
+   * will be ignored
+   */
+  public static final String STOPWORDS_COMMENT = "#";
+
+  /**
+   * Builds an analyzer with the default stop words:
+   * {@link #DEFAULT_STOPWORD_FILE}.
+   */
+  public PersianAnalyzer() {
+    try {
+      InputStream stream = PersianAnalyzer.class
+          .getResourceAsStream(DEFAULT_STOPWORD_FILE);
+      InputStreamReader reader = new InputStreamReader(stream, "UTF-8");
+      stoptable = WordlistLoader.getWordSet(reader, STOPWORDS_COMMENT);
+      reader.close();
+      stream.close();
+    } catch (IOException e) {
+      // TODO: throw IOException
+      throw new RuntimeException(e);
+    }
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public PersianAnalyzer(String[] stopwords) {
+    stoptable = StopFilter.makeStopSet(stopwords);
+  }
+
+  /**
+   * Builds an analyzer with the given stop words.
+   */
+  public PersianAnalyzer(Hashtable stopwords) {
+    stoptable = new HashSet(stopwords.keySet());
+  }
+
+  /**
+   * Builds an analyzer with the given stop words. Lines can be commented out
+   * using {@link #STOPWORDS_COMMENT}
+   */
+  public PersianAnalyzer(File stopwords) throws IOException {
+    stoptable = WordlistLoader.getWordSet(stopwords, STOPWORDS_COMMENT);
+  }
+
+  /**
+   * Creates a TokenStream which tokenizes all the text in the provided Reader.
+   * 
+   * @return A TokenStream build from a ArabicLetterTokenizer filtered with
+   *         LowerCaseFilter, ArabicNormalizationFilter,
+   *         PersianNormalizationFilter and Persian Stop words
+   */
+  public TokenStream tokenStream(String fieldName, Reader reader) {
+    TokenStream result = new ArabicLetterTokenizer(reader);
+    result = new LowerCaseFilter(result);
+    result = new ArabicNormalizationFilter(result);
+    /* additional persian-specific normalization */
+    result = new PersianNormalizationFilter(result);
+    /*
+     * the order here is important: the stopword list is normalized with the
+     * above!
+     */
+    result = new StopFilter(result, stoptable);
+
+    return result;
+  }
+  
+  private class SavedStreams {
+    Tokenizer source;
+    TokenStream result;
+  }
+
+  /**
+   * Returns a (possibly reused) TokenStream which tokenizes all the text 
+   * in the provided Reader.
+   * 
+   * @return A TokenStream build from a ArabicLetterTokenizer filtered with
+   *         LowerCaseFilter, ArabicNormalizationFilter,
+   *         PersianNormalizationFilter and Persian Stop words
+   */
+  public TokenStream reusableTokenStream(String fieldName, Reader reader)
+      throws IOException {
+    SavedStreams streams = (SavedStreams) getPreviousTokenStream();
+    if (streams == null) {
+      streams = new SavedStreams();
+      streams.source = new ArabicLetterTokenizer(reader);
+      streams.result = new LowerCaseFilter(streams.source);
+      streams.result = new ArabicNormalizationFilter(streams.result);
+      /* additional persian-specific normalization */
+      streams.result = new PersianNormalizationFilter(streams.result);
+      /*
+       * the order here is important: the stopword list is normalized with the
+       * above!
+       */
+      streams.result = new StopFilter(streams.result, stoptable);
+      setPreviousTokenStream(streams);
+    } else {
+      streams.source.reset(reader);
+    }
+    return streams.result;
+  }
+}
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java
new file mode 100644
index 0000000..1106cca
--- /dev/null
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizationFilter.java
@@ -0,0 +1,53 @@
+package org.apache.lucene.analysis.fa;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+
+/**
+ * A TokenFilter that applies {@link PersianNormalizer} to normalize the
+ * orthography.
+ * 
+ */
+
+public final class PersianNormalizationFilter extends TokenFilter {
+
+  private final PersianNormalizer normalizer;
+  private TermAttribute termAtt;
+
+  public PersianNormalizationFilter(TokenStream input) {
+    super(input);
+    normalizer = new PersianNormalizer();
+    termAtt = (TermAttribute) addAttribute(TermAttribute.class);
+  }
+
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      int newlen = normalizer.normalize(termAtt.termBuffer(), termAtt
+          .termLength());
+      termAtt.setTermLength(newlen);
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizer.java b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizer.java
new file mode 100644
index 0000000..53caa6e
--- /dev/null
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/PersianNormalizer.java
@@ -0,0 +1,95 @@
+package org.apache.lucene.analysis.fa;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Normalizer for Persian.
+ * <p>
+ * Normalization is done in-place for efficiency, operating on a termbuffer.
+ * <p>
+ * Normalization is defined as:
+ * <ul>
+ * <li>Normalization of various heh + hamza forms and heh goal to heh.
+ * <li>Normalization of farsi yeh and yeh barree to arabic yeh
+ * <li>Normalization of persian keheh to arabic kaf
+ * </ul>
+ * 
+ */
+public class PersianNormalizer {
+  public static final char YEH = '\u064A';
+
+  public static final char FARSI_YEH = '\u06CC';
+
+  public static final char YEH_BARREE = '\u06D2';
+
+  public static final char KEHEH = '\u06A9';
+
+  public static final char KAF = '\u0643';
+
+  public static final char HAMZA_ABOVE = '\u0654';
+
+  public static final char HEH_YEH = '\u06C0';
+
+  public static final char HEH_GOAL = '\u06C1';
+
+  public static final char HEH = '\u0647';
+
+  /**
+   * Normalize an input buffer of Persian text
+   * 
+   * @param s input buffer
+   * @param len length of input buffer
+   * @return length of input buffer after normalization
+   */
+  public int normalize(char s[], int len) {
+
+    for (int i = 0; i < len; i++) {
+      if (s[i] == FARSI_YEH || s[i] == YEH_BARREE)
+        s[i] = YEH;
+
+      if (s[i] == KEHEH)
+        s[i] = KAF;
+
+      if (s[i] == HEH_YEH || s[i] == HEH_GOAL)
+        s[i] = HEH;
+
+      if (s[i] == HAMZA_ABOVE) { // necessary for HEH + HAMZA
+        len = delete(s, i, len);
+        i--;
+      }
+    }
+
+    return len;
+  }
+
+  /**
+   * Delete a character in-place
+   * 
+   * @param s Input Buffer
+   * @param pos Position of character to delete
+   * @param len length of input buffer
+   * @return length of input buffer after deletion
+   */
+  protected int delete(char s[], int pos, int len) {
+    if (pos < len)
+      System.arraycopy(s, pos + 1, s, pos, len - pos - 1);
+
+    return len - 1;
+  }
+
+}
diff --git a/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/package.html b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/package.html
new file mode 100644
index 0000000..4a062ac
--- /dev/null
+++ b/contrib/analyzers/common/src/java/org/apache/lucene/analysis/fa/package.html
@@ -0,0 +1,5 @@
+<html><head></head>
+<body>
+Analyzer for Persian.
+</body>
+</html>
diff --git a/contrib/analyzers/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt b/contrib/analyzers/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt
new file mode 100644
index 0000000..3618281
--- /dev/null
+++ b/contrib/analyzers/common/src/resources/org/apache/lucene/analysis/fa/stopwords.txt
@@ -0,0 +1,311 @@
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# Also see http://www.opensource.org/licenses/bsd-license.html
+Ø§?Ø§?
+?Ø¯Ø§Ø´Øª?
+Ø³Ø±Ø§Ø³Ø±
+Ø®?Ø§?
+Ø§?Ø´Ø§?
+??
+ØªØ§????
+Ø¨?Ø´ØªØ±?
+Ø¯??
+Ù¾Ø³
+?Ø§Ø´?
+?Ú¯?
+?Ø§
+Ø¯Ø§Ø´Øª?Ø¯
+Ø³Ù¾Ø³
+??Ú¯Ø§?
+?Ø±Ú¯Ø²
+Ù¾?Ø¬
+?Ø´Ø§?
+Ø§?Ø³Ø§?
+Ø¯?Ú¯Ø±
+Ú¯Ø±???
+Ø´Ø¯?Ø¯
+?Ø·?Ø±
+Ø¯?
+?
+Ø¯?
+?Ø®Ø³Øª??
+???
+?Ø±Ø§
+??
+?Ø³Ø·
+?
+?Ø¯Ø§?
+?Ø§Ø¨?
+??
+Ø±?Øª
+??Øª
+??????
+Ø¯Ø±
+?Ø²Ø§Ø±
+Ø¨??
+Ø¨??
+Ø´Ø§?Ø¯
+Ø§?Ø§
+Ø´?Ø§Ø³?
+Ú¯Ø±?Øª?
+Ø¯?Ø¯
+Ø¯Ø§Ø´Øª?
+Ø¯Ø§?Ø³Øª
+Ø¯Ø§Ø´Øª?
+Ø®?Ø§???
+????Ø§Ø±Ø¯
+??Øª???
+Ø§?Ø¯
+Ø®?Ø§?Ø¯
+Ø¬Ø²
+Ø§?Ø±Ø¯?
+Ø´Ø¯?
+Ø¨???
+Ø®Ø¯?Ø§Øª
+Ø´Ø¯?
+Ø¨Ø±Ø®?
+?Ø¨?Ø¯
+Ø¨Ø³?Ø§Ø±?
+Ø¬??Ú¯?Ø±?
+Ø­?
+?Ø±Ø¯?Ø¯
+??Ø¹?
+Ø¨Ø¹Ø±?
+??Ø±Ø¯?
+?Ø¸?Ø±
+?Ø¨Ø§?Ø¯
+Ø¨?Ø¯?
+Ø¨?Ø¯?
+Ø¯Ø§Ø¯
+Ø§?Ø±Ø¯
+?Ø³Øª
+Ø¬Ø§??
+Ø´?Ø¯
+Ø¯?Ø¨Ø§?
+Ø¯Ø§Ø¯?
+Ø¨Ø§?Ø¯
+Ø³Ø§Ø¨?
+???
+??Ø§?
+Ø§?Ø¬Ø§
+??ØªØ±
+?Ø¬Ø§Ø³Øª
+Ú¯Ø±Ø¯Ø¯
+?Ø³?
+ØªØ±
+?Ø±Ø¯?
+ØªØ§?
+Ø¯Ø§Ø¯?
+Ø¨?Ø¯?Ø¯
+Ø³Ø±?
+Ø¬Ø¯Ø§
+?Ø¯Ø§Ø±?Ø¯
+?Ú¯Ø±
+??Ø¯?Ú¯Ø±
+Ø¯Ø§Ø±Ø¯
+Ø¯??Ø¯
+Ø¨?Ø§Ø¨Ø±Ø§??
+??Ú¯Ø§??
+Ø³?Øª
+Ø¬Ø§
+Ø§???
+Ø®?Ø¯
+Ø¯Ø§Ø¯?Ø¯
+Ø²?Ø§Ø¯
+Ø¯Ø§Ø±?Ø¯
+Ø§Ø«Ø±
+Ø¨Ø¯??
+Ø¨?ØªØ±??
+Ø¨?Ø´ØªØ±
+Ø§?Ø¨Øª?
+Ø¨?
+Ø¨Ø±Ø§Ø³Ø§Ø³
+Ø¨?Ø±??
+?Ø±Ø¯
+Ø¨Ø¹Ø¶?
+Ú¯Ø±?Øª
+Øª??
+Ø§?
+??????
+Ø§?
+Ø¬Ø±?Ø§?
+Øª??
+Ø¨Ø±
+?Ø§??Ø¯
+Ø¨Ø±Ø§Ø¨Ø±
+Ø¨Ø§Ø´??
+?Ø¯Øª?
+Ú¯???Ø¯
+Ø§????
+ØªØ§
+Øª??Ø§
+Ø¬Ø¯?Ø¯
+??Ø¯
+Ø¨?
+?Ø´Ø¯?
+?Ø±Ø¯?
+?Ø±Ø¯?
+Ú¯??Ø¯
+?Ø±Ø¯?
+????
+???
+?Ø²Ø¯
+Ø±??
+?ØµØ¯
+??Ø·
+Ø¨Ø§?Ø§?
+Ø¯?Ú¯Ø±Ø§?
+Ø§??
+Ø¯?Ø±?Ø²
+Øª?Ø³Ø·
+Ø³??
+Ø§??
+Ø¯Ø§??Ø¯
+Ø³??
+Ø§Ø³Øª?Ø§Ø¯?
+Ø´?Ø§
+??Ø§Ø±
+Ø¯Ø§Ø±??
+Ø³Ø§Ø®Øª?
+Ø·?Ø±
+Ø§?Ø¯?
+Ø±?Øª?
+?Ø®Ø³Øª
+Ø¨?Ø³Øª
+?Ø²Ø¯??
+Ø·?
+???Ø¯
+Ø§Ø²
+Ø§??Ø§
+Øª?Ø§??
+Ø¯Ø§Ø´Øª
+???
+Ø·Ø±??
+Ø§Ø´
+??Ø³Øª
+Ø±?Ø¨
+??Ø§?Ø¯
+Ú¯?Øª
+??Ø¯??
+??Ø²?
+Øª?Ø§?Ø¯
+Ø§?
+Ø§?Ø§
+Ø¨Ø§
+Ø§?
+Ø§?Ø¯
+ØªØ±??
+Ø§????
+Ø¯?Ú¯Ø±?
+Ø±Ø§?
+?Ø§??
+Ø¨Ø±?Ø²
+????Ø§?
+Ù¾Ø§Ø¹??
+?Ø³
+Ø­Ø¯?Ø¯
+?Ø®Øª??
+??Ø§Ø¨?
+??Ø²
+Ú¯?Ø±Ø¯
+?Ø¯Ø§Ø±Ø¯
+Ø¶Ø¯
+?????
+Ø³Ø§Ø²?
+Ø´Ø§?
+??Ø±Ø¯
+Ø¨Ø§Ø±?
+?Ø±Ø³?
+Ø®??Ø´
+Ø¨Ø±Ø®?Ø±Ø¯Ø§Ø±
+???
+Ø®Ø§Ø±Ø¬
+Ø´Ø´
+???Ø²
+ØªØ­Øª
+Ø¶??
+?Ø³Øª??
+Ú¯?Øª?
+??Ø±
+Ø¨Ø³?Ø§Ø±
+Ù¾?Ø´
+Ø¨Ø±Ø§?
+Ø±?Ø²?Ø§?
+Ø§???
+?Ø®?Ø§?Ø¯
+Ø¨Ø§?Ø§
+??
+??Øª?
+??
+????
+??
+Ú¯?Ø±?
+??Ø³Øª
+Ø§Ø³Øª
+?Ø¬Ø§
+??Ø¯
+??Ø²
+?Ø§Ø¨Ø¯
+Ø¨?Ø¯?
+Ø­Øª?
+Øª?Ø§??Ø¯
+Ø¹?Ø¨
+Ø®?Ø§Ø³Øª
+???Ø¯
+Ø¨??
+Øª?Ø§?
+???
+?Ø§
+Ø¨Ø§Ø´?Ø¯
+?Ø«?
+Ø´Ø¯
+Ø§Ø±?
+Ø¨Ø§Ø´Ø¯
+Ø§Ø±?
+Ø·Ø¨?
+Ø¨Ø¹Ø¯
+Ø§Ú¯Ø±
+Øµ?Ø±Øª
+Øº?Ø±
+Ø¬Ø§?
+Ø¨?Ø´
+Ø±?Ø²?
+Ø§?Ø¯
+Ø²?Ø±Ø§
+?Ú¯???
+Ø¨Ø§Ø±
+?Ø·?Ø§
+??
+Ø¯Ø±Ø¨Ø§Ø±?
+??
+Ø¯?Ø¯?
+????
+Ú¯Ø°Ø§Ø±?
+Ø¨Ø±Ø¯Ø§Ø±?
+Ø¹?Øª
+Ú¯Ø°Ø§Ø´Øª?
+??
+???
+??
+?Ø§
+Ø´??Ø¯
+Ø§Ø¨Ø§Ø¯
+???Ø§Ø±?
+?Ø±
+Ø§??
+Ø®?Ø§??Ø¯
+??Ø§Ø±
+?Ø§?
+Ø§?Ø±?Ø²
+?Ø§?
+?Ø§?
+?Ø¨?
+???
+Ø³Ø¹?
+ØªØ§Ø²?
+Ø±Ø§
+?Ø³Øª?Ø¯
+Ø²?Ø±
+Ø¬???
+Ø¹??Ø§?
+Ø¨?Ø¯
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
new file mode 100644
index 0000000..e067254
--- /dev/null
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
@@ -0,0 +1,248 @@
+package org.apache.lucene.analysis.fa;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.StringReader;
+
+import junit.framework.TestCase;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+
+/**
+ * Test the Persian Analyzer
+ * 
+ */
+public class TestPersianAnalyzer extends TestCase {
+
+  /**
+   * This test fails with NPE when the stopwords file is missing in classpath
+   */
+  public void testResourcesAvailable() {
+    new PersianAnalyzer();
+  }
+
+  /**
+   * This test shows how the combination of tokenization (breaking on zero-width
+   * non-joiner), normalization (such as treating arabic YEH and farsi YEH the
+   * same), and stopwords creates a light-stemming effect for verbs.
+   * 
+   * These verb forms are from http://en.wikipedia.org/wiki/Persian_grammar
+   */
+  public void testBehaviorVerbs() throws Exception {
+    Analyzer a = new PersianAnalyzer();
+    // active present indicative
+    assertAnalyzesTo(a, "??????±Ø?", new String[] { "Ø®?Ø±Ø¯" });
+    // active preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active imperfective preterite indicative
+    assertAnalyzesTo(a, "??????±Ø?", new String[] { "Ø®?Ø±Ø¯" });
+    // active future indicative
+    assertAnalyzesTo(a, "Ø®?Ø§?Ø¯ Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active present progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø±Ø¯ ??????±Ø?", new String[] { "Ø®?Ø±Ø¯" });
+    // active preterite progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø´Øª ??????±Ø?", new String[] { "Ø®?Ø±Ø¯" });
+
+    // active perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯???§Ø³Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective perfect indicative
+    assertAnalyzesTo(a, "??????±Ø????§Ø³Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // active pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective pluperfect indicative
+    assertAnalyzesTo(a, "??????±Ø?? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective preterite subjunctive
+    assertAnalyzesTo(a, "??????±Ø?? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective pluperfect subjunctive
+    assertAnalyzesTo(a, "??????±Ø?? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ù??", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯???§Ø³Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ø????§Ø³Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ø?? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive future indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø®?Ø§?Ø¯ Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø±Ø¯ Ø®?Ø±Ø¯? ????´Ù??", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø´Øª Ø®?Ø±Ø¯? ????´Ø?", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ø?? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ????´Ø?? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+
+    // active present subjunctive
+    assertAnalyzesTo(a, "Ø¨Ø®?Ø±Ø¯", new String[] { "Ø¨Ø®?Ø±Ø¯" });
+  }
+
+  /**
+   * This test shows how the combination of tokenization and stopwords creates a
+   * light-stemming effect for verbs.
+   * 
+   * In this case, these forms are presented with alternative orthography, using
+   * arabic yeh and whitespace. This yeh phenomenon is common for legacy text
+   * due to some previous bugs in Microsoft Windows.
+   * 
+   * These verb forms are from http://en.wikipedia.org/wiki/Persian_grammar
+   */
+  public void testBehaviorVerbsDefective() throws Exception {
+    Analyzer a = new PersianAnalyzer();
+    // active present indicative
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active imperfective preterite indicative
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active future indicative
+    assertAnalyzesTo(a, "Ø®?Ø§?Ø¯ Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active present progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø±Ø¯ ?? Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+    // active preterite progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø´Øª ?? Ø®?Ø±Ø¯", new String[] { "Ø®?Ø±Ø¯" });
+
+    // active perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø§Ø³Øª", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective perfect indicative
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯? Ø§Ø³Øª", new String[] { "Ø®?Ø±Ø¯?" });
+    // active pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective pluperfect indicative
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective preterite subjunctive
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // active imperfective pluperfect subjunctive
+    assertAnalyzesTo(a, "?? Ø®?Ø±Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective preterite indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø§Ø³Øª", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective perfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯? Ø§Ø³Øª", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective pluperfect indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯? Ø¨?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive future indicative
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø®?Ø§?Ø¯ Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø±Ø¯ Ø®?Ø±Ø¯? ?? Ø´?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite progressive indicative
+    assertAnalyzesTo(a, "Ø¯Ø§Ø´Øª Ø®?Ø±Ø¯? ?? Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive present subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´?Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective preterite subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? Ø´Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    // passive imperfective pluperfect subjunctive
+    assertAnalyzesTo(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+
+    // active present subjunctive
+    assertAnalyzesTo(a, "Ø¨Ø®?Ø±Ø¯", new String[] { "Ø¨Ø®?Ø±Ø¯" });
+  }
+
+  /**
+   * This test shows how the combination of tokenization (breaking on zero-width
+   * non-joiner or space) and stopwords creates a light-stemming effect for
+   * nouns, removing the plural -ha.
+   */
+  public void testBehaviorNouns() throws Exception {
+    Analyzer a = new PersianAnalyzer();
+    assertAnalyzesTo(a, "Ø¨Ø±Ú¯ ?Ø§", new String[] { "Ø¨Ø±Ú¯" });
+    assertAnalyzesTo(a, "Ø¨Ø±Ú¯????", new String[] { "Ø¨Ø±Ú¯" });
+  }
+
+  /**
+   * Test showing that non-persian text is treated very much like SimpleAnalyzer
+   * (lowercased, etc)
+   */
+  public void testBehaviorNonPersian() throws Exception {
+    Analyzer a = new PersianAnalyzer();
+    assertAnalyzesTo(a, "English test.", new String[] { "english", "test" });
+  }
+  
+  /**
+   * Basic test ensuring that reusableTokenStream works correctly.
+   */
+  public void testReusableTokenStream() throws Exception {
+    Analyzer a = new PersianAnalyzer();
+    assertAnalyzesToReuse(a, "Ø®?Ø±Ø¯? ?? Ø´Ø¯? Ø¨?Ø¯? Ø¨Ø§Ø´Ø¯", new String[] { "Ø®?Ø±Ø¯?" });
+    assertAnalyzesToReuse(a, "Ø¨Ø±Ú¯????", new String[] { "Ø¨Ø±Ú¯" });
+  }
+
+  private void assertAnalyzesTo(Analyzer a, String input, String[] output)
+      throws Exception {
+	TokenStream ts = a.tokenStream("dummy", new StringReader(input));
+	TermAttribute termAtt = (TermAttribute) ts.getAttribute(TermAttribute.class);
+
+	for (int i = 0; i < output.length; i++) {
+		assertTrue(ts.incrementToken());
+		assertEquals(output[i], termAtt.term());
+	}
+	
+	assertFalse(ts.incrementToken());
+    ts.close();
+  }
+  
+  private void assertAnalyzesToReuse(Analyzer a, String input, String[] output)
+      throws Exception {
+    TokenStream ts = a.reusableTokenStream("dummy", new StringReader(input));
+    TermAttribute termAtt = (TermAttribute) ts
+        .getAttribute(TermAttribute.class);
+
+    for (int i = 0; i < output.length; i++) {
+      assertTrue(ts.incrementToken());
+      assertEquals(output[i], termAtt.term());
+    }
+
+    assertFalse(ts.incrementToken());
+    ts.close();
+  }
+
+}
diff --git a/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilter.java b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilter.java
new file mode 100644
index 0000000..195cd82
--- /dev/null
+++ b/contrib/analyzers/common/src/test/org/apache/lucene/analysis/fa/TestPersianNormalizationFilter.java
@@ -0,0 +1,71 @@
+package org.apache.lucene.analysis.fa;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+
+import junit.framework.TestCase;
+
+import org.apache.lucene.analysis.ar.ArabicLetterTokenizer;
+import org.apache.lucene.analysis.tokenattributes.TermAttribute;
+
+/**
+ * Test the Arabic Normalization Filter
+ * 
+ */
+public class TestPersianNormalizationFilter extends TestCase {
+
+  public void testFarsiYeh() throws IOException {
+    check("?Ø§?", "?Ø§?");
+  }
+
+  public void testYehBarree() throws IOException {
+    check("?Ø§?", "?Ø§?");
+  }
+
+  public void testKeheh() throws IOException {
+    check("Ú©Ø´Ø§?Ø¯?", "?Ø´Ø§?Ø¯?");
+  }
+
+  public void testHehYeh() throws IOException {
+    check("?ØªØ§Ø¨?", "?ØªØ§Ø¨?");
+  }
+
+  public void testHehHamzaAbove() throws IOException {
+    check("?ØªØ§Ø¨??", "?ØªØ§Ø¨?");
+  }
+
+  public void testHehGoal() throws IOException {
+    check("Ø²Ø§Ø¯?", "Ø²Ø§Ø¯?");
+  }
+
+  private void check(final String input, final String expected)
+      throws IOException {
+    ArabicLetterTokenizer tokenStream = new ArabicLetterTokenizer(
+        new StringReader(input));
+    PersianNormalizationFilter filter = new PersianNormalizationFilter(
+        tokenStream);
+    TermAttribute termAtt = (TermAttribute) filter.getAttribute(TermAttribute.class);
+    assertTrue(filter.incrementToken());
+    assertEquals(expected, termAtt.term());
+    assertFalse(filter.incrementToken());
+    filter.close();
+  }
+
+}

