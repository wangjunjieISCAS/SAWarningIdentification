GitDiffStart: 150d8b308930928da5598661af406f4c1d9e3585 | Sun May 29 13:12:32 2011 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 6c26ecb..1c63484 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -434,6 +434,12 @@ Bug fixes
 
 ======================= Lucene 3.x (not yet released) ================
 
+Changes in backwards compatibility policy
+
+* LUCENE-3140: IndexOutput.copyBytes now takes a DataInput (superclass
+  of IndexInput) as its first argument.  (Robert Muir, Dawid Weiss,
+  Mike McCandless)
+
 Changes in runtime behavior
 
 * LUCENE-2834: the hash used to compute the lock file name when the
@@ -441,6 +447,11 @@ Changes in runtime behavior
   will see a different lucene-XXX-write.lock in your lock directory.
   (Robert Muir, Uwe Schindler, Mike McCandless)
 
+New Features
+
+* LUCENE-3140: Added experimental FST implementation to Lucene.
+  (Robert Muir, Dawid Weiss, Mike McCandless)
+
 ======================= Lucene 3.2.0 =======================
 
 Changes in backwards compatibility policy
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexReader.java b/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexReader.java
index 77dc6ed..9812d0d 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexReader.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexReader.java
@@ -33,11 +33,11 @@ import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CodecUtil;
-import org.apache.lucene.util.automaton.fst.Builder;
-import org.apache.lucene.util.automaton.fst.BytesRefFSTEnum;
-import org.apache.lucene.util.automaton.fst.FST;
-import org.apache.lucene.util.automaton.fst.PositiveIntOutputs;
-import org.apache.lucene.util.automaton.fst.Util; // for toDot
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.BytesRefFSTEnum;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
+import org.apache.lucene.util.fst.Util; // for toDot
 
 /** See {@link VariableGapTermsIndexWriter}
  * 
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexWriter.java b/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexWriter.java
index 9c1aba9..d106088 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexWriter.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/VariableGapTermsIndexWriter.java
@@ -29,9 +29,9 @@ import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CodecUtil;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.automaton.fst.Builder;
-import org.apache.lucene.util.automaton.fst.FST;
-import org.apache.lucene.util.automaton.fst.PositiveIntOutputs;
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
 
 /**
  * Selects index terms according to provided pluggable
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextFieldsReader.java b/lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextFieldsReader.java
index 5f5b68c..ab17022 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextFieldsReader.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/simpletext/SimpleTextFieldsReader.java
@@ -32,11 +32,11 @@ import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.StringHelper;
 import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util.automaton.fst.Builder;
-import org.apache.lucene.util.automaton.fst.BytesRefFSTEnum;
-import org.apache.lucene.util.automaton.fst.FST;
-import org.apache.lucene.util.automaton.fst.PositiveIntOutputs;
-import org.apache.lucene.util.automaton.fst.PairOutputs;
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.BytesRefFSTEnum;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
+import org.apache.lucene.util.fst.PairOutputs;
 
 import java.io.IOException;
 import java.util.Comparator;
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/Builder.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/Builder.java
deleted file mode 100644
index 1994917..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/Builder.java
+++ /dev/null
@@ -1,545 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-
-import java.io.IOException;
-
-/**
- * Builds a compact FST (maps an IntsRef term to an arbitrary
- * output) from pre-sorted terms with outputs (the FST
- * becomes an FSA if you use NoOutputs).  The FST is written
- * on-the-fly into a compact serialized format byte array, which can
- * be saved to / loaded from a Directory or used directly
- * for traversal.  The FST is always finite (no cycles).
- *
- * <p>NOTE: The algorithm is described at
- * http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.3698</p>
- *
- * If your outputs are ByteSequenceOutput then the final FST
- * will be minimal, but if you use PositiveIntOutput then
- * it's only "near minimal".  For example, aa/0, aab/1, bbb/2
- * will produce 6 states when a 5 state fst is also
- * possible.
- *
- * The parameterized type T is the output type.  See the
- * subclasses of {@link Outputs}.
- *
- * @lucene.experimental
- */
-
-public class Builder<T> {
-  private final NodeHash<T> dedupHash;
-  private final FST<T> fst;
-  private final T NO_OUTPUT;
-
-  // simplistic pruning: we prune node (and all following
-  // nodes) if less than this number of terms go through it:
-  private final int minSuffixCount1;
-
-  // better pruning: we prune node (and all following
-  // nodes) if the prior node has less than this number of
-  // terms go through it:
-  private final int minSuffixCount2;
-
-  private final IntsRef lastInput = new IntsRef();
-
-  // NOTE: cutting this over to ArrayList instead loses ~6%
-  // in build performance on 9.8M Wikipedia terms; so we
-  // left this as an array:
-  // current "frontier"
-  private UnCompiledNode<T>[] frontier;
-
-  public Builder(FST.INPUT_TYPE inputType, int minSuffixCount1, int minSuffixCount2, boolean doMinSuffix, Outputs<T> outputs) {
-    this.minSuffixCount1 = minSuffixCount1;
-    this.minSuffixCount2 = minSuffixCount2;
-    fst = new FST<T>(inputType, outputs);
-    if (doMinSuffix) {
-      dedupHash = new NodeHash<T>(fst);
-    } else {
-      dedupHash = null;
-    }
-    NO_OUTPUT = outputs.getNoOutput();
-
-    @SuppressWarnings("unchecked") final UnCompiledNode<T>[] f = (UnCompiledNode<T>[]) new UnCompiledNode[10];
-    frontier = f;
-    for(int idx=0;idx<frontier.length;idx++) {
-      frontier[idx] = new UnCompiledNode<T>(this, idx);
-    }
-  }
-
-  public int getTotStateCount() {
-    return fst.nodeCount;
-  }
-
-  public long getTermCount() {
-    return frontier[0].inputCount;
-  }
-
-  public int getMappedStateCount() {
-    return dedupHash == null ? 0 : fst.nodeCount;
-  }
-
-  private CompiledNode compileNode(UnCompiledNode<T> n) throws IOException {
-
-    final int address;
-    if (dedupHash != null) {
-      if (n.numArcs == 0) {
-        address = fst.addNode(n);
-      } else {
-        address = dedupHash.add(n);
-      }
-    } else {
-      address = fst.addNode(n);
-    }
-    assert address != -2;
-
-    n.clear();
-
-    final CompiledNode fn = new CompiledNode();
-    fn.address = address;
-    return fn;
-  }
-
-  private void compilePrevTail(int prefixLenPlus1) throws IOException {
-    assert prefixLenPlus1 >= 1;
-    //System.out.println("  compileTail " + prefixLenPlus1);
-    for(int idx=lastInput.length; idx >= prefixLenPlus1; idx--) {
-      boolean doPrune = false;
-      boolean doCompile = false;
-
-      final UnCompiledNode<T> node = frontier[idx];
-      final UnCompiledNode<T> parent = frontier[idx-1];
-
-      if (node.inputCount < minSuffixCount1) {
-        doPrune = true;
-        doCompile = true;
-      } else if (idx > prefixLenPlus1) {
-        // prune if parent's inputCount is less than suffixMinCount2
-        if (parent.inputCount < minSuffixCount2 || minSuffixCount2 == 1 && parent.inputCount == 1) {
-          // my parent, about to be compiled, doesn't make the cut, so
-          // I'm definitely pruned 
-
-          // if pruneCount2 is 1, we keep only up
-          // until the 'distinguished edge', ie we keep only the
-          // 'divergent' part of the FST. if my parent, about to be
-          // compiled, has inputCount 1 then we are already past the
-          // distinguished edge.  NOTE: this only works if
-          // the FST outputs are not "compressible" (simple
-          // ords ARE compressible).
-          doPrune = true;
-        } else {
-          // my parent, about to be compiled, does make the cut, so
-          // I'm definitely not pruned 
-          doPrune = false;
-        }
-        doCompile = true;
-      } else {
-        // if pruning is disabled (count is 0) we can always
-        // compile current node
-        doCompile = minSuffixCount2 == 0;
-      }
-
-      //System.out.println("    label=" + ((char) lastInput.ints[lastInput.offset+idx-1]) + " idx=" + idx + " inputCount=" + frontier[idx].inputCount + " doCompile=" + doCompile + " doPrune=" + doPrune);
-
-      if (node.inputCount < minSuffixCount2 || minSuffixCount2 == 1 && node.inputCount == 1) {
-        // drop all arcs
-        for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
-          @SuppressWarnings("unchecked") final UnCompiledNode<T> target = (UnCompiledNode<T>) node.arcs[arcIdx].target;
-          target.clear();
-        }
-        node.numArcs = 0;
-      }
-
-      if (doPrune) {
-        // this node doesn't make it -- deref it
-        node.clear();
-        parent.deleteLast(lastInput.ints[lastInput.offset+idx-1], node);
-      } else {
-
-        if (minSuffixCount2 != 0) {
-          compileAllTargets(node);
-        }
-        final T nextFinalOutput = node.output;
-
-        // We "fake" the node as being final if it has no
-        // outgoing arcs; in theory we could leave it
-        // as non-final (the FST can represent this), but
-        // FSTEnum, Util, etc., have trouble w/ non-final
-        // dead-end states:
-        final boolean isFinal = node.isFinal || node.numArcs == 0;
-
-        if (doCompile) {
-          // this node makes it and we now compile it.  first,
-          // compile any targets that were previously
-          // undecided:
-          parent.replaceLast(lastInput.ints[lastInput.offset + idx-1],
-                             compileNode(node),
-                             nextFinalOutput,
-                             isFinal);
-        } else {
-          // replaceLast just to install
-          // nextFinalOutput/isFinal onto the arc
-          parent.replaceLast(lastInput.ints[lastInput.offset + idx-1],
-                             node,
-                             nextFinalOutput,
-                             isFinal);
-          // this node will stay in play for now, since we are
-          // undecided on whether to prune it.  later, it
-          // will be either compiled or pruned, so we must
-          // allocate a new node:
-          frontier[idx] = new UnCompiledNode<T>(this, idx);
-        }
-      }
-    }
-  }
-
-  private final IntsRef scratchIntsRef = new IntsRef(10);
-
-  public void add(BytesRef input, T output) throws IOException {
-    assert fst.getInputType() == FST.INPUT_TYPE.BYTE1;
-    scratchIntsRef.grow(input.length);
-    for(int i=0;i<input.length;i++) {
-      scratchIntsRef.ints[i] = input.bytes[i+input.offset] & 0xFF;
-    }
-    scratchIntsRef.length = input.length;
-    add(scratchIntsRef, output);
-  }
-
-  /** Sugar: adds the UTF32 codepoints from char[] slice.  FST
-   *  must be FST.INPUT_TYPE.BYTE4! */
-  public void add(char[] s, int offset, int length, T output) throws IOException {
-    assert fst.getInputType() == FST.INPUT_TYPE.BYTE4;
-    int charIdx = offset;
-    int intIdx = 0;
-    final int charLimit = offset + length;
-    while(charIdx < charLimit) {
-      scratchIntsRef.grow(intIdx+1);
-      final int utf32 = Character.codePointAt(s, charIdx);
-      scratchIntsRef.ints[intIdx] = utf32;
-      charIdx += Character.charCount(utf32);
-      intIdx++;
-    }
-    scratchIntsRef.length = intIdx;
-    add(scratchIntsRef, output);
-  }
-
-  /** Sugar: adds the UTF32 codepoints from CharSequence.  FST
-   *  must be FST.INPUT_TYPE.BYTE4! */
-  public void add(CharSequence s, T output) throws IOException {
-    assert fst.getInputType() == FST.INPUT_TYPE.BYTE4;
-    int charIdx = 0;
-    int intIdx = 0;
-    final int charLimit = s.length();
-    while(charIdx < charLimit) {
-      scratchIntsRef.grow(intIdx+1);
-      final int utf32 = Character.codePointAt(s, charIdx);
-      scratchIntsRef.ints[intIdx] = utf32;
-      charIdx += Character.charCount(utf32);
-      intIdx++;
-    }
-    scratchIntsRef.length = intIdx;
-    add(scratchIntsRef, output);
-  }
-
-  /** It's OK to add the same input twice in a row with
-   *  different outputs, as long as outputs impls the merge
-   *  method. */
-  public void add(IntsRef input, T output) throws IOException {
-    //System.out.println("\nFST ADD: input=" + input + " output=" + fst.outputs.outputToString(output));
-    assert lastInput.length == 0 || input.compareTo(lastInput) >= 0: "inputs are added out of order lastInput=" + lastInput + " vs input=" + input;
-    assert validOutput(output);
-
-    //System.out.println("\nadd: " + input);
-    if (input.length == 0) {
-      // empty input: only allowed as first input.  we have
-      // to special case this because the packed FST
-      // format cannot represent the empty input since
-      // 'finalness' is stored on the incoming arc, not on
-      // the node
-      frontier[0].inputCount++;
-      frontier[0].isFinal = true;
-      fst.setEmptyOutput(output);
-      return;
-    }
-
-    // compare shared prefix length
-    int pos1 = 0;
-    int pos2 = input.offset;
-    final int pos1Stop = Math.min(lastInput.length, input.length);
-    while(true) {
-      //System.out.println("  incr " + pos1);
-      frontier[pos1].inputCount++;
-      if (pos1 >= pos1Stop || lastInput.ints[pos1] != input.ints[pos2]) {
-        break;
-      }
-      pos1++;
-      pos2++;
-    }
-    final int prefixLenPlus1 = pos1+1;
-      
-    if (frontier.length < input.length+1) {
-      @SuppressWarnings("unchecked") final UnCompiledNode<T>[] next =
-        new UnCompiledNode[ArrayUtil.oversize(input.length+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
-      System.arraycopy(frontier, 0, next, 0, frontier.length);
-      for(int idx=frontier.length;idx<next.length;idx++) {
-        next[idx] = new UnCompiledNode<T>(this, idx);
-      }
-      frontier = next;
-    }
-
-    // minimize/compile states from previous input's
-    // orphan'd suffix
-    compilePrevTail(prefixLenPlus1);
-
-    // init tail states for current input
-    for(int idx=prefixLenPlus1;idx<=input.length;idx++) {
-      frontier[idx-1].addArc(input.ints[input.offset + idx - 1],
-                             frontier[idx]);
-      //System.out.println("  incr tail " + idx);
-      frontier[idx].inputCount++;
-    }
-
-    final UnCompiledNode<T> lastNode = frontier[input.length];
-    lastNode.isFinal = true;
-    lastNode.output = NO_OUTPUT;
-
-    // push conflicting outputs forward, only as far as
-    // needed
-    for(int idx=1;idx<prefixLenPlus1;idx++) {
-      final UnCompiledNode<T> node = frontier[idx];
-      final UnCompiledNode<T> parentNode = frontier[idx-1];
-
-      final T lastOutput = parentNode.getLastOutput(input.ints[input.offset + idx - 1]);
-      assert validOutput(lastOutput);
-
-      final T commonOutputPrefix;
-      final T wordSuffix;
-
-      if (lastOutput != NO_OUTPUT) {
-        commonOutputPrefix = fst.outputs.common(output, lastOutput);
-        assert validOutput(commonOutputPrefix);
-        wordSuffix = fst.outputs.subtract(lastOutput, commonOutputPrefix);
-        assert validOutput(wordSuffix);
-        parentNode.setLastOutput(input.ints[input.offset + idx - 1], commonOutputPrefix);
-        node.prependOutput(wordSuffix);
-      } else {
-        commonOutputPrefix = wordSuffix = NO_OUTPUT;
-      }
-
-      output = fst.outputs.subtract(output, commonOutputPrefix);
-      assert validOutput(output);
-    }
-
-    if (lastInput.length == input.length && prefixLenPlus1 == 1+input.length) {
-      // same input more than 1 time in a row, mapping to
-      // multiple outputs
-      lastNode.output = fst.outputs.merge(lastNode.output, output);
-    } else {
-      // this new arc is private to this new input; set its
-      // arc output to the leftover output:
-      frontier[prefixLenPlus1-1].setLastOutput(input.ints[input.offset + prefixLenPlus1-1], output);
-    }
-
-    // save last input
-    lastInput.copy(input);
-
-    //System.out.println("  count[0]=" + frontier[0].inputCount);
-  }
-
-  private boolean validOutput(T output) {
-    return output == NO_OUTPUT || !output.equals(NO_OUTPUT);
-  }
-
-  /** Returns final FST.  NOTE: this will return null if
-   *  nothing is accepted by the FST. */
-  public FST<T> finish() throws IOException {
-
-    // minimize nodes in the last word's suffix
-    compilePrevTail(1);
-    //System.out.println("finish: inputCount=" + frontier[0].inputCount);
-    if (frontier[0].inputCount < minSuffixCount1 || frontier[0].inputCount < minSuffixCount2 || frontier[0].numArcs == 0) {
-      if (fst.emptyOutput == null) {
-        return null;
-      } else if (minSuffixCount1 > 0 || minSuffixCount2 > 0) {
-        // empty string got pruned
-        return null;
-      } else {
-        fst.finish(compileNode(frontier[0]).address);
-        //System.out.println("compile addr = " + fst.getStartNode());
-        return fst;
-      }
-    } else {
-      if (minSuffixCount2 != 0) {
-        compileAllTargets(frontier[0]);
-      }
-      //System.out.println("NOW: " + frontier[0].numArcs);
-      fst.finish(compileNode(frontier[0]).address);
-    }
-    
-    return fst;
-  }
-
-  private void compileAllTargets(UnCompiledNode<T> node) throws IOException {
-    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
-      final Arc<T> arc = node.arcs[arcIdx];
-      if (!arc.target.isCompiled()) {
-        // not yet compiled
-        @SuppressWarnings("unchecked") final UnCompiledNode<T> n = (UnCompiledNode<T>) arc.target;
-        if (n.numArcs == 0) {
-          //System.out.println("seg=" + segment + "        FORCE final arc=" + (char) arc.label);
-          arc.isFinal = n.isFinal = true;
-        }
-        arc.target = compileNode(n);
-      }
-    }
-  }
-
-  static class Arc<T> {
-    public int label;                             // really an "unsigned" byte
-    public Node target;
-    public boolean isFinal;
-    public T output;
-    public T nextFinalOutput;
-  }
-
-  // NOTE: not many instances of Node or CompiledNode are in
-  // memory while the FST is being built; it's only the
-  // current "frontier":
-
-  static interface Node {
-    boolean isCompiled();
-  }
-
-  static final class CompiledNode implements Node {
-    int address;
-    public boolean isCompiled() {
-      return true;
-    }
-  }
-
-  static final class UnCompiledNode<T> implements Node {
-    final Builder<T> owner;
-    int numArcs;
-    Arc<T>[] arcs;
-    T output;
-    boolean isFinal;
-    long inputCount;
-
-    /** This node's depth, starting from the automaton root. */
-    final int depth;
-
-    /**
-     * @param depth
-     *          The node's depth starting from the automaton root. Needed for
-     *          LUCENE-2934 (node expansion based on conditions other than the
-     *          fanout size).
-     */
-    @SuppressWarnings("unchecked")
-    public UnCompiledNode(Builder<T> owner, int depth) {
-      this.owner = owner;
-      arcs = (Arc<T>[]) new Arc[1];
-      arcs[0] = new Arc<T>();
-      output = owner.NO_OUTPUT;
-      this.depth = depth;
-    }
-
-    public boolean isCompiled() {
-      return false;
-    }
-
-    public void clear() {
-      numArcs = 0;
-      isFinal = false;
-      output = owner.NO_OUTPUT;
-      inputCount = 0;
-
-      // We don't clear the depth here because it never changes 
-      // for nodes on the frontier (even when reused).
-    }
-
-    public T getLastOutput(int labelToMatch) {
-      assert numArcs > 0;
-      assert arcs[numArcs-1].label == labelToMatch;
-      return arcs[numArcs-1].output;
-    }
-
-    public void addArc(int label, Node target) {
-      assert label >= 0;
-      assert numArcs == 0 || label > arcs[numArcs-1].label: "arc[-1].label=" + arcs[numArcs-1].label + " new label=" + label + " numArcs=" + numArcs;
-      if (numArcs == arcs.length) {
-        @SuppressWarnings("unchecked") final Arc<T>[] newArcs =
-          new Arc[ArrayUtil.oversize(numArcs+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
-        System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
-        for(int arcIdx=numArcs;arcIdx<newArcs.length;arcIdx++) {
-          newArcs[arcIdx] = new Arc<T>();
-        }
-        arcs = newArcs;
-      }
-      final Arc<T> arc = arcs[numArcs++];
-      arc.label = label;
-      arc.target = target;
-      arc.output = arc.nextFinalOutput = owner.NO_OUTPUT;
-      arc.isFinal = false;
-    }
-
-    public void replaceLast(int labelToMatch, Node target, T nextFinalOutput, boolean isFinal) {
-      assert numArcs > 0;
-      final Arc<T> arc = arcs[numArcs-1];
-      assert arc.label == labelToMatch: "arc.label=" + arc.label + " vs " + labelToMatch;
-      arc.target = target;
-      //assert target.address != -2;
-      arc.nextFinalOutput = nextFinalOutput;
-      arc.isFinal = isFinal;
-    }
-
-    public void deleteLast(int label, Node target) {
-      assert numArcs > 0;
-      assert label == arcs[numArcs-1].label;
-      assert target == arcs[numArcs-1].target;
-      numArcs--;
-    }
-
-    public void setLastOutput(int labelToMatch, T newOutput) {
-      assert owner.validOutput(newOutput);
-      assert numArcs > 0;
-      final Arc<T> arc = arcs[numArcs-1];
-      assert arc.label == labelToMatch;
-      arc.output = newOutput;
-    }
-
-    // pushes an output prefix forward onto all arcs
-    public void prependOutput(T outputPrefix) {
-      assert owner.validOutput(outputPrefix);
-
-      for(int arcIdx=0;arcIdx<numArcs;arcIdx++) {
-        arcs[arcIdx].output = owner.fst.outputs.add(outputPrefix, arcs[arcIdx].output);
-        assert owner.validOutput(arcs[arcIdx].output);
-      }
-
-      if (isFinal) {
-        output = owner.fst.outputs.add(outputPrefix, output);
-        assert owner.validOutput(output);
-      }
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/ByteSequenceOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/ByteSequenceOutputs.java
deleted file mode 100644
index f99c80f..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/ByteSequenceOutputs.java
+++ /dev/null
@@ -1,137 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.BytesRef;
-
-/**
- * Output is a sequence of bytes, for each input term.
- * @lucene.experimental
- */
-
-public final class ByteSequenceOutputs extends Outputs<BytesRef> {
-
-  private final static BytesRef NO_OUTPUT = new BytesRef();
-
-  private ByteSequenceOutputs() {
-  }
-
-  public static ByteSequenceOutputs getSingleton() {
-    return new ByteSequenceOutputs();
-  }
-
-  @Override
-  public BytesRef common(BytesRef output1, BytesRef output2) {
-    assert output1 != null;
-    assert output2 != null;
-
-    int pos1 = output1.offset;
-    int pos2 = output2.offset;
-    int stopAt1 = pos1 + Math.min(output1.length, output2.length);
-    while(pos1 < stopAt1) {
-      if (output1.bytes[pos1] != output2.bytes[pos2]) {
-        break;
-      }
-      pos1++;
-      pos2++;
-    }
-
-    if (pos1 == output1.offset) {
-      // no common prefix
-      return NO_OUTPUT;
-    } else if (pos1 == output1.offset + output1.length) {
-      // output1 is a prefix of output2
-      return output1;
-    } else if (pos2 == output2.offset + output2.length) {
-      // output2 is a prefix of output1
-      return output2;
-    } else {
-      return new BytesRef(output1.bytes, output1.offset, pos1-output1.offset);
-    }
-  }
-
-  @Override
-  public BytesRef subtract(BytesRef output, BytesRef inc) {
-    assert output != null;
-    assert inc != null;
-    if (inc == NO_OUTPUT) {
-      // no prefix removed
-      return output;
-    } else if (inc.length == output.length) {
-      // entire output removed
-      return NO_OUTPUT;
-    } else {
-      assert inc.length < output.length: "inc.length=" + inc.length + " vs output.length=" + output.length;
-      assert inc.length > 0;
-      return new BytesRef(output.bytes, output.offset + inc.length, output.length-inc.length);
-    }
-  }
-
-  @Override
-  public BytesRef add(BytesRef prefix, BytesRef output) {
-    assert prefix != null;
-    assert output != null;
-    if (prefix == NO_OUTPUT) {
-      return output;
-    } else if (output == NO_OUTPUT) {
-      return prefix;
-    } else {
-      assert prefix.length > 0;
-      assert output.length > 0;
-      BytesRef result = new BytesRef(prefix.length + output.length);
-      System.arraycopy(prefix.bytes, prefix.offset, result.bytes, 0, prefix.length);
-      System.arraycopy(output.bytes, output.offset, result.bytes, prefix.length, output.length);
-      result.length = prefix.length + output.length;
-      return result;
-    }
-  }
-
-  @Override
-  public void write(BytesRef prefix, DataOutput out) throws IOException {
-    assert prefix != null;
-    out.writeVInt(prefix.length);
-    out.writeBytes(prefix.bytes, prefix.offset, prefix.length);
-  }
-
-  @Override
-  public BytesRef read(DataInput in) throws IOException {
-    final int len = in.readVInt();
-    if (len == 0) {
-      return NO_OUTPUT;
-    } else {
-      final BytesRef output = new BytesRef(len);
-      in.readBytes(output.bytes, 0, len);
-      output.length = len;
-      return output;
-    }
-  }
-
-  @Override
-  public BytesRef getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(BytesRef output) {
-    return output.utf8ToString();
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/BytesRefFSTEnum.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/BytesRefFSTEnum.java
deleted file mode 100644
index 01ce6ef..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/BytesRefFSTEnum.java
+++ /dev/null
@@ -1,107 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.util.BytesRef;
-
-/** Can next() and advance() through the terms in an FST
-  * @lucene.experimental
-*/
-
-public final class BytesRefFSTEnum<T> extends FSTEnum<T> {
-  private final BytesRef current = new BytesRef(10);
-  private final InputOutput<T> result = new InputOutput<T>();
-  private BytesRef target;
-
-  public static class InputOutput<T> {
-    public BytesRef input;
-    public T output;
-  }
-
-  /** doFloor controls the behavior of advance: if it's true
-   *  doFloor is true, advance positions to the biggest
-   *  term before target.  */
-  public BytesRefFSTEnum(FST<T> fst) {
-    super(fst);
-    result.input = current;
-    current.offset = 1;
-  }
-
-  public InputOutput<T> current() {
-    return result;
-  }
-
-  public InputOutput<T> next() throws IOException {
-    //System.out.println("  enum.next");
-    doNext();
-    return setResult();
-  }
-
-  /** Seeks to smallest term that's >= target. */
-  public InputOutput<T> seekCeil(BytesRef target) throws IOException {
-    this.target = target;
-    targetLength = target.length;
-    super.doSeekCeil();
-    return setResult();
-  }
-
-  /** Seeks to biggest term that's <= target. */
-  public InputOutput<T> seekFloor(BytesRef target) throws IOException {
-    this.target = target;
-    targetLength = target.length;
-    super.doSeekFloor();
-    return setResult();
-  }
-
-  @Override
-  protected int getTargetLabel() {
-    if (upto-1 == target.length) {
-      return FST.END_LABEL;
-    } else {
-      return target.bytes[target.offset + upto - 1] & 0xFF;
-    }
-  }
-
-  @Override
-  protected int getCurrentLabel() {
-    // current.offset fixed at 1
-    return current.bytes[upto] & 0xFF;
-  }
-
-  @Override
-  protected void setCurrentLabel(int label) {
-    current.bytes[upto] = (byte) label;
-  }
-
-  @Override
-  protected void grow() {
-    current.grow(upto+1);
-  }
-
-  private InputOutput<T> setResult() {
-    if (upto == 0) {
-      return null;
-    } else {
-      current.length = upto-1;
-      result.output = output[upto];
-      return result;
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/FST.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/FST.java
deleted file mode 100644
index 62c5199..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/FST.java
+++ /dev/null
@@ -1,871 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.CodecUtil;
-import org.apache.lucene.util.automaton.fst.Builder.UnCompiledNode;
-
-// NOTE: while the FST is able to represent a non-final
-// dead-end state (NON_FINAL_END_NODE=0), the layres above
-// (FSTEnum, Util) have problems with this!!
-
-/** Represents an FST using a compact byte[] format.
- *  <p> The format is similar to what's used by Morfologik
- *  (http://sourceforge.net/projects/morfologik).
- * @lucene.experimental
- */
-public class FST<T> {
-  public static enum INPUT_TYPE {BYTE1, BYTE2, BYTE4};
-  public final INPUT_TYPE inputType;
-
-  private final static int BIT_FINAL_ARC = 1 << 0;
-  private final static int BIT_LAST_ARC = 1 << 1;
-  private final static int BIT_TARGET_NEXT = 1 << 2;
-  private final static int BIT_STOP_NODE = 1 << 3;
-  private final static int BIT_ARC_HAS_OUTPUT = 1 << 4;
-  private final static int BIT_ARC_HAS_FINAL_OUTPUT = 1 << 5;
-
-  // Arcs are stored as fixed-size (per entry) array, so
-  // that we can find an arc using binary search.  We do
-  // this when number of arcs is > NUM_ARCS_ARRAY:
-  private final static int BIT_ARCS_AS_FIXED_ARRAY = 1 << 6;
-
-  /**
-   * @see #shouldExpand(UnCompiledNode)
-   */
-  final static int FIXED_ARRAY_SHALLOW_DISTANCE = 3; // 0 => only root node.
-
-  /**
-   * @see #shouldExpand(UnCompiledNode)
-   */
-  final static int FIXED_ARRAY_NUM_ARCS_SHALLOW = 5;
-
-  /**
-   * @see #shouldExpand(UnCompiledNode)
-   */
-  final static int FIXED_ARRAY_NUM_ARCS_DEEP = 10;
-
-  private int[] bytesPerArc = new int[0];
-
-  // Increment version to change it
-  private final static String FILE_FORMAT_NAME = "FST";
-  private final static int VERSION_START = 0;
-  private final static int VERSION_CURRENT = VERSION_START;
-
-  // Never serialized; just used to represent the virtual
-  // final node w/ no arcs:
-  private final static int FINAL_END_NODE = -1;
-
-  // Never serialized; just used to represent the virtual
-  // non-final node w/ no arcs:
-  private final static int NON_FINAL_END_NODE = 0;
-
-  // if non-null, this FST accepts the empty string and
-  // produces this output
-  T emptyOutput;
-  private byte[] emptyOutputBytes;
-
-  private byte[] bytes;
-  int byteUpto = 0;
-
-  private int startNode = -1;
-
-  public final Outputs<T> outputs;
-
-  private int lastFrozenNode;
-
-  private final T NO_OUTPUT;
-
-  public int nodeCount;
-  public int arcCount;
-  public int arcWithOutputCount;
-
-  // If arc has this label then that arc is final/accepted
-  public static final int END_LABEL = -1;
-
-  public final static class Arc<T> {
-    public int label;
-    public T output;
-
-    int target;
-
-    byte flags;
-    T nextFinalOutput;
-    int nextArc;
-
-    // This is non-zero if current arcs are fixed array:
-    int posArcsStart;
-    int bytesPerArc;
-    int arcIdx;
-    int numArcs;
-
-    /** Returns this */
-    public Arc<T> copyFrom(Arc<T> other) {
-      label = other.label;
-      target = other.target;
-      flags = other.flags;
-      output = other.output;
-      nextFinalOutput = other.nextFinalOutput;
-      nextArc = other.nextArc;
-      if (other.bytesPerArc != 0) {
-        bytesPerArc = other.bytesPerArc;
-        posArcsStart = other.posArcsStart;
-        arcIdx = other.arcIdx;
-        numArcs = other.numArcs;
-      } else {
-        bytesPerArc = 0;
-      }
-      return this;
-    }
-
-    boolean flag(int flag) {
-      return FST.flag(flags, flag);
-    }
-
-    public boolean isLast() {
-      return flag(BIT_LAST_ARC);
-    }
-
-    boolean isFinal() {
-      return flag(BIT_FINAL_ARC);
-    }
-  };
-
-  static boolean flag(int flags, int bit) {
-    return (flags & bit) != 0;
-  }
-
-  private final BytesWriter writer;
-
-  // make a new empty FST, for building
-  public FST(INPUT_TYPE inputType, Outputs<T> outputs) {
-    this.inputType = inputType;
-    this.outputs = outputs;
-    bytes = new byte[128];
-    NO_OUTPUT = outputs.getNoOutput();
-    
-    writer = new BytesWriter();
-
-    emptyOutput = null;
-  }
-
-  // create an existing FST
-  public FST(DataInput in, Outputs<T> outputs) throws IOException {
-    this.outputs = outputs;
-    writer = null;
-    CodecUtil.checkHeader(in, FILE_FORMAT_NAME, VERSION_START, VERSION_START);
-    if (in.readByte() == 1) {
-      // accepts empty string
-      int numBytes = in.readVInt();
-      // messy
-      bytes = new byte[numBytes];
-      in.readBytes(bytes, 0, numBytes);
-      emptyOutput = outputs.read(getBytesReader(numBytes-1));
-    } else {
-      emptyOutput = null;
-    }
-    final byte t = in.readByte();
-    switch(t) {
-      case 0:
-        inputType = INPUT_TYPE.BYTE1;
-        break;
-      case 1:
-        inputType = INPUT_TYPE.BYTE2;
-        break;
-      case 2:
-        inputType = INPUT_TYPE.BYTE4;
-        break;
-    default:
-      throw new IllegalStateException("invalid input type " + t);
-    }
-    startNode = in.readVInt();
-    nodeCount = in.readVInt();
-    arcCount = in.readVInt();
-    arcWithOutputCount = in.readVInt();
-
-    bytes = new byte[in.readVInt()];
-    in.readBytes(bytes, 0, bytes.length);
-    NO_OUTPUT = outputs.getNoOutput();
-  }
-
-  public INPUT_TYPE getInputType() {
-    return inputType;
-  }
-
-  /** Returns bytes used to represent the FST */
-  public int sizeInBytes() {
-    return bytes.length;
-  }
-
-  void finish(int startNode) {
-    if (startNode == FINAL_END_NODE && emptyOutput != null) {
-      startNode = 0;
-    }
-    if (this.startNode != -1) {
-      throw new IllegalStateException("already finished");
-    }
-    byte[] finalBytes = new byte[writer.posWrite];
-    System.arraycopy(bytes, 0, finalBytes, 0, writer.posWrite);
-    bytes = finalBytes;
-    this.startNode = startNode;
-  }
-
-  void setEmptyOutput(T v) throws IOException {
-    if (emptyOutput != null) {
-      emptyOutput = outputs.merge(emptyOutput, v);
-    } else {
-      emptyOutput = v;
-    }
-
-    // TODO: this is messy -- replace with sillyBytesWriter; maybe make
-    // bytes private
-    final int posSave = writer.posWrite;
-    outputs.write(emptyOutput, writer);
-    emptyOutputBytes = new byte[writer.posWrite-posSave];
-
-    // reverse
-    final int stopAt = (writer.posWrite - posSave)/2;
-    int upto = 0;
-    while(upto < stopAt) {
-      final byte b = bytes[posSave + upto];
-      bytes[posSave+upto] = bytes[writer.posWrite-upto-1];
-      bytes[writer.posWrite-upto-1] = b;
-      upto++;
-    }
-    System.arraycopy(bytes, posSave, emptyOutputBytes, 0, writer.posWrite-posSave);
-    writer.posWrite = posSave;
-  }
-
-  public void save(DataOutput out) throws IOException {
-    if (startNode == -1) {
-      throw new IllegalStateException("call finish first");
-    }
-    CodecUtil.writeHeader(out, FILE_FORMAT_NAME, VERSION_CURRENT);
-    // TODO: really we should encode this as an arc, arriving
-    // to the root node, instead of special casing here:
-    if (emptyOutput != null) {
-      out.writeByte((byte) 1);
-      out.writeVInt(emptyOutputBytes.length);
-      out.writeBytes(emptyOutputBytes, 0, emptyOutputBytes.length);
-    } else {
-      out.writeByte((byte) 0);
-    }
-    final byte t;
-    if (inputType == INPUT_TYPE.BYTE1) {
-      t = 0;
-    } else if (inputType == INPUT_TYPE.BYTE2) {
-      t = 1;
-    } else {
-      t = 2;
-    }
-    out.writeByte(t);
-    out.writeVInt(startNode);
-    out.writeVInt(nodeCount);
-    out.writeVInt(arcCount);
-    out.writeVInt(arcWithOutputCount);
-    out.writeVInt(bytes.length);
-    out.writeBytes(bytes, 0, bytes.length);
-  }
-
-  private void writeLabel(int v) throws IOException {
-    assert v >= 0: "v=" + v;
-    if (inputType == INPUT_TYPE.BYTE1) {
-      assert v <= 255: "v=" + v;
-      writer.writeByte((byte) v);
-    } else if (inputType == INPUT_TYPE.BYTE2) {
-      assert v <= 65535: "v=" + v;
-      writer.writeVInt(v);
-    } else {
-      //writeInt(v);
-      writer.writeVInt(v);
-    }
-  }
-
-  int readLabel(DataInput in) throws IOException {
-    final int v;
-    if (inputType == INPUT_TYPE.BYTE1) {
-      v = in.readByte()&0xFF;
-    } else { 
-      v = in.readVInt();
-    }
-    return v;
-  }
-
-  // returns true if the node at this address has any
-  // outgoing arcs
-  public boolean targetHasArcs(Arc<T> arc) {
-    return arc.target > 0;
-  }
-
-  // serializes new node by appending its bytes to the end
-  // of the current byte[]
-  int addNode(Builder.UnCompiledNode<T> node) throws IOException {
-    //System.out.println("FST.addNode pos=" + posWrite + " numArcs=" + node.numArcs);
-    if (node.numArcs == 0) {
-      if (node.isFinal) {
-        return FINAL_END_NODE;
-      } else {
-        return NON_FINAL_END_NODE;
-      }
-    }
-
-    int startAddress = writer.posWrite;
-    //System.out.println("  startAddr=" + startAddress);
-
-    final boolean doFixedArray = shouldExpand(node);
-    final int fixedArrayStart;
-    if (doFixedArray) {
-      if (bytesPerArc.length < node.numArcs) {
-        bytesPerArc = new int[ArrayUtil.oversize(node.numArcs, 1)];
-      }
-      // write a "false" first arc:
-      writer.writeByte((byte) BIT_ARCS_AS_FIXED_ARRAY);
-      writer.writeVInt(node.numArcs);
-      // placeholder -- we'll come back and write the number
-      // of bytes per arc here:
-      writer.writeByte((byte) 0);
-      fixedArrayStart = writer.posWrite;
-      //System.out.println("  do fixed arcs array arcsStart=" + fixedArrayStart);
-    } else {
-      fixedArrayStart = 0;
-    }
-
-    nodeCount++;
-    arcCount += node.numArcs;
-    
-    final int lastArc = node.numArcs-1;
-
-    int lastArcStart = writer.posWrite;
-    int maxBytesPerArc = 0;
-    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
-      final Builder.Arc<T> arc = node.arcs[arcIdx];
-      final Builder.CompiledNode target = (Builder.CompiledNode) arc.target;
-      int flags = 0;
-
-      if (arcIdx == lastArc) {
-        flags += BIT_LAST_ARC;
-      }
-
-      if (lastFrozenNode == target.address && !doFixedArray) {
-        flags += BIT_TARGET_NEXT;
-      }
-
-      if (arc.isFinal) {
-        flags += BIT_FINAL_ARC;
-        if (arc.nextFinalOutput != NO_OUTPUT) {
-          flags += BIT_ARC_HAS_FINAL_OUTPUT;
-        }
-      } else {
-        assert arc.nextFinalOutput == NO_OUTPUT;
-      }
-
-      boolean targetHasArcs = target.address > 0;
-
-      if (!targetHasArcs) {
-        flags += BIT_STOP_NODE;
-      }
-
-      if (arc.output != NO_OUTPUT) {
-        flags += BIT_ARC_HAS_OUTPUT;
-      }
-
-      writer.writeByte((byte) flags);
-      writeLabel(arc.label);
-
-      //System.out.println("  write arc: label=" + arc.label + " flags=" + flags);
-
-      if (arc.output != NO_OUTPUT) {
-        outputs.write(arc.output, writer);
-        arcWithOutputCount++;
-      }
-      if (arc.nextFinalOutput != NO_OUTPUT) {
-        outputs.write(arc.nextFinalOutput, writer);
-      }
-
-      if (targetHasArcs && (doFixedArray || lastFrozenNode != target.address)) {
-        assert target.address > 0;
-        writer.writeInt(target.address);
-      }
-
-      // just write the arcs "like normal" on first pass,
-      // but record how many bytes each one took, and max
-      // byte size:
-      if (doFixedArray) {
-        bytesPerArc[arcIdx] = writer.posWrite - lastArcStart;
-        lastArcStart = writer.posWrite;
-        maxBytesPerArc = Math.max(maxBytesPerArc, bytesPerArc[arcIdx]);
-        //System.out.println("    bytes=" + bytesPerArc[arcIdx]);
-      }
-    }
-
-    if (doFixedArray) {
-      assert maxBytesPerArc > 0;
-      // 2nd pass just "expands" all arcs to take up a fixed
-      // byte size
-      final int sizeNeeded = fixedArrayStart + node.numArcs * maxBytesPerArc;
-      bytes = ArrayUtil.grow(bytes, sizeNeeded);
-      if (maxBytesPerArc > 255) {
-        throw new IllegalStateException("max arc size is too large (" + maxBytesPerArc + ")");
-      }
-      bytes[fixedArrayStart-1] = (byte) maxBytesPerArc;
-
-      // expand the arcs in place, backwards
-      int srcPos = writer.posWrite;
-      int destPos = fixedArrayStart + node.numArcs*maxBytesPerArc;
-      writer.posWrite = destPos;
-      for(int arcIdx=node.numArcs-1;arcIdx>=0;arcIdx--) {
-        //System.out.println("  repack arcIdx=" + arcIdx + " srcPos=" + srcPos + " destPos=" + destPos);
-        destPos -= maxBytesPerArc;
-        srcPos -= bytesPerArc[arcIdx];
-        if (srcPos != destPos) {
-          assert destPos > srcPos;
-          System.arraycopy(bytes, srcPos, bytes, destPos, bytesPerArc[arcIdx]);
-        }
-      }
-    }
-
-    // reverse bytes in-place; we do this so that the
-    // "BIT_TARGET_NEXT" opto can work, ie, it reads the
-    // node just before the current one
-    final int endAddress = lastFrozenNode = writer.posWrite - 1;
-
-    int left = startAddress;
-    int right = endAddress;
-    while (left < right) {
-      final byte b = bytes[left];
-      bytes[left++] = bytes[right];
-      bytes[right--] = b;
-    }
-
-    return endAddress;
-  }
-
-  /** Fills virtual 'start' arc, ie, an empty incoming arc to
-   *  the FST's start node */
-  public Arc<T> getFirstArc(Arc<T> arc) {
-    if (emptyOutput != null) {
-      arc.flags = BIT_FINAL_ARC | BIT_LAST_ARC;
-      arc.nextFinalOutput = emptyOutput;
-    } else {
-      arc.flags = BIT_LAST_ARC;
-      arc.nextFinalOutput = NO_OUTPUT;
-    }
-    arc.output = NO_OUTPUT;
-
-    // If there are no nodes, ie, the FST only accepts the
-    // empty string, then startNode is 0, and then readFirstTargetArc
-    arc.target = startNode;
-    return arc;
-  }
-
-  /** Follows the <code>follow</code> arc and reads the last
-   *  arc of its target; this changes the provided
-   *  <code>arc</code> (2nd arg) in-place and returns it.
-   * 
-   * @return Returns the second argument
-   * (<code>arc</code>). */
-  public Arc<T> readLastTargetArc(Arc<T> follow, Arc<T> arc) throws IOException {
-    //System.out.println("readLast");
-    if (!targetHasArcs(follow)) {
-      //System.out.println("  end node");
-      assert follow.isFinal();
-      arc.label = -1;
-      arc.output = follow.nextFinalOutput;
-      arc.flags = BIT_LAST_ARC;
-      return arc;
-    } else {
-      final BytesReader in = getBytesReader(follow.target);
-      arc.flags = in.readByte();
-      if (arc.flag(BIT_ARCS_AS_FIXED_ARRAY)) {
-        // array: jump straight to end
-        arc.numArcs = in.readVInt();
-        arc.bytesPerArc = in.readByte() & 0xFF;
-        //System.out.println("  array numArcs=" + arc.numArcs + " bpa=" + arc.bytesPerArc);
-        arc.posArcsStart = in.pos;
-        arc.arcIdx = arc.numArcs - 2;
-      } else {
-        // non-array: linear scan
-        arc.bytesPerArc = 0;
-        //System.out.println("  scan");
-        while(!arc.isLast()) {
-          // skip this arc:
-          readLabel(in);
-          if (arc.flag(BIT_ARC_HAS_OUTPUT)) {
-            outputs.read(in);
-          }
-          if (arc.flag(BIT_ARC_HAS_FINAL_OUTPUT)) {
-            outputs.read(in);
-          }
-          if (arc.flag(BIT_STOP_NODE)) {
-          } else if (arc.flag(BIT_TARGET_NEXT)) {
-          } else {
-            in.pos -= 4;
-          }
-          arc.flags = in.readByte();
-        }
-        arc.nextArc = in.pos+1;
-      }
-      readNextRealArc(arc);
-      assert arc.isLast();
-      return arc;
-    }
-  }
-
-  /**
-   * Follow the <code>follow</code> arc and read the first arc of its target;
-   * this changes the provided <code>arc</code> (2nd arg) in-place and returns
-   * it.
-   * 
-   * @return Returns the second argument (<code>arc</code>).
-   */
-  public Arc<T> readFirstTargetArc(Arc<T> follow, Arc<T> arc) throws IOException {
-    //int pos = address;
-    //System.out.println("    readFirstTarget follow.target=" + follow.target + " isFinal=" + follow.isFinal());
-    if (follow.isFinal()) {
-      // Insert "fake" final first arc:
-      arc.label = -1;
-      arc.output = follow.nextFinalOutput;
-      if (follow.target <= 0) {
-        arc.flags = BIT_LAST_ARC;
-      } else {
-        arc.flags = 0;
-        arc.nextArc = follow.target;
-      }
-      //System.out.println("    insert isFinal; nextArc=" + follow.target + " isLast=" + arc.isLast() + " output=" + outputs.outputToString(arc.output));
-      return arc;
-    } else {
-      return readFirstRealArc(follow.target, arc);
-    }
-  }
-
-  // Not private because NodeHash needs access:
-  Arc<T> readFirstRealArc(int address, Arc<T> arc) throws IOException {
-
-    final BytesReader in = getBytesReader(address);
-
-    arc.flags = in.readByte();
-
-    if (arc.flag(BIT_ARCS_AS_FIXED_ARRAY)) {
-      //System.out.println("  fixedArray");
-      // this is first arc in a fixed-array
-      arc.numArcs = in.readVInt();
-      arc.bytesPerArc = in.readByte() & 0xFF;
-      arc.arcIdx = -1;
-      arc.nextArc = arc.posArcsStart = in.pos;
-      //System.out.println("  bytesPer=" + arc.bytesPerArc + " numArcs=" + arc.numArcs + " arcsStart=" + pos);
-    } else {
-      arc.nextArc = address;
-      arc.bytesPerArc = 0;
-    }
-    return readNextRealArc(arc);
-  }
-
-  /**
-   * Checks if <code>arc</code>'s target state is in expanded (or vector) format. 
-   * 
-   * @return Returns <code>true</code> if <code>arc</code> points to a state in an
-   * expanded array format.
-   */
-  boolean isExpandedTarget(Arc<T> follow) throws IOException {
-    if (!targetHasArcs(follow)) {
-      return false;
-    } else {
-      final BytesReader in = getBytesReader(follow.target);
-      final byte b = in.readByte();
-      return (b & BIT_ARCS_AS_FIXED_ARRAY) != 0;
-    }
-  }
-
-  /** In-place read; returns the arc. */
-  public Arc<T> readNextArc(Arc<T> arc) throws IOException {
-    if (arc.label == -1) {
-      // This was a fake inserted "final" arc
-      if (arc.nextArc <= 0) {
-        // This arc went to virtual final node, ie has no outgoing arcs
-        return null;
-      }
-      return readFirstRealArc(arc.nextArc, arc);
-    } else {
-      return readNextRealArc(arc);
-    }
-  }
-
-  /** Peeks at next arc's label; does not alter arc.  Do
-   *  not call this if arc.isLast()! */
-  public int readNextArcLabel(Arc<T> arc) throws IOException {
-    assert !arc.isLast();
-
-    final BytesReader in;
-    if (arc.label == END_LABEL) {
-      //System.out.println("    nextArc fake " + arc.nextArc);
-      in = getBytesReader(arc.nextArc);
-      byte flags = bytes[in.pos];
-      if (flag(flags, BIT_ARCS_AS_FIXED_ARRAY)) {
-        //System.out.println("    nextArc fake array");
-        in.pos--;
-        in.readVInt();
-        in.readByte();
-      }
-    } else {
-      if (arc.bytesPerArc != 0) {
-        //System.out.println("    nextArc real array");
-        // arcs are at fixed entries
-        in = getBytesReader(arc.posArcsStart - (1+arc.arcIdx)*arc.bytesPerArc);
-      } else {
-        // arcs are packed
-        //System.out.println("    nextArc real packed");
-        in = getBytesReader(arc.nextArc);
-      }
-    }
-    // skip flags
-    in.readByte();
-    return readLabel(in);
-  }
-
-  Arc<T> readNextRealArc(Arc<T> arc) throws IOException {
-    // this is a continuing arc in a fixed array
-    final BytesReader in;
-    if (arc.bytesPerArc != 0) {
-      // arcs are at fixed entries
-      arc.arcIdx++;
-      assert arc.arcIdx < arc.numArcs;
-      in = getBytesReader(arc.posArcsStart - arc.arcIdx*arc.bytesPerArc);
-    } else {
-      // arcs are packed
-      in = getBytesReader(arc.nextArc);
-    }
-    arc.flags = in.readByte();
-    arc.label = readLabel(in);
-
-    if (arc.flag(BIT_ARC_HAS_OUTPUT)) {
-      arc.output = outputs.read(in);
-    } else {
-      arc.output = outputs.getNoOutput();
-    }
-
-    if (arc.flag(BIT_ARC_HAS_FINAL_OUTPUT)) {
-      arc.nextFinalOutput = outputs.read(in);
-    } else {
-      arc.nextFinalOutput = outputs.getNoOutput();
-    }
-
-    if (arc.flag(BIT_STOP_NODE)) {
-      if (arc.flag(BIT_FINAL_ARC)) {
-        arc.target = FINAL_END_NODE;
-      } else {
-        arc.target = NON_FINAL_END_NODE;
-      }
-      arc.nextArc = in.pos;
-    } else if (arc.flag(BIT_TARGET_NEXT)) {
-      arc.nextArc = in.pos;
-      if (!arc.flag(BIT_LAST_ARC)) {
-        if (arc.bytesPerArc == 0) {
-          // must scan
-          seekToNextNode(in);
-        } else {
-          in.pos = arc.posArcsStart - arc.bytesPerArc * arc.numArcs;
-        }
-      }
-      arc.target = in.pos;
-    } else {
-      arc.target = in.readInt();
-      arc.nextArc = in.pos;
-    }
-
-    return arc;
-  }
-
-  /** Finds an arc leaving the incoming arc, replacing the arc in place.
-   *  This returns null if the arc was not found, else the incoming arc. */
-  public Arc<T> findTargetArc(int labelToMatch, Arc<T> follow, Arc<T> arc) throws IOException {
-
-    if (labelToMatch == END_LABEL) {
-      if (follow.isFinal()) {
-        arc.output = follow.nextFinalOutput;
-        arc.label = END_LABEL;
-        return arc;
-      } else {
-        return null;
-      }
-    }
-
-    if (!targetHasArcs(follow)) {
-      return null;
-    }
-
-    // TODO: maybe make an explicit thread state that holds
-    // reusable stuff eg BytesReader:
-    final BytesReader in = getBytesReader(follow.target);
-
-    if ((in.readByte() & BIT_ARCS_AS_FIXED_ARRAY) != 0) {
-      // Arcs are full array; do binary search:
-      arc.numArcs = in.readVInt();
-      arc.bytesPerArc = in.readByte() & 0xFF;
-      arc.posArcsStart = in.pos;
-      int low = 0;
-      int high = arc.numArcs-1;
-      while (low <= high) {
-        int mid = (low + high) >>> 1;
-        in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
-        int midLabel = readLabel(in);
-        final int cmp = midLabel - labelToMatch;
-        if (cmp < 0)
-          low = mid + 1;
-        else if (cmp > 0)
-          high = mid - 1;
-        else {
-          arc.arcIdx = mid-1;
-          return readNextRealArc(arc);
-        }
-      }
-
-      return null;
-    }
-
-    // Linear scan
-    readFirstTargetArc(follow, arc);
-    while(true) {
-      if (arc.label == labelToMatch) {
-        return arc;
-      } else if (arc.label > labelToMatch) {
-        return null;
-      } else if (arc.isLast()) {
-        return null;
-      } else {
-        readNextArc(arc);
-      }
-    }
-  }
-
-  private void seekToNextNode(BytesReader in) throws IOException {
-
-    while(true) {
-
-      final int flags = in.readByte();
-      readLabel(in);
-
-      if (flag(flags, BIT_ARC_HAS_OUTPUT)) {
-        outputs.read(in);
-      }
-
-      if (flag(flags, BIT_ARC_HAS_FINAL_OUTPUT)) {
-        outputs.read(in);
-      }
-
-      if (!flag(flags, BIT_STOP_NODE) && !flag(flags, BIT_TARGET_NEXT)) {
-        in.readInt();
-      }
-
-      if (flag(flags, BIT_LAST_ARC)) {
-        return;
-      }
-    }
-  }
-
-  public int getNodeCount() {
-    // 1+ in order to count the -1 implicit final node
-    return 1+nodeCount;
-  }
-  
-  public int getArcCount() {
-    return arcCount;
-  }
-
-  public int getArcWithOutputCount() {
-    return arcWithOutputCount;
-  }
-  
-  /**
-   * Nodes will be expanded if their depth (distance from the root node) is
-   * &lt;= this value and their number of arcs is &gt;=
-   * {@link #FIXED_ARRAY_NUM_ARCS_SHALLOW}.
-   * 
-   * <p>
-   * Fixed array consumes more RAM but enables binary search on the arcs
-   * (instead of a linear scan) on lookup by arc label.
-   * 
-   * @return <code>true</code> if <code>node</code> should be stored in an
-   *         expanded (array) form.
-   * 
-   * @see #FIXED_ARRAY_NUM_ARCS_DEEP
-   * @see Builder.UnCompiledNode#depth
-   */
-  private boolean shouldExpand(UnCompiledNode<T> node) {
-    return (node.depth <= FIXED_ARRAY_SHALLOW_DISTANCE && node.numArcs >= FIXED_ARRAY_NUM_ARCS_SHALLOW) || 
-            node.numArcs >= FIXED_ARRAY_NUM_ARCS_DEEP;
-  }
-
-  // Non-static: writes to FST's byte[]
-  class BytesWriter extends DataOutput {
-    int posWrite;
-
-    public BytesWriter() {
-      // pad: ensure no node gets address 0 which is reserved to mean
-      // the stop state w/ no arcs
-      posWrite = 1;
-    }
-
-    @Override
-    public void writeByte(byte b) {
-      if (bytes.length == posWrite) {
-        bytes = ArrayUtil.grow(bytes);
-      }
-      assert posWrite < bytes.length: "posWrite=" + posWrite + " bytes.length=" + bytes.length;
-      bytes[posWrite++] = b;
-    }
-
-    @Override
-    public void writeBytes(byte[] b, int offset, int length) {
-      final int size = posWrite + length;
-      bytes = ArrayUtil.grow(bytes, size);
-      System.arraycopy(b, offset, bytes, posWrite, length);
-      posWrite += length;
-    }
-  }
-
-  final BytesReader getBytesReader(int pos) {
-    // TODO: maybe re-use via ThreadLocal?
-    return new BytesReader(pos);
-  }
-
-  // Non-static: reads byte[] from FST
-  class BytesReader extends DataInput {
-    int pos;
-
-    public BytesReader(int pos) {
-      this.pos = pos;
-    }
-
-    @Override
-    public byte readByte() {
-      return bytes[pos--];
-    }
-
-    @Override
-    public void readBytes(byte[] b, int offset, int len) {
-      for(int i=0;i<len;i++) {
-        b[offset+i] = bytes[pos--];
-      }
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/FSTEnum.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/FSTEnum.java
deleted file mode 100644
index db1b7dd..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/FSTEnum.java
+++ /dev/null
@@ -1,478 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.RamUsageEstimator;
-
-import java.io.IOException;
-
-/** Can next() and advance() through the terms in an FST
-  * @lucene.experimental
-*/
-
-abstract class FSTEnum<T> {
-  protected final FST<T> fst;
-
-  @SuppressWarnings("unchecked") protected FST.Arc<T>[] arcs = new FST.Arc[10];
-  // outputs are cumulative
-  @SuppressWarnings("unchecked") protected T[] output = (T[]) new Object[10];
-
-  protected final T NO_OUTPUT;
-  protected final FST.Arc<T> scratchArc = new FST.Arc<T>();
-
-  protected int upto;
-  protected int targetLength;
-
-  /** doFloor controls the behavior of advance: if it's true
-   *  doFloor is true, advance positions to the biggest
-   *  term before target.  */
-  protected FSTEnum(FST<T> fst) {
-    this.fst = fst;
-    NO_OUTPUT = fst.outputs.getNoOutput();
-    fst.getFirstArc(getArc(0));
-    output[0] = NO_OUTPUT;
-  }
-
-  protected abstract int getTargetLabel();
-  protected abstract int getCurrentLabel();
-
-  protected abstract void setCurrentLabel(int label);
-  protected abstract void grow();
-
-  /** Rewinds enum state to match the shared prefix between
-   *  current term and target term */
-  protected final void rewindPrefix() throws IOException {
-    if (upto == 0) {
-      //System.out.println("  init");
-      upto = 1;
-      fst.readFirstTargetArc(getArc(0), getArc(1));
-      return;
-    }
-    //System.out.println("  rewind upto=" + upto + " vs targetLength=" + targetLength);
-
-    final int currentLimit = upto;
-    upto = 1;
-    while (upto < currentLimit && upto <= targetLength+1) {
-      final int cmp = getCurrentLabel() - getTargetLabel();
-      if (cmp < 0) {
-        // seek forward
-        break;
-      } else if (cmp > 0) {
-        // seek backwards -- reset this arc to the first arc
-        final FST.Arc<T> arc = getArc(upto);
-        fst.readFirstTargetArc(getArc(upto-1), arc);
-        //System.out.println("    seek first arc");
-        break;
-      }
-      upto++;
-    }
-  }
-
-  protected void doNext() throws IOException {
-    //System.out.println("FE: next upto=" + upto);
-    if (upto == 0) {
-      //System.out.println("  init");
-      upto = 1;
-      fst.readFirstTargetArc(getArc(0), getArc(1));
-    } else {
-      // pop
-      //System.out.println("  check pop curArc target=" + arcs[upto].target + " label=" + arcs[upto].label + " isLast?=" + arcs[upto].isLast());
-      while (arcs[upto].isLast()) {
-        upto--;
-        if (upto == 0) {
-          //System.out.println("  eof");
-          return;
-        }
-      }
-      fst.readNextArc(arcs[upto]);
-    }
-
-    pushFirst();
-  }
-
-  // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
-  // SEEK_END)?  saves the eq check above?
-
-  /** Seeks to smallest term that's >= target. */
-  protected void doSeekCeil() throws IOException {
-
-    //System.out.println("    advance len=" + target.length + " curlen=" + current.length);
-
-    // TODO: possibly caller could/should provide common
-    // prefix length?  ie this work may be redundant if
-    // caller is in fact intersecting against its own
-    // automaton
-
-    //System.out.println("FE.seekCeil upto=" + upto);
-
-    // Save time by starting at the end of the shared prefix
-    // b/w our current term & the target:
-    rewindPrefix();
-    //System.out.println("  after rewind upto=" + upto);
-
-    FST.Arc<T> arc = getArc(upto);
-    int targetLabel = getTargetLabel();
-    //System.out.println("  init targetLabel=" + targetLabel);
-
-    // Now scan forward, matching the new suffix of the target
-    while(true) {
-
-      //System.out.println("  cycle upto=" + upto + " arc.label=" + arc.label + " (" + (char) arc.label + ") vs targetLabel=" + targetLabel);
-
-      if (arc.bytesPerArc != 0 && arc.label != -1) {
-
-        // Arcs are fixed array -- use binary search to find
-        // the target.
-
-        final FST<T>.BytesReader in = fst.getBytesReader(0);
-        int low = arc.arcIdx;
-        int high = arc.numArcs-1;
-        int mid = 0;
-        //System.out.println("do arc array low=" + low + " high=" + high + " targetLabel=" + targetLabel);
-        boolean found = false;
-        while (low <= high) {
-          mid = (low + high) >>> 1;
-          in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
-          final int midLabel = fst.readLabel(in);
-          final int cmp = midLabel - targetLabel;
-          //System.out.println("  cycle low=" + low + " high=" + high + " mid=" + mid + " midLabel=" + midLabel + " cmp=" + cmp);
-          if (cmp < 0)
-            low = mid + 1;
-          else if (cmp > 0)
-            high = mid - 1;
-          else {
-            found = true;
-            break;
-          }
-        }
-
-        // NOTE: this code is dup'd w/ the code below (in
-        // the outer else clause):
-        if (found) {
-          // Match
-          arc.arcIdx = mid-1;
-          fst.readNextRealArc(arc);
-          assert arc.arcIdx == mid;
-          assert arc.label == targetLabel: "arc.label=" + arc.label + " vs targetLabel=" + targetLabel + " mid=" + mid;
-          output[upto] = fst.outputs.add(output[upto-1], arc.output);
-          if (targetLabel == FST.END_LABEL) {
-            return;
-          }
-          setCurrentLabel(arc.label);
-          incr();
-          arc = fst.readFirstTargetArc(arc, getArc(upto));
-          targetLabel = getTargetLabel();
-          continue;
-        } else if (low == arc.numArcs) {
-          // Dead end
-          arc.arcIdx = arc.numArcs-2;
-          fst.readNextRealArc(arc);
-          assert arc.isLast();
-          // Dead end (target is after the last arc);
-          // rollback to last fork then push
-          upto--;
-          while(true) {
-            if (upto == 0) {
-              return;
-            }
-            final FST.Arc<T> prevArc = getArc(upto);
-            //System.out.println("  rollback upto=" + upto + " arc.label=" + prevArc.label + " isLast?=" + prevArc.isLast());
-            if (!prevArc.isLast()) {
-              fst.readNextArc(prevArc);
-              pushFirst();
-              return;
-            }
-            upto--;
-          }
-        } else {
-          arc.arcIdx = (low > high ? low : high)-1;
-          fst.readNextRealArc(arc);
-          assert arc.label > targetLabel;
-          pushFirst();
-          return;
-        }
-      } else {
-        // Arcs are not array'd -- must do linear scan:
-        if (arc.label == targetLabel) {
-          // recurse
-          output[upto] = fst.outputs.add(output[upto-1], arc.output);
-          if (targetLabel == FST.END_LABEL) {
-            return;
-          }
-          setCurrentLabel(arc.label);
-          incr();
-          arc = fst.readFirstTargetArc(arc, getArc(upto));
-          targetLabel = getTargetLabel();
-        } else if (arc.label > targetLabel) {
-          pushFirst();
-          return;
-        } else if (arc.isLast()) {
-          // Dead end (target is after the last arc);
-          // rollback to last fork then push
-          upto--;
-          while(true) {
-            if (upto == 0) {
-              return;
-            }
-            final FST.Arc<T> prevArc = getArc(upto);
-            //System.out.println("  rollback upto=" + upto + " arc.label=" + prevArc.label + " isLast?=" + prevArc.isLast());
-            if (!prevArc.isLast()) {
-              fst.readNextArc(prevArc);
-              pushFirst();
-              return;
-            }
-            upto--;
-          }
-        } else {
-          // keep scanning
-          //System.out.println("    next scan");
-          fst.readNextArc(arc);
-        }
-      }
-    }
-  }
-
-  // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
-  // SEEK_END)?  saves the eq check above?
-  /** Seeks to largest term that's <= target. */
-  protected void doSeekFloor() throws IOException {
-
-    // TODO: possibly caller could/should provide common
-    // prefix length?  ie this work may be redundant if
-    // caller is in fact intersecting against its own
-    // automaton
-    //System.out.println("FE: seek floor upto=" + upto);
-
-    // Save CPU by starting at the end of the shared prefix
-    // b/w our current term & the target:
-    rewindPrefix();
-
-    //System.out.println("FE: after rewind upto=" + upto);
-
-    FST.Arc<T> arc = getArc(upto);
-    int targetLabel = getTargetLabel();
-
-    //System.out.println("FE: init targetLabel=" + targetLabel);
-
-    // Now scan forward, matching the new suffix of the target
-    while(true) {
-      //System.out.println("  cycle upto=" + upto + " arc.label=" + arc.label + " (" + (char) arc.label + ") targetLabel=" + targetLabel + " isLast?=" + arc.isLast());
-
-      if (arc.bytesPerArc != 0 && arc.label != FST.END_LABEL) {
-        // Arcs are fixed array -- use binary search to find
-        // the target.
-
-        final FST<T>.BytesReader in = fst.getBytesReader(0);
-        int low = arc.arcIdx;
-        int high = arc.numArcs-1;
-        int mid = 0;
-        //System.out.println("do arc array low=" + low + " high=" + high + " targetLabel=" + targetLabel);
-        boolean found = false;
-        while (low <= high) {
-          mid = (low + high) >>> 1;
-          in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
-          final int midLabel = fst.readLabel(in);
-          final int cmp = midLabel - targetLabel;
-          //System.out.println("  cycle low=" + low + " high=" + high + " mid=" + mid + " midLabel=" + midLabel + " cmp=" + cmp);
-          if (cmp < 0)
-            low = mid + 1;
-          else if (cmp > 0)
-            high = mid - 1;
-          else {
-            found = true;
-            break;
-          }
-        }
-
-        // NOTE: this code is dup'd w/ the code below (in
-        // the outer else clause):
-        if (found) {
-          // Match -- recurse
-          //System.out.println("  match!  arcIdx=" + mid);
-          arc.arcIdx = mid-1;
-          fst.readNextRealArc(arc);
-          assert arc.arcIdx == mid;
-          assert arc.label == targetLabel: "arc.label=" + arc.label + " vs targetLabel=" + targetLabel + " mid=" + mid;
-          output[upto] = fst.outputs.add(output[upto-1], arc.output);
-          if (targetLabel == FST.END_LABEL) {
-            return;
-          }
-          setCurrentLabel(arc.label);
-          incr();
-          arc = fst.readFirstTargetArc(arc, getArc(upto));
-          targetLabel = getTargetLabel();
-          continue;
-        } else if (high == -1) {
-          //System.out.println("  before first");
-          // Very first arc is after our target
-          // TODO: if each arc could somehow read the arc just
-          // before, we can save this re-scan.  The ceil case
-          // doesn't need this because it reads the next arc
-          // instead:
-          while(true) {
-            // First, walk backwards until we find a first arc
-            // that's before our target label:
-            fst.readFirstTargetArc(getArc(upto-1), arc);
-            if (arc.label < targetLabel) {
-              // Then, scan forwards to the arc just before
-              // the targetLabel:
-              while(!arc.isLast() && fst.readNextArcLabel(arc) < targetLabel) {
-                fst.readNextArc(arc);
-              }
-              pushLast();
-              return;
-            }
-            upto--;
-            if (upto == 0) {
-              return;
-            }
-            targetLabel = getTargetLabel();
-            arc = getArc(upto);
-          }
-        } else {
-          // There is a floor arc:
-          arc.arcIdx = (low > high ? high : low)-1;
-          //System.out.println(" hasFloor arcIdx=" + (arc.arcIdx+1));
-          fst.readNextRealArc(arc);
-          assert arc.isLast() || fst.readNextArcLabel(arc) > targetLabel;
-          assert arc.label < targetLabel;
-          pushLast();
-          return;
-        }        
-      } else {
-
-        if (arc.label == targetLabel) {
-          // Match -- recurse
-          output[upto] = fst.outputs.add(output[upto-1], arc.output);
-          if (targetLabel == FST.END_LABEL) {
-            return;
-          }
-          setCurrentLabel(arc.label);
-          incr();
-          arc = fst.readFirstTargetArc(arc, getArc(upto));
-          targetLabel = getTargetLabel();
-        } else if (arc.label > targetLabel) {
-          // TODO: if each arc could somehow read the arc just
-          // before, we can save this re-scan.  The ceil case
-          // doesn't need this because it reads the next arc
-          // instead:
-          while(true) {
-            // First, walk backwards until we find a first arc
-            // that's before our target label:
-            fst.readFirstTargetArc(getArc(upto-1), arc);
-            if (arc.label < targetLabel) {
-              // Then, scan forwards to the arc just before
-              // the targetLabel:
-              while(!arc.isLast() && fst.readNextArcLabel(arc) < targetLabel) {
-                fst.readNextArc(arc);
-              }
-              pushLast();
-              return;
-            }
-            upto--;
-            if (upto == 0) {
-              return;
-            }
-            targetLabel = getTargetLabel();
-            arc = getArc(upto);
-          }
-        } else if (!arc.isLast()) {
-          //System.out.println("  check next label=" + fst.readNextArcLabel(arc) + " (" + (char) fst.readNextArcLabel(arc) + ")");
-          if (fst.readNextArcLabel(arc) > targetLabel) {
-            pushLast();
-            return;
-          } else {
-            // keep scanning
-            fst.readNextArc(arc);
-          }
-        } else {
-          pushLast();
-          return;
-        }
-      }
-    }
-  }
-
-  private void incr() {
-    upto++;
-    grow();
-    if (arcs.length <= upto) {
-      @SuppressWarnings("unchecked") final FST.Arc<T>[] newArcs =
-        new FST.Arc[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
-      System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
-      arcs = newArcs;
-    }
-    if (output.length <= upto) {
-      @SuppressWarnings("unchecked") final T[] newOutput =
-        (T[]) new Object[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
-      System.arraycopy(output, 0, newOutput, 0, output.length);
-      output = newOutput;
-    }
-  }
-
-  // Appends current arc, and then recurses from its target,
-  // appending first arc all the way to the final node
-  private void pushFirst() throws IOException {
-
-    FST.Arc<T> arc = arcs[upto];
-    assert arc != null;
-
-    while (true) {
-      output[upto] = fst.outputs.add(output[upto-1], arc.output);
-      if (arc.label == FST.END_LABEL) {
-        // Final node
-        break;
-      }
-      //System.out.println("  pushFirst label=" + (char) arc.label + " upto=" + upto + " output=" + fst.outputs.outputToString(output[upto]));
-      setCurrentLabel(arc.label);
-      incr();
-      
-      final FST.Arc<T> nextArc = getArc(upto);
-      fst.readFirstTargetArc(arc, nextArc);
-      arc = nextArc;
-    }
-  }
-
-  // Recurses from current arc, appending last arc all the
-  // way to the first final node
-  private void pushLast() throws IOException {
-
-    FST.Arc<T> arc = arcs[upto];
-    assert arc != null;
-
-    while (true) {
-      setCurrentLabel(arc.label);
-      output[upto] = fst.outputs.add(output[upto-1], arc.output);
-      if (arc.label == FST.END_LABEL) {
-        // Final node
-        break;
-      }
-      incr();
-
-      arc = fst.readLastTargetArc(arc, getArc(upto));
-    }
-  }
-
-  private FST.Arc<T> getArc(int idx) {
-    if (arcs[idx] == null) {
-      arcs[idx] = new FST.Arc<T>();
-    }
-    return arcs[idx];
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/IntSequenceOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/IntSequenceOutputs.java
deleted file mode 100644
index 807bd83..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/IntSequenceOutputs.java
+++ /dev/null
@@ -1,141 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.util.IntsRef;
-
-/**
- * Output is a sequence of ints, for each input term.
- * @lucene.experimental
- */
-
-public final class IntSequenceOutputs extends Outputs<IntsRef> {
-
-  private final static IntsRef NO_OUTPUT = new IntsRef();
-
-  private IntSequenceOutputs() {
-  }
-
-  public static IntSequenceOutputs getSingleton() {
-    return new IntSequenceOutputs();
-  }
-
-  @Override
-  public IntsRef common(IntsRef output1, IntsRef output2) {
-    assert output1 != null;
-    assert output2 != null;
-
-    int pos1 = output1.offset;
-    int pos2 = output2.offset;
-    int stopAt1 = pos1 + Math.min(output1.length, output2.length);
-    while(pos1 < stopAt1) {
-      if (output1.ints[pos1] != output2.ints[pos2]) {
-        break;
-      }
-      pos1++;
-      pos2++;
-    }
-
-    if (pos1 == output1.offset) {
-      // no common prefix
-      return NO_OUTPUT;
-    } else if (pos1 == output1.offset + output1.length) {
-      // output1 is a prefix of output2
-      return output1;
-    } else if (pos2 == output2.offset + output2.length) {
-      // output2 is a prefix of output1
-      return output2;
-    } else {
-      return new IntsRef(output1.ints, output1.offset, pos1-output1.offset);
-    }
-  }
-
-  @Override
-  public IntsRef subtract(IntsRef output, IntsRef inc) {
-    assert output != null;
-    assert inc != null;
-    if (inc == NO_OUTPUT) {
-      // no prefix removed
-      return output;
-    } else if (inc.length == output.length) {
-      // entire output removed
-      return NO_OUTPUT;
-    } else {
-      assert inc.length < output.length: "inc.length=" + inc.length + " vs output.length=" + output.length;
-      assert inc.length > 0;
-      return new IntsRef(output.ints, output.offset + inc.length, output.length-inc.length);
-    }
-  }
-
-  @Override
-  public IntsRef add(IntsRef prefix, IntsRef output) {
-    assert prefix != null;
-    assert output != null;
-    if (prefix == NO_OUTPUT) {
-      return output;
-    } else if (output == NO_OUTPUT) {
-      return prefix;
-    } else {
-      assert prefix.length > 0;
-      assert output.length > 0;
-      IntsRef result = new IntsRef(prefix.length + output.length);
-      System.arraycopy(prefix.ints, prefix.offset, result.ints, 0, prefix.length);
-      System.arraycopy(output.ints, output.offset, result.ints, prefix.length, output.length);
-      result.length = prefix.length + output.length;
-      return result;
-    }
-  }
-
-  @Override
-  public void write(IntsRef prefix, DataOutput out) throws IOException {
-    assert prefix != null;
-    out.writeVInt(prefix.length);
-    for(int idx=0;idx<prefix.length;idx++) {
-      out.writeVInt(prefix.ints[prefix.offset+idx]);
-    }
-  }
-
-  @Override
-  public IntsRef read(DataInput in) throws IOException {
-    final int len = in.readVInt();
-    if (len == 0) {
-      return NO_OUTPUT;
-    } else {
-      final IntsRef output = new IntsRef(len);
-      for(int idx=0;idx<len;idx++) {
-        output.ints[idx] = in.readVInt();
-      }
-      output.length = len;
-      return output;
-    }
-  }
-
-  @Override
-  public IntsRef getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(IntsRef output) {
-    return output.toString();
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/IntsRefFSTEnum.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/IntsRefFSTEnum.java
deleted file mode 100644
index cb99f83..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/IntsRefFSTEnum.java
+++ /dev/null
@@ -1,107 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.IntsRef;
-
-import java.io.IOException;
-
-/** Can next() and advance() through the terms in an FST
-  * @lucene.experimental
-*/
-
-public final class IntsRefFSTEnum<T> extends FSTEnum<T> {
-  private final IntsRef current = new IntsRef(10);
-  private final InputOutput<T> result = new InputOutput<T>();
-  private IntsRef target;
-
-  public static class InputOutput<T> {
-    public IntsRef input;
-    public T output;
-  }
-
-  /** doFloor controls the behavior of advance: if it's true
-   *  doFloor is true, advance positions to the biggest
-   *  term before target.  */
-  public IntsRefFSTEnum(FST<T> fst) {
-    super(fst);
-    result.input = current;
-    current.offset = 1;
-  }
-
-  public InputOutput<T> current() {
-    return result;
-  }
-
-  public InputOutput<T> next() throws IOException {
-    //System.out.println("  enum.next");
-    doNext();
-    return setResult();
-  }
-
-  /** Seeks to smallest term that's >= target. */
-  public InputOutput<T> seekCeil(IntsRef target) throws IOException {
-    this.target = target;
-    targetLength = target.length;
-    super.doSeekCeil();
-    return setResult();
-  }
-
-  /** Seeks to biggest term that's <= target. */
-  public InputOutput<T> seekFloor(IntsRef target) throws IOException {
-    this.target = target;
-    targetLength = target.length;
-    super.doSeekFloor();
-    return setResult();
-  }
-
-  @Override
-  protected int getTargetLabel() {
-    if (upto-1 == target.length) {
-      return FST.END_LABEL;
-    } else {
-      return target.ints[target.offset + upto - 1];
-    }
-  }
-
-  @Override
-  protected int getCurrentLabel() {
-    // current.offset fixed at 1
-    return current.ints[upto];
-  }
-
-  @Override
-  protected void setCurrentLabel(int label) {
-    current.ints[upto] = label;
-  }
-
-  @Override
-  protected void grow() {
-    current.grow(upto+1);
-  }
-
-  private InputOutput<T> setResult() {
-    if (upto == 0) {
-      return null;
-    } else {
-      current.length = upto-1;
-      result.output = output[upto];
-      return result;
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/NoOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/NoOutputs.java
deleted file mode 100644
index edb9167..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/NoOutputs.java
+++ /dev/null
@@ -1,94 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-
-/**
- * Use this if you just want to build an FSA.
- */
-
-public final class NoOutputs extends Outputs<Object> {
-
-  final Object NO_OUTPUT = new Object() {
-    // NodeHash calls hashCode for this output; we fix this
-    // so we get deterministic hashing.
-    @Override
-    public int hashCode() {
-      return 42;
-    }
-
-    @Override
-    public boolean equals(Object other) {
-      return other == this;
-    }
-  };
-
-  private static final NoOutputs singleton = new NoOutputs();
-
-  private NoOutputs() {
-  }
-
-  public static NoOutputs getSingleton() {
-    return singleton;
-  }
-
-  @Override
-  public Object common(Object output1, Object output2) {
-    assert output1 == NO_OUTPUT;
-    assert output2 == NO_OUTPUT;
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public Object subtract(Object output, Object inc) {
-    assert output == NO_OUTPUT;
-    assert inc == NO_OUTPUT;
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public Object add(Object prefix, Object output) {
-    assert prefix == NO_OUTPUT: "got " + prefix;
-    assert output == NO_OUTPUT;
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public void write(Object prefix, DataOutput out) {
-    //assert false;
-  }
-
-  @Override
-  public Object read(DataInput in) {
-    //assert false;
-    //return null;
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public Object getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(Object output) {
-    return "";
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/NodeHash.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/NodeHash.java
deleted file mode 100644
index dde6409..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/NodeHash.java
+++ /dev/null
@@ -1,165 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-// Used to dedup states (lookup already-frozen states)
-final class NodeHash<T> {
-
-  private int[] table;
-  private int count;
-  private int mask;
-  private final FST<T> fst;
-  private final FST.Arc<T> scratchArc = new FST.Arc<T>();
-
-  public NodeHash(FST<T> fst) {
-    table = new int[16];
-    mask = 15;
-    this.fst = fst;
-  }
-
-  private boolean nodesEqual(Builder.UnCompiledNode<T> node, int address) throws IOException {
-    fst.readFirstRealArc(address, scratchArc);
-    if (scratchArc.bytesPerArc != 0 && node.numArcs != scratchArc.numArcs) {
-      return false;
-    }
-    for(int arcUpto=0;arcUpto<node.numArcs;arcUpto++) {
-      final Builder.Arc<T> arc = node.arcs[arcUpto];
-      if (arc.label != scratchArc.label ||
-          !arc.output.equals(scratchArc.output) ||
-          ((Builder.CompiledNode) arc.target).address != scratchArc.target ||
-          !arc.nextFinalOutput.equals(scratchArc.nextFinalOutput) ||
-          arc.isFinal != scratchArc.isFinal()) {
-        return false;
-      }
-
-      if (scratchArc.isLast()) {
-        if (arcUpto == node.numArcs-1) {
-          return true;
-        } else {
-          return false;
-        }
-      }
-      fst.readNextRealArc(scratchArc);
-    }
-
-    return false;
-  }
-
-  // hash code for an unfrozen node.  This must be identical
-  // to the un-frozen case (below)!!
-  private int hash(Builder.UnCompiledNode<T> node) {
-    final int PRIME = 31;
-    //System.out.println("hash unfrozen");
-    int h = 0;
-    // TODO: maybe if number of arcs is high we can safely subsample?
-    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
-      final Builder.Arc<T> arc = node.arcs[arcIdx];
-      //System.out.println("  label=" + arc.label + " target=" + ((Builder.CompiledNode) arc.target).address + " h=" + h + " output=" + fst.outputs.outputToString(arc.output) + " isFinal?=" + arc.isFinal);
-      h = PRIME * h + arc.label;
-      h = PRIME * h + ((Builder.CompiledNode) arc.target).address;
-      h = PRIME * h + arc.output.hashCode();
-      h = PRIME * h + arc.nextFinalOutput.hashCode();
-      if (arc.isFinal) {
-        h += 17;
-      }
-    }
-    //System.out.println("  ret " + (h&Integer.MAX_VALUE));
-    return h & Integer.MAX_VALUE;
-  }
-
-  // hash code for a frozen node
-  private int hash(int node) throws IOException {
-    final int PRIME = 31;
-    //System.out.println("hash frozen");
-    int h = 0;
-    fst.readFirstRealArc(node, scratchArc);
-    while(true) {
-      //System.out.println("  label=" + scratchArc.label + " target=" + scratchArc.target + " h=" + h + " output=" + fst.outputs.outputToString(scratchArc.output) + " next?=" + scratchArc.flag(4) + " final?=" + scratchArc.isFinal());
-      h = PRIME * h + scratchArc.label;
-      h = PRIME * h + scratchArc.target;
-      h = PRIME * h + scratchArc.output.hashCode();
-      h = PRIME * h + scratchArc.nextFinalOutput.hashCode();
-      if (scratchArc.isFinal()) {
-        h += 17;
-      }
-      if (scratchArc.isLast()) {
-        break;
-      }
-      fst.readNextRealArc(scratchArc);
-    }
-    //System.out.println("  ret " + (h&Integer.MAX_VALUE));
-    return h & Integer.MAX_VALUE;
-  }
-
-  public int add(Builder.UnCompiledNode<T> node) throws IOException {
-    // System.out.println("hash: add count=" + count + " vs " + table.length);
-    final int h = hash(node);
-    int pos = h & mask;
-    int c = 0;
-    while(true) {
-      final int v = table[pos];
-      if (v == 0) {
-        // freeze & add
-        final int address = fst.addNode(node);
-        //System.out.println("  now freeze addr=" + address);
-        assert hash(address) == h : "frozenHash=" + hash(address) + " vs h=" + h;
-        count++;
-        table[pos] = address;
-        if (table.length < 2*count) {
-          rehash();
-        }
-        return address;
-      } else if (nodesEqual(node, v)) {
-        // same node is already here
-        return v;
-      }
-
-      // quadratic probe
-      pos = (pos + (++c)) & mask;
-    }
-  }
-
-  // called only by rehash
-  private void addNew(int address) throws IOException {
-    int pos = hash(address) & mask;
-    int c = 0;
-    while(true) {
-      if (table[pos] == 0) {
-        table[pos] = address;
-        break;
-      }
-
-      // quadratic probe
-      pos = (pos + (++c)) & mask;
-    }
-  }
-
-  private void rehash() throws IOException {
-    final int[] oldTable = table;
-    table = new int[2*table.length];
-    mask = table.length-1;
-    for(int idx=0;idx<oldTable.length;idx++) {
-      final int address = oldTable[idx];
-      if (address != 0) {
-        addNew(address);
-      }
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/Outputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/Outputs.java
deleted file mode 100644
index 66efc3f..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/Outputs.java
+++ /dev/null
@@ -1,61 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-
-/**
- * Represents the outputs for an FST, providing the basic
- * algebra needed for the FST.
- * @lucene.experimental
- */
-
-public abstract class Outputs<T> {
-
-  // TODO: maybe change this API to allow for re-use of the
-  // output instances -- this is an insane amount of garbage
-  // (new object per byte/char/int) if eg used during
-  // analysis
-
-  /** Eg common("foo", "foobar") -> "foo" */
-  public abstract T common(T output1, T output2);
-
-  /** Eg subtract("foobar", "foo") -> "bar" */
-  public abstract T subtract(T output, T inc);
-
-  /** Eg add("foo", "bar") -> "foobar" */
-  public abstract T add(T prefix, T output);
-
-  public abstract void write(T output, DataOutput out) throws IOException;
-
-  public abstract T read(DataInput in) throws IOException;
-
-  /** NOTE: this output is compared with == so you must
-   *  ensure that all methods return the single object if
-   *  it's really no output */
-  public abstract T getNoOutput();
-
-  public abstract String outputToString(T output);
-
-  public T merge(T first, T second) {
-    throw new UnsupportedOperationException();
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/PairOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/PairOutputs.java
deleted file mode 100644
index 7b6ead9..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/PairOutputs.java
+++ /dev/null
@@ -1,118 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-
-/**
- * Pairs up two outputs into one.
- * @lucene.experimental
- */
-
-
-public class PairOutputs<A,B> extends Outputs<PairOutputs.Pair<A,B>> {
-
-  private final Pair<A,B> NO_OUTPUT;
-  private final Outputs<A> outputs1;
-  private final Outputs<B> outputs2;
-
-  public static class Pair<A,B> {
-    public final A output1;
-    public final B output2;
-
-    public Pair(A output1, B output2) {
-      this.output1 = output1;
-      this.output2 = output2;
-    }
-
-    @Override @SuppressWarnings("rawtypes")
-    public boolean equals(Object other) {
-      if (other == this) {
-        return true;
-      } else if (other instanceof Pair) {
-        Pair pair = (Pair) other;
-        return output1.equals(pair.output1) && output2.equals(pair.output2);
-      } else {
-        return false;
-      }
-    }
-
-    @Override
-    public int hashCode() {
-      return output1.hashCode() + output2.hashCode();
-    }
-  };
-
-  public PairOutputs(Outputs<A> outputs1, Outputs<B> outputs2) {
-    this.outputs1 = outputs1;
-    this.outputs2 = outputs2;
-    NO_OUTPUT = new Pair<A,B>(outputs1.getNoOutput(), outputs2.getNoOutput());
-  }
-  
-  public Pair<A,B> get(A output1, B output2) {
-    if (output1 == outputs1.getNoOutput() && output2 == outputs2.getNoOutput()) {
-      return NO_OUTPUT;
-    } else {
-      return new Pair<A,B>(output1, output2);
-    }
-  }
- 
-  @Override
-  public Pair<A,B> common(Pair<A,B> pair1, Pair<A,B> pair2) {
-    return get(outputs1.common(pair1.output1, pair2.output1),
-               outputs2.common(pair1.output2, pair2.output2));
-  }
-
-  @Override
-  public Pair<A,B> subtract(Pair<A,B> output, Pair<A,B> inc) {
-    return get(outputs1.subtract(output.output1, inc.output1),
-               outputs2.subtract(output.output2, inc.output2));
-  }
-
-  @Override
-  public Pair<A,B> add(Pair<A,B> prefix, Pair<A,B> output) {
-    return get(outputs1.add(prefix.output1, output.output1),
-               outputs2.add(prefix.output2, output.output2));
-  }
-
-  @Override
-  public void write(Pair<A,B> output, DataOutput writer) throws IOException {
-    outputs1.write(output.output1, writer);
-    outputs2.write(output.output2, writer);
-  }
-
-  @Override
-  public Pair<A,B> read(DataInput in) throws IOException {
-    A output1 = outputs1.read(in);
-    B output2 = outputs2.read(in);
-    return get(output1, output2);
-  }
-
-  @Override
-  public Pair<A,B> getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(Pair<A,B> output) {
-    return "<pair:" + outputs1.outputToString(output.output1) + "," + outputs2.outputToString(output.output2) + ">";
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/PositiveIntOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/PositiveIntOutputs.java
deleted file mode 100644
index 984324e..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/PositiveIntOutputs.java
+++ /dev/null
@@ -1,135 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-
-/**
- * Output is a long, for each input term.  NOTE: the
- * resulting FST is not guaranteed to be minimal!  See
- * {@link Builder}.  You cannot store 0 output with this
- * (that's reserved to mean "no output")!
- * @lucene.experimental
- */
-
-public final class PositiveIntOutputs extends Outputs<Long> {
-  
-  private final static Long NO_OUTPUT = new Long(0);
-
-  private final boolean doShare;
-
-  private final static PositiveIntOutputs singletonShare = new PositiveIntOutputs(true);
-  private final static PositiveIntOutputs singletonNoShare = new PositiveIntOutputs(false);
-
-  private PositiveIntOutputs(boolean doShare) {
-    this.doShare = doShare;
-  }
-
-  public static PositiveIntOutputs getSingleton(boolean doShare) {
-    return doShare ? singletonShare : singletonNoShare;
-  }
-
-  public Long get(long v) {
-    if (v == 0) {
-      return NO_OUTPUT;
-    } else {
-      return Long.valueOf(v);
-    }
-  }
-
-  @Override
-  public Long common(Long output1, Long output2) {
-    assert valid(output1);
-    assert valid(output2);
-    if (output1 == NO_OUTPUT || output2 == NO_OUTPUT) {
-      return NO_OUTPUT;
-    } else if (doShare) {
-      assert output1 > 0;
-      assert output2 > 0;
-      return Math.min(output1, output2);
-    } else if (output1.equals(output2)) {
-      return output1;
-    } else {
-      return NO_OUTPUT;
-    }
-  }
-
-  @Override
-  public Long subtract(Long output, Long inc) {
-    assert valid(output);
-    assert valid(inc);
-    assert output >= inc;
-
-    if (inc == NO_OUTPUT) {
-      return output;
-    } else if (output.equals(inc)) {
-      return NO_OUTPUT;
-    } else {
-      return output - inc;
-    }
-  }
-
-  @Override
-  public Long add(Long prefix, Long output) {
-    assert valid(prefix);
-    assert valid(output);
-    if (prefix == NO_OUTPUT) {
-      return output;
-    } else if (output == NO_OUTPUT) {
-      return prefix;
-    } else {
-      return prefix + output;
-    }
-  }
-
-  @Override
-  public void write(Long output, DataOutput out) throws IOException {
-    assert valid(output);
-    out.writeVLong(output);
-  }
-
-  @Override
-  public Long read(DataInput in) throws IOException {
-    long v = in.readVLong();
-    if (v == 0) {
-      return NO_OUTPUT;
-    } else {
-      return v;
-    }
-  }
-
-  private boolean valid(Long o) {
-    assert o != null;
-    assert o instanceof Long;
-    assert o == NO_OUTPUT || o > 0;
-    return true;
-  }
-
-  @Override
-  public Long getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(Long output) {
-    return output.toString();
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/TODO b/lucene/src/java/org/apache/lucene/util/automaton/fst/TODO
deleted file mode 100644
index 98fc679..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/TODO
+++ /dev/null
@@ -1,39 +0,0 @@
-is threadlocal.get costly?  if so maybe make an FSTReader?  would hold this "relative" pos, and each thread'd use it for reading, instead of PosRef
-
-maybe changed Outputs class to "reuse" stuff?  eg this new BytesRef in ByteSequenceOutputs..
-
-do i even "need" both non_final_end_state and final_end_state?
-
-hmm -- can I get weights working here?
-
-can FST be used to index all internal substrings, mapping to term?
-  - maybe put back ability to add multiple outputs per input...?
-
-make this work w/ char...?
-  - then FSTCharFilter/FSTTokenFilter
-  - syn filter?
-
-experiment: try reversing terms before compressing -- how much smaller?
-
-maybe seprate out a 'writable/growing fst' from a read-only one?
-
-can we somehow [partially] tableize lookups like oal.util.automaton?
-
-make an FST terms index option for codecs...?
-
-make an FSTCharsMap?
-
-need a benchmark testing FST traversal -- just fix the static main to rewind & visit all terms
-
-thread state
-
-when writing FST to disk:
-- Sequentially writing (would save memory in codec during indexing). We are now using DataOutput, which could also go directly to disk
-- problem: size of BytesRef must be known before
-
-later
-  - maybe don't require FSTEnum.advance to be forward only?
-  - should i make a posIntOutputs separate from posLongOutputs?
-  - mv randomAccpetedWord / run / etc. from test into FST?
-  - hmm get multi-outputs working again?  do we ever need this?
-
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/UpToTwoPositiveIntOutputs.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/UpToTwoPositiveIntOutputs.java
deleted file mode 100644
index 0c388d2..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/UpToTwoPositiveIntOutputs.java
+++ /dev/null
@@ -1,224 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.DataOutput;
-
-/**
- * Holds one or two longs for each input term.  If it's a
- * single output, Long is returned; else, TwoLongs.  Order
- * is preseved in the TwoLongs case, ie .first is the first
- * input/output added to Builder, and .second is the
- * second.  You cannot store 0 output with this (that's
- * reserved to mean "no output")!
- *
- * NOTE: the resulting FST is not guaranteed to be minimal!
- * See {@link Builder}.
- *
- * @lucene.experimental
- */
-
-public final class UpToTwoPositiveIntOutputs extends Outputs<Object> {
-
-  public final static class TwoLongs {
-    final long first;
-    final long second;
-
-    public TwoLongs(long first, long second) {
-      this.first = first;
-      this.second = second;
-      assert first >= 0;
-      assert second >= 0;
-    }
-
-    @Override
-    public String toString() {
-      return "TwoLongs:" + first + "," + second;
-    }
-
-    @Override
-    public boolean equals(Object _other) {
-      if (_other instanceof TwoLongs) {
-        final TwoLongs other = (TwoLongs) _other;
-        return first == other.first && second == other.second;
-      } else {
-        return false;
-      }
-    }
-
-    @Override
-    public int hashCode() {
-      return (int) ((first^(first>>>32)) ^ (second^(second>>32)));
-    }
-  }
-  
-  private final static Long NO_OUTPUT = new Long(0);
-
-  private final boolean doShare;
-
-  private final static UpToTwoPositiveIntOutputs singletonShare = new UpToTwoPositiveIntOutputs(true);
-  private final static UpToTwoPositiveIntOutputs singletonNoShare = new UpToTwoPositiveIntOutputs(false);
-
-  private UpToTwoPositiveIntOutputs(boolean doShare) {
-    this.doShare = doShare;
-  }
-
-  public static UpToTwoPositiveIntOutputs getSingleton(boolean doShare) {
-    return doShare ? singletonShare : singletonNoShare;
-  }
-
-  public Long get(long v) {
-    if (v == 0) {
-      return NO_OUTPUT;
-    } else {
-      return Long.valueOf(v);
-    }
-  }
-
-  public TwoLongs get(long first, long second) {
-    return new TwoLongs(first, second);
-  }
-
-  @Override
-  public Long common(Object _output1, Object _output2) {
-    assert valid(_output1, false);
-    assert valid(_output2, false);
-    final Long output1 = (Long) _output1;
-    final Long output2 = (Long) _output2;
-    if (output1 == NO_OUTPUT || output2 == NO_OUTPUT) {
-      return NO_OUTPUT;
-    } else if (doShare) {
-      assert output1 > 0;
-      assert output2 > 0;
-      return Math.min(output1, output2);
-    } else if (output1.equals(output2)) {
-      return output1;
-    } else {
-      return NO_OUTPUT;
-    }
-  }
-
-  @Override
-  public Long subtract(Object _output, Object _inc) {
-    assert valid(_output, false);
-    assert valid(_inc, false);
-    final Long output = (Long) _output;
-    final Long inc = (Long) _inc;
-    assert output >= inc;
-
-    if (inc == NO_OUTPUT) {
-      return output;
-    } else if (output.equals(inc)) {
-      return NO_OUTPUT;
-    } else {
-      return output - inc;
-    }
-  }
-
-  @Override
-  public Object add(Object _prefix, Object _output) {
-    assert valid(_prefix, false);
-    assert valid(_output, true);
-    final Long prefix = (Long) _prefix;
-    if (_output instanceof Long) {
-      final Long output = (Long) _output;
-      if (prefix == NO_OUTPUT) {
-        return output;
-      } else if (output == NO_OUTPUT) {
-        return prefix;
-      } else {
-        return prefix + output;
-      }
-    } else {
-      final TwoLongs output = (TwoLongs) _output;
-      final long v = prefix;
-      return new TwoLongs(output.first + v, output.second + v);
-    }
-  }
-
-  @Override
-  public void write(Object _output, DataOutput out) throws IOException {
-    assert valid(_output, true);
-    if (_output instanceof Long) {
-      final Long output = (Long) _output;
-      out.writeVLong(output<<1);
-    } else {
-      final TwoLongs output = (TwoLongs) _output;
-      out.writeVLong((output.first<<1) | 1);
-      out.writeVLong(output.second);
-    }
-  }
-
-  @Override
-  public Object read(DataInput in) throws IOException {
-    final long code = in.readVLong();
-    if ((code & 1) == 0) {
-      // single long
-      final long v = code >>> 1;
-      if (v == 0) {
-        return NO_OUTPUT;
-      } else {
-        return Long.valueOf(v);
-      }
-    } else {
-      // two longs
-      final long first = code >>> 1;
-      final long second = in.readVLong();
-      return new TwoLongs(first, second);
-    }
-  }
-
-  private boolean valid(Long o) {
-    assert o != null;
-    assert o instanceof Long;
-    assert o == NO_OUTPUT || o > 0;
-    return true;
-  }
-
-  // Used only by assert
-  private boolean valid(Object _o, boolean allowDouble) {
-    if (!allowDouble) {
-      assert _o instanceof Long;
-      return valid((Long) _o);
-    } else if (_o instanceof TwoLongs) {
-      return true;
-    } else {
-      return valid((Long) _o);
-    }
-  }
-
-  @Override
-  public Object getNoOutput() {
-    return NO_OUTPUT;
-  }
-
-  @Override
-  public String outputToString(Object output) {
-    return output.toString();
-  }
-
-  @Override
-  public Object merge(Object first, Object second) {
-    assert valid(first, false);
-    assert valid(second, false);
-    return new TwoLongs((Long) first, (Long) second);
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/Util.java b/lucene/src/java/org/apache/lucene/util/automaton/fst/Util.java
deleted file mode 100644
index 6699ac6..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/Util.java
+++ /dev/null
@@ -1,326 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.*;
-import java.util.*;
-
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-
-/** Static helper methods */
-public final class Util {
-  private Util() {
-  }
-
-  /** Looks up the output for this input, or null if the
-   *  input is not accepted. FST must be
-   *  INPUT_TYPE.BYTE4. */
-  public static<T> T get(FST<T> fst, IntsRef input) throws IOException {
-    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
-
-    // TODO: would be nice not to alloc this on every lookup
-    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-    // Accumulate output as we go
-    final T NO_OUTPUT = fst.outputs.getNoOutput();
-    T output = NO_OUTPUT;
-    for(int i=0;i<input.length;i++) {
-      if (fst.findTargetArc(input.ints[input.offset + i], arc, arc) == null) {
-        return null;
-      } else if (arc.output != NO_OUTPUT) {
-        output = fst.outputs.add(output, arc.output);
-      }
-    }
-
-    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
-      return null;
-    } else if (arc.output != NO_OUTPUT) {
-      return fst.outputs.add(output, arc.output);
-    } else {
-      return output;
-    }
-  }
-
-  /** Logically casts input to UTF32 ints then looks up the output
-   *  or null if the input is not accepted.  FST must be
-   *  INPUT_TYPE.BYTE4.  */
-  public static<T> T get(FST<T> fst, char[] input, int offset, int length) throws IOException {
-    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
-
-    // TODO: would be nice not to alloc this on every lookup
-    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-    int charIdx = offset;
-    final int charLimit = offset + length;
-
-    // Accumulate output as we go
-    final T NO_OUTPUT = fst.outputs.getNoOutput();
-    T output = NO_OUTPUT;
-    while(charIdx < charLimit) {
-      final int utf32 = Character.codePointAt(input, charIdx);
-      charIdx += Character.charCount(utf32);
-
-      if (fst.findTargetArc(utf32, arc, arc) == null) {
-        return null;
-      } else if (arc.output != NO_OUTPUT) {
-        output = fst.outputs.add(output, arc.output);
-      }
-    }
-
-    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
-      return null;
-    } else if (arc.output != NO_OUTPUT) {
-      return fst.outputs.add(output, arc.output);
-    } else {
-      return output;
-    }
-  }
-
-
-  /** Logically casts input to UTF32 ints then looks up the output
-   *  or null if the input is not accepted.  FST must be
-   *  INPUT_TYPE.BYTE4.  */
-  public static<T> T get(FST<T> fst, CharSequence input) throws IOException {
-    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
-    
-    // TODO: would be nice not to alloc this on every lookup
-    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-    int charIdx = 0;
-    final int charLimit = input.length();
-
-    // Accumulate output as we go
-    final T NO_OUTPUT = fst.outputs.getNoOutput();
-    T output = NO_OUTPUT;
-
-    while(charIdx < charLimit) {
-      final int utf32 = Character.codePointAt(input, charIdx);
-      charIdx += Character.charCount(utf32);
-
-      if (fst.findTargetArc(utf32, arc, arc) == null) {
-        return null;
-      } else if (arc.output != NO_OUTPUT) {
-        output = fst.outputs.add(output, arc.output);
-      }
-    }
-
-    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
-      return null;
-    } else if (arc.output != NO_OUTPUT) {
-      return fst.outputs.add(output, arc.output);
-    } else {
-      return output;
-    }
-  }
-
-  /** Looks up the output for this input, or null if the
-   *  input is not accepted */
-  public static<T> T get(FST<T> fst, BytesRef input) throws IOException {
-    assert fst.inputType == FST.INPUT_TYPE.BYTE1;
-
-    // TODO: would be nice not to alloc this on every lookup
-    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-    // Accumulate output as we go
-    final T NO_OUTPUT = fst.outputs.getNoOutput();
-    T output = NO_OUTPUT;
-    for(int i=0;i<input.length;i++) {
-      if (fst.findTargetArc(input.bytes[i+input.offset] & 0xFF, arc, arc) == null) {
-        return null;
-      } else if (arc.output != NO_OUTPUT) {
-        output = fst.outputs.add(output, arc.output);
-      }
-    }
-
-    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
-      return null;
-    } else if (arc.output != NO_OUTPUT) {
-      return fst.outputs.add(output, arc.output);
-    } else {
-      return output;
-    }
-  }
-  
-  /**
-   * Dumps an {@link FST} to a GraphViz's <code>dot</code> language description
-   * for visualization. Example of use:
-   * 
-   * <pre>
-   * PrintStream ps = new PrintStream(&quot;out.dot&quot;);
-   * fst.toDot(ps);
-   * ps.close();
-   * </pre>
-   * 
-   * and then, from command line:
-   * 
-   * <pre>
-   * dot -Tpng -o out.png out.dot
-   * </pre>
-   * 
-   * <p>
-   * Note: larger FSTs (a few thousand nodes) won't even render, don't bother.
-   * 
-   * @param sameRank
-   *          If <code>true</code>, the resulting <code>dot</code> file will try
-   *          to order states in layers of breadth-first traversal. This may
-   *          mess up arcs, but makes the output FST's structure a bit clearer.
-   * 
-   * @param labelStates
-   *          If <code>true</code> states will have labels equal to their offsets in their
-   *          binary format. Expands the graph considerably. 
-   * 
-   * @see "http://www.graphviz.org/"
-   */
-  public static <T> void toDot(FST<T> fst, Writer out, boolean sameRank, boolean labelStates) 
-    throws IOException {    
-    final String expandedNodeColor = "blue";
-
-    // This is the start arc in the automaton (from the epsilon state to the first state 
-    // with outgoing transitions.
-    final FST.Arc<T> startArc = fst.getFirstArc(new FST.Arc<T>());
-
-    // A queue of transitions to consider for the next level.
-    final List<FST.Arc<T>> thisLevelQueue = new ArrayList<FST.Arc<T>>();
-
-    // A queue of transitions to consider when processing the next level.
-    final List<FST.Arc<T>> nextLevelQueue = new ArrayList<FST.Arc<T>>();
-    nextLevelQueue.add(startArc);
-    
-    // A list of states on the same level (for ranking).
-    final List<Integer> sameLevelStates = new ArrayList<Integer>();
-
-    // A bitset of already seen states (target offset).
-    final BitSet seen = new BitSet();
-    seen.set(startArc.target);
-
-    // Shape for states.
-    final String stateShape = "circle";
-
-    // Emit DOT prologue.
-    out.write("digraph FST {\n");
-    out.write("  rankdir = LR; splines=true; concentrate=true; ordering=out; ranksep=2.5; \n");
-
-    if (!labelStates) {
-      out.write("  node [shape=circle, width=.2, height=.2, style=filled]\n");      
-    }
-
-    emitDotState(out, "initial", "point", "white", "");
-    emitDotState(out, Integer.toString(startArc.target), stateShape, 
-        fst.isExpandedTarget(startArc) ? expandedNodeColor : null, 
-        "");
-    out.write("  initial -> " + startArc.target + "\n");
-
-    final T NO_OUTPUT = fst.outputs.getNoOutput();
-    int level = 0;
-
-    while (!nextLevelQueue.isEmpty()) {
-      // we could double buffer here, but it doesn't matter probably.
-      thisLevelQueue.addAll(nextLevelQueue);
-      nextLevelQueue.clear();
-
-      level++;
-      out.write("\n  // Transitions and states at level: " + level + "\n");
-      while (!thisLevelQueue.isEmpty()) {
-        final FST.Arc<T> arc = thisLevelQueue.remove(thisLevelQueue.size() - 1);
-        
-        if (fst.targetHasArcs(arc)) {
-          // scan all arcs
-          final int node = arc.target;
-          fst.readFirstTargetArc(arc, arc);
-          
-          while (true) {
-            // Emit the unseen state and add it to the queue for the next level.
-            if (arc.target >= 0 && !seen.get(arc.target)) {
-              final boolean isExpanded = fst.isExpandedTarget(arc);
-              emitDotState(out, Integer.toString(arc.target), stateShape, 
-                  isExpanded ?  expandedNodeColor : null, 
-                  labelStates ? Integer.toString(arc.target) : ""); 
-              seen.set(arc.target);
-              nextLevelQueue.add(new FST.Arc<T>().copyFrom(arc));
-              sameLevelStates.add(arc.target);
-            }
-
-            String outs;
-            if (arc.output != NO_OUTPUT) {
-              outs = "/" + fst.outputs.outputToString(arc.output);
-            } else {
-              outs = "";
-            }
-
-            final String cl;
-            if (arc.label == FST.END_LABEL) {
-              cl = "~";
-            } else {
-              cl = printableLabel(arc.label);
-            }
-
-            out.write("  " + node + " -> " + arc.target + " [label=\"" + cl + outs + "\"]\n");
-            
-            // Break the loop if we're on the last arc of this state.
-            if (arc.isLast()) {
-              break;
-            }
-            fst.readNextArc(arc);
-          }
-        }
-      }
-
-      // Emit state ranking information.
-      if (sameRank && sameLevelStates.size() > 1) {
-        out.write("  {rank=same; ");
-        for (int state : sameLevelStates) {
-          out.write(state + "; ");
-        }
-        out.write(" }\n");
-      }
-      sameLevelStates.clear();                
-    }
-
-    // Emit terminating state (always there anyway).
-    out.write("  -1 [style=filled, color=black, shape=circle, label=\"\"]\n\n");
-    out.write("  {rank=sink; -1 }\n");
-    
-    out.write("}\n");
-    out.flush();
-  }
-
-  /**
-   * Emit a single state in the <code>dot</code> language. 
-   */
-  private static void emitDotState(Writer out, String name, String shape,
-      String color, String label) throws IOException {
-    out.write("  " + name 
-        + " [" 
-        + (shape != null ? "shape=" + shape : "") + " "
-        + (color != null ? "color=" + color : "") + " "
-        + (label != null ? "label=\"" + label + "\"" : "label=\"\"") + " "
-        + "]\n");
-  }
-
-  /**
-   * Ensures an arc's label is indeed printable (dot uses US-ASCII). 
-   */
-  private static String printableLabel(int label) {
-    if (label >= 0x20 && label <= 0x7d) {
-      return Character.toString((char) label);
-    } else {
-      return "0x" + Integer.toHexString(label);
-    }
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/util/automaton/fst/package.html b/lucene/src/java/org/apache/lucene/util/automaton/fst/package.html
deleted file mode 100644
index c5be56e..0000000
--- a/lucene/src/java/org/apache/lucene/util/automaton/fst/package.html
+++ /dev/null
@@ -1,25 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html>
-<head>
-   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
-</head>
-<body>
-Finite state transducers
-</body>
-</html>
diff --git a/lucene/src/java/org/apache/lucene/util/fst/Builder.java b/lucene/src/java/org/apache/lucene/util/fst/Builder.java
new file mode 100644
index 0000000..b573626
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/Builder.java
@@ -0,0 +1,545 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.RamUsageEstimator;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IntsRef;
+
+import java.io.IOException;
+
+/**
+ * Builds a compact FST (maps an IntsRef term to an arbitrary
+ * output) from pre-sorted terms with outputs (the FST
+ * becomes an FSA if you use NoOutputs).  The FST is written
+ * on-the-fly into a compact serialized format byte array, which can
+ * be saved to / loaded from a Directory or used directly
+ * for traversal.  The FST is always finite (no cycles).
+ *
+ * <p>NOTE: The algorithm is described at
+ * http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.24.3698</p>
+ *
+ * If your outputs are ByteSequenceOutput then the final FST
+ * will be minimal, but if you use PositiveIntOutput then
+ * it's only "near minimal".  For example, aa/0, aab/1, bbb/2
+ * will produce 6 states when a 5 state fst is also
+ * possible.
+ *
+ * The parameterized type T is the output type.  See the
+ * subclasses of {@link Outputs}.
+ *
+ * @lucene.experimental
+ */
+
+public class Builder<T> {
+  private final NodeHash<T> dedupHash;
+  private final FST<T> fst;
+  private final T NO_OUTPUT;
+
+  // simplistic pruning: we prune node (and all following
+  // nodes) if less than this number of terms go through it:
+  private final int minSuffixCount1;
+
+  // better pruning: we prune node (and all following
+  // nodes) if the prior node has less than this number of
+  // terms go through it:
+  private final int minSuffixCount2;
+
+  private final IntsRef lastInput = new IntsRef();
+
+  // NOTE: cutting this over to ArrayList instead loses ~6%
+  // in build performance on 9.8M Wikipedia terms; so we
+  // left this as an array:
+  // current "frontier"
+  private UnCompiledNode<T>[] frontier;
+
+  public Builder(FST.INPUT_TYPE inputType, int minSuffixCount1, int minSuffixCount2, boolean doMinSuffix, Outputs<T> outputs) {
+    this.minSuffixCount1 = minSuffixCount1;
+    this.minSuffixCount2 = minSuffixCount2;
+    fst = new FST<T>(inputType, outputs);
+    if (doMinSuffix) {
+      dedupHash = new NodeHash<T>(fst);
+    } else {
+      dedupHash = null;
+    }
+    NO_OUTPUT = outputs.getNoOutput();
+
+    @SuppressWarnings("unchecked") final UnCompiledNode<T>[] f = (UnCompiledNode<T>[]) new UnCompiledNode[10];
+    frontier = f;
+    for(int idx=0;idx<frontier.length;idx++) {
+      frontier[idx] = new UnCompiledNode<T>(this, idx);
+    }
+  }
+
+  public int getTotStateCount() {
+    return fst.nodeCount;
+  }
+
+  public long getTermCount() {
+    return frontier[0].inputCount;
+  }
+
+  public int getMappedStateCount() {
+    return dedupHash == null ? 0 : fst.nodeCount;
+  }
+
+  private CompiledNode compileNode(UnCompiledNode<T> n) throws IOException {
+
+    final int address;
+    if (dedupHash != null) {
+      if (n.numArcs == 0) {
+        address = fst.addNode(n);
+      } else {
+        address = dedupHash.add(n);
+      }
+    } else {
+      address = fst.addNode(n);
+    }
+    assert address != -2;
+
+    n.clear();
+
+    final CompiledNode fn = new CompiledNode();
+    fn.address = address;
+    return fn;
+  }
+
+  private void compilePrevTail(int prefixLenPlus1) throws IOException {
+    assert prefixLenPlus1 >= 1;
+    //System.out.println("  compileTail " + prefixLenPlus1);
+    for(int idx=lastInput.length; idx >= prefixLenPlus1; idx--) {
+      boolean doPrune = false;
+      boolean doCompile = false;
+
+      final UnCompiledNode<T> node = frontier[idx];
+      final UnCompiledNode<T> parent = frontier[idx-1];
+
+      if (node.inputCount < minSuffixCount1) {
+        doPrune = true;
+        doCompile = true;
+      } else if (idx > prefixLenPlus1) {
+        // prune if parent's inputCount is less than suffixMinCount2
+        if (parent.inputCount < minSuffixCount2 || minSuffixCount2 == 1 && parent.inputCount == 1) {
+          // my parent, about to be compiled, doesn't make the cut, so
+          // I'm definitely pruned 
+
+          // if pruneCount2 is 1, we keep only up
+          // until the 'distinguished edge', ie we keep only the
+          // 'divergent' part of the FST. if my parent, about to be
+          // compiled, has inputCount 1 then we are already past the
+          // distinguished edge.  NOTE: this only works if
+          // the FST outputs are not "compressible" (simple
+          // ords ARE compressible).
+          doPrune = true;
+        } else {
+          // my parent, about to be compiled, does make the cut, so
+          // I'm definitely not pruned 
+          doPrune = false;
+        }
+        doCompile = true;
+      } else {
+        // if pruning is disabled (count is 0) we can always
+        // compile current node
+        doCompile = minSuffixCount2 == 0;
+      }
+
+      //System.out.println("    label=" + ((char) lastInput.ints[lastInput.offset+idx-1]) + " idx=" + idx + " inputCount=" + frontier[idx].inputCount + " doCompile=" + doCompile + " doPrune=" + doPrune);
+
+      if (node.inputCount < minSuffixCount2 || minSuffixCount2 == 1 && node.inputCount == 1) {
+        // drop all arcs
+        for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
+          @SuppressWarnings("unchecked") final UnCompiledNode<T> target = (UnCompiledNode<T>) node.arcs[arcIdx].target;
+          target.clear();
+        }
+        node.numArcs = 0;
+      }
+
+      if (doPrune) {
+        // this node doesn't make it -- deref it
+        node.clear();
+        parent.deleteLast(lastInput.ints[lastInput.offset+idx-1], node);
+      } else {
+
+        if (minSuffixCount2 != 0) {
+          compileAllTargets(node);
+        }
+        final T nextFinalOutput = node.output;
+
+        // We "fake" the node as being final if it has no
+        // outgoing arcs; in theory we could leave it
+        // as non-final (the FST can represent this), but
+        // FSTEnum, Util, etc., have trouble w/ non-final
+        // dead-end states:
+        final boolean isFinal = node.isFinal || node.numArcs == 0;
+
+        if (doCompile) {
+          // this node makes it and we now compile it.  first,
+          // compile any targets that were previously
+          // undecided:
+          parent.replaceLast(lastInput.ints[lastInput.offset + idx-1],
+                             compileNode(node),
+                             nextFinalOutput,
+                             isFinal);
+        } else {
+          // replaceLast just to install
+          // nextFinalOutput/isFinal onto the arc
+          parent.replaceLast(lastInput.ints[lastInput.offset + idx-1],
+                             node,
+                             nextFinalOutput,
+                             isFinal);
+          // this node will stay in play for now, since we are
+          // undecided on whether to prune it.  later, it
+          // will be either compiled or pruned, so we must
+          // allocate a new node:
+          frontier[idx] = new UnCompiledNode<T>(this, idx);
+        }
+      }
+    }
+  }
+
+  private final IntsRef scratchIntsRef = new IntsRef(10);
+
+  public void add(BytesRef input, T output) throws IOException {
+    assert fst.getInputType() == FST.INPUT_TYPE.BYTE1;
+    scratchIntsRef.grow(input.length);
+    for(int i=0;i<input.length;i++) {
+      scratchIntsRef.ints[i] = input.bytes[i+input.offset] & 0xFF;
+    }
+    scratchIntsRef.length = input.length;
+    add(scratchIntsRef, output);
+  }
+
+  /** Sugar: adds the UTF32 codepoints from char[] slice.  FST
+   *  must be FST.INPUT_TYPE.BYTE4! */
+  public void add(char[] s, int offset, int length, T output) throws IOException {
+    assert fst.getInputType() == FST.INPUT_TYPE.BYTE4;
+    int charIdx = offset;
+    int intIdx = 0;
+    final int charLimit = offset + length;
+    while(charIdx < charLimit) {
+      scratchIntsRef.grow(intIdx+1);
+      final int utf32 = Character.codePointAt(s, charIdx);
+      scratchIntsRef.ints[intIdx] = utf32;
+      charIdx += Character.charCount(utf32);
+      intIdx++;
+    }
+    scratchIntsRef.length = intIdx;
+    add(scratchIntsRef, output);
+  }
+
+  /** Sugar: adds the UTF32 codepoints from CharSequence.  FST
+   *  must be FST.INPUT_TYPE.BYTE4! */
+  public void add(CharSequence s, T output) throws IOException {
+    assert fst.getInputType() == FST.INPUT_TYPE.BYTE4;
+    int charIdx = 0;
+    int intIdx = 0;
+    final int charLimit = s.length();
+    while(charIdx < charLimit) {
+      scratchIntsRef.grow(intIdx+1);
+      final int utf32 = Character.codePointAt(s, charIdx);
+      scratchIntsRef.ints[intIdx] = utf32;
+      charIdx += Character.charCount(utf32);
+      intIdx++;
+    }
+    scratchIntsRef.length = intIdx;
+    add(scratchIntsRef, output);
+  }
+
+  /** It's OK to add the same input twice in a row with
+   *  different outputs, as long as outputs impls the merge
+   *  method. */
+  public void add(IntsRef input, T output) throws IOException {
+    //System.out.println("\nFST ADD: input=" + input + " output=" + fst.outputs.outputToString(output));
+    assert lastInput.length == 0 || input.compareTo(lastInput) >= 0: "inputs are added out of order lastInput=" + lastInput + " vs input=" + input;
+    assert validOutput(output);
+
+    //System.out.println("\nadd: " + input);
+    if (input.length == 0) {
+      // empty input: only allowed as first input.  we have
+      // to special case this because the packed FST
+      // format cannot represent the empty input since
+      // 'finalness' is stored on the incoming arc, not on
+      // the node
+      frontier[0].inputCount++;
+      frontier[0].isFinal = true;
+      fst.setEmptyOutput(output);
+      return;
+    }
+
+    // compare shared prefix length
+    int pos1 = 0;
+    int pos2 = input.offset;
+    final int pos1Stop = Math.min(lastInput.length, input.length);
+    while(true) {
+      //System.out.println("  incr " + pos1);
+      frontier[pos1].inputCount++;
+      if (pos1 >= pos1Stop || lastInput.ints[pos1] != input.ints[pos2]) {
+        break;
+      }
+      pos1++;
+      pos2++;
+    }
+    final int prefixLenPlus1 = pos1+1;
+      
+    if (frontier.length < input.length+1) {
+      @SuppressWarnings("unchecked") final UnCompiledNode<T>[] next =
+        new UnCompiledNode[ArrayUtil.oversize(input.length+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
+      System.arraycopy(frontier, 0, next, 0, frontier.length);
+      for(int idx=frontier.length;idx<next.length;idx++) {
+        next[idx] = new UnCompiledNode<T>(this, idx);
+      }
+      frontier = next;
+    }
+
+    // minimize/compile states from previous input's
+    // orphan'd suffix
+    compilePrevTail(prefixLenPlus1);
+
+    // init tail states for current input
+    for(int idx=prefixLenPlus1;idx<=input.length;idx++) {
+      frontier[idx-1].addArc(input.ints[input.offset + idx - 1],
+                             frontier[idx]);
+      //System.out.println("  incr tail " + idx);
+      frontier[idx].inputCount++;
+    }
+
+    final UnCompiledNode<T> lastNode = frontier[input.length];
+    lastNode.isFinal = true;
+    lastNode.output = NO_OUTPUT;
+
+    // push conflicting outputs forward, only as far as
+    // needed
+    for(int idx=1;idx<prefixLenPlus1;idx++) {
+      final UnCompiledNode<T> node = frontier[idx];
+      final UnCompiledNode<T> parentNode = frontier[idx-1];
+
+      final T lastOutput = parentNode.getLastOutput(input.ints[input.offset + idx - 1]);
+      assert validOutput(lastOutput);
+
+      final T commonOutputPrefix;
+      final T wordSuffix;
+
+      if (lastOutput != NO_OUTPUT) {
+        commonOutputPrefix = fst.outputs.common(output, lastOutput);
+        assert validOutput(commonOutputPrefix);
+        wordSuffix = fst.outputs.subtract(lastOutput, commonOutputPrefix);
+        assert validOutput(wordSuffix);
+        parentNode.setLastOutput(input.ints[input.offset + idx - 1], commonOutputPrefix);
+        node.prependOutput(wordSuffix);
+      } else {
+        commonOutputPrefix = wordSuffix = NO_OUTPUT;
+      }
+
+      output = fst.outputs.subtract(output, commonOutputPrefix);
+      assert validOutput(output);
+    }
+
+    if (lastInput.length == input.length && prefixLenPlus1 == 1+input.length) {
+      // same input more than 1 time in a row, mapping to
+      // multiple outputs
+      lastNode.output = fst.outputs.merge(lastNode.output, output);
+    } else {
+      // this new arc is private to this new input; set its
+      // arc output to the leftover output:
+      frontier[prefixLenPlus1-1].setLastOutput(input.ints[input.offset + prefixLenPlus1-1], output);
+    }
+
+    // save last input
+    lastInput.copy(input);
+
+    //System.out.println("  count[0]=" + frontier[0].inputCount);
+  }
+
+  private boolean validOutput(T output) {
+    return output == NO_OUTPUT || !output.equals(NO_OUTPUT);
+  }
+
+  /** Returns final FST.  NOTE: this will return null if
+   *  nothing is accepted by the FST. */
+  public FST<T> finish() throws IOException {
+
+    // minimize nodes in the last word's suffix
+    compilePrevTail(1);
+    //System.out.println("finish: inputCount=" + frontier[0].inputCount);
+    if (frontier[0].inputCount < minSuffixCount1 || frontier[0].inputCount < minSuffixCount2 || frontier[0].numArcs == 0) {
+      if (fst.emptyOutput == null) {
+        return null;
+      } else if (minSuffixCount1 > 0 || minSuffixCount2 > 0) {
+        // empty string got pruned
+        return null;
+      } else {
+        fst.finish(compileNode(frontier[0]).address);
+        //System.out.println("compile addr = " + fst.getStartNode());
+        return fst;
+      }
+    } else {
+      if (minSuffixCount2 != 0) {
+        compileAllTargets(frontier[0]);
+      }
+      //System.out.println("NOW: " + frontier[0].numArcs);
+      fst.finish(compileNode(frontier[0]).address);
+    }
+    
+    return fst;
+  }
+
+  private void compileAllTargets(UnCompiledNode<T> node) throws IOException {
+    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
+      final Arc<T> arc = node.arcs[arcIdx];
+      if (!arc.target.isCompiled()) {
+        // not yet compiled
+        @SuppressWarnings("unchecked") final UnCompiledNode<T> n = (UnCompiledNode<T>) arc.target;
+        if (n.numArcs == 0) {
+          //System.out.println("seg=" + segment + "        FORCE final arc=" + (char) arc.label);
+          arc.isFinal = n.isFinal = true;
+        }
+        arc.target = compileNode(n);
+      }
+    }
+  }
+
+  static class Arc<T> {
+    public int label;                             // really an "unsigned" byte
+    public Node target;
+    public boolean isFinal;
+    public T output;
+    public T nextFinalOutput;
+  }
+
+  // NOTE: not many instances of Node or CompiledNode are in
+  // memory while the FST is being built; it's only the
+  // current "frontier":
+
+  static interface Node {
+    boolean isCompiled();
+  }
+
+  static final class CompiledNode implements Node {
+    int address;
+    public boolean isCompiled() {
+      return true;
+    }
+  }
+
+  static final class UnCompiledNode<T> implements Node {
+    final Builder<T> owner;
+    int numArcs;
+    Arc<T>[] arcs;
+    T output;
+    boolean isFinal;
+    long inputCount;
+
+    /** This node's depth, starting from the automaton root. */
+    final int depth;
+
+    /**
+     * @param depth
+     *          The node's depth starting from the automaton root. Needed for
+     *          LUCENE-2934 (node expansion based on conditions other than the
+     *          fanout size).
+     */
+    @SuppressWarnings("unchecked")
+    public UnCompiledNode(Builder<T> owner, int depth) {
+      this.owner = owner;
+      arcs = (Arc<T>[]) new Arc[1];
+      arcs[0] = new Arc<T>();
+      output = owner.NO_OUTPUT;
+      this.depth = depth;
+    }
+
+    public boolean isCompiled() {
+      return false;
+    }
+
+    public void clear() {
+      numArcs = 0;
+      isFinal = false;
+      output = owner.NO_OUTPUT;
+      inputCount = 0;
+
+      // We don't clear the depth here because it never changes 
+      // for nodes on the frontier (even when reused).
+    }
+
+    public T getLastOutput(int labelToMatch) {
+      assert numArcs > 0;
+      assert arcs[numArcs-1].label == labelToMatch;
+      return arcs[numArcs-1].output;
+    }
+
+    public void addArc(int label, Node target) {
+      assert label >= 0;
+      assert numArcs == 0 || label > arcs[numArcs-1].label: "arc[-1].label=" + arcs[numArcs-1].label + " new label=" + label + " numArcs=" + numArcs;
+      if (numArcs == arcs.length) {
+        @SuppressWarnings("unchecked") final Arc<T>[] newArcs =
+          new Arc[ArrayUtil.oversize(numArcs+1, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
+        System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
+        for(int arcIdx=numArcs;arcIdx<newArcs.length;arcIdx++) {
+          newArcs[arcIdx] = new Arc<T>();
+        }
+        arcs = newArcs;
+      }
+      final Arc<T> arc = arcs[numArcs++];
+      arc.label = label;
+      arc.target = target;
+      arc.output = arc.nextFinalOutput = owner.NO_OUTPUT;
+      arc.isFinal = false;
+    }
+
+    public void replaceLast(int labelToMatch, Node target, T nextFinalOutput, boolean isFinal) {
+      assert numArcs > 0;
+      final Arc<T> arc = arcs[numArcs-1];
+      assert arc.label == labelToMatch: "arc.label=" + arc.label + " vs " + labelToMatch;
+      arc.target = target;
+      //assert target.address != -2;
+      arc.nextFinalOutput = nextFinalOutput;
+      arc.isFinal = isFinal;
+    }
+
+    public void deleteLast(int label, Node target) {
+      assert numArcs > 0;
+      assert label == arcs[numArcs-1].label;
+      assert target == arcs[numArcs-1].target;
+      numArcs--;
+    }
+
+    public void setLastOutput(int labelToMatch, T newOutput) {
+      assert owner.validOutput(newOutput);
+      assert numArcs > 0;
+      final Arc<T> arc = arcs[numArcs-1];
+      assert arc.label == labelToMatch;
+      arc.output = newOutput;
+    }
+
+    // pushes an output prefix forward onto all arcs
+    public void prependOutput(T outputPrefix) {
+      assert owner.validOutput(outputPrefix);
+
+      for(int arcIdx=0;arcIdx<numArcs;arcIdx++) {
+        arcs[arcIdx].output = owner.fst.outputs.add(outputPrefix, arcs[arcIdx].output);
+        assert owner.validOutput(arcs[arcIdx].output);
+      }
+
+      if (isFinal) {
+        output = owner.fst.outputs.add(outputPrefix, output);
+        assert owner.validOutput(output);
+      }
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java
new file mode 100644
index 0000000..8969090
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/ByteSequenceOutputs.java
@@ -0,0 +1,138 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.util.BytesRef;
+
+/**
+ * Output is a sequence of bytes, for each input term.
+ *
+ * @lucene.experimental
+ */
+
+public final class ByteSequenceOutputs extends Outputs<BytesRef> {
+
+  private final static BytesRef NO_OUTPUT = new BytesRef();
+
+  private ByteSequenceOutputs() {
+  }
+
+  public static ByteSequenceOutputs getSingleton() {
+    return new ByteSequenceOutputs();
+  }
+
+  @Override
+  public BytesRef common(BytesRef output1, BytesRef output2) {
+    assert output1 != null;
+    assert output2 != null;
+
+    int pos1 = output1.offset;
+    int pos2 = output2.offset;
+    int stopAt1 = pos1 + Math.min(output1.length, output2.length);
+    while(pos1 < stopAt1) {
+      if (output1.bytes[pos1] != output2.bytes[pos2]) {
+        break;
+      }
+      pos1++;
+      pos2++;
+    }
+
+    if (pos1 == output1.offset) {
+      // no common prefix
+      return NO_OUTPUT;
+    } else if (pos1 == output1.offset + output1.length) {
+      // output1 is a prefix of output2
+      return output1;
+    } else if (pos2 == output2.offset + output2.length) {
+      // output2 is a prefix of output1
+      return output2;
+    } else {
+      return new BytesRef(output1.bytes, output1.offset, pos1-output1.offset);
+    }
+  }
+
+  @Override
+  public BytesRef subtract(BytesRef output, BytesRef inc) {
+    assert output != null;
+    assert inc != null;
+    if (inc == NO_OUTPUT) {
+      // no prefix removed
+      return output;
+    } else if (inc.length == output.length) {
+      // entire output removed
+      return NO_OUTPUT;
+    } else {
+      assert inc.length < output.length: "inc.length=" + inc.length + " vs output.length=" + output.length;
+      assert inc.length > 0;
+      return new BytesRef(output.bytes, output.offset + inc.length, output.length-inc.length);
+    }
+  }
+
+  @Override
+  public BytesRef add(BytesRef prefix, BytesRef output) {
+    assert prefix != null;
+    assert output != null;
+    if (prefix == NO_OUTPUT) {
+      return output;
+    } else if (output == NO_OUTPUT) {
+      return prefix;
+    } else {
+      assert prefix.length > 0;
+      assert output.length > 0;
+      BytesRef result = new BytesRef(prefix.length + output.length);
+      System.arraycopy(prefix.bytes, prefix.offset, result.bytes, 0, prefix.length);
+      System.arraycopy(output.bytes, output.offset, result.bytes, prefix.length, output.length);
+      result.length = prefix.length + output.length;
+      return result;
+    }
+  }
+
+  @Override
+  public void write(BytesRef prefix, DataOutput out) throws IOException {
+    assert prefix != null;
+    out.writeVInt(prefix.length);
+    out.writeBytes(prefix.bytes, prefix.offset, prefix.length);
+  }
+
+  @Override
+  public BytesRef read(DataInput in) throws IOException {
+    final int len = in.readVInt();
+    if (len == 0) {
+      return NO_OUTPUT;
+    } else {
+      final BytesRef output = new BytesRef(len);
+      in.readBytes(output.bytes, 0, len);
+      output.length = len;
+      return output;
+    }
+  }
+
+  @Override
+  public BytesRef getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(BytesRef output) {
+    return output.utf8ToString();
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java b/lucene/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java
new file mode 100644
index 0000000..e3eff43
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/BytesRefFSTEnum.java
@@ -0,0 +1,108 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.util.BytesRef;
+
+/** Can next() and advance() through the terms in an FST
+ *
+  * @lucene.experimental
+*/
+
+public final class BytesRefFSTEnum<T> extends FSTEnum<T> {
+  private final BytesRef current = new BytesRef(10);
+  private final InputOutput<T> result = new InputOutput<T>();
+  private BytesRef target;
+
+  public static class InputOutput<T> {
+    public BytesRef input;
+    public T output;
+  }
+
+  /** doFloor controls the behavior of advance: if it's true
+   *  doFloor is true, advance positions to the biggest
+   *  term before target.  */
+  public BytesRefFSTEnum(FST<T> fst) {
+    super(fst);
+    result.input = current;
+    current.offset = 1;
+  }
+
+  public InputOutput<T> current() {
+    return result;
+  }
+
+  public InputOutput<T> next() throws IOException {
+    //System.out.println("  enum.next");
+    doNext();
+    return setResult();
+  }
+
+  /** Seeks to smallest term that's >= target. */
+  public InputOutput<T> seekCeil(BytesRef target) throws IOException {
+    this.target = target;
+    targetLength = target.length;
+    super.doSeekCeil();
+    return setResult();
+  }
+
+  /** Seeks to biggest term that's <= target. */
+  public InputOutput<T> seekFloor(BytesRef target) throws IOException {
+    this.target = target;
+    targetLength = target.length;
+    super.doSeekFloor();
+    return setResult();
+  }
+
+  @Override
+  protected int getTargetLabel() {
+    if (upto-1 == target.length) {
+      return FST.END_LABEL;
+    } else {
+      return target.bytes[target.offset + upto - 1] & 0xFF;
+    }
+  }
+
+  @Override
+  protected int getCurrentLabel() {
+    // current.offset fixed at 1
+    return current.bytes[upto] & 0xFF;
+  }
+
+  @Override
+  protected void setCurrentLabel(int label) {
+    current.bytes[upto] = (byte) label;
+  }
+
+  @Override
+  protected void grow() {
+    current.grow(upto+1);
+  }
+
+  private InputOutput<T> setResult() {
+    if (upto == 0) {
+      return null;
+    } else {
+      current.length = upto-1;
+      result.output = output[upto];
+      return result;
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/FST.java b/lucene/src/java/org/apache/lucene/util/fst/FST.java
new file mode 100644
index 0000000..04428c6
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/FST.java
@@ -0,0 +1,872 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.CodecUtil;
+import org.apache.lucene.util.fst.Builder.UnCompiledNode;
+
+// NOTE: while the FST is able to represent a non-final
+// dead-end state (NON_FINAL_END_NODE=0), the layres above
+// (FSTEnum, Util) have problems with this!!
+
+/** Represents an FST using a compact byte[] format.
+ *  <p> The format is similar to what's used by Morfologik
+ *  (http://sourceforge.net/projects/morfologik).
+ *
+ * @lucene.experimental
+ */
+public class FST<T> {
+  public static enum INPUT_TYPE {BYTE1, BYTE2, BYTE4};
+  public final INPUT_TYPE inputType;
+
+  private final static int BIT_FINAL_ARC = 1 << 0;
+  private final static int BIT_LAST_ARC = 1 << 1;
+  private final static int BIT_TARGET_NEXT = 1 << 2;
+  private final static int BIT_STOP_NODE = 1 << 3;
+  private final static int BIT_ARC_HAS_OUTPUT = 1 << 4;
+  private final static int BIT_ARC_HAS_FINAL_OUTPUT = 1 << 5;
+
+  // Arcs are stored as fixed-size (per entry) array, so
+  // that we can find an arc using binary search.  We do
+  // this when number of arcs is > NUM_ARCS_ARRAY:
+  private final static int BIT_ARCS_AS_FIXED_ARRAY = 1 << 6;
+
+  /**
+   * @see #shouldExpand(UnCompiledNode)
+   */
+  final static int FIXED_ARRAY_SHALLOW_DISTANCE = 3; // 0 => only root node.
+
+  /**
+   * @see #shouldExpand(UnCompiledNode)
+   */
+  final static int FIXED_ARRAY_NUM_ARCS_SHALLOW = 5;
+
+  /**
+   * @see #shouldExpand(UnCompiledNode)
+   */
+  final static int FIXED_ARRAY_NUM_ARCS_DEEP = 10;
+
+  private int[] bytesPerArc = new int[0];
+
+  // Increment version to change it
+  private final static String FILE_FORMAT_NAME = "FST";
+  private final static int VERSION_START = 0;
+  private final static int VERSION_CURRENT = VERSION_START;
+
+  // Never serialized; just used to represent the virtual
+  // final node w/ no arcs:
+  private final static int FINAL_END_NODE = -1;
+
+  // Never serialized; just used to represent the virtual
+  // non-final node w/ no arcs:
+  private final static int NON_FINAL_END_NODE = 0;
+
+  // if non-null, this FST accepts the empty string and
+  // produces this output
+  T emptyOutput;
+  private byte[] emptyOutputBytes;
+
+  private byte[] bytes;
+  int byteUpto = 0;
+
+  private int startNode = -1;
+
+  public final Outputs<T> outputs;
+
+  private int lastFrozenNode;
+
+  private final T NO_OUTPUT;
+
+  public int nodeCount;
+  public int arcCount;
+  public int arcWithOutputCount;
+
+  // If arc has this label then that arc is final/accepted
+  public static final int END_LABEL = -1;
+
+  public final static class Arc<T> {
+    public int label;
+    public T output;
+
+    int target;
+
+    byte flags;
+    T nextFinalOutput;
+    int nextArc;
+
+    // This is non-zero if current arcs are fixed array:
+    int posArcsStart;
+    int bytesPerArc;
+    int arcIdx;
+    int numArcs;
+
+    /** Returns this */
+    public Arc<T> copyFrom(Arc<T> other) {
+      label = other.label;
+      target = other.target;
+      flags = other.flags;
+      output = other.output;
+      nextFinalOutput = other.nextFinalOutput;
+      nextArc = other.nextArc;
+      if (other.bytesPerArc != 0) {
+        bytesPerArc = other.bytesPerArc;
+        posArcsStart = other.posArcsStart;
+        arcIdx = other.arcIdx;
+        numArcs = other.numArcs;
+      } else {
+        bytesPerArc = 0;
+      }
+      return this;
+    }
+
+    boolean flag(int flag) {
+      return FST.flag(flags, flag);
+    }
+
+    public boolean isLast() {
+      return flag(BIT_LAST_ARC);
+    }
+
+    boolean isFinal() {
+      return flag(BIT_FINAL_ARC);
+    }
+  };
+
+  static boolean flag(int flags, int bit) {
+    return (flags & bit) != 0;
+  }
+
+  private final BytesWriter writer;
+
+  // make a new empty FST, for building
+  public FST(INPUT_TYPE inputType, Outputs<T> outputs) {
+    this.inputType = inputType;
+    this.outputs = outputs;
+    bytes = new byte[128];
+    NO_OUTPUT = outputs.getNoOutput();
+    
+    writer = new BytesWriter();
+
+    emptyOutput = null;
+  }
+
+  // create an existing FST
+  public FST(DataInput in, Outputs<T> outputs) throws IOException {
+    this.outputs = outputs;
+    writer = null;
+    CodecUtil.checkHeader(in, FILE_FORMAT_NAME, VERSION_START, VERSION_START);
+    if (in.readByte() == 1) {
+      // accepts empty string
+      int numBytes = in.readVInt();
+      // messy
+      bytes = new byte[numBytes];
+      in.readBytes(bytes, 0, numBytes);
+      emptyOutput = outputs.read(getBytesReader(numBytes-1));
+    } else {
+      emptyOutput = null;
+    }
+    final byte t = in.readByte();
+    switch(t) {
+      case 0:
+        inputType = INPUT_TYPE.BYTE1;
+        break;
+      case 1:
+        inputType = INPUT_TYPE.BYTE2;
+        break;
+      case 2:
+        inputType = INPUT_TYPE.BYTE4;
+        break;
+    default:
+      throw new IllegalStateException("invalid input type " + t);
+    }
+    startNode = in.readVInt();
+    nodeCount = in.readVInt();
+    arcCount = in.readVInt();
+    arcWithOutputCount = in.readVInt();
+
+    bytes = new byte[in.readVInt()];
+    in.readBytes(bytes, 0, bytes.length);
+    NO_OUTPUT = outputs.getNoOutput();
+  }
+
+  public INPUT_TYPE getInputType() {
+    return inputType;
+  }
+
+  /** Returns bytes used to represent the FST */
+  public int sizeInBytes() {
+    return bytes.length;
+  }
+
+  void finish(int startNode) {
+    if (startNode == FINAL_END_NODE && emptyOutput != null) {
+      startNode = 0;
+    }
+    if (this.startNode != -1) {
+      throw new IllegalStateException("already finished");
+    }
+    byte[] finalBytes = new byte[writer.posWrite];
+    System.arraycopy(bytes, 0, finalBytes, 0, writer.posWrite);
+    bytes = finalBytes;
+    this.startNode = startNode;
+  }
+
+  void setEmptyOutput(T v) throws IOException {
+    if (emptyOutput != null) {
+      emptyOutput = outputs.merge(emptyOutput, v);
+    } else {
+      emptyOutput = v;
+    }
+
+    // TODO: this is messy -- replace with sillyBytesWriter; maybe make
+    // bytes private
+    final int posSave = writer.posWrite;
+    outputs.write(emptyOutput, writer);
+    emptyOutputBytes = new byte[writer.posWrite-posSave];
+
+    // reverse
+    final int stopAt = (writer.posWrite - posSave)/2;
+    int upto = 0;
+    while(upto < stopAt) {
+      final byte b = bytes[posSave + upto];
+      bytes[posSave+upto] = bytes[writer.posWrite-upto-1];
+      bytes[writer.posWrite-upto-1] = b;
+      upto++;
+    }
+    System.arraycopy(bytes, posSave, emptyOutputBytes, 0, writer.posWrite-posSave);
+    writer.posWrite = posSave;
+  }
+
+  public void save(DataOutput out) throws IOException {
+    if (startNode == -1) {
+      throw new IllegalStateException("call finish first");
+    }
+    CodecUtil.writeHeader(out, FILE_FORMAT_NAME, VERSION_CURRENT);
+    // TODO: really we should encode this as an arc, arriving
+    // to the root node, instead of special casing here:
+    if (emptyOutput != null) {
+      out.writeByte((byte) 1);
+      out.writeVInt(emptyOutputBytes.length);
+      out.writeBytes(emptyOutputBytes, 0, emptyOutputBytes.length);
+    } else {
+      out.writeByte((byte) 0);
+    }
+    final byte t;
+    if (inputType == INPUT_TYPE.BYTE1) {
+      t = 0;
+    } else if (inputType == INPUT_TYPE.BYTE2) {
+      t = 1;
+    } else {
+      t = 2;
+    }
+    out.writeByte(t);
+    out.writeVInt(startNode);
+    out.writeVInt(nodeCount);
+    out.writeVInt(arcCount);
+    out.writeVInt(arcWithOutputCount);
+    out.writeVInt(bytes.length);
+    out.writeBytes(bytes, 0, bytes.length);
+  }
+
+  private void writeLabel(int v) throws IOException {
+    assert v >= 0: "v=" + v;
+    if (inputType == INPUT_TYPE.BYTE1) {
+      assert v <= 255: "v=" + v;
+      writer.writeByte((byte) v);
+    } else if (inputType == INPUT_TYPE.BYTE2) {
+      assert v <= 65535: "v=" + v;
+      writer.writeVInt(v);
+    } else {
+      //writeInt(v);
+      writer.writeVInt(v);
+    }
+  }
+
+  int readLabel(DataInput in) throws IOException {
+    final int v;
+    if (inputType == INPUT_TYPE.BYTE1) {
+      v = in.readByte()&0xFF;
+    } else { 
+      v = in.readVInt();
+    }
+    return v;
+  }
+
+  // returns true if the node at this address has any
+  // outgoing arcs
+  public boolean targetHasArcs(Arc<T> arc) {
+    return arc.target > 0;
+  }
+
+  // serializes new node by appending its bytes to the end
+  // of the current byte[]
+  int addNode(Builder.UnCompiledNode<T> node) throws IOException {
+    //System.out.println("FST.addNode pos=" + posWrite + " numArcs=" + node.numArcs);
+    if (node.numArcs == 0) {
+      if (node.isFinal) {
+        return FINAL_END_NODE;
+      } else {
+        return NON_FINAL_END_NODE;
+      }
+    }
+
+    int startAddress = writer.posWrite;
+    //System.out.println("  startAddr=" + startAddress);
+
+    final boolean doFixedArray = shouldExpand(node);
+    final int fixedArrayStart;
+    if (doFixedArray) {
+      if (bytesPerArc.length < node.numArcs) {
+        bytesPerArc = new int[ArrayUtil.oversize(node.numArcs, 1)];
+      }
+      // write a "false" first arc:
+      writer.writeByte((byte) BIT_ARCS_AS_FIXED_ARRAY);
+      writer.writeVInt(node.numArcs);
+      // placeholder -- we'll come back and write the number
+      // of bytes per arc here:
+      writer.writeByte((byte) 0);
+      fixedArrayStart = writer.posWrite;
+      //System.out.println("  do fixed arcs array arcsStart=" + fixedArrayStart);
+    } else {
+      fixedArrayStart = 0;
+    }
+
+    nodeCount++;
+    arcCount += node.numArcs;
+    
+    final int lastArc = node.numArcs-1;
+
+    int lastArcStart = writer.posWrite;
+    int maxBytesPerArc = 0;
+    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
+      final Builder.Arc<T> arc = node.arcs[arcIdx];
+      final Builder.CompiledNode target = (Builder.CompiledNode) arc.target;
+      int flags = 0;
+
+      if (arcIdx == lastArc) {
+        flags += BIT_LAST_ARC;
+      }
+
+      if (lastFrozenNode == target.address && !doFixedArray) {
+        flags += BIT_TARGET_NEXT;
+      }
+
+      if (arc.isFinal) {
+        flags += BIT_FINAL_ARC;
+        if (arc.nextFinalOutput != NO_OUTPUT) {
+          flags += BIT_ARC_HAS_FINAL_OUTPUT;
+        }
+      } else {
+        assert arc.nextFinalOutput == NO_OUTPUT;
+      }
+
+      boolean targetHasArcs = target.address > 0;
+
+      if (!targetHasArcs) {
+        flags += BIT_STOP_NODE;
+      }
+
+      if (arc.output != NO_OUTPUT) {
+        flags += BIT_ARC_HAS_OUTPUT;
+      }
+
+      writer.writeByte((byte) flags);
+      writeLabel(arc.label);
+
+      //System.out.println("  write arc: label=" + arc.label + " flags=" + flags);
+
+      if (arc.output != NO_OUTPUT) {
+        outputs.write(arc.output, writer);
+        arcWithOutputCount++;
+      }
+      if (arc.nextFinalOutput != NO_OUTPUT) {
+        outputs.write(arc.nextFinalOutput, writer);
+      }
+
+      if (targetHasArcs && (doFixedArray || lastFrozenNode != target.address)) {
+        assert target.address > 0;
+        writer.writeInt(target.address);
+      }
+
+      // just write the arcs "like normal" on first pass,
+      // but record how many bytes each one took, and max
+      // byte size:
+      if (doFixedArray) {
+        bytesPerArc[arcIdx] = writer.posWrite - lastArcStart;
+        lastArcStart = writer.posWrite;
+        maxBytesPerArc = Math.max(maxBytesPerArc, bytesPerArc[arcIdx]);
+        //System.out.println("    bytes=" + bytesPerArc[arcIdx]);
+      }
+    }
+
+    if (doFixedArray) {
+      assert maxBytesPerArc > 0;
+      // 2nd pass just "expands" all arcs to take up a fixed
+      // byte size
+      final int sizeNeeded = fixedArrayStart + node.numArcs * maxBytesPerArc;
+      bytes = ArrayUtil.grow(bytes, sizeNeeded);
+      if (maxBytesPerArc > 255) {
+        throw new IllegalStateException("max arc size is too large (" + maxBytesPerArc + ")");
+      }
+      bytes[fixedArrayStart-1] = (byte) maxBytesPerArc;
+
+      // expand the arcs in place, backwards
+      int srcPos = writer.posWrite;
+      int destPos = fixedArrayStart + node.numArcs*maxBytesPerArc;
+      writer.posWrite = destPos;
+      for(int arcIdx=node.numArcs-1;arcIdx>=0;arcIdx--) {
+        //System.out.println("  repack arcIdx=" + arcIdx + " srcPos=" + srcPos + " destPos=" + destPos);
+        destPos -= maxBytesPerArc;
+        srcPos -= bytesPerArc[arcIdx];
+        if (srcPos != destPos) {
+          assert destPos > srcPos;
+          System.arraycopy(bytes, srcPos, bytes, destPos, bytesPerArc[arcIdx]);
+        }
+      }
+    }
+
+    // reverse bytes in-place; we do this so that the
+    // "BIT_TARGET_NEXT" opto can work, ie, it reads the
+    // node just before the current one
+    final int endAddress = lastFrozenNode = writer.posWrite - 1;
+
+    int left = startAddress;
+    int right = endAddress;
+    while (left < right) {
+      final byte b = bytes[left];
+      bytes[left++] = bytes[right];
+      bytes[right--] = b;
+    }
+
+    return endAddress;
+  }
+
+  /** Fills virtual 'start' arc, ie, an empty incoming arc to
+   *  the FST's start node */
+  public Arc<T> getFirstArc(Arc<T> arc) {
+    if (emptyOutput != null) {
+      arc.flags = BIT_FINAL_ARC | BIT_LAST_ARC;
+      arc.nextFinalOutput = emptyOutput;
+    } else {
+      arc.flags = BIT_LAST_ARC;
+      arc.nextFinalOutput = NO_OUTPUT;
+    }
+    arc.output = NO_OUTPUT;
+
+    // If there are no nodes, ie, the FST only accepts the
+    // empty string, then startNode is 0, and then readFirstTargetArc
+    arc.target = startNode;
+    return arc;
+  }
+
+  /** Follows the <code>follow</code> arc and reads the last
+   *  arc of its target; this changes the provided
+   *  <code>arc</code> (2nd arg) in-place and returns it.
+   * 
+   * @return Returns the second argument
+   * (<code>arc</code>). */
+  public Arc<T> readLastTargetArc(Arc<T> follow, Arc<T> arc) throws IOException {
+    //System.out.println("readLast");
+    if (!targetHasArcs(follow)) {
+      //System.out.println("  end node");
+      assert follow.isFinal();
+      arc.label = -1;
+      arc.output = follow.nextFinalOutput;
+      arc.flags = BIT_LAST_ARC;
+      return arc;
+    } else {
+      final BytesReader in = getBytesReader(follow.target);
+      arc.flags = in.readByte();
+      if (arc.flag(BIT_ARCS_AS_FIXED_ARRAY)) {
+        // array: jump straight to end
+        arc.numArcs = in.readVInt();
+        arc.bytesPerArc = in.readByte() & 0xFF;
+        //System.out.println("  array numArcs=" + arc.numArcs + " bpa=" + arc.bytesPerArc);
+        arc.posArcsStart = in.pos;
+        arc.arcIdx = arc.numArcs - 2;
+      } else {
+        // non-array: linear scan
+        arc.bytesPerArc = 0;
+        //System.out.println("  scan");
+        while(!arc.isLast()) {
+          // skip this arc:
+          readLabel(in);
+          if (arc.flag(BIT_ARC_HAS_OUTPUT)) {
+            outputs.read(in);
+          }
+          if (arc.flag(BIT_ARC_HAS_FINAL_OUTPUT)) {
+            outputs.read(in);
+          }
+          if (arc.flag(BIT_STOP_NODE)) {
+          } else if (arc.flag(BIT_TARGET_NEXT)) {
+          } else {
+            in.pos -= 4;
+          }
+          arc.flags = in.readByte();
+        }
+        arc.nextArc = in.pos+1;
+      }
+      readNextRealArc(arc);
+      assert arc.isLast();
+      return arc;
+    }
+  }
+
+  /**
+   * Follow the <code>follow</code> arc and read the first arc of its target;
+   * this changes the provided <code>arc</code> (2nd arg) in-place and returns
+   * it.
+   * 
+   * @return Returns the second argument (<code>arc</code>).
+   */
+  public Arc<T> readFirstTargetArc(Arc<T> follow, Arc<T> arc) throws IOException {
+    //int pos = address;
+    //System.out.println("    readFirstTarget follow.target=" + follow.target + " isFinal=" + follow.isFinal());
+    if (follow.isFinal()) {
+      // Insert "fake" final first arc:
+      arc.label = -1;
+      arc.output = follow.nextFinalOutput;
+      if (follow.target <= 0) {
+        arc.flags = BIT_LAST_ARC;
+      } else {
+        arc.flags = 0;
+        arc.nextArc = follow.target;
+      }
+      //System.out.println("    insert isFinal; nextArc=" + follow.target + " isLast=" + arc.isLast() + " output=" + outputs.outputToString(arc.output));
+      return arc;
+    } else {
+      return readFirstRealArc(follow.target, arc);
+    }
+  }
+
+  // Not private because NodeHash needs access:
+  Arc<T> readFirstRealArc(int address, Arc<T> arc) throws IOException {
+
+    final BytesReader in = getBytesReader(address);
+
+    arc.flags = in.readByte();
+
+    if (arc.flag(BIT_ARCS_AS_FIXED_ARRAY)) {
+      //System.out.println("  fixedArray");
+      // this is first arc in a fixed-array
+      arc.numArcs = in.readVInt();
+      arc.bytesPerArc = in.readByte() & 0xFF;
+      arc.arcIdx = -1;
+      arc.nextArc = arc.posArcsStart = in.pos;
+      //System.out.println("  bytesPer=" + arc.bytesPerArc + " numArcs=" + arc.numArcs + " arcsStart=" + pos);
+    } else {
+      arc.nextArc = address;
+      arc.bytesPerArc = 0;
+    }
+    return readNextRealArc(arc);
+  }
+
+  /**
+   * Checks if <code>arc</code>'s target state is in expanded (or vector) format. 
+   * 
+   * @return Returns <code>true</code> if <code>arc</code> points to a state in an
+   * expanded array format.
+   */
+  boolean isExpandedTarget(Arc<T> follow) throws IOException {
+    if (!targetHasArcs(follow)) {
+      return false;
+    } else {
+      final BytesReader in = getBytesReader(follow.target);
+      final byte b = in.readByte();
+      return (b & BIT_ARCS_AS_FIXED_ARRAY) != 0;
+    }
+  }
+
+  /** In-place read; returns the arc. */
+  public Arc<T> readNextArc(Arc<T> arc) throws IOException {
+    if (arc.label == -1) {
+      // This was a fake inserted "final" arc
+      if (arc.nextArc <= 0) {
+        // This arc went to virtual final node, ie has no outgoing arcs
+        return null;
+      }
+      return readFirstRealArc(arc.nextArc, arc);
+    } else {
+      return readNextRealArc(arc);
+    }
+  }
+
+  /** Peeks at next arc's label; does not alter arc.  Do
+   *  not call this if arc.isLast()! */
+  public int readNextArcLabel(Arc<T> arc) throws IOException {
+    assert !arc.isLast();
+
+    final BytesReader in;
+    if (arc.label == END_LABEL) {
+      //System.out.println("    nextArc fake " + arc.nextArc);
+      in = getBytesReader(arc.nextArc);
+      byte flags = bytes[in.pos];
+      if (flag(flags, BIT_ARCS_AS_FIXED_ARRAY)) {
+        //System.out.println("    nextArc fake array");
+        in.pos--;
+        in.readVInt();
+        in.readByte();
+      }
+    } else {
+      if (arc.bytesPerArc != 0) {
+        //System.out.println("    nextArc real array");
+        // arcs are at fixed entries
+        in = getBytesReader(arc.posArcsStart - (1+arc.arcIdx)*arc.bytesPerArc);
+      } else {
+        // arcs are packed
+        //System.out.println("    nextArc real packed");
+        in = getBytesReader(arc.nextArc);
+      }
+    }
+    // skip flags
+    in.readByte();
+    return readLabel(in);
+  }
+
+  Arc<T> readNextRealArc(Arc<T> arc) throws IOException {
+    // this is a continuing arc in a fixed array
+    final BytesReader in;
+    if (arc.bytesPerArc != 0) {
+      // arcs are at fixed entries
+      arc.arcIdx++;
+      assert arc.arcIdx < arc.numArcs;
+      in = getBytesReader(arc.posArcsStart - arc.arcIdx*arc.bytesPerArc);
+    } else {
+      // arcs are packed
+      in = getBytesReader(arc.nextArc);
+    }
+    arc.flags = in.readByte();
+    arc.label = readLabel(in);
+
+    if (arc.flag(BIT_ARC_HAS_OUTPUT)) {
+      arc.output = outputs.read(in);
+    } else {
+      arc.output = outputs.getNoOutput();
+    }
+
+    if (arc.flag(BIT_ARC_HAS_FINAL_OUTPUT)) {
+      arc.nextFinalOutput = outputs.read(in);
+    } else {
+      arc.nextFinalOutput = outputs.getNoOutput();
+    }
+
+    if (arc.flag(BIT_STOP_NODE)) {
+      if (arc.flag(BIT_FINAL_ARC)) {
+        arc.target = FINAL_END_NODE;
+      } else {
+        arc.target = NON_FINAL_END_NODE;
+      }
+      arc.nextArc = in.pos;
+    } else if (arc.flag(BIT_TARGET_NEXT)) {
+      arc.nextArc = in.pos;
+      if (!arc.flag(BIT_LAST_ARC)) {
+        if (arc.bytesPerArc == 0) {
+          // must scan
+          seekToNextNode(in);
+        } else {
+          in.pos = arc.posArcsStart - arc.bytesPerArc * arc.numArcs;
+        }
+      }
+      arc.target = in.pos;
+    } else {
+      arc.target = in.readInt();
+      arc.nextArc = in.pos;
+    }
+
+    return arc;
+  }
+
+  /** Finds an arc leaving the incoming arc, replacing the arc in place.
+   *  This returns null if the arc was not found, else the incoming arc. */
+  public Arc<T> findTargetArc(int labelToMatch, Arc<T> follow, Arc<T> arc) throws IOException {
+
+    if (labelToMatch == END_LABEL) {
+      if (follow.isFinal()) {
+        arc.output = follow.nextFinalOutput;
+        arc.label = END_LABEL;
+        return arc;
+      } else {
+        return null;
+      }
+    }
+
+    if (!targetHasArcs(follow)) {
+      return null;
+    }
+
+    // TODO: maybe make an explicit thread state that holds
+    // reusable stuff eg BytesReader:
+    final BytesReader in = getBytesReader(follow.target);
+
+    if ((in.readByte() & BIT_ARCS_AS_FIXED_ARRAY) != 0) {
+      // Arcs are full array; do binary search:
+      arc.numArcs = in.readVInt();
+      arc.bytesPerArc = in.readByte() & 0xFF;
+      arc.posArcsStart = in.pos;
+      int low = 0;
+      int high = arc.numArcs-1;
+      while (low <= high) {
+        int mid = (low + high) >>> 1;
+        in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
+        int midLabel = readLabel(in);
+        final int cmp = midLabel - labelToMatch;
+        if (cmp < 0)
+          low = mid + 1;
+        else if (cmp > 0)
+          high = mid - 1;
+        else {
+          arc.arcIdx = mid-1;
+          return readNextRealArc(arc);
+        }
+      }
+
+      return null;
+    }
+
+    // Linear scan
+    readFirstTargetArc(follow, arc);
+    while(true) {
+      if (arc.label == labelToMatch) {
+        return arc;
+      } else if (arc.label > labelToMatch) {
+        return null;
+      } else if (arc.isLast()) {
+        return null;
+      } else {
+        readNextArc(arc);
+      }
+    }
+  }
+
+  private void seekToNextNode(BytesReader in) throws IOException {
+
+    while(true) {
+
+      final int flags = in.readByte();
+      readLabel(in);
+
+      if (flag(flags, BIT_ARC_HAS_OUTPUT)) {
+        outputs.read(in);
+      }
+
+      if (flag(flags, BIT_ARC_HAS_FINAL_OUTPUT)) {
+        outputs.read(in);
+      }
+
+      if (!flag(flags, BIT_STOP_NODE) && !flag(flags, BIT_TARGET_NEXT)) {
+        in.readInt();
+      }
+
+      if (flag(flags, BIT_LAST_ARC)) {
+        return;
+      }
+    }
+  }
+
+  public int getNodeCount() {
+    // 1+ in order to count the -1 implicit final node
+    return 1+nodeCount;
+  }
+  
+  public int getArcCount() {
+    return arcCount;
+  }
+
+  public int getArcWithOutputCount() {
+    return arcWithOutputCount;
+  }
+  
+  /**
+   * Nodes will be expanded if their depth (distance from the root node) is
+   * &lt;= this value and their number of arcs is &gt;=
+   * {@link #FIXED_ARRAY_NUM_ARCS_SHALLOW}.
+   * 
+   * <p>
+   * Fixed array consumes more RAM but enables binary search on the arcs
+   * (instead of a linear scan) on lookup by arc label.
+   * 
+   * @return <code>true</code> if <code>node</code> should be stored in an
+   *         expanded (array) form.
+   * 
+   * @see #FIXED_ARRAY_NUM_ARCS_DEEP
+   * @see Builder.UnCompiledNode#depth
+   */
+  private boolean shouldExpand(UnCompiledNode<T> node) {
+    return (node.depth <= FIXED_ARRAY_SHALLOW_DISTANCE && node.numArcs >= FIXED_ARRAY_NUM_ARCS_SHALLOW) || 
+            node.numArcs >= FIXED_ARRAY_NUM_ARCS_DEEP;
+  }
+
+  // Non-static: writes to FST's byte[]
+  class BytesWriter extends DataOutput {
+    int posWrite;
+
+    public BytesWriter() {
+      // pad: ensure no node gets address 0 which is reserved to mean
+      // the stop state w/ no arcs
+      posWrite = 1;
+    }
+
+    @Override
+    public void writeByte(byte b) {
+      if (bytes.length == posWrite) {
+        bytes = ArrayUtil.grow(bytes);
+      }
+      assert posWrite < bytes.length: "posWrite=" + posWrite + " bytes.length=" + bytes.length;
+      bytes[posWrite++] = b;
+    }
+
+    @Override
+    public void writeBytes(byte[] b, int offset, int length) {
+      final int size = posWrite + length;
+      bytes = ArrayUtil.grow(bytes, size);
+      System.arraycopy(b, offset, bytes, posWrite, length);
+      posWrite += length;
+    }
+  }
+
+  final BytesReader getBytesReader(int pos) {
+    // TODO: maybe re-use via ThreadLocal?
+    return new BytesReader(pos);
+  }
+
+  // Non-static: reads byte[] from FST
+  class BytesReader extends DataInput {
+    int pos;
+
+    public BytesReader(int pos) {
+      this.pos = pos;
+    }
+
+    @Override
+    public byte readByte() {
+      return bytes[pos--];
+    }
+
+    @Override
+    public void readBytes(byte[] b, int offset, int len) {
+      for(int i=0;i<len;i++) {
+        b[offset+i] = bytes[pos--];
+      }
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/FSTEnum.java b/lucene/src/java/org/apache/lucene/util/fst/FSTEnum.java
new file mode 100644
index 0000000..8fbd4ea
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/FSTEnum.java
@@ -0,0 +1,479 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.RamUsageEstimator;
+
+import java.io.IOException;
+
+/** Can next() and advance() through the terms in an FST
+ *
+  * @lucene.experimental
+*/
+
+abstract class FSTEnum<T> {
+  protected final FST<T> fst;
+
+  @SuppressWarnings("unchecked") protected FST.Arc<T>[] arcs = new FST.Arc[10];
+  // outputs are cumulative
+  @SuppressWarnings("unchecked") protected T[] output = (T[]) new Object[10];
+
+  protected final T NO_OUTPUT;
+  protected final FST.Arc<T> scratchArc = new FST.Arc<T>();
+
+  protected int upto;
+  protected int targetLength;
+
+  /** doFloor controls the behavior of advance: if it's true
+   *  doFloor is true, advance positions to the biggest
+   *  term before target.  */
+  protected FSTEnum(FST<T> fst) {
+    this.fst = fst;
+    NO_OUTPUT = fst.outputs.getNoOutput();
+    fst.getFirstArc(getArc(0));
+    output[0] = NO_OUTPUT;
+  }
+
+  protected abstract int getTargetLabel();
+  protected abstract int getCurrentLabel();
+
+  protected abstract void setCurrentLabel(int label);
+  protected abstract void grow();
+
+  /** Rewinds enum state to match the shared prefix between
+   *  current term and target term */
+  protected final void rewindPrefix() throws IOException {
+    if (upto == 0) {
+      //System.out.println("  init");
+      upto = 1;
+      fst.readFirstTargetArc(getArc(0), getArc(1));
+      return;
+    }
+    //System.out.println("  rewind upto=" + upto + " vs targetLength=" + targetLength);
+
+    final int currentLimit = upto;
+    upto = 1;
+    while (upto < currentLimit && upto <= targetLength+1) {
+      final int cmp = getCurrentLabel() - getTargetLabel();
+      if (cmp < 0) {
+        // seek forward
+        break;
+      } else if (cmp > 0) {
+        // seek backwards -- reset this arc to the first arc
+        final FST.Arc<T> arc = getArc(upto);
+        fst.readFirstTargetArc(getArc(upto-1), arc);
+        //System.out.println("    seek first arc");
+        break;
+      }
+      upto++;
+    }
+  }
+
+  protected void doNext() throws IOException {
+    //System.out.println("FE: next upto=" + upto);
+    if (upto == 0) {
+      //System.out.println("  init");
+      upto = 1;
+      fst.readFirstTargetArc(getArc(0), getArc(1));
+    } else {
+      // pop
+      //System.out.println("  check pop curArc target=" + arcs[upto].target + " label=" + arcs[upto].label + " isLast?=" + arcs[upto].isLast());
+      while (arcs[upto].isLast()) {
+        upto--;
+        if (upto == 0) {
+          //System.out.println("  eof");
+          return;
+        }
+      }
+      fst.readNextArc(arcs[upto]);
+    }
+
+    pushFirst();
+  }
+
+  // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
+  // SEEK_END)?  saves the eq check above?
+
+  /** Seeks to smallest term that's >= target. */
+  protected void doSeekCeil() throws IOException {
+
+    //System.out.println("    advance len=" + target.length + " curlen=" + current.length);
+
+    // TODO: possibly caller could/should provide common
+    // prefix length?  ie this work may be redundant if
+    // caller is in fact intersecting against its own
+    // automaton
+
+    //System.out.println("FE.seekCeil upto=" + upto);
+
+    // Save time by starting at the end of the shared prefix
+    // b/w our current term & the target:
+    rewindPrefix();
+    //System.out.println("  after rewind upto=" + upto);
+
+    FST.Arc<T> arc = getArc(upto);
+    int targetLabel = getTargetLabel();
+    //System.out.println("  init targetLabel=" + targetLabel);
+
+    // Now scan forward, matching the new suffix of the target
+    while(true) {
+
+      //System.out.println("  cycle upto=" + upto + " arc.label=" + arc.label + " (" + (char) arc.label + ") vs targetLabel=" + targetLabel);
+
+      if (arc.bytesPerArc != 0 && arc.label != -1) {
+
+        // Arcs are fixed array -- use binary search to find
+        // the target.
+
+        final FST<T>.BytesReader in = fst.getBytesReader(0);
+        int low = arc.arcIdx;
+        int high = arc.numArcs-1;
+        int mid = 0;
+        //System.out.println("do arc array low=" + low + " high=" + high + " targetLabel=" + targetLabel);
+        boolean found = false;
+        while (low <= high) {
+          mid = (low + high) >>> 1;
+          in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
+          final int midLabel = fst.readLabel(in);
+          final int cmp = midLabel - targetLabel;
+          //System.out.println("  cycle low=" + low + " high=" + high + " mid=" + mid + " midLabel=" + midLabel + " cmp=" + cmp);
+          if (cmp < 0)
+            low = mid + 1;
+          else if (cmp > 0)
+            high = mid - 1;
+          else {
+            found = true;
+            break;
+          }
+        }
+
+        // NOTE: this code is dup'd w/ the code below (in
+        // the outer else clause):
+        if (found) {
+          // Match
+          arc.arcIdx = mid-1;
+          fst.readNextRealArc(arc);
+          assert arc.arcIdx == mid;
+          assert arc.label == targetLabel: "arc.label=" + arc.label + " vs targetLabel=" + targetLabel + " mid=" + mid;
+          output[upto] = fst.outputs.add(output[upto-1], arc.output);
+          if (targetLabel == FST.END_LABEL) {
+            return;
+          }
+          setCurrentLabel(arc.label);
+          incr();
+          arc = fst.readFirstTargetArc(arc, getArc(upto));
+          targetLabel = getTargetLabel();
+          continue;
+        } else if (low == arc.numArcs) {
+          // Dead end
+          arc.arcIdx = arc.numArcs-2;
+          fst.readNextRealArc(arc);
+          assert arc.isLast();
+          // Dead end (target is after the last arc);
+          // rollback to last fork then push
+          upto--;
+          while(true) {
+            if (upto == 0) {
+              return;
+            }
+            final FST.Arc<T> prevArc = getArc(upto);
+            //System.out.println("  rollback upto=" + upto + " arc.label=" + prevArc.label + " isLast?=" + prevArc.isLast());
+            if (!prevArc.isLast()) {
+              fst.readNextArc(prevArc);
+              pushFirst();
+              return;
+            }
+            upto--;
+          }
+        } else {
+          arc.arcIdx = (low > high ? low : high)-1;
+          fst.readNextRealArc(arc);
+          assert arc.label > targetLabel;
+          pushFirst();
+          return;
+        }
+      } else {
+        // Arcs are not array'd -- must do linear scan:
+        if (arc.label == targetLabel) {
+          // recurse
+          output[upto] = fst.outputs.add(output[upto-1], arc.output);
+          if (targetLabel == FST.END_LABEL) {
+            return;
+          }
+          setCurrentLabel(arc.label);
+          incr();
+          arc = fst.readFirstTargetArc(arc, getArc(upto));
+          targetLabel = getTargetLabel();
+        } else if (arc.label > targetLabel) {
+          pushFirst();
+          return;
+        } else if (arc.isLast()) {
+          // Dead end (target is after the last arc);
+          // rollback to last fork then push
+          upto--;
+          while(true) {
+            if (upto == 0) {
+              return;
+            }
+            final FST.Arc<T> prevArc = getArc(upto);
+            //System.out.println("  rollback upto=" + upto + " arc.label=" + prevArc.label + " isLast?=" + prevArc.isLast());
+            if (!prevArc.isLast()) {
+              fst.readNextArc(prevArc);
+              pushFirst();
+              return;
+            }
+            upto--;
+          }
+        } else {
+          // keep scanning
+          //System.out.println("    next scan");
+          fst.readNextArc(arc);
+        }
+      }
+    }
+  }
+
+  // TODO: should we return a status here (SEEK_FOUND / SEEK_NOT_FOUND /
+  // SEEK_END)?  saves the eq check above?
+  /** Seeks to largest term that's <= target. */
+  protected void doSeekFloor() throws IOException {
+
+    // TODO: possibly caller could/should provide common
+    // prefix length?  ie this work may be redundant if
+    // caller is in fact intersecting against its own
+    // automaton
+    //System.out.println("FE: seek floor upto=" + upto);
+
+    // Save CPU by starting at the end of the shared prefix
+    // b/w our current term & the target:
+    rewindPrefix();
+
+    //System.out.println("FE: after rewind upto=" + upto);
+
+    FST.Arc<T> arc = getArc(upto);
+    int targetLabel = getTargetLabel();
+
+    //System.out.println("FE: init targetLabel=" + targetLabel);
+
+    // Now scan forward, matching the new suffix of the target
+    while(true) {
+      //System.out.println("  cycle upto=" + upto + " arc.label=" + arc.label + " (" + (char) arc.label + ") targetLabel=" + targetLabel + " isLast?=" + arc.isLast());
+
+      if (arc.bytesPerArc != 0 && arc.label != FST.END_LABEL) {
+        // Arcs are fixed array -- use binary search to find
+        // the target.
+
+        final FST<T>.BytesReader in = fst.getBytesReader(0);
+        int low = arc.arcIdx;
+        int high = arc.numArcs-1;
+        int mid = 0;
+        //System.out.println("do arc array low=" + low + " high=" + high + " targetLabel=" + targetLabel);
+        boolean found = false;
+        while (low <= high) {
+          mid = (low + high) >>> 1;
+          in.pos = arc.posArcsStart - arc.bytesPerArc*mid - 1;
+          final int midLabel = fst.readLabel(in);
+          final int cmp = midLabel - targetLabel;
+          //System.out.println("  cycle low=" + low + " high=" + high + " mid=" + mid + " midLabel=" + midLabel + " cmp=" + cmp);
+          if (cmp < 0)
+            low = mid + 1;
+          else if (cmp > 0)
+            high = mid - 1;
+          else {
+            found = true;
+            break;
+          }
+        }
+
+        // NOTE: this code is dup'd w/ the code below (in
+        // the outer else clause):
+        if (found) {
+          // Match -- recurse
+          //System.out.println("  match!  arcIdx=" + mid);
+          arc.arcIdx = mid-1;
+          fst.readNextRealArc(arc);
+          assert arc.arcIdx == mid;
+          assert arc.label == targetLabel: "arc.label=" + arc.label + " vs targetLabel=" + targetLabel + " mid=" + mid;
+          output[upto] = fst.outputs.add(output[upto-1], arc.output);
+          if (targetLabel == FST.END_LABEL) {
+            return;
+          }
+          setCurrentLabel(arc.label);
+          incr();
+          arc = fst.readFirstTargetArc(arc, getArc(upto));
+          targetLabel = getTargetLabel();
+          continue;
+        } else if (high == -1) {
+          //System.out.println("  before first");
+          // Very first arc is after our target
+          // TODO: if each arc could somehow read the arc just
+          // before, we can save this re-scan.  The ceil case
+          // doesn't need this because it reads the next arc
+          // instead:
+          while(true) {
+            // First, walk backwards until we find a first arc
+            // that's before our target label:
+            fst.readFirstTargetArc(getArc(upto-1), arc);
+            if (arc.label < targetLabel) {
+              // Then, scan forwards to the arc just before
+              // the targetLabel:
+              while(!arc.isLast() && fst.readNextArcLabel(arc) < targetLabel) {
+                fst.readNextArc(arc);
+              }
+              pushLast();
+              return;
+            }
+            upto--;
+            if (upto == 0) {
+              return;
+            }
+            targetLabel = getTargetLabel();
+            arc = getArc(upto);
+          }
+        } else {
+          // There is a floor arc:
+          arc.arcIdx = (low > high ? high : low)-1;
+          //System.out.println(" hasFloor arcIdx=" + (arc.arcIdx+1));
+          fst.readNextRealArc(arc);
+          assert arc.isLast() || fst.readNextArcLabel(arc) > targetLabel;
+          assert arc.label < targetLabel;
+          pushLast();
+          return;
+        }        
+      } else {
+
+        if (arc.label == targetLabel) {
+          // Match -- recurse
+          output[upto] = fst.outputs.add(output[upto-1], arc.output);
+          if (targetLabel == FST.END_LABEL) {
+            return;
+          }
+          setCurrentLabel(arc.label);
+          incr();
+          arc = fst.readFirstTargetArc(arc, getArc(upto));
+          targetLabel = getTargetLabel();
+        } else if (arc.label > targetLabel) {
+          // TODO: if each arc could somehow read the arc just
+          // before, we can save this re-scan.  The ceil case
+          // doesn't need this because it reads the next arc
+          // instead:
+          while(true) {
+            // First, walk backwards until we find a first arc
+            // that's before our target label:
+            fst.readFirstTargetArc(getArc(upto-1), arc);
+            if (arc.label < targetLabel) {
+              // Then, scan forwards to the arc just before
+              // the targetLabel:
+              while(!arc.isLast() && fst.readNextArcLabel(arc) < targetLabel) {
+                fst.readNextArc(arc);
+              }
+              pushLast();
+              return;
+            }
+            upto--;
+            if (upto == 0) {
+              return;
+            }
+            targetLabel = getTargetLabel();
+            arc = getArc(upto);
+          }
+        } else if (!arc.isLast()) {
+          //System.out.println("  check next label=" + fst.readNextArcLabel(arc) + " (" + (char) fst.readNextArcLabel(arc) + ")");
+          if (fst.readNextArcLabel(arc) > targetLabel) {
+            pushLast();
+            return;
+          } else {
+            // keep scanning
+            fst.readNextArc(arc);
+          }
+        } else {
+          pushLast();
+          return;
+        }
+      }
+    }
+  }
+
+  private void incr() {
+    upto++;
+    grow();
+    if (arcs.length <= upto) {
+      @SuppressWarnings("unchecked") final FST.Arc<T>[] newArcs =
+        new FST.Arc[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
+      System.arraycopy(arcs, 0, newArcs, 0, arcs.length);
+      arcs = newArcs;
+    }
+    if (output.length <= upto) {
+      @SuppressWarnings("unchecked") final T[] newOutput =
+        (T[]) new Object[ArrayUtil.oversize(1+upto, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
+      System.arraycopy(output, 0, newOutput, 0, output.length);
+      output = newOutput;
+    }
+  }
+
+  // Appends current arc, and then recurses from its target,
+  // appending first arc all the way to the final node
+  private void pushFirst() throws IOException {
+
+    FST.Arc<T> arc = arcs[upto];
+    assert arc != null;
+
+    while (true) {
+      output[upto] = fst.outputs.add(output[upto-1], arc.output);
+      if (arc.label == FST.END_LABEL) {
+        // Final node
+        break;
+      }
+      //System.out.println("  pushFirst label=" + (char) arc.label + " upto=" + upto + " output=" + fst.outputs.outputToString(output[upto]));
+      setCurrentLabel(arc.label);
+      incr();
+      
+      final FST.Arc<T> nextArc = getArc(upto);
+      fst.readFirstTargetArc(arc, nextArc);
+      arc = nextArc;
+    }
+  }
+
+  // Recurses from current arc, appending last arc all the
+  // way to the first final node
+  private void pushLast() throws IOException {
+
+    FST.Arc<T> arc = arcs[upto];
+    assert arc != null;
+
+    while (true) {
+      setCurrentLabel(arc.label);
+      output[upto] = fst.outputs.add(output[upto-1], arc.output);
+      if (arc.label == FST.END_LABEL) {
+        // Final node
+        break;
+      }
+      incr();
+
+      arc = fst.readLastTargetArc(arc, getArc(upto));
+    }
+  }
+
+  private FST.Arc<T> getArc(int idx) {
+    if (arcs[idx] == null) {
+      arcs[idx] = new FST.Arc<T>();
+    }
+    return arcs[idx];
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java
new file mode 100644
index 0000000..8f3ad73
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/IntSequenceOutputs.java
@@ -0,0 +1,142 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.util.IntsRef;
+
+/**
+ * Output is a sequence of ints, for each input term.
+ *
+ * @lucene.experimental
+ */
+
+public final class IntSequenceOutputs extends Outputs<IntsRef> {
+
+  private final static IntsRef NO_OUTPUT = new IntsRef();
+
+  private IntSequenceOutputs() {
+  }
+
+  public static IntSequenceOutputs getSingleton() {
+    return new IntSequenceOutputs();
+  }
+
+  @Override
+  public IntsRef common(IntsRef output1, IntsRef output2) {
+    assert output1 != null;
+    assert output2 != null;
+
+    int pos1 = output1.offset;
+    int pos2 = output2.offset;
+    int stopAt1 = pos1 + Math.min(output1.length, output2.length);
+    while(pos1 < stopAt1) {
+      if (output1.ints[pos1] != output2.ints[pos2]) {
+        break;
+      }
+      pos1++;
+      pos2++;
+    }
+
+    if (pos1 == output1.offset) {
+      // no common prefix
+      return NO_OUTPUT;
+    } else if (pos1 == output1.offset + output1.length) {
+      // output1 is a prefix of output2
+      return output1;
+    } else if (pos2 == output2.offset + output2.length) {
+      // output2 is a prefix of output1
+      return output2;
+    } else {
+      return new IntsRef(output1.ints, output1.offset, pos1-output1.offset);
+    }
+  }
+
+  @Override
+  public IntsRef subtract(IntsRef output, IntsRef inc) {
+    assert output != null;
+    assert inc != null;
+    if (inc == NO_OUTPUT) {
+      // no prefix removed
+      return output;
+    } else if (inc.length == output.length) {
+      // entire output removed
+      return NO_OUTPUT;
+    } else {
+      assert inc.length < output.length: "inc.length=" + inc.length + " vs output.length=" + output.length;
+      assert inc.length > 0;
+      return new IntsRef(output.ints, output.offset + inc.length, output.length-inc.length);
+    }
+  }
+
+  @Override
+  public IntsRef add(IntsRef prefix, IntsRef output) {
+    assert prefix != null;
+    assert output != null;
+    if (prefix == NO_OUTPUT) {
+      return output;
+    } else if (output == NO_OUTPUT) {
+      return prefix;
+    } else {
+      assert prefix.length > 0;
+      assert output.length > 0;
+      IntsRef result = new IntsRef(prefix.length + output.length);
+      System.arraycopy(prefix.ints, prefix.offset, result.ints, 0, prefix.length);
+      System.arraycopy(output.ints, output.offset, result.ints, prefix.length, output.length);
+      result.length = prefix.length + output.length;
+      return result;
+    }
+  }
+
+  @Override
+  public void write(IntsRef prefix, DataOutput out) throws IOException {
+    assert prefix != null;
+    out.writeVInt(prefix.length);
+    for(int idx=0;idx<prefix.length;idx++) {
+      out.writeVInt(prefix.ints[prefix.offset+idx]);
+    }
+  }
+
+  @Override
+  public IntsRef read(DataInput in) throws IOException {
+    final int len = in.readVInt();
+    if (len == 0) {
+      return NO_OUTPUT;
+    } else {
+      final IntsRef output = new IntsRef(len);
+      for(int idx=0;idx<len;idx++) {
+        output.ints[idx] = in.readVInt();
+      }
+      output.length = len;
+      return output;
+    }
+  }
+
+  @Override
+  public IntsRef getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(IntsRef output) {
+    return output.toString();
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java b/lucene/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java
new file mode 100644
index 0000000..cdd79c3
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/IntsRefFSTEnum.java
@@ -0,0 +1,108 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.IntsRef;
+
+import java.io.IOException;
+
+/** Can next() and advance() through the terms in an FST
+ *
+  * @lucene.experimental
+*/
+
+public final class IntsRefFSTEnum<T> extends FSTEnum<T> {
+  private final IntsRef current = new IntsRef(10);
+  private final InputOutput<T> result = new InputOutput<T>();
+  private IntsRef target;
+
+  public static class InputOutput<T> {
+    public IntsRef input;
+    public T output;
+  }
+
+  /** doFloor controls the behavior of advance: if it's true
+   *  doFloor is true, advance positions to the biggest
+   *  term before target.  */
+  public IntsRefFSTEnum(FST<T> fst) {
+    super(fst);
+    result.input = current;
+    current.offset = 1;
+  }
+
+  public InputOutput<T> current() {
+    return result;
+  }
+
+  public InputOutput<T> next() throws IOException {
+    //System.out.println("  enum.next");
+    doNext();
+    return setResult();
+  }
+
+  /** Seeks to smallest term that's >= target. */
+  public InputOutput<T> seekCeil(IntsRef target) throws IOException {
+    this.target = target;
+    targetLength = target.length;
+    super.doSeekCeil();
+    return setResult();
+  }
+
+  /** Seeks to biggest term that's <= target. */
+  public InputOutput<T> seekFloor(IntsRef target) throws IOException {
+    this.target = target;
+    targetLength = target.length;
+    super.doSeekFloor();
+    return setResult();
+  }
+
+  @Override
+  protected int getTargetLabel() {
+    if (upto-1 == target.length) {
+      return FST.END_LABEL;
+    } else {
+      return target.ints[target.offset + upto - 1];
+    }
+  }
+
+  @Override
+  protected int getCurrentLabel() {
+    // current.offset fixed at 1
+    return current.ints[upto];
+  }
+
+  @Override
+  protected void setCurrentLabel(int label) {
+    current.ints[upto] = label;
+  }
+
+  @Override
+  protected void grow() {
+    current.grow(upto+1);
+  }
+
+  private InputOutput<T> setResult() {
+    if (upto == 0) {
+      return null;
+    } else {
+      current.length = upto-1;
+      result.output = output[upto];
+      return result;
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/NoOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/NoOutputs.java
new file mode 100644
index 0000000..40404a3
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/NoOutputs.java
@@ -0,0 +1,96 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Use this if you just want to build an FSA.
+ *
+ * @lucene.experimental
+ */
+
+public final class NoOutputs extends Outputs<Object> {
+
+  final Object NO_OUTPUT = new Object() {
+    // NodeHash calls hashCode for this output; we fix this
+    // so we get deterministic hashing.
+    @Override
+    public int hashCode() {
+      return 42;
+    }
+
+    @Override
+    public boolean equals(Object other) {
+      return other == this;
+    }
+  };
+
+  private static final NoOutputs singleton = new NoOutputs();
+
+  private NoOutputs() {
+  }
+
+  public static NoOutputs getSingleton() {
+    return singleton;
+  }
+
+  @Override
+  public Object common(Object output1, Object output2) {
+    assert output1 == NO_OUTPUT;
+    assert output2 == NO_OUTPUT;
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public Object subtract(Object output, Object inc) {
+    assert output == NO_OUTPUT;
+    assert inc == NO_OUTPUT;
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public Object add(Object prefix, Object output) {
+    assert prefix == NO_OUTPUT: "got " + prefix;
+    assert output == NO_OUTPUT;
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public void write(Object prefix, DataOutput out) {
+    //assert false;
+  }
+
+  @Override
+  public Object read(DataInput in) {
+    //assert false;
+    //return null;
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public Object getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(Object output) {
+    return "";
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/NodeHash.java b/lucene/src/java/org/apache/lucene/util/fst/NodeHash.java
new file mode 100644
index 0000000..a10376e
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/NodeHash.java
@@ -0,0 +1,165 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+// Used to dedup states (lookup already-frozen states)
+final class NodeHash<T> {
+
+  private int[] table;
+  private int count;
+  private int mask;
+  private final FST<T> fst;
+  private final FST.Arc<T> scratchArc = new FST.Arc<T>();
+
+  public NodeHash(FST<T> fst) {
+    table = new int[16];
+    mask = 15;
+    this.fst = fst;
+  }
+
+  private boolean nodesEqual(Builder.UnCompiledNode<T> node, int address) throws IOException {
+    fst.readFirstRealArc(address, scratchArc);
+    if (scratchArc.bytesPerArc != 0 && node.numArcs != scratchArc.numArcs) {
+      return false;
+    }
+    for(int arcUpto=0;arcUpto<node.numArcs;arcUpto++) {
+      final Builder.Arc<T> arc = node.arcs[arcUpto];
+      if (arc.label != scratchArc.label ||
+          !arc.output.equals(scratchArc.output) ||
+          ((Builder.CompiledNode) arc.target).address != scratchArc.target ||
+          !arc.nextFinalOutput.equals(scratchArc.nextFinalOutput) ||
+          arc.isFinal != scratchArc.isFinal()) {
+        return false;
+      }
+
+      if (scratchArc.isLast()) {
+        if (arcUpto == node.numArcs-1) {
+          return true;
+        } else {
+          return false;
+        }
+      }
+      fst.readNextRealArc(scratchArc);
+    }
+
+    return false;
+  }
+
+  // hash code for an unfrozen node.  This must be identical
+  // to the un-frozen case (below)!!
+  private int hash(Builder.UnCompiledNode<T> node) {
+    final int PRIME = 31;
+    //System.out.println("hash unfrozen");
+    int h = 0;
+    // TODO: maybe if number of arcs is high we can safely subsample?
+    for(int arcIdx=0;arcIdx<node.numArcs;arcIdx++) {
+      final Builder.Arc<T> arc = node.arcs[arcIdx];
+      //System.out.println("  label=" + arc.label + " target=" + ((Builder.CompiledNode) arc.target).address + " h=" + h + " output=" + fst.outputs.outputToString(arc.output) + " isFinal?=" + arc.isFinal);
+      h = PRIME * h + arc.label;
+      h = PRIME * h + ((Builder.CompiledNode) arc.target).address;
+      h = PRIME * h + arc.output.hashCode();
+      h = PRIME * h + arc.nextFinalOutput.hashCode();
+      if (arc.isFinal) {
+        h += 17;
+      }
+    }
+    //System.out.println("  ret " + (h&Integer.MAX_VALUE));
+    return h & Integer.MAX_VALUE;
+  }
+
+  // hash code for a frozen node
+  private int hash(int node) throws IOException {
+    final int PRIME = 31;
+    //System.out.println("hash frozen");
+    int h = 0;
+    fst.readFirstRealArc(node, scratchArc);
+    while(true) {
+      //System.out.println("  label=" + scratchArc.label + " target=" + scratchArc.target + " h=" + h + " output=" + fst.outputs.outputToString(scratchArc.output) + " next?=" + scratchArc.flag(4) + " final?=" + scratchArc.isFinal());
+      h = PRIME * h + scratchArc.label;
+      h = PRIME * h + scratchArc.target;
+      h = PRIME * h + scratchArc.output.hashCode();
+      h = PRIME * h + scratchArc.nextFinalOutput.hashCode();
+      if (scratchArc.isFinal()) {
+        h += 17;
+      }
+      if (scratchArc.isLast()) {
+        break;
+      }
+      fst.readNextRealArc(scratchArc);
+    }
+    //System.out.println("  ret " + (h&Integer.MAX_VALUE));
+    return h & Integer.MAX_VALUE;
+  }
+
+  public int add(Builder.UnCompiledNode<T> node) throws IOException {
+    // System.out.println("hash: add count=" + count + " vs " + table.length);
+    final int h = hash(node);
+    int pos = h & mask;
+    int c = 0;
+    while(true) {
+      final int v = table[pos];
+      if (v == 0) {
+        // freeze & add
+        final int address = fst.addNode(node);
+        //System.out.println("  now freeze addr=" + address);
+        assert hash(address) == h : "frozenHash=" + hash(address) + " vs h=" + h;
+        count++;
+        table[pos] = address;
+        if (table.length < 2*count) {
+          rehash();
+        }
+        return address;
+      } else if (nodesEqual(node, v)) {
+        // same node is already here
+        return v;
+      }
+
+      // quadratic probe
+      pos = (pos + (++c)) & mask;
+    }
+  }
+
+  // called only by rehash
+  private void addNew(int address) throws IOException {
+    int pos = hash(address) & mask;
+    int c = 0;
+    while(true) {
+      if (table[pos] == 0) {
+        table[pos] = address;
+        break;
+      }
+
+      // quadratic probe
+      pos = (pos + (++c)) & mask;
+    }
+  }
+
+  private void rehash() throws IOException {
+    final int[] oldTable = table;
+    table = new int[2*table.length];
+    mask = table.length-1;
+    for(int idx=0;idx<oldTable.length;idx++) {
+      final int address = oldTable[idx];
+      if (address != 0) {
+        addNew(address);
+      }
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/Outputs.java b/lucene/src/java/org/apache/lucene/util/fst/Outputs.java
new file mode 100644
index 0000000..e0cabaf
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/Outputs.java
@@ -0,0 +1,62 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Represents the outputs for an FST, providing the basic
+ * algebra needed for the FST.
+ *
+ * @lucene.experimental
+ */
+
+public abstract class Outputs<T> {
+
+  // TODO: maybe change this API to allow for re-use of the
+  // output instances -- this is an insane amount of garbage
+  // (new object per byte/char/int) if eg used during
+  // analysis
+
+  /** Eg common("foo", "foobar") -> "foo" */
+  public abstract T common(T output1, T output2);
+
+  /** Eg subtract("foobar", "foo") -> "bar" */
+  public abstract T subtract(T output, T inc);
+
+  /** Eg add("foo", "bar") -> "foobar" */
+  public abstract T add(T prefix, T output);
+
+  public abstract void write(T output, DataOutput out) throws IOException;
+
+  public abstract T read(DataInput in) throws IOException;
+
+  /** NOTE: this output is compared with == so you must
+   *  ensure that all methods return the single object if
+   *  it's really no output */
+  public abstract T getNoOutput();
+
+  public abstract String outputToString(T output);
+
+  public T merge(T first, T second) {
+    throw new UnsupportedOperationException();
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/PairOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/PairOutputs.java
new file mode 100644
index 0000000..4cfd7f6
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/PairOutputs.java
@@ -0,0 +1,118 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Pairs up two outputs into one.
+ *
+ * @lucene.experimental
+ */
+
+public class PairOutputs<A,B> extends Outputs<PairOutputs.Pair<A,B>> {
+
+  private final Pair<A,B> NO_OUTPUT;
+  private final Outputs<A> outputs1;
+  private final Outputs<B> outputs2;
+
+  public static class Pair<A,B> {
+    public final A output1;
+    public final B output2;
+
+    public Pair(A output1, B output2) {
+      this.output1 = output1;
+      this.output2 = output2;
+    }
+
+    @Override @SuppressWarnings("rawtypes")
+    public boolean equals(Object other) {
+      if (other == this) {
+        return true;
+      } else if (other instanceof Pair) {
+        Pair pair = (Pair) other;
+        return output1.equals(pair.output1) && output2.equals(pair.output2);
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public int hashCode() {
+      return output1.hashCode() + output2.hashCode();
+    }
+  };
+
+  public PairOutputs(Outputs<A> outputs1, Outputs<B> outputs2) {
+    this.outputs1 = outputs1;
+    this.outputs2 = outputs2;
+    NO_OUTPUT = new Pair<A,B>(outputs1.getNoOutput(), outputs2.getNoOutput());
+  }
+  
+  public Pair<A,B> get(A output1, B output2) {
+    if (output1 == outputs1.getNoOutput() && output2 == outputs2.getNoOutput()) {
+      return NO_OUTPUT;
+    } else {
+      return new Pair<A,B>(output1, output2);
+    }
+  }
+ 
+  @Override
+  public Pair<A,B> common(Pair<A,B> pair1, Pair<A,B> pair2) {
+    return get(outputs1.common(pair1.output1, pair2.output1),
+               outputs2.common(pair1.output2, pair2.output2));
+  }
+
+  @Override
+  public Pair<A,B> subtract(Pair<A,B> output, Pair<A,B> inc) {
+    return get(outputs1.subtract(output.output1, inc.output1),
+               outputs2.subtract(output.output2, inc.output2));
+  }
+
+  @Override
+  public Pair<A,B> add(Pair<A,B> prefix, Pair<A,B> output) {
+    return get(outputs1.add(prefix.output1, output.output1),
+               outputs2.add(prefix.output2, output.output2));
+  }
+
+  @Override
+  public void write(Pair<A,B> output, DataOutput writer) throws IOException {
+    outputs1.write(output.output1, writer);
+    outputs2.write(output.output2, writer);
+  }
+
+  @Override
+  public Pair<A,B> read(DataInput in) throws IOException {
+    A output1 = outputs1.read(in);
+    B output2 = outputs2.read(in);
+    return get(output1, output2);
+  }
+
+  @Override
+  public Pair<A,B> getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(Pair<A,B> output) {
+    return "<pair:" + outputs1.outputToString(output.output1) + "," + outputs2.outputToString(output.output2) + ">";
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/PositiveIntOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/PositiveIntOutputs.java
new file mode 100644
index 0000000..616ecb5
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/PositiveIntOutputs.java
@@ -0,0 +1,136 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Output is a long, for each input term.  NOTE: the
+ * resulting FST is not guaranteed to be minimal!  See
+ * {@link Builder}.  You cannot store 0 output with this
+ * (that's reserved to mean "no output")!
+ *
+ * @lucene.experimental
+ */
+
+public final class PositiveIntOutputs extends Outputs<Long> {
+  
+  private final static Long NO_OUTPUT = new Long(0);
+
+  private final boolean doShare;
+
+  private final static PositiveIntOutputs singletonShare = new PositiveIntOutputs(true);
+  private final static PositiveIntOutputs singletonNoShare = new PositiveIntOutputs(false);
+
+  private PositiveIntOutputs(boolean doShare) {
+    this.doShare = doShare;
+  }
+
+  public static PositiveIntOutputs getSingleton(boolean doShare) {
+    return doShare ? singletonShare : singletonNoShare;
+  }
+
+  public Long get(long v) {
+    if (v == 0) {
+      return NO_OUTPUT;
+    } else {
+      return Long.valueOf(v);
+    }
+  }
+
+  @Override
+  public Long common(Long output1, Long output2) {
+    assert valid(output1);
+    assert valid(output2);
+    if (output1 == NO_OUTPUT || output2 == NO_OUTPUT) {
+      return NO_OUTPUT;
+    } else if (doShare) {
+      assert output1 > 0;
+      assert output2 > 0;
+      return Math.min(output1, output2);
+    } else if (output1.equals(output2)) {
+      return output1;
+    } else {
+      return NO_OUTPUT;
+    }
+  }
+
+  @Override
+  public Long subtract(Long output, Long inc) {
+    assert valid(output);
+    assert valid(inc);
+    assert output >= inc;
+
+    if (inc == NO_OUTPUT) {
+      return output;
+    } else if (output.equals(inc)) {
+      return NO_OUTPUT;
+    } else {
+      return output - inc;
+    }
+  }
+
+  @Override
+  public Long add(Long prefix, Long output) {
+    assert valid(prefix);
+    assert valid(output);
+    if (prefix == NO_OUTPUT) {
+      return output;
+    } else if (output == NO_OUTPUT) {
+      return prefix;
+    } else {
+      return prefix + output;
+    }
+  }
+
+  @Override
+  public void write(Long output, DataOutput out) throws IOException {
+    assert valid(output);
+    out.writeVLong(output);
+  }
+
+  @Override
+  public Long read(DataInput in) throws IOException {
+    long v = in.readVLong();
+    if (v == 0) {
+      return NO_OUTPUT;
+    } else {
+      return v;
+    }
+  }
+
+  private boolean valid(Long o) {
+    assert o != null;
+    assert o instanceof Long;
+    assert o == NO_OUTPUT || o > 0;
+    return true;
+  }
+
+  @Override
+  public Long getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(Long output) {
+    return output.toString();
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/TODO b/lucene/src/java/org/apache/lucene/util/fst/TODO
new file mode 100644
index 0000000..98fc679
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/TODO
@@ -0,0 +1,39 @@
+is threadlocal.get costly?  if so maybe make an FSTReader?  would hold this "relative" pos, and each thread'd use it for reading, instead of PosRef
+
+maybe changed Outputs class to "reuse" stuff?  eg this new BytesRef in ByteSequenceOutputs..
+
+do i even "need" both non_final_end_state and final_end_state?
+
+hmm -- can I get weights working here?
+
+can FST be used to index all internal substrings, mapping to term?
+  - maybe put back ability to add multiple outputs per input...?
+
+make this work w/ char...?
+  - then FSTCharFilter/FSTTokenFilter
+  - syn filter?
+
+experiment: try reversing terms before compressing -- how much smaller?
+
+maybe seprate out a 'writable/growing fst' from a read-only one?
+
+can we somehow [partially] tableize lookups like oal.util.automaton?
+
+make an FST terms index option for codecs...?
+
+make an FSTCharsMap?
+
+need a benchmark testing FST traversal -- just fix the static main to rewind & visit all terms
+
+thread state
+
+when writing FST to disk:
+- Sequentially writing (would save memory in codec during indexing). We are now using DataOutput, which could also go directly to disk
+- problem: size of BytesRef must be known before
+
+later
+  - maybe don't require FSTEnum.advance to be forward only?
+  - should i make a posIntOutputs separate from posLongOutputs?
+  - mv randomAccpetedWord / run / etc. from test into FST?
+  - hmm get multi-outputs working again?  do we ever need this?
+
diff --git a/lucene/src/java/org/apache/lucene/util/fst/UpToTwoPositiveIntOutputs.java b/lucene/src/java/org/apache/lucene/util/fst/UpToTwoPositiveIntOutputs.java
new file mode 100644
index 0000000..1bae8f9
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/UpToTwoPositiveIntOutputs.java
@@ -0,0 +1,224 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.DataOutput;
+
+/**
+ * Holds one or two longs for each input term.  If it's a
+ * single output, Long is returned; else, TwoLongs.  Order
+ * is preseved in the TwoLongs case, ie .first is the first
+ * input/output added to Builder, and .second is the
+ * second.  You cannot store 0 output with this (that's
+ * reserved to mean "no output")!
+ *
+ * NOTE: the resulting FST is not guaranteed to be minimal!
+ * See {@link Builder}.
+ *
+ * @lucene.experimental
+ */
+
+public final class UpToTwoPositiveIntOutputs extends Outputs<Object> {
+
+  public final static class TwoLongs {
+    final long first;
+    final long second;
+
+    public TwoLongs(long first, long second) {
+      this.first = first;
+      this.second = second;
+      assert first >= 0;
+      assert second >= 0;
+    }
+
+    @Override
+    public String toString() {
+      return "TwoLongs:" + first + "," + second;
+    }
+
+    @Override
+    public boolean equals(Object _other) {
+      if (_other instanceof TwoLongs) {
+        final TwoLongs other = (TwoLongs) _other;
+        return first == other.first && second == other.second;
+      } else {
+        return false;
+      }
+    }
+
+    @Override
+    public int hashCode() {
+      return (int) ((first^(first>>>32)) ^ (second^(second>>32)));
+    }
+  }
+  
+  private final static Long NO_OUTPUT = new Long(0);
+
+  private final boolean doShare;
+
+  private final static UpToTwoPositiveIntOutputs singletonShare = new UpToTwoPositiveIntOutputs(true);
+  private final static UpToTwoPositiveIntOutputs singletonNoShare = new UpToTwoPositiveIntOutputs(false);
+
+  private UpToTwoPositiveIntOutputs(boolean doShare) {
+    this.doShare = doShare;
+  }
+
+  public static UpToTwoPositiveIntOutputs getSingleton(boolean doShare) {
+    return doShare ? singletonShare : singletonNoShare;
+  }
+
+  public Long get(long v) {
+    if (v == 0) {
+      return NO_OUTPUT;
+    } else {
+      return Long.valueOf(v);
+    }
+  }
+
+  public TwoLongs get(long first, long second) {
+    return new TwoLongs(first, second);
+  }
+
+  @Override
+  public Long common(Object _output1, Object _output2) {
+    assert valid(_output1, false);
+    assert valid(_output2, false);
+    final Long output1 = (Long) _output1;
+    final Long output2 = (Long) _output2;
+    if (output1 == NO_OUTPUT || output2 == NO_OUTPUT) {
+      return NO_OUTPUT;
+    } else if (doShare) {
+      assert output1 > 0;
+      assert output2 > 0;
+      return Math.min(output1, output2);
+    } else if (output1.equals(output2)) {
+      return output1;
+    } else {
+      return NO_OUTPUT;
+    }
+  }
+
+  @Override
+  public Long subtract(Object _output, Object _inc) {
+    assert valid(_output, false);
+    assert valid(_inc, false);
+    final Long output = (Long) _output;
+    final Long inc = (Long) _inc;
+    assert output >= inc;
+
+    if (inc == NO_OUTPUT) {
+      return output;
+    } else if (output.equals(inc)) {
+      return NO_OUTPUT;
+    } else {
+      return output - inc;
+    }
+  }
+
+  @Override
+  public Object add(Object _prefix, Object _output) {
+    assert valid(_prefix, false);
+    assert valid(_output, true);
+    final Long prefix = (Long) _prefix;
+    if (_output instanceof Long) {
+      final Long output = (Long) _output;
+      if (prefix == NO_OUTPUT) {
+        return output;
+      } else if (output == NO_OUTPUT) {
+        return prefix;
+      } else {
+        return prefix + output;
+      }
+    } else {
+      final TwoLongs output = (TwoLongs) _output;
+      final long v = prefix;
+      return new TwoLongs(output.first + v, output.second + v);
+    }
+  }
+
+  @Override
+  public void write(Object _output, DataOutput out) throws IOException {
+    assert valid(_output, true);
+    if (_output instanceof Long) {
+      final Long output = (Long) _output;
+      out.writeVLong(output<<1);
+    } else {
+      final TwoLongs output = (TwoLongs) _output;
+      out.writeVLong((output.first<<1) | 1);
+      out.writeVLong(output.second);
+    }
+  }
+
+  @Override
+  public Object read(DataInput in) throws IOException {
+    final long code = in.readVLong();
+    if ((code & 1) == 0) {
+      // single long
+      final long v = code >>> 1;
+      if (v == 0) {
+        return NO_OUTPUT;
+      } else {
+        return Long.valueOf(v);
+      }
+    } else {
+      // two longs
+      final long first = code >>> 1;
+      final long second = in.readVLong();
+      return new TwoLongs(first, second);
+    }
+  }
+
+  private boolean valid(Long o) {
+    assert o != null;
+    assert o instanceof Long;
+    assert o == NO_OUTPUT || o > 0;
+    return true;
+  }
+
+  // Used only by assert
+  private boolean valid(Object _o, boolean allowDouble) {
+    if (!allowDouble) {
+      assert _o instanceof Long;
+      return valid((Long) _o);
+    } else if (_o instanceof TwoLongs) {
+      return true;
+    } else {
+      return valid((Long) _o);
+    }
+  }
+
+  @Override
+  public Object getNoOutput() {
+    return NO_OUTPUT;
+  }
+
+  @Override
+  public String outputToString(Object output) {
+    return output.toString();
+  }
+
+  @Override
+  public Object merge(Object first, Object second) {
+    assert valid(first, false);
+    assert valid(second, false);
+    return new TwoLongs((Long) first, (Long) second);
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/Util.java b/lucene/src/java/org/apache/lucene/util/fst/Util.java
new file mode 100644
index 0000000..2101f89
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/Util.java
@@ -0,0 +1,328 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.*;
+import java.util.*;
+
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IntsRef;
+
+/** Static helper methods
+ *
+ * @lucene.experimental */
+public final class Util {
+  private Util() {
+  }
+
+  /** Looks up the output for this input, or null if the
+   *  input is not accepted. FST must be
+   *  INPUT_TYPE.BYTE4. */
+  public static<T> T get(FST<T> fst, IntsRef input) throws IOException {
+    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
+
+    // TODO: would be nice not to alloc this on every lookup
+    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+
+    // Accumulate output as we go
+    final T NO_OUTPUT = fst.outputs.getNoOutput();
+    T output = NO_OUTPUT;
+    for(int i=0;i<input.length;i++) {
+      if (fst.findTargetArc(input.ints[input.offset + i], arc, arc) == null) {
+        return null;
+      } else if (arc.output != NO_OUTPUT) {
+        output = fst.outputs.add(output, arc.output);
+      }
+    }
+
+    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
+      return null;
+    } else if (arc.output != NO_OUTPUT) {
+      return fst.outputs.add(output, arc.output);
+    } else {
+      return output;
+    }
+  }
+
+  /** Logically casts input to UTF32 ints then looks up the output
+   *  or null if the input is not accepted.  FST must be
+   *  INPUT_TYPE.BYTE4.  */
+  public static<T> T get(FST<T> fst, char[] input, int offset, int length) throws IOException {
+    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
+
+    // TODO: would be nice not to alloc this on every lookup
+    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+
+    int charIdx = offset;
+    final int charLimit = offset + length;
+
+    // Accumulate output as we go
+    final T NO_OUTPUT = fst.outputs.getNoOutput();
+    T output = NO_OUTPUT;
+    while(charIdx < charLimit) {
+      final int utf32 = Character.codePointAt(input, charIdx);
+      charIdx += Character.charCount(utf32);
+
+      if (fst.findTargetArc(utf32, arc, arc) == null) {
+        return null;
+      } else if (arc.output != NO_OUTPUT) {
+        output = fst.outputs.add(output, arc.output);
+      }
+    }
+
+    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
+      return null;
+    } else if (arc.output != NO_OUTPUT) {
+      return fst.outputs.add(output, arc.output);
+    } else {
+      return output;
+    }
+  }
+
+
+  /** Logically casts input to UTF32 ints then looks up the output
+   *  or null if the input is not accepted.  FST must be
+   *  INPUT_TYPE.BYTE4.  */
+  public static<T> T get(FST<T> fst, CharSequence input) throws IOException {
+    assert fst.inputType == FST.INPUT_TYPE.BYTE4;
+    
+    // TODO: would be nice not to alloc this on every lookup
+    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+
+    int charIdx = 0;
+    final int charLimit = input.length();
+
+    // Accumulate output as we go
+    final T NO_OUTPUT = fst.outputs.getNoOutput();
+    T output = NO_OUTPUT;
+
+    while(charIdx < charLimit) {
+      final int utf32 = Character.codePointAt(input, charIdx);
+      charIdx += Character.charCount(utf32);
+
+      if (fst.findTargetArc(utf32, arc, arc) == null) {
+        return null;
+      } else if (arc.output != NO_OUTPUT) {
+        output = fst.outputs.add(output, arc.output);
+      }
+    }
+
+    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
+      return null;
+    } else if (arc.output != NO_OUTPUT) {
+      return fst.outputs.add(output, arc.output);
+    } else {
+      return output;
+    }
+  }
+
+  /** Looks up the output for this input, or null if the
+   *  input is not accepted */
+  public static<T> T get(FST<T> fst, BytesRef input) throws IOException {
+    assert fst.inputType == FST.INPUT_TYPE.BYTE1;
+
+    // TODO: would be nice not to alloc this on every lookup
+    final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+
+    // Accumulate output as we go
+    final T NO_OUTPUT = fst.outputs.getNoOutput();
+    T output = NO_OUTPUT;
+    for(int i=0;i<input.length;i++) {
+      if (fst.findTargetArc(input.bytes[i+input.offset] & 0xFF, arc, arc) == null) {
+        return null;
+      } else if (arc.output != NO_OUTPUT) {
+        output = fst.outputs.add(output, arc.output);
+      }
+    }
+
+    if (fst.findTargetArc(FST.END_LABEL, arc, arc) == null) {
+      return null;
+    } else if (arc.output != NO_OUTPUT) {
+      return fst.outputs.add(output, arc.output);
+    } else {
+      return output;
+    }
+  }
+  
+  /**
+   * Dumps an {@link FST} to a GraphViz's <code>dot</code> language description
+   * for visualization. Example of use:
+   * 
+   * <pre>
+   * PrintStream ps = new PrintStream(&quot;out.dot&quot;);
+   * fst.toDot(ps);
+   * ps.close();
+   * </pre>
+   * 
+   * and then, from command line:
+   * 
+   * <pre>
+   * dot -Tpng -o out.png out.dot
+   * </pre>
+   * 
+   * <p>
+   * Note: larger FSTs (a few thousand nodes) won't even render, don't bother.
+   * 
+   * @param sameRank
+   *          If <code>true</code>, the resulting <code>dot</code> file will try
+   *          to order states in layers of breadth-first traversal. This may
+   *          mess up arcs, but makes the output FST's structure a bit clearer.
+   * 
+   * @param labelStates
+   *          If <code>true</code> states will have labels equal to their offsets in their
+   *          binary format. Expands the graph considerably. 
+   * 
+   * @see "http://www.graphviz.org/"
+   */
+  public static <T> void toDot(FST<T> fst, Writer out, boolean sameRank, boolean labelStates) 
+    throws IOException {    
+    final String expandedNodeColor = "blue";
+
+    // This is the start arc in the automaton (from the epsilon state to the first state 
+    // with outgoing transitions.
+    final FST.Arc<T> startArc = fst.getFirstArc(new FST.Arc<T>());
+
+    // A queue of transitions to consider for the next level.
+    final List<FST.Arc<T>> thisLevelQueue = new ArrayList<FST.Arc<T>>();
+
+    // A queue of transitions to consider when processing the next level.
+    final List<FST.Arc<T>> nextLevelQueue = new ArrayList<FST.Arc<T>>();
+    nextLevelQueue.add(startArc);
+    
+    // A list of states on the same level (for ranking).
+    final List<Integer> sameLevelStates = new ArrayList<Integer>();
+
+    // A bitset of already seen states (target offset).
+    final BitSet seen = new BitSet();
+    seen.set(startArc.target);
+
+    // Shape for states.
+    final String stateShape = "circle";
+
+    // Emit DOT prologue.
+    out.write("digraph FST {\n");
+    out.write("  rankdir = LR; splines=true; concentrate=true; ordering=out; ranksep=2.5; \n");
+
+    if (!labelStates) {
+      out.write("  node [shape=circle, width=.2, height=.2, style=filled]\n");      
+    }
+
+    emitDotState(out, "initial", "point", "white", "");
+    emitDotState(out, Integer.toString(startArc.target), stateShape, 
+        fst.isExpandedTarget(startArc) ? expandedNodeColor : null, 
+        "");
+    out.write("  initial -> " + startArc.target + "\n");
+
+    final T NO_OUTPUT = fst.outputs.getNoOutput();
+    int level = 0;
+
+    while (!nextLevelQueue.isEmpty()) {
+      // we could double buffer here, but it doesn't matter probably.
+      thisLevelQueue.addAll(nextLevelQueue);
+      nextLevelQueue.clear();
+
+      level++;
+      out.write("\n  // Transitions and states at level: " + level + "\n");
+      while (!thisLevelQueue.isEmpty()) {
+        final FST.Arc<T> arc = thisLevelQueue.remove(thisLevelQueue.size() - 1);
+        
+        if (fst.targetHasArcs(arc)) {
+          // scan all arcs
+          final int node = arc.target;
+          fst.readFirstTargetArc(arc, arc);
+          
+          while (true) {
+            // Emit the unseen state and add it to the queue for the next level.
+            if (arc.target >= 0 && !seen.get(arc.target)) {
+              final boolean isExpanded = fst.isExpandedTarget(arc);
+              emitDotState(out, Integer.toString(arc.target), stateShape, 
+                  isExpanded ?  expandedNodeColor : null, 
+                  labelStates ? Integer.toString(arc.target) : ""); 
+              seen.set(arc.target);
+              nextLevelQueue.add(new FST.Arc<T>().copyFrom(arc));
+              sameLevelStates.add(arc.target);
+            }
+
+            String outs;
+            if (arc.output != NO_OUTPUT) {
+              outs = "/" + fst.outputs.outputToString(arc.output);
+            } else {
+              outs = "";
+            }
+
+            final String cl;
+            if (arc.label == FST.END_LABEL) {
+              cl = "~";
+            } else {
+              cl = printableLabel(arc.label);
+            }
+
+            out.write("  " + node + " -> " + arc.target + " [label=\"" + cl + outs + "\"]\n");
+            
+            // Break the loop if we're on the last arc of this state.
+            if (arc.isLast()) {
+              break;
+            }
+            fst.readNextArc(arc);
+          }
+        }
+      }
+
+      // Emit state ranking information.
+      if (sameRank && sameLevelStates.size() > 1) {
+        out.write("  {rank=same; ");
+        for (int state : sameLevelStates) {
+          out.write(state + "; ");
+        }
+        out.write(" }\n");
+      }
+      sameLevelStates.clear();                
+    }
+
+    // Emit terminating state (always there anyway).
+    out.write("  -1 [style=filled, color=black, shape=circle, label=\"\"]\n\n");
+    out.write("  {rank=sink; -1 }\n");
+    
+    out.write("}\n");
+    out.flush();
+  }
+
+  /**
+   * Emit a single state in the <code>dot</code> language. 
+   */
+  private static void emitDotState(Writer out, String name, String shape,
+      String color, String label) throws IOException {
+    out.write("  " + name 
+        + " [" 
+        + (shape != null ? "shape=" + shape : "") + " "
+        + (color != null ? "color=" + color : "") + " "
+        + (label != null ? "label=\"" + label + "\"" : "label=\"\"") + " "
+        + "]\n");
+  }
+
+  /**
+   * Ensures an arc's label is indeed printable (dot uses US-ASCII). 
+   */
+  private static String printableLabel(int label) {
+    if (label >= 0x20 && label <= 0x7d) {
+      return Character.toString((char) label);
+    } else {
+      return "0x" + Integer.toHexString(label);
+    }
+  }
+}
diff --git a/lucene/src/java/org/apache/lucene/util/fst/package.html b/lucene/src/java/org/apache/lucene/util/fst/package.html
new file mode 100644
index 0000000..c5be56e
--- /dev/null
+++ b/lucene/src/java/org/apache/lucene/util/fst/package.html
@@ -0,0 +1,25 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html>
+<head>
+   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
+</head>
+<body>
+Finite state transducers
+</body>
+</html>
diff --git a/lucene/src/test/org/apache/lucene/util/automaton/fst/TestFSTs.java b/lucene/src/test/org/apache/lucene/util/automaton/fst/TestFSTs.java
deleted file mode 100644
index 672faff..0000000
--- a/lucene/src/test/org/apache/lucene/util/automaton/fst/TestFSTs.java
+++ /dev/null
@@ -1,1535 +0,0 @@
-package org.apache.lucene.util.automaton.fst;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.OutputStreamWriter;
-import java.io.Writer;
-import java.util.*;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.codecs.CodecProvider;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.MockDirectoryWrapper;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.LineFileDocs;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
-import org.apache.lucene.util.automaton.fst.FST.Arc;
-
-public class TestFSTs extends LuceneTestCase {
-
-  private MockDirectoryWrapper dir;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    dir = newDirectory();
-    dir.setPreventDoubleWrite(false);
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    dir.close();
-    super.tearDown();
-  }
-
-  private static BytesRef toBytesRef(IntsRef ir) {
-    BytesRef br = new BytesRef(ir.length);
-    for(int i=0;i<ir.length;i++) {
-      int x = ir.ints[ir.offset+i];
-      assert x >= 0 && x <= 255;
-      br.bytes[i] = (byte) x;
-    }
-    br.length = ir.length;
-    return br;
-  }
-
-  private static IntsRef toIntsRef(String s, int inputMode) {
-    return toIntsRef(s, inputMode, new IntsRef(10));
-  }
-
-  private static IntsRef toIntsRef(String s, int inputMode, IntsRef ir) {
-    if (inputMode == 0) {
-      // utf8
-      return toIntsRef(new BytesRef(s), ir);
-    } else {
-      // utf32
-      return toIntsRefUTF32(s, ir);
-    }
-  }
-
-  private static IntsRef toIntsRefUTF32(String s, IntsRef ir) {
-    final int charLength = s.length();
-    int charIdx = 0;
-    int intIdx = 0;
-    while(charIdx < charLength) {
-      if (intIdx == ir.ints.length) {
-        ir.grow(intIdx+1);
-      }
-      final int utf32 = s.codePointAt(charIdx);
-      ir.ints[intIdx] = utf32;
-      charIdx += Character.charCount(utf32);
-      intIdx++;
-    }
-    ir.length = intIdx;
-    return ir;
-  }
-
-  private static IntsRef toIntsRef(BytesRef br, IntsRef ir) {
-    if (br.length > ir.ints.length) {
-      ir.grow(br.length);
-    }
-    for(int i=0;i<br.length;i++) {
-      ir.ints[i] = br.bytes[br.offset+i]&0xFF;
-    }
-    ir.length = br.length;
-    return ir;
-  }
-
-  public void testBasicFSA() throws IOException {
-    String[] strings = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation", "stat"};
-    String[] strings2 = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation"};
-    IntsRef[] terms = new IntsRef[strings.length];
-    IntsRef[] terms2 = new IntsRef[strings2.length];
-    for(int inputMode=0;inputMode<2;inputMode++) {
-      if (VERBOSE) {
-        System.out.println("TEST: inputMode=" + inputModeToString(inputMode));
-      }
-
-      for(int idx=0;idx<strings.length;idx++) {
-        terms[idx] = toIntsRef(strings[idx], inputMode);
-      }
-      for(int idx=0;idx<strings2.length;idx++) {
-        terms2[idx] = toIntsRef(strings2[idx], inputMode);
-      }
-      Arrays.sort(terms2);
-
-      doTest(inputMode, terms);
-    
-      // Test pre-determined FST sizes to make sure we haven't lost minimality (at least on this trivial set of terms):
-
-      // FSA
-      {
-        final Outputs<Object> outputs = NoOutputs.getSingleton();
-        final Object NO_OUTPUT = outputs.getNoOutput();      
-        final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms2.length);
-        for(IntsRef term : terms2) {
-          pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
-        }
-        FST<Object> fst = new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
-        assertNotNull(fst);
-        assertEquals(22, fst.getNodeCount());
-        assertEquals(27, fst.getArcCount());
-      }
-
-      // FST ord pos int
-      {
-        final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-        final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms2.length);
-        for(int idx=0;idx<terms2.length;idx++) {
-          pairs.add(new FSTTester.InputOutput<Long>(terms2[idx], outputs.get(idx)));
-        }
-        final FST<Long> fst = new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
-        assertNotNull(fst);
-        assertEquals(22, fst.getNodeCount());
-        assertEquals(27, fst.getArcCount());
-      }
-
-      // FST byte sequence ord
-      {
-        final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
-        final BytesRef NO_OUTPUT = outputs.getNoOutput();      
-        final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms2.length);
-        for(int idx=0;idx<terms2.length;idx++) {
-          final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
-          pairs.add(new FSTTester.InputOutput<BytesRef>(terms2[idx], output));
-        }
-        final FST<BytesRef> fst = new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
-        assertNotNull(fst);
-        assertEquals(24, fst.getNodeCount());
-        assertEquals(30, fst.getArcCount());
-      }
-    }
-  }
-
-  private static String simpleRandomString(Random r) {
-    final int end = r.nextInt(10);
-    if (end == 0) {
-      // allow 0 length
-      return "";
-    }
-    final char[] buffer = new char[end];
-    for (int i = 0; i < end; i++) {
-      buffer[i] = (char) _TestUtil.nextInt(r, 97, 102);
-    }
-    return new String(buffer, 0, end);
-  }
-
-  // given set of terms, test the different outputs for them
-  private void doTest(int inputMode, IntsRef[] terms) throws IOException {
-    Arrays.sort(terms);
-
-    // NoOutputs (simple FSA)
-    {
-      final Outputs<Object> outputs = NoOutputs.getSingleton();
-      final Object NO_OUTPUT = outputs.getNoOutput();      
-      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
-      for(IntsRef term : terms) {
-        pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
-      }
-      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (ord)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(idx)));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (random monotonically increasing positive number)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
-        lastOutput = value;
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(value)));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // PositiveIntOutput (random positive number)
-    {
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(random.nextLong()) & Long.MAX_VALUE));
-      }
-      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Pair<ord, (random monotonically increasing positive number>
-    {
-      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(random.nextBoolean());
-      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
-      final List<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>> pairs = new ArrayList<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
-        lastOutput = value;
-        pairs.add(new FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>(terms[idx],
-                                                                         outputs.get(o1.get(idx),
-                                                                                     o2.get(value))));
-      }
-      new FSTTester<PairOutputs.Pair<Long,Long>>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Sequence-of-bytes
-    {
-      final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
-      final BytesRef NO_OUTPUT = outputs.getNoOutput();      
-      final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
-        pairs.add(new FSTTester.InputOutput<BytesRef>(terms[idx], output));
-      }
-      new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Sequence-of-ints
-    {
-      final IntSequenceOutputs outputs = IntSequenceOutputs.getSingleton();
-      final List<FSTTester.InputOutput<IntsRef>> pairs = new ArrayList<FSTTester.InputOutput<IntsRef>>(terms.length);
-      for(int idx=0;idx<terms.length;idx++) {
-        final String s = Integer.toString(idx);
-        final IntsRef output = new IntsRef(s.length());
-        output.length = s.length();
-        for(int idx2=0;idx2<output.length;idx2++) {
-          output.ints[idx2] = s.charAt(idx2);
-        }
-        pairs.add(new FSTTester.InputOutput<IntsRef>(terms[idx], output));
-      }
-      new FSTTester<IntsRef>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-
-    // Up to two positive ints, shared, generally but not
-    // monotonically increasing
-    {
-      if (VERBOSE) {
-        System.out.println("TEST: now test UpToTwoPositiveIntOutputs");
-      }
-      final UpToTwoPositiveIntOutputs outputs = UpToTwoPositiveIntOutputs.getSingleton(true);
-      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
-      long lastOutput = 0;
-      for(int idx=0;idx<terms.length;idx++) {
-        // Sometimes go backwards
-        long value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-        while(value < 0) {
-          value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-        }
-        final Object output;
-        if (random.nextInt(5) == 3) {
-          long value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-          while(value2 < 0) {
-            value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
-          }
-          output = outputs.get(value, value2);
-        } else {
-          output = outputs.get(value);
-        }
-        pairs.add(new FSTTester.InputOutput<Object>(terms[idx], output));
-      }
-      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
-    }
-  }
-
-  private static class FSTTester<T> {
-
-    final Random random;
-    final List<InputOutput<T>> pairs;
-    final int inputMode;
-    final Outputs<T> outputs;
-    final Directory dir;
-
-    public FSTTester(Random random, Directory dir, int inputMode, List<InputOutput<T>> pairs, Outputs<T> outputs) {
-      this.random = random;
-      this.dir = dir;
-      this.inputMode = inputMode;
-      this.pairs = pairs;
-      this.outputs = outputs;
-    }
-
-    private static class InputOutput<T> implements Comparable<InputOutput<T>> {
-      public final IntsRef input;
-      public final T output;
-
-      public InputOutput(IntsRef input, T output) {
-        this.input = input;
-        this.output = output;
-      }
-
-      public int compareTo(InputOutput<T> other) {
-        if (other instanceof InputOutput) {
-          return input.compareTo((other).input);
-        } else {
-          throw new IllegalArgumentException();
-        }
-      }
-    }
-
-    public void doTest() throws IOException {
-      // no pruning
-      doTest(0, 0);
-
-      if (!(outputs instanceof UpToTwoPositiveIntOutputs)) {
-        // simple pruning
-        doTest(_TestUtil.nextInt(random, 1, 1+pairs.size()), 0);
-        
-        // leafy pruning
-        doTest(0, _TestUtil.nextInt(random, 1, 1+pairs.size()));
-      }
-    }
-
-    // runs the term, returning the output, or null if term
-    // isn't accepted.  if prefixLength is non-null it must be
-    // length 1 int array; prefixLength[0] is set to the length
-    // of the term prefix that matches
-    private T run(FST<T> fst, IntsRef term, int[] prefixLength) throws IOException {
-      assert prefixLength == null || prefixLength.length == 1;
-      final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-      final T NO_OUTPUT = fst.outputs.getNoOutput();
-      T output = NO_OUTPUT;
-
-      for(int i=0;i<=term.length;i++) {
-        final int label;
-        if (i == term.length) {
-          label = FST.END_LABEL;
-        } else {
-          label = term.ints[term.offset+i];
-        }
-        //System.out.println("   loop i=" + i + " label=" + label + " output=" + fst.outputs.outputToString(output) + " curArc: target=" + arc.target + " isFinal?=" + arc.isFinal());
-        if (fst.findTargetArc(label, arc, arc) == null) {
-          if (prefixLength != null) {
-            prefixLength[0] = i;
-            return output;
-          } else {
-            return null;
-          }
-        }
-        output = fst.outputs.add(output, arc.output);
-      }
-
-      if (prefixLength != null) {
-        prefixLength[0] = term.length;
-      }
-
-      return output;
-    }
-
-    private T randomAcceptedWord(FST<T> fst, IntsRef in) throws IOException {
-      FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
-
-      final List<FST.Arc<T>> arcs = new ArrayList<FST.Arc<T>>();
-      in.length = 0;
-      in.offset = 0;
-      final T NO_OUTPUT = fst.outputs.getNoOutput();
-      T output = NO_OUTPUT;
-
-      while(true) {
-        // read all arcs:
-        fst.readFirstTargetArc(arc, arc);
-        arcs.add(new FST.Arc<T>().copyFrom(arc));
-        while(!arc.isLast()) {
-          fst.readNextArc(arc);
-          arcs.add(new FST.Arc<T>().copyFrom(arc));
-        }
-      
-        // pick one
-        arc = arcs.get(random.nextInt(arcs.size()));
-        arcs.clear();
-
-        // accumulate output
-        output = fst.outputs.add(output, arc.output);
-
-        // append label
-        if (arc.label == FST.END_LABEL) {
-          break;
-        }
-
-        if (in.ints.length == in.length) {
-          in.grow(1+in.length);
-        }
-        in.ints[in.length++] = arc.label;
-      }
-
-      return output;
-    }
-
-
-    FST<T> doTest(int prune1, int prune2) throws IOException {
-      if (VERBOSE) {
-        System.out.println("TEST: prune1=" + prune1 + " prune2=" + prune2);
-      }
-
-      final Builder<T> builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4,
-                                                prune1, prune2,
-                                                prune1==0 && prune2==0, outputs);
-
-      for(InputOutput<T> pair : pairs) {
-        if (pair.output instanceof UpToTwoPositiveIntOutputs.TwoLongs) {
-          final UpToTwoPositiveIntOutputs _outputs = (UpToTwoPositiveIntOutputs) outputs;
-          final UpToTwoPositiveIntOutputs.TwoLongs twoLongs = (UpToTwoPositiveIntOutputs.TwoLongs) pair.output;
-          @SuppressWarnings("unchecked") final Builder<Object> builderObject = (Builder<Object>) builder;
-          builderObject.add(pair.input, _outputs.get(twoLongs.first));
-          builderObject.add(pair.input, _outputs.get(twoLongs.second));
-        } else {
-          builder.add(pair.input, pair.output);
-        }
-      }
-      FST<T> fst = builder.finish();
-
-      if (random.nextBoolean() && fst != null) {
-        IndexOutput out = dir.createOutput("fst.bin");
-        fst.save(out);
-        out.close();
-        IndexInput in = dir.openInput("fst.bin");
-        try {
-          fst = new FST<T>(in, outputs);
-        } finally {
-          in.close();
-          dir.deleteFile("fst.bin");
-        }
-      }
-
-      if (VERBOSE && pairs.size() <= 20 && fst != null) {
-        Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
-        Util.toDot(fst, w, false, false);
-        w.close();
-        System.out.println("SAVED out.dot");
-      }
-
-      if (VERBOSE) {
-        if (fst == null) {
-          System.out.println("  fst has 0 nodes (fully pruned)");
-        } else {
-          System.out.println("  fst has " + fst.getNodeCount() + " nodes and " + fst.getArcCount() + " arcs");
-        }
-      }
-
-      if (prune1 == 0 && prune2 == 0) {
-        verifyUnPruned(inputMode, fst);
-      } else {
-        verifyPruned(inputMode, fst, prune1, prune2);
-      }
-
-      return fst;
-    }
-
-    // FST is complete
-    private void verifyUnPruned(int inputMode, FST<T> fst) throws IOException {
-
-      if (pairs.size() == 0) {
-        assertNull(fst);
-        return;
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: now verify " + pairs.size() + " terms");
-        for(InputOutput<T> pair : pairs) {
-          assertNotNull(pair);
-          assertNotNull(pair.input);
-          assertNotNull(pair.output);
-          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
-        }
-      }
-
-      assertNotNull(fst);
-
-      // visit valid paris in order -- make sure all words
-      // are accepted, and FSTEnum's next() steps through
-      // them correctly
-      if (VERBOSE) {
-        System.out.println("TEST: check valid terms/next()");
-      }
-      {
-        IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-        for(InputOutput<T> pair : pairs) {
-          IntsRef term = pair.input;
-          if (VERBOSE) {
-            System.out.println("TEST: check term=" + inputToString(inputMode, term) + " output=" + fst.outputs.outputToString(pair.output));
-          }
-          Object output = run(fst, term, null);
-
-          assertNotNull("term " + inputToString(inputMode, term) + " is not accepted", output);
-          assertEquals(pair.output, output);
-
-          // verify enum's next
-          IntsRefFSTEnum.InputOutput<T> t = fstEnum.next();
-          assertNotNull(t);
-          assertEquals("expected input=" + inputToString(inputMode, term) + " but fstEnum returned " + inputToString(inputMode, t.input), term, t.input);
-          assertEquals(pair.output, t.output);
-        }
-        assertNull(fstEnum.next());
-      }
-
-      final Map<IntsRef,T> termsMap = new HashMap<IntsRef,T>();
-      for(InputOutput<T> pair : pairs) {
-        termsMap.put(pair.input, pair.output);
-      }
-
-      // find random matching word and make sure it's valid
-      if (VERBOSE) {
-        System.out.println("TEST: verify random accepted terms");
-      }
-      final IntsRef scratch = new IntsRef(10);
-      for(int iter=0;iter<500*RANDOM_MULTIPLIER;iter++) {
-        T output = randomAcceptedWord(fst, scratch);
-        assertTrue("accepted word " + inputToString(inputMode, scratch) + " is not valid", termsMap.containsKey(scratch));
-        assertEquals(termsMap.get(scratch), output);
-      }
-    
-      // test IntsRefFSTEnum.seek:
-      if (VERBOSE) {
-        System.out.println("TEST: verify seek");
-      }
-      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-      for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-        if (VERBOSE) {
-          System.out.println("TEST: iter=" + iter);
-        }
-        if (random.nextBoolean()) {
-          // seek to term that doesn't exist:
-          while(true) {
-            final IntsRef term = toIntsRef(getRandomString(), inputMode);
-            int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
-            if (pos < 0) {
-              pos = -(pos+1);
-              // ok doesn't exist
-              //System.out.println("  seek " + inputToString(inputMode, term));
-              final IntsRefFSTEnum.InputOutput<T> seekResult;
-              if (random.nextBoolean()) {
-                if (VERBOSE) {
-                  System.out.println("  do non-exist seekFloor term=" + inputToString(inputMode, term));
-                }
-                seekResult = fstEnum.seekFloor(term);
-                pos--;
-              } else {
-                if (VERBOSE) {
-                  System.out.println("  do non-exist seekCeil term=" + inputToString(inputMode, term));
-                }
-                seekResult = fstEnum.seekCeil(term);
-              }
-
-              if (pos != -1 && pos < pairs.size()) {
-                //System.out.println("    got " + inputToString(inputMode,seekResult.input) + " output=" + fst.outputs.outputToString(seekResult.output));
-                assertNotNull("got null but expected term=" + inputToString(inputMode, pairs.get(pos).input), seekResult);
-                if (VERBOSE) {
-                  System.out.println("    got " + inputToString(inputMode, seekResult.input));
-                }
-                assertEquals("expected " + inputToString(inputMode, pairs.get(pos).input) + " but got " + inputToString(inputMode, seekResult.input), pairs.get(pos).input, seekResult.input);
-                assertEquals(pairs.get(pos).output, seekResult.output);
-              } else {
-                // seeked before start or beyond end
-                //System.out.println("seek=" + seekTerm);
-                assertNull("expected null but got " + (seekResult==null ? "null" : inputToString(inputMode, seekResult.input)), seekResult);
-                if (VERBOSE) {
-                  System.out.println("    got null");
-                }
-              }
-
-              break;
-            }
-          }
-        } else {
-          // seek to term that does exist:
-          InputOutput<T> pair = pairs.get(random.nextInt(pairs.size()));
-          final IntsRefFSTEnum.InputOutput<T> seekResult;
-          if (random.nextBoolean()) {
-            if (VERBOSE) {
-              System.out.println("  do exists seekFloor " + inputToString(inputMode, pair.input));
-            }
-            seekResult = fstEnum.seekFloor(pair.input);
-          } else {
-            if (VERBOSE) {
-              System.out.println("  do exists seekCeil " + inputToString(inputMode, pair.input));
-            }
-            seekResult = fstEnum.seekCeil(pair.input);
-          }
-          assertNotNull(seekResult);
-          assertEquals("got " + inputToString(inputMode, seekResult.input) + " but expected " + inputToString(inputMode, pair.input), pair.input, seekResult.input);
-          assertEquals(pair.output, seekResult.output);
-        }
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: mixed next/seek");
-      }
-
-      // test mixed next/seek
-      for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-        if (VERBOSE) {
-          System.out.println("TEST: iter " + iter);
-        }
-        // reset:
-        fstEnum = new IntsRefFSTEnum<T>(fst);
-        int upto = -1;
-        while(true) {
-          boolean isDone = false;
-          if (upto == pairs.size()-1 || random.nextBoolean()) {
-            // next
-            upto++;
-            if (VERBOSE) {
-              System.out.println("  do next");
-            }
-            isDone = fstEnum.next() == null;
-          } else if (upto != -1 && upto < 0.75 * pairs.size() && random.nextBoolean()) {
-            int attempt = 0;
-            for(;attempt<10;attempt++) {
-              IntsRef term = toIntsRef(getRandomString(), inputMode);
-              if (!termsMap.containsKey(term) && term.compareTo(pairs.get(upto).input) > 0) {
-                int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
-                assert pos < 0;
-                upto = -(pos+1);
-
-                if (random.nextBoolean()) {
-                  upto--;
-                  assertTrue(upto != -1);
-                  if (VERBOSE) {
-                    System.out.println("  do non-exist seekFloor(" + inputToString(inputMode, term) + ")");
-                  }
-                  isDone = fstEnum.seekFloor(term) == null;
-                } else {
-                  if (VERBOSE) {
-                    System.out.println("  do non-exist seekCeil(" + inputToString(inputMode, term) + ")");
-                  }
-                  isDone = fstEnum.seekCeil(term) == null;
-                }
-
-                break;
-              }
-            }
-            if (attempt == 10) {
-              continue;
-            }
-            
-          } else {
-            final int inc = random.nextInt(pairs.size() - upto - 1);
-            upto += inc;
-            if (upto == -1) {
-              upto = 0;
-            }
-
-            if (random.nextBoolean()) {
-              if (VERBOSE) {
-                System.out.println("  do advanceCeil(" + inputToString(inputMode, pairs.get(upto).input) + ")");
-              }
-              isDone = fstEnum.seekCeil(pairs.get(upto).input) == null;
-            } else {
-              if (VERBOSE) {
-                System.out.println("  do advanceFloor(" + inputToString(inputMode, pairs.get(upto).input) + ")");
-              }
-              isDone = fstEnum.seekFloor(pairs.get(upto).input) == null;
-            }
-          }
-          if (VERBOSE) {
-            if (!isDone) {
-              System.out.println("    got " + inputToString(inputMode, fstEnum.current().input));
-            } else {
-              System.out.println("    got null");
-            }
-          }
-
-          if (upto == pairs.size()) {
-            assertTrue(isDone);
-            break;
-          } else {
-            assertFalse(isDone);
-            assertEquals(pairs.get(upto).input, fstEnum.current().input);
-            assertEquals(pairs.get(upto).output, fstEnum.current().output);
-
-            /*
-            if (upto < pairs.size()-1) {
-              int tryCount = 0;
-              while(tryCount < 10) {
-                final IntsRef t = toIntsRef(getRandomString(), inputMode);
-                if (pairs.get(upto).input.compareTo(t) < 0) {
-                  final boolean expected = t.compareTo(pairs.get(upto+1).input) < 0;
-                  if (VERBOSE) {
-                    System.out.println("TEST: call beforeNext(" + inputToString(inputMode, t) + "); current=" + inputToString(inputMode, pairs.get(upto).input) + " next=" + inputToString(inputMode, pairs.get(upto+1).input) + " expected=" + expected);
-                  }
-                  assertEquals(expected, fstEnum.beforeNext(t));
-                  break;
-                }
-                tryCount++;
-              }
-            }
-            */
-          }
-        }
-      }
-    }
-
-    private static class CountMinOutput<T> {
-      int count;
-      T output;
-      T finalOutput;
-      boolean isLeaf = true;
-      boolean isFinal;
-    }
-
-    // FST is pruned
-    private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) throws IOException {
-
-      if (VERBOSE) {
-        System.out.println("TEST: now verify pruned " + pairs.size() + " terms; outputs=" + outputs);
-        for(InputOutput<T> pair : pairs) {
-          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
-        }
-      }
-
-      // To validate the FST, we brute-force compute all prefixes
-      // in the terms, matched to their "common" outputs, prune that
-      // set according to the prune thresholds, then assert the FST
-      // matches that same set.
-
-      // NOTE: Crazy RAM intensive!!
-
-      //System.out.println("TEST: tally prefixes");
-
-      // build all prefixes
-      final Map<IntsRef,CountMinOutput<T>> prefixes = new HashMap<IntsRef,CountMinOutput<T>>();
-      final IntsRef scratch = new IntsRef(10);
-      for(InputOutput<T> pair: pairs) {
-        scratch.copy(pair.input);
-        for(int idx=0;idx<=pair.input.length;idx++) {
-          scratch.length = idx;
-          CountMinOutput<T> cmo = prefixes.get(scratch);
-          if (cmo == null) {
-            cmo = new CountMinOutput<T>();
-            cmo.count = 1;
-            cmo.output = pair.output;
-            prefixes.put(new IntsRef(scratch), cmo);
-          } else {
-            cmo.count++;
-            cmo.output = outputs.common(cmo.output, pair.output);
-          }
-          if (idx == pair.input.length) {
-            cmo.isFinal = true;
-            cmo.finalOutput = cmo.output;
-          }
-        }
-      }
-
-      if (VERBOSE) {
-        System.out.println("TEST: now prune");
-      }
-
-      // prune 'em
-      final Iterator<Map.Entry<IntsRef,CountMinOutput<T>>> it = prefixes.entrySet().iterator();
-      while(it.hasNext()) {
-        Map.Entry<IntsRef,CountMinOutput<T>> ent = it.next();
-        final IntsRef prefix = ent.getKey();
-        final CountMinOutput<T> cmo = ent.getValue();
-        if (VERBOSE) {
-          System.out.println("  term=" + inputToString(inputMode, prefix) + " count=" + cmo.count + " isLeaf=" + cmo.isLeaf + " output=" + outputs.outputToString(cmo.output) + " isFinal=" + cmo.isFinal);
-        }
-        final boolean keep;
-        if (prune1 > 0) {
-          keep = cmo.count >= prune1;
-        } else {
-          assert prune2 > 0;
-          if (prune2 > 1 && cmo.count >= prune2) {
-            keep = true;
-          } else if (prefix.length > 0) {
-            // consult our parent
-            scratch.length = prefix.length-1;
-            System.arraycopy(prefix.ints, prefix.offset, scratch.ints, 0, scratch.length);
-            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
-            //System.out.println("    parent count = " + (cmo2 == null ? -1 : cmo2.count));
-            keep = cmo2 != null && ((prune2 > 1 && cmo2.count >= prune2) || (prune2 == 1 && (cmo2.count >= 2 || prefix.length <= 1)));
-          } else if (cmo.count >= prune2) {
-            keep = true;
-          } else {
-            keep = false;
-          }
-        }
-
-        if (!keep) {
-          it.remove();
-          //System.out.println("    remove");
-        } else {
-          // clear isLeaf for all ancestors
-          //System.out.println("    keep");
-          scratch.copy(prefix);
-          scratch.length--;
-          while(scratch.length >= 0) {
-            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
-            if (cmo2 != null) {
-              //System.out.println("    clear isLeaf " + inputToString(inputMode, scratch));
-              cmo2.isLeaf = false;
-            }
-            scratch.length--;
-          }
-        }
-      }
-
-      //System.out.println("TEST: after prune");
-      /*
-        for(Map.Entry<BytesRef,CountMinOutput> ent : prefixes.entrySet()) {
-        System.out.println("  " + inputToString(inputMode, ent.getKey()) + ": isLeaf=" + ent.getValue().isLeaf + " isFinal=" + ent.getValue().isFinal);
-        if (ent.getValue().isFinal) {
-        System.out.println("    finalOutput=" + outputs.outputToString(ent.getValue().finalOutput));
-        }
-        }
-      */
-
-      if (prefixes.size() <= 1) {
-        assertNull(fst);
-        return;
-      }
-
-      assertNotNull(fst);
-
-      // make sure FST only enums valid prefixes
-      if (VERBOSE) {
-        System.out.println("TEST: check pruned enum");
-      }
-      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
-      IntsRefFSTEnum.InputOutput<T> current;
-      while((current = fstEnum.next()) != null) {
-        if (VERBOSE) {
-          System.out.println("  fstEnum.next term=" + inputToString(inputMode, current.input) + " output=" + outputs.outputToString(current.output));
-        }
-        final CountMinOutput cmo = prefixes.get(current.input);
-        assertNotNull(cmo);
-        assertTrue(cmo.isLeaf || cmo.isFinal);
-        //if (cmo.isFinal && !cmo.isLeaf) {
-        if (cmo.isFinal) {
-          assertEquals(cmo.finalOutput, current.output);
-        } else {
-          assertEquals(cmo.output, current.output);
-        }
-      }
-
-      // make sure all non-pruned prefixes are present in the FST
-      if (VERBOSE) {
-        System.out.println("TEST: verify all prefixes");
-      }
-      final int[] stopNode = new int[1];
-      for(Map.Entry<IntsRef,CountMinOutput<T>> ent : prefixes.entrySet()) {
-        if (ent.getKey().length > 0) {
-          final CountMinOutput<T> cmo = ent.getValue();
-          final T output = run(fst, ent.getKey(), stopNode);
-          if (VERBOSE) {
-            System.out.println("TEST: verify term=" + inputToString(inputMode, ent.getKey()) + " output=" + outputs.outputToString(cmo.output));
-          }
-          // if (cmo.isFinal && !cmo.isLeaf) {
-          if (cmo.isFinal) {
-            assertEquals(cmo.finalOutput, output);
-          } else {
-            assertEquals(cmo.output, output);
-          }
-          assertEquals(ent.getKey().length, stopNode[0]);
-        }
-      }
-    }
-  }
-
-  public void testRandomWords() throws IOException {
-    testRandomWords(1000, 5 * RANDOM_MULTIPLIER);
-    //testRandomWords(20, 100);
-  }
-
-  private String inputModeToString(int mode) {
-    if (mode == 0) {
-      return "utf8";
-    } else {
-      return "utf32";
-    }
-  }
-
-  private void testRandomWords(int maxNumWords, int numIter) throws IOException {
-    for(int iter=0;iter<numIter;iter++) {
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter " + iter);
-      }
-      for(int inputMode=0;inputMode<2;inputMode++) {
-        final int numWords = random.nextInt(maxNumWords+1);
-        Set<IntsRef> termsSet = new HashSet<IntsRef>();
-        IntsRef[] terms = new IntsRef[numWords];
-        while(termsSet.size() < numWords) {
-          final String term = getRandomString();
-          termsSet.add(toIntsRef(term, inputMode));
-        }
-        doTest(inputMode, termsSet.toArray(new IntsRef[termsSet.size()]));
-      }
-    }
-  }
-
-  static String getRandomString() {
-    final String term;
-    if (random.nextBoolean()) {
-      term = _TestUtil.randomRealisticUnicodeString(random);
-    } else {
-      // we want to mix in limited-alphabet symbols so
-      // we get more sharing of the nodes given how few
-      // terms we are testing...
-      term = simpleRandomString(random);
-    }
-    return term;
-  }
-
-  @Nightly
-  public void testBigSet() throws IOException {
-    testRandomWords(50000, RANDOM_MULTIPLIER);
-  }
-
-  private static String inputToString(int inputMode, IntsRef term) {
-    if (inputMode == 0) {
-      // utf8
-      return toBytesRef(term).utf8ToString() + " " + term;
-    } else {
-      // utf32
-      return UnicodeUtil.newString(term.ints, term.offset, term.length) + " " + term;
-    }
-  }
-
-  // Build FST for all unique terms in the test line docs
-  // file, up until a time limit
-  public void testRealTerms() throws Exception {
-
-    if (CodecProvider.getDefault().getDefaultFieldCodec().equals("SimpleText")) {
-      // no
-      CodecProvider.getDefault().setDefaultFieldCodec("Standard");
-    }
-
-    final LineFileDocs docs = new LineFileDocs(random);
-    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 100 : 1;
-    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64);
-    final File tempDir = _TestUtil.getTempDir("fstlines");
-    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));
-    final IndexWriter writer = new IndexWriter(dir, conf);
-    writer.setInfoStream(VERBOSE ? System.out : null);
-    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC * 1000;
-    Document doc;
-    int docCount = 0;
-    while((doc = docs.nextDoc()) != null && System.currentTimeMillis() < stopTime) {
-      writer.addDocument(doc);
-      docCount++;
-    }
-    IndexReader r = IndexReader.open(writer, true);
-    writer.close();
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
-    Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
-
-    boolean storeOrd = random.nextBoolean();
-    if (VERBOSE) {
-      if (storeOrd) {
-        System.out.println("FST stores ord");
-      } else {
-        System.out.println("FST stores docFreq");
-      }
-    }
-    Terms terms = MultiFields.getTerms(r, "body");
-    if (terms != null) {
-      final TermsEnum termsEnum = terms.iterator();
-      if (VERBOSE) {
-        System.out.println("TEST: got termsEnum=" + termsEnum);
-      }
-      BytesRef term;
-      int ord = 0;
-      while((term = termsEnum.next()) != null) {
-        if (ord == 0) {
-          try {
-            termsEnum.ord();
-          } catch (UnsupportedOperationException uoe) {
-            if (VERBOSE) {
-              System.out.println("TEST: codec doesn't support ord; FST stores docFreq");
-            }
-            storeOrd = false;
-          }
-        }
-        final int output;
-        if (storeOrd) {
-          output = ord;
-        } else {
-          output = termsEnum.docFreq();
-        }
-        builder.add(term, outputs.get(output));
-        ord++;
-        if (ord % 100000 == 0 && LuceneTestCase.TEST_NIGHTLY) {
-          System.out.println(ord + " terms...");
-        }
-      }
-      final FST<Long> fst = builder.finish();
-      if (VERBOSE) {
-        System.out.println("FST: " + docCount + " docs; " + ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs;" + " " + fst.sizeInBytes() + " bytes");
-      }
-
-      if (ord > 0) {
-        // Now confirm BytesRefFSTEnum and TermsEnum act the
-        // same:
-        final BytesRefFSTEnum<Long> fstEnum = new BytesRefFSTEnum<Long>(fst);
-        for(int iter=0;iter<1000*RANDOM_MULTIPLIER;iter++) {
-          final BytesRef randomTerm = new BytesRef(getRandomString());
-        
-          if (VERBOSE) {
-            System.out.println("TEST: seek " + randomTerm.utf8ToString() + " " + randomTerm);
-          }
-
-          final TermsEnum.SeekStatus seekResult = termsEnum.seek(randomTerm);
-          final BytesRefFSTEnum.InputOutput fstSeekResult = fstEnum.seekCeil(randomTerm);
-
-          if (seekResult == TermsEnum.SeekStatus.END) {
-            assertNull("got " + (fstSeekResult == null ? "null" : fstSeekResult.input.utf8ToString()) + " but expected null", fstSeekResult);
-          } else {
-            assertSame(termsEnum, fstEnum, storeOrd);
-            for(int nextIter=0;nextIter<10;nextIter++) {
-              if (VERBOSE) {
-                System.out.println("TEST: next");
-                if (storeOrd) {
-                  System.out.println("  ord=" + termsEnum.ord());
-                }
-              }
-              if (termsEnum.next() != null) {
-                if (VERBOSE) {
-                  System.out.println("  term=" + termsEnum.term().utf8ToString());
-                }
-                assertNotNull(fstEnum.next());
-                assertSame(termsEnum, fstEnum, storeOrd);
-              } else {
-                if (VERBOSE) {
-                  System.out.println("  end!");
-                }
-                BytesRefFSTEnum.InputOutput<Long> nextResult = fstEnum.next();
-                if (nextResult != null) {
-                  System.out.println("expected null but got: input=" + nextResult.input.utf8ToString() + " output=" + outputs.outputToString(nextResult.output));
-                  fail();
-                }
-                break;
-              }
-            }
-          }
-        }
-      }
-    }
-
-    r.close();
-    dir.close();
-  }
-
-  private void assertSame(TermsEnum termsEnum, BytesRefFSTEnum fstEnum, boolean storeOrd) throws Exception {
-    if (termsEnum.term() == null) {
-      assertNull(fstEnum.current());
-    } else {
-      assertNotNull(fstEnum.current());
-      assertEquals(termsEnum.term().utf8ToString() + " != " + fstEnum.current().input.utf8ToString(), termsEnum.term(), fstEnum.current().input);
-      if (storeOrd) {
-        // fst stored the ord
-        assertEquals(termsEnum.ord(), ((Long) fstEnum.current().output).longValue());
-      } else {
-        // fst stored the docFreq
-        assertEquals(termsEnum.docFreq(), (int) (((Long) fstEnum.current().output).longValue()));
-      }
-    }
-  }
-
-  private static abstract class VisitTerms<T> {
-    private final String dirOut;
-    private final String wordsFileIn;
-    private int inputMode;
-    private final Outputs<T> outputs;
-    private final Builder<T> builder;
-
-    public VisitTerms(String dirOut, String wordsFileIn, int inputMode, int prune, Outputs<T> outputs) {
-      this.dirOut = dirOut;
-      this.wordsFileIn = wordsFileIn;
-      this.inputMode = inputMode;
-      this.outputs = outputs;
-      
-      builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4, 0, prune, prune == 0, outputs);
-    }
-
-    protected abstract T getOutput(IntsRef input, int ord) throws IOException;
-
-    public void run(int limit, boolean verify) throws IOException {
-      BufferedReader is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
-      try {
-        final IntsRef intsRef = new IntsRef(10);
-        long tStart = System.currentTimeMillis();
-        int ord = 0;
-        while(true) {
-          String w = is.readLine();
-          if (w == null) {
-            break;
-          }
-          toIntsRef(w, inputMode, intsRef);
-          builder.add(intsRef,
-                      getOutput(intsRef, ord));
-
-          ord++;
-          if (ord % 500000 == 0) {
-            System.out.println(
-                String.format(Locale.ENGLISH, 
-                    "%6.2fs: %9d...", ((System.currentTimeMillis() - tStart) / 1000.0), ord));
-          }
-          if (ord >= limit) {
-            break;
-          }
-        }
-
-        assert builder.getTermCount() == ord;
-        final FST<T> fst = builder.finish();
-        if (fst == null) {
-          System.out.println("FST was fully pruned!");
-          System.exit(0);
-        }
-
-        if (dirOut == null)
-          return;
-
-        System.out.println(ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs; " + fst.getArcWithOutputCount() + " arcs w/ output; tot size " + fst.sizeInBytes());
-        if (fst.getNodeCount() < 100) {
-          Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
-          Util.toDot(fst, w, false, false);
-          w.close();
-          System.out.println("Wrote FST to out.dot");
-        }
-
-        Directory dir = FSDirectory.open(new File(dirOut));
-        IndexOutput out = dir.createOutput("fst.bin");
-        fst.save(out);
-        out.close();
-
-        System.out.println("Saved FST to fst.bin.");
-
-        if (!verify) {
-          return;
-        }
-
-        System.out.println("\nNow verify...");
-
-        is.close();
-        is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
-
-        ord = 0;
-        tStart = System.currentTimeMillis();
-        while(true) {
-          String w = is.readLine();
-          if (w == null) {
-            break;
-          }
-          toIntsRef(w, inputMode, intsRef);
-          T expected = getOutput(intsRef, ord);
-          T actual = Util.get(fst, intsRef);
-          if (actual == null) {
-            throw new RuntimeException("unexpected null output on input=" + w);
-          }
-          if (!actual.equals(expected)) {
-            throw new RuntimeException("wrong output (got " + outputs.outputToString(actual) + " but expected " + outputs.outputToString(expected) + ") on input=" + w);
-          }
-
-          ord++;
-          if (ord % 500000 == 0) {
-            System.out.println(((System.currentTimeMillis()-tStart)/1000.0) + "s: " + ord + "...");
-          }
-          if (ord >= limit) {
-            break;
-          }
-        }
-
-        double totSec = ((System.currentTimeMillis() - tStart)/1000.0);
-        System.out.println("Verify took " + totSec + " sec + (" + (int) ((totSec*1000000000/ord)) + " nsec per lookup)");
-
-      } finally {
-        is.close();
-      }
-    }
-  }
-
-  // java -cp build/classes/test:build/classes/java:lib/junit-4.7.jar org.apache.lucene.util.automaton.fst.TestFSTs /x/tmp/allTerms3.txt out
-  public static void main(String[] args) throws IOException {
-    int prune = 0;
-    int limit = Integer.MAX_VALUE;
-    int inputMode = 0;                             // utf8
-    boolean storeOrds = false;
-    boolean storeDocFreqs = false;
-    boolean verify = true;
-    
-    String wordsFileIn = null;
-    String dirOut = null;
-
-    int idx = 0;
-    while (idx < args.length) {
-      if (args[idx].equals("-prune")) {
-        prune = Integer.valueOf(args[1 + idx]);
-        idx++;
-      } else if (args[idx].equals("-limit")) {
-        limit = Integer.valueOf(args[1 + idx]);
-        idx++;
-      } else if (args[idx].equals("-utf8")) {
-        inputMode = 0;
-      } else if (args[idx].equals("-utf32")) {
-        inputMode = 1;
-      } else if (args[idx].equals("-docFreq")) {
-        storeDocFreqs = true;
-      } else if (args[idx].equals("-ords")) {
-        storeOrds = true;
-      } else if (args[idx].equals("-noverify")) {
-        verify = false;
-      } else if (args[idx].startsWith("-")) {
-        System.err.println("Unrecognized option: " + args[idx]);
-        System.exit(-1);
-      } else {
-        if (wordsFileIn == null) {
-          wordsFileIn = args[idx];
-        } else if (dirOut == null) {
-          dirOut = args[idx];
-        } else {
-          System.err.println("Too many arguments, expected: input [output]");
-          System.exit(-1);
-        }
-      }
-      idx++;
-    }
-    
-    if (wordsFileIn == null) {
-      System.err.println("No input file.");
-      System.exit(-1);
-    }
-
-    // ord benefits from share, docFreqs don't:
-
-    if (storeOrds && storeDocFreqs) {
-      // Store both ord & docFreq:
-      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(true);
-      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(false);
-      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
-      new VisitTerms<PairOutputs.Pair<Long,Long>>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        Random rand;
-        @Override
-        public PairOutputs.Pair<Long,Long> getOutput(IntsRef input, int ord) {
-          if (ord == 0) {
-            rand = new Random(17);
-          }
-          return new PairOutputs.Pair<Long,Long>(o1.get(ord),
-                                                 o2.get(_TestUtil.nextInt(rand, 1, 5000)));
-        }
-      }.run(limit, verify);
-    } else if (storeOrds) {
-      // Store only ords
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        @Override
-        public Long getOutput(IntsRef input, int ord) {
-          return outputs.get(ord);
-        }
-      }.run(limit, verify);
-    } else if (storeDocFreqs) {
-      // Store only docFreq
-      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(false);
-      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        Random rand;
-        @Override
-        public Long getOutput(IntsRef input, int ord) {
-          if (ord == 0) {
-            rand = new Random(17);
-          }
-          return outputs.get(_TestUtil.nextInt(rand, 1, 5000));
-        }
-      }.run(limit, verify);
-    } else {
-      // Store nothing
-      final NoOutputs outputs = NoOutputs.getSingleton();
-      final Object NO_OUTPUT = outputs.getNoOutput();
-      new VisitTerms<Object>(dirOut, wordsFileIn, inputMode, prune, outputs) {
-        @Override
-        public Object getOutput(IntsRef input, int ord) {
-          return NO_OUTPUT;
-        }
-      }.run(limit, verify);
-    }
-  }
-
-  public void testSingleString() throws Exception {
-    final Outputs<Object> outputs = NoOutputs.getSingleton();
-    final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
-    b.add(new BytesRef("foobar"), outputs.getNoOutput());
-    final BytesRefFSTEnum<Object> fstEnum = new BytesRefFSTEnum<Object>(b.finish());
-    assertNull(fstEnum.seekFloor(new BytesRef("foo")));
-    assertNull(fstEnum.seekCeil(new BytesRef("foobaz")));
-  }
-
-  public void testSimple() throws Exception {
-
-    // Get outputs -- passing true means FST will share
-    // (delta code) the outputs.  This should result in
-    // smaller FST if the outputs grow monotonically.  But
-    // if numbers are "random", false should give smaller
-    // final size:
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-
-    // Build an FST mapping BytesRef -> Long
-    final Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
-
-    final BytesRef a = new BytesRef("a");
-    final BytesRef b = new BytesRef("b");
-    final BytesRef c = new BytesRef("c");
-
-    builder.add(a, outputs.get(17));
-    builder.add(b, outputs.get(42));
-    builder.add(c, outputs.get(13824324872317238L));
-
-    final FST<Long> fst = builder.finish();
-
-    assertEquals(13824324872317238L, (long) Util.get(fst, c));
-    assertEquals(42, (long) Util.get(fst, b));
-    assertEquals(17, (long) Util.get(fst, a));
-
-    BytesRefFSTEnum<Long> fstEnum = new BytesRefFSTEnum<Long>(fst);
-    BytesRefFSTEnum.InputOutput<Long> seekResult;
-    seekResult = fstEnum.seekFloor(a);
-    assertNotNull(seekResult);
-    assertEquals(17, (long) seekResult.output);
-
-    // goes to a
-    seekResult = fstEnum.seekFloor(new BytesRef("aa"));
-    assertNotNull(seekResult);
-    assertEquals(17, (long) seekResult.output);
-
-    // goes to b
-    seekResult = fstEnum.seekCeil(new BytesRef("aa"));
-    assertNotNull(seekResult);
-    assertEquals(b, seekResult.input);
-    assertEquals(42, (long) seekResult.output);
-  }
-
-  /**
-   * Test state expansion (array format) on close-to-root states. Creates
-   * synthetic input that has one expanded state on each level.
-   * 
-   * @see "https://issues.apache.org/jira/browse/LUCENE-2933" 
-   */
-  public void testExpandedCloseToRoot() throws Exception {
-    class SyntheticData {
-      FST<Object> compile(String[] lines) throws IOException {
-        final NoOutputs outputs = NoOutputs.getSingleton();
-        final Object nothing = outputs.getNoOutput();
-        final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
-
-        int line = 0;
-        final BytesRef term = new BytesRef();
-        while (line < lines.length) {
-          String w = lines[line++];
-          if (w == null) {
-            break;
-          }
-          term.copy(w);
-          b.add(term, nothing);
-        }
-        
-        return b.finish();
-      }
-      
-      void generate(ArrayList<String> out, StringBuilder b, char from, char to,
-          int depth) {
-        if (depth == 0 || from == to) {
-          String seq = b.toString() + "_" + out.size() + "_end";
-          out.add(seq);
-        } else {
-          for (char c = from; c <= to; c++) {
-            b.append(c);
-            generate(out, b, from, c == to ? to : from, depth - 1);
-            b.deleteCharAt(b.length() - 1);
-          }
-        }
-      }
-
-      public int verifyStateAndBelow(FST<Object> fst, Arc<Object> arc, int depth) 
-        throws IOException {
-        if (fst.targetHasArcs(arc)) {
-          int childCount = 0;
-          for (arc = fst.readFirstTargetArc(arc, arc);; 
-               arc = fst.readNextArc(arc), childCount++)
-          {
-            boolean expanded = fst.isExpandedTarget(arc);
-            int children = verifyStateAndBelow(fst, new FST.Arc<Object>().copyFrom(arc), depth + 1);
-
-            assertEquals(
-                expanded,
-                (depth <= FST.FIXED_ARRAY_SHALLOW_DISTANCE && 
-                    children >= FST.FIXED_ARRAY_NUM_ARCS_SHALLOW) ||
-                 children >= FST.FIXED_ARRAY_NUM_ARCS_DEEP);
-            if (arc.isLast()) break;
-          }
-
-          return childCount;
-        }
-        return 0;
-      }
-    }
-
-    // Sanity check.
-    assertTrue(FST.FIXED_ARRAY_NUM_ARCS_SHALLOW < FST.FIXED_ARRAY_NUM_ARCS_DEEP);
-    assertTrue(FST.FIXED_ARRAY_SHALLOW_DISTANCE >= 0);
-
-    SyntheticData s = new SyntheticData();
-
-    ArrayList<String> out = new ArrayList<String>();
-    StringBuilder b = new StringBuilder();
-    s.generate(out, b, 'a', 'i', 10);
-    String[] input = out.toArray(new String[out.size()]);
-    Arrays.sort(input);
-    FST<Object> fst = s.compile(input);
-    FST.Arc<Object> arc = fst.getFirstArc(new FST.Arc<Object>());
-    s.verifyStateAndBelow(fst, arc, 1);
-  }
-
-  // Make sure raw FST can differentiate between final vs
-  // non-final end nodes
-  public void testNonFinalStopNodes() throws Exception {
-    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
-    final Long nothing = outputs.getNoOutput();
-    final Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
-
-    final FST<Long> fst = new FST<Long>(FST.INPUT_TYPE.BYTE1, outputs);
-
-    final Builder.UnCompiledNode<Long> rootNode = new Builder.UnCompiledNode<Long>(b, 0);
-
-    // Add final stop node
-    {
-      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
-      node.isFinal = true;
-      rootNode.addArc('a', node);
-      final Builder.CompiledNode frozen = new Builder.CompiledNode();
-      frozen.address = fst.addNode(node);
-      rootNode.arcs[0].nextFinalOutput = outputs.get(17);
-      rootNode.arcs[0].isFinal = true;
-      rootNode.arcs[0].output = nothing;
-      rootNode.arcs[0].target = frozen;
-    }
-
-    // Add non-final stop node
-    {
-      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
-      rootNode.addArc('b', node);
-      final Builder.CompiledNode frozen = new Builder.CompiledNode();
-      frozen.address = fst.addNode(node);
-      rootNode.arcs[1].nextFinalOutput = nothing;
-      rootNode.arcs[1].output = outputs.get(42);
-      rootNode.arcs[1].target = frozen;
-    }
-
-    fst.finish(fst.addNode(rootNode));
-    
-    checkStopNodes(fst, outputs);
-
-    // Make sure it still works after save/load:
-    Directory dir = newDirectory();
-    IndexOutput out = dir.createOutput("fst");
-    fst.save(out);
-    out.close();
-
-    IndexInput in = dir.openInput("fst");
-    final FST<Long> fst2 = new FST<Long>(in, outputs);
-    checkStopNodes(fst2, outputs);
-    in.close();
-    dir.close();
-  }
-
-  private void checkStopNodes(FST<Long> fst, PositiveIntOutputs outputs) throws Exception {
-    final Long nothing = outputs.getNoOutput();
-    FST.Arc<Long> startArc = fst.getFirstArc(new FST.Arc<Long>());
-    assertEquals(nothing, startArc.output);
-    assertEquals(nothing, startArc.nextFinalOutput);
-
-    FST.Arc<Long> arc = fst.readFirstTargetArc(startArc, new FST.Arc<Long>());
-    assertEquals('a', arc.label);
-    assertEquals(17, arc.nextFinalOutput.longValue());
-    assertTrue(arc.isFinal());
-
-    arc = fst.readNextArc(arc);
-    assertEquals('b', arc.label);
-    assertFalse(arc.isFinal());
-    assertEquals(42, arc.output.longValue());
-  }
-}
diff --git a/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java b/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java
new file mode 100644
index 0000000..2439e13
--- /dev/null
+++ b/lucene/src/test/org/apache/lucene/util/fst/TestFSTs.java
@@ -0,0 +1,1535 @@
+package org.apache.lucene.util.fst;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.OutputStreamWriter;
+import java.io.Writer;
+import java.util.*;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.MultiFields;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.codecs.CodecProvider;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.FSDirectory;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.store.MockDirectoryWrapper;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.LineFileDocs;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.lucene.util._TestUtil;
+import org.apache.lucene.util.fst.FST.Arc;
+
+public class TestFSTs extends LuceneTestCase {
+
+  private MockDirectoryWrapper dir;
+
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    dir = newDirectory();
+    dir.setPreventDoubleWrite(false);
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    dir.close();
+    super.tearDown();
+  }
+
+  private static BytesRef toBytesRef(IntsRef ir) {
+    BytesRef br = new BytesRef(ir.length);
+    for(int i=0;i<ir.length;i++) {
+      int x = ir.ints[ir.offset+i];
+      assert x >= 0 && x <= 255;
+      br.bytes[i] = (byte) x;
+    }
+    br.length = ir.length;
+    return br;
+  }
+
+  private static IntsRef toIntsRef(String s, int inputMode) {
+    return toIntsRef(s, inputMode, new IntsRef(10));
+  }
+
+  private static IntsRef toIntsRef(String s, int inputMode, IntsRef ir) {
+    if (inputMode == 0) {
+      // utf8
+      return toIntsRef(new BytesRef(s), ir);
+    } else {
+      // utf32
+      return toIntsRefUTF32(s, ir);
+    }
+  }
+
+  private static IntsRef toIntsRefUTF32(String s, IntsRef ir) {
+    final int charLength = s.length();
+    int charIdx = 0;
+    int intIdx = 0;
+    while(charIdx < charLength) {
+      if (intIdx == ir.ints.length) {
+        ir.grow(intIdx+1);
+      }
+      final int utf32 = s.codePointAt(charIdx);
+      ir.ints[intIdx] = utf32;
+      charIdx += Character.charCount(utf32);
+      intIdx++;
+    }
+    ir.length = intIdx;
+    return ir;
+  }
+
+  private static IntsRef toIntsRef(BytesRef br, IntsRef ir) {
+    if (br.length > ir.ints.length) {
+      ir.grow(br.length);
+    }
+    for(int i=0;i<br.length;i++) {
+      ir.ints[i] = br.bytes[br.offset+i]&0xFF;
+    }
+    ir.length = br.length;
+    return ir;
+  }
+
+  public void testBasicFSA() throws IOException {
+    String[] strings = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation", "stat"};
+    String[] strings2 = new String[] {"station", "commotion", "elation", "elastic", "plastic", "stop", "ftop", "ftation"};
+    IntsRef[] terms = new IntsRef[strings.length];
+    IntsRef[] terms2 = new IntsRef[strings2.length];
+    for(int inputMode=0;inputMode<2;inputMode++) {
+      if (VERBOSE) {
+        System.out.println("TEST: inputMode=" + inputModeToString(inputMode));
+      }
+
+      for(int idx=0;idx<strings.length;idx++) {
+        terms[idx] = toIntsRef(strings[idx], inputMode);
+      }
+      for(int idx=0;idx<strings2.length;idx++) {
+        terms2[idx] = toIntsRef(strings2[idx], inputMode);
+      }
+      Arrays.sort(terms2);
+
+      doTest(inputMode, terms);
+    
+      // Test pre-determined FST sizes to make sure we haven't lost minimality (at least on this trivial set of terms):
+
+      // FSA
+      {
+        final Outputs<Object> outputs = NoOutputs.getSingleton();
+        final Object NO_OUTPUT = outputs.getNoOutput();      
+        final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms2.length);
+        for(IntsRef term : terms2) {
+          pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
+        }
+        FST<Object> fst = new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
+        assertNotNull(fst);
+        assertEquals(22, fst.getNodeCount());
+        assertEquals(27, fst.getArcCount());
+      }
+
+      // FST ord pos int
+      {
+        final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+        final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms2.length);
+        for(int idx=0;idx<terms2.length;idx++) {
+          pairs.add(new FSTTester.InputOutput<Long>(terms2[idx], outputs.get(idx)));
+        }
+        final FST<Long> fst = new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
+        assertNotNull(fst);
+        assertEquals(22, fst.getNodeCount());
+        assertEquals(27, fst.getArcCount());
+      }
+
+      // FST byte sequence ord
+      {
+        final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
+        final BytesRef NO_OUTPUT = outputs.getNoOutput();      
+        final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms2.length);
+        for(int idx=0;idx<terms2.length;idx++) {
+          final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
+          pairs.add(new FSTTester.InputOutput<BytesRef>(terms2[idx], output));
+        }
+        final FST<BytesRef> fst = new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest(0, 0);
+        assertNotNull(fst);
+        assertEquals(24, fst.getNodeCount());
+        assertEquals(30, fst.getArcCount());
+      }
+    }
+  }
+
+  private static String simpleRandomString(Random r) {
+    final int end = r.nextInt(10);
+    if (end == 0) {
+      // allow 0 length
+      return "";
+    }
+    final char[] buffer = new char[end];
+    for (int i = 0; i < end; i++) {
+      buffer[i] = (char) _TestUtil.nextInt(r, 97, 102);
+    }
+    return new String(buffer, 0, end);
+  }
+
+  // given set of terms, test the different outputs for them
+  private void doTest(int inputMode, IntsRef[] terms) throws IOException {
+    Arrays.sort(terms);
+
+    // NoOutputs (simple FSA)
+    {
+      final Outputs<Object> outputs = NoOutputs.getSingleton();
+      final Object NO_OUTPUT = outputs.getNoOutput();      
+      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
+      for(IntsRef term : terms) {
+        pairs.add(new FSTTester.InputOutput<Object>(term, NO_OUTPUT));
+      }
+      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // PositiveIntOutput (ord)
+    {
+      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
+      for(int idx=0;idx<terms.length;idx++) {
+        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(idx)));
+      }
+      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // PositiveIntOutput (random monotonically increasing positive number)
+    {
+      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
+      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
+      long lastOutput = 0;
+      for(int idx=0;idx<terms.length;idx++) {
+        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
+        lastOutput = value;
+        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(value)));
+      }
+      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // PositiveIntOutput (random positive number)
+    {
+      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
+      final List<FSTTester.InputOutput<Long>> pairs = new ArrayList<FSTTester.InputOutput<Long>>(terms.length);
+      for(int idx=0;idx<terms.length;idx++) {
+        pairs.add(new FSTTester.InputOutput<Long>(terms[idx], outputs.get(random.nextLong()) & Long.MAX_VALUE));
+      }
+      new FSTTester<Long>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // Pair<ord, (random monotonically increasing positive number>
+    {
+      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(random.nextBoolean());
+      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(random.nextBoolean());
+      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
+      final List<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>> pairs = new ArrayList<FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>>(terms.length);
+      long lastOutput = 0;
+      for(int idx=0;idx<terms.length;idx++) {
+        final long value = lastOutput + _TestUtil.nextInt(random, 1, 1000);
+        lastOutput = value;
+        pairs.add(new FSTTester.InputOutput<PairOutputs.Pair<Long,Long>>(terms[idx],
+                                                                         outputs.get(o1.get(idx),
+                                                                                     o2.get(value))));
+      }
+      new FSTTester<PairOutputs.Pair<Long,Long>>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // Sequence-of-bytes
+    {
+      final ByteSequenceOutputs outputs = ByteSequenceOutputs.getSingleton();
+      final BytesRef NO_OUTPUT = outputs.getNoOutput();      
+      final List<FSTTester.InputOutput<BytesRef>> pairs = new ArrayList<FSTTester.InputOutput<BytesRef>>(terms.length);
+      for(int idx=0;idx<terms.length;idx++) {
+        final BytesRef output = random.nextInt(30) == 17 ? NO_OUTPUT : new BytesRef(Integer.toString(idx));
+        pairs.add(new FSTTester.InputOutput<BytesRef>(terms[idx], output));
+      }
+      new FSTTester<BytesRef>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // Sequence-of-ints
+    {
+      final IntSequenceOutputs outputs = IntSequenceOutputs.getSingleton();
+      final List<FSTTester.InputOutput<IntsRef>> pairs = new ArrayList<FSTTester.InputOutput<IntsRef>>(terms.length);
+      for(int idx=0;idx<terms.length;idx++) {
+        final String s = Integer.toString(idx);
+        final IntsRef output = new IntsRef(s.length());
+        output.length = s.length();
+        for(int idx2=0;idx2<output.length;idx2++) {
+          output.ints[idx2] = s.charAt(idx2);
+        }
+        pairs.add(new FSTTester.InputOutput<IntsRef>(terms[idx], output));
+      }
+      new FSTTester<IntsRef>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+
+    // Up to two positive ints, shared, generally but not
+    // monotonically increasing
+    {
+      if (VERBOSE) {
+        System.out.println("TEST: now test UpToTwoPositiveIntOutputs");
+      }
+      final UpToTwoPositiveIntOutputs outputs = UpToTwoPositiveIntOutputs.getSingleton(true);
+      final List<FSTTester.InputOutput<Object>> pairs = new ArrayList<FSTTester.InputOutput<Object>>(terms.length);
+      long lastOutput = 0;
+      for(int idx=0;idx<terms.length;idx++) {
+        // Sometimes go backwards
+        long value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
+        while(value < 0) {
+          value = lastOutput + _TestUtil.nextInt(random, -100, 1000);
+        }
+        final Object output;
+        if (random.nextInt(5) == 3) {
+          long value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
+          while(value2 < 0) {
+            value2 = lastOutput + _TestUtil.nextInt(random, -100, 1000);
+          }
+          output = outputs.get(value, value2);
+        } else {
+          output = outputs.get(value);
+        }
+        pairs.add(new FSTTester.InputOutput<Object>(terms[idx], output));
+      }
+      new FSTTester<Object>(random, dir, inputMode, pairs, outputs).doTest();
+    }
+  }
+
+  private static class FSTTester<T> {
+
+    final Random random;
+    final List<InputOutput<T>> pairs;
+    final int inputMode;
+    final Outputs<T> outputs;
+    final Directory dir;
+
+    public FSTTester(Random random, Directory dir, int inputMode, List<InputOutput<T>> pairs, Outputs<T> outputs) {
+      this.random = random;
+      this.dir = dir;
+      this.inputMode = inputMode;
+      this.pairs = pairs;
+      this.outputs = outputs;
+    }
+
+    private static class InputOutput<T> implements Comparable<InputOutput<T>> {
+      public final IntsRef input;
+      public final T output;
+
+      public InputOutput(IntsRef input, T output) {
+        this.input = input;
+        this.output = output;
+      }
+
+      public int compareTo(InputOutput<T> other) {
+        if (other instanceof InputOutput) {
+          return input.compareTo((other).input);
+        } else {
+          throw new IllegalArgumentException();
+        }
+      }
+    }
+
+    public void doTest() throws IOException {
+      // no pruning
+      doTest(0, 0);
+
+      if (!(outputs instanceof UpToTwoPositiveIntOutputs)) {
+        // simple pruning
+        doTest(_TestUtil.nextInt(random, 1, 1+pairs.size()), 0);
+        
+        // leafy pruning
+        doTest(0, _TestUtil.nextInt(random, 1, 1+pairs.size()));
+      }
+    }
+
+    // runs the term, returning the output, or null if term
+    // isn't accepted.  if prefixLength is non-null it must be
+    // length 1 int array; prefixLength[0] is set to the length
+    // of the term prefix that matches
+    private T run(FST<T> fst, IntsRef term, int[] prefixLength) throws IOException {
+      assert prefixLength == null || prefixLength.length == 1;
+      final FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+      final T NO_OUTPUT = fst.outputs.getNoOutput();
+      T output = NO_OUTPUT;
+
+      for(int i=0;i<=term.length;i++) {
+        final int label;
+        if (i == term.length) {
+          label = FST.END_LABEL;
+        } else {
+          label = term.ints[term.offset+i];
+        }
+        //System.out.println("   loop i=" + i + " label=" + label + " output=" + fst.outputs.outputToString(output) + " curArc: target=" + arc.target + " isFinal?=" + arc.isFinal());
+        if (fst.findTargetArc(label, arc, arc) == null) {
+          if (prefixLength != null) {
+            prefixLength[0] = i;
+            return output;
+          } else {
+            return null;
+          }
+        }
+        output = fst.outputs.add(output, arc.output);
+      }
+
+      if (prefixLength != null) {
+        prefixLength[0] = term.length;
+      }
+
+      return output;
+    }
+
+    private T randomAcceptedWord(FST<T> fst, IntsRef in) throws IOException {
+      FST.Arc<T> arc = fst.getFirstArc(new FST.Arc<T>());
+
+      final List<FST.Arc<T>> arcs = new ArrayList<FST.Arc<T>>();
+      in.length = 0;
+      in.offset = 0;
+      final T NO_OUTPUT = fst.outputs.getNoOutput();
+      T output = NO_OUTPUT;
+
+      while(true) {
+        // read all arcs:
+        fst.readFirstTargetArc(arc, arc);
+        arcs.add(new FST.Arc<T>().copyFrom(arc));
+        while(!arc.isLast()) {
+          fst.readNextArc(arc);
+          arcs.add(new FST.Arc<T>().copyFrom(arc));
+        }
+      
+        // pick one
+        arc = arcs.get(random.nextInt(arcs.size()));
+        arcs.clear();
+
+        // accumulate output
+        output = fst.outputs.add(output, arc.output);
+
+        // append label
+        if (arc.label == FST.END_LABEL) {
+          break;
+        }
+
+        if (in.ints.length == in.length) {
+          in.grow(1+in.length);
+        }
+        in.ints[in.length++] = arc.label;
+      }
+
+      return output;
+    }
+
+
+    FST<T> doTest(int prune1, int prune2) throws IOException {
+      if (VERBOSE) {
+        System.out.println("TEST: prune1=" + prune1 + " prune2=" + prune2);
+      }
+
+      final Builder<T> builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4,
+                                                prune1, prune2,
+                                                prune1==0 && prune2==0, outputs);
+
+      for(InputOutput<T> pair : pairs) {
+        if (pair.output instanceof UpToTwoPositiveIntOutputs.TwoLongs) {
+          final UpToTwoPositiveIntOutputs _outputs = (UpToTwoPositiveIntOutputs) outputs;
+          final UpToTwoPositiveIntOutputs.TwoLongs twoLongs = (UpToTwoPositiveIntOutputs.TwoLongs) pair.output;
+          @SuppressWarnings("unchecked") final Builder<Object> builderObject = (Builder<Object>) builder;
+          builderObject.add(pair.input, _outputs.get(twoLongs.first));
+          builderObject.add(pair.input, _outputs.get(twoLongs.second));
+        } else {
+          builder.add(pair.input, pair.output);
+        }
+      }
+      FST<T> fst = builder.finish();
+
+      if (random.nextBoolean() && fst != null) {
+        IndexOutput out = dir.createOutput("fst.bin");
+        fst.save(out);
+        out.close();
+        IndexInput in = dir.openInput("fst.bin");
+        try {
+          fst = new FST<T>(in, outputs);
+        } finally {
+          in.close();
+          dir.deleteFile("fst.bin");
+        }
+      }
+
+      if (VERBOSE && pairs.size() <= 20 && fst != null) {
+        Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
+        Util.toDot(fst, w, false, false);
+        w.close();
+        System.out.println("SAVED out.dot");
+      }
+
+      if (VERBOSE) {
+        if (fst == null) {
+          System.out.println("  fst has 0 nodes (fully pruned)");
+        } else {
+          System.out.println("  fst has " + fst.getNodeCount() + " nodes and " + fst.getArcCount() + " arcs");
+        }
+      }
+
+      if (prune1 == 0 && prune2 == 0) {
+        verifyUnPruned(inputMode, fst);
+      } else {
+        verifyPruned(inputMode, fst, prune1, prune2);
+      }
+
+      return fst;
+    }
+
+    // FST is complete
+    private void verifyUnPruned(int inputMode, FST<T> fst) throws IOException {
+
+      if (pairs.size() == 0) {
+        assertNull(fst);
+        return;
+      }
+
+      if (VERBOSE) {
+        System.out.println("TEST: now verify " + pairs.size() + " terms");
+        for(InputOutput<T> pair : pairs) {
+          assertNotNull(pair);
+          assertNotNull(pair.input);
+          assertNotNull(pair.output);
+          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
+        }
+      }
+
+      assertNotNull(fst);
+
+      // visit valid paris in order -- make sure all words
+      // are accepted, and FSTEnum's next() steps through
+      // them correctly
+      if (VERBOSE) {
+        System.out.println("TEST: check valid terms/next()");
+      }
+      {
+        IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
+        for(InputOutput<T> pair : pairs) {
+          IntsRef term = pair.input;
+          if (VERBOSE) {
+            System.out.println("TEST: check term=" + inputToString(inputMode, term) + " output=" + fst.outputs.outputToString(pair.output));
+          }
+          Object output = run(fst, term, null);
+
+          assertNotNull("term " + inputToString(inputMode, term) + " is not accepted", output);
+          assertEquals(pair.output, output);
+
+          // verify enum's next
+          IntsRefFSTEnum.InputOutput<T> t = fstEnum.next();
+          assertNotNull(t);
+          assertEquals("expected input=" + inputToString(inputMode, term) + " but fstEnum returned " + inputToString(inputMode, t.input), term, t.input);
+          assertEquals(pair.output, t.output);
+        }
+        assertNull(fstEnum.next());
+      }
+
+      final Map<IntsRef,T> termsMap = new HashMap<IntsRef,T>();
+      for(InputOutput<T> pair : pairs) {
+        termsMap.put(pair.input, pair.output);
+      }
+
+      // find random matching word and make sure it's valid
+      if (VERBOSE) {
+        System.out.println("TEST: verify random accepted terms");
+      }
+      final IntsRef scratch = new IntsRef(10);
+      for(int iter=0;iter<500*RANDOM_MULTIPLIER;iter++) {
+        T output = randomAcceptedWord(fst, scratch);
+        assertTrue("accepted word " + inputToString(inputMode, scratch) + " is not valid", termsMap.containsKey(scratch));
+        assertEquals(termsMap.get(scratch), output);
+      }
+    
+      // test IntsRefFSTEnum.seek:
+      if (VERBOSE) {
+        System.out.println("TEST: verify seek");
+      }
+      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
+      for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
+        if (VERBOSE) {
+          System.out.println("TEST: iter=" + iter);
+        }
+        if (random.nextBoolean()) {
+          // seek to term that doesn't exist:
+          while(true) {
+            final IntsRef term = toIntsRef(getRandomString(), inputMode);
+            int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
+            if (pos < 0) {
+              pos = -(pos+1);
+              // ok doesn't exist
+              //System.out.println("  seek " + inputToString(inputMode, term));
+              final IntsRefFSTEnum.InputOutput<T> seekResult;
+              if (random.nextBoolean()) {
+                if (VERBOSE) {
+                  System.out.println("  do non-exist seekFloor term=" + inputToString(inputMode, term));
+                }
+                seekResult = fstEnum.seekFloor(term);
+                pos--;
+              } else {
+                if (VERBOSE) {
+                  System.out.println("  do non-exist seekCeil term=" + inputToString(inputMode, term));
+                }
+                seekResult = fstEnum.seekCeil(term);
+              }
+
+              if (pos != -1 && pos < pairs.size()) {
+                //System.out.println("    got " + inputToString(inputMode,seekResult.input) + " output=" + fst.outputs.outputToString(seekResult.output));
+                assertNotNull("got null but expected term=" + inputToString(inputMode, pairs.get(pos).input), seekResult);
+                if (VERBOSE) {
+                  System.out.println("    got " + inputToString(inputMode, seekResult.input));
+                }
+                assertEquals("expected " + inputToString(inputMode, pairs.get(pos).input) + " but got " + inputToString(inputMode, seekResult.input), pairs.get(pos).input, seekResult.input);
+                assertEquals(pairs.get(pos).output, seekResult.output);
+              } else {
+                // seeked before start or beyond end
+                //System.out.println("seek=" + seekTerm);
+                assertNull("expected null but got " + (seekResult==null ? "null" : inputToString(inputMode, seekResult.input)), seekResult);
+                if (VERBOSE) {
+                  System.out.println("    got null");
+                }
+              }
+
+              break;
+            }
+          }
+        } else {
+          // seek to term that does exist:
+          InputOutput<T> pair = pairs.get(random.nextInt(pairs.size()));
+          final IntsRefFSTEnum.InputOutput<T> seekResult;
+          if (random.nextBoolean()) {
+            if (VERBOSE) {
+              System.out.println("  do exists seekFloor " + inputToString(inputMode, pair.input));
+            }
+            seekResult = fstEnum.seekFloor(pair.input);
+          } else {
+            if (VERBOSE) {
+              System.out.println("  do exists seekCeil " + inputToString(inputMode, pair.input));
+            }
+            seekResult = fstEnum.seekCeil(pair.input);
+          }
+          assertNotNull(seekResult);
+          assertEquals("got " + inputToString(inputMode, seekResult.input) + " but expected " + inputToString(inputMode, pair.input), pair.input, seekResult.input);
+          assertEquals(pair.output, seekResult.output);
+        }
+      }
+
+      if (VERBOSE) {
+        System.out.println("TEST: mixed next/seek");
+      }
+
+      // test mixed next/seek
+      for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
+        if (VERBOSE) {
+          System.out.println("TEST: iter " + iter);
+        }
+        // reset:
+        fstEnum = new IntsRefFSTEnum<T>(fst);
+        int upto = -1;
+        while(true) {
+          boolean isDone = false;
+          if (upto == pairs.size()-1 || random.nextBoolean()) {
+            // next
+            upto++;
+            if (VERBOSE) {
+              System.out.println("  do next");
+            }
+            isDone = fstEnum.next() == null;
+          } else if (upto != -1 && upto < 0.75 * pairs.size() && random.nextBoolean()) {
+            int attempt = 0;
+            for(;attempt<10;attempt++) {
+              IntsRef term = toIntsRef(getRandomString(), inputMode);
+              if (!termsMap.containsKey(term) && term.compareTo(pairs.get(upto).input) > 0) {
+                int pos = Collections.binarySearch(pairs, new InputOutput<T>(term, null));
+                assert pos < 0;
+                upto = -(pos+1);
+
+                if (random.nextBoolean()) {
+                  upto--;
+                  assertTrue(upto != -1);
+                  if (VERBOSE) {
+                    System.out.println("  do non-exist seekFloor(" + inputToString(inputMode, term) + ")");
+                  }
+                  isDone = fstEnum.seekFloor(term) == null;
+                } else {
+                  if (VERBOSE) {
+                    System.out.println("  do non-exist seekCeil(" + inputToString(inputMode, term) + ")");
+                  }
+                  isDone = fstEnum.seekCeil(term) == null;
+                }
+
+                break;
+              }
+            }
+            if (attempt == 10) {
+              continue;
+            }
+            
+          } else {
+            final int inc = random.nextInt(pairs.size() - upto - 1);
+            upto += inc;
+            if (upto == -1) {
+              upto = 0;
+            }
+
+            if (random.nextBoolean()) {
+              if (VERBOSE) {
+                System.out.println("  do advanceCeil(" + inputToString(inputMode, pairs.get(upto).input) + ")");
+              }
+              isDone = fstEnum.seekCeil(pairs.get(upto).input) == null;
+            } else {
+              if (VERBOSE) {
+                System.out.println("  do advanceFloor(" + inputToString(inputMode, pairs.get(upto).input) + ")");
+              }
+              isDone = fstEnum.seekFloor(pairs.get(upto).input) == null;
+            }
+          }
+          if (VERBOSE) {
+            if (!isDone) {
+              System.out.println("    got " + inputToString(inputMode, fstEnum.current().input));
+            } else {
+              System.out.println("    got null");
+            }
+          }
+
+          if (upto == pairs.size()) {
+            assertTrue(isDone);
+            break;
+          } else {
+            assertFalse(isDone);
+            assertEquals(pairs.get(upto).input, fstEnum.current().input);
+            assertEquals(pairs.get(upto).output, fstEnum.current().output);
+
+            /*
+            if (upto < pairs.size()-1) {
+              int tryCount = 0;
+              while(tryCount < 10) {
+                final IntsRef t = toIntsRef(getRandomString(), inputMode);
+                if (pairs.get(upto).input.compareTo(t) < 0) {
+                  final boolean expected = t.compareTo(pairs.get(upto+1).input) < 0;
+                  if (VERBOSE) {
+                    System.out.println("TEST: call beforeNext(" + inputToString(inputMode, t) + "); current=" + inputToString(inputMode, pairs.get(upto).input) + " next=" + inputToString(inputMode, pairs.get(upto+1).input) + " expected=" + expected);
+                  }
+                  assertEquals(expected, fstEnum.beforeNext(t));
+                  break;
+                }
+                tryCount++;
+              }
+            }
+            */
+          }
+        }
+      }
+    }
+
+    private static class CountMinOutput<T> {
+      int count;
+      T output;
+      T finalOutput;
+      boolean isLeaf = true;
+      boolean isFinal;
+    }
+
+    // FST is pruned
+    private void verifyPruned(int inputMode, FST<T> fst, int prune1, int prune2) throws IOException {
+
+      if (VERBOSE) {
+        System.out.println("TEST: now verify pruned " + pairs.size() + " terms; outputs=" + outputs);
+        for(InputOutput<T> pair : pairs) {
+          System.out.println("  " + inputToString(inputMode, pair.input) + ": " + outputs.outputToString(pair.output));
+        }
+      }
+
+      // To validate the FST, we brute-force compute all prefixes
+      // in the terms, matched to their "common" outputs, prune that
+      // set according to the prune thresholds, then assert the FST
+      // matches that same set.
+
+      // NOTE: Crazy RAM intensive!!
+
+      //System.out.println("TEST: tally prefixes");
+
+      // build all prefixes
+      final Map<IntsRef,CountMinOutput<T>> prefixes = new HashMap<IntsRef,CountMinOutput<T>>();
+      final IntsRef scratch = new IntsRef(10);
+      for(InputOutput<T> pair: pairs) {
+        scratch.copy(pair.input);
+        for(int idx=0;idx<=pair.input.length;idx++) {
+          scratch.length = idx;
+          CountMinOutput<T> cmo = prefixes.get(scratch);
+          if (cmo == null) {
+            cmo = new CountMinOutput<T>();
+            cmo.count = 1;
+            cmo.output = pair.output;
+            prefixes.put(new IntsRef(scratch), cmo);
+          } else {
+            cmo.count++;
+            cmo.output = outputs.common(cmo.output, pair.output);
+          }
+          if (idx == pair.input.length) {
+            cmo.isFinal = true;
+            cmo.finalOutput = cmo.output;
+          }
+        }
+      }
+
+      if (VERBOSE) {
+        System.out.println("TEST: now prune");
+      }
+
+      // prune 'em
+      final Iterator<Map.Entry<IntsRef,CountMinOutput<T>>> it = prefixes.entrySet().iterator();
+      while(it.hasNext()) {
+        Map.Entry<IntsRef,CountMinOutput<T>> ent = it.next();
+        final IntsRef prefix = ent.getKey();
+        final CountMinOutput<T> cmo = ent.getValue();
+        if (VERBOSE) {
+          System.out.println("  term=" + inputToString(inputMode, prefix) + " count=" + cmo.count + " isLeaf=" + cmo.isLeaf + " output=" + outputs.outputToString(cmo.output) + " isFinal=" + cmo.isFinal);
+        }
+        final boolean keep;
+        if (prune1 > 0) {
+          keep = cmo.count >= prune1;
+        } else {
+          assert prune2 > 0;
+          if (prune2 > 1 && cmo.count >= prune2) {
+            keep = true;
+          } else if (prefix.length > 0) {
+            // consult our parent
+            scratch.length = prefix.length-1;
+            System.arraycopy(prefix.ints, prefix.offset, scratch.ints, 0, scratch.length);
+            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
+            //System.out.println("    parent count = " + (cmo2 == null ? -1 : cmo2.count));
+            keep = cmo2 != null && ((prune2 > 1 && cmo2.count >= prune2) || (prune2 == 1 && (cmo2.count >= 2 || prefix.length <= 1)));
+          } else if (cmo.count >= prune2) {
+            keep = true;
+          } else {
+            keep = false;
+          }
+        }
+
+        if (!keep) {
+          it.remove();
+          //System.out.println("    remove");
+        } else {
+          // clear isLeaf for all ancestors
+          //System.out.println("    keep");
+          scratch.copy(prefix);
+          scratch.length--;
+          while(scratch.length >= 0) {
+            final CountMinOutput<T> cmo2 = prefixes.get(scratch);
+            if (cmo2 != null) {
+              //System.out.println("    clear isLeaf " + inputToString(inputMode, scratch));
+              cmo2.isLeaf = false;
+            }
+            scratch.length--;
+          }
+        }
+      }
+
+      //System.out.println("TEST: after prune");
+      /*
+        for(Map.Entry<BytesRef,CountMinOutput> ent : prefixes.entrySet()) {
+        System.out.println("  " + inputToString(inputMode, ent.getKey()) + ": isLeaf=" + ent.getValue().isLeaf + " isFinal=" + ent.getValue().isFinal);
+        if (ent.getValue().isFinal) {
+        System.out.println("    finalOutput=" + outputs.outputToString(ent.getValue().finalOutput));
+        }
+        }
+      */
+
+      if (prefixes.size() <= 1) {
+        assertNull(fst);
+        return;
+      }
+
+      assertNotNull(fst);
+
+      // make sure FST only enums valid prefixes
+      if (VERBOSE) {
+        System.out.println("TEST: check pruned enum");
+      }
+      IntsRefFSTEnum<T> fstEnum = new IntsRefFSTEnum<T>(fst);
+      IntsRefFSTEnum.InputOutput<T> current;
+      while((current = fstEnum.next()) != null) {
+        if (VERBOSE) {
+          System.out.println("  fstEnum.next term=" + inputToString(inputMode, current.input) + " output=" + outputs.outputToString(current.output));
+        }
+        final CountMinOutput cmo = prefixes.get(current.input);
+        assertNotNull(cmo);
+        assertTrue(cmo.isLeaf || cmo.isFinal);
+        //if (cmo.isFinal && !cmo.isLeaf) {
+        if (cmo.isFinal) {
+          assertEquals(cmo.finalOutput, current.output);
+        } else {
+          assertEquals(cmo.output, current.output);
+        }
+      }
+
+      // make sure all non-pruned prefixes are present in the FST
+      if (VERBOSE) {
+        System.out.println("TEST: verify all prefixes");
+      }
+      final int[] stopNode = new int[1];
+      for(Map.Entry<IntsRef,CountMinOutput<T>> ent : prefixes.entrySet()) {
+        if (ent.getKey().length > 0) {
+          final CountMinOutput<T> cmo = ent.getValue();
+          final T output = run(fst, ent.getKey(), stopNode);
+          if (VERBOSE) {
+            System.out.println("TEST: verify term=" + inputToString(inputMode, ent.getKey()) + " output=" + outputs.outputToString(cmo.output));
+          }
+          // if (cmo.isFinal && !cmo.isLeaf) {
+          if (cmo.isFinal) {
+            assertEquals(cmo.finalOutput, output);
+          } else {
+            assertEquals(cmo.output, output);
+          }
+          assertEquals(ent.getKey().length, stopNode[0]);
+        }
+      }
+    }
+  }
+
+  public void testRandomWords() throws IOException {
+    testRandomWords(1000, 5 * RANDOM_MULTIPLIER);
+    //testRandomWords(20, 100);
+  }
+
+  private String inputModeToString(int mode) {
+    if (mode == 0) {
+      return "utf8";
+    } else {
+      return "utf32";
+    }
+  }
+
+  private void testRandomWords(int maxNumWords, int numIter) throws IOException {
+    for(int iter=0;iter<numIter;iter++) {
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter " + iter);
+      }
+      for(int inputMode=0;inputMode<2;inputMode++) {
+        final int numWords = random.nextInt(maxNumWords+1);
+        Set<IntsRef> termsSet = new HashSet<IntsRef>();
+        IntsRef[] terms = new IntsRef[numWords];
+        while(termsSet.size() < numWords) {
+          final String term = getRandomString();
+          termsSet.add(toIntsRef(term, inputMode));
+        }
+        doTest(inputMode, termsSet.toArray(new IntsRef[termsSet.size()]));
+      }
+    }
+  }
+
+  static String getRandomString() {
+    final String term;
+    if (random.nextBoolean()) {
+      term = _TestUtil.randomRealisticUnicodeString(random);
+    } else {
+      // we want to mix in limited-alphabet symbols so
+      // we get more sharing of the nodes given how few
+      // terms we are testing...
+      term = simpleRandomString(random);
+    }
+    return term;
+  }
+
+  @Nightly
+  public void testBigSet() throws IOException {
+    testRandomWords(50000, RANDOM_MULTIPLIER);
+  }
+
+  private static String inputToString(int inputMode, IntsRef term) {
+    if (inputMode == 0) {
+      // utf8
+      return toBytesRef(term).utf8ToString() + " " + term;
+    } else {
+      // utf32
+      return UnicodeUtil.newString(term.ints, term.offset, term.length) + " " + term;
+    }
+  }
+
+  // Build FST for all unique terms in the test line docs
+  // file, up until a time limit
+  public void testRealTerms() throws Exception {
+
+    if (CodecProvider.getDefault().getDefaultFieldCodec().equals("SimpleText")) {
+      // no
+      CodecProvider.getDefault().setDefaultFieldCodec("Standard");
+    }
+
+    final LineFileDocs docs = new LineFileDocs(random);
+    final int RUN_TIME_SEC = LuceneTestCase.TEST_NIGHTLY ? 100 : 1;
+    final IndexWriterConfig conf = newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(-1).setRAMBufferSizeMB(64);
+    final File tempDir = _TestUtil.getTempDir("fstlines");
+    final MockDirectoryWrapper dir = new MockDirectoryWrapper(random, FSDirectory.open(tempDir));
+    final IndexWriter writer = new IndexWriter(dir, conf);
+    writer.setInfoStream(VERBOSE ? System.out : null);
+    final long stopTime = System.currentTimeMillis() + RUN_TIME_SEC * 1000;
+    Document doc;
+    int docCount = 0;
+    while((doc = docs.nextDoc()) != null && System.currentTimeMillis() < stopTime) {
+      writer.addDocument(doc);
+      docCount++;
+    }
+    IndexReader r = IndexReader.open(writer, true);
+    writer.close();
+    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(random.nextBoolean());
+    Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
+
+    boolean storeOrd = random.nextBoolean();
+    if (VERBOSE) {
+      if (storeOrd) {
+        System.out.println("FST stores ord");
+      } else {
+        System.out.println("FST stores docFreq");
+      }
+    }
+    Terms terms = MultiFields.getTerms(r, "body");
+    if (terms != null) {
+      final TermsEnum termsEnum = terms.iterator();
+      if (VERBOSE) {
+        System.out.println("TEST: got termsEnum=" + termsEnum);
+      }
+      BytesRef term;
+      int ord = 0;
+      while((term = termsEnum.next()) != null) {
+        if (ord == 0) {
+          try {
+            termsEnum.ord();
+          } catch (UnsupportedOperationException uoe) {
+            if (VERBOSE) {
+              System.out.println("TEST: codec doesn't support ord; FST stores docFreq");
+            }
+            storeOrd = false;
+          }
+        }
+        final int output;
+        if (storeOrd) {
+          output = ord;
+        } else {
+          output = termsEnum.docFreq();
+        }
+        builder.add(term, outputs.get(output));
+        ord++;
+        if (ord % 100000 == 0 && LuceneTestCase.TEST_NIGHTLY) {
+          System.out.println(ord + " terms...");
+        }
+      }
+      final FST<Long> fst = builder.finish();
+      if (VERBOSE) {
+        System.out.println("FST: " + docCount + " docs; " + ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs;" + " " + fst.sizeInBytes() + " bytes");
+      }
+
+      if (ord > 0) {
+        // Now confirm BytesRefFSTEnum and TermsEnum act the
+        // same:
+        final BytesRefFSTEnum<Long> fstEnum = new BytesRefFSTEnum<Long>(fst);
+        for(int iter=0;iter<1000*RANDOM_MULTIPLIER;iter++) {
+          final BytesRef randomTerm = new BytesRef(getRandomString());
+        
+          if (VERBOSE) {
+            System.out.println("TEST: seek " + randomTerm.utf8ToString() + " " + randomTerm);
+          }
+
+          final TermsEnum.SeekStatus seekResult = termsEnum.seek(randomTerm);
+          final BytesRefFSTEnum.InputOutput fstSeekResult = fstEnum.seekCeil(randomTerm);
+
+          if (seekResult == TermsEnum.SeekStatus.END) {
+            assertNull("got " + (fstSeekResult == null ? "null" : fstSeekResult.input.utf8ToString()) + " but expected null", fstSeekResult);
+          } else {
+            assertSame(termsEnum, fstEnum, storeOrd);
+            for(int nextIter=0;nextIter<10;nextIter++) {
+              if (VERBOSE) {
+                System.out.println("TEST: next");
+                if (storeOrd) {
+                  System.out.println("  ord=" + termsEnum.ord());
+                }
+              }
+              if (termsEnum.next() != null) {
+                if (VERBOSE) {
+                  System.out.println("  term=" + termsEnum.term().utf8ToString());
+                }
+                assertNotNull(fstEnum.next());
+                assertSame(termsEnum, fstEnum, storeOrd);
+              } else {
+                if (VERBOSE) {
+                  System.out.println("  end!");
+                }
+                BytesRefFSTEnum.InputOutput<Long> nextResult = fstEnum.next();
+                if (nextResult != null) {
+                  System.out.println("expected null but got: input=" + nextResult.input.utf8ToString() + " output=" + outputs.outputToString(nextResult.output));
+                  fail();
+                }
+                break;
+              }
+            }
+          }
+        }
+      }
+    }
+
+    r.close();
+    dir.close();
+  }
+
+  private void assertSame(TermsEnum termsEnum, BytesRefFSTEnum fstEnum, boolean storeOrd) throws Exception {
+    if (termsEnum.term() == null) {
+      assertNull(fstEnum.current());
+    } else {
+      assertNotNull(fstEnum.current());
+      assertEquals(termsEnum.term().utf8ToString() + " != " + fstEnum.current().input.utf8ToString(), termsEnum.term(), fstEnum.current().input);
+      if (storeOrd) {
+        // fst stored the ord
+        assertEquals(termsEnum.ord(), ((Long) fstEnum.current().output).longValue());
+      } else {
+        // fst stored the docFreq
+        assertEquals(termsEnum.docFreq(), (int) (((Long) fstEnum.current().output).longValue()));
+      }
+    }
+  }
+
+  private static abstract class VisitTerms<T> {
+    private final String dirOut;
+    private final String wordsFileIn;
+    private int inputMode;
+    private final Outputs<T> outputs;
+    private final Builder<T> builder;
+
+    public VisitTerms(String dirOut, String wordsFileIn, int inputMode, int prune, Outputs<T> outputs) {
+      this.dirOut = dirOut;
+      this.wordsFileIn = wordsFileIn;
+      this.inputMode = inputMode;
+      this.outputs = outputs;
+      
+      builder = new Builder<T>(inputMode == 0 ? FST.INPUT_TYPE.BYTE1 : FST.INPUT_TYPE.BYTE4, 0, prune, prune == 0, outputs);
+    }
+
+    protected abstract T getOutput(IntsRef input, int ord) throws IOException;
+
+    public void run(int limit, boolean verify) throws IOException {
+      BufferedReader is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
+      try {
+        final IntsRef intsRef = new IntsRef(10);
+        long tStart = System.currentTimeMillis();
+        int ord = 0;
+        while(true) {
+          String w = is.readLine();
+          if (w == null) {
+            break;
+          }
+          toIntsRef(w, inputMode, intsRef);
+          builder.add(intsRef,
+                      getOutput(intsRef, ord));
+
+          ord++;
+          if (ord % 500000 == 0) {
+            System.out.println(
+                String.format(Locale.ENGLISH, 
+                    "%6.2fs: %9d...", ((System.currentTimeMillis() - tStart) / 1000.0), ord));
+          }
+          if (ord >= limit) {
+            break;
+          }
+        }
+
+        assert builder.getTermCount() == ord;
+        final FST<T> fst = builder.finish();
+        if (fst == null) {
+          System.out.println("FST was fully pruned!");
+          System.exit(0);
+        }
+
+        if (dirOut == null)
+          return;
+
+        System.out.println(ord + " terms; " + fst.getNodeCount() + " nodes; " + fst.getArcCount() + " arcs; " + fst.getArcWithOutputCount() + " arcs w/ output; tot size " + fst.sizeInBytes());
+        if (fst.getNodeCount() < 100) {
+          Writer w = new OutputStreamWriter(new FileOutputStream("out.dot"), "UTF-8");
+          Util.toDot(fst, w, false, false);
+          w.close();
+          System.out.println("Wrote FST to out.dot");
+        }
+
+        Directory dir = FSDirectory.open(new File(dirOut));
+        IndexOutput out = dir.createOutput("fst.bin");
+        fst.save(out);
+        out.close();
+
+        System.out.println("Saved FST to fst.bin.");
+
+        if (!verify) {
+          return;
+        }
+
+        System.out.println("\nNow verify...");
+
+        is.close();
+        is = new BufferedReader(new InputStreamReader(new FileInputStream(wordsFileIn), "UTF-8"), 65536);
+
+        ord = 0;
+        tStart = System.currentTimeMillis();
+        while(true) {
+          String w = is.readLine();
+          if (w == null) {
+            break;
+          }
+          toIntsRef(w, inputMode, intsRef);
+          T expected = getOutput(intsRef, ord);
+          T actual = Util.get(fst, intsRef);
+          if (actual == null) {
+            throw new RuntimeException("unexpected null output on input=" + w);
+          }
+          if (!actual.equals(expected)) {
+            throw new RuntimeException("wrong output (got " + outputs.outputToString(actual) + " but expected " + outputs.outputToString(expected) + ") on input=" + w);
+          }
+
+          ord++;
+          if (ord % 500000 == 0) {
+            System.out.println(((System.currentTimeMillis()-tStart)/1000.0) + "s: " + ord + "...");
+          }
+          if (ord >= limit) {
+            break;
+          }
+        }
+
+        double totSec = ((System.currentTimeMillis() - tStart)/1000.0);
+        System.out.println("Verify took " + totSec + " sec + (" + (int) ((totSec*1000000000/ord)) + " nsec per lookup)");
+
+      } finally {
+        is.close();
+      }
+    }
+  }
+
+  // java -cp build/classes/test:build/classes/java:lib/junit-4.7.jar org.apache.lucene.util.fst.TestFSTs /x/tmp/allTerms3.txt out
+  public static void main(String[] args) throws IOException {
+    int prune = 0;
+    int limit = Integer.MAX_VALUE;
+    int inputMode = 0;                             // utf8
+    boolean storeOrds = false;
+    boolean storeDocFreqs = false;
+    boolean verify = true;
+    
+    String wordsFileIn = null;
+    String dirOut = null;
+
+    int idx = 0;
+    while (idx < args.length) {
+      if (args[idx].equals("-prune")) {
+        prune = Integer.valueOf(args[1 + idx]);
+        idx++;
+      } else if (args[idx].equals("-limit")) {
+        limit = Integer.valueOf(args[1 + idx]);
+        idx++;
+      } else if (args[idx].equals("-utf8")) {
+        inputMode = 0;
+      } else if (args[idx].equals("-utf32")) {
+        inputMode = 1;
+      } else if (args[idx].equals("-docFreq")) {
+        storeDocFreqs = true;
+      } else if (args[idx].equals("-ords")) {
+        storeOrds = true;
+      } else if (args[idx].equals("-noverify")) {
+        verify = false;
+      } else if (args[idx].startsWith("-")) {
+        System.err.println("Unrecognized option: " + args[idx]);
+        System.exit(-1);
+      } else {
+        if (wordsFileIn == null) {
+          wordsFileIn = args[idx];
+        } else if (dirOut == null) {
+          dirOut = args[idx];
+        } else {
+          System.err.println("Too many arguments, expected: input [output]");
+          System.exit(-1);
+        }
+      }
+      idx++;
+    }
+    
+    if (wordsFileIn == null) {
+      System.err.println("No input file.");
+      System.exit(-1);
+    }
+
+    // ord benefits from share, docFreqs don't:
+
+    if (storeOrds && storeDocFreqs) {
+      // Store both ord & docFreq:
+      final PositiveIntOutputs o1 = PositiveIntOutputs.getSingleton(true);
+      final PositiveIntOutputs o2 = PositiveIntOutputs.getSingleton(false);
+      final PairOutputs<Long,Long> outputs = new PairOutputs<Long,Long>(o1, o2);
+      new VisitTerms<PairOutputs.Pair<Long,Long>>(dirOut, wordsFileIn, inputMode, prune, outputs) {
+        Random rand;
+        @Override
+        public PairOutputs.Pair<Long,Long> getOutput(IntsRef input, int ord) {
+          if (ord == 0) {
+            rand = new Random(17);
+          }
+          return new PairOutputs.Pair<Long,Long>(o1.get(ord),
+                                                 o2.get(_TestUtil.nextInt(rand, 1, 5000)));
+        }
+      }.run(limit, verify);
+    } else if (storeOrds) {
+      // Store only ords
+      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
+        @Override
+        public Long getOutput(IntsRef input, int ord) {
+          return outputs.get(ord);
+        }
+      }.run(limit, verify);
+    } else if (storeDocFreqs) {
+      // Store only docFreq
+      final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(false);
+      new VisitTerms<Long>(dirOut, wordsFileIn, inputMode, prune, outputs) {
+        Random rand;
+        @Override
+        public Long getOutput(IntsRef input, int ord) {
+          if (ord == 0) {
+            rand = new Random(17);
+          }
+          return outputs.get(_TestUtil.nextInt(rand, 1, 5000));
+        }
+      }.run(limit, verify);
+    } else {
+      // Store nothing
+      final NoOutputs outputs = NoOutputs.getSingleton();
+      final Object NO_OUTPUT = outputs.getNoOutput();
+      new VisitTerms<Object>(dirOut, wordsFileIn, inputMode, prune, outputs) {
+        @Override
+        public Object getOutput(IntsRef input, int ord) {
+          return NO_OUTPUT;
+        }
+      }.run(limit, verify);
+    }
+  }
+
+  public void testSingleString() throws Exception {
+    final Outputs<Object> outputs = NoOutputs.getSingleton();
+    final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
+    b.add(new BytesRef("foobar"), outputs.getNoOutput());
+    final BytesRefFSTEnum<Object> fstEnum = new BytesRefFSTEnum<Object>(b.finish());
+    assertNull(fstEnum.seekFloor(new BytesRef("foo")));
+    assertNull(fstEnum.seekCeil(new BytesRef("foobaz")));
+  }
+
+  public void testSimple() throws Exception {
+
+    // Get outputs -- passing true means FST will share
+    // (delta code) the outputs.  This should result in
+    // smaller FST if the outputs grow monotonically.  But
+    // if numbers are "random", false should give smaller
+    // final size:
+    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+
+    // Build an FST mapping BytesRef -> Long
+    final Builder<Long> builder = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
+
+    final BytesRef a = new BytesRef("a");
+    final BytesRef b = new BytesRef("b");
+    final BytesRef c = new BytesRef("c");
+
+    builder.add(a, outputs.get(17));
+    builder.add(b, outputs.get(42));
+    builder.add(c, outputs.get(13824324872317238L));
+
+    final FST<Long> fst = builder.finish();
+
+    assertEquals(13824324872317238L, (long) Util.get(fst, c));
+    assertEquals(42, (long) Util.get(fst, b));
+    assertEquals(17, (long) Util.get(fst, a));
+
+    BytesRefFSTEnum<Long> fstEnum = new BytesRefFSTEnum<Long>(fst);
+    BytesRefFSTEnum.InputOutput<Long> seekResult;
+    seekResult = fstEnum.seekFloor(a);
+    assertNotNull(seekResult);
+    assertEquals(17, (long) seekResult.output);
+
+    // goes to a
+    seekResult = fstEnum.seekFloor(new BytesRef("aa"));
+    assertNotNull(seekResult);
+    assertEquals(17, (long) seekResult.output);
+
+    // goes to b
+    seekResult = fstEnum.seekCeil(new BytesRef("aa"));
+    assertNotNull(seekResult);
+    assertEquals(b, seekResult.input);
+    assertEquals(42, (long) seekResult.output);
+  }
+
+  /**
+   * Test state expansion (array format) on close-to-root states. Creates
+   * synthetic input that has one expanded state on each level.
+   * 
+   * @see "https://issues.apache.org/jira/browse/LUCENE-2933" 
+   */
+  public void testExpandedCloseToRoot() throws Exception {
+    class SyntheticData {
+      FST<Object> compile(String[] lines) throws IOException {
+        final NoOutputs outputs = NoOutputs.getSingleton();
+        final Object nothing = outputs.getNoOutput();
+        final Builder<Object> b = new Builder<Object>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
+
+        int line = 0;
+        final BytesRef term = new BytesRef();
+        while (line < lines.length) {
+          String w = lines[line++];
+          if (w == null) {
+            break;
+          }
+          term.copy(w);
+          b.add(term, nothing);
+        }
+        
+        return b.finish();
+      }
+      
+      void generate(ArrayList<String> out, StringBuilder b, char from, char to,
+          int depth) {
+        if (depth == 0 || from == to) {
+          String seq = b.toString() + "_" + out.size() + "_end";
+          out.add(seq);
+        } else {
+          for (char c = from; c <= to; c++) {
+            b.append(c);
+            generate(out, b, from, c == to ? to : from, depth - 1);
+            b.deleteCharAt(b.length() - 1);
+          }
+        }
+      }
+
+      public int verifyStateAndBelow(FST<Object> fst, Arc<Object> arc, int depth) 
+        throws IOException {
+        if (fst.targetHasArcs(arc)) {
+          int childCount = 0;
+          for (arc = fst.readFirstTargetArc(arc, arc);; 
+               arc = fst.readNextArc(arc), childCount++)
+          {
+            boolean expanded = fst.isExpandedTarget(arc);
+            int children = verifyStateAndBelow(fst, new FST.Arc<Object>().copyFrom(arc), depth + 1);
+
+            assertEquals(
+                expanded,
+                (depth <= FST.FIXED_ARRAY_SHALLOW_DISTANCE && 
+                    children >= FST.FIXED_ARRAY_NUM_ARCS_SHALLOW) ||
+                 children >= FST.FIXED_ARRAY_NUM_ARCS_DEEP);
+            if (arc.isLast()) break;
+          }
+
+          return childCount;
+        }
+        return 0;
+      }
+    }
+
+    // Sanity check.
+    assertTrue(FST.FIXED_ARRAY_NUM_ARCS_SHALLOW < FST.FIXED_ARRAY_NUM_ARCS_DEEP);
+    assertTrue(FST.FIXED_ARRAY_SHALLOW_DISTANCE >= 0);
+
+    SyntheticData s = new SyntheticData();
+
+    ArrayList<String> out = new ArrayList<String>();
+    StringBuilder b = new StringBuilder();
+    s.generate(out, b, 'a', 'i', 10);
+    String[] input = out.toArray(new String[out.size()]);
+    Arrays.sort(input);
+    FST<Object> fst = s.compile(input);
+    FST.Arc<Object> arc = fst.getFirstArc(new FST.Arc<Object>());
+    s.verifyStateAndBelow(fst, arc, 1);
+  }
+
+  // Make sure raw FST can differentiate between final vs
+  // non-final end nodes
+  public void testNonFinalStopNodes() throws Exception {
+    final PositiveIntOutputs outputs = PositiveIntOutputs.getSingleton(true);
+    final Long nothing = outputs.getNoOutput();
+    final Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE1, 0, 0, true, outputs);
+
+    final FST<Long> fst = new FST<Long>(FST.INPUT_TYPE.BYTE1, outputs);
+
+    final Builder.UnCompiledNode<Long> rootNode = new Builder.UnCompiledNode<Long>(b, 0);
+
+    // Add final stop node
+    {
+      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
+      node.isFinal = true;
+      rootNode.addArc('a', node);
+      final Builder.CompiledNode frozen = new Builder.CompiledNode();
+      frozen.address = fst.addNode(node);
+      rootNode.arcs[0].nextFinalOutput = outputs.get(17);
+      rootNode.arcs[0].isFinal = true;
+      rootNode.arcs[0].output = nothing;
+      rootNode.arcs[0].target = frozen;
+    }
+
+    // Add non-final stop node
+    {
+      final Builder.UnCompiledNode<Long> node = new Builder.UnCompiledNode<Long>(b, 0);
+      rootNode.addArc('b', node);
+      final Builder.CompiledNode frozen = new Builder.CompiledNode();
+      frozen.address = fst.addNode(node);
+      rootNode.arcs[1].nextFinalOutput = nothing;
+      rootNode.arcs[1].output = outputs.get(42);
+      rootNode.arcs[1].target = frozen;
+    }
+
+    fst.finish(fst.addNode(rootNode));
+    
+    checkStopNodes(fst, outputs);
+
+    // Make sure it still works after save/load:
+    Directory dir = newDirectory();
+    IndexOutput out = dir.createOutput("fst");
+    fst.save(out);
+    out.close();
+
+    IndexInput in = dir.openInput("fst");
+    final FST<Long> fst2 = new FST<Long>(in, outputs);
+    checkStopNodes(fst2, outputs);
+    in.close();
+    dir.close();
+  }
+
+  private void checkStopNodes(FST<Long> fst, PositiveIntOutputs outputs) throws Exception {
+    final Long nothing = outputs.getNoOutput();
+    FST.Arc<Long> startArc = fst.getFirstArc(new FST.Arc<Long>());
+    assertEquals(nothing, startArc.output);
+    assertEquals(nothing, startArc.nextFinalOutput);
+
+    FST.Arc<Long> arc = fst.readFirstTargetArc(startArc, new FST.Arc<Long>());
+    assertEquals('a', arc.label);
+    assertEquals(17, arc.nextFinalOutput.longValue());
+    assertTrue(arc.isFinal());
+
+    arc = fst.readNextArc(arc);
+    assertEquals('b', arc.label);
+    assertFalse(arc.isFinal());
+    assertEquals(42, arc.output.longValue());
+  }
+}
diff --git a/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java b/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java
index 47d81ec..22f81b0 100644
--- a/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java
+++ b/modules/suggest/src/java/org/apache/lucene/search/suggest/fst/FSTLookup.java
@@ -15,11 +15,11 @@ import java.util.List;
 
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.automaton.fst.Builder;
-import org.apache.lucene.util.automaton.fst.FST;
-import org.apache.lucene.util.automaton.fst.FST.Arc;
-import org.apache.lucene.util.automaton.fst.NoOutputs;
-import org.apache.lucene.util.automaton.fst.Outputs;
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.FST.Arc;
+import org.apache.lucene.util.fst.NoOutputs;
+import org.apache.lucene.util.fst.Outputs;
 
 import org.apache.lucene.search.suggest.Lookup;
 import org.apache.lucene.search.suggest.tst.TSTLookup;

