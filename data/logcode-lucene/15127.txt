GitDiffStart: 9772db3703b03f6e4a167268b757dd863684564c | Fri Jul 22 13:24:17 2011 +0000
diff --git a/dev-tools/scripts/SOLR-2452.patch.hack.pl b/dev-tools/scripts/SOLR-2452.patch.hack.pl
index 873cbad..3b1d1d6 100755
--- a/dev-tools/scripts/SOLR-2452.patch.hack.pl
+++ b/dev-tools/scripts/SOLR-2452.patch.hack.pl
@@ -30,11 +30,20 @@ use strict;
 use warnings;
 
 my @moves = (
+    'solr/contrib/analysis-extras/src/test-files/solr-analysis-extras'
+ => 'solr/contrib/analysis-extras/src/test-files/analysis-extras/solr',
+
+    'solr/contrib/analysis-extras/src/test-files'
+ => 'solr/contrib/analysis-extras/src/test-files/analysis-extras',
+
     'solr/contrib/clustering/src/test/java'
  => 'solr/contrib/clustering/src/test',
 
+    'solr/contrib/clustering/src/test/resources/solr-clustering'
+ => 'solr/contrib/clustering/src/test-files/clustering/solr',
+
     'solr/contrib/clustering/src/test/resources'
- => 'solr/contrib/clustering/src/test-files',
+ => 'solr/contrib/clustering/src/test-files/clustering',
 
     'solr/contrib/clustering/src/main/java'
  => 'solr/contrib/clustering/src/java',
@@ -42,8 +51,11 @@ my @moves = (
     'solr/contrib/dataimporthandler/src/test/java'
  => 'solr/contrib/dataimporthandler/src/test',
 
+    'solr/contrib/dataimporthandler/src/test/resources/solr-dih'
+ => 'solr/contrib/dataimporthandler/src/test-files/dih/solr',
+
     'solr/contrib/dataimporthandler/src/test/resources'
- => 'solr/contrib/dataimporthandler/src/test-files',
+ => 'solr/contrib/dataimporthandler/src/test-files/dih',
 
     'solr/contrib/dataimporthandler/src/main/java'
  => 'solr/contrib/dataimporthandler/src/java',
@@ -54,8 +66,11 @@ my @moves = (
     'solr/contrib/dataimporthandler/src/extras/test/java'
  => 'solr/contrib/dataimporthandler-extras/src/test',
 
+    'solr/contrib/dataimporthandler/src/extras/test/resources/solr-dihextras'
+ => 'solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr',
+
     'solr/contrib/dataimporthandler/src/extras/test/resources'
- => 'solr/contrib/dataimporthandler-extras/src/test-files',
+ => 'solr/contrib/dataimporthandler-extras/src/test-files/dihextras',
 
     'solr/contrib/dataimporthandler/src/extras/main/java'
  => 'solr/contrib/dataimporthandler-extras/src/java',
@@ -63,8 +78,11 @@ my @moves = (
     'solr/contrib/extraction/src/test/java'
  => 'solr/contrib/extraction/src/test',
 
+    'solr/contrib/extraction/src/test/resources/solr-extraction'
+ => 'solr/contrib/extraction/src/test-files/extraction/solr',
+
     'solr/contrib/extraction/src/test/resources'
- => 'solr/contrib/extraction/src/test-files',
+ => 'solr/contrib/extraction/src/test-files/extraction',
 
     'solr/contrib/extraction/src/main/java'
  => 'solr/contrib/extraction/src/java',
@@ -72,8 +90,11 @@ my @moves = (
     'solr/contrib/uima/src/test/java'
  => 'solr/contrib/uima/src/test',
 
+    'solr/contrib/uima/src/test/resources/solr-uima'
+ => 'solr/contrib/uima/src/test-files/uima/solr',
+
     'solr/contrib/uima/src/test/resources'
- => 'solr/contrib/uima/src/test-files',
+ => 'solr/contrib/uima/src/test-files/uima',
 
     'solr/contrib/uima/src/main/java'
  => 'solr/contrib/uima/src/java',
@@ -82,13 +103,13 @@ my @moves = (
  => 'solr/contrib/uima/src/resources',
 
     'solr/src/test-files/books.csv'
- => 'solr/solrj/src/test-files/books.csv',
+ => 'solr/solrj/src/test-files/solrj/books.csv',
 
     'solr/src/test-files/sampleDateFacetResponse.xml'
- => 'solr/solrj/src/test-files/sampleDateFacetResponse.xml',
+ => 'solr/solrj/src/test-files/solrj/sampleDateFacetResponse.xml',
 
     'solr/src/test-files/solr/shared'
- => 'solr/solrj/src/test-files/solr/shared',
+ => 'solr/solrj/src/test-files/solrj/solr/shared',
 
     'solr/src/solrj'
  => 'solr/solrj/src/java',
@@ -150,19 +171,19 @@ my @moves = (
 
 my @copies = (
     'solr/core/src/test-files/README'
- => 'solr/solrj/src/test-files/README',
+ => 'solr/solrj/src/test-files/solrj/README',
 
     'solr/core/src/test-files/solr/crazy-path-to-schema.xml'
- => 'solr/solrj/src/test-files/solr/crazy-path-to-schema.xml',
+ => 'solr/solrj/src/test-files/solrj/solr/crazy-path-to-schema.xml',
 
     'solr/core/src/test-files/solr/conf/schema.xml'
- => 'solr/solrj/src/test-files/solr/conf/schema.xml',
+ => 'solr/solrj/src/test-files/solrj/solr/conf/schema.xml',
 
     'solr/core/src/test-files/solr/conf/schema-replication1.xml'
- => 'solr/solrj/src/test-files/solr/conf/schema-replication1.xml',
+ => 'solr/solrj/src/test-files/solrj/solr/conf/schema-replication1.xml',
 
     'solr/core/src/test-files/solr/conf/solrconfig-slave1.xml'
- => 'solr/solrj/src/test-files/solr/conf/solrconfig-slave1.xml',
+ => 'solr/solrj/src/test-files/solrj/solr/conf/solrconfig-slave1.xml',
 );
 
 my $diff;
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 5922eca..eab05b7 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -373,11 +373,12 @@ Bug Fixes
 Build
 ----------------------
 
-* SOLR-2452: Rewrote the Solr build system:
+* SOLR-2452,SOLR-2653,LUCENE-3323,SOLR-2659,LUCENE-3329,SOLR-2666:
+  Rewrote the Solr build system:
   - Integrated more fully with the Lucene build system: generalized the
     Lucene build system and eliminated duplication.
   - Converted all Solr contribs to the Lucene/Solr conventional src/ layout:
-    java/, resources/, test/, and test-files/.
+    java/, resources/, test/, and test-files/<contrib-name>.
   - Created a new Solr-internal module named "core" by moving the java/,
     test/, and test-files/ directories from solr/src/ to solr/core/src/.
   - Merged solr/src/webapp/src/ into solr/core/src/java/.
diff --git a/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/schema-icucollate.xml b/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/schema-icucollate.xml
new file mode 100644
index 0000000..3ec19c6
--- /dev/null
+++ b/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/schema-icucollate.xml
@@ -0,0 +1,59 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- Test schema file for CollationField -->
+
+<schema name="test" version="1.0">
+  <types>
+    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+
+    <!-- basic text field -->
+    <fieldtype name="text" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    
+    <fieldtype name="sort_ar_t"       class="solr.ICUCollationField" locale="ar"/>
+    <fieldtype name="sort_de_t"       class="solr.ICUCollationField" locale="de" strength="primary"/>
+    <fieldtype name="sort_tr_canon_t" class="solr.ICUCollationField" locale="tr" strength="primary"   decomposition="canonical"/>
+    <fieldtype name="sort_da_t"       class="solr.ICUCollationField" locale="da" strength="primary"/>
+    <fieldtype name="sort_custom_t"   class="solr.ICUCollationField" custom="customrules.dat" strength="primary"/>
+  </types>
+
+  <fields>
+    <field name="id" type="int" indexed="true" stored="true" multiValued="false" required="false"/>
+    <field name="text" type="text" indexed="true" stored="false"/>
+    <field name="sort_ar"       type="sort_ar_t"       indexed="true" stored="false" multiValued="false"/>
+    <field name="sort_de"       type="sort_de_t"       indexed="true" stored="false" multiValued="false"/>
+    <field name="sort_tr_canon" type="sort_tr_canon_t" indexed="true" stored="false" multiValued="false"/>
+    <field name="sort_da"       type="sort_da_t"       indexed="true" stored="false" multiValued="false"/>
+    <field name="sort_custom"   type="sort_custom_t"   indexed="true" stored="false" multiValued="false"/>
+  </fields>
+
+  <defaultSearchField>text</defaultSearchField>
+  <uniqueKey>id</uniqueKey>
+
+  <!-- copy our text to some sort fields with different orders -->
+  <copyField source="text" dest="sort_ar"/>
+  <copyField source="text" dest="sort_de"/>
+  <copyField source="text" dest="sort_tr_canon"/>
+  <copyField source="text" dest="sort_da"/>
+  <copyField source="text" dest="sort_custom"/>
+</schema>
diff --git a/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/solrconfig-icucollate.xml b/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/solrconfig-icucollate.xml
new file mode 100644
index 0000000..2c9b55c
--- /dev/null
+++ b/solr/contrib/analysis-extras/src/test-files/analysis-extras/solr/conf/solrconfig-icucollate.xml
@@ -0,0 +1,23 @@
+<?xml version="1.0" ?>
+
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+  <requestHandler name="standard" class="solr.StandardRequestHandler"></requestHandler>
+</config>
diff --git a/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/schema-icucollate.xml b/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/schema-icucollate.xml
deleted file mode 100644
index 3ec19c6..0000000
--- a/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/schema-icucollate.xml
+++ /dev/null
@@ -1,59 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- Test schema file for CollationField -->
-
-<schema name="test" version="1.0">
-  <types>
-    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-
-    <!-- basic text field -->
-    <fieldtype name="text" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    
-    <fieldtype name="sort_ar_t"       class="solr.ICUCollationField" locale="ar"/>
-    <fieldtype name="sort_de_t"       class="solr.ICUCollationField" locale="de" strength="primary"/>
-    <fieldtype name="sort_tr_canon_t" class="solr.ICUCollationField" locale="tr" strength="primary"   decomposition="canonical"/>
-    <fieldtype name="sort_da_t"       class="solr.ICUCollationField" locale="da" strength="primary"/>
-    <fieldtype name="sort_custom_t"   class="solr.ICUCollationField" custom="customrules.dat" strength="primary"/>
-  </types>
-
-  <fields>
-    <field name="id" type="int" indexed="true" stored="true" multiValued="false" required="false"/>
-    <field name="text" type="text" indexed="true" stored="false"/>
-    <field name="sort_ar"       type="sort_ar_t"       indexed="true" stored="false" multiValued="false"/>
-    <field name="sort_de"       type="sort_de_t"       indexed="true" stored="false" multiValued="false"/>
-    <field name="sort_tr_canon" type="sort_tr_canon_t" indexed="true" stored="false" multiValued="false"/>
-    <field name="sort_da"       type="sort_da_t"       indexed="true" stored="false" multiValued="false"/>
-    <field name="sort_custom"   type="sort_custom_t"   indexed="true" stored="false" multiValued="false"/>
-  </fields>
-
-  <defaultSearchField>text</defaultSearchField>
-  <uniqueKey>id</uniqueKey>
-
-  <!-- copy our text to some sort fields with different orders -->
-  <copyField source="text" dest="sort_ar"/>
-  <copyField source="text" dest="sort_de"/>
-  <copyField source="text" dest="sort_tr_canon"/>
-  <copyField source="text" dest="sort_da"/>
-  <copyField source="text" dest="sort_custom"/>
-</schema>
diff --git a/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/solrconfig-icucollate.xml b/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/solrconfig-icucollate.xml
deleted file mode 100644
index 2c9b55c..0000000
--- a/solr/contrib/analysis-extras/src/test-files/solr-analysis-extras/conf/solrconfig-icucollate.xml
+++ /dev/null
@@ -1,23 +0,0 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-  <requestHandler name="standard" class="solr.StandardRequestHandler"></requestHandler>
-</config>
diff --git a/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java b/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java
index ddf9d0f..63fcfbc 100644
--- a/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java
+++ b/solr/contrib/analysis-extras/src/test/org/apache/solr/schema/TestICUCollationField.java
@@ -74,8 +74,8 @@ public class TestICUCollationField extends SolrTestCaseJ4 {
     confDir.mkdir();
     
     // copy over configuration files
-    FileUtils.copyFile(getFile("solr-analysis-extras/conf/solrconfig-icucollate.xml"), new File(confDir, "solrconfig.xml"));
-    FileUtils.copyFile(getFile("solr-analysis-extras/conf/schema-icucollate.xml"), new File(confDir, "schema.xml"));
+    FileUtils.copyFile(getFile("analysis-extras/solr/conf/solrconfig-icucollate.xml"), new File(confDir, "solrconfig.xml"));
+    FileUtils.copyFile(getFile("analysis-extras/solr/conf/schema-icucollate.xml"), new File(confDir, "schema.xml"));
     
     // generate custom collation rules (DIN 5007-2), saving to customrules.dat
     RuleBasedCollator baseCollator = (RuleBasedCollator) Collator.getInstance(new ULocale("de", "DE"));
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stoplabels.mt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stoplabels.mt
new file mode 100644
index 0000000..b9d9a14
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stoplabels.mt
@@ -0,0 +1 @@
+customsolrstoplabel
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stopwords.mt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stopwords.mt
new file mode 100644
index 0000000..eb3f5f7
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/carrot2/stopwords.mt
@@ -0,0 +1 @@
+customsolrstopword
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stoplabels.mt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stoplabels.mt
new file mode 100644
index 0000000..e6d8a57
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stoplabels.mt
@@ -0,0 +1 @@
+customsolrstoplabelcustomdir
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stopwords.mt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stopwords.mt
new file mode 100644
index 0000000..c7a3464
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/clustering/custom/stopwords.mt
@@ -0,0 +1 @@
+customsolrstopwordcustomdir
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/mapping-ISOLatin1Accent.txt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/mapping-ISOLatin1Accent.txt
new file mode 100644
index 0000000..ede7742
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/mapping-ISOLatin1Accent.txt
@@ -0,0 +1,246 @@
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# Syntax:
+#   "source" => "target"
+#     "source".length() > 0 (source cannot be empty.)
+#     "target".length() >= 0 (target can be empty.)
+
+# example:
+#   "?" => "A"
+#   "\u00C0" => "A"
+#   "\u00C0" => "\u0041"
+#   "?" => "ss"
+#   "\t" => " "
+#   "\n" => ""
+
+# ? => A
+"\u00C0" => "A"
+
+# ? => A
+"\u00C1" => "A"
+
+# ? => A
+"\u00C2" => "A"
+
+# ? => A
+"\u00C3" => "A"
+
+# ? => A
+"\u00C4" => "A"
+
+# ? => A
+"\u00C5" => "A"
+
+# ? => AE
+"\u00C6" => "AE"
+
+# ? => C
+"\u00C7" => "C"
+
+# ? => E
+"\u00C8" => "E"
+
+# ? => E
+"\u00C9" => "E"
+
+# ? => E
+"\u00CA" => "E"
+
+# ? => E
+"\u00CB" => "E"
+
+# ? => I
+"\u00CC" => "I"
+
+# ? => I
+"\u00CD" => "I"
+
+# ? => I
+"\u00CE" => "I"
+
+# ? => I
+"\u00CF" => "I"
+
+# Ä² => IJ
+"\u0132" => "IJ"
+
+# ? => D
+"\u00D0" => "D"
+
+# ? => N
+"\u00D1" => "N"
+
+# ? => O
+"\u00D2" => "O"
+
+# ? => O
+"\u00D3" => "O"
+
+# ? => O
+"\u00D4" => "O"
+
+# ? => O
+"\u00D5" => "O"
+
+# ? => O
+"\u00D6" => "O"
+
+# ? => O
+"\u00D8" => "O"
+
+# ? => OE
+"\u0152" => "OE"
+
+# ?
+"\u00DE" => "TH"
+
+# ? => U
+"\u00D9" => "U"
+
+# ? => U
+"\u00DA" => "U"
+
+# ? => U
+"\u00DB" => "U"
+
+# ? => U
+"\u00DC" => "U"
+
+# ? => Y
+"\u00DD" => "Y"
+
+# Å¸ => Y
+"\u0178" => "Y"
+
+# ? => a
+"\u00E0" => "a"
+
+# Ã¡ => a
+"\u00E1" => "a"
+
+# Ã¢ => a
+"\u00E2" => "a"
+
+# Ã£ => a
+"\u00E3" => "a"
+
+# Ã¤ => a
+"\u00E4" => "a"
+
+# Ã¥ => a
+"\u00E5" => "a"
+
+# Ã¦ => ae
+"\u00E6" => "ae"
+
+# Ã§ => c
+"\u00E7" => "c"
+
+# Ã¨ => e
+"\u00E8" => "e"
+
+# Ã© => e
+"\u00E9" => "e"
+
+# Ãª => e
+"\u00EA" => "e"
+
+# Ã« => e
+"\u00EB" => "e"
+
+# Ã¬ => i
+"\u00EC" => "i"
+
+# Ã­ => i
+"\u00ED" => "i"
+
+# Ã® => i
+"\u00EE" => "i"
+
+# Ã¯ => i
+"\u00EF" => "i"
+
+# Ä³ => ij
+"\u0133" => "ij"
+
+# Ã° => d
+"\u00F0" => "d"
+
+# Ã± => n
+"\u00F1" => "n"
+
+# Ã² => o
+"\u00F2" => "o"
+
+# Ã³ => o
+"\u00F3" => "o"
+
+# Ã´ => o
+"\u00F4" => "o"
+
+# Ãµ => o
+"\u00F5" => "o"
+
+# Ã¶ => o
+"\u00F6" => "o"
+
+# Ã¸ => o
+"\u00F8" => "o"
+
+# ? => oe
+"\u0153" => "oe"
+
+# ? => ss
+"\u00DF" => "ss"
+
+# Ã¾ => th
+"\u00FE" => "th"
+
+# Ã¹ => u
+"\u00F9" => "u"
+
+# Ãº => u
+"\u00FA" => "u"
+
+# Ã» => u
+"\u00FB" => "u"
+
+# Ã¼ => u
+"\u00FC" => "u"
+
+# Ã½ => y
+"\u00FD" => "y"
+
+# Ã¿ => y
+"\u00FF" => "y"
+
+# ï¬? => ff
+"\uFB00" => "ff"
+
+# ï¬? => fi
+"\uFB01" => "fi"
+
+# ï¬? => fl
+"\uFB02" => "fl"
+
+# ï¬? => ffi
+"\uFB03" => "ffi"
+
+# ï¬? => ffl
+"\uFB04" => "ffl"
+
+# ï¬? => ft
+"\uFB05" => "ft"
+
+# ï¬? => st
+"\uFB06" => "st"
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/protwords.txt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/protwords.txt
new file mode 100644
index 0000000..1dfc0ab
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/protwords.txt
@@ -0,0 +1,21 @@
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+# Use a protected word file to protect against the stemmer reducing two
+# unrelated words to the same base word.
+
+# Some non-words that normally won't be encountered,
+# just to test that they won't be stemmed.
+dontstems
+zwhacky
+
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/schema.xml b/solr/contrib/clustering/src/test-files/clustering/solr/conf/schema.xml
new file mode 100644
index 0000000..1a00116
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/schema.xml
@@ -0,0 +1,350 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="example" version="1.1">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!-- Case insensitive stop word removal.
+             enablePositionIncrements=true ensures that a 'gap' is left to
+             allow for accurate phrase queries.
+        -->
+        <filter class="solr.StopFilterFactory"
+                ignoreCase="true"
+                words="stopwords.txt"
+                enablePositionIncrements="true"
+                />
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+
+    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
+         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
+    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.EnglishMinimalStemFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!--
+     Setup simple analysis for spell checking
+     -->
+    <fieldType name="textSpell" class="solr.TextField" positionIncrementGap="100" >
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- This is an example of using the KeywordTokenizer along
+         With various TokenFilterFactories to produce a sortable field
+         that does not include some properties of the source text
+      -->
+    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
+      <analyzer>
+        <!-- KeywordTokenizer does no actual tokenizing, so the entire
+             input string is preserved as a single token
+          -->
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+        <!-- The LowerCase TokenFilter does what you expect, which can be
+             when you want your sorting to be case insensitive
+          -->
+        <filter class="solr.LowerCaseFilterFactory" />
+        <!-- The TrimFilter removes any leading or trailing whitespace -->
+        <filter class="solr.TrimFilterFactory" />
+        <!-- The PatternReplaceFilter gives you the flexibility to use
+             Java Regular expression to replace any sequence of characters
+             matching a pattern with an arbitrary replacement string, 
+             which may include back refrences to portions of the orriginal
+             string matched by the pattern.
+             
+             See the Java Regular Expression documentation for more
+             infomation on pattern and replacement string syntax.
+             
+             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
+          -->
+        <filter class="solr.PatternReplaceFilterFactory"
+                pattern="([^a-z])" replacement="" replace="all"
+        />
+      </analyzer>
+    </fieldType>
+
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <!-- Valid attributes for fields:
+     name: mandatory - the name for the field
+     type: mandatory - the name of a previously defined type from the <types> section
+     indexed: true if this field should be indexed (searchable or sortable)
+     stored: true if this field should be retrievable
+     compressed: [false] if this field should be stored using gzip compression
+       (this will only apply if the field type is compressable; among
+       the standard field types, only TextField and StrField are)
+     multiValued: true if this field may contain multiple values per document
+     omitNorms: (expert) set to true to omit the norms associated with
+       this field (this disables length normalization and index-time
+       boosting for the field, and saves some memory).  Only full-text
+       fields or fields that need an index-time boost need norms.
+     termVectors: [false] set to true to store the term vector for a given field.
+       When using MoreLikeThis, fields used for similarity should be stored for 
+       best performance.
+   -->
+
+   <field name="id" type="string" indexed="true" stored="true" required="true" />
+   <field name="url" type="string" indexed="true" stored="true" required="true" />
+
+   <field name="title" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="snippet" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="body" type="text" indexed="true" stored="true" multiValued="true"/>
+   <!-- catchall field, containing all other searchable text fields (implemented
+        via copyField further on in this schema  -->
+   <field name="text" type="text" indexed="true" stored="false" multiValued="true"/>
+   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
+        will be used if the name matches any of the patterns.
+        RESTRICTION: the glob-like pattern in the name attribute must have
+        a "*" only at the start or the end.
+        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
+        Longer patterns will be matched first.  if equal size patterns
+        both match, the first appearing in the schema will be used.  -->
+   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
+   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
+   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
+
+   <dynamicField name="random*" type="random" />
+
+   <!-- uncomment the following to ignore any fields that don't already match an existing 
+        field name or dynamic field, rather than reporting them as an error. 
+        alternately, change the type="ignored" to some other type e.g. "text" if you want 
+        unknown fields indexed and/or stored by default --> 
+   <!--dynamicField name="*" type="ignored" /-->
+   
+ </fields>
+
+ <!-- Field to use to determine and enforce document uniqueness. 
+      Unless this field is marked with required="false", it will be a required field
+   -->
+ <uniqueKey>id</uniqueKey>
+
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>text</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+  <!-- copyField commands copy one field to another at the time a document
+        is added to the index.  It's used either to index the same field differently,
+        or to add multiple fields to the same field for easier/faster searching.  -->
+  <copyField source="url" dest="text"/>
+   <copyField source="title" dest="text"/>
+   <copyField source="body" dest="text"/>
+  <copyField source="snippet" dest="text"/>
+
+ <!-- Similarity is the scoring routine for each document vs. a query.
+      A custom similarity may be specified here, but the default is fine
+      for most applications.  -->
+ <!-- <similarity class="org.apache.lucene.search.DefaultSimilarity"/> -->
+ <!-- ... OR ...
+      Specify a SimilarityFactory class name implementation
+      allowing parameters to be used.
+ -->
+ <!--
+ <similarity class="com.example.solr.CustomSimilarityFactory">
+   <str name="paramkey">param value</str>
+ </similarity>
+ -->
+
+
+</schema>
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/solrconfig.xml b/solr/contrib/clustering/src/test-files/clustering/solr/conf/solrconfig.xml
new file mode 100644
index 0000000..c4bd3f4
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/solrconfig.xml
@@ -0,0 +1,539 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+  <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      This option specifies which Lucene LockFactory implementation to use.
+      
+      single = SingleInstanceLockFactory - suggested for a read-only index
+               or when there is no possibility of another process trying
+               to modify the index.
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      (For backwards compatibility with Solr 1.2, 'simple' is the default
+       if not specified.)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+  
+  <!--	Enables JMX if and only if an existing MBeanServer is found, use 
+  		this if you want to configure JMX through JVM parameters. Remove
+  		this to disable exposing Solr configuration and statistics to JMX.
+  		
+		If you want to connect to a particular server, specify the agentId
+		e.g. <jmx agentId="myAgent" />
+		
+		If you want to start a new MBeanServer, specify the serviceUrl
+		e.g <jmx serviceurl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr" />
+		
+		For more details see http://wiki.apache.org/solr/SolrJmx
+  -->
+  <jmx />
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Perform a <commit/> automatically under certain conditions:
+         maxDocs - number of updates since last commit is greater than this
+         maxTime - oldest uncommited update (in ms) is this long ago
+    <autoCommit> 
+      <maxDocs>10000</maxDocs>
+      <maxTime>1000</maxTime> 
+    </autoCommit>
+    -->
+
+    <!-- The RunExecutableListener executes an external command.
+         exe - the name of the executable to run
+         dir - dir to use as the current working directory. default="."
+         wait - the calling thread waits until the executable returns. default="true"
+         args - the arguments to pass to the program.  default=nothing
+         env - environment variables to set.  default=nothing
+      -->
+    <!-- A postCommit event is fired after every commit or optimize command
+    <listener event="postCommit" class="solr.RunExecutableListener">
+      <str name="exe">solr/bin/snapshooter</str>
+      <str name="dir">.</str>
+      <bool name="wait">true</bool>
+      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
+      <arr name="env"> <str>MYVAR=val1</str> </arr>
+    </listener>
+    -->
+    <!-- A postOptimize event is fired only after every optimize command, useful
+         in conjunction with index distribution to only distribute optimized indicies 
+    <listener event="postOptimize" class="solr.RunExecutableListener">
+      <str name="exe">snapshooter</str>
+      <str name="dir">solr/bin</str>
+      <bool name="wait">true</bool>
+    </listener>
+    -->
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="128"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="32"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static firstSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>2</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <!-- <httpCaching never304="true"> -->
+    <httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr">
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.SearchHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+    <arr name="last-components">
+      <str>clustering</str>
+    </arr>
+  </requestHandler>
+
+
+  <requestHandler name="docClustering" class="solr.SearchHandler">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!--
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+    <arr name="last-components">
+      <str>doc-clustering</str>
+    </arr>
+  </requestHandler>
+
+  <!-- DisMaxRequestHandler allows easy searching across multiple fields
+       for simple user-entered phrases.  It's implementation is now
+       just the standard SearchHandler with a default query type
+       of "dismax". 
+       see http://wiki.apache.org/solr/DisMaxRequestHandler
+   -->
+
+
+  <searchComponent class="org.apache.solr.handler.clustering.ClusteringComponent" name="clustering">
+    <!-- Declare an engine -->
+    <lst name="engine">
+      <!-- The name, only one can be named "default" -->
+      <str name="name">default</str>
+      <str name="carrot.algorithm">org.carrot2.clustering.lingo.LingoClusteringAlgorithm</str>
+    </lst>
+    <lst name="engine">
+      <str name="name">stc</str>
+      <str name="carrot.algorithm">org.carrot2.clustering.stc.STCClusteringAlgorithm</str>
+    </lst>
+    <lst name="engine">
+      <str name="name">mock</str>
+      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.MockClusteringAlgorithm</str>
+    </lst>
+    <lst name="engine">
+      <str name="name">lexical-resource-check</str>
+      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.LexicalResourcesCheckClusteringAlgorithm</str>
+    </lst>
+    <lst name="engine">
+      <str name="name">lexical-resource-check-custom-resource-dir</str>
+      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.LexicalResourcesCheckClusteringAlgorithm</str>
+      <str name="carrot.lexicalResourcesDir">clustering/custom</str>
+    </lst>
+  </searchComponent>
+
+  <searchComponent class="org.apache.solr.handler.clustering.ClusteringComponent" name="doc-clustering">
+    <!-- Declare an engine -->
+    <lst name="engine">
+      <!-- The name, only one can be named "default" -->
+      <str name="name">mock</str>
+      <str name="classname">org.apache.solr.handler.clustering.MockDocumentClusteringEngine</str>
+    </lst>
+  </searchComponent>
+ 
+
+  
+
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />
+
+  <!-- CSV update handler, loaded on demand -->
+  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy" />
+
+
+  <!-- 
+   Admin Handlers - This will register all the standard admin RequestHandlers.  Adding 
+   this single handler is equivolent to registering:
+   
+  <requestHandler name="/admin/luke"       class="org.apache.solr.handler.admin.LukeRequestHandler" />
+  <requestHandler name="/admin/system"     class="org.apache.solr.handler.admin.SystemInfoHandler" />
+  <requestHandler name="/admin/plugins"    class="org.apache.solr.handler.admin.PluginInfoHandler" />
+  <requestHandler name="/admin/threads"    class="org.apache.solr.handler.admin.ThreadDumpHandler" />
+  <requestHandler name="/admin/properties" class="org.apache.solr.handler.admin.PropertiesRequestHandler" />
+  <requestHandler name="/admin/file"       class="org.apache.solr.handler.admin.ShowFileRequestHandler" >
+  
+  If you wish to hide files under ${solr.home}/conf, explicitly register the ShowFileRequestHandler using:
+  <requestHandler name="/admin/file" class="org.apache.solr.handler.admin.ShowFileRequestHandler" >
+    <lst name="invariants">
+     <str name="hidden">synonyms.txt</str> 
+     <str name="hidden">anotherfile.txt</str> 
+    </lst>
+  </requestHandler>
+  -->
+  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
+  
+  <!-- Echo the request contents back to the client -->
+  <requestHandler name="/debug/dump" class="solr.DumpRequestHandler" >
+    <lst name="defaults">
+     <str name="echoParams">explicit</str> <!-- for all params (including the default etc) use: 'all' -->
+     <str name="echoHandler">true</str>
+    </lst>
+  </requestHandler>
+  
+  <highlighting>
+   <!-- Configure the standard fragmenter -->
+   <!-- This could most likely be commented out in the "default" case -->
+   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
+    <lst name="defaults">
+     <int name="hl.fragsize">100</int>
+    </lst>
+   </fragmenter>
+
+   <!-- A regular-expression-based fragmenter (f.i., for sentence extraction) -->
+   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
+    <lst name="defaults">
+      <!-- slightly smaller fragsizes work better because of slop -->
+      <int name="hl.fragsize">70</int>
+      <!-- allow 50% slop on fragment sizes -->
+      <float name="hl.regex.slop">0.5</float> 
+      <!-- a basic sentence pattern -->
+      <str name="hl.regex.pattern">[-\w ,/\n\"']{20,200}</str>
+    </lst>
+   </fragmenter>
+   
+   <!-- Configure the standard formatter -->
+   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
+    <lst name="defaults">
+     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
+     <str name="hl.simple.post"><![CDATA[</em>]]></str>
+    </lst>
+   </formatter>
+  </highlighting>
+  
+  
+  <!-- queryResponseWriter plugins... query responses will be written using the
+    writer specified by the 'wt' request parameter matching the name of a registered
+    writer.
+    The "default" writer is the default and will be used if 'wt' is not specified 
+    in the request. XMLResponseWriter will be used if nothing is specified here.
+    The json, python, and ruby writers are also available by default.
+
+    <queryResponseWriter name="xml" class="solr.XMLResponseWriter" default="true"/>
+    <queryResponseWriter name="json" class="solr.JSONResponseWriter"/>
+    <queryResponseWriter name="python" class="solr.PythonResponseWriter"/>
+    <queryResponseWriter name="ruby" class="solr.RubyResponseWriter"/>
+    <queryResponseWriter name="php" class="solr.PHPResponseWriter"/>
+    <queryResponseWriter name="phps" class="solr.PHPSerializedResponseWriter"/>
+
+    <queryResponseWriter name="custom" class="com.example.MyResponseWriter"/>
+  -->
+
+  <!-- XSLT response writer transforms the XML output by any xslt file found
+       in Solr's conf/xslt directory.  Changes to xslt files are checked for
+       every xsltCacheLifetimeSeconds.  
+   -->
+  <queryResponseWriter name="xslt" class="solr.XSLTResponseWriter">
+    <int name="xsltCacheLifetimeSeconds">5</int>
+  </queryResponseWriter> 
+
+
+  <!-- example of registering a query parser
+  <queryParser name="lucene" class="org.apache.solr.search.LuceneQParserPlugin"/>
+  -->
+
+  <!-- example of registering a custom function parser 
+  <valueSourceParser name="myfunc" class="com.mycompany.MyValueSourceParser" />
+  -->
+    
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>solr</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/spellings.txt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/spellings.txt
new file mode 100644
index 0000000..d7ede6f
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/spellings.txt
@@ -0,0 +1,2 @@
+pizza
+history
\ No newline at end of file
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/stopwords.txt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/stopwords.txt
new file mode 100644
index 0000000..54f0b99
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/stopwords.txt
@@ -0,0 +1,59 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+# a couple of test stopwords to test that the words are really being
+# configured from this file:
+stopworda
+stopwordb
+
+#Standard english stop words taken from Lucene's StopAnalyzer
+a
+an
+and
+are
+as
+at
+be
+but
+by
+for
+if
+in
+into
+is
+it
+no
+not
+of
+on
+or
+s
+such
+t
+that
+the
+their
+then
+there
+these
+they
+this
+to
+was
+will
+with
+solrownstopword
+
diff --git a/solr/contrib/clustering/src/test-files/clustering/solr/conf/synonyms.txt b/solr/contrib/clustering/src/test-files/clustering/solr/conf/synonyms.txt
new file mode 100644
index 0000000..b0e31cb
--- /dev/null
+++ b/solr/contrib/clustering/src/test-files/clustering/solr/conf/synonyms.txt
@@ -0,0 +1,31 @@
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+#some test synonym mappings unlikely to appear in real input text
+aaa => aaaa
+bbb => bbbb1 bbbb2
+ccc => cccc1,cccc2
+a\=>a => b\=>b
+a\,a => b\,b
+fooaaa,baraaa,bazaaa
+
+# Some synonym groups specific to this example
+GB,gib,gigabyte,gigabytes
+MB,mib,megabyte,megabytes
+Television, Televisions, TV, TVs
+#notice we use "gib" instead of "GiB" so any WordDelimiterFilter coming
+#after us won't split it into two words.
+
+# Synonym mappings can be used for spelling correction too
+pixima => pixma
+
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stoplabels.mt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stoplabels.mt
deleted file mode 100644
index b9d9a14..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stoplabels.mt
+++ /dev/null
@@ -1 +0,0 @@
-customsolrstoplabel
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stopwords.mt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stopwords.mt
deleted file mode 100644
index eb3f5f7..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/carrot2/stopwords.mt
+++ /dev/null
@@ -1 +0,0 @@
-customsolrstopword
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stoplabels.mt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stoplabels.mt
deleted file mode 100644
index e6d8a57..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stoplabels.mt
+++ /dev/null
@@ -1 +0,0 @@
-customsolrstoplabelcustomdir
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stopwords.mt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stopwords.mt
deleted file mode 100644
index c7a3464..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/clustering/custom/stopwords.mt
+++ /dev/null
@@ -1 +0,0 @@
-customsolrstopwordcustomdir
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/mapping-ISOLatin1Accent.txt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/mapping-ISOLatin1Accent.txt
deleted file mode 100644
index ede7742..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/mapping-ISOLatin1Accent.txt
+++ /dev/null
@@ -1,246 +0,0 @@
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# Syntax:
-#   "source" => "target"
-#     "source".length() > 0 (source cannot be empty.)
-#     "target".length() >= 0 (target can be empty.)
-
-# example:
-#   "?" => "A"
-#   "\u00C0" => "A"
-#   "\u00C0" => "\u0041"
-#   "?" => "ss"
-#   "\t" => " "
-#   "\n" => ""
-
-# ? => A
-"\u00C0" => "A"
-
-# ? => A
-"\u00C1" => "A"
-
-# ? => A
-"\u00C2" => "A"
-
-# ? => A
-"\u00C3" => "A"
-
-# ? => A
-"\u00C4" => "A"
-
-# ? => A
-"\u00C5" => "A"
-
-# ? => AE
-"\u00C6" => "AE"
-
-# ? => C
-"\u00C7" => "C"
-
-# ? => E
-"\u00C8" => "E"
-
-# ? => E
-"\u00C9" => "E"
-
-# ? => E
-"\u00CA" => "E"
-
-# ? => E
-"\u00CB" => "E"
-
-# ? => I
-"\u00CC" => "I"
-
-# ? => I
-"\u00CD" => "I"
-
-# ? => I
-"\u00CE" => "I"
-
-# ? => I
-"\u00CF" => "I"
-
-# Ä² => IJ
-"\u0132" => "IJ"
-
-# ? => D
-"\u00D0" => "D"
-
-# ? => N
-"\u00D1" => "N"
-
-# ? => O
-"\u00D2" => "O"
-
-# ? => O
-"\u00D3" => "O"
-
-# ? => O
-"\u00D4" => "O"
-
-# ? => O
-"\u00D5" => "O"
-
-# ? => O
-"\u00D6" => "O"
-
-# ? => O
-"\u00D8" => "O"
-
-# ? => OE
-"\u0152" => "OE"
-
-# ?
-"\u00DE" => "TH"
-
-# ? => U
-"\u00D9" => "U"
-
-# ? => U
-"\u00DA" => "U"
-
-# ? => U
-"\u00DB" => "U"
-
-# ? => U
-"\u00DC" => "U"
-
-# ? => Y
-"\u00DD" => "Y"
-
-# Å¸ => Y
-"\u0178" => "Y"
-
-# ? => a
-"\u00E0" => "a"
-
-# Ã¡ => a
-"\u00E1" => "a"
-
-# Ã¢ => a
-"\u00E2" => "a"
-
-# Ã£ => a
-"\u00E3" => "a"
-
-# Ã¤ => a
-"\u00E4" => "a"
-
-# Ã¥ => a
-"\u00E5" => "a"
-
-# Ã¦ => ae
-"\u00E6" => "ae"
-
-# Ã§ => c
-"\u00E7" => "c"
-
-# Ã¨ => e
-"\u00E8" => "e"
-
-# Ã© => e
-"\u00E9" => "e"
-
-# Ãª => e
-"\u00EA" => "e"
-
-# Ã« => e
-"\u00EB" => "e"
-
-# Ã¬ => i
-"\u00EC" => "i"
-
-# Ã­ => i
-"\u00ED" => "i"
-
-# Ã® => i
-"\u00EE" => "i"
-
-# Ã¯ => i
-"\u00EF" => "i"
-
-# Ä³ => ij
-"\u0133" => "ij"
-
-# Ã° => d
-"\u00F0" => "d"
-
-# Ã± => n
-"\u00F1" => "n"
-
-# Ã² => o
-"\u00F2" => "o"
-
-# Ã³ => o
-"\u00F3" => "o"
-
-# Ã´ => o
-"\u00F4" => "o"
-
-# Ãµ => o
-"\u00F5" => "o"
-
-# Ã¶ => o
-"\u00F6" => "o"
-
-# Ã¸ => o
-"\u00F8" => "o"
-
-# ? => oe
-"\u0153" => "oe"
-
-# ? => ss
-"\u00DF" => "ss"
-
-# Ã¾ => th
-"\u00FE" => "th"
-
-# Ã¹ => u
-"\u00F9" => "u"
-
-# Ãº => u
-"\u00FA" => "u"
-
-# Ã» => u
-"\u00FB" => "u"
-
-# Ã¼ => u
-"\u00FC" => "u"
-
-# Ã½ => y
-"\u00FD" => "y"
-
-# Ã¿ => y
-"\u00FF" => "y"
-
-# ï¬? => ff
-"\uFB00" => "ff"
-
-# ï¬? => fi
-"\uFB01" => "fi"
-
-# ï¬? => fl
-"\uFB02" => "fl"
-
-# ï¬? => ffi
-"\uFB03" => "ffi"
-
-# ï¬? => ffl
-"\uFB04" => "ffl"
-
-# ï¬? => ft
-"\uFB05" => "ft"
-
-# ï¬? => st
-"\uFB06" => "st"
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/protwords.txt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/protwords.txt
deleted file mode 100644
index 1dfc0ab..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/protwords.txt
+++ /dev/null
@@ -1,21 +0,0 @@
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-# Use a protected word file to protect against the stemmer reducing two
-# unrelated words to the same base word.
-
-# Some non-words that normally won't be encountered,
-# just to test that they won't be stemmed.
-dontstems
-zwhacky
-
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/schema.xml b/solr/contrib/clustering/src/test-files/solr-clustering/conf/schema.xml
deleted file mode 100644
index 1a00116..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/schema.xml
+++ /dev/null
@@ -1,350 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="example" version="1.1">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!-- Case insensitive stop word removal.
-             enablePositionIncrements=true ensures that a 'gap' is left to
-             allow for accurate phrase queries.
-        -->
-        <filter class="solr.StopFilterFactory"
-                ignoreCase="true"
-                words="stopwords.txt"
-                enablePositionIncrements="true"
-                />
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-
-    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
-         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
-    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.EnglishMinimalStemFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!--
-     Setup simple analysis for spell checking
-     -->
-    <fieldType name="textSpell" class="solr.TextField" positionIncrementGap="100" >
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- This is an example of using the KeywordTokenizer along
-         With various TokenFilterFactories to produce a sortable field
-         that does not include some properties of the source text
-      -->
-    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
-      <analyzer>
-        <!-- KeywordTokenizer does no actual tokenizing, so the entire
-             input string is preserved as a single token
-          -->
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-        <!-- The LowerCase TokenFilter does what you expect, which can be
-             when you want your sorting to be case insensitive
-          -->
-        <filter class="solr.LowerCaseFilterFactory" />
-        <!-- The TrimFilter removes any leading or trailing whitespace -->
-        <filter class="solr.TrimFilterFactory" />
-        <!-- The PatternReplaceFilter gives you the flexibility to use
-             Java Regular expression to replace any sequence of characters
-             matching a pattern with an arbitrary replacement string, 
-             which may include back refrences to portions of the orriginal
-             string matched by the pattern.
-             
-             See the Java Regular Expression documentation for more
-             infomation on pattern and replacement string syntax.
-             
-             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
-          -->
-        <filter class="solr.PatternReplaceFilterFactory"
-                pattern="([^a-z])" replacement="" replace="all"
-        />
-      </analyzer>
-    </fieldType>
-
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <!-- Valid attributes for fields:
-     name: mandatory - the name for the field
-     type: mandatory - the name of a previously defined type from the <types> section
-     indexed: true if this field should be indexed (searchable or sortable)
-     stored: true if this field should be retrievable
-     compressed: [false] if this field should be stored using gzip compression
-       (this will only apply if the field type is compressable; among
-       the standard field types, only TextField and StrField are)
-     multiValued: true if this field may contain multiple values per document
-     omitNorms: (expert) set to true to omit the norms associated with
-       this field (this disables length normalization and index-time
-       boosting for the field, and saves some memory).  Only full-text
-       fields or fields that need an index-time boost need norms.
-     termVectors: [false] set to true to store the term vector for a given field.
-       When using MoreLikeThis, fields used for similarity should be stored for 
-       best performance.
-   -->
-
-   <field name="id" type="string" indexed="true" stored="true" required="true" />
-   <field name="url" type="string" indexed="true" stored="true" required="true" />
-
-   <field name="title" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="snippet" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="body" type="text" indexed="true" stored="true" multiValued="true"/>
-   <!-- catchall field, containing all other searchable text fields (implemented
-        via copyField further on in this schema  -->
-   <field name="text" type="text" indexed="true" stored="false" multiValued="true"/>
-   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
-        will be used if the name matches any of the patterns.
-        RESTRICTION: the glob-like pattern in the name attribute must have
-        a "*" only at the start or the end.
-        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
-        Longer patterns will be matched first.  if equal size patterns
-        both match, the first appearing in the schema will be used.  -->
-   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
-   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
-   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
-
-   <dynamicField name="random*" type="random" />
-
-   <!-- uncomment the following to ignore any fields that don't already match an existing 
-        field name or dynamic field, rather than reporting them as an error. 
-        alternately, change the type="ignored" to some other type e.g. "text" if you want 
-        unknown fields indexed and/or stored by default --> 
-   <!--dynamicField name="*" type="ignored" /-->
-   
- </fields>
-
- <!-- Field to use to determine and enforce document uniqueness. 
-      Unless this field is marked with required="false", it will be a required field
-   -->
- <uniqueKey>id</uniqueKey>
-
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>text</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-  <!-- copyField commands copy one field to another at the time a document
-        is added to the index.  It's used either to index the same field differently,
-        or to add multiple fields to the same field for easier/faster searching.  -->
-  <copyField source="url" dest="text"/>
-   <copyField source="title" dest="text"/>
-   <copyField source="body" dest="text"/>
-  <copyField source="snippet" dest="text"/>
-
- <!-- Similarity is the scoring routine for each document vs. a query.
-      A custom similarity may be specified here, but the default is fine
-      for most applications.  -->
- <!-- <similarity class="org.apache.lucene.search.DefaultSimilarity"/> -->
- <!-- ... OR ...
-      Specify a SimilarityFactory class name implementation
-      allowing parameters to be used.
- -->
- <!--
- <similarity class="com.example.solr.CustomSimilarityFactory">
-   <str name="paramkey">param value</str>
- </similarity>
- -->
-
-
-</schema>
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/solrconfig.xml b/solr/contrib/clustering/src/test-files/solr-clustering/conf/solrconfig.xml
deleted file mode 100644
index c4bd3f4..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/solrconfig.xml
+++ /dev/null
@@ -1,539 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-  <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      This option specifies which Lucene LockFactory implementation to use.
-      
-      single = SingleInstanceLockFactory - suggested for a read-only index
-               or when there is no possibility of another process trying
-               to modify the index.
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      (For backwards compatibility with Solr 1.2, 'simple' is the default
-       if not specified.)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-  
-  <!--	Enables JMX if and only if an existing MBeanServer is found, use 
-  		this if you want to configure JMX through JVM parameters. Remove
-  		this to disable exposing Solr configuration and statistics to JMX.
-  		
-		If you want to connect to a particular server, specify the agentId
-		e.g. <jmx agentId="myAgent" />
-		
-		If you want to start a new MBeanServer, specify the serviceUrl
-		e.g <jmx serviceurl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr" />
-		
-		For more details see http://wiki.apache.org/solr/SolrJmx
-  -->
-  <jmx />
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Perform a <commit/> automatically under certain conditions:
-         maxDocs - number of updates since last commit is greater than this
-         maxTime - oldest uncommited update (in ms) is this long ago
-    <autoCommit> 
-      <maxDocs>10000</maxDocs>
-      <maxTime>1000</maxTime> 
-    </autoCommit>
-    -->
-
-    <!-- The RunExecutableListener executes an external command.
-         exe - the name of the executable to run
-         dir - dir to use as the current working directory. default="."
-         wait - the calling thread waits until the executable returns. default="true"
-         args - the arguments to pass to the program.  default=nothing
-         env - environment variables to set.  default=nothing
-      -->
-    <!-- A postCommit event is fired after every commit or optimize command
-    <listener event="postCommit" class="solr.RunExecutableListener">
-      <str name="exe">solr/bin/snapshooter</str>
-      <str name="dir">.</str>
-      <bool name="wait">true</bool>
-      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
-      <arr name="env"> <str>MYVAR=val1</str> </arr>
-    </listener>
-    -->
-    <!-- A postOptimize event is fired only after every optimize command, useful
-         in conjunction with index distribution to only distribute optimized indicies 
-    <listener event="postOptimize" class="solr.RunExecutableListener">
-      <str name="exe">snapshooter</str>
-      <str name="dir">solr/bin</str>
-      <bool name="wait">true</bool>
-    </listener>
-    -->
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="128"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="32"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static firstSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>2</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <!-- <httpCaching never304="true"> -->
-    <httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr">
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.SearchHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-    <arr name="last-components">
-      <str>clustering</str>
-    </arr>
-  </requestHandler>
-
-
-  <requestHandler name="docClustering" class="solr.SearchHandler">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!--
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-    <arr name="last-components">
-      <str>doc-clustering</str>
-    </arr>
-  </requestHandler>
-
-  <!-- DisMaxRequestHandler allows easy searching across multiple fields
-       for simple user-entered phrases.  It's implementation is now
-       just the standard SearchHandler with a default query type
-       of "dismax". 
-       see http://wiki.apache.org/solr/DisMaxRequestHandler
-   -->
-
-
-  <searchComponent class="org.apache.solr.handler.clustering.ClusteringComponent" name="clustering">
-    <!-- Declare an engine -->
-    <lst name="engine">
-      <!-- The name, only one can be named "default" -->
-      <str name="name">default</str>
-      <str name="carrot.algorithm">org.carrot2.clustering.lingo.LingoClusteringAlgorithm</str>
-    </lst>
-    <lst name="engine">
-      <str name="name">stc</str>
-      <str name="carrot.algorithm">org.carrot2.clustering.stc.STCClusteringAlgorithm</str>
-    </lst>
-    <lst name="engine">
-      <str name="name">mock</str>
-      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.MockClusteringAlgorithm</str>
-    </lst>
-    <lst name="engine">
-      <str name="name">lexical-resource-check</str>
-      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.LexicalResourcesCheckClusteringAlgorithm</str>
-    </lst>
-    <lst name="engine">
-      <str name="name">lexical-resource-check-custom-resource-dir</str>
-      <str name="carrot.algorithm">org.apache.solr.handler.clustering.carrot2.LexicalResourcesCheckClusteringAlgorithm</str>
-      <str name="carrot.lexicalResourcesDir">clustering/custom</str>
-    </lst>
-  </searchComponent>
-
-  <searchComponent class="org.apache.solr.handler.clustering.ClusteringComponent" name="doc-clustering">
-    <!-- Declare an engine -->
-    <lst name="engine">
-      <!-- The name, only one can be named "default" -->
-      <str name="name">mock</str>
-      <str name="classname">org.apache.solr.handler.clustering.MockDocumentClusteringEngine</str>
-    </lst>
-  </searchComponent>
- 
-
-  
-
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />
-
-  <!-- CSV update handler, loaded on demand -->
-  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy" />
-
-
-  <!-- 
-   Admin Handlers - This will register all the standard admin RequestHandlers.  Adding 
-   this single handler is equivolent to registering:
-   
-  <requestHandler name="/admin/luke"       class="org.apache.solr.handler.admin.LukeRequestHandler" />
-  <requestHandler name="/admin/system"     class="org.apache.solr.handler.admin.SystemInfoHandler" />
-  <requestHandler name="/admin/plugins"    class="org.apache.solr.handler.admin.PluginInfoHandler" />
-  <requestHandler name="/admin/threads"    class="org.apache.solr.handler.admin.ThreadDumpHandler" />
-  <requestHandler name="/admin/properties" class="org.apache.solr.handler.admin.PropertiesRequestHandler" />
-  <requestHandler name="/admin/file"       class="org.apache.solr.handler.admin.ShowFileRequestHandler" >
-  
-  If you wish to hide files under ${solr.home}/conf, explicitly register the ShowFileRequestHandler using:
-  <requestHandler name="/admin/file" class="org.apache.solr.handler.admin.ShowFileRequestHandler" >
-    <lst name="invariants">
-     <str name="hidden">synonyms.txt</str> 
-     <str name="hidden">anotherfile.txt</str> 
-    </lst>
-  </requestHandler>
-  -->
-  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
-  
-  <!-- Echo the request contents back to the client -->
-  <requestHandler name="/debug/dump" class="solr.DumpRequestHandler" >
-    <lst name="defaults">
-     <str name="echoParams">explicit</str> <!-- for all params (including the default etc) use: 'all' -->
-     <str name="echoHandler">true</str>
-    </lst>
-  </requestHandler>
-  
-  <highlighting>
-   <!-- Configure the standard fragmenter -->
-   <!-- This could most likely be commented out in the "default" case -->
-   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
-    <lst name="defaults">
-     <int name="hl.fragsize">100</int>
-    </lst>
-   </fragmenter>
-
-   <!-- A regular-expression-based fragmenter (f.i., for sentence extraction) -->
-   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
-    <lst name="defaults">
-      <!-- slightly smaller fragsizes work better because of slop -->
-      <int name="hl.fragsize">70</int>
-      <!-- allow 50% slop on fragment sizes -->
-      <float name="hl.regex.slop">0.5</float> 
-      <!-- a basic sentence pattern -->
-      <str name="hl.regex.pattern">[-\w ,/\n\"']{20,200}</str>
-    </lst>
-   </fragmenter>
-   
-   <!-- Configure the standard formatter -->
-   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
-    <lst name="defaults">
-     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
-     <str name="hl.simple.post"><![CDATA[</em>]]></str>
-    </lst>
-   </formatter>
-  </highlighting>
-  
-  
-  <!-- queryResponseWriter plugins... query responses will be written using the
-    writer specified by the 'wt' request parameter matching the name of a registered
-    writer.
-    The "default" writer is the default and will be used if 'wt' is not specified 
-    in the request. XMLResponseWriter will be used if nothing is specified here.
-    The json, python, and ruby writers are also available by default.
-
-    <queryResponseWriter name="xml" class="solr.XMLResponseWriter" default="true"/>
-    <queryResponseWriter name="json" class="solr.JSONResponseWriter"/>
-    <queryResponseWriter name="python" class="solr.PythonResponseWriter"/>
-    <queryResponseWriter name="ruby" class="solr.RubyResponseWriter"/>
-    <queryResponseWriter name="php" class="solr.PHPResponseWriter"/>
-    <queryResponseWriter name="phps" class="solr.PHPSerializedResponseWriter"/>
-
-    <queryResponseWriter name="custom" class="com.example.MyResponseWriter"/>
-  -->
-
-  <!-- XSLT response writer transforms the XML output by any xslt file found
-       in Solr's conf/xslt directory.  Changes to xslt files are checked for
-       every xsltCacheLifetimeSeconds.  
-   -->
-  <queryResponseWriter name="xslt" class="solr.XSLTResponseWriter">
-    <int name="xsltCacheLifetimeSeconds">5</int>
-  </queryResponseWriter> 
-
-
-  <!-- example of registering a query parser
-  <queryParser name="lucene" class="org.apache.solr.search.LuceneQParserPlugin"/>
-  -->
-
-  <!-- example of registering a custom function parser 
-  <valueSourceParser name="myfunc" class="com.mycompany.MyValueSourceParser" />
-  -->
-    
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>solr</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/spellings.txt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/spellings.txt
deleted file mode 100644
index d7ede6f..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/spellings.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-pizza
-history
\ No newline at end of file
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/stopwords.txt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/stopwords.txt
deleted file mode 100644
index 54f0b99..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/stopwords.txt
+++ /dev/null
@@ -1,59 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-# a couple of test stopwords to test that the words are really being
-# configured from this file:
-stopworda
-stopwordb
-
-#Standard english stop words taken from Lucene's StopAnalyzer
-a
-an
-and
-are
-as
-at
-be
-but
-by
-for
-if
-in
-into
-is
-it
-no
-not
-of
-on
-or
-s
-such
-t
-that
-the
-their
-then
-there
-these
-they
-this
-to
-was
-will
-with
-solrownstopword
-
diff --git a/solr/contrib/clustering/src/test-files/solr-clustering/conf/synonyms.txt b/solr/contrib/clustering/src/test-files/solr-clustering/conf/synonyms.txt
deleted file mode 100644
index b0e31cb..0000000
--- a/solr/contrib/clustering/src/test-files/solr-clustering/conf/synonyms.txt
+++ /dev/null
@@ -1,31 +0,0 @@
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-#some test synonym mappings unlikely to appear in real input text
-aaa => aaaa
-bbb => bbbb1 bbbb2
-ccc => cccc1,cccc2
-a\=>a => b\=>b
-a\,a => b\,b
-fooaaa,baraaa,bazaaa
-
-# Some synonym groups specific to this example
-GB,gib,gigabyte,gigabytes
-MB,mib,megabyte,megabytes
-Television, Televisions, TV, TVs
-#notice we use "gib" instead of "GiB" so any WordDelimiterFilter coming
-#after us won't split it into two words.
-
-# Synonym mappings can be used for spelling correction too
-pixima => pixma
-
diff --git a/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/AbstractClusteringTestCase.java b/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/AbstractClusteringTestCase.java
index c4fec5e..5e57017 100644
--- a/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/AbstractClusteringTestCase.java
+++ b/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/AbstractClusteringTestCase.java
@@ -28,7 +28,7 @@ public abstract class AbstractClusteringTestCase extends SolrTestCaseJ4 {
 
   @BeforeClass
   public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml", "schema.xml", "solr-clustering");
+    initCore("solrconfig.xml", "schema.xml", "clustering/solr");
     numberOfDocs = 0;
     for (String[] doc : DOCUMENTS) {
       assertNull(h.validateUpdate(adoc("id", Integer.toString(numberOfDocs), "url", doc[0], "title", doc[1], "snippet", doc[2])));
diff --git a/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/DistributedClusteringComponentTest.java b/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/DistributedClusteringComponentTest.java
index 758d829..41ccf23 100644
--- a/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/DistributedClusteringComponentTest.java
+++ b/solr/contrib/clustering/src/test/org/apache/solr/handler/clustering/DistributedClusteringComponentTest.java
@@ -25,8 +25,7 @@ public class DistributedClusteringComponentTest extends
 
   @Override
   public String getSolrHome() {
-    // TODO: this should work with just "solr-clustering"...
-    return getFile("solr-clustering").getAbsolutePath();
+    return "clustering/solr";
   }
 
   @Override
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr-word.pdf b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr-word.pdf
new file mode 100644
index 0000000..bd8b865
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr-word.pdf
@@ -0,0 +1,2 @@
+This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
+
\ No newline at end of file
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-schema-no-unique-key.xml b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-schema-no-unique-key.xml
new file mode 100644
index 0000000..b1ec8be
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-schema-no-unique-key.xml
@@ -0,0 +1,205 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.2">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <field name="title" type="string" indexed="true" stored="true"/>
+   <field name="author" type="string" indexed="true" stored="true" />
+   <field name="text" type="text" indexed="true" stored="true" />
+   
+ </fields>
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>text</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-solrconfig.xml
new file mode 100644
index 0000000..9f41933
--- /dev/null
+++ b/solr/contrib/dataimporthandler-extras/src/test-files/dihextras/solr/conf/dataimport-solrconfig.xml
@@ -0,0 +1,397 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert: Turn on Lucene's auto commit capability.
+
+     TODO: Add recommendations on why you would want to do this.
+
+     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
+
+     -->
+    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+  
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
+
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-schema-no-unique-key.xml b/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
deleted file mode 100644
index b1ec8be..0000000
--- a/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-schema-no-unique-key.xml
+++ /dev/null
@@ -1,205 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.2">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <field name="title" type="string" indexed="true" stored="true"/>
-   <field name="author" type="string" indexed="true" stored="true" />
-   <field name="text" type="text" indexed="true" stored="true" />
-   
- </fields>
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>text</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-solrconfig.xml
deleted file mode 100644
index 9f41933..0000000
--- a/solr/contrib/dataimporthandler-extras/src/test-files/solr-dihextras/conf/dataimport-solrconfig.xml
+++ /dev/null
@@ -1,397 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert: Turn on Lucene's auto commit capability.
-
-     TODO: Add recommendations on why you would want to do this.
-
-     NOTE: Despite the name, this value does not have any relation to Solr's autoCommit functionality
-
-     -->
-    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-  
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
-
diff --git a/solr/contrib/dataimporthandler-extras/src/test-files/solr-word.pdf b/solr/contrib/dataimporthandler-extras/src/test-files/solr-word.pdf
deleted file mode 100644
index bd8b865..0000000
--- a/solr/contrib/dataimporthandler-extras/src/test-files/solr-word.pdf
+++ /dev/null
@@ -1,2 +0,0 @@
-This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
-
\ No newline at end of file
diff --git a/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java b/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
index 7912c5f..61a0a09 100644
--- a/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
+++ b/solr/contrib/dataimporthandler-extras/src/test/org/apache/solr/handler/dataimport/TestTikaEntityProcessor.java
@@ -40,7 +40,7 @@ public class TestTikaEntityProcessor extends AbstractDataImportHandlerTestCase {
   "<dataConfig>" +
   "  <dataSource type=\"BinFileDataSource\"/>" +
   "  <document>" +
-  "    <entity processor=\"TikaEntityProcessor\" url=\"" + getFile("solr-word.pdf").getAbsolutePath() + "\" >" +
+  "    <entity processor=\"TikaEntityProcessor\" url=\"" + getFile("dihextras/solr-word.pdf").getAbsolutePath() + "\" >" +
   "      <field column=\"Author\" meta=\"true\" name=\"author\"/>" +
   "      <field column=\"title\" meta=\"true\" name=\"title\"/>" +
   "      <field column=\"text\"/>" +
@@ -58,7 +58,7 @@ public class TestTikaEntityProcessor extends AbstractDataImportHandlerTestCase {
 
   @BeforeClass
   public static void beforeClass() throws Exception {
-    initCore("dataimport-solrconfig.xml", "dataimport-schema-no-unique-key.xml", getFile("solr-dihextras").getAbsolutePath());
+    initCore("dataimport-solrconfig.xml", "dataimport-schema-no-unique-key.xml", getFile("dihextras/solr").getAbsolutePath());
   }
 
   @Test
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/contentstream-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/contentstream-solrconfig.xml
new file mode 100644
index 0000000..5070c0a
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/contentstream-solrconfig.xml
@@ -0,0 +1,398 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+    <lst name="defaults">
+      <str name="config">data-config.xml</str>
+
+    </lst>
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+  <updateRequestProcessorChain key="contentstream" default="true">
+    <processor class="org.apache.solr.handler.dataimport.AbstractDataImportHandlerTestCase$TestUpdateRequestProcessorFactory"/>
+    <processor class="solr.RunUpdateProcessorFactory"/>
+    <processor class="solr.LogUpdateProcessorFactory"/>
+  </updateRequestProcessorChain>
+
+</config>
+
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-datasource.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-datasource.xml
new file mode 100644
index 0000000..9566a54
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-datasource.xml
@@ -0,0 +1,9 @@
+<dataConfig>
+	<dataSource type="MockDataSource" />
+	<document>
+		<entity name="x" query="select * from x">
+			<field column="id" />
+			<field column="desc" />
+		</entity>
+	</document>
+</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-transformer.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-transformer.xml
new file mode 100644
index 0000000..c58b21d
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/data-config-with-transformer.xml
@@ -0,0 +1,10 @@
+<dataConfig>
+	<dataSource  type="MockDataSource" />
+	<dataSource name="mockDs" type="TestDocBuilder2$MockDataSource2" />
+	<document>
+		<entity name="x" query="select * from x" transformer="TestDocBuilder2$MockTransformer">
+			<field column="id" />
+			<field column="desc" />
+		</entity>
+	</document>
+</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataconfig-contentstream.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataconfig-contentstream.xml
new file mode 100644
index 0000000..7520e74
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataconfig-contentstream.xml
@@ -0,0 +1,10 @@
+<dataConfig>
+  <dataSource type="ContentStreamDataSource" name="c"/>
+  <document>
+    <entity name="b" dataSource="c" processor="XPathEntityProcessor"
+            forEach="/root/b">
+      <field column="desc" xpath="/root/b/c"/>
+      <field column="id" xpath="/root/b/id"/>
+    </entity>
+  </document>
+</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-nodatasource-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-nodatasource-solrconfig.xml
new file mode 100644
index 0000000..dbcb7ba
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-nodatasource-solrconfig.xml
@@ -0,0 +1,388 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+  
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
+
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-schema.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-schema.xml
new file mode 100644
index 0000000..a5017e9
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-schema.xml
@@ -0,0 +1,307 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.1">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+
+    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
+         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
+    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.EnglishMinimalStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- This is an example of using the KeywordTokenizer along
+         With various TokenFilterFactories to produce a sortable field
+         that does not include some properties of the source text
+      -->
+    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
+      <analyzer>
+        <!-- KeywordTokenizer does no actual tokenizing, so the entire
+             input string is preserved as a single token
+          -->
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+        <!-- The LowerCase TokenFilter does what you expect, which can be
+             when you want your sorting to be case insensitive
+          -->
+        <filter class="solr.LowerCaseFilterFactory" />
+        <!-- The TrimFilter removes any leading or trailing whitespace -->
+        <filter class="solr.TrimFilterFactory" />
+        <!-- The PatternReplaceFilter gives you the flexibility to use
+             Java Regular expression to replace any sequence of characters
+             matching a pattern with an arbitrary replacement string, 
+             which may include back refrences to portions of the orriginal
+             string matched by the pattern.
+             
+             See the Java Regular Expression documentation for more
+             infomation on pattern and replacement string syntax.
+             
+             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
+          -->
+        <filter class="solr.PatternReplaceFilterFactory"
+                pattern="([^a-z])" replacement="" replace="all"
+        />
+      </analyzer>
+    </fieldType>
+
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <!-- Valid attributes for fields:
+     name: mandatory - the name for the field
+     type: mandatory - the name of a previously defined type from the <types> section
+     indexed: true if this field should be indexed (searchable or sortable)
+     stored: true if this field should be retrievable
+     compressed: [false] if this field should be stored using gzip compression
+       (this will only apply if the field type is compressable; among
+       the standard field types, only TextField and StrField are)
+     multiValued: true if this field may contain multiple values per document
+     omitNorms: (expert) set to true to omit the norms associated with
+       this field (this disables length normalization and index-time
+       boosting for the field, and saves some memory).  Only full-text
+       fields or fields that need an index-time boost need norms.
+     termVectors: [false] set to true to store the term vector for a given field.
+       When using MoreLikeThis, fields used for similarity should be stored for 
+       best performance.
+   -->
+
+   <field name="id" type="string" indexed="true" stored="true" required="true" />
+   <field name="desc" type="string" indexed="true" stored="true" multiValued="true" />
+   
+   <field name="date" type="date" indexed="true" stored="true" />
+
+   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
+   
+
+   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
+        will be used if the name matches any of the patterns.
+        RESTRICTION: the glob-like pattern in the name attribute must have
+        a "*" only at the start or the end.
+        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
+        Longer patterns will be matched first.  if equal size patterns
+        both match, the first appearing in the schema will be used.  -->
+   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
+   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
+   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
+
+   <dynamicField name="random*" type="random" />
+
+   <!-- uncomment the following to ignore any fields that don't already match an existing 
+        field name or dynamic field, rather than reporting them as an error. 
+        alternately, change the type="ignored" to some other type e.g. "text" if you want 
+        unknown fields indexed and/or stored by default --> 
+   <!--dynamicField name="*" type="ignored" /-->
+   
+ </fields>
+
+ <!-- Field to use to determine and enforce document uniqueness. 
+      Unless this field is marked with required="false", it will be a required field
+   -->
+ <uniqueKey>id</uniqueKey>
+
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>desc</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solr_id-schema.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solr_id-schema.xml
new file mode 100644
index 0000000..4ef1117
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solr_id-schema.xml
@@ -0,0 +1,307 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--  
+ This is the Solr schema file. This file should be named "schema.xml" and
+ should be in the conf directory under the solr home
+ (i.e. ./solr/conf/schema.xml by default) 
+ or located where the classloader for the Solr webapp can find it.
+
+ This example schema is the recommended starting point for users.
+ It should be kept correct and concise, usable out-of-the-box.
+
+ For more information, on how to customize this file, please see
+ http://wiki.apache.org/solr/SchemaXml
+-->
+
+<schema name="test" version="1.1">
+  <!-- attribute "name" is the name of this schema and is only used for display purposes.
+       Applications should change this to reflect the nature of the search collection.
+       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
+       not normally be changed by applications.
+       1.0: multiValued attribute did not exist, all fields are multiValued by nature
+       1.1: multiValued attribute introduced, false by default -->
+
+  <types>
+    <!-- field type definitions. The "name" attribute is
+       just a label to be used by field definitions.  The "class"
+       attribute and any other attributes determine the real
+       behavior of the fieldType.
+         Class names starting with "solr" refer to java classes in the
+       org.apache.solr.analysis package.
+    -->
+
+    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
+       - StrField and TextField support an optional compressThreshold which
+       limits compression (if enabled in the derived fields) to values which
+       exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
+
+    <!-- The optional sortMissingLast and sortMissingFirst attributes are
+         currently supported on types that are sorted internally as strings.
+       - If sortMissingLast="true", then a sort on this field will cause documents
+         without the field to come after documents with the field,
+         regardless of the requested sort order (asc or desc).
+       - If sortMissingFirst="true", then a sort on this field will cause documents
+         without the field to come before documents with the field,
+         regardless of the requested sort order.
+       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
+         then default lucene sorting will be used which places docs without the
+         field first in an ascending sort and last in a descending sort.
+    -->    
+
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't support range queries, since the
+         lexicographic ordering isn't equal to the numeric ordering) -->
+    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
+    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
+    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
+    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
+
+
+    <!-- Numeric field types that manipulate the value into
+         a string value that isn't human-readable in its internal form,
+         but with a lexicographic ordering the same as the numeric ordering,
+         so that range queries work correctly. -->
+    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
+         is a more restricted form of the canonical representation of dateTime
+         http://www.w3.org/TR/xmlschema-2/#dateTime    
+         The trailing "Z" designates UTC time and is mandatory.
+         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
+         All other components are mandatory.
+
+         Expressions can also be used to denote calculations that should be
+         performed relative to "NOW" to determine the value, ie...
+
+               NOW/HOUR
+                  ... Round to the start of the current hour
+               NOW-1DAY
+                  ... Exactly 1 day prior to now
+               NOW/DAY+6MONTHS+3DAYS
+                  ... 6 months and 3 days in the future from the start of
+                      the current day
+                      
+         Consult the DateField javadocs for more information.
+      -->
+    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
+
+
+    <!-- The "RandomSortField" is not used to store or search any
+         data.  You can declare fields of this type it in your schema
+         to generate psuedo-random orderings of your docs for sorting 
+         purposes.  The ordering is generated based on the field name 
+         and the version of the index, As long as the index version
+         remains unchanged, and the same field name is reused,
+         the ordering of the docs will be consistent.  
+         If you want differend psuedo-random orderings of documents,
+         for the same version of the index, use a dynamicField and
+         change the name
+     -->
+    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
+
+    <!-- solr.TextField allows the specification of custom text analyzers
+         specified as a tokenizer and a list of token filters. Different
+         analyzers may be specified for indexing and querying.
+
+         The optional positionIncrementGap puts space between multiple fields of
+         this type on the same document, with the purpose of preventing false phrase
+         matching across fields.
+
+         For more info on customizing your analyzer chain, please see
+         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+     -->
+
+    <!-- One can also specify an existing Analyzer class that has a
+         default constructor via the class attribute on the analyzer element
+    <fieldType name="text_greek" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
+    </fieldType>
+    -->
+
+    <!-- A text field that only splits on whitespace for exact matching of words -->
+    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
+        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
+        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
+        Synonyms and stopwords are customized by external files, and stemming is enabled.
+        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
+        WordDelim parts) are removed.
+        -->
+    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!-- in this example, we will only use synonyms at query time
+        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
+        -->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+
+    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
+         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
+    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>-->
+        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.EnglishMinimalStemFilterFactory"/>-->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- This is an example of using the KeywordTokenizer along
+         With various TokenFilterFactories to produce a sortable field
+         that does not include some properties of the source text
+      -->
+    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
+      <analyzer>
+        <!-- KeywordTokenizer does no actual tokenizing, so the entire
+             input string is preserved as a single token
+          -->
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+        <!-- The LowerCase TokenFilter does what you expect, which can be
+             when you want your sorting to be case insensitive
+          -->
+        <filter class="solr.LowerCaseFilterFactory" />
+        <!-- The TrimFilter removes any leading or trailing whitespace -->
+        <filter class="solr.TrimFilterFactory" />
+        <!-- The PatternReplaceFilter gives you the flexibility to use
+             Java Regular expression to replace any sequence of characters
+             matching a pattern with an arbitrary replacement string, 
+             which may include back refrences to portions of the orriginal
+             string matched by the pattern.
+             
+             See the Java Regular Expression documentation for more
+             infomation on pattern and replacement string syntax.
+             
+             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
+          -->
+        <filter class="solr.PatternReplaceFilterFactory"
+                pattern="([^a-z])" replacement="" replace="all"
+        />
+      </analyzer>
+    </fieldType>
+
+    <!-- since fields of this type are by default not stored or indexed, any data added to 
+         them will be ignored outright 
+     --> 
+    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
+
+ </types>
+
+
+ <fields>
+   <!-- Valid attributes for fields:
+     name: mandatory - the name for the field
+     type: mandatory - the name of a previously defined type from the <types> section
+     indexed: true if this field should be indexed (searchable or sortable)
+     stored: true if this field should be retrievable
+     compressed: [false] if this field should be stored using gzip compression
+       (this will only apply if the field type is compressable; among
+       the standard field types, only TextField and StrField are)
+     multiValued: true if this field may contain multiple values per document
+     omitNorms: (expert) set to true to omit the norms associated with
+       this field (this disables length normalization and index-time
+       boosting for the field, and saves some memory).  Only full-text
+       fields or fields that need an index-time boost need norms.
+     termVectors: [false] set to true to store the term vector for a given field.
+       When using MoreLikeThis, fields used for similarity should be stored for 
+       best performance.
+   -->
+
+   <field name="solr_id" type="string" indexed="true" stored="true" required="true" />
+   <field name="desc" type="string" indexed="true" stored="true" multiValued="true" />
+   
+   <field name="date" type="date" indexed="true" stored="true" />
+
+   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
+   
+
+   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
+        will be used if the name matches any of the patterns.
+        RESTRICTION: the glob-like pattern in the name attribute must have
+        a "*" only at the start or the end.
+        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
+        Longer patterns will be matched first.  if equal size patterns
+        both match, the first appearing in the schema will be used.  -->
+   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
+   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
+   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
+
+   <dynamicField name="random*" type="random" />
+
+   <!-- uncomment the following to ignore any fields that don't already match an existing 
+        field name or dynamic field, rather than reporting them as an error. 
+        alternately, change the type="ignored" to some other type e.g. "text" if you want 
+        unknown fields indexed and/or stored by default --> 
+   <!--dynamicField name="*" type="ignored" /-->
+   
+ </fields>
+
+ <!-- Field to use to determine and enforce document uniqueness. 
+      Unless this field is marked with required="false", it will be a required field
+   -->
+ <uniqueKey>solr_id</uniqueKey>
+
+ <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+ <defaultSearchField>desc</defaultSearchField>
+
+ <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+ <solrQueryParser defaultOperator="OR"/>
+
+</schema>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solrconfig.xml
new file mode 100644
index 0000000..113e371
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/dataimport-solrconfig.xml
@@ -0,0 +1,394 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+
+  <!-- Used to specify an alternate directory to hold all index data
+       other than the default ./data under the Solr home.
+       If replication is in use, this should match the replication configuration. -->
+       <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
+
+    <!--
+      As long as Solr is the only process modifying your index, it is
+      safe to use Lucene's in process locking mechanism.  But you may
+      specify one of the other Lucene LockFactory implementations in
+      the event that you have a custom situation.
+      
+      none = NoLockFactory (typically only used with read only indexes)
+      single = SingleInstanceLockFactory (suggested)
+      native = NativeFSLockFactory
+      simple = SimpleFSLockFactory
+
+      ('simple' is the default for backwards compatibility with Solr 1.2)
+    -->
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <!-- If true, unlock any held write or commit locks on startup. 
+         This defeats the locking mechanism that allows multiple
+         processes to safely access a lucene index, and should be
+         used with care.
+         This is not needed if lock type is 'none' or 'single'
+     -->
+    <unlockOnStartup>false</unlockOnStartup>
+  </mainIndex>
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- A prefix of "solr." for class names is an alias that
+         causes solr to search appropriate packages, including
+         org.apache.solr.(search|update|request|core|analysis)
+     -->
+
+    <!-- Limit the number of deletions Solr will buffer during doc updating.
+        
+        Setting this lower can help bound memory use during indexing.
+    -->
+    <maxPendingDeletes>100000</maxPendingDeletes>
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or prefix queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.  -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+    
+    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
+         unordered sets of *all* documents that match a query.
+         When a new searcher is opened, its caches may be prepopulated
+         or "autowarmed" using data from caches in the old searcher.
+         autowarmCount is the number of items to prepopulate.  For LRUCache,
+         the autowarmed items will be the most recently accessed items.
+       Parameters:
+         class - the SolrCache implementation (currently only LRUCache)
+         size - the maximum number of entries in the cache
+         initialSize - the initial capacity (number of entries) of
+           the cache.  (seel java.util.HashMap)
+         autowarmCount - the number of entries to prepopulate from
+           and old cache.
+         -->
+    <filterCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+   <!-- queryResultCache caches results of searches - ordered lists of
+         document ids (DocList) based on a query, a sort, and the range
+         of documents requested.  -->
+    <queryResultCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
+       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
+    <documentCache
+      class="solr.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+
+    This can result in a significant speed improvement if the usual case is to
+    not load all stored fields, especially if the skipped fields are large compressed
+    text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!-- Example of a generic cache.  These caches may be accessed by name
+         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
+         The purpose is to enable easy caching of user/application level data.
+         The regenerator argument should be specified as an implementation
+         of solr.search.CacheRegenerator if autowarming is desired.  -->
+    <!--
+    <cache name="myUserCache"
+      class="solr.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator"
+      />
+    -->
+
+   <!-- An optimization that attempts to use a filter to satisfy a search.
+         If the requested sort does not include score, then the filterCache
+         will be checked for a filter matching the query. If found, the filter
+         will be used as the source of document ids, and then the sort will be
+         applied to that.
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+   -->
+
+   <!-- An optimization for use with the queryResultCache.  When a search
+         is requested, a superset of the requested number of document ids
+         are collected.  For example, if a search for a particular query
+         requests matching documents 10 through 19, and queryWindowSize is 50,
+         then documents 0 through 49 will be collected and cached.  Any further
+         requests in that range can be satisfied via the cache.  -->
+    <queryResultWindowSize>50</queryResultWindowSize>
+    
+    <!-- Maximum number of documents to cache for any entry in the
+         queryResultCache. -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!-- This entry enables an int hash representation for filters (DocSets)
+         when the number of items in the set is less than maxSize.  For smaller
+         sets, this representation is more memory efficient, more efficient to
+         iterate over, and faster to take intersections.  -->
+    <HashDocSet maxSize="3000" loadFactor="0.75"/>
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
+      </arr>
+    </listener>
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain autowarming data from. -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+      </arr>
+    </listener>
+
+    <!-- If a search request comes in and there is no current registered searcher,
+         then immediately register the still warming searcher and use it.  If
+         "false" then all requests will block until the first searcher is done
+         warming. -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!-- Maximum number of searchers that may be warming in the background
+      concurrently.  An error is returned if this limit is exceeded. Recommend
+      1-2 for read-only slaves, higher for masters w/o cache warming. -->
+    <maxWarmingSearchers>4</maxWarmingSearchers>
+
+  </query>
+
+  <!-- 
+    Let the dispatch filter handler /select?qt=XXX
+    handleSelect=true will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+    -->
+  <requestDispatcher handleSelect="true" >
+    <!--Make sure your system has some authentication before enabling remote streaming!  -->
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+        
+    <!-- Set HTTP caching related parameters (for proxy caches and clients).
+          
+         To get the behaviour of Solr 1.2 (ie: no caching related headers)
+         use the never304="true" option and do not specify a value for
+         <cacheControl>
+    -->
+    <httpCaching never304="true">
+    <!--httpCaching lastModifiedFrom="openTime"
+                 etagSeed="Solr"-->
+       <!-- lastModFrom="openTime" is the default, the Last-Modified value
+            (and validation against If-Modified-Since requests) will all be
+            relative to when the current Searcher was opened.
+            You can change it to lastModFrom="dirLastMod" if you want the
+            value to exactly corrispond to when the physical index was last
+            modified.
+               
+            etagSeed="..." is an option you can change to force the ETag
+            header (and validation against If-None-Match requests) to be
+            differnet even if the index has not changed (ie: when making
+            significant changes to your config file)
+
+            lastModifiedFrom and etagSeed are both ignored if you use the
+            never304="true" option.
+       -->
+       <!-- If you include a <cacheControl> directive, it will be used to
+            generate a Cache-Control header, as well as an Expires header
+            if the value contains "max-age="
+               
+            By default, no Cache-Control header is generated.
+
+            You can use the <cacheControl> option even if you have set
+            never304="true"
+       -->
+       <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+  
+      
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the path or the qt (query type) param.
+     Names starting with a '/' are accessed with the a path equal to the 
+     registered name.  Names without a leading '/' are accessed with:
+      http://host/app/select?qt=name
+     If no qt is defined, the requestHandler that declares default="true"
+     will be used.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
+    <!-- default values for query parameters -->
+     <lst name="defaults">
+       <str name="echoParams">explicit</str>
+       <!-- 
+       <int name="rows">10</int>
+       <str name="fl">*</str>
+       <str name="version">2.1</str>
+        -->
+     </lst>
+  </requestHandler>
+  
+  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
+  </requestHandler>
+    
+  <!--
+   
+   Search components are registered to SolrCore and used by Search Handlers
+   
+   By default, the following components are avaliable:
+    
+   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
+   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
+   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
+   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
+  
+   If you register a searchComponent to one of the standard names, that will be used instead.
+  
+   -->
+ 
+  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+    </lst>
+    <!--
+    By default, this will register the following components:
+    
+    <arr name="components">
+      <str>query</str>
+      <str>facet</str>
+      <str>mlt</str>
+      <str>highlight</str>
+      <str>debug</str>
+    </arr>
+    
+    To insert handlers before or after the 'standard' components, use:
+    
+    <arr name="first-components">
+      <str>first</str>
+    </arr>
+    
+    <arr name="last-components">
+      <str>last</str>
+    </arr>
+    
+    -->
+  </requestHandler>
+  
+  <!-- Update request handler.  
+  
+       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
+       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
+       The response format differs from solr1.1 formatting and returns a standard error code.
+       
+       To enable solr1.1 behavior, remove the /update handler or change its path
+       
+       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
+       only once.  This can not be changed for each request.
+    -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
+    <!--
+    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
+    -->
+  </requestHandler>
+  
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>*:*</defaultQuery>
+    
+    <!-- configure a healthcheck file for servers behind a loadbalancer
+    <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+  <updateRequestProcessorChain key="dataimport" default="true">
+    <processor class="org.apache.solr.handler.dataimport.AbstractDataImportHandlerTestCase$TestUpdateRequestProcessorFactory"/>
+    <processor class="solr.RunUpdateProcessorFactory"/>
+    <processor class="solr.LogUpdateProcessorFactory"/>
+  </updateRequestProcessorChain>
+
+</config>
+
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/protwords.txt b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/protwords.txt
new file mode 100644
index 0000000..7878147
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/protwords.txt
@@ -0,0 +1,20 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#use a protected word file to avoid stemming two
+#unrelated words to the same base word.
+#to test, we will use words that would normally obviously be stemmed.
+cats
+ridding
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/single-entity-data-config.xml b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/single-entity-data-config.xml
new file mode 100644
index 0000000..f9d3523
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/single-entity-data-config.xml
@@ -0,0 +1,9 @@
+<dataConfig>
+  <dataSource type="MockDataSource"/>
+	<document>
+		<entity name="x" query="select * from x">
+			<field column="id" />
+			<field column="desc" />
+		</entity>
+	</document>
+</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/stopwords.txt b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/stopwords.txt
new file mode 100644
index 0000000..688e307
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/stopwords.txt
@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+stopworda
+stopwordb
diff --git a/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/synonyms.txt b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/synonyms.txt
new file mode 100644
index 0000000..a7624f0
--- /dev/null
+++ b/solr/contrib/dataimporthandler/src/test-files/dih/solr/conf/synonyms.txt
@@ -0,0 +1,22 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+a => aa
+b => b1 b2
+c => c1,c2
+a\=>a => b\=>b
+a\,a => b\,b
+foo,bar,baz
+
+Television,TV,Televisions
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/contentstream-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/contentstream-solrconfig.xml
deleted file mode 100644
index 5070c0a..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/contentstream-solrconfig.xml
+++ /dev/null
@@ -1,398 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-    <lst name="defaults">
-      <str name="config">data-config.xml</str>
-
-    </lst>
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-  <updateRequestProcessorChain key="contentstream" default="true">
-    <processor class="org.apache.solr.handler.dataimport.AbstractDataImportHandlerTestCase$TestUpdateRequestProcessorFactory"/>
-    <processor class="solr.RunUpdateProcessorFactory"/>
-    <processor class="solr.LogUpdateProcessorFactory"/>
-  </updateRequestProcessorChain>
-
-</config>
-
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-datasource.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-datasource.xml
deleted file mode 100644
index 9566a54..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-datasource.xml
+++ /dev/null
@@ -1,9 +0,0 @@
-<dataConfig>
-	<dataSource type="MockDataSource" />
-	<document>
-		<entity name="x" query="select * from x">
-			<field column="id" />
-			<field column="desc" />
-		</entity>
-	</document>
-</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-transformer.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-transformer.xml
deleted file mode 100644
index c58b21d..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/data-config-with-transformer.xml
+++ /dev/null
@@ -1,10 +0,0 @@
-<dataConfig>
-	<dataSource  type="MockDataSource" />
-	<dataSource name="mockDs" type="TestDocBuilder2$MockDataSource2" />
-	<document>
-		<entity name="x" query="select * from x" transformer="TestDocBuilder2$MockTransformer">
-			<field column="id" />
-			<field column="desc" />
-		</entity>
-	</document>
-</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataconfig-contentstream.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataconfig-contentstream.xml
deleted file mode 100644
index 7520e74..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataconfig-contentstream.xml
+++ /dev/null
@@ -1,10 +0,0 @@
-<dataConfig>
-  <dataSource type="ContentStreamDataSource" name="c"/>
-  <document>
-    <entity name="b" dataSource="c" processor="XPathEntityProcessor"
-            forEach="/root/b">
-      <field column="desc" xpath="/root/b/c"/>
-      <field column="id" xpath="/root/b/id"/>
-    </entity>
-  </document>
-</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-nodatasource-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-nodatasource-solrconfig.xml
deleted file mode 100644
index dbcb7ba..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-nodatasource-solrconfig.xml
+++ /dev/null
@@ -1,388 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-  
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
-
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-schema.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-schema.xml
deleted file mode 100644
index a5017e9..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-schema.xml
+++ /dev/null
@@ -1,307 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.1">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-
-    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
-         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
-    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.EnglishMinimalStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- This is an example of using the KeywordTokenizer along
-         With various TokenFilterFactories to produce a sortable field
-         that does not include some properties of the source text
-      -->
-    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
-      <analyzer>
-        <!-- KeywordTokenizer does no actual tokenizing, so the entire
-             input string is preserved as a single token
-          -->
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-        <!-- The LowerCase TokenFilter does what you expect, which can be
-             when you want your sorting to be case insensitive
-          -->
-        <filter class="solr.LowerCaseFilterFactory" />
-        <!-- The TrimFilter removes any leading or trailing whitespace -->
-        <filter class="solr.TrimFilterFactory" />
-        <!-- The PatternReplaceFilter gives you the flexibility to use
-             Java Regular expression to replace any sequence of characters
-             matching a pattern with an arbitrary replacement string, 
-             which may include back refrences to portions of the orriginal
-             string matched by the pattern.
-             
-             See the Java Regular Expression documentation for more
-             infomation on pattern and replacement string syntax.
-             
-             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
-          -->
-        <filter class="solr.PatternReplaceFilterFactory"
-                pattern="([^a-z])" replacement="" replace="all"
-        />
-      </analyzer>
-    </fieldType>
-
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <!-- Valid attributes for fields:
-     name: mandatory - the name for the field
-     type: mandatory - the name of a previously defined type from the <types> section
-     indexed: true if this field should be indexed (searchable or sortable)
-     stored: true if this field should be retrievable
-     compressed: [false] if this field should be stored using gzip compression
-       (this will only apply if the field type is compressable; among
-       the standard field types, only TextField and StrField are)
-     multiValued: true if this field may contain multiple values per document
-     omitNorms: (expert) set to true to omit the norms associated with
-       this field (this disables length normalization and index-time
-       boosting for the field, and saves some memory).  Only full-text
-       fields or fields that need an index-time boost need norms.
-     termVectors: [false] set to true to store the term vector for a given field.
-       When using MoreLikeThis, fields used for similarity should be stored for 
-       best performance.
-   -->
-
-   <field name="id" type="string" indexed="true" stored="true" required="true" />
-   <field name="desc" type="string" indexed="true" stored="true" multiValued="true" />
-   
-   <field name="date" type="date" indexed="true" stored="true" />
-
-   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
-   
-
-   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
-        will be used if the name matches any of the patterns.
-        RESTRICTION: the glob-like pattern in the name attribute must have
-        a "*" only at the start or the end.
-        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
-        Longer patterns will be matched first.  if equal size patterns
-        both match, the first appearing in the schema will be used.  -->
-   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
-   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
-   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
-
-   <dynamicField name="random*" type="random" />
-
-   <!-- uncomment the following to ignore any fields that don't already match an existing 
-        field name or dynamic field, rather than reporting them as an error. 
-        alternately, change the type="ignored" to some other type e.g. "text" if you want 
-        unknown fields indexed and/or stored by default --> 
-   <!--dynamicField name="*" type="ignored" /-->
-   
- </fields>
-
- <!-- Field to use to determine and enforce document uniqueness. 
-      Unless this field is marked with required="false", it will be a required field
-   -->
- <uniqueKey>id</uniqueKey>
-
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>desc</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solr_id-schema.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solr_id-schema.xml
deleted file mode 100644
index 4ef1117..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solr_id-schema.xml
+++ /dev/null
@@ -1,307 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--  
- This is the Solr schema file. This file should be named "schema.xml" and
- should be in the conf directory under the solr home
- (i.e. ./solr/conf/schema.xml by default) 
- or located where the classloader for the Solr webapp can find it.
-
- This example schema is the recommended starting point for users.
- It should be kept correct and concise, usable out-of-the-box.
-
- For more information, on how to customize this file, please see
- http://wiki.apache.org/solr/SchemaXml
--->
-
-<schema name="test" version="1.1">
-  <!-- attribute "name" is the name of this schema and is only used for display purposes.
-       Applications should change this to reflect the nature of the search collection.
-       version="1.1" is Solr's version number for the schema syntax and semantics.  It should
-       not normally be changed by applications.
-       1.0: multiValued attribute did not exist, all fields are multiValued by nature
-       1.1: multiValued attribute introduced, false by default -->
-
-  <types>
-    <!-- field type definitions. The "name" attribute is
-       just a label to be used by field definitions.  The "class"
-       attribute and any other attributes determine the real
-       behavior of the fieldType.
-         Class names starting with "solr" refer to java classes in the
-       org.apache.solr.analysis package.
-    -->
-
-    <!-- The StrField type is not analyzed, but indexed/stored verbatim.  
-       - StrField and TextField support an optional compressThreshold which
-       limits compression (if enabled in the derived fields) to values which
-       exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField" sortMissingLast="true" omitNorms="true"/>
-
-    <!-- The optional sortMissingLast and sortMissingFirst attributes are
-         currently supported on types that are sorted internally as strings.
-       - If sortMissingLast="true", then a sort on this field will cause documents
-         without the field to come after documents with the field,
-         regardless of the requested sort order (asc or desc).
-       - If sortMissingFirst="true", then a sort on this field will cause documents
-         without the field to come before documents with the field,
-         regardless of the requested sort order.
-       - If sortMissingLast="false" and sortMissingFirst="false" (the default),
-         then default lucene sorting will be used which places docs without the
-         field first in an ascending sort and last in a descending sort.
-    -->    
-
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't support range queries, since the
-         lexicographic ordering isn't equal to the numeric ordering) -->
-    <fieldType name="integer" class="solr.IntField" omitNorms="true"/>
-    <fieldType name="long" class="solr.LongField" omitNorms="true"/>
-    <fieldType name="float" class="solr.FloatField" omitNorms="true"/>
-    <fieldType name="double" class="solr.DoubleField" omitNorms="true"/>
-
-
-    <!-- Numeric field types that manipulate the value into
-         a string value that isn't human-readable in its internal form,
-         but with a lexicographic ordering the same as the numeric ordering,
-         so that range queries work correctly. -->
-    <fieldType name="sint" class="solr.SortableIntField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="slong" class="solr.SortableLongField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sfloat" class="solr.SortableFloatField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The format for this date field is of the form 1995-12-31T23:59:59Z, and
-         is a more restricted form of the canonical representation of dateTime
-         http://www.w3.org/TR/xmlschema-2/#dateTime    
-         The trailing "Z" designates UTC time and is mandatory.
-         Optional fractional seconds are allowed: 1995-12-31T23:59:59.999Z
-         All other components are mandatory.
-
-         Expressions can also be used to denote calculations that should be
-         performed relative to "NOW" to determine the value, ie...
-
-               NOW/HOUR
-                  ... Round to the start of the current hour
-               NOW-1DAY
-                  ... Exactly 1 day prior to now
-               NOW/DAY+6MONTHS+3DAYS
-                  ... 6 months and 3 days in the future from the start of
-                      the current day
-                      
-         Consult the DateField javadocs for more information.
-      -->
-    <fieldType name="date" class="solr.DateField" sortMissingLast="true" omitNorms="true"/>
-
-
-    <!-- The "RandomSortField" is not used to store or search any
-         data.  You can declare fields of this type it in your schema
-         to generate psuedo-random orderings of your docs for sorting 
-         purposes.  The ordering is generated based on the field name 
-         and the version of the index, As long as the index version
-         remains unchanged, and the same field name is reused,
-         the ordering of the docs will be consistent.  
-         If you want differend psuedo-random orderings of documents,
-         for the same version of the index, use a dynamicField and
-         change the name
-     -->
-    <fieldType name="random" class="solr.RandomSortField" indexed="true" />
-
-    <!-- solr.TextField allows the specification of custom text analyzers
-         specified as a tokenizer and a list of token filters. Different
-         analyzers may be specified for indexing and querying.
-
-         The optional positionIncrementGap puts space between multiple fields of
-         this type on the same document, with the purpose of preventing false phrase
-         matching across fields.
-
-         For more info on customizing your analyzer chain, please see
-         http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-     -->
-
-    <!-- One can also specify an existing Analyzer class that has a
-         default constructor via the class attribute on the analyzer element
-    <fieldType name="text_greek" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.el.GreekAnalyzer"/>
-    </fieldType>
-    -->
-
-    <!-- A text field that only splits on whitespace for exact matching of words -->
-    <fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- A text field that uses WordDelimiterFilter to enable splitting and matching of
-        words on case-change, alpha numeric boundaries, and non-alphanumeric chars,
-        so that a query of "wifi" or "wi fi" could match a document containing "Wi-Fi".
-        Synonyms and stopwords are customized by external files, and stemming is enabled.
-        Duplicate tokens at the same position (which may result from Stemmed Synonyms or
-        WordDelim parts) are removed.
-        -->
-    <fieldType name="text" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!-- in this example, we will only use synonyms at query time
-        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
-        -->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-
-    <!-- Less flexible matching, but less false matches.  Probably not ideal for product names,
-         but may be good for SKUs.  Can insert dashes in the wrong place and still match. -->
-    <fieldType name="textTight" class="solr.TextField" positionIncrementGap="100" >
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <!--<filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>-->
-        <!--<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt"/>-->
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <!--<filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.EnglishMinimalStemFilterFactory"/>-->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <!-- This is an example of using the KeywordTokenizer along
-         With various TokenFilterFactories to produce a sortable field
-         that does not include some properties of the source text
-      -->
-    <fieldType name="alphaOnlySort" class="solr.TextField" sortMissingLast="true" omitNorms="true">
-      <analyzer>
-        <!-- KeywordTokenizer does no actual tokenizing, so the entire
-             input string is preserved as a single token
-          -->
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-        <!-- The LowerCase TokenFilter does what you expect, which can be
-             when you want your sorting to be case insensitive
-          -->
-        <filter class="solr.LowerCaseFilterFactory" />
-        <!-- The TrimFilter removes any leading or trailing whitespace -->
-        <filter class="solr.TrimFilterFactory" />
-        <!-- The PatternReplaceFilter gives you the flexibility to use
-             Java Regular expression to replace any sequence of characters
-             matching a pattern with an arbitrary replacement string, 
-             which may include back refrences to portions of the orriginal
-             string matched by the pattern.
-             
-             See the Java Regular Expression documentation for more
-             infomation on pattern and replacement string syntax.
-             
-             http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
-          -->
-        <filter class="solr.PatternReplaceFilterFactory"
-                pattern="([^a-z])" replacement="" replace="all"
-        />
-      </analyzer>
-    </fieldType>
-
-    <!-- since fields of this type are by default not stored or indexed, any data added to 
-         them will be ignored outright 
-     --> 
-    <fieldtype name="ignored" stored="false" indexed="false" class="solr.StrField" /> 
-
- </types>
-
-
- <fields>
-   <!-- Valid attributes for fields:
-     name: mandatory - the name for the field
-     type: mandatory - the name of a previously defined type from the <types> section
-     indexed: true if this field should be indexed (searchable or sortable)
-     stored: true if this field should be retrievable
-     compressed: [false] if this field should be stored using gzip compression
-       (this will only apply if the field type is compressable; among
-       the standard field types, only TextField and StrField are)
-     multiValued: true if this field may contain multiple values per document
-     omitNorms: (expert) set to true to omit the norms associated with
-       this field (this disables length normalization and index-time
-       boosting for the field, and saves some memory).  Only full-text
-       fields or fields that need an index-time boost need norms.
-     termVectors: [false] set to true to store the term vector for a given field.
-       When using MoreLikeThis, fields used for similarity should be stored for 
-       best performance.
-   -->
-
-   <field name="solr_id" type="string" indexed="true" stored="true" required="true" />
-   <field name="desc" type="string" indexed="true" stored="true" multiValued="true" />
-   
-   <field name="date" type="date" indexed="true" stored="true" />
-
-   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
-   
-
-   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
-        will be used if the name matches any of the patterns.
-        RESTRICTION: the glob-like pattern in the name attribute must have
-        a "*" only at the start or the end.
-        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
-        Longer patterns will be matched first.  if equal size patterns
-        both match, the first appearing in the schema will be used.  -->
-   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
-   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
-   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
-
-   <dynamicField name="random*" type="random" />
-
-   <!-- uncomment the following to ignore any fields that don't already match an existing 
-        field name or dynamic field, rather than reporting them as an error. 
-        alternately, change the type="ignored" to some other type e.g. "text" if you want 
-        unknown fields indexed and/or stored by default --> 
-   <!--dynamicField name="*" type="ignored" /-->
-   
- </fields>
-
- <!-- Field to use to determine and enforce document uniqueness. 
-      Unless this field is marked with required="false", it will be a required field
-   -->
- <uniqueKey>solr_id</uniqueKey>
-
- <!-- field for the QueryParser to use when an explicit fieldname is absent -->
- <defaultSearchField>desc</defaultSearchField>
-
- <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
- <solrQueryParser defaultOperator="OR"/>
-
-</schema>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solrconfig.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solrconfig.xml
deleted file mode 100644
index 113e371..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/dataimport-solrconfig.xml
+++ /dev/null
@@ -1,394 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-
-  <!-- Used to specify an alternate directory to hold all index data
-       other than the default ./data under the Solr home.
-       If replication is in use, this should match the replication configuration. -->
-       <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-     If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <!--<mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>-->
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <!--<mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>-->
-
-    <!--
-      As long as Solr is the only process modifying your index, it is
-      safe to use Lucene's in process locking mechanism.  But you may
-      specify one of the other Lucene LockFactory implementations in
-      the event that you have a custom situation.
-      
-      none = NoLockFactory (typically only used with read only indexes)
-      single = SingleInstanceLockFactory (suggested)
-      native = NativeFSLockFactory
-      simple = SimpleFSLockFactory
-
-      ('simple' is the default for backwards compatibility with Solr 1.2)
-    -->
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <!-- If true, unlock any held write or commit locks on startup. 
-         This defeats the locking mechanism that allows multiple
-         processes to safely access a lucene index, and should be
-         used with care.
-         This is not needed if lock type is 'none' or 'single'
-     -->
-    <unlockOnStartup>false</unlockOnStartup>
-  </mainIndex>
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- A prefix of "solr." for class names is an alias that
-         causes solr to search appropriate packages, including
-         org.apache.solr.(search|update|request|core|analysis)
-     -->
-
-    <!-- Limit the number of deletions Solr will buffer during doc updating.
-        
-        Setting this lower can help bound memory use during indexing.
-    -->
-    <maxPendingDeletes>100000</maxPendingDeletes>
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or prefix queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.  -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-    
-    <!-- Cache used by SolrIndexSearcher for filters (DocSets),
-         unordered sets of *all* documents that match a query.
-         When a new searcher is opened, its caches may be prepopulated
-         or "autowarmed" using data from caches in the old searcher.
-         autowarmCount is the number of items to prepopulate.  For LRUCache,
-         the autowarmed items will be the most recently accessed items.
-       Parameters:
-         class - the SolrCache implementation (currently only LRUCache)
-         size - the maximum number of entries in the cache
-         initialSize - the initial capacity (number of entries) of
-           the cache.  (seel java.util.HashMap)
-         autowarmCount - the number of entries to prepopulate from
-           and old cache.
-         -->
-    <filterCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-   <!-- queryResultCache caches results of searches - ordered lists of
-         document ids (DocList) based on a query, a sort, and the range
-         of documents requested.  -->
-    <queryResultCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-  <!-- documentCache caches Lucene Document objects (the stored fields for each document).
-       Since Lucene internal document ids are transient, this cache will not be autowarmed.  -->
-    <documentCache
-      class="solr.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-
-    This can result in a significant speed improvement if the usual case is to
-    not load all stored fields, especially if the skipped fields are large compressed
-    text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!-- Example of a generic cache.  These caches may be accessed by name
-         through SolrIndexSearcher.getCache(),cacheLookup(), and cacheInsert().
-         The purpose is to enable easy caching of user/application level data.
-         The regenerator argument should be specified as an implementation
-         of solr.search.CacheRegenerator if autowarming is desired.  -->
-    <!--
-    <cache name="myUserCache"
-      class="solr.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator"
-      />
-    -->
-
-   <!-- An optimization that attempts to use a filter to satisfy a search.
-         If the requested sort does not include score, then the filterCache
-         will be checked for a filter matching the query. If found, the filter
-         will be used as the source of document ids, and then the sort will be
-         applied to that.
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-   -->
-
-   <!-- An optimization for use with the queryResultCache.  When a search
-         is requested, a superset of the requested number of document ids
-         are collected.  For example, if a search for a particular query
-         requests matching documents 10 through 19, and queryWindowSize is 50,
-         then documents 0 through 49 will be collected and cached.  Any further
-         requests in that range can be satisfied via the cache.  -->
-    <queryResultWindowSize>50</queryResultWindowSize>
-    
-    <!-- Maximum number of documents to cache for any entry in the
-         queryResultCache. -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!-- This entry enables an int hash representation for filters (DocSets)
-         when the number of items in the set is less than maxSize.  For smaller
-         sets, this representation is more memory efficient, more efficient to
-         iterate over, and faster to take intersections.  -->
-    <HashDocSet maxSize="3000" loadFactor="0.75"/>
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst><str name="q">static newSearcher warming query from solrconfig.xml</str></lst>
-      </arr>
-    </listener>
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain autowarming data from. -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-      </arr>
-    </listener>
-
-    <!-- If a search request comes in and there is no current registered searcher,
-         then immediately register the still warming searcher and use it.  If
-         "false" then all requests will block until the first searcher is done
-         warming. -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!-- Maximum number of searchers that may be warming in the background
-      concurrently.  An error is returned if this limit is exceeded. Recommend
-      1-2 for read-only slaves, higher for masters w/o cache warming. -->
-    <maxWarmingSearchers>4</maxWarmingSearchers>
-
-  </query>
-
-  <!-- 
-    Let the dispatch filter handler /select?qt=XXX
-    handleSelect=true will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-    -->
-  <requestDispatcher handleSelect="true" >
-    <!--Make sure your system has some authentication before enabling remote streaming!  -->
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-        
-    <!-- Set HTTP caching related parameters (for proxy caches and clients).
-          
-         To get the behaviour of Solr 1.2 (ie: no caching related headers)
-         use the never304="true" option and do not specify a value for
-         <cacheControl>
-    -->
-    <httpCaching never304="true">
-    <!--httpCaching lastModifiedFrom="openTime"
-                 etagSeed="Solr"-->
-       <!-- lastModFrom="openTime" is the default, the Last-Modified value
-            (and validation against If-Modified-Since requests) will all be
-            relative to when the current Searcher was opened.
-            You can change it to lastModFrom="dirLastMod" if you want the
-            value to exactly corrispond to when the physical index was last
-            modified.
-               
-            etagSeed="..." is an option you can change to force the ETag
-            header (and validation against If-None-Match requests) to be
-            differnet even if the index has not changed (ie: when making
-            significant changes to your config file)
-
-            lastModifiedFrom and etagSeed are both ignored if you use the
-            never304="true" option.
-       -->
-       <!-- If you include a <cacheControl> directive, it will be used to
-            generate a Cache-Control header, as well as an Expires header
-            if the value contains "max-age="
-               
-            By default, no Cache-Control header is generated.
-
-            You can use the <cacheControl> option even if you have set
-            never304="true"
-       -->
-       <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-  
-      
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the path or the qt (query type) param.
-     Names starting with a '/' are accessed with the a path equal to the 
-     registered name.  Names without a leading '/' are accessed with:
-      http://host/app/select?qt=name
-     If no qt is defined, the requestHandler that declares default="true"
-     will be used.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true">
-    <!-- default values for query parameters -->
-     <lst name="defaults">
-       <str name="echoParams">explicit</str>
-       <!-- 
-       <int name="rows">10</int>
-       <str name="fl">*</str>
-       <str name="version">2.1</str>
-        -->
-     </lst>
-  </requestHandler>
-  
-  <requestHandler name="/dataimport" class="org.apache.solr.handler.dataimport.DataImportHandler">
-  </requestHandler>
-    
-  <!--
-   
-   Search components are registered to SolrCore and used by Search Handlers
-   
-   By default, the following components are avaliable:
-    
-   <searchComponent name="query"     class="org.apache.solr.handler.component.QueryComponent" />
-   <searchComponent name="facet"     class="org.apache.solr.handler.component.FacetComponent" />
-   <searchComponent name="mlt"       class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-   <searchComponent name="highlight" class="org.apache.solr.handler.component.HighlightComponent" />
-   <searchComponent name="debug"     class="org.apache.solr.handler.component.DebugComponent" />
-  
-   If you register a searchComponent to one of the standard names, that will be used instead.
-  
-   -->
- 
-  <requestHandler name="/search" class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-    </lst>
-    <!--
-    By default, this will register the following components:
-    
-    <arr name="components">
-      <str>query</str>
-      <str>facet</str>
-      <str>mlt</str>
-      <str>highlight</str>
-      <str>debug</str>
-    </arr>
-    
-    To insert handlers before or after the 'standard' components, use:
-    
-    <arr name="first-components">
-      <str>first</str>
-    </arr>
-    
-    <arr name="last-components">
-      <str>last</str>
-    </arr>
-    
-    -->
-  </requestHandler>
-  
-  <!-- Update request handler.  
-  
-       Note: Since solr1.1 requestHandlers requires a valid content type header if posted in 
-       the body. For example, curl now requires: -H 'Content-type:text/xml; charset=utf-8'
-       The response format differs from solr1.1 formatting and returns a standard error code.
-       
-       To enable solr1.1 behavior, remove the /update handler or change its path
-       
-       "update.processor.class" is the class name for the UpdateRequestProcessor.  It is initalized
-       only once.  This can not be changed for each request.
-    -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" >
-    <!--
-    <str name="update.processor.class">org.apache.solr.handler.UpdateRequestProcessor</str>
-    -->
-  </requestHandler>
-  
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>*:*</defaultQuery>
-    
-    <!-- configure a healthcheck file for servers behind a loadbalancer
-    <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-  <updateRequestProcessorChain key="dataimport" default="true">
-    <processor class="org.apache.solr.handler.dataimport.AbstractDataImportHandlerTestCase$TestUpdateRequestProcessorFactory"/>
-    <processor class="solr.RunUpdateProcessorFactory"/>
-    <processor class="solr.LogUpdateProcessorFactory"/>
-  </updateRequestProcessorChain>
-
-</config>
-
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/protwords.txt b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/protwords.txt
deleted file mode 100644
index 7878147..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/protwords.txt
+++ /dev/null
@@ -1,20 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#use a protected word file to avoid stemming two
-#unrelated words to the same base word.
-#to test, we will use words that would normally obviously be stemmed.
-cats
-ridding
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/single-entity-data-config.xml b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/single-entity-data-config.xml
deleted file mode 100644
index f9d3523..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/single-entity-data-config.xml
+++ /dev/null
@@ -1,9 +0,0 @@
-<dataConfig>
-  <dataSource type="MockDataSource"/>
-	<document>
-		<entity name="x" query="select * from x">
-			<field column="id" />
-			<field column="desc" />
-		</entity>
-	</document>
-</dataConfig>
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/stopwords.txt b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/stopwords.txt
deleted file mode 100644
index 688e307..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/stopwords.txt
+++ /dev/null
@@ -1,16 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-stopworda
-stopwordb
diff --git a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/synonyms.txt b/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/synonyms.txt
deleted file mode 100644
index a7624f0..0000000
--- a/solr/contrib/dataimporthandler/src/test-files/solr-dih/conf/synonyms.txt
+++ /dev/null
@@ -1,22 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-a => aa
-b => b1 b2
-c => c1,c2
-a\=>a => b\=>b
-a\,a => b\,b
-foo,bar,baz
-
-Television,TV,Televisions
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java
index f4ebad9..af1a3b2 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/AbstractDataImportHandlerTestCase.java
@@ -54,7 +54,7 @@ public abstract class AbstractDataImportHandlerTestCase extends
 
   // note, a little twisted that we shadow this static method
   public static void initCore(String config, String schema) throws Exception {
-    initCore(config, schema, getFile("solr-dih").getAbsolutePath());
+    initCore(config, schema, getFile("dih/solr").getAbsolutePath());
   }
   
   @Override
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
index 0ea8b1d..b7ea4ec 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
@@ -39,7 +39,7 @@ import java.util.List;
  * @since solr 1.4
  */
 public class TestContentStreamDataSource extends AbstractDataImportHandlerTestCase {
-  private static final String CONF_DIR = "." + File.separator + "solr-dih" + File.separator + "conf" + File.separator;
+  private static final String CONF_DIR = "dih/solr/conf/";
   SolrInstance instance = null;
   JettySolrRunner jetty;
 
diff --git a/solr/contrib/extraction/src/test-files/arabic.pdf b/solr/contrib/extraction/src/test-files/arabic.pdf
deleted file mode 100644
index 3d47b99..0000000
--- a/solr/contrib/extraction/src/test-files/arabic.pdf
+++ /dev/null
@@ -1,2 +0,0 @@
-??§Ù?³Ù?? Ø¹??????
-
\ No newline at end of file
diff --git a/solr/contrib/extraction/src/test-files/example.html b/solr/contrib/extraction/src/test-files/example.html
deleted file mode 100644
index 5732f62..0000000
--- a/solr/contrib/extraction/src/test-files/example.html
+++ /dev/null
@@ -1,49 +0,0 @@
-<html>
-<head>
-  <title>Welcome to Solr</title>
-</head>
-<body>
-<p>
-  Here is some text
-</p>
-<div>Here is some text in a div</div>
-<div>This has a <a href="http://www.apache.org">link</a>.</div>
-<a href="#news">News</a>
-<ul class="minitoc">
-<li>
-<a href="#03+October+2008+-+Solr+Logo+Contest">03 October 2008 - Solr Logo Contest</a>
-</li>
-<li>
-<a href="#15+September+2008+-+Solr+1.3.0+Available">15 September 2008 - Solr 1.3.0 Available</a>
-</li>
-<li>
-<a href="#28+August+2008+-+Lucene%2FSolr+at+ApacheCon+New+Orleans">28 August 2008 - Lucene/Solr at ApacheCon New Orleans</a>
-</li>
-<li>
-<a href="#03+September+2007+-+Lucene+at+ApacheCon+Atlanta">03 September 2007 - Lucene at ApacheCon Atlanta</a>
-</li>
-<li>
-<a href="#06+June+2007%3A+Release+1.2+available">06 June 2007: Release 1.2 available</a>
-</li>
-<li>
-<a href="#17+January+2007%3A+Solr+graduates+from+Incubator">17 January 2007: Solr graduates from Incubator</a>
-</li>
-<li>
-<a href="#22+December+2006%3A+Release+1.1.0+available">22 December 2006: Release 1.1.0 available</a>
-</li>
-<li>
-<a href="#15+August+2006%3A+Solr+at+ApacheCon+US">15 August 2006: Solr at ApacheCon US</a>
-</li>
-<li>
-<a href="#21+April+2006%3A+Solr+at+ApacheCon">21 April 2006: Solr at ApacheCon</a>
-</li>
-<li>
-<a href="#21+February+2006%3A+nightly+builds">21 February 2006: nightly builds</a>
-</li>
-<li>
-<a href="#17+January+2006%3A+Solr+Joins+Apache+Incubator">17 January 2006: Solr Joins Apache Incubator</a>
-</li>
-</ul>
-
-</body>
-</html>
diff --git a/solr/contrib/extraction/src/test-files/extraction/arabic.pdf b/solr/contrib/extraction/src/test-files/extraction/arabic.pdf
new file mode 100644
index 0000000..3d47b99
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/arabic.pdf
@@ -0,0 +1,2 @@
+??§Ù?³Ù?? Ø¹??????
+
\ No newline at end of file
diff --git a/solr/contrib/extraction/src/test-files/extraction/example.html b/solr/contrib/extraction/src/test-files/extraction/example.html
new file mode 100644
index 0000000..5732f62
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/example.html
@@ -0,0 +1,49 @@
+<html>
+<head>
+  <title>Welcome to Solr</title>
+</head>
+<body>
+<p>
+  Here is some text
+</p>
+<div>Here is some text in a div</div>
+<div>This has a <a href="http://www.apache.org">link</a>.</div>
+<a href="#news">News</a>
+<ul class="minitoc">
+<li>
+<a href="#03+October+2008+-+Solr+Logo+Contest">03 October 2008 - Solr Logo Contest</a>
+</li>
+<li>
+<a href="#15+September+2008+-+Solr+1.3.0+Available">15 September 2008 - Solr 1.3.0 Available</a>
+</li>
+<li>
+<a href="#28+August+2008+-+Lucene%2FSolr+at+ApacheCon+New+Orleans">28 August 2008 - Lucene/Solr at ApacheCon New Orleans</a>
+</li>
+<li>
+<a href="#03+September+2007+-+Lucene+at+ApacheCon+Atlanta">03 September 2007 - Lucene at ApacheCon Atlanta</a>
+</li>
+<li>
+<a href="#06+June+2007%3A+Release+1.2+available">06 June 2007: Release 1.2 available</a>
+</li>
+<li>
+<a href="#17+January+2007%3A+Solr+graduates+from+Incubator">17 January 2007: Solr graduates from Incubator</a>
+</li>
+<li>
+<a href="#22+December+2006%3A+Release+1.1.0+available">22 December 2006: Release 1.1.0 available</a>
+</li>
+<li>
+<a href="#15+August+2006%3A+Solr+at+ApacheCon+US">15 August 2006: Solr at ApacheCon US</a>
+</li>
+<li>
+<a href="#21+April+2006%3A+Solr+at+ApacheCon">21 April 2006: Solr at ApacheCon</a>
+</li>
+<li>
+<a href="#21+February+2006%3A+nightly+builds">21 February 2006: nightly builds</a>
+</li>
+<li>
+<a href="#17+January+2006%3A+Solr+Joins+Apache+Incubator">17 January 2006: Solr Joins Apache Incubator</a>
+</li>
+</ul>
+
+</body>
+</html>
diff --git a/solr/contrib/extraction/src/test-files/extraction/password-is-solrcell.docx b/solr/contrib/extraction/src/test-files/extraction/password-is-solrcell.docx
new file mode 100644
index 0000000..2723d56
diff --git a/solr/contrib/extraction/src/test-files/extraction/simple.html b/solr/contrib/extraction/src/test-files/extraction/simple.html
new file mode 100644
index 0000000..f33cf92
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/simple.html
@@ -0,0 +1,12 @@
+<html>
+<head>
+  <title>Welcome to Solr</title>
+</head>
+<body>
+<p>
+  Here is some text
+</p>
+<div>Here is some text in a div</div>
+<div>This has a <a href="http://www.apache.org">link</a>.</div>
+</body>
+</html>
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr-word.pdf b/solr/contrib/extraction/src/test-files/extraction/solr-word.pdf
new file mode 100644
index 0000000..bd8b865
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr-word.pdf
@@ -0,0 +1,2 @@
+This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
+
\ No newline at end of file
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/conf/protwords.txt b/solr/contrib/extraction/src/test-files/extraction/solr/conf/protwords.txt
new file mode 100644
index 0000000..7878147
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/conf/protwords.txt
@@ -0,0 +1,20 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#use a protected word file to avoid stemming two
+#unrelated words to the same base word.
+#to test, we will use words that would normally obviously be stemmed.
+cats
+ridding
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/conf/schema.xml b/solr/contrib/extraction/src/test-files/extraction/solr/conf/schema.xml
new file mode 100644
index 0000000..8cc3aaa
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/conf/schema.xml
@@ -0,0 +1,475 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- The Solr schema file. This file should be named "schema.xml" and
+     should be located where the classloader for the Solr webapp can find it.
+
+     This schema is used for testing, and as such has everything and the 
+     kitchen sink thrown in. See example/solr/conf/schema.xml for a 
+     more concise example.
+
+     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
+     $Name:  $
+  -->
+
+<schema name="test" version="1.0">
+  <types>
+
+    <!-- field type definitions... note that the "name" attribute is
+         just a label to be used by field definitions.  The "class"
+         attribute and any other attributes determine the real type and
+         behavior of the fieldtype.
+      -->
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't sort correctly or support range queries.)
+         These are provided more for backward compatability, allowing one
+         to create a schema that matches an existing lucene index.
+    -->
+    <fieldType name="integer" class="solr.IntField"/>
+    <fieldType name="long" class="solr.LongField"/>
+    <fieldtype name="float" class="solr.FloatField"/>
+    <fieldType name="double" class="solr.DoubleField"/>
+
+    <!-- numeric field types that manipulate the value into
+       a string value that isn't human readable in it's internal form,
+       but sorts correctly and supports range queries.
+
+         If sortMissingLast="true" then a sort on this field will cause documents
+       without the field to come after documents with the field,
+       regardless of the requested sort order.
+         If sortMissingFirst="true" then a sort on this field will cause documents
+       without the field to come before documents with the field,
+       regardless of the requested sort order.
+         If sortMissingLast="false" and sortMissingFirst="false" (the default),
+       then default lucene sorting will be used which places docs without the field
+       first in an ascending sort and last in a descending sort.
+    -->
+    <fieldtype name="sint" class="solr.SortableIntField" sortMissingLast="true"/>
+    <fieldtype name="slong" class="solr.SortableLongField" sortMissingLast="true"/>
+    <fieldtype name="sfloat" class="solr.SortableFloatField" sortMissingLast="true"/>
+    <fieldtype name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true"/>
+
+    <!-- bcd versions of sortable numeric type may provide smaller
+         storage space and support very large numbers.
+    -->
+    <fieldtype name="bcdint" class="solr.BCDIntField" sortMissingLast="true"/>
+    <fieldtype name="bcdlong" class="solr.BCDLongField" sortMissingLast="true"/>
+    <fieldtype name="bcdstr" class="solr.BCDStrField" sortMissingLast="true"/>
+
+    <!-- Field type demonstrating an Analyzer failure -->
+    <fieldtype name="failtype1" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- Demonstrating ignoreCaseChange -->
+    <fieldtype name="wdf_nocase" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    
+     <fieldtype name="wdf_preserve" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="1"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+
+    <!-- HighlitText optimizes storage for (long) columns which will be highlit -->
+    <fieldtype name="highlittext" class="solr.TextField" compressThreshold="345" />
+
+    <fieldtype name="boolean" class="solr.BoolField" sortMissingLast="true"/>
+    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
+
+    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
+         seconds part (.999) is optional.
+      -->
+    <fieldtype name="date" class="solr.DateField" sortMissingLast="true"/>
+
+    <!-- solr.TextField allows the specification of custom
+         text analyzers specified as a tokenizer and a list
+         of token filters.
+      -->
+    <fieldtype name="text" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.ClassicTokenizerFactory"/>
+        <filter class="solr.ClassicFilterFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+
+    <fieldtype name="nametext" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.core.WhitespaceAnalyzer"/>
+    </fieldtype>
+
+    <fieldtype name="teststop" class="solr.TextField">
+       <analyzer>
+        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
+        <filter class="solr.ClassicFilterFactory"/>
+        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- fieldtypes in this section isolate tokenizers and tokenfilters for testing -->
+    <fieldtype name="lowertok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.LowerCaseTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="keywordtok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.KeywordTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="standardtok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.StandardTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="lettertok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.LetterTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="whitetok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.WhitespaceTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="HTMLstandardtok" class="solr.TextField">
+      <analyzer>
+      <charFilter class="solr.HTMLStripCharFilterFactory"/>
+      <tokenizer class="solr.StandardTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="HTMLwhitetok" class="solr.TextField">
+      <analyzer>
+      <charFilter class="solr.HTMLStripCharFilterFactory"/>
+      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="standardtokfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.ClassicTokenizerFactory"/>
+        <filter class="solr.ClassicFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="standardfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.ClassicFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="lowerfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="patternreplacefilt" class="solr.TextField">
+      <analyzer type="index">
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+        <filter class="solr.PatternReplaceFilterFactory"
+                pattern="([^a-zA-Z])" replacement="_" replace="all"
+        />
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="porterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <!-- fieldtype name="snowballfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.SnowballPorterFilterFactory"/>
+      </analyzer>
+    </fieldtype -->
+    <fieldtype name="engporterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="custengporterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="stopfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="custstopfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="lengthfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.LengthFilterFactory" min="2" max="5"/>
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype name="subword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- more flexible in matching skus, but more chance of a false match -->
+    <fieldtype name="skutype1" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- less flexible in matching skus, but less chance of a false match -->
+    <fieldtype name="skutype2" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- less flexible in matching skus, but less chance of a false match -->
+    <fieldtype name="syn" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter name="syn" class="solr.SynonymFilterFactory" synonyms="synonyms.txt"/>
+      </analyzer>
+    </fieldtype>
+    
+    <!-- Demonstrates How RemoveDuplicatesTokenFilter makes stemmed
+         synonyms "better"
+      -->
+    <fieldtype name="dedup" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.SynonymFilterFactory"
+                  synonyms="synonyms.txt" expand="true" />
+          <filter class="solr.PorterStemFilterFactory"/>
+          <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype  name="unstored" class="solr.StrField" indexed="true" stored="false"/>
+
+
+  <fieldtype name="textgap" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+  </fieldtype>
+
+ </types>
+
+
+ <fields>
+   <field name="id" type="string" indexed="true" stored="true" multiValued="false" required="false"/>
+   <field name="name" type="nametext" indexed="true" stored="true"/>
+   <field name="text" type="text" indexed="true" stored="false"/>
+   <field name="subject" type="text" indexed="true" stored="true"/>
+   <field name="title" type="nametext" indexed="true" stored="true"/>
+   <field name="weight" type="float" indexed="true" stored="true"/>
+   <field name="bday" type="date" indexed="true" stored="true"/>
+
+   <field name="title_stemmed" type="text" indexed="true" stored="false"/>
+   <field name="title_lettertok" type="lettertok" indexed="true" stored="false"/>
+
+   <field name="syn" type="syn" indexed="true" stored="true"/>
+
+   <!-- to test property inheritance and overriding -->
+   <field name="shouldbeunstored" type="unstored" />
+   <field name="shouldbestored" type="unstored" stored="true"/>
+   <field name="shouldbeunindexed" type="unstored" indexed="false" stored="true"/>
+
+
+   <!-- test different combinations of indexed and stored -->
+   <field name="bind" type="boolean" indexed="true" stored="false"/>
+   <field name="bsto" type="boolean" indexed="false" stored="true"/>
+   <field name="bindsto" type="boolean" indexed="true" stored="true"/>
+   <field name="isto" type="integer" indexed="false" stored="true"/>
+   <field name="iind" type="integer" indexed="true" stored="false"/>
+   <field name="ssto" type="string" indexed="false" stored="true"/>
+   <field name="sind" type="string" indexed="true" stored="false"/>
+   <field name="sindsto" type="string" indexed="true" stored="true"/>
+
+   <!-- test combinations of term vector settings -->
+   <field name="test_basictv" type="text" termVectors="true"/>
+   <field name="test_notv" type="text" termVectors="false"/>
+   <field name="test_postv" type="text" termVectors="true" termPositions="true"/>
+   <field name="test_offtv" type="text" termVectors="true" termOffsets="true"/>
+   <field name="test_posofftv" type="text" termVectors="true" 
+     termPositions="true" termOffsets="true"/>
+
+   <!-- test highlit field settings -->
+   <field name="test_hlt" type="highlittext" indexed="true" compressed="true"/>
+   <field name="test_hlt_off" type="highlittext" indexed="true" compressed="false"/>
+
+   <!-- fields to test individual tokenizers and tokenfilters -->
+   <field name="teststop" type="teststop" indexed="true" stored="true"/>
+   <field name="lowertok" type="lowertok" indexed="true" stored="true"/>
+   <field name="keywordtok" type="keywordtok" indexed="true" stored="true"/>
+   <field name="standardtok" type="standardtok" indexed="true" stored="true"/>
+   <field name="HTMLstandardtok" type="HTMLstandardtok" indexed="true" stored="true"/>
+   <field name="lettertok" type="lettertok" indexed="true" stored="true"/>
+   <field name="whitetok" type="whitetok" indexed="true" stored="true"/>
+   <field name="HTMLwhitetok" type="HTMLwhitetok" indexed="true" stored="true"/>
+   <field name="standardtokfilt" type="standardtokfilt" indexed="true" stored="true"/>
+   <field name="standardfilt" type="standardfilt" indexed="true" stored="true"/>
+   <field name="lowerfilt" type="lowerfilt" indexed="true" stored="true"/>
+   <field name="patternreplacefilt" type="patternreplacefilt" indexed="true" stored="true"/>
+   <field name="porterfilt" type="porterfilt" indexed="true" stored="true"/>
+   <field name="engporterfilt" type="engporterfilt" indexed="true" stored="true"/>
+   <field name="custengporterfilt" type="custengporterfilt" indexed="true" stored="true"/>
+   <field name="stopfilt" type="stopfilt" indexed="true" stored="true"/>
+   <field name="custstopfilt" type="custstopfilt" indexed="true" stored="true"/>
+   <field name="lengthfilt" type="lengthfilt" indexed="true" stored="true"/>
+   <field name="dedup" type="dedup" indexed="true" stored="true"/>
+   <field name="wdf_nocase" type="wdf_nocase" indexed="true" stored="true"/>
+   <field name="wdf_preserve" type="wdf_preserve" indexed="true" stored="true"/>
+
+   <field name="numberpartfail" type="failtype1" indexed="true" stored="true"/>
+
+   <field name="nullfirst" type="string" indexed="true" stored="true" sortMissingFirst="true"/>
+
+   <field name="subword" type="subword" indexed="true" stored="true"/>
+   <field name="sku1" type="skutype1" indexed="true" stored="true"/>
+   <field name="sku2" type="skutype2" indexed="true" stored="true"/>
+
+   <field name="textgap" type="textgap" indexed="true" stored="true"/>
+   
+   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
+   <field name="multiDefault" type="string" indexed="true" stored="true" default="muLti-Default" multiValued="true"/>
+   <field name="intDefault" type="sint" indexed="true" stored="true" default="42" multiValued="false"/>
+   
+   <field name="extractedDate" type="date" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedContent" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedProducer" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedCreator" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedKeywords" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedAuthor" type="text" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractedLanguage" type="string" indexed="true" stored="true" multiValued="true"/>
+   <field name="resourceName" type="string" indexed="true" stored="true" multiValued="true"/>
+
+   <field name="extractionLiteralMV" type="string" indexed="true" stored="true" multiValued="true"/>
+   <field name="extractionLiteral" type="string" indexed="true" stored="true" multiValued="false"/>
+
+   <field name="defaultExtr" type="string" indexed="true" stored="false" />
+   
+   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
+        will be used if the name matches any of the patterns.
+        RESTRICTION: the glob-like pattern in the name attribute must have
+        a "*" only at the start or the end.
+        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
+        Longer patterns will be matched first.  if equal size patterns
+        both match, the first appearing in the schema will be used.
+   -->
+   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
+   <dynamicField name="*_s1"  type="string"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
+   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
+   <dynamicField name="*_bcd" type="bcdstr" indexed="true"  stored="true"/>
+
+   <dynamicField name="*_sI" type="string"  indexed="true"  stored="false"/>
+   <dynamicField name="*_sS" type="string"  indexed="false" stored="true"/>
+   <dynamicField name="t_*"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="tv_*"  type="text" indexed="true"  stored="true" 
+      termVectors="true" termPositions="true" termOffsets="true"/>
+
+   <dynamicField name="stream_*"  type="text" indexed="true"  stored="true"/>
+   <dynamicField name="Content*"  type="text" indexed="true"  stored="true"/>
+
+
+   <!-- special fields for dynamic copyField test -->
+   <dynamicField name="dynamic_*" type="string" indexed="true" stored="true"/>
+   <dynamicField name="*_dynamic" type="string" indexed="true" stored="true"/>
+  
+   <!-- for testing to ensure that longer patterns are matched first -->
+   <dynamicField name="*aa"  type="string"  indexed="true" stored="true"/>
+   <dynamicField name="*aaa" type="integer" indexed="false" stored="true"/>
+
+   <!-- ignored because not stored or indexed -->
+   <dynamicField name="ignored_*" type="text" indexed="false" stored="false"/>
+
+ </fields>
+
+ <defaultSearchField>text</defaultSearchField>
+ <uniqueKey>id</uniqueKey>
+
+  <!-- copyField commands copy one field to another at the time a document
+        is added to the index.  It's used either to index the same field different
+        ways, or to add multiple fields to the same field for easier/faster searching.
+   -->
+   <copyField source="title" dest="title_stemmed"/>
+   <copyField source="title" dest="title_lettertok"/>
+
+   <copyField source="title" dest="text"/>
+   <copyField source="subject" dest="text"/>
+ 
+   <copyField source="*_t" dest="text"/>
+   
+   <!-- dynamic destination -->
+   <copyField source="*_dynamic" dest="dynamic_*"/>
+    
+
+</schema>
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/conf/solrconfig.xml b/solr/contrib/extraction/src/test-files/extraction/solr/conf/solrconfig.xml
new file mode 100644
index 0000000..077f776
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/conf/solrconfig.xml
@@ -0,0 +1,300 @@
+<?xml version="1.0" ?>
+
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source$
+     $Name$
+  -->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+  <jmx />
+
+  <!-- Used to specify an alternate directory to hold all index data.
+       It defaults to "index" if not present, and should probably
+       not be changed if replication is in use. -->
+  <dataDir>${solr.data.dir:}</dataDir>
+
+  <indexDefaults>
+   <!-- Values here affect all index writers and act as a default
+   unless overridden. -->
+    <!-- Values here affect all index writers and act as a default unless overridden. -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+     -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!-- Tell Lucene when to flush documents to disk.
+    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
+
+    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
+
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+     Expert:
+     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
+     versions used LogDocMergePolicy.
+
+     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
+     to merge based on number of documents
+
+     Other implementations of MergePolicy must have a no-argument constructor
+     -->
+    <mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>
+
+    <!--
+     Expert:
+     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
+      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
+     -->
+    <mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>
+    <!-- these are global... can't currently override per index -->
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- lucene options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <unlockOnStartup>true</unlockOnStartup>
+  </mainIndex>
+
+  <updateHandler class="solr.DirectUpdateHandler2">
+
+    <!-- autocommit pending docs if certain criteria are met 
+    <autoCommit> 
+      <maxDocs>10000</maxDocs>
+      <maxTime>3600000</maxTime> 
+    </autoCommit>
+    -->
+    <!-- represents a lower bound on the frequency that commits may
+    occur (in seconds). NOTE: not yet implemented
+    
+    <commitIntervalLowerBound>0</commitIntervalLowerBound>
+    -->
+
+    <!-- The RunExecutableListener executes an external command.
+         exe - the name of the executable to run
+         dir - dir to use as the current working directory. default="."
+         wait - the calling thread waits until the executable returns. default="true"
+         args - the arguments to pass to the program.  default=nothing
+         env - environment variables to set.  default=nothing
+      -->
+    <!-- A postCommit event is fired after every commit
+    <listener event="postCommit" class="solr.RunExecutableListener">
+      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
+      <str name="dir">/var/opt/resin3/__PORT__</str>
+      <bool name="wait">true</bool>
+      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
+      <arr name="env"> <str>MYVAR=val1</str> </arr>
+    </listener>
+    -->
+
+
+  </updateHandler>
+
+
+  <query>
+    <!-- Maximum number of clauses in a boolean query... can affect
+        range or wildcard queries that expand to big boolean
+        queries.  An exception is thrown if exceeded.
+    -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+
+    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
+         that match a particular query.
+      -->
+    <filterCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="256"/>
+
+    <queryResultCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="1024"/>
+
+    <documentCache
+      class="solr.search.LRUCache"
+      size="512"
+      initialSize="512"
+      autowarmCount="0"/>
+
+    <!-- If true, stored fields that are not requested will be loaded lazily.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!--
+
+    <cache name="myUserCache"
+      class="solr.search.LRUCache"
+      size="4096"
+      initialSize="1024"
+      autowarmCount="1024"
+      regenerator="MyRegenerator"
+      />
+    -->
+
+
+    <useFilterForSortedQuery>true</useFilterForSortedQuery>
+
+    <queryResultWindowSize>10</queryResultWindowSize>
+
+    <!-- set maxSize artificially low to exercise both types of sets -->
+    <HashDocSet maxSize="3" loadFactor="0.75"/>
+
+
+    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
+         into cached filters if the number of docs selected by the clause exceeds
+         the threshold (represented as a fraction of the total index)
+    -->
+    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
+
+
+    <!-- a newSearcher event is fired whenever a new searcher is being prepared
+         and there is a current searcher handling requests (aka registered). -->
+    <!-- QuerySenderListener takes an array of NamedList and executes a
+         local query request for each NamedList in sequence. -->
+    <!--
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+    <!-- a firstSearcher event is fired whenever a new searcher is being
+         prepared but there is no current registered searcher to handle
+         requests or to gain prewarming data from. -->
+    <!--
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
+      </arr>
+    </listener>
+    -->
+
+
+  </query>
+
+
+  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
+       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
+       based HashBitset. -->
+
+  <!-- requestHandler plugins... incoming queries will be dispatched to the
+     correct handler based on the qt (query type) param matching the
+     name of registered handlers.
+      The "standard" request handler is the default and will be used if qt
+     is not specified in the request.
+  -->
+  <requestHandler name="standard" class="solr.StandardRequestHandler">
+  	<bool name="httpCaching">true</bool>
+  </requestHandler>
+  <requestHandler name="dismax" class="solr.SearchHandler" >
+    <lst name="defaults">
+     <str name="defType">dismax</str>
+    </lst>
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="defaults" class="solr.StandardRequestHandler">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
+    <lst name="defaults">
+      <int name="rows">4</int>
+      <bool name="hl">true</bool>
+      <str name="hl.fl">text,name,subject,title,whitetok</str>
+    </lst>
+  </requestHandler>
+
+  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
+  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
+  	<bool name="httpCaching">false</bool>
+  </requestHandler>
+  
+  <requestHandler name="/update/extract" class="org.apache.solr.handler.extraction.ExtractingRequestHandler"/>
+
+
+  <highlighting>
+   <!-- Configure the standard fragmenter -->
+   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
+    <lst name="defaults">
+     <int name="hl.fragsize">100</int>
+    </lst>
+   </fragmenter>
+
+   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
+    <lst name="defaults">
+     <int name="hl.fragsize">70</int>
+    </lst>
+   </fragmenter>
+
+   <!-- Configure the standard formatter -->
+   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
+    <lst name="defaults">
+     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
+     <str name="hl.simple.post"><![CDATA[</em>]]></str>
+    </lst>
+   </formatter>
+  </highlighting>
+
+
+  <!-- enable streaming for testing... -->
+  <requestDispatcher handleSelect="true" >
+    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
+    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
+      <cacheControl>max-age=30, public</cacheControl>
+    </httpCaching>
+  </requestDispatcher>
+
+  <admin>
+    <defaultQuery>solr</defaultQuery>
+    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
+  </admin>
+
+  <!-- test getting system property -->
+  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
+            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
+
+</config>
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/conf/stopwords.txt b/solr/contrib/extraction/src/test-files/extraction/solr/conf/stopwords.txt
new file mode 100644
index 0000000..688e307
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/conf/stopwords.txt
@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+stopworda
+stopwordb
diff --git a/solr/contrib/extraction/src/test-files/extraction/solr/conf/synonyms.txt b/solr/contrib/extraction/src/test-files/extraction/solr/conf/synonyms.txt
new file mode 100644
index 0000000..a7624f0
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/solr/conf/synonyms.txt
@@ -0,0 +1,22 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+a => aa
+b => b1 b2
+c => c1,c2
+a\=>a => b\=>b
+a\,a => b\,b
+foo,bar,baz
+
+Television,TV,Televisions
diff --git a/solr/contrib/extraction/src/test-files/extraction/version_control.txt b/solr/contrib/extraction/src/test-files/extraction/version_control.txt
new file mode 100644
index 0000000..7a89c5b
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/version_control.txt
@@ -0,0 +1,18 @@
+Solr Version Control System
+ 
+Overview
+ 
+The Solr source code resides in the Apache Subversion (SVN) repository.
+The command-line SVN client can be obtained here or as an optional package
+for cygwin.
+
+The TortoiseSVN GUI client for Windows can be obtained here. There
+are also SVN plugins available for older versions of Eclipse and 
+IntelliJ IDEA that don't have subversion support already included.
+
+-------------------------------
+
+Note: This document is an excerpt from a document Licensed to the
+Apache Software Foundation (ASF) under one or more contributor
+license agreements. See the XML version (version_control.xml) for
+more details.
diff --git a/solr/contrib/extraction/src/test-files/extraction/version_control.xml b/solr/contrib/extraction/src/test-files/extraction/version_control.xml
new file mode 100644
index 0000000..4e09960
--- /dev/null
+++ b/solr/contrib/extraction/src/test-files/extraction/version_control.xml
@@ -0,0 +1,42 @@
+<?xml version="1.0"?>
+<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<document>
+  
+  <header>
+    <title>Solr Version Control System</title>
+  </header>
+  
+  <body>
+  
+    <section>
+      <title>Overview</title>
+      <p>
+        The Solr source code resides in the Apache <a href="http://subversion.tigris.org/">Subversion (SVN)</a> repository.
+        The command-line SVN client can be obtained <a href="http://subversion.tigris.org/project_packages.html">here</a> or as an optional package for <a href="http://www.cygwin.com/">cygwin</a>.
+        The TortoiseSVN GUI client for Windows can be obtained <a href="http://tortoisesvn.tigris.org/">here</a>. There
+        are also SVN plugins available for older versions of <a href="http://subclipse.tigris.org/">Eclipse</a> and 
+        <a href="http://svnup.tigris.org/">IntelliJ IDEA</a> that don't have subversion support already included.
+      </p>
+    </section>
+    <p>Here is some more text.  It contains <a href="http://lucene.apache.org">a link</a>. </p>
+    <p>Text Here</p>
+  </body>
+  
+</document>
diff --git a/solr/contrib/extraction/src/test-files/password-is-solrcell.docx b/solr/contrib/extraction/src/test-files/password-is-solrcell.docx
deleted file mode 100644
index 2723d56..0000000
diff --git a/solr/contrib/extraction/src/test-files/simple.html b/solr/contrib/extraction/src/test-files/simple.html
deleted file mode 100644
index f33cf92..0000000
--- a/solr/contrib/extraction/src/test-files/simple.html
+++ /dev/null
@@ -1,12 +0,0 @@
-<html>
-<head>
-  <title>Welcome to Solr</title>
-</head>
-<body>
-<p>
-  Here is some text
-</p>
-<div>Here is some text in a div</div>
-<div>This has a <a href="http://www.apache.org">link</a>.</div>
-</body>
-</html>
diff --git a/solr/contrib/extraction/src/test-files/solr-extraction/conf/protwords.txt b/solr/contrib/extraction/src/test-files/solr-extraction/conf/protwords.txt
deleted file mode 100644
index 7878147..0000000
--- a/solr/contrib/extraction/src/test-files/solr-extraction/conf/protwords.txt
+++ /dev/null
@@ -1,20 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#use a protected word file to avoid stemming two
-#unrelated words to the same base word.
-#to test, we will use words that would normally obviously be stemmed.
-cats
-ridding
diff --git a/solr/contrib/extraction/src/test-files/solr-extraction/conf/schema.xml b/solr/contrib/extraction/src/test-files/solr-extraction/conf/schema.xml
deleted file mode 100644
index 8cc3aaa..0000000
--- a/solr/contrib/extraction/src/test-files/solr-extraction/conf/schema.xml
+++ /dev/null
@@ -1,475 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- The Solr schema file. This file should be named "schema.xml" and
-     should be located where the classloader for the Solr webapp can find it.
-
-     This schema is used for testing, and as such has everything and the 
-     kitchen sink thrown in. See example/solr/conf/schema.xml for a 
-     more concise example.
-
-     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
-     $Name:  $
-  -->
-
-<schema name="test" version="1.0">
-  <types>
-
-    <!-- field type definitions... note that the "name" attribute is
-         just a label to be used by field definitions.  The "class"
-         attribute and any other attributes determine the real type and
-         behavior of the fieldtype.
-      -->
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't sort correctly or support range queries.)
-         These are provided more for backward compatability, allowing one
-         to create a schema that matches an existing lucene index.
-    -->
-    <fieldType name="integer" class="solr.IntField"/>
-    <fieldType name="long" class="solr.LongField"/>
-    <fieldtype name="float" class="solr.FloatField"/>
-    <fieldType name="double" class="solr.DoubleField"/>
-
-    <!-- numeric field types that manipulate the value into
-       a string value that isn't human readable in it's internal form,
-       but sorts correctly and supports range queries.
-
-         If sortMissingLast="true" then a sort on this field will cause documents
-       without the field to come after documents with the field,
-       regardless of the requested sort order.
-         If sortMissingFirst="true" then a sort on this field will cause documents
-       without the field to come before documents with the field,
-       regardless of the requested sort order.
-         If sortMissingLast="false" and sortMissingFirst="false" (the default),
-       then default lucene sorting will be used which places docs without the field
-       first in an ascending sort and last in a descending sort.
-    -->
-    <fieldtype name="sint" class="solr.SortableIntField" sortMissingLast="true"/>
-    <fieldtype name="slong" class="solr.SortableLongField" sortMissingLast="true"/>
-    <fieldtype name="sfloat" class="solr.SortableFloatField" sortMissingLast="true"/>
-    <fieldtype name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true"/>
-
-    <!-- bcd versions of sortable numeric type may provide smaller
-         storage space and support very large numbers.
-    -->
-    <fieldtype name="bcdint" class="solr.BCDIntField" sortMissingLast="true"/>
-    <fieldtype name="bcdlong" class="solr.BCDLongField" sortMissingLast="true"/>
-    <fieldtype name="bcdstr" class="solr.BCDStrField" sortMissingLast="true"/>
-
-    <!-- Field type demonstrating an Analyzer failure -->
-    <fieldtype name="failtype1" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- Demonstrating ignoreCaseChange -->
-    <fieldtype name="wdf_nocase" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    
-     <fieldtype name="wdf_preserve" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="1"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-
-    <!-- HighlitText optimizes storage for (long) columns which will be highlit -->
-    <fieldtype name="highlittext" class="solr.TextField" compressThreshold="345" />
-
-    <fieldtype name="boolean" class="solr.BoolField" sortMissingLast="true"/>
-    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
-
-    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
-         seconds part (.999) is optional.
-      -->
-    <fieldtype name="date" class="solr.DateField" sortMissingLast="true"/>
-
-    <!-- solr.TextField allows the specification of custom
-         text analyzers specified as a tokenizer and a list
-         of token filters.
-      -->
-    <fieldtype name="text" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.ClassicTokenizerFactory"/>
-        <filter class="solr.ClassicFilterFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.StopFilterFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-
-    <fieldtype name="nametext" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.core.WhitespaceAnalyzer"/>
-    </fieldtype>
-
-    <fieldtype name="teststop" class="solr.TextField">
-       <analyzer>
-        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
-        <filter class="solr.ClassicFilterFactory"/>
-        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- fieldtypes in this section isolate tokenizers and tokenfilters for testing -->
-    <fieldtype name="lowertok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.LowerCaseTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="keywordtok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.KeywordTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="standardtok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.StandardTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="lettertok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.LetterTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="whitetok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.WhitespaceTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="HTMLstandardtok" class="solr.TextField">
-      <analyzer>
-      <charFilter class="solr.HTMLStripCharFilterFactory"/>
-      <tokenizer class="solr.StandardTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="HTMLwhitetok" class="solr.TextField">
-      <analyzer>
-      <charFilter class="solr.HTMLStripCharFilterFactory"/>
-      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="standardtokfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.ClassicTokenizerFactory"/>
-        <filter class="solr.ClassicFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="standardfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.ClassicFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="lowerfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="patternreplacefilt" class="solr.TextField">
-      <analyzer type="index">
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-        <filter class="solr.PatternReplaceFilterFactory"
-                pattern="([^a-zA-Z])" replacement="_" replace="all"
-        />
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="porterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <!-- fieldtype name="snowballfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.SnowballPorterFilterFactory"/>
-      </analyzer>
-    </fieldtype -->
-    <fieldtype name="engporterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="custengporterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="stopfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="custstopfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="lengthfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.LengthFilterFactory" min="2" max="5"/>
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype name="subword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- more flexible in matching skus, but more chance of a false match -->
-    <fieldtype name="skutype1" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- less flexible in matching skus, but less chance of a false match -->
-    <fieldtype name="skutype2" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- less flexible in matching skus, but less chance of a false match -->
-    <fieldtype name="syn" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter name="syn" class="solr.SynonymFilterFactory" synonyms="synonyms.txt"/>
-      </analyzer>
-    </fieldtype>
-    
-    <!-- Demonstrates How RemoveDuplicatesTokenFilter makes stemmed
-         synonyms "better"
-      -->
-    <fieldtype name="dedup" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.SynonymFilterFactory"
-                  synonyms="synonyms.txt" expand="true" />
-          <filter class="solr.PorterStemFilterFactory"/>
-          <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype  name="unstored" class="solr.StrField" indexed="true" stored="false"/>
-
-
-  <fieldtype name="textgap" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-  </fieldtype>
-
- </types>
-
-
- <fields>
-   <field name="id" type="string" indexed="true" stored="true" multiValued="false" required="false"/>
-   <field name="name" type="nametext" indexed="true" stored="true"/>
-   <field name="text" type="text" indexed="true" stored="false"/>
-   <field name="subject" type="text" indexed="true" stored="true"/>
-   <field name="title" type="nametext" indexed="true" stored="true"/>
-   <field name="weight" type="float" indexed="true" stored="true"/>
-   <field name="bday" type="date" indexed="true" stored="true"/>
-
-   <field name="title_stemmed" type="text" indexed="true" stored="false"/>
-   <field name="title_lettertok" type="lettertok" indexed="true" stored="false"/>
-
-   <field name="syn" type="syn" indexed="true" stored="true"/>
-
-   <!-- to test property inheritance and overriding -->
-   <field name="shouldbeunstored" type="unstored" />
-   <field name="shouldbestored" type="unstored" stored="true"/>
-   <field name="shouldbeunindexed" type="unstored" indexed="false" stored="true"/>
-
-
-   <!-- test different combinations of indexed and stored -->
-   <field name="bind" type="boolean" indexed="true" stored="false"/>
-   <field name="bsto" type="boolean" indexed="false" stored="true"/>
-   <field name="bindsto" type="boolean" indexed="true" stored="true"/>
-   <field name="isto" type="integer" indexed="false" stored="true"/>
-   <field name="iind" type="integer" indexed="true" stored="false"/>
-   <field name="ssto" type="string" indexed="false" stored="true"/>
-   <field name="sind" type="string" indexed="true" stored="false"/>
-   <field name="sindsto" type="string" indexed="true" stored="true"/>
-
-   <!-- test combinations of term vector settings -->
-   <field name="test_basictv" type="text" termVectors="true"/>
-   <field name="test_notv" type="text" termVectors="false"/>
-   <field name="test_postv" type="text" termVectors="true" termPositions="true"/>
-   <field name="test_offtv" type="text" termVectors="true" termOffsets="true"/>
-   <field name="test_posofftv" type="text" termVectors="true" 
-     termPositions="true" termOffsets="true"/>
-
-   <!-- test highlit field settings -->
-   <field name="test_hlt" type="highlittext" indexed="true" compressed="true"/>
-   <field name="test_hlt_off" type="highlittext" indexed="true" compressed="false"/>
-
-   <!-- fields to test individual tokenizers and tokenfilters -->
-   <field name="teststop" type="teststop" indexed="true" stored="true"/>
-   <field name="lowertok" type="lowertok" indexed="true" stored="true"/>
-   <field name="keywordtok" type="keywordtok" indexed="true" stored="true"/>
-   <field name="standardtok" type="standardtok" indexed="true" stored="true"/>
-   <field name="HTMLstandardtok" type="HTMLstandardtok" indexed="true" stored="true"/>
-   <field name="lettertok" type="lettertok" indexed="true" stored="true"/>
-   <field name="whitetok" type="whitetok" indexed="true" stored="true"/>
-   <field name="HTMLwhitetok" type="HTMLwhitetok" indexed="true" stored="true"/>
-   <field name="standardtokfilt" type="standardtokfilt" indexed="true" stored="true"/>
-   <field name="standardfilt" type="standardfilt" indexed="true" stored="true"/>
-   <field name="lowerfilt" type="lowerfilt" indexed="true" stored="true"/>
-   <field name="patternreplacefilt" type="patternreplacefilt" indexed="true" stored="true"/>
-   <field name="porterfilt" type="porterfilt" indexed="true" stored="true"/>
-   <field name="engporterfilt" type="engporterfilt" indexed="true" stored="true"/>
-   <field name="custengporterfilt" type="custengporterfilt" indexed="true" stored="true"/>
-   <field name="stopfilt" type="stopfilt" indexed="true" stored="true"/>
-   <field name="custstopfilt" type="custstopfilt" indexed="true" stored="true"/>
-   <field name="lengthfilt" type="lengthfilt" indexed="true" stored="true"/>
-   <field name="dedup" type="dedup" indexed="true" stored="true"/>
-   <field name="wdf_nocase" type="wdf_nocase" indexed="true" stored="true"/>
-   <field name="wdf_preserve" type="wdf_preserve" indexed="true" stored="true"/>
-
-   <field name="numberpartfail" type="failtype1" indexed="true" stored="true"/>
-
-   <field name="nullfirst" type="string" indexed="true" stored="true" sortMissingFirst="true"/>
-
-   <field name="subword" type="subword" indexed="true" stored="true"/>
-   <field name="sku1" type="skutype1" indexed="true" stored="true"/>
-   <field name="sku2" type="skutype2" indexed="true" stored="true"/>
-
-   <field name="textgap" type="textgap" indexed="true" stored="true"/>
-   
-   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
-   <field name="multiDefault" type="string" indexed="true" stored="true" default="muLti-Default" multiValued="true"/>
-   <field name="intDefault" type="sint" indexed="true" stored="true" default="42" multiValued="false"/>
-   
-   <field name="extractedDate" type="date" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedContent" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedProducer" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedCreator" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedKeywords" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedAuthor" type="text" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractedLanguage" type="string" indexed="true" stored="true" multiValued="true"/>
-   <field name="resourceName" type="string" indexed="true" stored="true" multiValued="true"/>
-
-   <field name="extractionLiteralMV" type="string" indexed="true" stored="true" multiValued="true"/>
-   <field name="extractionLiteral" type="string" indexed="true" stored="true" multiValued="false"/>
-
-   <field name="defaultExtr" type="string" indexed="true" stored="false" />
-   
-   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
-        will be used if the name matches any of the patterns.
-        RESTRICTION: the glob-like pattern in the name attribute must have
-        a "*" only at the start or the end.
-        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
-        Longer patterns will be matched first.  if equal size patterns
-        both match, the first appearing in the schema will be used.
-   -->
-   <dynamicField name="*_i"  type="sint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
-   <dynamicField name="*_s1"  type="string"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_l"  type="slong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
-   <dynamicField name="*_f"  type="sfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_d"  type="sdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
-   <dynamicField name="*_bcd" type="bcdstr" indexed="true"  stored="true"/>
-
-   <dynamicField name="*_sI" type="string"  indexed="true"  stored="false"/>
-   <dynamicField name="*_sS" type="string"  indexed="false" stored="true"/>
-   <dynamicField name="t_*"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="tv_*"  type="text" indexed="true"  stored="true" 
-      termVectors="true" termPositions="true" termOffsets="true"/>
-
-   <dynamicField name="stream_*"  type="text" indexed="true"  stored="true"/>
-   <dynamicField name="Content*"  type="text" indexed="true"  stored="true"/>
-
-
-   <!-- special fields for dynamic copyField test -->
-   <dynamicField name="dynamic_*" type="string" indexed="true" stored="true"/>
-   <dynamicField name="*_dynamic" type="string" indexed="true" stored="true"/>
-  
-   <!-- for testing to ensure that longer patterns are matched first -->
-   <dynamicField name="*aa"  type="string"  indexed="true" stored="true"/>
-   <dynamicField name="*aaa" type="integer" indexed="false" stored="true"/>
-
-   <!-- ignored because not stored or indexed -->
-   <dynamicField name="ignored_*" type="text" indexed="false" stored="false"/>
-
- </fields>
-
- <defaultSearchField>text</defaultSearchField>
- <uniqueKey>id</uniqueKey>
-
-  <!-- copyField commands copy one field to another at the time a document
-        is added to the index.  It's used either to index the same field different
-        ways, or to add multiple fields to the same field for easier/faster searching.
-   -->
-   <copyField source="title" dest="title_stemmed"/>
-   <copyField source="title" dest="title_lettertok"/>
-
-   <copyField source="title" dest="text"/>
-   <copyField source="subject" dest="text"/>
- 
-   <copyField source="*_t" dest="text"/>
-   
-   <!-- dynamic destination -->
-   <copyField source="*_dynamic" dest="dynamic_*"/>
-    
-
-</schema>
diff --git a/solr/contrib/extraction/src/test-files/solr-extraction/conf/solrconfig.xml b/solr/contrib/extraction/src/test-files/solr-extraction/conf/solrconfig.xml
deleted file mode 100644
index 077f776..0000000
--- a/solr/contrib/extraction/src/test-files/solr-extraction/conf/solrconfig.xml
+++ /dev/null
@@ -1,300 +0,0 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- $Id: solrconfig.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source$
-     $Name$
-  -->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-  <jmx />
-
-  <!-- Used to specify an alternate directory to hold all index data.
-       It defaults to "index" if not present, and should probably
-       not be changed if replication is in use. -->
-  <dataDir>${solr.data.dir:}</dataDir>
-
-  <indexDefaults>
-   <!-- Values here affect all index writers and act as a default
-   unless overridden. -->
-    <!-- Values here affect all index writers and act as a default unless overridden. -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <!-- If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-     -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!-- Tell Lucene when to flush documents to disk.
-    Giving Lucene more memory for indexing means faster indexing at the cost of more RAM
-
-    If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene will flush based on whichever limit is hit first.
-
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-     Expert:
-     The Merge Policy in Lucene controls how merging is handled by Lucene.  The default in 2.3 is the LogByteSizeMergePolicy, previous
-     versions used LogDocMergePolicy.
-
-     LogByteSizeMergePolicy chooses segments to merge based on their size.  The Lucene 2.2 default, LogDocMergePolicy chose when
-     to merge based on number of documents
-
-     Other implementations of MergePolicy must have a no-argument constructor
-     -->
-    <mergePolicy>org.apache.lucene.index.LogByteSizeMergePolicy</mergePolicy>
-
-    <!--
-     Expert:
-     The Merge Scheduler in Lucene controls how merges are performed.  The ConcurrentMergeScheduler (Lucene 2.3 default)
-      can perform merges in the background using separate threads.  The SerialMergeScheduler (Lucene 2.2 default) does not.
-     -->
-    <mergeScheduler>org.apache.lucene.index.ConcurrentMergeScheduler</mergeScheduler>
-    <!-- these are global... can't currently override per index -->
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- lucene options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <unlockOnStartup>true</unlockOnStartup>
-  </mainIndex>
-
-  <updateHandler class="solr.DirectUpdateHandler2">
-
-    <!-- autocommit pending docs if certain criteria are met 
-    <autoCommit> 
-      <maxDocs>10000</maxDocs>
-      <maxTime>3600000</maxTime> 
-    </autoCommit>
-    -->
-    <!-- represents a lower bound on the frequency that commits may
-    occur (in seconds). NOTE: not yet implemented
-    
-    <commitIntervalLowerBound>0</commitIntervalLowerBound>
-    -->
-
-    <!-- The RunExecutableListener executes an external command.
-         exe - the name of the executable to run
-         dir - dir to use as the current working directory. default="."
-         wait - the calling thread waits until the executable returns. default="true"
-         args - the arguments to pass to the program.  default=nothing
-         env - environment variables to set.  default=nothing
-      -->
-    <!-- A postCommit event is fired after every commit
-    <listener event="postCommit" class="solr.RunExecutableListener">
-      <str name="exe">/var/opt/resin3/__PORT__/scripts/solr/snapshooter</str>
-      <str name="dir">/var/opt/resin3/__PORT__</str>
-      <bool name="wait">true</bool>
-      <arr name="args"> <str>arg1</str> <str>arg2</str> </arr>
-      <arr name="env"> <str>MYVAR=val1</str> </arr>
-    </listener>
-    -->
-
-
-  </updateHandler>
-
-
-  <query>
-    <!-- Maximum number of clauses in a boolean query... can affect
-        range or wildcard queries that expand to big boolean
-        queries.  An exception is thrown if exceeded.
-    -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-
-    <!-- Cache specification for Filters or DocSets - unordered set of *all* documents
-         that match a particular query.
-      -->
-    <filterCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="256"/>
-
-    <queryResultCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="1024"/>
-
-    <documentCache
-      class="solr.search.LRUCache"
-      size="512"
-      initialSize="512"
-      autowarmCount="0"/>
-
-    <!-- If true, stored fields that are not requested will be loaded lazily.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!--
-
-    <cache name="myUserCache"
-      class="solr.search.LRUCache"
-      size="4096"
-      initialSize="1024"
-      autowarmCount="1024"
-      regenerator="MyRegenerator"
-      />
-    -->
-
-
-    <useFilterForSortedQuery>true</useFilterForSortedQuery>
-
-    <queryResultWindowSize>10</queryResultWindowSize>
-
-    <!-- set maxSize artificially low to exercise both types of sets -->
-    <HashDocSet maxSize="3" loadFactor="0.75"/>
-
-
-    <!-- boolToFilterOptimizer converts boolean clauses with zero boost
-         into cached filters if the number of docs selected by the clause exceeds
-         the threshold (represented as a fraction of the total index)
-    -->
-    <boolTofilterOptimizer enabled="false" cacheSize="32" threshold=".05"/>
-
-
-    <!-- a newSearcher event is fired whenever a new searcher is being prepared
-         and there is a current searcher handling requests (aka registered). -->
-    <!-- QuerySenderListener takes an array of NamedList and executes a
-         local query request for each NamedList in sequence. -->
-    <!--
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">solr</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-        <lst> <str name="q">rocks</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-    <!-- a firstSearcher event is fired whenever a new searcher is being
-         prepared but there is no current registered searcher to handle
-         requests or to gain prewarming data from. -->
-    <!--
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst> <str name="q">fast_warm</str> <str name="start">0</str> <str name="rows">10</str> </lst>
-      </arr>
-    </listener>
-    -->
-
-
-  </query>
-
-
-  <!-- An alternate set representation that uses an integer hash to store filters (sets of docids).
-       If the set cardinality <= maxSize elements, then HashDocSet will be used instead of the bitset
-       based HashBitset. -->
-
-  <!-- requestHandler plugins... incoming queries will be dispatched to the
-     correct handler based on the qt (query type) param matching the
-     name of registered handlers.
-      The "standard" request handler is the default and will be used if qt
-     is not specified in the request.
-  -->
-  <requestHandler name="standard" class="solr.StandardRequestHandler">
-  	<bool name="httpCaching">true</bool>
-  </requestHandler>
-  <requestHandler name="dismax" class="solr.SearchHandler" >
-    <lst name="defaults">
-     <str name="defType">dismax</str>
-    </lst>
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="defaults" class="solr.StandardRequestHandler">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
-    <lst name="defaults">
-      <int name="rows">4</int>
-      <bool name="hl">true</bool>
-      <str name="hl.fl">text,name,subject,title,whitetok</str>
-    </lst>
-  </requestHandler>
-
-  <requestHandler name="/update"     class="solr.XmlUpdateRequestHandler"          />
-  <requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
-  	<bool name="httpCaching">false</bool>
-  </requestHandler>
-  
-  <requestHandler name="/update/extract" class="org.apache.solr.handler.extraction.ExtractingRequestHandler"/>
-
-
-  <highlighting>
-   <!-- Configure the standard fragmenter -->
-   <fragmenter name="gap" class="org.apache.solr.highlight.GapFragmenter" default="true">
-    <lst name="defaults">
-     <int name="hl.fragsize">100</int>
-    </lst>
-   </fragmenter>
-
-   <fragmenter name="regex" class="org.apache.solr.highlight.RegexFragmenter">
-    <lst name="defaults">
-     <int name="hl.fragsize">70</int>
-    </lst>
-   </fragmenter>
-
-   <!-- Configure the standard formatter -->
-   <formatter name="html" class="org.apache.solr.highlight.HtmlFormatter" default="true">
-    <lst name="defaults">
-     <str name="hl.simple.pre"><![CDATA[<em>]]></str>
-     <str name="hl.simple.post"><![CDATA[</em>]]></str>
-    </lst>
-   </formatter>
-  </highlighting>
-
-
-  <!-- enable streaming for testing... -->
-  <requestDispatcher handleSelect="true" >
-    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048" />
-    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
-      <cacheControl>max-age=30, public</cacheControl>
-    </httpCaching>
-  </requestDispatcher>
-
-  <admin>
-    <defaultQuery>solr</defaultQuery>
-    <gettableFiles>solrconfig.xml scheam.xml admin-extra.html</gettableFiles>
-  </admin>
-
-  <!-- test getting system property -->
-  <propTest attr1="${solr.test.sys.prop1}-$${literal}"
-            attr2="${non.existent.sys.prop:default-from-config}">prefix-${solr.test.sys.prop2}-suffix</propTest>
-
-</config>
diff --git a/solr/contrib/extraction/src/test-files/solr-extraction/conf/stopwords.txt b/solr/contrib/extraction/src/test-files/solr-extraction/conf/stopwords.txt
deleted file mode 100644
index 688e307..0000000
--- a/solr/contrib/extraction/src/test-files/solr-extraction/conf/stopwords.txt
+++ /dev/null
@@ -1,16 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-stopworda
-stopwordb
diff --git a/solr/contrib/extraction/src/test-files/solr-extraction/conf/synonyms.txt b/solr/contrib/extraction/src/test-files/solr-extraction/conf/synonyms.txt
deleted file mode 100644
index a7624f0..0000000
--- a/solr/contrib/extraction/src/test-files/solr-extraction/conf/synonyms.txt
+++ /dev/null
@@ -1,22 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-a => aa
-b => b1 b2
-c => c1,c2
-a\=>a => b\=>b
-a\,a => b\,b
-foo,bar,baz
-
-Television,TV,Televisions
diff --git a/solr/contrib/extraction/src/test-files/solr-word.pdf b/solr/contrib/extraction/src/test-files/solr-word.pdf
deleted file mode 100644
index bd8b865..0000000
--- a/solr/contrib/extraction/src/test-files/solr-word.pdf
+++ /dev/null
@@ -1,2 +0,0 @@
-This is a test of PDF and Word extraction in Solr, it is only a test. Do not panic.
-
\ No newline at end of file
diff --git a/solr/contrib/extraction/src/test-files/version_control.txt b/solr/contrib/extraction/src/test-files/version_control.txt
deleted file mode 100644
index 7a89c5b..0000000
--- a/solr/contrib/extraction/src/test-files/version_control.txt
+++ /dev/null
@@ -1,18 +0,0 @@
-Solr Version Control System
- 
-Overview
- 
-The Solr source code resides in the Apache Subversion (SVN) repository.
-The command-line SVN client can be obtained here or as an optional package
-for cygwin.
-
-The TortoiseSVN GUI client for Windows can be obtained here. There
-are also SVN plugins available for older versions of Eclipse and 
-IntelliJ IDEA that don't have subversion support already included.
-
--------------------------------
-
-Note: This document is an excerpt from a document Licensed to the
-Apache Software Foundation (ASF) under one or more contributor
-license agreements. See the XML version (version_control.xml) for
-more details.
diff --git a/solr/contrib/extraction/src/test-files/version_control.xml b/solr/contrib/extraction/src/test-files/version_control.xml
deleted file mode 100644
index 4e09960..0000000
--- a/solr/contrib/extraction/src/test-files/version_control.xml
+++ /dev/null
@@ -1,42 +0,0 @@
-<?xml version="1.0"?>
-<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<document>
-  
-  <header>
-    <title>Solr Version Control System</title>
-  </header>
-  
-  <body>
-  
-    <section>
-      <title>Overview</title>
-      <p>
-        The Solr source code resides in the Apache <a href="http://subversion.tigris.org/">Subversion (SVN)</a> repository.
-        The command-line SVN client can be obtained <a href="http://subversion.tigris.org/project_packages.html">here</a> or as an optional package for <a href="http://www.cygwin.com/">cygwin</a>.
-        The TortoiseSVN GUI client for Windows can be obtained <a href="http://tortoisesvn.tigris.org/">here</a>. There
-        are also SVN plugins available for older versions of <a href="http://subclipse.tigris.org/">Eclipse</a> and 
-        <a href="http://svnup.tigris.org/">IntelliJ IDEA</a> that don't have subversion support already included.
-      </p>
-    </section>
-    <p>Here is some more text.  It contains <a href="http://lucene.apache.org">a link</a>. </p>
-    <p>Text Here</p>
-  </body>
-  
-</document>
diff --git a/solr/contrib/extraction/src/test/org/apache/solr/handler/extraction/ExtractingRequestHandlerTest.java b/solr/contrib/extraction/src/test/org/apache/solr/handler/extraction/ExtractingRequestHandlerTest.java
index f42b2d4..4b57a60 100644
--- a/solr/contrib/extraction/src/test/org/apache/solr/handler/extraction/ExtractingRequestHandlerTest.java
+++ b/solr/contrib/extraction/src/test/org/apache/solr/handler/extraction/ExtractingRequestHandlerTest.java
@@ -41,7 +41,7 @@ import org.junit.Test;
 public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
   @BeforeClass
   public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml", "schema.xml", "solr-extraction");
+    initCore("solrconfig.xml", "schema.xml", getFile("extraction/solr").getAbsolutePath());
   }
 
   @Override
@@ -56,7 +56,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
   public void testExtraction() throws Exception {
     ExtractingRequestHandler handler = (ExtractingRequestHandler) h.getCore().getRequestHandler("/update/extract");
     assertTrue("handler is null and it shouldn't be", handler != null);
-    loadLocal("solr-word.pdf",
+    loadLocal("extraction/solr-word.pdf",
             "fmap.created", "extractedDate",
             "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
@@ -73,7 +73,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("title:solr-word"), "//*[@numFound='1']");
 
 
-    loadLocal("simple.html", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/simple.html", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "fmap.language", "extractedLanguage",
@@ -86,7 +86,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("title:Welcome"), "//*[@numFound='1']");
 
 
-    loadLocal("simple.html",
+    loadLocal("extraction/simple.html",
       "literal.id","simple2",
       "uprefix", "t_",
       "lowernames", "true",
@@ -105,7 +105,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("+id:simple2 +t_abcxyz:[* TO *]"), "//*[@numFound='1']");
 
     // load again in the exact same way, but boost one field
-    loadLocal("simple.html",
+    loadLocal("extraction/simple.html",
       "literal.id","simple3",
       "uprefix", "t_",
       "lowernames", "true",
@@ -120,7 +120,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("+id:simple3 +t_content_type:[* TO *]"), "//*[@numFound='1']");//test lowercase and then uprefix
 
     // test capture
-     loadLocal("simple.html",
+     loadLocal("extraction/simple.html",
       "literal.id","simple4",
       "uprefix", "t_",
       "capture","p",     // capture only what is in the title element
@@ -129,7 +129,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("+id:simple4 +t_content:Solr"), "//*[@numFound='1']");
     assertQ(req("+id:simple4 +t_p:\"here is some text\""), "//*[@numFound='1']");
 
-    loadLocal("version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "literal.id", "three",
@@ -152,7 +152,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     try {
       ignoreException("unknown field 'a'");
       ignoreException("unknown field 'meta'");  // TODO: should this exception be happening?
-      loadLocal("simple.html",
+      loadLocal("extraction/simple.html",
       "literal.id","simple2",
       "lowernames", "true",
         "captureAttr", "true",
@@ -168,7 +168,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     }
     
 
-    loadLocal("simple.html",
+    loadLocal("extraction/simple.html",
       "literal.id","simple2",
       ExtractingParams.DEFAULT_FIELD, "defaultExtr",//test that unmapped fields go to the text field when no uprefix is specified
       "lowernames", "true",
@@ -180,7 +180,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("defaultExtr:http\\://www.apache.org"), "//*[@numFound='1']");
 
     //Test when both uprefix and default are specified.
-    loadLocal("simple.html",
+    loadLocal("extraction/simple.html",
       "literal.id","simple2",
       ExtractingParams.DEFAULT_FIELD, "defaultExtr",//test that unmapped fields go to the text field when no uprefix is specified
             ExtractingParams.UNKNOWN_FIELD_PREFIX, "t_",
@@ -198,7 +198,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     ExtractingRequestHandler handler = (ExtractingRequestHandler) h.getCore().getRequestHandler("/update/extract");
     assertTrue("handler is null and it shouldn't be", handler != null);
     //test literal
-    loadLocal("version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "fmap.content", "extractedContent",
@@ -217,7 +217,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("extractionLiteralMV:two"), "//*[@numFound='1']");
 
     try {
-      loadLocal("version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+      loadLocal("extraction/version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
               "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
               "fmap.Author", "extractedAuthor",
               "fmap.content", "extractedContent",
@@ -233,7 +233,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
       //nothing to see here, move along
     }
 
-    loadLocal("version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/version_control.xml", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "fmap.content", "extractedContent",
@@ -253,7 +253,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertTrue("handler is null and it shouldn't be", handler != null);
 
     // Load plain text specifying MIME type:
-    loadLocal("version_control.txt", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/version_control.txt", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "literal.id", "one",
@@ -272,13 +272,13 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertTrue("handler is null and it shouldn't be", handler != null);
 
     // Load plain text specifying filename
-    loadLocal("version_control.txt", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/version_control.txt", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
             "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
             "fmap.Author", "extractedAuthor",
             "literal.id", "one",
             "fmap.language", "extractedLanguage",
             "fmap.content", "extractedContent",
-            ExtractingParams.RESOURCE_NAME, "version_control.txt"
+            ExtractingParams.RESOURCE_NAME, "extraction/version_control.txt"
     );
     assertQ(req("extractedContent:Apache"), "//*[@numFound='0']");
     assertU(commit());
@@ -292,7 +292,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
   public void testExtractOnly() throws Exception {
     ExtractingRequestHandler handler = (ExtractingRequestHandler) h.getCore().getRequestHandler("/update/extract");
     assertTrue("handler is null and it shouldn't be", handler != null);
-    SolrQueryResponse rsp = loadLocal("solr-word.pdf", ExtractingParams.EXTRACT_ONLY, "true");
+    SolrQueryResponse rsp = loadLocal("extraction/solr-word.pdf", ExtractingParams.EXTRACT_ONLY, "true");
     assertTrue("rsp is null and it shouldn't be", rsp != null);
     NamedList list = rsp.getValues();
 
@@ -306,7 +306,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertTrue("title is null and it shouldn't be", title != null);
     assertTrue(extraction.indexOf("<?xml") != -1);
 
-    rsp = loadLocal("solr-word.pdf", ExtractingParams.EXTRACT_ONLY, "true",
+    rsp = loadLocal("extraction/solr-word.pdf", ExtractingParams.EXTRACT_ONLY, "true",
             ExtractingParams.EXTRACT_FORMAT, ExtractingDocumentLoader.TEXT_FORMAT);
     assertTrue("rsp is null and it shouldn't be", rsp != null);
     list = rsp.getValues();
@@ -329,7 +329,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
   public void testXPath() throws Exception {
     ExtractingRequestHandler handler = (ExtractingRequestHandler) h.getCore().getRequestHandler("/update/extract");
     assertTrue("handler is null and it shouldn't be", handler != null);
-    SolrQueryResponse rsp = loadLocal("example.html",
+    SolrQueryResponse rsp = loadLocal("extraction/example.html",
             ExtractingParams.XPATH_EXPRESSION, "/xhtml:html/xhtml:body/xhtml:a/descendant:node()",
             ExtractingParams.EXTRACT_ONLY, "true"
     );
@@ -347,7 +347,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
       h.getCore().getRequestHandler("/update/extract");
     assertTrue("handler is null and it shouldn't be", handler != null);
 
-    loadLocal("arabic.pdf", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+    loadLocal("extraction/arabic.pdf", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
         "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
         "fmap.Creation-Date", "extractedDate",
         "fmap.AAPL:Keywords", "ignored_a",
@@ -368,7 +368,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertTrue("handler is null and it shouldn't be", handler != null);
 
     try{
-      loadLocal("password-is-solrcell.docx",
+      loadLocal("extraction/password-is-solrcell.docx",
           "literal.id", "one");
       fail("TikaException is expected because of trying to extract text from password protected word file.");
     }
@@ -377,7 +377,7 @@ public class ExtractingRequestHandlerTest extends SolrTestCaseJ4 {
     assertQ(req("*:*"), "//result[@numFound=0]");
 
     try{
-      loadLocal("password-is-solrcell.docx", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
+      loadLocal("extraction/password-is-solrcell.docx", "fmap.created", "extractedDate", "fmap.producer", "extractedProducer",
           "fmap.creator", "extractedCreator", "fmap.Keywords", "extractedKeywords",
           "fmap.Creation-Date", "extractedDate",
           "fmap.AAPL:Keywords", "ignored_a",
diff --git a/solr/contrib/uima/src/test-files/AggregateSentenceAE.xml b/solr/contrib/uima/src/test-files/AggregateSentenceAE.xml
deleted file mode 100644
index 73d697e..0000000
--- a/solr/contrib/uima/src/test-files/AggregateSentenceAE.xml
+++ /dev/null
@@ -1,70 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>false</primitive>
-  <delegateAnalysisEngineSpecifiers>
-    <delegateAnalysisEngine key="WhitespaceTokenizer">
-      <import name="WhitespaceTokenizer"/>
-    </delegateAnalysisEngine>
-    <delegateAnalysisEngine key="HmmTagger">
-      <import name="HmmTagger"/>
-    </delegateAnalysisEngine>
-  </delegateAnalysisEngineSpecifiers>
-  <analysisEngineMetaData>
-    <name>AggregateSentenceAE</name>
-    <description/>
-    <version>1.0</version>
-    <vendor/>
-    <configurationParameters>
-      <configurationParameter>
-        <name>ngramsize</name>
-        <type>Integer</type>
-        <multiValued>false</multiValued>
-        <mandatory>false</mandatory>
-        <overrides>
-          <parameter>HmmTagger/NGRAM_SIZE</parameter>
-        </overrides>
-      </configurationParameter>
-    </configurationParameters>
-    <configurationParameterSettings/>
-    <flowConstraints>
-      <fixedFlow>
-        <node>WhitespaceTokenizer</node>
-        <node>HmmTagger</node>
-      </fixedFlow>
-    </flowConstraints>
-    <fsIndexCollection/>
-    <capabilities>
-      <capability>
-        <inputs/>
-        <outputs>
-          <type allAnnotatorFeatures="true">org.apache.uima.SentenceAnnotation</type>
-          <type allAnnotatorFeatures="true">org.apache.uima.TokenAnnotation</type>
-        </outputs>
-        <languagesSupported/>
-      </capability>
-    </capabilities>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/DummyEntityAEDescriptor.xml b/solr/contrib/uima/src/test-files/DummyEntityAEDescriptor.xml
deleted file mode 100644
index 33f05e5..0000000
--- a/solr/contrib/uima/src/test-files/DummyEntityAEDescriptor.xml
+++ /dev/null
@@ -1,68 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>true</primitive>
-  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummyEntityAnnotator</annotatorImplementationName>
-  <analysisEngineMetaData>
-    <name>DummyEntityAEDescriptor</name>
-    <description/>
-    <version>1.0</version>
-    <vendor>ASF</vendor>
-    <configurationParameters/>
-    <configurationParameterSettings/>
-    <typeSystemDescription>
-      <types>
-        <typeDescription>
-          <name>org.apache.solr.uima.ts.EntityAnnotation</name>
-          <description/>
-          <supertypeName>uima.tcas.Annotation</supertypeName>
-          <features>
-            <featureDescription>
-              <name>name</name>
-              <description/>
-              <rangeTypeName>uima.cas.String</rangeTypeName>
-            </featureDescription>
-            <featureDescription>
-              <name>entity</name>
-              <description/>
-              <rangeTypeName>uima.cas.String</rangeTypeName>
-            </featureDescription>
-          </features>
-        </typeDescription>
-      </types>
-    </typeSystemDescription>
-    <typePriorities/>
-    <fsIndexCollection/>
-    <capabilities>
-      <capability>
-        <inputs/>
-        <outputs>
-          <type allAnnotatorFeatures="true">org.apache.solr.uima.ts.EntityAnnotation</type>
-        </outputs>
-        <languagesSupported/>
-      </capability>
-    </capabilities>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/DummyExceptionAEDescriptor.xml b/solr/contrib/uima/src/test-files/DummyExceptionAEDescriptor.xml
deleted file mode 100644
index 3d0314a..0000000
--- a/solr/contrib/uima/src/test-files/DummyExceptionAEDescriptor.xml
+++ /dev/null
@@ -1,40 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>true</primitive>
-  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummyExceptionAnnotator</annotatorImplementationName>
-  <analysisEngineMetaData>
-    <name>DummyExceptionAEDescriptor</name>
-    <description/>
-    <version>1.0</version>
-    <vendor>ASF</vendor>
-    <configurationParameters/>
-    <configurationParameterSettings/>
-    <typeSystemDescription/>
-    <typePriorities/>
-    <fsIndexCollection/>
-    <capabilities/>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/DummySentimentAnalysisAEDescriptor.xml b/solr/contrib/uima/src/test-files/DummySentimentAnalysisAEDescriptor.xml
deleted file mode 100644
index 315266d..0000000
--- a/solr/contrib/uima/src/test-files/DummySentimentAnalysisAEDescriptor.xml
+++ /dev/null
@@ -1,60 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>true</primitive>
-  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummySentimentAnnotator</annotatorImplementationName>
-  <analysisEngineMetaData>
-    <name>DummySentimentAnalysisAEDescriptor</name>
-    <description/>
-    <version>1.0</version>
-    <vendor>ASF</vendor>
-    <configurationParameters/>
-    <configurationParameterSettings/>
-    <typeSystemDescription>
-      <types>
-        <typeDescription>
-          <name>org.apache.solr.uima.ts.SentimentAnnotation</name>
-          <description/>
-          <supertypeName>uima.tcas.Annotation</supertypeName>
-          <features>
-            <featureDescription>
-              <name>mood</name>
-              <description/>
-              <rangeTypeName>uima.cas.String</rangeTypeName>
-            </featureDescription>
-          </features>
-        </typeDescription>
-      </types>
-    </typeSystemDescription>
-    <typePriorities/>
-    <fsIndexCollection/>
-    <capabilities>
-      <capability>
-        <inputs/>
-        <outputs/>
-      </capability>
-    </capabilities>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/TestAE.xml b/solr/contrib/uima/src/test-files/TestAE.xml
deleted file mode 100644
index 70fb9b6..0000000
--- a/solr/contrib/uima/src/test-files/TestAE.xml
+++ /dev/null
@@ -1,72 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
-  -->
-
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>false</primitive>
-  <delegateAnalysisEngineSpecifiers>
-    <delegateAnalysisEngine key="AggregateSentenceAE">
-      <import location="AggregateSentenceAE.xml"/>
-    </delegateAnalysisEngine>
-    <delegateAnalysisEngine key="DummyEntityAEDescriptor">
-      <import location="DummyEntityAEDescriptor.xml"/>
-    </delegateAnalysisEngine>
-    <delegateAnalysisEngine key="DummySentimentAnalysisAEDescriptor">
-      <import location="DummySentimentAnalysisAEDescriptor.xml"/>
-    </delegateAnalysisEngine>
-  </delegateAnalysisEngineSpecifiers>
-  <analysisEngineMetaData>
-    <name>TestAE</name>
-    <description/>
-    <version>1.0</version>
-    <vendor/>
-    <configurationParameters>
-      <configurationParameter>
-        <name>ngramsize</name>
-        <type>Integer</type>
-        <multiValued>false</multiValued>
-        <mandatory>false</mandatory>
-        <overrides>
-          <parameter>AggregateSentenceAE/ngramsize</parameter>
-        </overrides>
-      </configurationParameter>
-    </configurationParameters>
-    <configurationParameterSettings/>
-    <flowConstraints>
-      <fixedFlow>
-        <node>AggregateSentenceAE</node>
-        <node>DummyEntityAEDescriptor</node>
-        <node>DummySentimentAnalysisAEDescriptor</node>
-      </fixedFlow>
-    </flowConstraints>
-    <fsIndexCollection/>
-    <capabilities>
-      <capability>
-        <inputs/>
-        <outputs/>
-        <languagesSupported/>
-      </capability>
-    </capabilities>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
\ No newline at end of file
diff --git a/solr/contrib/uima/src/test-files/TestExceptionAE.xml b/solr/contrib/uima/src/test-files/TestExceptionAE.xml
deleted file mode 100644
index 434105f..0000000
--- a/solr/contrib/uima/src/test-files/TestExceptionAE.xml
+++ /dev/null
@@ -1,54 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed to the Apache Software Foundation (ASF) under one or more
-  contributor license agreements.  See the NOTICE file distributed with
-  this work for additional information regarding copyright ownership.
-  The ASF licenses this file to You under the Apache License, Version 2.0
-  (the "License"); you may not use this file except in compliance with
-  the License.  You may obtain a copy of the License at
-
-      http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
-  -->
-
-<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
-  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
-  <primitive>false</primitive>
-  <delegateAnalysisEngineSpecifiers>
-    <delegateAnalysisEngine key="DummyExceptionAEDescriptor">
-      <import location="DummyExceptionAEDescriptor.xml"/>
-    </delegateAnalysisEngine>
-  </delegateAnalysisEngineSpecifiers>
-  <analysisEngineMetaData>
-    <name>TestExceptionAE</name>
-    <description/>
-    <version>1.0</version>
-    <vendor/>
-    <configurationParameters/>
-    <configurationParameterSettings/>
-    <flowConstraints>
-      <fixedFlow>
-        <node>DummyExceptionAEDescriptor</node>
-      </fixedFlow>
-    </flowConstraints>
-    <fsIndexCollection/>
-    <capabilities>
-      <capability>
-        <inputs/>
-        <outputs/>
-        <languagesSupported/>
-      </capability>
-    </capabilities>
-    <operationalProperties>
-      <modifiesCas>true</modifiesCas>
-      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
-      <outputsNewCASes>false</outputsNewCASes>
-    </operationalProperties>
-  </analysisEngineMetaData>
-  <resourceManagerConfiguration/>
-</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/protwords.txt b/solr/contrib/uima/src/test-files/solr-uima/conf/protwords.txt
deleted file mode 100644
index 1dfc0ab..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/protwords.txt
+++ /dev/null
@@ -1,21 +0,0 @@
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-# Use a protected word file to protect against the stemmer reducing two
-# unrelated words to the same base word.
-
-# Some non-words that normally won't be encountered,
-# just to test that they won't be stemmed.
-dontstems
-zwhacky
-
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/schema.xml b/solr/contrib/uima/src/test-files/solr-uima/conf/schema.xml
deleted file mode 100644
index 3abb0ce..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/schema.xml
+++ /dev/null
@@ -1,678 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-  <!--
-    Licensed to the Apache Software Foundation (ASF) under one or more
-    contributor license agreements. See the NOTICE file distributed with
-    this work for additional information regarding copyright ownership.
-    The ASF licenses this file to You under the Apache License, Version
-    2.0 (the "License"); you may not use this file except in compliance
-    with the License. You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0 Unless required by
-    applicable law or agreed to in writing, software distributed under
-    the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES
-    OR CONDITIONS OF ANY KIND, either express or implied. See the
-    License for the specific language governing permissions and
-    limitations under the License.
-  -->
-
-  <!--
-    This is the Solr schema file. This file should be named "schema.xml"
-    and should be in the conf directory under the solr home (i.e.
-    ./solr/conf/schema.xml by default) or located where the classloader
-    for the Solr webapp can find it. This example schema is the
-    recommended starting point for users. It should be kept correct and
-    concise, usable out-of-the-box. For more information, on how to
-    customize this file, please see
-    http://wiki.apache.org/solr/SchemaXml PERFORMANCE NOTE: this schema
-    includes many optional features and should not be used for
-    benchmarking. To improve performance one could - set stored="false"
-    for all fields possible (esp large fields) when you only need to
-    search on the field but don't need to return the original value. -
-    set indexed="false" if you don't need to search on the field, but
-    only return the field as a result of searching on other indexed
-    fields. - remove all unneeded copyField statements - for best index
-    size and searching performance, set "index" to false for all general
-    text fields, use copyField to copy them to the catchall "text"
-    field, and use that for searching. - For maximum indexing
-    performance, use the StreamingUpdateSolrServer java client. -
-    Remember to run the JVM in server mode, and use a higher logging
-    level that avoids logging every request
-  -->
-
-<schema name="sample" version="1.2">
-  <!--
-    attribute "name" is the name of this schema and is only used for
-    display purposes. Applications should change this to reflect the
-    nature of the search collection. version="1.2" is Solr's version
-    number for the schema syntax and semantics. It should not normally
-    be changed by applications. 1.0: multiValued attribute did not
-    exist, all fields are multiValued by nature 1.1: multiValued
-    attribute introduced, false by default 1.2: omitTermFreqAndPositions
-    attribute introduced, true by default except for text fields.
-  -->
-
-  <types>
-    <!--
-      field type definitions. The "name" attribute is just a label to be
-      used by field definitions. The "class" attribute and any other
-      attributes determine the real behavior of the fieldType. Class
-      names starting with "solr" refer to java classes in the
-      org.apache.solr.analysis package.
-    -->
-
-    <!--
-      The StrField type is not analyzed, but indexed/stored verbatim. -
-      StrField and TextField support an optional compressThreshold which
-      limits compression (if enabled in the derived fields) to values
-      which exceed a certain size (in characters).
-    -->
-    <fieldType name="string" class="solr.StrField"
-      sortMissingLast="true" omitNorms="true" />
-
-    <!-- boolean type: "true" or "false" -->
-    <fieldType name="boolean" class="solr.BoolField"
-      sortMissingLast="true" omitNorms="true" />
-    <!--
-      Binary data type. The data should be sent/retrieved in as Base64
-      encoded Strings
-    -->
-    <fieldtype name="binary" class="solr.BinaryField" />
-
-    <!--
-      The optional sortMissingLast and sortMissingFirst attributes are
-      currently supported on types that are sorted internally as
-      strings. This includes
-      "string","boolean","sint","slong","sfloat","sdouble","pdate" - If
-      sortMissingLast="true", then a sort on this field will cause
-      documents without the field to come after documents with the
-      field, regardless of the requested sort order (asc or desc). - If
-      sortMissingFirst="true", then a sort on this field will cause
-      documents without the field to come before documents with the
-      field, regardless of the requested sort order. - If
-      sortMissingLast="false" and sortMissingFirst="false" (the
-      default), then default lucene sorting will be used which places
-      docs without the field first in an ascending sort and last in a
-      descending sort.
-    -->
-
-    <!--
-      Default numeric field types. For faster range queries, consider
-      the tint/tfloat/tlong/tdouble types.
-    -->
-    <fieldType name="int" class="solr.TrieIntField"
-      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="float" class="solr.TrieFloatField"
-      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="long" class="solr.TrieLongField"
-      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="double" class="solr.TrieDoubleField"
-      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
-
-    <!--
-      Numeric field types that index each value at various levels of
-      precision to accelerate range queries when the number of values
-      between the range endpoints is large. See the javadoc for
-      NumericRangeQuery for internal implementation details. Smaller
-      precisionStep values (specified in bits) will lead to more tokens
-      indexed per value, slightly larger index size, and faster range
-      queries. A precisionStep of 0 disables indexing at different
-      precision levels.
-    -->
-    <fieldType name="tint" class="solr.TrieIntField"
-      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="tfloat" class="solr.TrieFloatField"
-      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="tlong" class="solr.TrieLongField"
-      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
-    <fieldType name="tdouble" class="solr.TrieDoubleField"
-      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
-
-    <!--
-      The format for this date field is of the form
-      1995-12-31T23:59:59Z, and is a more restricted form of the
-      canonical representation of dateTime
-      http://www.w3.org/TR/xmlschema-2/#dateTime The trailing "Z"
-      designates UTC time and is mandatory. Optional fractional seconds
-      are allowed: 1995-12-31T23:59:59.999Z All other components are
-      mandatory. Expressions can also be used to denote calculations
-      that should be performed relative to "NOW" to determine the value,
-      ie... NOW/HOUR ... Round to the start of the current hour NOW-1DAY
-      ... Exactly 1 day prior to now NOW/DAY+6MONTHS+3DAYS ... 6 months
-      and 3 days in the future from the start of the current day Consult
-      the DateField javadocs for more information. Note: For faster
-      range queries, consider the tdate type
-    -->
-    <fieldType name="date" class="solr.TrieDateField"
-      omitNorms="true" precisionStep="0" positionIncrementGap="0" />
-
-    <!--
-      A Trie based date field for faster date range queries and date
-      faceting.
-    -->
-    <fieldType name="tdate" class="solr.TrieDateField"
-      omitNorms="true" precisionStep="6" positionIncrementGap="0" />
-
-
-    <!--
-      Note: These should only be used for compatibility with existing
-      indexes (created with older Solr versions) or if
-      "sortMissingFirst" or "sortMissingLast" functionality is needed.
-      Use Trie based fields instead. Plain numeric field types that
-      store and index the text value verbatim (and hence don't support
-      range queries, since the lexicographic ordering isn't equal to the
-      numeric ordering)
-    -->
-    <fieldType name="pint" class="solr.IntField" omitNorms="true" />
-    <fieldType name="plong" class="solr.LongField" omitNorms="true" />
-    <fieldType name="pfloat" class="solr.FloatField"
-      omitNorms="true" />
-    <fieldType name="pdouble" class="solr.DoubleField"
-      omitNorms="true" />
-    <fieldType name="pdate" class="solr.DateField"
-      sortMissingLast="true" omitNorms="true" />
-
-
-    <!--
-      Note: These should only be used for compatibility with existing
-      indexes (created with older Solr versions) or if
-      "sortMissingFirst" or "sortMissingLast" functionality is needed.
-      Use Trie based fields instead. Numeric field types that manipulate
-      the value into a string value that isn't human-readable in its
-      internal form, but with a lexicographic ordering the same as the
-      numeric ordering, so that range queries work correctly.
-    -->
-    <fieldType name="sint" class="solr.SortableIntField"
-      sortMissingLast="true" omitNorms="true" />
-    <fieldType name="slong" class="solr.SortableLongField"
-      sortMissingLast="true" omitNorms="true" />
-    <fieldType name="sfloat" class="solr.SortableFloatField"
-      sortMissingLast="true" omitNorms="true" />
-    <fieldType name="sdouble" class="solr.SortableDoubleField"
-      sortMissingLast="true" omitNorms="true" />
-
-
-    <!--
-      The "RandomSortField" is not used to store or search any data. You
-      can declare fields of this type it in your schema to generate
-      pseudo-random orderings of your docs for sorting purposes. The
-      ordering is generated based on the field name and the version of
-      the index, As long as the index version remains unchanged, and the
-      same field name is reused, the ordering of the docs will be
-      consistent. If you want different psuedo-random orderings of
-      documents, for the same version of the index, use a dynamicField
-      and change the name
-    -->
-    <fieldType name="random" class="solr.RandomSortField"
-      indexed="true" />
-
-    <!--
-      solr.TextField allows the specification of custom text analyzers
-      specified as a tokenizer and a list of token filters. Different
-      analyzers may be specified for indexing and querying. The optional
-      positionIncrementGap puts space between multiple fields of this
-      type on the same document, with the purpose of preventing false
-      phrase matching across fields. For more info on customizing your
-      analyzer chain, please see
-      http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
-    -->
-
-    <!--
-      One can also specify an existing Analyzer class that has a default
-      constructor via the class attribute on the analyzer element
-      <fieldType name="text_greek" class="solr.TextField"> <analyzer
-      class="org.apache.lucene.analysis.el.GreekAnalyzer"/> </fieldType>
-    -->
-
-    <!--
-      A text field that only splits on whitespace for exact matching of
-      words
-    -->
-    <fieldType name="text_ws" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-      </analyzer>
-    </fieldType>
-
-    <!--
-      A text field that uses WordDelimiterFilter to enable splitting and
-      matching of words on case-change, alpha numeric boundaries, and
-      non-alphanumeric chars, so that a query of "wifi" or "wi fi" could
-      match a document containing "Wi-Fi". Synonyms and stopwords are
-      customized by external files, and stemming is enabled.
-    -->
-    <fieldType name="text" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <!--
-          in this example, we will only use synonyms at query time
-          <filter class="solr.SynonymFilterFactory"
-          synonyms="index_synonyms.txt" ignoreCase="true"
-          expand="false"/>
-        -->
-        <!--
-          Case insensitive stop word removal. add
-          enablePositionIncrements=true in both the index and query
-          analyzers to leave a 'gap' for more accurate phrase queries.
-        -->
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="1"
-          catenateNumbers="1" catenateAll="0" splitOnCaseChange="1" />
-        <filter class="solr.LowerCaseFilterFactory" />
-        
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
-          ignoreCase="true" expand="true" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="0"
-          catenateNumbers="0" catenateAll="0" splitOnCaseChange="1" />
-        <filter class="solr.LowerCaseFilterFactory" />
-        
-      </analyzer>
-    </fieldType>
-
-
-    <!--
-      Less flexible matching, but less false matches. Probably not ideal
-      for product names, but may be good for SKUs. Can insert dashes in
-      the wrong place and still match.
-    -->
-    <fieldType name="textTight" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
-          ignoreCase="true" expand="false" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="0" generateNumberParts="0" catenateWords="1"
-          catenateNumbers="1" catenateAll="0" />
-        <filter class="solr.LowerCaseFilterFactory" />
-        
-        <!--
-          this filter can remove any duplicate tokens that appear at the
-          same position - sometimes possible with WordDelimiterFilter in
-          conjuncton with stemming.
-        -->
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
-      </analyzer>
-    </fieldType>
-
-
-    <!--
-      A general unstemmed text field - good if one does not know the
-      language of the field
-    -->
-    <fieldType name="textgen" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="1"
-          catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
-        <filter class="solr.LowerCaseFilterFactory" />
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
-          ignoreCase="true" expand="true" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="0"
-          catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
-        <filter class="solr.LowerCaseFilterFactory" />
-      </analyzer>
-    </fieldType>
-
-
-    <!--
-      A general unstemmed text field that indexes tokens normally and
-      also reversed (via ReversedWildcardFilterFactory), to enable more
-      efficient leading wildcard queries.
-    -->
-    <fieldType name="text_rev" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="1"
-          catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
-        <filter class="solr.LowerCaseFilterFactory" />
-        <filter class="solr.ReversedWildcardFilterFactory"
-          withOriginal="true" maxPosAsterisk="3" maxPosQuestion="2"
-          maxFractionAsterisk="0.33" />
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
-          ignoreCase="true" expand="true" />
-        <filter class="solr.StopFilterFactory" ignoreCase="true"
-          words="stopwords.txt" enablePositionIncrements="true" />
-        <filter class="solr.WordDelimiterFilterFactory"
-          generateWordParts="1" generateNumberParts="1" catenateWords="0"
-          catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
-        <filter class="solr.LowerCaseFilterFactory" />
-      </analyzer>
-    </fieldType>
-
-    <!-- charFilter + WhitespaceTokenizer  -->
-    <!--
-      <fieldType name="textCharNorm" class="solr.TextField"
-      positionIncrementGap="100" > <analyzer> <charFilter
-      class="solr.MappingCharFilterFactory"
-      mapping="mapping-ISOLatin1Accent.txt"/> <tokenizer
-      class="solr.WhitespaceTokenizerFactory"/> </analyzer> </fieldType>
-    -->
-
-    <!--
-      This is an example of using the KeywordTokenizer along With
-      various TokenFilterFactories to produce a sortable field that does
-      not include some properties of the source text
-    -->
-    <fieldType name="alphaOnlySort" class="solr.TextField"
-      sortMissingLast="true" omitNorms="true">
-      <analyzer>
-        <!--
-          KeywordTokenizer does no actual tokenizing, so the entire
-          input string is preserved as a single token
-        -->
-        <tokenizer class="solr.KeywordTokenizerFactory" />
-        <!--
-          The LowerCase TokenFilter does what you expect, which can be
-          when you want your sorting to be case insensitive
-        -->
-        <filter class="solr.LowerCaseFilterFactory" />
-        <!-- The TrimFilter removes any leading or trailing whitespace -->
-        <filter class="solr.TrimFilterFactory" />
-        <!--
-          The PatternReplaceFilter gives you the flexibility to use Java
-          Regular expression to replace any sequence of characters
-          matching a pattern with an arbitrary replacement string, which
-          may include back references to portions of the original string
-          matched by the pattern. See the Java Regular Expression
-          documentation for more information on pattern and replacement
-          string syntax.
-
-          http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
-        -->
-        <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])"
-          replacement="" replace="all" />
-      </analyzer>
-    </fieldType>
-
-    <fieldtype name="phonetic" stored="false" indexed="true"
-      class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory" />
-        <filter class="solr.DoubleMetaphoneFilterFactory" inject="false" />
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype name="payloads" stored="false" indexed="true"
-      class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory" />
-        <!--
-          The DelimitedPayloadTokenFilter can put payloads on tokens...
-          for example, a token of "foo|1.4" would be indexed as "foo"
-          with a payload of 1.4f Attributes of the
-          DelimitedPayloadTokenFilterFactory : "delimiter" - a one
-          character delimiter. Default is | (pipe) "encoder" - how to
-          encode the following value into a playload float ->
-          org.apache.lucene.analysis.payloads.FloatEncoder, integer ->
-          o.a.l.a.p.IntegerEncoder identity -> o.a.l.a.p.IdentityEncoder
-          Fully Qualified class name implementing PayloadEncoder,
-          Encoder must have a no arg constructor.
-        -->
-        <filter class="solr.DelimitedPayloadTokenFilterFactory"
-          encoder="float" />
-      </analyzer>
-    </fieldtype>
-
-    <!--
-      lowercases the entire field value, keeping it as a single token.
-    -->
-    <fieldType name="lowercase" class="solr.TextField"
-      positionIncrementGap="100">
-      <analyzer>
-        <tokenizer class="solr.KeywordTokenizerFactory" />
-        <filter class="solr.LowerCaseFilterFactory" />
-      </analyzer>
-    </fieldType>
-
-
-    <!--
-      since fields of this type are by default not stored or indexed,
-      any data added to them will be ignored outright.
-    -->
-    <fieldtype name="ignored" stored="false" indexed="false"
-      multiValued="true" class="solr.StrField" />
-
-  </types>
-
-
-  <fields>
-    <!--
-      Valid attributes for fields: name: mandatory - the name for the
-      field type: mandatory - the name of a previously defined type from
-      the <types> section indexed: true if this field should be indexed
-      (searchable or sortable) stored: true if this field should be
-      retrievable compressed: [false] if this field should be stored
-      using gzip compression (this will only apply if the field type is
-      compressable; among the standard field types, only TextField and
-      StrField are) multiValued: true if this field may contain multiple
-      values per document omitNorms: (expert) set to true to omit the
-      norms associated with this field (this disables length
-      normalization and index-time boosting for the field, and saves
-      some memory). Only full-text fields or fields that need an
-      index-time boost need norms. termVectors: [false] set to true to
-      store the term vector for a given field. When using MoreLikeThis,
-      fields used for similarity should be stored for best performance.
-      termPositions: Store position information with the term vector.
-      This will increase storage costs. termOffsets: Store offset
-      information with the term vector. This will increase storage
-      costs. default: a value that should be used if no value is
-      specified when adding a document.
-    -->
-    <field name="id" type="string" indexed="true" stored="true"
-      required="true" />
-    <field name="sku" type="textTight" indexed="true" stored="true"
-      omitNorms="true" />
-    <field name="name" type="textgen" indexed="true" stored="true" />
-    <field name="alphaNameSort" type="alphaOnlySort" indexed="true"
-      stored="false" />
-    <field name="manu" type="textgen" indexed="true" stored="true"
-      omitNorms="true" />
-    <field name="cat" type="text_ws" indexed="true" stored="true"
-      multiValued="true" omitNorms="true" />
-    <field name="features" type="text" indexed="true" stored="true"
-      multiValued="true" />
-    <field name="includes" type="text" indexed="true" stored="true"
-      termVectors="true" termPositions="true" termOffsets="true" />
-
-    <field name="weight" type="float" indexed="true" stored="true" />
-    <field name="price" type="float" indexed="true" stored="true" />
-    <field name="popularity" type="int" indexed="true" stored="true" />
-    <field name="inStock" type="boolean" indexed="true" stored="true" />
-
-
-    <!--
-      Common metadata fields, named specifically to match up with
-      SolrCell metadata when parsing rich documents such as Word, PDF.
-      Some fields are multiValued only because Tika currently may return
-      multiple values for them.
-    -->
-    <field name="title" type="text" indexed="true" stored="true"
-      multiValued="true" />
-    <field name="subject" type="text" indexed="true" stored="true" />
-    <field name="description" type="text" indexed="true" stored="true" />
-    <field name="comments" type="text" indexed="true" stored="true" />
-    <field name="author" type="textgen" indexed="true" stored="true" />
-    <field name="keywords" type="textgen" indexed="true" stored="true" />
-    <field name="category" type="textgen" indexed="true" stored="true" />
-    <field name="content_type" type="string" indexed="true"
-      stored="true" multiValued="true" />
-    <field name="last_modified" type="date" indexed="true" stored="true" />
-    <field name="links" type="string" indexed="true" stored="true"
-      multiValued="true" />
-
-
-    <!--
-      catchall field, containing all other searchable text fields
-      (implemented via copyField further on in this schema
-    -->
-    <field name="text" type="text" indexed="true" stored="false"
-      multiValued="true" />
-
-    <!--
-      catchall text field that indexes tokens both normally and in
-      reverse for efficient leading wildcard queries.
-    -->
-    <field name="text_rev" type="text_rev" indexed="true" stored="false"
-      multiValued="true" />
-
-    <!--
-      non-tokenized version of manufacturer to make it easier to sort or
-      group results by manufacturer. copied from "manu" via copyField
-    -->
-    <field name="manu_exact" type="string" indexed="true" stored="false" />
-
-    <field name="payloads" type="payloads" indexed="true" stored="true" />
-
-    <!--
-      Uncommenting the following will create a "timestamp" field using a
-      default value of "NOW" to indicate when each document was indexed.
-    -->
-    <!--
-      <field name="timestamp" type="date" indexed="true" stored="true"
-      default="NOW" multiValued="false"/>
-    -->
-
-  <field name="language" type="string" indexed="true" stored="true" required="false"/>
-  <field name="sentence" type="text" indexed="true" stored="true" multiValued="true" required="false" />
-  <field name="sentiment" type="string" indexed="true" stored="true" multiValued="true"/>
-  <field name="entity" type="text" indexed="true" stored="true" multiValued="true"/>
-
-    <!--
-      Dynamic field definitions. If a field name is not found,
-      dynamicFields will be used if the name matches any of the
-      patterns. RESTRICTION: the glob-like pattern in the name attribute
-      must have a "*" only at the start or the end. EXAMPLE: name="*_i"
-      will match any field ending in _i (like myid_i, z_i) Longer
-      patterns will be matched first. if equal size patterns both match,
-      the first appearing in the schema will be used. <dynamicField
-      name="*_i" type="int" indexed="true" stored="true"/> <dynamicField
-      name="*_s" type="string" indexed="true" stored="true"/>
-      <dynamicField name="*_l" type="long" indexed="true"
-      stored="true"/> <dynamicField name="*_t" type="text"
-      indexed="true" stored="true"/> <dynamicField name="*_b"
-      type="boolean" indexed="true" stored="true"/> <dynamicField
-      name="*_f" type="float" indexed="true" stored="true"/>
-      <dynamicField name="*_d" type="double" indexed="true"
-      stored="true"/> <dynamicField name="*_dt" type="date"
-      indexed="true" stored="true"/> <dynamicField name="*_ti"
-      type="tint" indexed="true" stored="true"/> <dynamicField
-      name="*_tl" type="tlong" indexed="true" stored="true"/>
-      <dynamicField name="*_tf" type="tfloat" indexed="true"
-      stored="true"/> <dynamicField name="*_td" type="tdouble"
-      indexed="true" stored="true"/> <dynamicField name="*_tdt"
-      type="tdate" indexed="true" stored="true"/> <dynamicField
-      name="*_pi" type="pint" indexed="true" stored="true"/>
-
-      <dynamicField name="ignored_*" type="ignored" multiValued="true"/>
-      <dynamicField name="attr_*" type="textgen" indexed="true"
-      stored="true" multiValued="true"/> <dynamicField name="random_*"
-      type="random" />
-    -->
-    <dynamicField name="*_sm" type="string" indexed="true" stored="true" multiValued="true"/>
-    <!--
-      uncomment the following to ignore any fields that don't already
-      match an existing field name or dynamic field, rather than
-      reporting them as an error. alternately, change the type="ignored"
-      to some other type e.g. "text" if you want unknown fields indexed
-      and/or stored by default
-    -->
-    <!--dynamicField name="*" type="ignored" multiValued="true" /-->
-
-  </fields>
-
-  <!--
-    Field to use to determine and enforce document uniqueness. Unless
-    this field is marked with required="false", it will be a required
-    field
-  -->
-  <uniqueKey>id</uniqueKey>
-
-  <!--
-    field for the QueryParser to use when an explicit fieldname is
-    absent
-  -->
-  <defaultSearchField>text</defaultSearchField>
-
-  <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
-  <solrQueryParser defaultOperator="OR" />
-
-  <!--
-    copyField commands copy one field to another at the time a document
-    is added to the index. It's used either to index the same field
-    differently, or to add multiple fields to the same field for
-    easier/faster searching.
-  -->
-
-  <copyField source="cat" dest="text" />
-  <copyField source="name" dest="text" />
-  <copyField source="manu" dest="text" />
-  <copyField source="features" dest="text" />
-  <copyField source="includes" dest="text" />
-  <copyField source="manu" dest="manu_exact" />
-
-
-  <!--copyField source="Titolo" dest="text"/-->
-
-  <!--
-    Above, multiple source fields are copied to the [text] field.
-    Another way to map multiple source fields to the same destination
-    field is to use the dynamic field syntax. copyField also supports a
-    maxChars to copy setting.
-  -->
-
-  <!-- <copyField source="*_t" dest="text" maxChars="3000"/> -->
-
-  <!--
-    copy name to alphaNameSort, a field designed for sorting by name
-  -->
-  <!-- <copyField source="name" dest="alphaNameSort"/> -->
-
-
-  <!--
-    Similarity is the scoring routine for each document vs. a query. A
-    custom similarity may be specified here, but the default is fine for
-    most applications.
-  -->
-  <!--
-    <similarity class="org.apache.lucene.search.DefaultSimilarity"/>
-  -->
-  <!--
-    ... OR ... Specify a SimilarityFactory class name implementation
-    allowing parameters to be used.
-  -->
-  <!--
-    <similarity class="com.example.solr.CustomSimilarityFactory"> <str
-    name="paramkey">param value</str> </similarity>
-  -->
-
-
-</schema>
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/solrconfig.xml b/solr/contrib/uima/src/test-files/solr-uima/conf/solrconfig.xml
deleted file mode 100644
index 4da170e..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/solrconfig.xml
+++ /dev/null
@@ -1,1124 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-
-  <!--
-    Licensed to the Apache Software Foundation (ASF) under one or more
-    contributor license agreements. See the NOTICE file distributed with
-    this work for additional information regarding copyright ownership.
-    The ASF licenses this file to You under the Apache License, Version
-    2.0 (the "License"); you may not use this file except in compliance
-    with the License. You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0 Unless required by
-    applicable law or agreed to in writing, software distributed under
-    the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES
-    OR CONDITIONS OF ANY KIND, either express or implied. See the
-    License for the specific language governing permissions and
-    limitations under the License.
-  -->
-  <!--
-    For more details about configurations options that may appear in
-    this file, see http://wiki.apache.org/solr/SolrConfigXml.
-
-    Specifically, the Solr Config can support XInclude, which may make
-    it easier to manage the configuration. See
-    https://issues.apache.org/jira/browse/SOLR-1167
-  -->
-<config xmlns:xi="http://www.w3.org/2001/XInclude">
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-  <!--
-    lib directives can be used to instruct Solr to load an Jars
-    identified and use them to resolve any "plugins" specified in your
-    solrconfig.xml or schema.xml (ie: Analyzers, Request Handlers,
-    etc...). All directories and paths are resolved relative the
-    instanceDir. If a "./lib" directory exists in your instanceDir, all
-    files found in it are included as if you had used the following
-    syntax... <lib dir="./lib" />
-  -->
-  <!--
-    A dir option by itself adds any files found in the directory to the
-    classpath, this is useful for including all jars in a directory.
-  -->
-  <lib dir="../../contrib/extraction/lib" />
-  <!--
-    When a regex is specified in addition to a directory, only the files
-    in that directory which completely match the regex (anchored on both
-    ends) will be included.
-  -->
-  <lib dir="../../dist/" regex="apache-solr-cell-\d.*\.jar" />
-  <lib dir="../../dist/" regex="apache-solr-clustering-\d.*\.jar" />
-  <!--
-    If a dir option (with or without a regex) is used and nothing is
-    found that matches, it will be ignored
-  -->
-  <lib dir="../../contrib/clustering/lib/downloads/" />
-  <lib dir="../../contrib/clustering/lib/" />
-  <lib dir="/total/crap/dir/ignored" />
-  <!--
-    an exact path can be used to specify a specific file. This will
-    cause a serious error to be logged if it can't be loaded. <lib
-    path="../a-jar-that-does-not-exist.jar" />
-  -->
-
-
-  <!--
-    Used to specify an alternate directory to hold all index data other
-    than the default ./data under the Solr home. If replication is in
-    use, this should match the replication configuration.
-  -->
-  <dataDir>${solr.data.dir:}</dataDir>
-
-
-  <!--
-    WARNING: this <indexDefaults> section only provides defaults for
-    index writers in general. See also the <mainIndex> section after
-    that when changing parameters for Solr's main Lucene index.
-  -->
-  <indexDefaults>
-    <!--
-      Values here affect all index writers and act as a default unless
-      overridden.
-    -->
-    <useCompoundFile>false</useCompoundFile>
-
-    <mergeFactor>10</mergeFactor>
-    <!--
-      If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene
-      will flush based on whichever limit is hit first.
-    -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-
-    <!--
-      Sets the amount of RAM that may be used by Lucene indexing for
-      buffering added documents and deletions before they are flushed to
-      the Directory.
-    -->
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <!-- <maxMergeDocs>2147483647</maxMergeDocs> -->
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <!--
-      Expert: Turn on Lucene's auto commit capability. This causes
-      intermediate segment flushes to write a new lucene index
-      descriptor, enabling it to be opened by an external IndexReader.
-      This can greatly slow down indexing speed. NOTE: Despite the name,
-      this value does not have any relation to Solr's autoCommit
-      functionality
-    -->
-    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
-
-    <!--
-      Expert: The Merge Policy in Lucene controls how merging is handled
-      by Lucene. The default in 2.3 is the LogByteSizeMergePolicy,
-      previous versions used LogDocMergePolicy. LogByteSizeMergePolicy
-      chooses segments to merge based on their size. The Lucene 2.2
-      default, LogDocMergePolicy chose when to merge based on number of
-      documents Other implementations of MergePolicy must have a
-      no-argument constructor
-    -->
-    <!--
-      <mergePolicy
-      class="org.apache.lucene.index.LogByteSizeMergePolicy"/>
-    -->
-
-    <!--
-      Expert: The Merge Scheduler in Lucene controls how merges are
-      performed. The ConcurrentMergeScheduler (Lucene 2.3 default) can
-      perform merges in the background using separate threads. The
-      SerialMergeScheduler (Lucene 2.2 default) does not.
-    -->
-    <!--
-      <mergeScheduler
-      class="org.apache.lucene.index.ConcurrentMergeScheduler"/>
-    -->
-
-
-    <!--
-      This option specifies which Lucene LockFactory implementation to
-      use. single = SingleInstanceLockFactory - suggested for a
-      read-only index or when there is no possibility of another process
-      trying to modify the index. native = NativeFSLockFactory - uses OS
-      native file locking simple = SimpleFSLockFactory - uses a plain
-      file for locking (For backwards compatibility with Solr 1.2,
-      'simple' is the default if not specified.)
-    -->
-    <lockType>native</lockType>
-    <!--
-      Expert: Controls how often Lucene loads terms into memory
-    -->
-    <!--<termIndexInterval>256</termIndexInterval>-->
-  </indexDefaults>
-
-  <mainIndex>
-    <!-- options specific to the main on-disk lucene index -->
-    <useCompoundFile>false</useCompoundFile>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <mergeFactor>10</mergeFactor>
-    <!-- Deprecated -->
-    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
-    <!--<maxMergeDocs>2147483647</maxMergeDocs>-->
-
-    <!--
-      inherit from indexDefaults <maxFieldLength>10000</maxFieldLength>
-    -->
-
-    <!--
-      If true, unlock any held write or commit locks on startup. This
-      defeats the locking mechanism that allows multiple processes to
-      safely access a lucene index, and should be used with care. This
-      is not needed if lock type is 'none' or 'single'
-    -->
-    <unlockOnStartup>false</unlockOnStartup>
-
-    <!--
-      If true, IndexReaders will be reopened (often more efficient)
-      instead of closed and then opened.
-    -->
-    <reopenReaders>true</reopenReaders>
-
-    <!--
-      Expert: Controls how often Lucene loads terms into memory. Default
-      is 128 and is likely good for most everyone.
-    -->
-    <!--<termIndexInterval>256</termIndexInterval>-->
-
-    <!--
-      Custom deletion policies can specified here. The class must
-      implement org.apache.lucene.index.IndexDeletionPolicy.
-
-      http://lucene.apache.org/java/2_3_2/api/org/apache/lucene/index/IndexDeletionPolicy.html
-
-      The standard Solr IndexDeletionPolicy implementation supports
-      deleting index commit points on number of commits, age of commit
-      point and optimized status. The latest commit point should always
-      be preserved regardless of the criteria.
-    -->
-    <deletionPolicy class="solr.SolrDeletionPolicy">
-      <!-- The number of commit points to be kept -->
-      <str name="maxCommitsToKeep">1</str>
-      <!-- The number of optimized commit points to be kept -->
-      <str name="maxOptimizedCommitsToKeep">0</str>
-      <!--
-        Delete all commit points once they have reached the given age.
-        Supports DateMathParser syntax e.g. <str
-        name="maxCommitAge">30MINUTES</str> <str
-        name="maxCommitAge">1DAY</str>
-      -->
-    </deletionPolicy>
-
-    <!--
-      To aid in advanced debugging, you may turn on IndexWriter debug
-      logging. Setting to true will set the file that the underlying
-      Lucene IndexWriter will write its debug infostream to.
-    -->
-    <infoStream file="INFOSTREAM.txt">false</infoStream>
-
-  </mainIndex>
-
-  <!--
-    Enables JMX if and only if an existing MBeanServer is found, use
-    this if you want to configure JMX through JVM parameters. Remove
-    this to disable exposing Solr configuration and statistics to JMX.
-
-    If you want to connect to a particular server, specify the agentId
-    e.g. <jmx agentId="myAgent" /> If you want to start a new
-    MBeanServer, specify the serviceUrl e.g <jmx
-    serviceUrl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr"/> For
-    more details see http://wiki.apache.org/solr/SolrJmx
-  -->
-  <jmx />
-
-  <!-- the default high-performance update handler -->
-  <updateHandler class="solr.DirectUpdateHandler2">
-    <!--
-      A prefix of "solr." for class names is an alias that causes solr
-      to search appropriate packages, including
-      org.apache.solr.(search|update|request|core|analysis)
-    -->
-
-    <!--
-      Perform a <commit/> automatically under certain conditions:
-      maxDocs - number of updates since last commit is greater than this
-      maxTime - oldest uncommited update (in ms) is this long ago
-      Instead of enabling autoCommit, consider using "commitWithin" when
-      adding documents. http://wiki.apache.org/solr/UpdateXmlMessages
-      <autoCommit> <maxDocs>10000</maxDocs> <maxTime>1000</maxTime>
-      </autoCommit>
-    -->
-
-
-    <!--
-      The RunExecutableListener executes an external command from a hook
-      such as postCommit or postOptimize. exe - the name of the
-      executable to run dir - dir to use as the current working
-      directory. default="." wait - the calling thread waits until the
-      executable returns. default="true" args - the arguments to pass to
-      the program. default=nothing env - environment variables to set.
-      default=nothing
-    -->
-    <!--
-      A postCommit event is fired after every commit or optimize command
-      <listener event="postCommit" class="solr.RunExecutableListener">
-      <str name="exe">solr/bin/snapshooter</str> <str name="dir">.</str>
-      <bool name="wait">true</bool> <arr name="args"> <str>arg1</str>
-      <str>arg2</str> </arr> <arr name="env"> <str>MYVAR=val1</str>
-      </arr> </listener>
-    -->
-    <!--
-      A postOptimize event is fired only after every optimize command
-      <listener event="postOptimize" class="solr.RunExecutableListener">
-      <str name="exe">snapshooter</str> <str name="dir">solr/bin</str>
-      <bool name="wait">true</bool> </listener>
-    -->
-
-  </updateHandler>
-
-  <!--
-    Use the following format to specify a custom IndexReaderFactory -
-    allows for alternate IndexReader implementations. ** Experimental
-    Feature ** Please note - Using a custom IndexReaderFactory may
-    prevent certain other features from working. The API to
-    IndexReaderFactory may change without warning or may even be removed
-    from future releases if the problems cannot be resolved. ** Features
-    that may not work with custom IndexReaderFactory ** The
-    ReplicationHandler assumes a disk-resident index. Using a custom
-    IndexReader implementation may cause incompatibility with
-    ReplicationHandler and may cause replication to not work correctly.
-    See SOLR-1366 for details. <indexReaderFactory
-    name="IndexReaderFactory" class="package.class"> Parameters as
-    required by the implementation </indexReaderFactory >
-  -->
-  <!-- To set the termInfosIndexDivisor, do this: -->
-  <!--
-    <indexReaderFactory name="IndexReaderFactory"
-    class="org.apache.solr.core.StandardIndexReaderFactory"> <int
-    name="setTermIndexDivisor">12</int> </indexReaderFactory >
-  -->
-
-
-  <query>
-    <!--
-      Maximum number of clauses in a boolean query... in the past, this
-      affected range or prefix queries that expanded to big boolean
-      queries - built in Solr query parsers no longer create queries
-      with this limitation. An exception is thrown if exceeded.
-    -->
-    <maxBooleanClauses>1024</maxBooleanClauses>
-
-
-    <!--
-      There are two implementations of cache available for Solr,
-      LRUCache, based on a synchronized LinkedHashMap, and FastLRUCache,
-      based on a ConcurrentHashMap. FastLRUCache has faster gets and
-      slower puts in single threaded operation and thus is generally
-      faster than LRUCache when the hit ratio of the cache is high (>
-      75%), and may be faster under other scenarios on multi-cpu
-      systems.
-    -->
-    <!--
-      Cache used by SolrIndexSearcher for filters (DocSets), unordered
-      sets of *all* documents that match a query. When a new searcher is
-      opened, its caches may be prepopulated or "autowarmed" using data
-      from caches in the old searcher. autowarmCount is the number of
-      items to prepopulate. For LRUCache, the autowarmed items will be
-      the most recently accessed items. Parameters: class - the
-      SolrCache implementation LRUCache or FastLRUCache size - the
-      maximum number of entries in the cache initialSize - the initial
-      capacity (number of entries) of the cache. (seel
-      java.util.HashMap) autowarmCount - the number of entries to
-      prepopulate from and old cache.
-    -->
-    <filterCache class="solr.FastLRUCache" size="512"
-      initialSize="512" autowarmCount="0" />
-
-    <!--
-      Cache used to hold field values that are quickly accessible by
-      document id. The fieldValueCache is created by default even if not
-      configured here. <fieldValueCache class="solr.FastLRUCache"
-      size="512" autowarmCount="128" showItems="32" />
-    -->
-
-    <!--
-      queryResultCache caches results of searches - ordered lists of
-      document ids (DocList) based on a query, a sort, and the range of
-      documents requested.
-    -->
-    <queryResultCache class="solr.LRUCache" size="512"
-      initialSize="512" autowarmCount="0" />
-
-    <!--
-      documentCache caches Lucene Document objects (the stored fields
-      for each document). Since Lucene internal document ids are
-      transient, this cache will not be autowarmed.
-    -->
-    <documentCache class="solr.LRUCache" size="512"
-      initialSize="512" autowarmCount="0" />
-
-    <!--
-      If true, stored fields that are not requested will be loaded
-      lazily. This can result in a significant speed improvement if the
-      usual case is to not load all stored fields, especially if the
-      skipped fields are large compressed text fields.
-    -->
-    <enableLazyFieldLoading>true</enableLazyFieldLoading>
-
-    <!--
-      Example of a generic cache. These caches may be accessed by name
-      through SolrIndexSearcher.getCache(),cacheLookup(), and
-      cacheInsert(). The purpose is to enable easy caching of
-      user/application level data. The regenerator argument should be
-      specified as an implementation of solr.search.CacheRegenerator if
-      autowarming is desired.
-    -->
-    <!--
-      <cache name="myUserCache" class="solr.LRUCache" size="4096"
-      initialSize="1024" autowarmCount="1024"
-      regenerator="org.mycompany.mypackage.MyRegenerator" />
-    -->
-
-    <!--
-      An optimization that attempts to use a filter to satisfy a search.
-      If the requested sort does not include score, then the filterCache
-      will be checked for a filter matching the query. If found, the
-      filter will be used as the source of document ids, and then the
-      sort will be applied to that.
-      <useFilterForSortedQuery>true</useFilterForSortedQuery>
-    -->
-
-    <!--
-      An optimization for use with the queryResultCache. When a search
-      is requested, a superset of the requested number of document ids
-      are collected. For example, if a search for a particular query
-      requests matching documents 10 through 19, and queryWindowSize is
-      50, then documents 0 through 49 will be collected and cached. Any
-      further requests in that range can be satisfied via the cache.
-    -->
-    <queryResultWindowSize>20</queryResultWindowSize>
-
-    <!--
-      Maximum number of documents to cache for any entry in the
-      queryResultCache.
-    -->
-    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
-
-    <!--
-      a newSearcher event is fired whenever a new searcher is being
-      prepared and there is a current searcher handling requests (aka
-      registered). It can be used to prime certain caches to prevent
-      long request times for certain requests.
-    -->
-    <!--
-      QuerySenderListener takes an array of NamedList and executes a
-      local query request for each NamedList in sequence.
-    -->
-    <listener event="newSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <!--
-          <lst> <str name="q">solr</str> <str name="start">0</str> <str
-          name="rows">10</str> </lst> <lst> <str name="q">rocks</str>
-          <str name="start">0</str> <str name="rows">10</str> </lst>
-          <lst><str name="q">static newSearcher warming query from
-          solrconfig.xml</str></lst>
-        -->
-      </arr>
-    </listener>
-
-    <!--
-      a firstSearcher event is fired whenever a new searcher is being
-      prepared but there is no current registered searcher to handle
-      requests or to gain autowarming data from.
-    -->
-    <listener event="firstSearcher" class="solr.QuerySenderListener">
-      <arr name="queries">
-        <lst>
-          <str name="q">solr rocks</str>
-          <str name="start">0</str>
-          <str name="rows">10</str>
-        </lst>
-        <lst>
-          <str name="q">static firstSearcher warming query from
-            solrconfig.xml</str>
-        </lst>
-      </arr>
-    </listener>
-
-    <!--
-      If a search request comes in and there is no current registered
-      searcher, then immediately register the still warming searcher and
-      use it. If "false" then all requests will block until the first
-      searcher is done warming.
-    -->
-    <useColdSearcher>false</useColdSearcher>
-
-    <!--
-      Maximum number of searchers that may be warming in the background
-      concurrently. An error is returned if this limit is exceeded.
-      Recommend 1-2 for read-only slaves, higher for masters w/o cache
-      warming.
-    -->
-    <maxWarmingSearchers>2</maxWarmingSearchers>
-
-  </query>
-
-  <!--
-    Let the dispatch filter handler /select?qt=XXX handleSelect=true
-    will use consistent error handling for /select and /update
-    handleSelect=false will use solr1.1 style error formatting
-  -->
-  <requestDispatcher handleSelect="true">
-    <!--
-      Make sure your system has some authentication before enabling
-      remote streaming!
-    -->
-    <requestParsers enableRemoteStreaming="true"
-      multipartUploadLimitInKB="2048000" />
-
-    <!--
-      Set HTTP caching related parameters (for proxy caches and
-      clients). To get the behaviour of Solr 1.2 (ie: no caching related
-      headers) use the never304="true" option and do not specify a value
-      for <cacheControl>
-    -->
-    <!-- <httpCaching never304="true"> -->
-    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr">
-      <!--
-        lastModFrom="openTime" is the default, the Last-Modified value
-        (and validation against If-Modified-Since requests) will all be
-        relative to when the current Searcher was opened. You can change
-        it to lastModFrom="dirLastMod" if you want the value to exactly
-        corrispond to when the physical index was last modified.
-
-        etagSeed="..." is an option you can change to force the ETag
-        header (and validation against If-None-Match requests) to be
-        differnet even if the index has not changed (ie: when making
-        significant changes to your config file) lastModifiedFrom and
-        etagSeed are both ignored if you use the never304="true" option.
-      -->
-      <!--
-        If you include a <cacheControl> directive, it will be used to
-        generate a Cache-Control header, as well as an Expires header if
-        the value contains "max-age=" By default, no Cache-Control
-        header is generated. You can use the <cacheControl> option even
-        if you have set never304="true"
-      -->
-      <!-- <cacheControl>max-age=30, public</cacheControl> -->
-    </httpCaching>
-  </requestDispatcher>
-
-
-  <!--
-    requestHandler plugins... incoming queries will be dispatched to the
-    correct handler based on the path or the qt (query type) param.
-    Names starting with a '/' are accessed with the a path equal to the
-    registered name. Names without a leading '/' are accessed with:
-    http://host/app/select?qt=name If no qt is defined, the
-    requestHandler that declares default="true" will be used.
-  -->
-  <requestHandler name="standard" class="solr.SearchHandler"
-    default="true">
-    <!-- default values for query parameters -->
-    <lst name="defaults">
-      <str name="echoParams">explicit</str>
-      <!--
-        <int name="rows">10</int> <str name="fl">*</str> <str
-        name="version">2.1</str>
-      -->
-    </lst>
-  </requestHandler>
-
-  <!--
-    Please refer to http://wiki.apache.org/solr/SolrReplication for
-    details on configuring replication
-  -->
-  <!-- remove the <lst name="master"> section if this is just a slave -->
-  <!-- remove  the <lst name="slave"> section if this is just a master -->
-  <!--
-    <requestHandler name="/replication" class="solr.ReplicationHandler"
-    > <lst name="master"> <str name="replicateAfter">commit</str> <str
-    name="replicateAfter">startup</str> <str
-    name="confFiles">schema.xml,stopwords.txt</str> </lst> <lst
-    name="slave"> <str
-    name="masterUrl">http://localhost:8983/solr/replication</str> <str
-    name="pollInterval">00:00:60</str> </lst> </requestHandler>
-  -->
-
-  <!--
-    DisMaxRequestHandler allows easy searching across multiple fields
-    for simple user-entered phrases. It's implementation is now just the
-    standard SearchHandler with a default query type of "dismax". see
-    http://wiki.apache.org/solr/DisMaxRequestHandler
-  -->
-  <requestHandler name="dismax" class="solr.SearchHandler">
-    <lst name="defaults">
-      <str name="defType">dismax</str>
-      <str name="echoParams">explicit</str>
-      <float name="tie">0.01</float>
-      <str name="qf">
-        text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0
-        manu^1.1 cat^1.4
-     </str>
-      <str name="pf">
-        text^0.2 features^1.1 name^1.5 manu^1.4
-        manu_exact^1.9
-     </str>
-      <str name="bf">
-        popularity^0.5 recip(price,1,1000,1000)^0.3
-     </str>
-      <str name="fl">
-        id,name,price,score
-     </str>
-      <str name="mm">
-        2&lt;-1 5&lt;-2 6&lt;90% </str>
-      <int name="ps">100</int>
-      <str name="q.alt">*:*</str>
-      <!-- example highlighter config, enable per-query with hl=true -->
-      <str name="hl.fl">text features name</str>
-      <!-- for this field, we want no fragmenting, just highlighting -->
-      <str name="f.name.hl.fragsize">0</str>
-      <!--
-        instructs Solr to return the field itself if no query terms are
-        found
-      -->
-      <str name="f.name.hl.alternateField">name</str>
-      <str name="f.text.hl.fragmenter">regex</str> <!-- defined below -->
-    </lst>
-  </requestHandler>
-
-  <!--
-    Note how you can register the same handler multiple times with
-    different names (and different init parameters)
-  -->
-  <requestHandler name="partitioned" class="solr.SearchHandler">
-    <lst name="defaults">
-      <str name="defType">dismax</str>
-      <str name="echoParams">explicit</str>
-      <str name="qf">text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0</str>
-      <str name="mm">2&lt;-1 5&lt;-2 6&lt;90%</str>
-      <!--
-        This is an example of using Date Math to specify a constantly
-        moving date range in a config...
-      -->
-      <str name="bq">incubationdate_dt:[* TO NOW/DAY-1MONTH]^2.2</str>
-    </lst>
-    <!--
-      In addition to defaults, "appends" params can be specified to
-      identify values which should be appended to the list of multi-val
-      params from the query (or the existing "defaults"). In this
-      example, the param "fq=instock:true" will be appended to any query
-      time fq params the user may specify, as a mechanism for
-      partitioning the index, independent of any user selected filtering
-      that may also be desired (perhaps as a result of faceted
-      searching). NOTE: there is *absolutely* nothing a client can do to
-      prevent these "appends" values from being used, so don't use this
-      mechanism unless you are sure you always want it.
-    -->
-    <lst name="appends">
-      <str name="fq">inStock:true</str>
-    </lst>
-    <!--
-      "invariants" are a way of letting the Solr maintainer lock down
-      the options available to Solr clients. Any params values specified
-      here are used regardless of what values may be specified in either
-      the query, the "defaults", or the "appends" params. In this
-      example, the facet.field and facet.query params are fixed,
-      limiting the facets clients can use. Faceting is not turned on by
-      default - but if the client does specify facet=true in the
-      request, these are the only facets they will be able to see counts
-      for; regardless of what other facet.field or facet.query params
-      they may specify. NOTE: there is *absolutely* nothing a client can
-      do to prevent these "invariants" values from being used, so don't
-      use this mechanism unless you are sure you always want it.
-    -->
-    <lst name="invariants">
-      <str name="facet.field">cat</str>
-      <str name="facet.field">manu_exact</str>
-      <str name="facet.query">price:[* TO 500]</str>
-      <str name="facet.query">price:[500 TO *]</str>
-    </lst>
-  </requestHandler>
-
-
-  <!--
-    Search components are registered to SolrCore and used by Search
-    Handlers By default, the following components are avaliable:
-
-    <searchComponent name="query"
-    class="org.apache.solr.handler.component.QueryComponent" />
-    <searchComponent name="facet"
-    class="org.apache.solr.handler.component.FacetComponent" />
-    <searchComponent name="mlt"
-    class="org.apache.solr.handler.component.MoreLikeThisComponent" />
-    <searchComponent name="highlight"
-    class="org.apache.solr.handler.component.HighlightComponent" />
-    <searchComponent name="stats"
-    class="org.apache.solr.handler.component.StatsComponent" />
-    <searchComponent name="debug"
-    class="org.apache.solr.handler.component.DebugComponent" /> Default
-    configuration in a requestHandler would look like: <arr
-    name="components"> <str>query</str> <str>facet</str> <str>mlt</str>
-    <str>highlight</str> <str>stats</str> <str>debug</str> </arr> If you
-    register a searchComponent to one of the standard names, that will
-    be used instead. To insert components before or after the 'standard'
-    components, use: <arr name="first-components">
-    <str>myFirstComponentName</str> </arr> <arr name="last-components">
-    <str>myLastComponentName</str> </arr>
-  -->
-
-  <!--
-    The spell check component can return a list of alternative spelling
-    suggestions.
-  -->
-  <searchComponent name="spellcheck" class="solr.SpellCheckComponent">
-
-    <str name="queryAnalyzerFieldType">textSpell</str>
-
-    <lst name="spellchecker">
-      <str name="name">default</str>
-      <str name="field">name</str>
-      <str name="spellcheckIndexDir">./spellchecker</str>
-    </lst>
-
-    <!--
-      a spellchecker that uses a different distance measure <lst
-      name="spellchecker"> <str name="name">jarowinkler</str> <str
-      name="field">spell</str> <str
-      name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
-      <str name="spellcheckIndexDir">./spellchecker2</str> </lst>
-    -->
-
-    <!--
-      a file based spell checker <lst name="spellchecker"> <str
-      name="classname">solr.FileBasedSpellChecker</str> <str
-      name="name">file</str> <str
-      name="sourceLocation">spellings.txt</str> <str
-      name="characterEncoding">UTF-8</str> <str
-      name="spellcheckIndexDir">./spellcheckerFile</str> </lst>
-    -->
-  </searchComponent>
-
-  <!--
-    A request handler utilizing the spellcheck component.
-    #############################################################################
-    NOTE: This is purely as an example. The whole purpose of the
-    SpellCheckComponent is to hook it into the request handler that
-    handles (i.e. the standard or dismax SearchHandler) queries such
-    that a separate request is not needed to get suggestions. IN OTHER
-    WORDS, THERE IS REALLY GOOD CHANCE THE SETUP BELOW IS NOT WHAT YOU
-    WANT FOR YOUR PRODUCTION SYSTEM!
-    #############################################################################
-  -->
-  <requestHandler name="/spell" class="solr.SearchHandler"
-    lazy="true">
-    <lst name="defaults">
-      <!-- omp = Only More Popular -->
-      <str name="spellcheck.onlyMorePopular">false</str>
-      <!-- exr = Extended Results -->
-      <str name="spellcheck.extendedResults">false</str>
-      <!--  The number of suggestions to return -->
-      <str name="spellcheck.count">1</str>
-    </lst>
-    <arr name="last-components">
-      <str>spellcheck</str>
-    </arr>
-  </requestHandler>
-
-  <searchComponent name="tvComponent"
-    class="org.apache.solr.handler.component.TermVectorComponent" />
-  <!--
-    A Req Handler for working with the tvComponent. This is purely as an
-    example. You will likely want to add the component to your already
-    specified request handlers.
-  -->
-  <requestHandler name="tvrh"
-    class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <bool name="tv">true</bool>
-    </lst>
-    <arr name="last-components">
-      <str>tvComponent</str>
-    </arr>
-  </requestHandler>
-
-  <!--
-    Clustering Component http://wiki.apache.org/solr/ClusteringComponent
-    This relies on third party jars which are not included in the
-    release. To use this component (and the "/clustering" handler) Those
-    jars will need to be downloaded, and you'll need to set the
-    solr.cluster.enabled system property when running solr... java
-    -Dsolr.clustering.enabled=true -jar start.jar
-  -->
-  <searchComponent name="clusteringComponent"
-    enable="${solr.clustering.enabled:false}" class="org.apache.solr.handler.clustering.ClusteringComponent">
-    <!-- Declare an engine -->
-    <lst name="engine">
-      <!-- The name, only one can be named "default" -->
-      <str name="name">default</str>
-      <!--
-        Class name of Carrot2 clustering algorithm. Currently available
-        algorithms are: *
-        org.carrot2.clustering.lingo.LingoClusteringAlgorithm *
-        org.carrot2.clustering.stc.STCClusteringAlgorithm See
-        http://project.carrot2.org/algorithms.html for the algorithm's
-        characteristics.
-      -->
-      <str name="carrot.algorithm">org.carrot2.clustering.lingo.LingoClusteringAlgorithm</str>
-      <!--
-        Overriding values for Carrot2 default algorithm attributes. For
-        a description of all available attributes, see:
-        http://download.carrot2.org/stable/manual/#chapter.components.
-        Use attribute key as name attribute of str elements below. These
-        can be further overridden for individual requests by specifying
-        attribute key as request parameter name and attribute value as
-        parameter value.
-      -->
-      <str name="LingoClusteringAlgorithm.desiredClusterCountBase">20</str>
-    </lst>
-    <lst name="engine">
-      <str name="name">stc</str>
-      <str name="carrot.algorithm">org.carrot2.clustering.stc.STCClusteringAlgorithm</str>
-    </lst>
-  </searchComponent>
-  <requestHandler name="/clustering" enable="${solr.clustering.enabled:false}"
-    class="solr.SearchHandler">
-    <lst name="defaults">
-      <bool name="clustering">true</bool>
-      <str name="clustering.engine">default</str>
-      <bool name="clustering.results">true</bool>
-      <!-- The title field -->
-      <str name="carrot.title">name</str>
-      <str name="carrot.url">id</str>
-      <!-- The field to cluster on -->
-      <str name="carrot.snippet">features</str>
-      <!-- produce summaries -->
-      <bool name="carrot.produceSummary">true</bool>
-      <!-- the maximum number of labels per cluster -->
-      <!--<int name="carrot.numDescriptions">5</int>-->
-      <!-- produce sub clusters -->
-      <bool name="carrot.outputSubClusters">false</bool>
-    </lst>
-    <arr name="last-components">
-      <str>clusteringComponent</str>
-    </arr>
-  </requestHandler>
-
-  <!-- Solr Cell: http://wiki.apache.org/solr/ExtractingRequestHandler -->
-  <requestHandler name="/update/extract"
-    class="org.apache.solr.handler.extraction.ExtractingRequestHandler"
-    startup="lazy">
-    <lst name="defaults">
-      <!--
-        All the main content goes into "text"... if you need to return
-        the extracted text or do highlighting, use a stored field.
-      -->
-      <str name="fmap.content">text</str>
-      <str name="lowernames">true</str>
-      <str name="uprefix">ignored_</str>
-
-      <!-- capture link hrefs but ignore div attributes -->
-      <str name="captureAttr">true</str>
-      <str name="fmap.a">links</str>
-      <str name="fmap.div">ignored_</str>
-    </lst>
-  </requestHandler>
-
-
-  <!--
-    A component to return terms and document frequency of those terms.
-    This component does not yet support distributed search.
-  -->
-  <searchComponent name="termsComponent"
-    class="org.apache.solr.handler.component.TermsComponent" />
-
-  <requestHandler name="/terms"
-    class="org.apache.solr.handler.component.SearchHandler">
-    <lst name="defaults">
-      <bool name="terms">true</bool>
-    </lst>
-    <arr name="components">
-      <str>termsComponent</str>
-    </arr>
-  </requestHandler>
-
-
-
-
-  <!--
-    Update request handler. Note: Since solr1.1 requestHandlers requires
-    a valid content type header if posted in the body. For example, curl
-    now requires: -H 'Content-type:text/xml; charset=utf-8' The response
-    format differs from solr1.1 formatting and returns a standard error
-    code. To enable solr1.1 behavior, remove the /update handler or
-    change its path
-  -->
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler">
-    <lst name="defaults">
-      <str name="update.chain">uima</str>
-    </lst>
-  </requestHandler>
-
-
-  <requestHandler name="/update/javabin" class="solr.BinaryUpdateRequestHandler" />
-
-  <!--
-    Analysis request handler. Since Solr 1.3. Use to return how a
-    document is analyzed. Useful for debugging and as a token server for
-    other types of applications. This is deprecated in favor of the
-    improved DocumentAnalysisRequestHandler and
-    FieldAnalysisRequestHandler <requestHandler name="/analysis"
-    class="solr.AnalysisRequestHandler" />
-  -->
-
-  <!--
-    An analysis handler that provides a breakdown of the analysis
-    process of provided docuemnts. This handler expects a (single)
-    content stream with the following format: <docs> <doc> <field
-    name="id">1</field> <field name="name">The Name</field> <field
-    name="text">The Text Value</field> <doc> <doc>...</doc>
-    <doc>...</doc> ... </docs> Note: Each document must contain a field
-    which serves as the unique key. This key is used in the returned
-    response to assoicate an analysis breakdown to the analyzed
-    document. Like the FieldAnalysisRequestHandler, this handler also
-    supports query analysis by sending either an "analysis.query" or "q"
-    request paraemter that holds the query text to be analyized. It also
-    supports the "analysis.showmatch" parameter which when set to true,
-    all field tokens that match the query tokens will be marked as a
-    "match".
-  -->
-  <requestHandler name="/analysis/document"
-    class="solr.DocumentAnalysisRequestHandler" />
-
-  <!--
-    RequestHandler that provides much the same functionality as
-    analysis.jsp. Provides the ability to specify multiple field types
-    and field names in the same request and outputs index-time and
-    query-time analysis for each of them. Request parameters are:
-    analysis.fieldname - The field name whose analyzers are to be used
-    analysis.fieldtype - The field type whose analyzers are to be used
-    analysis.fieldvalue - The text for index-time analysis q (or
-    analysis.q) - The text for query time analysis analysis.showmatch
-    (true|false) - When set to true and when query analysis is
-    performed, the produced tokens of the field value analysis will be
-    marked as "matched" for every token that is produces by the query
-    analysis
-  -->
-  <requestHandler name="/analysis/field" class="solr.FieldAnalysisRequestHandler" />
-
-
-  <!-- CSV update handler, loaded on demand -->
-  <requestHandler name="/update/csv" class="solr.CSVRequestHandler"
-    startup="lazy" />
-
-
-  <!--
-    Admin Handlers - This will register all the standard admin
-    RequestHandlers. Adding this single handler is equivalent to
-    registering: <requestHandler name="/admin/luke"
-    class="org.apache.solr.handler.admin.LukeRequestHandler" />
-    <requestHandler name="/admin/system"
-    class="org.apache.solr.handler.admin.SystemInfoHandler" />
-    <requestHandler name="/admin/plugins"
-    class="org.apache.solr.handler.admin.PluginInfoHandler" />
-    <requestHandler name="/admin/threads"
-    class="org.apache.solr.handler.admin.ThreadDumpHandler" />
-    <requestHandler name="/admin/properties"
-    class="org.apache.solr.handler.admin.PropertiesRequestHandler" />
-    <requestHandler name="/admin/file"
-    class="org.apache.solr.handler.admin.ShowFileRequestHandler" > If
-    you wish to hide files under ${solr.home}/conf, explicitly register
-    the ShowFileRequestHandler using: <requestHandler name="/admin/file"
-    class="org.apache.solr.handler.admin.ShowFileRequestHandler" > <lst
-    name="invariants"> <str name="hidden">synonyms.txt</str> <str
-    name="hidden">anotherfile.txt</str> </lst> </requestHandler>
-  -->
-  <requestHandler name="/admin/"
-    class="org.apache.solr.handler.admin.AdminHandlers" />
-
-  <!-- Echo the request contents back to the client -->
-  <requestHandler name="/debug/dump" class="solr.DumpRequestHandler">
-    <lst name="defaults">
-      <str name="echoParams">explicit</str> <!-- for all params (including the default etc) use: 'all' -->
-      <str name="echoHandler">true</str>
-    </lst>
-  </requestHandler>
-
-  <!--
-    An example dedup update processor that creates the "id" field on the
-    fly based on the hash code of some other fields. This example has
-    overwriteDupes set to false since we are using the id field as the
-    signatureField and Solr will maintain uniqueness based on that
-    anyway. You have to link the chain to an update handler above to use
-    it ie: <requestHandler name="/update
-    "class="solr.XmlUpdateRequestHandler"> <lst name="defaults"> <str
-    name="update.chain">dedupe</str> </lst> </requestHandler>
-  -->
-
-  <updateRequestProcessorChain name="uima">
-    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
-      <lst name="uimaConfig">
-        <lst name="runtimeParameters">
-          <int name="ngramsize">3</int>
-        </lst>
-        <str name="analysisEngine">/TestAE.xml</str>
-        <lst name="analyzeFields">
-          <bool name="merge">false</bool>
-          <arr name="fields">
-            <str>text</str>
-          </arr>
-        </lst>
-        <lst name="fieldMappings">
-          <lst name="type">
-            <str name="name">org.apache.uima.SentenceAnnotation</str>
-            <lst name="mapping">
-              <str name="feature">coveredText</str>
-              <str name="field">sentence</str>
-            </lst>
-          </lst>
-          <lst name="type">
-            <str name="name">org.apache.solr.uima.ts.SentimentAnnotation</str>
-            <lst name="mapping">
-              <str name="feature">mood</str>
-              <str name="field">sentiment</str>
-            </lst>
-          </lst>
-          <lst name="type">
-            <str name="name">org.apache.solr.uima.ts.EntityAnnotation</str>
-            <lst name="mapping">
-              <str name="feature">entity</str>
-              <str name="fieldNameFeature">name</str>
-              <str name="dynamicField">*_sm</str>
-            </lst>
-          </lst>
-        </lst>
-      </lst>
-    </processor>
-    <processor class="solr.RunUpdateProcessorFactory" />
-  </updateRequestProcessorChain>
-
-  <updateRequestProcessorChain name="uima-multi-map">
-    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
-      <lst name="uimaConfig">
-        <lst name="runtimeParameters">
-          <int name="ngramsize">3</int>
-        </lst>
-        <str name="analysisEngine">/TestAE.xml</str>
-        <lst name="analyzeFields">
-          <bool name="merge">false</bool>
-          <arr name="fields">
-            <str>text</str>
-          </arr>
-        </lst>
-        <lst name="fieldMappings">
-          <lst name="type">
-            <str name="name">a-type-which-can-have-multiple-features</str>
-            <lst name="mapping">
-              <str name="feature">A</str>
-              <str name="field">1</str>
-            </lst>
-            <lst name="mapping">
-              <str name="feature">B</str>
-              <str name="field">2</str>
-            </lst>
-          </lst>
-        </lst>
-      </lst>
-    </processor>
-  </updateRequestProcessorChain>
-
-  <updateRequestProcessorChain name="uima-not-ignoreErrors">
-    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
-      <lst name="uimaConfig">
-        <lst name="runtimeParameters">
-          <int name="ngramsize">3</int>
-        </lst>
-        <str name="analysisEngine">/TestExceptionAE.xml</str>
-        <bool name="ignoreErrors">false</bool>
-        <lst name="analyzeFields">
-          <bool name="merge">false</bool>
-          <arr name="fields">
-            <str>text</str>
-          </arr>
-        </lst>
-        <lst name="fieldMappings"/>
-      </lst>
-    </processor>
-    <processor class="solr.RunUpdateProcessorFactory" />
-  </updateRequestProcessorChain>
-
-  <updateRequestProcessorChain name="uima-ignoreErrors">
-    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
-      <lst name="uimaConfig">
-        <lst name="runtimeParameters">
-          <int name="ngramsize">3</int>
-        </lst>
-        <str name="analysisEngine">/TestExceptionAE.xml</str>
-        <bool name="ignoreErrors">true</bool>
-        <!-- This is optional. It is used for logging when text processing fails. Usually, set uniqueKey field name -->
-        <str name="logField">id</str>
-        <lst name="analyzeFields">
-          <bool name="merge">false</bool>
-          <arr name="fields">
-            <str>text</str>
-          </arr>
-        </lst>
-        <lst name="fieldMappings"/>
-      </lst>
-    </processor>
-    <processor class="solr.RunUpdateProcessorFactory" />
-  </updateRequestProcessorChain>
-
-  <!--
-    queryResponseWriter plugins... query responses will be written using
-    the writer specified by the 'wt' request parameter matching the name
-    of a registered writer. The "default" writer is the default and will
-    be used if 'wt' is not specified in the request. XMLResponseWriter
-    will be used if nothing is specified here. The json, python, and
-    ruby writers are also available by default. <queryResponseWriter
-    name="xml" class="org.apache.solr.request.XMLResponseWriter"
-    default="true"/> <queryResponseWriter name="json"
-    class="org.apache.solr.request.JSONResponseWriter"/>
-    <queryResponseWriter name="python"
-    class="org.apache.solr.request.PythonResponseWriter"/>
-    <queryResponseWriter name="ruby"
-    class="org.apache.solr.request.RubyResponseWriter"/>
-    <queryResponseWriter name="php"
-    class="org.apache.solr.request.PHPResponseWriter"/>
-    <queryResponseWriter name="phps"
-    class="org.apache.solr.request.PHPSerializedResponseWriter"/>
-
-    <queryResponseWriter name="custom"
-    class="com.example.MyResponseWriter"/>
-  -->
-
-  <!--
-    XSLT response writer transforms the XML output by any xslt file
-    found in Solr's conf/xslt directory. Changes to xslt files are
-    checked for every xsltCacheLifetimeSeconds.
-  -->
-  <queryResponseWriter name="xslt"
-    class="org.apache.solr.response.XSLTResponseWriter">
-    <int name="xsltCacheLifetimeSeconds">5</int>
-  </queryResponseWriter>
-
-
-  <!--
-    example of registering a query parser <queryParser name="lucene"
-    class="org.apache.solr.search.LuceneQParserPlugin"/>
-  -->
-
-  <!--
-    example of registering a custom function parser <valueSourceParser
-    name="myfunc" class="com.mycompany.MyValueSourceParser" />
-  -->
-
-  <!-- config for the admin interface -->
-  <admin>
-    <defaultQuery>*</defaultQuery>
-
-    <!--
-      configure a healthcheck file for servers behind a loadbalancer
-      <healthcheck type="file">server-enabled</healthcheck>
-    -->
-  </admin>
-
-</config>
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/spellings.txt b/solr/contrib/uima/src/test-files/solr-uima/conf/spellings.txt
deleted file mode 100644
index 162a044..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/spellings.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-pizza
-history
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/stopwords.txt b/solr/contrib/uima/src/test-files/solr-uima/conf/stopwords.txt
deleted file mode 100644
index b5824da..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/stopwords.txt
+++ /dev/null
@@ -1,58 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-# a couple of test stopwords to test that the words are really being
-# configured from this file:
-stopworda
-stopwordb
-
-#Standard english stop words taken from Lucene's StopAnalyzer
-a
-an
-and
-are
-as
-at
-be
-but
-by
-for
-if
-in
-into
-is
-it
-no
-not
-of
-on
-or
-s
-such
-t
-that
-the
-their
-then
-there
-these
-they
-this
-to
-was
-will
-with
-
diff --git a/solr/contrib/uima/src/test-files/solr-uima/conf/synonyms.txt b/solr/contrib/uima/src/test-files/solr-uima/conf/synonyms.txt
deleted file mode 100644
index b0e31cb..0000000
--- a/solr/contrib/uima/src/test-files/solr-uima/conf/synonyms.txt
+++ /dev/null
@@ -1,31 +0,0 @@
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#-----------------------------------------------------------------------
-#some test synonym mappings unlikely to appear in real input text
-aaa => aaaa
-bbb => bbbb1 bbbb2
-ccc => cccc1,cccc2
-a\=>a => b\=>b
-a\,a => b\,b
-fooaaa,baraaa,bazaaa
-
-# Some synonym groups specific to this example
-GB,gib,gigabyte,gigabytes
-MB,mib,megabyte,megabytes
-Television, Televisions, TV, TVs
-#notice we use "gib" instead of "GiB" so any WordDelimiterFilter coming
-#after us won't split it into two words.
-
-# Synonym mappings can be used for spelling correction too
-pixima => pixma
-
diff --git a/solr/contrib/uima/src/test-files/uima/AggregateSentenceAE.xml b/solr/contrib/uima/src/test-files/uima/AggregateSentenceAE.xml
new file mode 100644
index 0000000..73d697e
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/AggregateSentenceAE.xml
@@ -0,0 +1,70 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>false</primitive>
+  <delegateAnalysisEngineSpecifiers>
+    <delegateAnalysisEngine key="WhitespaceTokenizer">
+      <import name="WhitespaceTokenizer"/>
+    </delegateAnalysisEngine>
+    <delegateAnalysisEngine key="HmmTagger">
+      <import name="HmmTagger"/>
+    </delegateAnalysisEngine>
+  </delegateAnalysisEngineSpecifiers>
+  <analysisEngineMetaData>
+    <name>AggregateSentenceAE</name>
+    <description/>
+    <version>1.0</version>
+    <vendor/>
+    <configurationParameters>
+      <configurationParameter>
+        <name>ngramsize</name>
+        <type>Integer</type>
+        <multiValued>false</multiValued>
+        <mandatory>false</mandatory>
+        <overrides>
+          <parameter>HmmTagger/NGRAM_SIZE</parameter>
+        </overrides>
+      </configurationParameter>
+    </configurationParameters>
+    <configurationParameterSettings/>
+    <flowConstraints>
+      <fixedFlow>
+        <node>WhitespaceTokenizer</node>
+        <node>HmmTagger</node>
+      </fixedFlow>
+    </flowConstraints>
+    <fsIndexCollection/>
+    <capabilities>
+      <capability>
+        <inputs/>
+        <outputs>
+          <type allAnnotatorFeatures="true">org.apache.uima.SentenceAnnotation</type>
+          <type allAnnotatorFeatures="true">org.apache.uima.TokenAnnotation</type>
+        </outputs>
+        <languagesSupported/>
+      </capability>
+    </capabilities>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/uima/DummyEntityAEDescriptor.xml b/solr/contrib/uima/src/test-files/uima/DummyEntityAEDescriptor.xml
new file mode 100644
index 0000000..33f05e5
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/DummyEntityAEDescriptor.xml
@@ -0,0 +1,68 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>true</primitive>
+  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummyEntityAnnotator</annotatorImplementationName>
+  <analysisEngineMetaData>
+    <name>DummyEntityAEDescriptor</name>
+    <description/>
+    <version>1.0</version>
+    <vendor>ASF</vendor>
+    <configurationParameters/>
+    <configurationParameterSettings/>
+    <typeSystemDescription>
+      <types>
+        <typeDescription>
+          <name>org.apache.solr.uima.ts.EntityAnnotation</name>
+          <description/>
+          <supertypeName>uima.tcas.Annotation</supertypeName>
+          <features>
+            <featureDescription>
+              <name>name</name>
+              <description/>
+              <rangeTypeName>uima.cas.String</rangeTypeName>
+            </featureDescription>
+            <featureDescription>
+              <name>entity</name>
+              <description/>
+              <rangeTypeName>uima.cas.String</rangeTypeName>
+            </featureDescription>
+          </features>
+        </typeDescription>
+      </types>
+    </typeSystemDescription>
+    <typePriorities/>
+    <fsIndexCollection/>
+    <capabilities>
+      <capability>
+        <inputs/>
+        <outputs>
+          <type allAnnotatorFeatures="true">org.apache.solr.uima.ts.EntityAnnotation</type>
+        </outputs>
+        <languagesSupported/>
+      </capability>
+    </capabilities>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/uima/DummyExceptionAEDescriptor.xml b/solr/contrib/uima/src/test-files/uima/DummyExceptionAEDescriptor.xml
new file mode 100644
index 0000000..3d0314a
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/DummyExceptionAEDescriptor.xml
@@ -0,0 +1,40 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>true</primitive>
+  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummyExceptionAnnotator</annotatorImplementationName>
+  <analysisEngineMetaData>
+    <name>DummyExceptionAEDescriptor</name>
+    <description/>
+    <version>1.0</version>
+    <vendor>ASF</vendor>
+    <configurationParameters/>
+    <configurationParameterSettings/>
+    <typeSystemDescription/>
+    <typePriorities/>
+    <fsIndexCollection/>
+    <capabilities/>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/uima/DummySentimentAnalysisAEDescriptor.xml b/solr/contrib/uima/src/test-files/uima/DummySentimentAnalysisAEDescriptor.xml
new file mode 100644
index 0000000..315266d
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/DummySentimentAnalysisAEDescriptor.xml
@@ -0,0 +1,60 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+-->
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>true</primitive>
+  <annotatorImplementationName>org.apache.solr.uima.processor.an.DummySentimentAnnotator</annotatorImplementationName>
+  <analysisEngineMetaData>
+    <name>DummySentimentAnalysisAEDescriptor</name>
+    <description/>
+    <version>1.0</version>
+    <vendor>ASF</vendor>
+    <configurationParameters/>
+    <configurationParameterSettings/>
+    <typeSystemDescription>
+      <types>
+        <typeDescription>
+          <name>org.apache.solr.uima.ts.SentimentAnnotation</name>
+          <description/>
+          <supertypeName>uima.tcas.Annotation</supertypeName>
+          <features>
+            <featureDescription>
+              <name>mood</name>
+              <description/>
+              <rangeTypeName>uima.cas.String</rangeTypeName>
+            </featureDescription>
+          </features>
+        </typeDescription>
+      </types>
+    </typeSystemDescription>
+    <typePriorities/>
+    <fsIndexCollection/>
+    <capabilities>
+      <capability>
+        <inputs/>
+        <outputs/>
+      </capability>
+    </capabilities>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/uima/TestAE.xml b/solr/contrib/uima/src/test-files/uima/TestAE.xml
new file mode 100644
index 0000000..70fb9b6
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/TestAE.xml
@@ -0,0 +1,72 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+  -->
+
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>false</primitive>
+  <delegateAnalysisEngineSpecifiers>
+    <delegateAnalysisEngine key="AggregateSentenceAE">
+      <import location="AggregateSentenceAE.xml"/>
+    </delegateAnalysisEngine>
+    <delegateAnalysisEngine key="DummyEntityAEDescriptor">
+      <import location="DummyEntityAEDescriptor.xml"/>
+    </delegateAnalysisEngine>
+    <delegateAnalysisEngine key="DummySentimentAnalysisAEDescriptor">
+      <import location="DummySentimentAnalysisAEDescriptor.xml"/>
+    </delegateAnalysisEngine>
+  </delegateAnalysisEngineSpecifiers>
+  <analysisEngineMetaData>
+    <name>TestAE</name>
+    <description/>
+    <version>1.0</version>
+    <vendor/>
+    <configurationParameters>
+      <configurationParameter>
+        <name>ngramsize</name>
+        <type>Integer</type>
+        <multiValued>false</multiValued>
+        <mandatory>false</mandatory>
+        <overrides>
+          <parameter>AggregateSentenceAE/ngramsize</parameter>
+        </overrides>
+      </configurationParameter>
+    </configurationParameters>
+    <configurationParameterSettings/>
+    <flowConstraints>
+      <fixedFlow>
+        <node>AggregateSentenceAE</node>
+        <node>DummyEntityAEDescriptor</node>
+        <node>DummySentimentAnalysisAEDescriptor</node>
+      </fixedFlow>
+    </flowConstraints>
+    <fsIndexCollection/>
+    <capabilities>
+      <capability>
+        <inputs/>
+        <outputs/>
+        <languagesSupported/>
+      </capability>
+    </capabilities>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
\ No newline at end of file
diff --git a/solr/contrib/uima/src/test-files/uima/TestExceptionAE.xml b/solr/contrib/uima/src/test-files/uima/TestExceptionAE.xml
new file mode 100644
index 0000000..434105f
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/TestExceptionAE.xml
@@ -0,0 +1,54 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<!--
+  Licensed to the Apache Software Foundation (ASF) under one or more
+  contributor license agreements.  See the NOTICE file distributed with
+  this work for additional information regarding copyright ownership.
+  The ASF licenses this file to You under the Apache License, Version 2.0
+  (the "License"); you may not use this file except in compliance with
+  the License.  You may obtain a copy of the License at
+
+      http://www.apache.org/licenses/LICENSE-2.0
+
+  Unless required by applicable law or agreed to in writing, software
+  distributed under the License is distributed on an "AS IS" BASIS,
+  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  See the License for the specific language governing permissions and
+  limitations under the License.
+  -->
+
+<analysisEngineDescription xmlns="http://uima.apache.org/resourceSpecifier">
+  <frameworkImplementation>org.apache.uima.java</frameworkImplementation>
+  <primitive>false</primitive>
+  <delegateAnalysisEngineSpecifiers>
+    <delegateAnalysisEngine key="DummyExceptionAEDescriptor">
+      <import location="DummyExceptionAEDescriptor.xml"/>
+    </delegateAnalysisEngine>
+  </delegateAnalysisEngineSpecifiers>
+  <analysisEngineMetaData>
+    <name>TestExceptionAE</name>
+    <description/>
+    <version>1.0</version>
+    <vendor/>
+    <configurationParameters/>
+    <configurationParameterSettings/>
+    <flowConstraints>
+      <fixedFlow>
+        <node>DummyExceptionAEDescriptor</node>
+      </fixedFlow>
+    </flowConstraints>
+    <fsIndexCollection/>
+    <capabilities>
+      <capability>
+        <inputs/>
+        <outputs/>
+        <languagesSupported/>
+      </capability>
+    </capabilities>
+    <operationalProperties>
+      <modifiesCas>true</modifiesCas>
+      <multipleDeploymentAllowed>true</multipleDeploymentAllowed>
+      <outputsNewCASes>false</outputsNewCASes>
+    </operationalProperties>
+  </analysisEngineMetaData>
+  <resourceManagerConfiguration/>
+</analysisEngineDescription>
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/protwords.txt b/solr/contrib/uima/src/test-files/uima/solr/conf/protwords.txt
new file mode 100644
index 0000000..1dfc0ab
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/protwords.txt
@@ -0,0 +1,21 @@
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+# Use a protected word file to protect against the stemmer reducing two
+# unrelated words to the same base word.
+
+# Some non-words that normally won't be encountered,
+# just to test that they won't be stemmed.
+dontstems
+zwhacky
+
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/schema.xml b/solr/contrib/uima/src/test-files/uima/solr/conf/schema.xml
new file mode 100644
index 0000000..3abb0ce
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/schema.xml
@@ -0,0 +1,678 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+  <!--
+    Licensed to the Apache Software Foundation (ASF) under one or more
+    contributor license agreements. See the NOTICE file distributed with
+    this work for additional information regarding copyright ownership.
+    The ASF licenses this file to You under the Apache License, Version
+    2.0 (the "License"); you may not use this file except in compliance
+    with the License. You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0 Unless required by
+    applicable law or agreed to in writing, software distributed under
+    the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES
+    OR CONDITIONS OF ANY KIND, either express or implied. See the
+    License for the specific language governing permissions and
+    limitations under the License.
+  -->
+
+  <!--
+    This is the Solr schema file. This file should be named "schema.xml"
+    and should be in the conf directory under the solr home (i.e.
+    ./solr/conf/schema.xml by default) or located where the classloader
+    for the Solr webapp can find it. This example schema is the
+    recommended starting point for users. It should be kept correct and
+    concise, usable out-of-the-box. For more information, on how to
+    customize this file, please see
+    http://wiki.apache.org/solr/SchemaXml PERFORMANCE NOTE: this schema
+    includes many optional features and should not be used for
+    benchmarking. To improve performance one could - set stored="false"
+    for all fields possible (esp large fields) when you only need to
+    search on the field but don't need to return the original value. -
+    set indexed="false" if you don't need to search on the field, but
+    only return the field as a result of searching on other indexed
+    fields. - remove all unneeded copyField statements - for best index
+    size and searching performance, set "index" to false for all general
+    text fields, use copyField to copy them to the catchall "text"
+    field, and use that for searching. - For maximum indexing
+    performance, use the StreamingUpdateSolrServer java client. -
+    Remember to run the JVM in server mode, and use a higher logging
+    level that avoids logging every request
+  -->
+
+<schema name="sample" version="1.2">
+  <!--
+    attribute "name" is the name of this schema and is only used for
+    display purposes. Applications should change this to reflect the
+    nature of the search collection. version="1.2" is Solr's version
+    number for the schema syntax and semantics. It should not normally
+    be changed by applications. 1.0: multiValued attribute did not
+    exist, all fields are multiValued by nature 1.1: multiValued
+    attribute introduced, false by default 1.2: omitTermFreqAndPositions
+    attribute introduced, true by default except for text fields.
+  -->
+
+  <types>
+    <!--
+      field type definitions. The "name" attribute is just a label to be
+      used by field definitions. The "class" attribute and any other
+      attributes determine the real behavior of the fieldType. Class
+      names starting with "solr" refer to java classes in the
+      org.apache.solr.analysis package.
+    -->
+
+    <!--
+      The StrField type is not analyzed, but indexed/stored verbatim. -
+      StrField and TextField support an optional compressThreshold which
+      limits compression (if enabled in the derived fields) to values
+      which exceed a certain size (in characters).
+    -->
+    <fieldType name="string" class="solr.StrField"
+      sortMissingLast="true" omitNorms="true" />
+
+    <!-- boolean type: "true" or "false" -->
+    <fieldType name="boolean" class="solr.BoolField"
+      sortMissingLast="true" omitNorms="true" />
+    <!--
+      Binary data type. The data should be sent/retrieved in as Base64
+      encoded Strings
+    -->
+    <fieldtype name="binary" class="solr.BinaryField" />
+
+    <!--
+      The optional sortMissingLast and sortMissingFirst attributes are
+      currently supported on types that are sorted internally as
+      strings. This includes
+      "string","boolean","sint","slong","sfloat","sdouble","pdate" - If
+      sortMissingLast="true", then a sort on this field will cause
+      documents without the field to come after documents with the
+      field, regardless of the requested sort order (asc or desc). - If
+      sortMissingFirst="true", then a sort on this field will cause
+      documents without the field to come before documents with the
+      field, regardless of the requested sort order. - If
+      sortMissingLast="false" and sortMissingFirst="false" (the
+      default), then default lucene sorting will be used which places
+      docs without the field first in an ascending sort and last in a
+      descending sort.
+    -->
+
+    <!--
+      Default numeric field types. For faster range queries, consider
+      the tint/tfloat/tlong/tdouble types.
+    -->
+    <fieldType name="int" class="solr.TrieIntField"
+      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="float" class="solr.TrieFloatField"
+      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="long" class="solr.TrieLongField"
+      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="double" class="solr.TrieDoubleField"
+      precisionStep="0" omitNorms="true" positionIncrementGap="0" />
+
+    <!--
+      Numeric field types that index each value at various levels of
+      precision to accelerate range queries when the number of values
+      between the range endpoints is large. See the javadoc for
+      NumericRangeQuery for internal implementation details. Smaller
+      precisionStep values (specified in bits) will lead to more tokens
+      indexed per value, slightly larger index size, and faster range
+      queries. A precisionStep of 0 disables indexing at different
+      precision levels.
+    -->
+    <fieldType name="tint" class="solr.TrieIntField"
+      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="tfloat" class="solr.TrieFloatField"
+      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="tlong" class="solr.TrieLongField"
+      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
+    <fieldType name="tdouble" class="solr.TrieDoubleField"
+      precisionStep="8" omitNorms="true" positionIncrementGap="0" />
+
+    <!--
+      The format for this date field is of the form
+      1995-12-31T23:59:59Z, and is a more restricted form of the
+      canonical representation of dateTime
+      http://www.w3.org/TR/xmlschema-2/#dateTime The trailing "Z"
+      designates UTC time and is mandatory. Optional fractional seconds
+      are allowed: 1995-12-31T23:59:59.999Z All other components are
+      mandatory. Expressions can also be used to denote calculations
+      that should be performed relative to "NOW" to determine the value,
+      ie... NOW/HOUR ... Round to the start of the current hour NOW-1DAY
+      ... Exactly 1 day prior to now NOW/DAY+6MONTHS+3DAYS ... 6 months
+      and 3 days in the future from the start of the current day Consult
+      the DateField javadocs for more information. Note: For faster
+      range queries, consider the tdate type
+    -->
+    <fieldType name="date" class="solr.TrieDateField"
+      omitNorms="true" precisionStep="0" positionIncrementGap="0" />
+
+    <!--
+      A Trie based date field for faster date range queries and date
+      faceting.
+    -->
+    <fieldType name="tdate" class="solr.TrieDateField"
+      omitNorms="true" precisionStep="6" positionIncrementGap="0" />
+
+
+    <!--
+      Note: These should only be used for compatibility with existing
+      indexes (created with older Solr versions) or if
+      "sortMissingFirst" or "sortMissingLast" functionality is needed.
+      Use Trie based fields instead. Plain numeric field types that
+      store and index the text value verbatim (and hence don't support
+      range queries, since the lexicographic ordering isn't equal to the
+      numeric ordering)
+    -->
+    <fieldType name="pint" class="solr.IntField" omitNorms="true" />
+    <fieldType name="plong" class="solr.LongField" omitNorms="true" />
+    <fieldType name="pfloat" class="solr.FloatField"
+      omitNorms="true" />
+    <fieldType name="pdouble" class="solr.DoubleField"
+      omitNorms="true" />
+    <fieldType name="pdate" class="solr.DateField"
+      sortMissingLast="true" omitNorms="true" />
+
+
+    <!--
+      Note: These should only be used for compatibility with existing
+      indexes (created with older Solr versions) or if
+      "sortMissingFirst" or "sortMissingLast" functionality is needed.
+      Use Trie based fields instead. Numeric field types that manipulate
+      the value into a string value that isn't human-readable in its
+      internal form, but with a lexicographic ordering the same as the
+      numeric ordering, so that range queries work correctly.
+    -->
+    <fieldType name="sint" class="solr.SortableIntField"
+      sortMissingLast="true" omitNorms="true" />
+    <fieldType name="slong" class="solr.SortableLongField"
+      sortMissingLast="true" omitNorms="true" />
+    <fieldType name="sfloat" class="solr.SortableFloatField"
+      sortMissingLast="true" omitNorms="true" />
+    <fieldType name="sdouble" class="solr.SortableDoubleField"
+      sortMissingLast="true" omitNorms="true" />
+
+
+    <!--
+      The "RandomSortField" is not used to store or search any data. You
+      can declare fields of this type it in your schema to generate
+      pseudo-random orderings of your docs for sorting purposes. The
+      ordering is generated based on the field name and the version of
+      the index, As long as the index version remains unchanged, and the
+      same field name is reused, the ordering of the docs will be
+      consistent. If you want different psuedo-random orderings of
+      documents, for the same version of the index, use a dynamicField
+      and change the name
+    -->
+    <fieldType name="random" class="solr.RandomSortField"
+      indexed="true" />
+
+    <!--
+      solr.TextField allows the specification of custom text analyzers
+      specified as a tokenizer and a list of token filters. Different
+      analyzers may be specified for indexing and querying. The optional
+      positionIncrementGap puts space between multiple fields of this
+      type on the same document, with the purpose of preventing false
+      phrase matching across fields. For more info on customizing your
+      analyzer chain, please see
+      http://wiki.apache.org/solr/AnalyzersTokenizersTokenFilters
+    -->
+
+    <!--
+      One can also specify an existing Analyzer class that has a default
+      constructor via the class attribute on the analyzer element
+      <fieldType name="text_greek" class="solr.TextField"> <analyzer
+      class="org.apache.lucene.analysis.el.GreekAnalyzer"/> </fieldType>
+    -->
+
+    <!--
+      A text field that only splits on whitespace for exact matching of
+      words
+    -->
+    <fieldType name="text_ws" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+      </analyzer>
+    </fieldType>
+
+    <!--
+      A text field that uses WordDelimiterFilter to enable splitting and
+      matching of words on case-change, alpha numeric boundaries, and
+      non-alphanumeric chars, so that a query of "wifi" or "wi fi" could
+      match a document containing "Wi-Fi". Synonyms and stopwords are
+      customized by external files, and stemming is enabled.
+    -->
+    <fieldType name="text" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <!--
+          in this example, we will only use synonyms at query time
+          <filter class="solr.SynonymFilterFactory"
+          synonyms="index_synonyms.txt" ignoreCase="true"
+          expand="false"/>
+        -->
+        <!--
+          Case insensitive stop word removal. add
+          enablePositionIncrements=true in both the index and query
+          analyzers to leave a 'gap' for more accurate phrase queries.
+        -->
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="1"
+          catenateNumbers="1" catenateAll="0" splitOnCaseChange="1" />
+        <filter class="solr.LowerCaseFilterFactory" />
+        
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
+          ignoreCase="true" expand="true" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="0"
+          catenateNumbers="0" catenateAll="0" splitOnCaseChange="1" />
+        <filter class="solr.LowerCaseFilterFactory" />
+        
+      </analyzer>
+    </fieldType>
+
+
+    <!--
+      Less flexible matching, but less false matches. Probably not ideal
+      for product names, but may be good for SKUs. Can insert dashes in
+      the wrong place and still match.
+    -->
+    <fieldType name="textTight" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
+          ignoreCase="true" expand="false" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="0" generateNumberParts="0" catenateWords="1"
+          catenateNumbers="1" catenateAll="0" />
+        <filter class="solr.LowerCaseFilterFactory" />
+        
+        <!--
+          this filter can remove any duplicate tokens that appear at the
+          same position - sometimes possible with WordDelimiterFilter in
+          conjuncton with stemming.
+        -->
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
+      </analyzer>
+    </fieldType>
+
+
+    <!--
+      A general unstemmed text field - good if one does not know the
+      language of the field
+    -->
+    <fieldType name="textgen" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="1"
+          catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
+        <filter class="solr.LowerCaseFilterFactory" />
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
+          ignoreCase="true" expand="true" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="0"
+          catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
+        <filter class="solr.LowerCaseFilterFactory" />
+      </analyzer>
+    </fieldType>
+
+
+    <!--
+      A general unstemmed text field that indexes tokens normally and
+      also reversed (via ReversedWildcardFilterFactory), to enable more
+      efficient leading wildcard queries.
+    -->
+    <fieldType name="text_rev" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="1"
+          catenateNumbers="1" catenateAll="0" splitOnCaseChange="0" />
+        <filter class="solr.LowerCaseFilterFactory" />
+        <filter class="solr.ReversedWildcardFilterFactory"
+          withOriginal="true" maxPosAsterisk="3" maxPosQuestion="2"
+          maxFractionAsterisk="0.33" />
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt"
+          ignoreCase="true" expand="true" />
+        <filter class="solr.StopFilterFactory" ignoreCase="true"
+          words="stopwords.txt" enablePositionIncrements="true" />
+        <filter class="solr.WordDelimiterFilterFactory"
+          generateWordParts="1" generateNumberParts="1" catenateWords="0"
+          catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" />
+        <filter class="solr.LowerCaseFilterFactory" />
+      </analyzer>
+    </fieldType>
+
+    <!-- charFilter + WhitespaceTokenizer  -->
+    <!--
+      <fieldType name="textCharNorm" class="solr.TextField"
+      positionIncrementGap="100" > <analyzer> <charFilter
+      class="solr.MappingCharFilterFactory"
+      mapping="mapping-ISOLatin1Accent.txt"/> <tokenizer
+      class="solr.WhitespaceTokenizerFactory"/> </analyzer> </fieldType>
+    -->
+
+    <!--
+      This is an example of using the KeywordTokenizer along With
+      various TokenFilterFactories to produce a sortable field that does
+      not include some properties of the source text
+    -->
+    <fieldType name="alphaOnlySort" class="solr.TextField"
+      sortMissingLast="true" omitNorms="true">
+      <analyzer>
+        <!--
+          KeywordTokenizer does no actual tokenizing, so the entire
+          input string is preserved as a single token
+        -->
+        <tokenizer class="solr.KeywordTokenizerFactory" />
+        <!--
+          The LowerCase TokenFilter does what you expect, which can be
+          when you want your sorting to be case insensitive
+        -->
+        <filter class="solr.LowerCaseFilterFactory" />
+        <!-- The TrimFilter removes any leading or trailing whitespace -->
+        <filter class="solr.TrimFilterFactory" />
+        <!--
+          The PatternReplaceFilter gives you the flexibility to use Java
+          Regular expression to replace any sequence of characters
+          matching a pattern with an arbitrary replacement string, which
+          may include back references to portions of the original string
+          matched by the pattern. See the Java Regular Expression
+          documentation for more information on pattern and replacement
+          string syntax.
+
+          http://java.sun.com/j2se/1.6.0/docs/api/java/util/regex/package-summary.html
+        -->
+        <filter class="solr.PatternReplaceFilterFactory" pattern="([^a-z])"
+          replacement="" replace="all" />
+      </analyzer>
+    </fieldType>
+
+    <fieldtype name="phonetic" stored="false" indexed="true"
+      class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory" />
+        <filter class="solr.DoubleMetaphoneFilterFactory" inject="false" />
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype name="payloads" stored="false" indexed="true"
+      class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory" />
+        <!--
+          The DelimitedPayloadTokenFilter can put payloads on tokens...
+          for example, a token of "foo|1.4" would be indexed as "foo"
+          with a payload of 1.4f Attributes of the
+          DelimitedPayloadTokenFilterFactory : "delimiter" - a one
+          character delimiter. Default is | (pipe) "encoder" - how to
+          encode the following value into a playload float ->
+          org.apache.lucene.analysis.payloads.FloatEncoder, integer ->
+          o.a.l.a.p.IntegerEncoder identity -> o.a.l.a.p.IdentityEncoder
+          Fully Qualified class name implementing PayloadEncoder,
+          Encoder must have a no arg constructor.
+        -->
+        <filter class="solr.DelimitedPayloadTokenFilterFactory"
+          encoder="float" />
+      </analyzer>
+    </fieldtype>
+
+    <!--
+      lowercases the entire field value, keeping it as a single token.
+    -->
+    <fieldType name="lowercase" class="solr.TextField"
+      positionIncrementGap="100">
+      <analyzer>
+        <tokenizer class="solr.KeywordTokenizerFactory" />
+        <filter class="solr.LowerCaseFilterFactory" />
+      </analyzer>
+    </fieldType>
+
+
+    <!--
+      since fields of this type are by default not stored or indexed,
+      any data added to them will be ignored outright.
+    -->
+    <fieldtype name="ignored" stored="false" indexed="false"
+      multiValued="true" class="solr.StrField" />
+
+  </types>
+
+
+  <fields>
+    <!--
+      Valid attributes for fields: name: mandatory - the name for the
+      field type: mandatory - the name of a previously defined type from
+      the <types> section indexed: true if this field should be indexed
+      (searchable or sortable) stored: true if this field should be
+      retrievable compressed: [false] if this field should be stored
+      using gzip compression (this will only apply if the field type is
+      compressable; among the standard field types, only TextField and
+      StrField are) multiValued: true if this field may contain multiple
+      values per document omitNorms: (expert) set to true to omit the
+      norms associated with this field (this disables length
+      normalization and index-time boosting for the field, and saves
+      some memory). Only full-text fields or fields that need an
+      index-time boost need norms. termVectors: [false] set to true to
+      store the term vector for a given field. When using MoreLikeThis,
+      fields used for similarity should be stored for best performance.
+      termPositions: Store position information with the term vector.
+      This will increase storage costs. termOffsets: Store offset
+      information with the term vector. This will increase storage
+      costs. default: a value that should be used if no value is
+      specified when adding a document.
+    -->
+    <field name="id" type="string" indexed="true" stored="true"
+      required="true" />
+    <field name="sku" type="textTight" indexed="true" stored="true"
+      omitNorms="true" />
+    <field name="name" type="textgen" indexed="true" stored="true" />
+    <field name="alphaNameSort" type="alphaOnlySort" indexed="true"
+      stored="false" />
+    <field name="manu" type="textgen" indexed="true" stored="true"
+      omitNorms="true" />
+    <field name="cat" type="text_ws" indexed="true" stored="true"
+      multiValued="true" omitNorms="true" />
+    <field name="features" type="text" indexed="true" stored="true"
+      multiValued="true" />
+    <field name="includes" type="text" indexed="true" stored="true"
+      termVectors="true" termPositions="true" termOffsets="true" />
+
+    <field name="weight" type="float" indexed="true" stored="true" />
+    <field name="price" type="float" indexed="true" stored="true" />
+    <field name="popularity" type="int" indexed="true" stored="true" />
+    <field name="inStock" type="boolean" indexed="true" stored="true" />
+
+
+    <!--
+      Common metadata fields, named specifically to match up with
+      SolrCell metadata when parsing rich documents such as Word, PDF.
+      Some fields are multiValued only because Tika currently may return
+      multiple values for them.
+    -->
+    <field name="title" type="text" indexed="true" stored="true"
+      multiValued="true" />
+    <field name="subject" type="text" indexed="true" stored="true" />
+    <field name="description" type="text" indexed="true" stored="true" />
+    <field name="comments" type="text" indexed="true" stored="true" />
+    <field name="author" type="textgen" indexed="true" stored="true" />
+    <field name="keywords" type="textgen" indexed="true" stored="true" />
+    <field name="category" type="textgen" indexed="true" stored="true" />
+    <field name="content_type" type="string" indexed="true"
+      stored="true" multiValued="true" />
+    <field name="last_modified" type="date" indexed="true" stored="true" />
+    <field name="links" type="string" indexed="true" stored="true"
+      multiValued="true" />
+
+
+    <!--
+      catchall field, containing all other searchable text fields
+      (implemented via copyField further on in this schema
+    -->
+    <field name="text" type="text" indexed="true" stored="false"
+      multiValued="true" />
+
+    <!--
+      catchall text field that indexes tokens both normally and in
+      reverse for efficient leading wildcard queries.
+    -->
+    <field name="text_rev" type="text_rev" indexed="true" stored="false"
+      multiValued="true" />
+
+    <!--
+      non-tokenized version of manufacturer to make it easier to sort or
+      group results by manufacturer. copied from "manu" via copyField
+    -->
+    <field name="manu_exact" type="string" indexed="true" stored="false" />
+
+    <field name="payloads" type="payloads" indexed="true" stored="true" />
+
+    <!--
+      Uncommenting the following will create a "timestamp" field using a
+      default value of "NOW" to indicate when each document was indexed.
+    -->
+    <!--
+      <field name="timestamp" type="date" indexed="true" stored="true"
+      default="NOW" multiValued="false"/>
+    -->
+
+  <field name="language" type="string" indexed="true" stored="true" required="false"/>
+  <field name="sentence" type="text" indexed="true" stored="true" multiValued="true" required="false" />
+  <field name="sentiment" type="string" indexed="true" stored="true" multiValued="true"/>
+  <field name="entity" type="text" indexed="true" stored="true" multiValued="true"/>
+
+    <!--
+      Dynamic field definitions. If a field name is not found,
+      dynamicFields will be used if the name matches any of the
+      patterns. RESTRICTION: the glob-like pattern in the name attribute
+      must have a "*" only at the start or the end. EXAMPLE: name="*_i"
+      will match any field ending in _i (like myid_i, z_i) Longer
+      patterns will be matched first. if equal size patterns both match,
+      the first appearing in the schema will be used. <dynamicField
+      name="*_i" type="int" indexed="true" stored="true"/> <dynamicField
+      name="*_s" type="string" indexed="true" stored="true"/>
+      <dynamicField name="*_l" type="long" indexed="true"
+      stored="true"/> <dynamicField name="*_t" type="text"
+      indexed="true" stored="true"/> <dynamicField name="*_b"
+      type="boolean" indexed="true" stored="true"/> <dynamicField
+      name="*_f" type="float" indexed="true" stored="true"/>
+      <dynamicField name="*_d" type="double" indexed="true"
+      stored="true"/> <dynamicField name="*_dt" type="date"
+      indexed="true" stored="true"/> <dynamicField name="*_ti"
+      type="tint" indexed="true" stored="true"/> <dynamicField
+      name="*_tl" type="tlong" indexed="true" stored="true"/>
+      <dynamicField name="*_tf" type="tfloat" indexed="true"
+      stored="true"/> <dynamicField name="*_td" type="tdouble"
+      indexed="true" stored="true"/> <dynamicField name="*_tdt"
+      type="tdate" indexed="true" stored="true"/> <dynamicField
+      name="*_pi" type="pint" indexed="true" stored="true"/>
+
+      <dynamicField name="ignored_*" type="ignored" multiValued="true"/>
+      <dynamicField name="attr_*" type="textgen" indexed="true"
+      stored="true" multiValued="true"/> <dynamicField name="random_*"
+      type="random" />
+    -->
+    <dynamicField name="*_sm" type="string" indexed="true" stored="true" multiValued="true"/>
+    <!--
+      uncomment the following to ignore any fields that don't already
+      match an existing field name or dynamic field, rather than
+      reporting them as an error. alternately, change the type="ignored"
+      to some other type e.g. "text" if you want unknown fields indexed
+      and/or stored by default
+    -->
+    <!--dynamicField name="*" type="ignored" multiValued="true" /-->
+
+  </fields>
+
+  <!--
+    Field to use to determine and enforce document uniqueness. Unless
+    this field is marked with required="false", it will be a required
+    field
+  -->
+  <uniqueKey>id</uniqueKey>
+
+  <!--
+    field for the QueryParser to use when an explicit fieldname is
+    absent
+  -->
+  <defaultSearchField>text</defaultSearchField>
+
+  <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+  <solrQueryParser defaultOperator="OR" />
+
+  <!--
+    copyField commands copy one field to another at the time a document
+    is added to the index. It's used either to index the same field
+    differently, or to add multiple fields to the same field for
+    easier/faster searching.
+  -->
+
+  <copyField source="cat" dest="text" />
+  <copyField source="name" dest="text" />
+  <copyField source="manu" dest="text" />
+  <copyField source="features" dest="text" />
+  <copyField source="includes" dest="text" />
+  <copyField source="manu" dest="manu_exact" />
+
+
+  <!--copyField source="Titolo" dest="text"/-->
+
+  <!--
+    Above, multiple source fields are copied to the [text] field.
+    Another way to map multiple source fields to the same destination
+    field is to use the dynamic field syntax. copyField also supports a
+    maxChars to copy setting.
+  -->
+
+  <!-- <copyField source="*_t" dest="text" maxChars="3000"/> -->
+
+  <!--
+    copy name to alphaNameSort, a field designed for sorting by name
+  -->
+  <!-- <copyField source="name" dest="alphaNameSort"/> -->
+
+
+  <!--
+    Similarity is the scoring routine for each document vs. a query. A
+    custom similarity may be specified here, but the default is fine for
+    most applications.
+  -->
+  <!--
+    <similarity class="org.apache.lucene.search.DefaultSimilarity"/>
+  -->
+  <!--
+    ... OR ... Specify a SimilarityFactory class name implementation
+    allowing parameters to be used.
+  -->
+  <!--
+    <similarity class="com.example.solr.CustomSimilarityFactory"> <str
+    name="paramkey">param value</str> </similarity>
+  -->
+
+
+</schema>
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/solrconfig.xml b/solr/contrib/uima/src/test-files/uima/solr/conf/solrconfig.xml
new file mode 100644
index 0000000..2e12f3b
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/solrconfig.xml
@@ -0,0 +1,1124 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+
+  <!--
+    Licensed to the Apache Software Foundation (ASF) under one or more
+    contributor license agreements. See the NOTICE file distributed with
+    this work for additional information regarding copyright ownership.
+    The ASF licenses this file to You under the Apache License, Version
+    2.0 (the "License"); you may not use this file except in compliance
+    with the License. You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0 Unless required by
+    applicable law or agreed to in writing, software distributed under
+    the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES
+    OR CONDITIONS OF ANY KIND, either express or implied. See the
+    License for the specific language governing permissions and
+    limitations under the License.
+  -->
+  <!--
+    For more details about configurations options that may appear in
+    this file, see http://wiki.apache.org/solr/SolrConfigXml.
+
+    Specifically, the Solr Config can support XInclude, which may make
+    it easier to manage the configuration. See
+    https://issues.apache.org/jira/browse/SOLR-1167
+  -->
+<config xmlns:xi="http://www.w3.org/2001/XInclude">
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+  <!--
+    lib directives can be used to instruct Solr to load an Jars
+    identified and use them to resolve any "plugins" specified in your
+    solrconfig.xml or schema.xml (ie: Analyzers, Request Handlers,
+    etc...). All directories and paths are resolved relative the
+    instanceDir. If a "./lib" directory exists in your instanceDir, all
+    files found in it are included as if you had used the following
+    syntax... <lib dir="./lib" />
+  -->
+  <!--
+    A dir option by itself adds any files found in the directory to the
+    classpath, this is useful for including all jars in a directory.
+  -->
+  <lib dir="../../contrib/extraction/lib" />
+  <!--
+    When a regex is specified in addition to a directory, only the files
+    in that directory which completely match the regex (anchored on both
+    ends) will be included.
+  -->
+  <lib dir="../../dist/" regex="apache-solr-cell-\d.*\.jar" />
+  <lib dir="../../dist/" regex="apache-solr-clustering-\d.*\.jar" />
+  <!--
+    If a dir option (with or without a regex) is used and nothing is
+    found that matches, it will be ignored
+  -->
+  <lib dir="../../contrib/clustering/lib/downloads/" />
+  <lib dir="../../contrib/clustering/lib/" />
+  <lib dir="/total/crap/dir/ignored" />
+  <!--
+    an exact path can be used to specify a specific file. This will
+    cause a serious error to be logged if it can't be loaded. <lib
+    path="../a-jar-that-does-not-exist.jar" />
+  -->
+
+
+  <!--
+    Used to specify an alternate directory to hold all index data other
+    than the default ./data under the Solr home. If replication is in
+    use, this should match the replication configuration.
+  -->
+  <dataDir>${solr.data.dir:}</dataDir>
+
+
+  <!--
+    WARNING: this <indexDefaults> section only provides defaults for
+    index writers in general. See also the <mainIndex> section after
+    that when changing parameters for Solr's main Lucene index.
+  -->
+  <indexDefaults>
+    <!--
+      Values here affect all index writers and act as a default unless
+      overridden.
+    -->
+    <useCompoundFile>false</useCompoundFile>
+
+    <mergeFactor>10</mergeFactor>
+    <!--
+      If both ramBufferSizeMB and maxBufferedDocs is set, then Lucene
+      will flush based on whichever limit is hit first.
+    -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+
+    <!--
+      Sets the amount of RAM that may be used by Lucene indexing for
+      buffering added documents and deletions before they are flushed to
+      the Directory.
+    -->
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <!-- <maxMergeDocs>2147483647</maxMergeDocs> -->
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <!--
+      Expert: Turn on Lucene's auto commit capability. This causes
+      intermediate segment flushes to write a new lucene index
+      descriptor, enabling it to be opened by an external IndexReader.
+      This can greatly slow down indexing speed. NOTE: Despite the name,
+      this value does not have any relation to Solr's autoCommit
+      functionality
+    -->
+    <!--<luceneAutoCommit>false</luceneAutoCommit>-->
+
+    <!--
+      Expert: The Merge Policy in Lucene controls how merging is handled
+      by Lucene. The default in 2.3 is the LogByteSizeMergePolicy,
+      previous versions used LogDocMergePolicy. LogByteSizeMergePolicy
+      chooses segments to merge based on their size. The Lucene 2.2
+      default, LogDocMergePolicy chose when to merge based on number of
+      documents Other implementations of MergePolicy must have a
+      no-argument constructor
+    -->
+    <!--
+      <mergePolicy
+      class="org.apache.lucene.index.LogByteSizeMergePolicy"/>
+    -->
+
+    <!--
+      Expert: The Merge Scheduler in Lucene controls how merges are
+      performed. The ConcurrentMergeScheduler (Lucene 2.3 default) can
+      perform merges in the background using separate threads. The
+      SerialMergeScheduler (Lucene 2.2 default) does not.
+    -->
+    <!--
+      <mergeScheduler
+      class="org.apache.lucene.index.ConcurrentMergeScheduler"/>
+    -->
+
+
+    <!--
+      This option specifies which Lucene LockFactory implementation to
+      use. single = SingleInstanceLockFactory - suggested for a
+      read-only index or when there is no possibility of another process
+      trying to modify the index. native = NativeFSLockFactory - uses OS
+      native file locking simple = SimpleFSLockFactory - uses a plain
+      file for locking (For backwards compatibility with Solr 1.2,
+      'simple' is the default if not specified.)
+    -->
+    <lockType>native</lockType>
+    <!--
+      Expert: Controls how often Lucene loads terms into memory
+    -->
+    <!--<termIndexInterval>256</termIndexInterval>-->
+  </indexDefaults>
+
+  <mainIndex>
+    <!-- options specific to the main on-disk lucene index -->
+    <useCompoundFile>false</useCompoundFile>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <mergeFactor>10</mergeFactor>
+    <!-- Deprecated -->
+    <!--<maxBufferedDocs>1000</maxBufferedDocs>-->
+    <!--<maxMergeDocs>2147483647</maxMergeDocs>-->
+
+    <!--
+      inherit from indexDefaults <maxFieldLength>10000</maxFieldLength>
+    -->
+
+    <!--
+      If true, unlock any held write or commit locks on startup. This
+      defeats the locking mechanism that allows multiple processes to
+      safely access a lucene index, and should be used with care. This
+      is not needed if lock type is 'none' or 'single'
+    -->
+    <unlockOnStartup>false</unlockOnStartup>
+
+    <!--
+      If true, IndexReaders will be reopened (often more efficient)
+      instead of closed and then opened.
+    -->
+    <reopenReaders>true</reopenReaders>
+
+    <!--
+      Expert: Controls how often Lucene loads terms into memory. Default
+      is 128 and is likely good for most everyone.
+    -->
+    <!--<termIndexInterval>256</termIndexInterval>-->
+
+    <!--
+      Custom deletion policies can specified here. The class must
+      implement org.apache.lucene.index.IndexDeletionPolicy.
+
+      http://lucene.apache.org/java/2_3_2/api/org/apache/lucene/index/IndexDeletionPolicy.html
+
+      The standard Solr IndexDeletionPolicy implementation supports
+      deleting index commit points on number of commits, age of commit
+      point and optimized status. The latest commit point should always
+      be preserved regardless of the criteria.
+    -->
+    <deletionPolicy class="solr.SolrDeletionPolicy">
+      <!-- The number of commit points to be kept -->
+      <str name="maxCommitsToKeep">1</str>
+      <!-- The number of optimized commit points to be kept -->
+      <str name="maxOptimizedCommitsToKeep">0</str>
+      <!--
+        Delete all commit points once they have reached the given age.
+        Supports DateMathParser syntax e.g. <str
+        name="maxCommitAge">30MINUTES</str> <str
+        name="maxCommitAge">1DAY</str>
+      -->
+    </deletionPolicy>
+
+    <!--
+      To aid in advanced debugging, you may turn on IndexWriter debug
+      logging. Setting to true will set the file that the underlying
+      Lucene IndexWriter will write its debug infostream to.
+    -->
+    <infoStream file="INFOSTREAM.txt">false</infoStream>
+
+  </mainIndex>
+
+  <!--
+    Enables JMX if and only if an existing MBeanServer is found, use
+    this if you want to configure JMX through JVM parameters. Remove
+    this to disable exposing Solr configuration and statistics to JMX.
+
+    If you want to connect to a particular server, specify the agentId
+    e.g. <jmx agentId="myAgent" /> If you want to start a new
+    MBeanServer, specify the serviceUrl e.g <jmx
+    serviceUrl="service:jmx:rmi:///jndi/rmi://localhost:9999/solr"/> For
+    more details see http://wiki.apache.org/solr/SolrJmx
+  -->
+  <jmx />
+
+  <!-- the default high-performance update handler -->
+  <updateHandler class="solr.DirectUpdateHandler2">
+    <!--
+      A prefix of "solr." for class names is an alias that causes solr
+      to search appropriate packages, including
+      org.apache.solr.(search|update|request|core|analysis)
+    -->
+
+    <!--
+      Perform a <commit/> automatically under certain conditions:
+      maxDocs - number of updates since last commit is greater than this
+      maxTime - oldest uncommited update (in ms) is this long ago
+      Instead of enabling autoCommit, consider using "commitWithin" when
+      adding documents. http://wiki.apache.org/solr/UpdateXmlMessages
+      <autoCommit> <maxDocs>10000</maxDocs> <maxTime>1000</maxTime>
+      </autoCommit>
+    -->
+
+
+    <!--
+      The RunExecutableListener executes an external command from a hook
+      such as postCommit or postOptimize. exe - the name of the
+      executable to run dir - dir to use as the current working
+      directory. default="." wait - the calling thread waits until the
+      executable returns. default="true" args - the arguments to pass to
+      the program. default=nothing env - environment variables to set.
+      default=nothing
+    -->
+    <!--
+      A postCommit event is fired after every commit or optimize command
+      <listener event="postCommit" class="solr.RunExecutableListener">
+      <str name="exe">solr/bin/snapshooter</str> <str name="dir">.</str>
+      <bool name="wait">true</bool> <arr name="args"> <str>arg1</str>
+      <str>arg2</str> </arr> <arr name="env"> <str>MYVAR=val1</str>
+      </arr> </listener>
+    -->
+    <!--
+      A postOptimize event is fired only after every optimize command
+      <listener event="postOptimize" class="solr.RunExecutableListener">
+      <str name="exe">snapshooter</str> <str name="dir">solr/bin</str>
+      <bool name="wait">true</bool> </listener>
+    -->
+
+  </updateHandler>
+
+  <!--
+    Use the following format to specify a custom IndexReaderFactory -
+    allows for alternate IndexReader implementations. ** Experimental
+    Feature ** Please note - Using a custom IndexReaderFactory may
+    prevent certain other features from working. The API to
+    IndexReaderFactory may change without warning or may even be removed
+    from future releases if the problems cannot be resolved. ** Features
+    that may not work with custom IndexReaderFactory ** The
+    ReplicationHandler assumes a disk-resident index. Using a custom
+    IndexReader implementation may cause incompatibility with
+    ReplicationHandler and may cause replication to not work correctly.
+    See SOLR-1366 for details. <indexReaderFactory
+    name="IndexReaderFactory" class="package.class"> Parameters as
+    required by the implementation </indexReaderFactory >
+  -->
+  <!-- To set the termInfosIndexDivisor, do this: -->
+  <!--
+    <indexReaderFactory name="IndexReaderFactory"
+    class="org.apache.solr.core.StandardIndexReaderFactory"> <int
+    name="setTermIndexDivisor">12</int> </indexReaderFactory >
+  -->
+
+
+  <query>
+    <!--
+      Maximum number of clauses in a boolean query... in the past, this
+      affected range or prefix queries that expanded to big boolean
+      queries - built in Solr query parsers no longer create queries
+      with this limitation. An exception is thrown if exceeded.
+    -->
+    <maxBooleanClauses>1024</maxBooleanClauses>
+
+
+    <!--
+      There are two implementations of cache available for Solr,
+      LRUCache, based on a synchronized LinkedHashMap, and FastLRUCache,
+      based on a ConcurrentHashMap. FastLRUCache has faster gets and
+      slower puts in single threaded operation and thus is generally
+      faster than LRUCache when the hit ratio of the cache is high (>
+      75%), and may be faster under other scenarios on multi-cpu
+      systems.
+    -->
+    <!--
+      Cache used by SolrIndexSearcher for filters (DocSets), unordered
+      sets of *all* documents that match a query. When a new searcher is
+      opened, its caches may be prepopulated or "autowarmed" using data
+      from caches in the old searcher. autowarmCount is the number of
+      items to prepopulate. For LRUCache, the autowarmed items will be
+      the most recently accessed items. Parameters: class - the
+      SolrCache implementation LRUCache or FastLRUCache size - the
+      maximum number of entries in the cache initialSize - the initial
+      capacity (number of entries) of the cache. (seel
+      java.util.HashMap) autowarmCount - the number of entries to
+      prepopulate from and old cache.
+    -->
+    <filterCache class="solr.FastLRUCache" size="512"
+      initialSize="512" autowarmCount="0" />
+
+    <!--
+      Cache used to hold field values that are quickly accessible by
+      document id. The fieldValueCache is created by default even if not
+      configured here. <fieldValueCache class="solr.FastLRUCache"
+      size="512" autowarmCount="128" showItems="32" />
+    -->
+
+    <!--
+      queryResultCache caches results of searches - ordered lists of
+      document ids (DocList) based on a query, a sort, and the range of
+      documents requested.
+    -->
+    <queryResultCache class="solr.LRUCache" size="512"
+      initialSize="512" autowarmCount="0" />
+
+    <!--
+      documentCache caches Lucene Document objects (the stored fields
+      for each document). Since Lucene internal document ids are
+      transient, this cache will not be autowarmed.
+    -->
+    <documentCache class="solr.LRUCache" size="512"
+      initialSize="512" autowarmCount="0" />
+
+    <!--
+      If true, stored fields that are not requested will be loaded
+      lazily. This can result in a significant speed improvement if the
+      usual case is to not load all stored fields, especially if the
+      skipped fields are large compressed text fields.
+    -->
+    <enableLazyFieldLoading>true</enableLazyFieldLoading>
+
+    <!--
+      Example of a generic cache. These caches may be accessed by name
+      through SolrIndexSearcher.getCache(),cacheLookup(), and
+      cacheInsert(). The purpose is to enable easy caching of
+      user/application level data. The regenerator argument should be
+      specified as an implementation of solr.search.CacheRegenerator if
+      autowarming is desired.
+    -->
+    <!--
+      <cache name="myUserCache" class="solr.LRUCache" size="4096"
+      initialSize="1024" autowarmCount="1024"
+      regenerator="org.mycompany.mypackage.MyRegenerator" />
+    -->
+
+    <!--
+      An optimization that attempts to use a filter to satisfy a search.
+      If the requested sort does not include score, then the filterCache
+      will be checked for a filter matching the query. If found, the
+      filter will be used as the source of document ids, and then the
+      sort will be applied to that.
+      <useFilterForSortedQuery>true</useFilterForSortedQuery>
+    -->
+
+    <!--
+      An optimization for use with the queryResultCache. When a search
+      is requested, a superset of the requested number of document ids
+      are collected. For example, if a search for a particular query
+      requests matching documents 10 through 19, and queryWindowSize is
+      50, then documents 0 through 49 will be collected and cached. Any
+      further requests in that range can be satisfied via the cache.
+    -->
+    <queryResultWindowSize>20</queryResultWindowSize>
+
+    <!--
+      Maximum number of documents to cache for any entry in the
+      queryResultCache.
+    -->
+    <queryResultMaxDocsCached>200</queryResultMaxDocsCached>
+
+    <!--
+      a newSearcher event is fired whenever a new searcher is being
+      prepared and there is a current searcher handling requests (aka
+      registered). It can be used to prime certain caches to prevent
+      long request times for certain requests.
+    -->
+    <!--
+      QuerySenderListener takes an array of NamedList and executes a
+      local query request for each NamedList in sequence.
+    -->
+    <listener event="newSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <!--
+          <lst> <str name="q">solr</str> <str name="start">0</str> <str
+          name="rows">10</str> </lst> <lst> <str name="q">rocks</str>
+          <str name="start">0</str> <str name="rows">10</str> </lst>
+          <lst><str name="q">static newSearcher warming query from
+          solrconfig.xml</str></lst>
+        -->
+      </arr>
+    </listener>
+
+    <!--
+      a firstSearcher event is fired whenever a new searcher is being
+      prepared but there is no current registered searcher to handle
+      requests or to gain autowarming data from.
+    -->
+    <listener event="firstSearcher" class="solr.QuerySenderListener">
+      <arr name="queries">
+        <lst>
+          <str name="q">solr rocks</str>
+          <str name="start">0</str>
+          <str name="rows">10</str>
+        </lst>
+        <lst>
+          <str name="q">static firstSearcher warming query from
+            solrconfig.xml</str>
+        </lst>
+      </arr>
+    </listener>
+
+    <!--
+      If a search request comes in and there is no current registered
+      searcher, then immediately register the still warming searcher and
+      use it. If "false" then all requests will block until the first
+      searcher is done warming.
+    -->
+    <useColdSearcher>false</useColdSearcher>
+
+    <!--
+      Maximum number of searchers that may be warming in the background
+      concurrently. An error is returned if this limit is exceeded.
+      Recommend 1-2 for read-only slaves, higher for masters w/o cache
+      warming.
+    -->
+    <maxWarmingSearchers>2</maxWarmingSearchers>
+
+  </query>
+
+  <!--
+    Let the dispatch filter handler /select?qt=XXX handleSelect=true
+    will use consistent error handling for /select and /update
+    handleSelect=false will use solr1.1 style error formatting
+  -->
+  <requestDispatcher handleSelect="true">
+    <!--
+      Make sure your system has some authentication before enabling
+      remote streaming!
+    -->
+    <requestParsers enableRemoteStreaming="true"
+      multipartUploadLimitInKB="2048000" />
+
+    <!--
+      Set HTTP caching related parameters (for proxy caches and
+      clients). To get the behaviour of Solr 1.2 (ie: no caching related
+      headers) use the never304="true" option and do not specify a value
+      for <cacheControl>
+    -->
+    <!-- <httpCaching never304="true"> -->
+    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr">
+      <!--
+        lastModFrom="openTime" is the default, the Last-Modified value
+        (and validation against If-Modified-Since requests) will all be
+        relative to when the current Searcher was opened. You can change
+        it to lastModFrom="dirLastMod" if you want the value to exactly
+        corrispond to when the physical index was last modified.
+
+        etagSeed="..." is an option you can change to force the ETag
+        header (and validation against If-None-Match requests) to be
+        differnet even if the index has not changed (ie: when making
+        significant changes to your config file) lastModifiedFrom and
+        etagSeed are both ignored if you use the never304="true" option.
+      -->
+      <!--
+        If you include a <cacheControl> directive, it will be used to
+        generate a Cache-Control header, as well as an Expires header if
+        the value contains "max-age=" By default, no Cache-Control
+        header is generated. You can use the <cacheControl> option even
+        if you have set never304="true"
+      -->
+      <!-- <cacheControl>max-age=30, public</cacheControl> -->
+    </httpCaching>
+  </requestDispatcher>
+
+
+  <!--
+    requestHandler plugins... incoming queries will be dispatched to the
+    correct handler based on the path or the qt (query type) param.
+    Names starting with a '/' are accessed with the a path equal to the
+    registered name. Names without a leading '/' are accessed with:
+    http://host/app/select?qt=name If no qt is defined, the
+    requestHandler that declares default="true" will be used.
+  -->
+  <requestHandler name="standard" class="solr.SearchHandler"
+    default="true">
+    <!-- default values for query parameters -->
+    <lst name="defaults">
+      <str name="echoParams">explicit</str>
+      <!--
+        <int name="rows">10</int> <str name="fl">*</str> <str
+        name="version">2.1</str>
+      -->
+    </lst>
+  </requestHandler>
+
+  <!--
+    Please refer to http://wiki.apache.org/solr/SolrReplication for
+    details on configuring replication
+  -->
+  <!-- remove the <lst name="master"> section if this is just a slave -->
+  <!-- remove  the <lst name="slave"> section if this is just a master -->
+  <!--
+    <requestHandler name="/replication" class="solr.ReplicationHandler"
+    > <lst name="master"> <str name="replicateAfter">commit</str> <str
+    name="replicateAfter">startup</str> <str
+    name="confFiles">schema.xml,stopwords.txt</str> </lst> <lst
+    name="slave"> <str
+    name="masterUrl">http://localhost:8983/solr/replication</str> <str
+    name="pollInterval">00:00:60</str> </lst> </requestHandler>
+  -->
+
+  <!--
+    DisMaxRequestHandler allows easy searching across multiple fields
+    for simple user-entered phrases. It's implementation is now just the
+    standard SearchHandler with a default query type of "dismax". see
+    http://wiki.apache.org/solr/DisMaxRequestHandler
+  -->
+  <requestHandler name="dismax" class="solr.SearchHandler">
+    <lst name="defaults">
+      <str name="defType">dismax</str>
+      <str name="echoParams">explicit</str>
+      <float name="tie">0.01</float>
+      <str name="qf">
+        text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0
+        manu^1.1 cat^1.4
+     </str>
+      <str name="pf">
+        text^0.2 features^1.1 name^1.5 manu^1.4
+        manu_exact^1.9
+     </str>
+      <str name="bf">
+        popularity^0.5 recip(price,1,1000,1000)^0.3
+     </str>
+      <str name="fl">
+        id,name,price,score
+     </str>
+      <str name="mm">
+        2&lt;-1 5&lt;-2 6&lt;90% </str>
+      <int name="ps">100</int>
+      <str name="q.alt">*:*</str>
+      <!-- example highlighter config, enable per-query with hl=true -->
+      <str name="hl.fl">text features name</str>
+      <!-- for this field, we want no fragmenting, just highlighting -->
+      <str name="f.name.hl.fragsize">0</str>
+      <!--
+        instructs Solr to return the field itself if no query terms are
+        found
+      -->
+      <str name="f.name.hl.alternateField">name</str>
+      <str name="f.text.hl.fragmenter">regex</str> <!-- defined below -->
+    </lst>
+  </requestHandler>
+
+  <!--
+    Note how you can register the same handler multiple times with
+    different names (and different init parameters)
+  -->
+  <requestHandler name="partitioned" class="solr.SearchHandler">
+    <lst name="defaults">
+      <str name="defType">dismax</str>
+      <str name="echoParams">explicit</str>
+      <str name="qf">text^0.5 features^1.0 name^1.2 sku^1.5 id^10.0</str>
+      <str name="mm">2&lt;-1 5&lt;-2 6&lt;90%</str>
+      <!--
+        This is an example of using Date Math to specify a constantly
+        moving date range in a config...
+      -->
+      <str name="bq">incubationdate_dt:[* TO NOW/DAY-1MONTH]^2.2</str>
+    </lst>
+    <!--
+      In addition to defaults, "appends" params can be specified to
+      identify values which should be appended to the list of multi-val
+      params from the query (or the existing "defaults"). In this
+      example, the param "fq=instock:true" will be appended to any query
+      time fq params the user may specify, as a mechanism for
+      partitioning the index, independent of any user selected filtering
+      that may also be desired (perhaps as a result of faceted
+      searching). NOTE: there is *absolutely* nothing a client can do to
+      prevent these "appends" values from being used, so don't use this
+      mechanism unless you are sure you always want it.
+    -->
+    <lst name="appends">
+      <str name="fq">inStock:true</str>
+    </lst>
+    <!--
+      "invariants" are a way of letting the Solr maintainer lock down
+      the options available to Solr clients. Any params values specified
+      here are used regardless of what values may be specified in either
+      the query, the "defaults", or the "appends" params. In this
+      example, the facet.field and facet.query params are fixed,
+      limiting the facets clients can use. Faceting is not turned on by
+      default - but if the client does specify facet=true in the
+      request, these are the only facets they will be able to see counts
+      for; regardless of what other facet.field or facet.query params
+      they may specify. NOTE: there is *absolutely* nothing a client can
+      do to prevent these "invariants" values from being used, so don't
+      use this mechanism unless you are sure you always want it.
+    -->
+    <lst name="invariants">
+      <str name="facet.field">cat</str>
+      <str name="facet.field">manu_exact</str>
+      <str name="facet.query">price:[* TO 500]</str>
+      <str name="facet.query">price:[500 TO *]</str>
+    </lst>
+  </requestHandler>
+
+
+  <!--
+    Search components are registered to SolrCore and used by Search
+    Handlers By default, the following components are avaliable:
+
+    <searchComponent name="query"
+    class="org.apache.solr.handler.component.QueryComponent" />
+    <searchComponent name="facet"
+    class="org.apache.solr.handler.component.FacetComponent" />
+    <searchComponent name="mlt"
+    class="org.apache.solr.handler.component.MoreLikeThisComponent" />
+    <searchComponent name="highlight"
+    class="org.apache.solr.handler.component.HighlightComponent" />
+    <searchComponent name="stats"
+    class="org.apache.solr.handler.component.StatsComponent" />
+    <searchComponent name="debug"
+    class="org.apache.solr.handler.component.DebugComponent" /> Default
+    configuration in a requestHandler would look like: <arr
+    name="components"> <str>query</str> <str>facet</str> <str>mlt</str>
+    <str>highlight</str> <str>stats</str> <str>debug</str> </arr> If you
+    register a searchComponent to one of the standard names, that will
+    be used instead. To insert components before or after the 'standard'
+    components, use: <arr name="first-components">
+    <str>myFirstComponentName</str> </arr> <arr name="last-components">
+    <str>myLastComponentName</str> </arr>
+  -->
+
+  <!--
+    The spell check component can return a list of alternative spelling
+    suggestions.
+  -->
+  <searchComponent name="spellcheck" class="solr.SpellCheckComponent">
+
+    <str name="queryAnalyzerFieldType">textSpell</str>
+
+    <lst name="spellchecker">
+      <str name="name">default</str>
+      <str name="field">name</str>
+      <str name="spellcheckIndexDir">./spellchecker</str>
+    </lst>
+
+    <!--
+      a spellchecker that uses a different distance measure <lst
+      name="spellchecker"> <str name="name">jarowinkler</str> <str
+      name="field">spell</str> <str
+      name="distanceMeasure">org.apache.lucene.search.spell.JaroWinklerDistance</str>
+      <str name="spellcheckIndexDir">./spellchecker2</str> </lst>
+    -->
+
+    <!--
+      a file based spell checker <lst name="spellchecker"> <str
+      name="classname">solr.FileBasedSpellChecker</str> <str
+      name="name">file</str> <str
+      name="sourceLocation">spellings.txt</str> <str
+      name="characterEncoding">UTF-8</str> <str
+      name="spellcheckIndexDir">./spellcheckerFile</str> </lst>
+    -->
+  </searchComponent>
+
+  <!--
+    A request handler utilizing the spellcheck component.
+    #############################################################################
+    NOTE: This is purely as an example. The whole purpose of the
+    SpellCheckComponent is to hook it into the request handler that
+    handles (i.e. the standard or dismax SearchHandler) queries such
+    that a separate request is not needed to get suggestions. IN OTHER
+    WORDS, THERE IS REALLY GOOD CHANCE THE SETUP BELOW IS NOT WHAT YOU
+    WANT FOR YOUR PRODUCTION SYSTEM!
+    #############################################################################
+  -->
+  <requestHandler name="/spell" class="solr.SearchHandler"
+    lazy="true">
+    <lst name="defaults">
+      <!-- omp = Only More Popular -->
+      <str name="spellcheck.onlyMorePopular">false</str>
+      <!-- exr = Extended Results -->
+      <str name="spellcheck.extendedResults">false</str>
+      <!--  The number of suggestions to return -->
+      <str name="spellcheck.count">1</str>
+    </lst>
+    <arr name="last-components">
+      <str>spellcheck</str>
+    </arr>
+  </requestHandler>
+
+  <searchComponent name="tvComponent"
+    class="org.apache.solr.handler.component.TermVectorComponent" />
+  <!--
+    A Req Handler for working with the tvComponent. This is purely as an
+    example. You will likely want to add the component to your already
+    specified request handlers.
+  -->
+  <requestHandler name="tvrh"
+    class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <bool name="tv">true</bool>
+    </lst>
+    <arr name="last-components">
+      <str>tvComponent</str>
+    </arr>
+  </requestHandler>
+
+  <!--
+    Clustering Component http://wiki.apache.org/solr/ClusteringComponent
+    This relies on third party jars which are not included in the
+    release. To use this component (and the "/clustering" handler) Those
+    jars will need to be downloaded, and you'll need to set the
+    solr.cluster.enabled system property when running solr... java
+    -Dsolr.clustering.enabled=true -jar start.jar
+  -->
+  <searchComponent name="clusteringComponent"
+    enable="${solr.clustering.enabled:false}" class="org.apache.solr.handler.clustering.ClusteringComponent">
+    <!-- Declare an engine -->
+    <lst name="engine">
+      <!-- The name, only one can be named "default" -->
+      <str name="name">default</str>
+      <!--
+        Class name of Carrot2 clustering algorithm. Currently available
+        algorithms are: *
+        org.carrot2.clustering.lingo.LingoClusteringAlgorithm *
+        org.carrot2.clustering.stc.STCClusteringAlgorithm See
+        http://project.carrot2.org/algorithms.html for the algorithm's
+        characteristics.
+      -->
+      <str name="carrot.algorithm">org.carrot2.clustering.lingo.LingoClusteringAlgorithm</str>
+      <!--
+        Overriding values for Carrot2 default algorithm attributes. For
+        a description of all available attributes, see:
+        http://download.carrot2.org/stable/manual/#chapter.components.
+        Use attribute key as name attribute of str elements below. These
+        can be further overridden for individual requests by specifying
+        attribute key as request parameter name and attribute value as
+        parameter value.
+      -->
+      <str name="LingoClusteringAlgorithm.desiredClusterCountBase">20</str>
+    </lst>
+    <lst name="engine">
+      <str name="name">stc</str>
+      <str name="carrot.algorithm">org.carrot2.clustering.stc.STCClusteringAlgorithm</str>
+    </lst>
+  </searchComponent>
+  <requestHandler name="/clustering" enable="${solr.clustering.enabled:false}"
+    class="solr.SearchHandler">
+    <lst name="defaults">
+      <bool name="clustering">true</bool>
+      <str name="clustering.engine">default</str>
+      <bool name="clustering.results">true</bool>
+      <!-- The title field -->
+      <str name="carrot.title">name</str>
+      <str name="carrot.url">id</str>
+      <!-- The field to cluster on -->
+      <str name="carrot.snippet">features</str>
+      <!-- produce summaries -->
+      <bool name="carrot.produceSummary">true</bool>
+      <!-- the maximum number of labels per cluster -->
+      <!--<int name="carrot.numDescriptions">5</int>-->
+      <!-- produce sub clusters -->
+      <bool name="carrot.outputSubClusters">false</bool>
+    </lst>
+    <arr name="last-components">
+      <str>clusteringComponent</str>
+    </arr>
+  </requestHandler>
+
+  <!-- Solr Cell: http://wiki.apache.org/solr/ExtractingRequestHandler -->
+  <requestHandler name="/update/extract"
+    class="org.apache.solr.handler.extraction.ExtractingRequestHandler"
+    startup="lazy">
+    <lst name="defaults">
+      <!--
+        All the main content goes into "text"... if you need to return
+        the extracted text or do highlighting, use a stored field.
+      -->
+      <str name="fmap.content">text</str>
+      <str name="lowernames">true</str>
+      <str name="uprefix">ignored_</str>
+
+      <!-- capture link hrefs but ignore div attributes -->
+      <str name="captureAttr">true</str>
+      <str name="fmap.a">links</str>
+      <str name="fmap.div">ignored_</str>
+    </lst>
+  </requestHandler>
+
+
+  <!--
+    A component to return terms and document frequency of those terms.
+    This component does not yet support distributed search.
+  -->
+  <searchComponent name="termsComponent"
+    class="org.apache.solr.handler.component.TermsComponent" />
+
+  <requestHandler name="/terms"
+    class="org.apache.solr.handler.component.SearchHandler">
+    <lst name="defaults">
+      <bool name="terms">true</bool>
+    </lst>
+    <arr name="components">
+      <str>termsComponent</str>
+    </arr>
+  </requestHandler>
+
+
+
+
+  <!--
+    Update request handler. Note: Since solr1.1 requestHandlers requires
+    a valid content type header if posted in the body. For example, curl
+    now requires: -H 'Content-type:text/xml; charset=utf-8' The response
+    format differs from solr1.1 formatting and returns a standard error
+    code. To enable solr1.1 behavior, remove the /update handler or
+    change its path
+  -->
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler">
+    <lst name="defaults">
+      <str name="update.chain">uima</str>
+    </lst>
+  </requestHandler>
+
+
+  <requestHandler name="/update/javabin" class="solr.BinaryUpdateRequestHandler" />
+
+  <!--
+    Analysis request handler. Since Solr 1.3. Use to return how a
+    document is analyzed. Useful for debugging and as a token server for
+    other types of applications. This is deprecated in favor of the
+    improved DocumentAnalysisRequestHandler and
+    FieldAnalysisRequestHandler <requestHandler name="/analysis"
+    class="solr.AnalysisRequestHandler" />
+  -->
+
+  <!--
+    An analysis handler that provides a breakdown of the analysis
+    process of provided docuemnts. This handler expects a (single)
+    content stream with the following format: <docs> <doc> <field
+    name="id">1</field> <field name="name">The Name</field> <field
+    name="text">The Text Value</field> <doc> <doc>...</doc>
+    <doc>...</doc> ... </docs> Note: Each document must contain a field
+    which serves as the unique key. This key is used in the returned
+    response to assoicate an analysis breakdown to the analyzed
+    document. Like the FieldAnalysisRequestHandler, this handler also
+    supports query analysis by sending either an "analysis.query" or "q"
+    request paraemter that holds the query text to be analyized. It also
+    supports the "analysis.showmatch" parameter which when set to true,
+    all field tokens that match the query tokens will be marked as a
+    "match".
+  -->
+  <requestHandler name="/analysis/document"
+    class="solr.DocumentAnalysisRequestHandler" />
+
+  <!--
+    RequestHandler that provides much the same functionality as
+    analysis.jsp. Provides the ability to specify multiple field types
+    and field names in the same request and outputs index-time and
+    query-time analysis for each of them. Request parameters are:
+    analysis.fieldname - The field name whose analyzers are to be used
+    analysis.fieldtype - The field type whose analyzers are to be used
+    analysis.fieldvalue - The text for index-time analysis q (or
+    analysis.q) - The text for query time analysis analysis.showmatch
+    (true|false) - When set to true and when query analysis is
+    performed, the produced tokens of the field value analysis will be
+    marked as "matched" for every token that is produces by the query
+    analysis
+  -->
+  <requestHandler name="/analysis/field" class="solr.FieldAnalysisRequestHandler" />
+
+
+  <!-- CSV update handler, loaded on demand -->
+  <requestHandler name="/update/csv" class="solr.CSVRequestHandler"
+    startup="lazy" />
+
+
+  <!--
+    Admin Handlers - This will register all the standard admin
+    RequestHandlers. Adding this single handler is equivalent to
+    registering: <requestHandler name="/admin/luke"
+    class="org.apache.solr.handler.admin.LukeRequestHandler" />
+    <requestHandler name="/admin/system"
+    class="org.apache.solr.handler.admin.SystemInfoHandler" />
+    <requestHandler name="/admin/plugins"
+    class="org.apache.solr.handler.admin.PluginInfoHandler" />
+    <requestHandler name="/admin/threads"
+    class="org.apache.solr.handler.admin.ThreadDumpHandler" />
+    <requestHandler name="/admin/properties"
+    class="org.apache.solr.handler.admin.PropertiesRequestHandler" />
+    <requestHandler name="/admin/file"
+    class="org.apache.solr.handler.admin.ShowFileRequestHandler" > If
+    you wish to hide files under ${solr.home}/conf, explicitly register
+    the ShowFileRequestHandler using: <requestHandler name="/admin/file"
+    class="org.apache.solr.handler.admin.ShowFileRequestHandler" > <lst
+    name="invariants"> <str name="hidden">synonyms.txt</str> <str
+    name="hidden">anotherfile.txt</str> </lst> </requestHandler>
+  -->
+  <requestHandler name="/admin/"
+    class="org.apache.solr.handler.admin.AdminHandlers" />
+
+  <!-- Echo the request contents back to the client -->
+  <requestHandler name="/debug/dump" class="solr.DumpRequestHandler">
+    <lst name="defaults">
+      <str name="echoParams">explicit</str> <!-- for all params (including the default etc) use: 'all' -->
+      <str name="echoHandler">true</str>
+    </lst>
+  </requestHandler>
+
+  <!--
+    An example dedup update processor that creates the "id" field on the
+    fly based on the hash code of some other fields. This example has
+    overwriteDupes set to false since we are using the id field as the
+    signatureField and Solr will maintain uniqueness based on that
+    anyway. You have to link the chain to an update handler above to use
+    it ie: <requestHandler name="/update
+    "class="solr.XmlUpdateRequestHandler"> <lst name="defaults"> <str
+    name="update.chain">dedupe</str> </lst> </requestHandler>
+  -->
+
+  <updateRequestProcessorChain name="uima">
+    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
+      <lst name="uimaConfig">
+        <lst name="runtimeParameters">
+          <int name="ngramsize">3</int>
+        </lst>
+        <str name="analysisEngine">/uima/TestAE.xml</str>
+        <lst name="analyzeFields">
+          <bool name="merge">false</bool>
+          <arr name="fields">
+            <str>text</str>
+          </arr>
+        </lst>
+        <lst name="fieldMappings">
+          <lst name="type">
+            <str name="name">org.apache.uima.SentenceAnnotation</str>
+            <lst name="mapping">
+              <str name="feature">coveredText</str>
+              <str name="field">sentence</str>
+            </lst>
+          </lst>
+          <lst name="type">
+            <str name="name">org.apache.solr.uima.ts.SentimentAnnotation</str>
+            <lst name="mapping">
+              <str name="feature">mood</str>
+              <str name="field">sentiment</str>
+            </lst>
+          </lst>
+          <lst name="type">
+            <str name="name">org.apache.solr.uima.ts.EntityAnnotation</str>
+            <lst name="mapping">
+              <str name="feature">entity</str>
+              <str name="fieldNameFeature">name</str>
+              <str name="dynamicField">*_sm</str>
+            </lst>
+          </lst>
+        </lst>
+      </lst>
+    </processor>
+    <processor class="solr.RunUpdateProcessorFactory" />
+  </updateRequestProcessorChain>
+
+  <updateRequestProcessorChain name="uima-multi-map">
+    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
+      <lst name="uimaConfig">
+        <lst name="runtimeParameters">
+          <int name="ngramsize">3</int>
+        </lst>
+        <str name="analysisEngine">/uima/TestAE.xml</str>
+        <lst name="analyzeFields">
+          <bool name="merge">false</bool>
+          <arr name="fields">
+            <str>text</str>
+          </arr>
+        </lst>
+        <lst name="fieldMappings">
+          <lst name="type">
+            <str name="name">a-type-which-can-have-multiple-features</str>
+            <lst name="mapping">
+              <str name="feature">A</str>
+              <str name="field">1</str>
+            </lst>
+            <lst name="mapping">
+              <str name="feature">B</str>
+              <str name="field">2</str>
+            </lst>
+          </lst>
+        </lst>
+      </lst>
+    </processor>
+  </updateRequestProcessorChain>
+
+  <updateRequestProcessorChain name="uima-not-ignoreErrors">
+    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
+      <lst name="uimaConfig">
+        <lst name="runtimeParameters">
+          <int name="ngramsize">3</int>
+        </lst>
+        <str name="analysisEngine">/uima/TestExceptionAE.xml</str>
+        <bool name="ignoreErrors">false</bool>
+        <lst name="analyzeFields">
+          <bool name="merge">false</bool>
+          <arr name="fields">
+            <str>text</str>
+          </arr>
+        </lst>
+        <lst name="fieldMappings"/>
+      </lst>
+    </processor>
+    <processor class="solr.RunUpdateProcessorFactory" />
+  </updateRequestProcessorChain>
+
+  <updateRequestProcessorChain name="uima-ignoreErrors">
+    <processor class="org.apache.solr.uima.processor.UIMAUpdateRequestProcessorFactory">
+      <lst name="uimaConfig">
+        <lst name="runtimeParameters">
+          <int name="ngramsize">3</int>
+        </lst>
+        <str name="analysisEngine">/uima/TestExceptionAE.xml</str>
+        <bool name="ignoreErrors">true</bool>
+        <!-- This is optional. It is used for logging when text processing fails. Usually, set uniqueKey field name -->
+        <str name="logField">id</str>
+        <lst name="analyzeFields">
+          <bool name="merge">false</bool>
+          <arr name="fields">
+            <str>text</str>
+          </arr>
+        </lst>
+        <lst name="fieldMappings"/>
+      </lst>
+    </processor>
+    <processor class="solr.RunUpdateProcessorFactory" />
+  </updateRequestProcessorChain>
+
+  <!--
+    queryResponseWriter plugins... query responses will be written using
+    the writer specified by the 'wt' request parameter matching the name
+    of a registered writer. The "default" writer is the default and will
+    be used if 'wt' is not specified in the request. XMLResponseWriter
+    will be used if nothing is specified here. The json, python, and
+    ruby writers are also available by default. <queryResponseWriter
+    name="xml" class="org.apache.solr.request.XMLResponseWriter"
+    default="true"/> <queryResponseWriter name="json"
+    class="org.apache.solr.request.JSONResponseWriter"/>
+    <queryResponseWriter name="python"
+    class="org.apache.solr.request.PythonResponseWriter"/>
+    <queryResponseWriter name="ruby"
+    class="org.apache.solr.request.RubyResponseWriter"/>
+    <queryResponseWriter name="php"
+    class="org.apache.solr.request.PHPResponseWriter"/>
+    <queryResponseWriter name="phps"
+    class="org.apache.solr.request.PHPSerializedResponseWriter"/>
+
+    <queryResponseWriter name="custom"
+    class="com.example.MyResponseWriter"/>
+  -->
+
+  <!--
+    XSLT response writer transforms the XML output by any xslt file
+    found in Solr's conf/xslt directory. Changes to xslt files are
+    checked for every xsltCacheLifetimeSeconds.
+  -->
+  <queryResponseWriter name="xslt"
+    class="org.apache.solr.response.XSLTResponseWriter">
+    <int name="xsltCacheLifetimeSeconds">5</int>
+  </queryResponseWriter>
+
+
+  <!--
+    example of registering a query parser <queryParser name="lucene"
+    class="org.apache.solr.search.LuceneQParserPlugin"/>
+  -->
+
+  <!--
+    example of registering a custom function parser <valueSourceParser
+    name="myfunc" class="com.mycompany.MyValueSourceParser" />
+  -->
+
+  <!-- config for the admin interface -->
+  <admin>
+    <defaultQuery>*</defaultQuery>
+
+    <!--
+      configure a healthcheck file for servers behind a loadbalancer
+      <healthcheck type="file">server-enabled</healthcheck>
+    -->
+  </admin>
+
+</config>
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/spellings.txt b/solr/contrib/uima/src/test-files/uima/solr/conf/spellings.txt
new file mode 100644
index 0000000..162a044
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/spellings.txt
@@ -0,0 +1,2 @@
+pizza
+history
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/stopwords.txt b/solr/contrib/uima/src/test-files/uima/solr/conf/stopwords.txt
new file mode 100644
index 0000000..b5824da
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/stopwords.txt
@@ -0,0 +1,58 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+# a couple of test stopwords to test that the words are really being
+# configured from this file:
+stopworda
+stopwordb
+
+#Standard english stop words taken from Lucene's StopAnalyzer
+a
+an
+and
+are
+as
+at
+be
+but
+by
+for
+if
+in
+into
+is
+it
+no
+not
+of
+on
+or
+s
+such
+t
+that
+the
+their
+then
+there
+these
+they
+this
+to
+was
+will
+with
+
diff --git a/solr/contrib/uima/src/test-files/uima/solr/conf/synonyms.txt b/solr/contrib/uima/src/test-files/uima/solr/conf/synonyms.txt
new file mode 100644
index 0000000..b0e31cb
--- /dev/null
+++ b/solr/contrib/uima/src/test-files/uima/solr/conf/synonyms.txt
@@ -0,0 +1,31 @@
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#-----------------------------------------------------------------------
+#some test synonym mappings unlikely to appear in real input text
+aaa => aaaa
+bbb => bbbb1 bbbb2
+ccc => cccc1,cccc2
+a\=>a => b\=>b
+a\,a => b\,b
+fooaaa,baraaa,bazaaa
+
+# Some synonym groups specific to this example
+GB,gib,gigabyte,gigabytes
+MB,mib,megabyte,megabytes
+Television, Televisions, TV, TVs
+#notice we use "gib" instead of "GiB" so any WordDelimiterFilter coming
+#after us won't split it into two words.
+
+# Synonym mappings can be used for spelling correction too
+pixima => pixma
+
diff --git a/solr/contrib/uima/src/test/org/apache/solr/uima/processor/UIMAUpdateRequestProcessorTest.java b/solr/contrib/uima/src/test/org/apache/solr/uima/processor/UIMAUpdateRequestProcessorTest.java
index 74164a5..eba0e09 100644
--- a/solr/contrib/uima/src/test/org/apache/solr/uima/processor/UIMAUpdateRequestProcessorTest.java
+++ b/solr/contrib/uima/src/test/org/apache/solr/uima/processor/UIMAUpdateRequestProcessorTest.java
@@ -50,7 +50,7 @@ public class UIMAUpdateRequestProcessorTest extends SolrTestCaseJ4 {
 
   @BeforeClass
   public static void beforeClass() throws Exception {
-    initCore("solrconfig.xml", "schema.xml", "solr-uima");
+    initCore("solrconfig.xml", "schema.xml", getFile("uima/solr").getAbsolutePath());
   }
 
   @Override
diff --git a/solr/solrj/src/test-files/README b/solr/solrj/src/test-files/README
deleted file mode 100644
index 10f878a..0000000
--- a/solr/solrj/src/test-files/README
+++ /dev/null
@@ -1,21 +0,0 @@
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-This directory is where any non-transient, non-java files needed
-for the execution of tests should live.
-
-It is used as the CWD when running JUnit tests.
diff --git a/solr/solrj/src/test-files/books.csv b/solr/solrj/src/test-files/books.csv
deleted file mode 100644
index 36b20f5..0000000
--- a/solr/solrj/src/test-files/books.csv
+++ /dev/null
@@ -1,11 +0,0 @@
-id,cat,name,price,inStock,author_t,series_t,sequence_i,genre_s
-0553573403,book,A Game of Thrones,7.99,true,George R.R. Martin,"A Song of Ice and Fire",1,fantasy
-0553579908,book,A Clash of Kings,7.99,true,George R.R. Martin,"A Song of Ice and Fire",2,fantasy
-055357342X,book,A Storm of Swords,7.99,true,George R.R. Martin,"A Song of Ice and Fire",3,fantasy
-0553293354,book,Foundation,7.99,true,Isaac Asimov,Foundation Novels,1,scifi
-0812521390,book,The Black Company,6.99,false,Glen Cook,The Chronicles of The Black Company,1,fantasy
-0812550706,book,Ender's Game,6.99,true,Orson Scott Card,Ender,1,scifi
-0441385532,book,Jhereg,7.95,false,Steven Brust,Vlad Taltos,1,fantasy
-0380014300,book,Nine Princes In Amber,6.99,true,Roger Zelazny,the Chronicles of Amber,1,fantasy
-0805080481,book,The Book of Three,5.99,true,Lloyd Alexander,The Chronicles of Prydain,1,fantasy
-080508049X,book,The Black Cauldron,5.99,true,Lloyd Alexander,The Chronicles of Prydain,2,fantasy
diff --git a/solr/solrj/src/test-files/docs1.xml b/solr/solrj/src/test-files/docs1.xml
deleted file mode 100644
index 3c5448d..0000000
--- a/solr/solrj/src/test-files/docs1.xml
+++ /dev/null
@@ -1,56 +0,0 @@
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<add>
-<doc>
-  <field name="id">SP2514N</field>
-  <field name="name">Samsung SpinPoint P120 SP2514N - hard drive - 250 GB - ATA-133</field>
-  <field name="manu">Samsung Electronics Co. Ltd.</field>
-  <!-- Join -->
-  <field name="manu_id_s">samsung</field>
-  <field name="cat">electronics</field>
-  <field name="cat">hard drive</field>
-  <field name="features">7200RPM, 8MB cache, IDE Ultra ATA-133</field>
-  <field name="features">NoiseGuard, SilentSeek technology, Fluid Dynamic Bearing (FDB) motor</field>
-  <field name="price">92</field>
-  <field name="popularity">6</field>
-  <field name="inStock">true</field>
-  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
-  <!-- Near Oklahoma city -->
-  <field name="store">35.0752,-97.032</field>
-</doc>
-
-<doc>
-  <field name="id">6H500F0</field>
-  <field name="name">Maxtor DiamondMax 11 - hard drive - 500 GB - SATA-300</field>
-  <field name="manu">Maxtor Corp.</field>
-  <!-- Join -->
-  <field name="manu_id_s">maxtor</field>
-  <field name="cat">electronics</field>
-  <field name="cat">hard drive</field>
-  <field name="features">SATA 3.0Gb/s, NCQ</field>
-  <field name="features">8.5ms seek</field>
-  <field name="features">16MB cache</field>
-  <field name="price">350</field>
-  <field name="popularity">6</field>
-  <field name="inStock">true</field>
-  <!-- Buffalo store -->
-  <field name="store">45.17614,-93.87341</field>
-  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
-</doc>
-</add>
-
diff --git a/solr/solrj/src/test-files/docs2.xml b/solr/solrj/src/test-files/docs2.xml
deleted file mode 100644
index 0b89d67..0000000
--- a/solr/solrj/src/test-files/docs2.xml
+++ /dev/null
@@ -1,77 +0,0 @@
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<add>
-<doc>
-  <field name="id">TWINX2048-3200PRO</field>
-  <field name="name">CORSAIR  XMS 2GB (2 x 1GB) 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) Dual Channel Kit System Memory - Retail</field>
-  <field name="manu">Corsair Microsystems Inc.</field>
-  <!-- Join -->
-  <field name="manu_id_s">corsair</field>
-  <field name="cat">electronics</field>
-  <field name="cat">memory</field>
-  <field name="features">CAS latency 2,	2-3-3-6 timing, 2.75v, unbuffered, heat-spreader</field>
-  <field name="price">185</field>
-  <field name="popularity">5</field>
-  <field name="inStock">true</field>
-  <!-- San Francisco store -->
-  <field name="store">37.7752,-122.4232</field>
-  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
-
-  <!-- a field for testing payload tagged text via DelimitedPayloadTokenFilter -->
-  <field name="payloads">electronics|6.0 memory|3.0</field>
-</doc>
-
-<doc>
-  <field name="id">VS1GB400C3</field>
-  <field name="name">CORSAIR ValueSelect 1GB 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) System Memory - Retail</field>
-  <field name="manu">Corsair Microsystems Inc.</field>
-  <!-- Join -->
-  <field name="manu_id_s">corsair</field>
-  <field name="cat">electronics</field>
-  <field name="cat">memory</field>
-  <field name="price">74.99</field>
-  <field name="popularity">7</field>
-  <field name="inStock">true</field>
-  <!-- Dodge City store -->
-  <field name="store">37.7752,-100.0232</field>
-  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
-
-  <field name="payloads">electronics|4.0 memory|2.0</field>
-</doc>
-
-<doc>
-  <field name="id">VDBDB1A16</field>
-  <field name="name">A-DATA V-Series 1GB 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) System Memory - OEM</field>
-  <field name="manu">A-DATA Technology Inc.</field>
-  <!-- Join -->
-  <field name="manu_id_s">corsair</field>
-  <field name="cat">electronics</field>
-  <field name="cat">memory</field>
-  <field name="features">CAS latency 3,	 2.7v</field>
-  <!-- note: price & popularity is missing on this one -->
-  <field name="popularity">0</field>
-  <field name="inStock">true</field>
-  <!-- Buffalo store -->
-  <field name="store">45.18414,-93.88141</field>
-  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
-
-  <field name="payloads">electronics|0.9 memory|0.1</field>
-</doc>
-
-</add>
-
diff --git a/solr/solrj/src/test-files/sampleDateFacetResponse.xml b/solr/solrj/src/test-files/sampleDateFacetResponse.xml
deleted file mode 100644
index 12e32c2..0000000
--- a/solr/solrj/src/test-files/sampleDateFacetResponse.xml
+++ /dev/null
@@ -1,4 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<response>
-<lst name="responseHeader"><int name="status">0</int><int name="QTime">0</int><lst name="params"><str name="facet.date.start">NOW/DAY-5DAYS</str><str name="facet">true</str><str name="facet.date.hardend">true</str><str name="q">*:*</str><arr name="facet.date"><str>timestamp</str><str>timestamp2</str></arr><str name="facet.date.gap">+1DAY</str><str name="facet.date.other">ALL</str><str name="facet.date.end">NOW/DAY+1DAY</str><str name="rows">0</str></lst></lst><result name="response" numFound="16" start="0"/><lst name="facet_counts"><lst name="facet_queries"/><lst name="facet_fields"/><lst name="facet_dates"><lst name="timestamp"><int name="2008-03-06T00:00:00.000Z">0</int><int name="2008-03-07T00:00:00.000Z">0</int><int name="2008-03-08T00:00:00.000Z">0</int><int name="2008-03-09T00:00:00.000Z">0</int><int name="2008-03-10T00:00:00.000Z">0</int><int name="2008-03-11T00:00:00.000Z">0</int><str name="gap">+1DAY</str><date name="end">2008-03-12T00:00:00Z</date><int name="before">16</int><int name="after">0</int><int name="between">0</int></lst><lst name="timestamp2"><int name="2008-03-06T00:00:00.000Z">0</int><int name="2008-03-07T00:00:00.000Z">0</int><int name="2008-03-08T00:00:00.000Z">0</int><int name="2008-03-09T00:00:00.000Z">0</int><int name="2008-03-10T00:00:00.000Z">0</int><int name="2008-03-11T00:00:00.000Z">0</int><str name="gap">+1DAY</str><date name="end">2008-03-12T00:00:00Z</date><int name="before">0</int><int name="after">0</int><int name="between">0</int></lst></lst></lst>
-</response>
diff --git a/solr/solrj/src/test-files/solr/conf/schema-replication1.xml b/solr/solrj/src/test-files/solr/conf/schema-replication1.xml
deleted file mode 100644
index 48ecd9f..0000000
--- a/solr/solrj/src/test-files/solr/conf/schema-replication1.xml
+++ /dev/null
@@ -1,49 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- The Solr schema file. This file should be named "schema.xml" and
-     should be located where the classloader for the Solr webapp can find it.
-
-     This schema is used for testing, and as such has everything and the 
-     kitchen sink thrown in. See example/solr/conf/schema.xml for a 
-     more concise example.
-
-     $Id$
-     $Source$
-     $Name$
-  -->
-
-<schema name="test" version="1.2">
-  <types>
-
-    <fieldType name="integer" class="solr.IntField"/>
-    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
-
-
-  </types>
-
-
-  <fields>
-    <field name="id" type="integer" indexed="true" stored="true" multiValued="false" required="false"/>
-    <field name="name" type="string" indexed="true" stored="true"/>
-
-  </fields>
-
-  <uniqueKey>id</uniqueKey>
-
-</schema>
diff --git a/solr/solrj/src/test-files/solr/conf/schema.xml b/solr/solrj/src/test-files/solr/conf/schema.xml
deleted file mode 100644
index f0fa272..0000000
--- a/solr/solrj/src/test-files/solr/conf/schema.xml
+++ /dev/null
@@ -1,657 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- The Solr schema file. This file should be named "schema.xml" and
-     should be located where the classloader for the Solr webapp can find it.
-
-     This schema is used for testing, and as such has everything and the
-     kitchen sink thrown in. See example/solr/conf/schema.xml for a
-     more concise example.
-
-     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
-     $Name:  $
-  -->
-
-<schema name="test" version="1.0">
-  <types>
-
-    <!-- field type definitions... note that the "name" attribute is
-         just a label to be used by field definitions.  The "class"
-         attribute and any other attributes determine the real type and
-         behavior of the fieldtype.
-      -->
-
-    <!-- numeric field types that store and index the text
-         value verbatim (and hence don't sort correctly or support range queries.)
-         These are provided more for backward compatability, allowing one
-         to create a schema that matches an existing lucene index.
-    -->
-    <fieldType name="pint" class="solr.IntField"/>
-    <fieldType name="plong" class="solr.LongField"/>
-    <fieldtype name="pfloat" class="solr.FloatField"/>
-    <fieldType name="pdouble" class="solr.DoubleField"/>
-
-    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="float" class="solr.TrieFloatField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="long" class="solr.TrieLongField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="double" class="solr.TrieDoubleField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
-
-    <fieldType name="tint" class="solr.TrieIntField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="tfloat" class="solr.TrieFloatField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="tlong" class="solr.TrieLongField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
-    <fieldType name="tdouble" class="solr.TrieDoubleField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
-
-    <!-- numeric field types that manipulate the value into
-       a string value that isn't human readable in it's internal form,
-       but sorts correctly and supports range queries.
-
-         If sortMissingLast="true" then a sort on this field will cause documents
-       without the field to come after documents with the field,
-       regardless of the requested sort order.
-         If sortMissingFirst="true" then a sort on this field will cause documents
-       without the field to come before documents with the field,
-       regardless of the requested sort order.
-         If sortMissingLast="false" and sortMissingFirst="false" (the default),
-       then default lucene sorting will be used which places docs without the field
-       first in an ascending sort and last in a descending sort.
-    -->
-    <fieldtype name="sint" class="solr.SortableIntField" sortMissingLast="true"/>
-    <fieldtype name="slong" class="solr.SortableLongField" sortMissingLast="true"/>
-    <fieldtype name="sfloat" class="solr.SortableFloatField" sortMissingLast="true"/>
-    <fieldtype name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true"/>
-
-    <!-- bcd versions of sortable numeric type may provide smaller
-         storage space and support very large numbers.
-    -->
-    <fieldtype name="bcdint" class="solr.BCDIntField" sortMissingLast="true"/>
-    <fieldtype name="bcdlong" class="solr.BCDLongField" sortMissingLast="true"/>
-    <fieldtype name="bcdstr" class="solr.BCDStrField" sortMissingLast="true"/>
-
-    <!-- Field type demonstrating an Analyzer failure -->
-    <fieldtype name="failtype1" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- Demonstrating ignoreCaseChange -->
-    <fieldtype name="wdf_nocase" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-     <fieldtype name="wdf_preserve" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="1"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-
-    <!-- HighlitText optimizes storage for (long) columns which will be highlit -->
-    <fieldtype name="highlittext" class="solr.TextField" compressThreshold="345" />
-
-    <fieldtype name="boolean" class="solr.BoolField" sortMissingLast="true"/>
-    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
-
-    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
-         seconds part (.999) is optional.
-      -->
-    <fieldtype name="date" class="solr.TrieDateField" precisionStep="0"/>
-    <fieldtype name="tdate" class="solr.TrieDateField" precisionStep="6"/>
-    <fieldtype name="pdate" class="solr.DateField" sortMissingLast="true"/>
-
-
-    <!-- solr.TextField allows the specification of custom
-         text analyzers specified as a tokenizer and a list
-         of token filters.
-      -->
-    <fieldtype name="text" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.StopFilterFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-
-    <fieldtype name="nametext" class="solr.TextField">
-      <analyzer class="org.apache.lucene.analysis.core.WhitespaceAnalyzer"/>
-    </fieldtype>
-
-    <fieldtype name="teststop" class="solr.TextField">
-       <analyzer>
-        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- fieldtypes in this section isolate tokenizers and tokenfilters for testing -->
-    <fieldtype name="lowertok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.LowerCaseTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="keywordtok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.KeywordTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="standardtok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.StandardTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="lettertok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.LetterTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="whitetok" class="solr.TextField">
-      <analyzer><tokenizer class="solr.WhitespaceTokenizerFactory"/></analyzer>
-    </fieldtype>
-    <fieldtype name="HTMLstandardtok" class="solr.TextField">
-      <analyzer>
-      <charFilter class="solr.HTMLStripCharFilterFactory"/>
-      <tokenizer class="solr.StandardTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="HTMLwhitetok" class="solr.TextField">
-      <analyzer>
-      <charFilter class="solr.HTMLStripCharFilterFactory"/>
-      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="standardtokfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StandardFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="standardfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.StandardFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="lowerfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="lowerpunctfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter name="syn" class="solr.SynonymFilterFactory" synonyms="synonyms.txt" expand="true"/>
-        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="1" splitOnCaseChange="1"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="patternreplacefilt" class="solr.TextField">
-      <analyzer type="index">
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-        <filter class="solr.PatternReplaceFilterFactory"
-                pattern="([^a-zA-Z])" replacement="_" replace="all"
-        />
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.KeywordTokenizerFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="patterntok" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.PatternTokenizerFactory" pattern=","/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="porterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <!-- fieldtype name="snowballfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.SnowballPorterFilterFactory"/>
-      </analyzer>
-    </fieldtype -->
-    <fieldtype name="engporterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="custengporterfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="stopfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="custstopfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
-      </analyzer>
-    </fieldtype>
-    <fieldtype name="lengthfilt" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-        <filter class="solr.LengthFilterFactory" min="2" max="5"/>
-      </analyzer>
-    </fieldtype>
-    <fieldType name="charfilthtmlmap" class="solr.TextField">
-      <analyzer>
-        <charFilter class="solr.HTMLStripCharFilterFactory"/>
-        <charFilter class="solr.MappingCharFilterFactory" mapping="mapping-ISOLatin1Accent.txt"/>
-        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-      </analyzer>
-    </fieldType>
-
-    <fieldtype name="subword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype name="numericsubword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.StopFilterFactory"/>
-          <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype name="protectedsubword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-
-    <!-- more flexible in matching skus, but more chance of a false match -->
-    <fieldtype name="skutype1" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- less flexible in matching skus, but less chance of a false match -->
-    <fieldtype name="skutype2" class="solr.TextField">
-      <analyzer type="index">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- less flexible in matching skus, but less chance of a false match -->
-    <fieldtype name="syn" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter name="syn" class="solr.SynonymFilterFactory" synonyms="old_synonyms.txt"/>
-      </analyzer>
-    </fieldtype>
-
-    <!-- Demonstrates How RemoveDuplicatesTokenFilter makes stemmed
-         synonyms "better"
-      -->
-    <fieldtype name="dedup" class="solr.TextField">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.SynonymFilterFactory"
-                  synonyms="old_synonyms.txt" expand="true" />
-          <filter class="solr.PorterStemFilterFactory"/>
-          <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
-      </analyzer>
-    </fieldtype>
-
-    <fieldtype  name="unstored" class="solr.StrField" indexed="true" stored="false"/>
-
-
-  <fieldtype name="textgap" class="solr.TextField" multiValued="true" positionIncrementGap="100">
-      <analyzer>
-          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-          <filter class="solr.LowerCaseFilterFactory"/>
-      </analyzer>
-  </fieldtype>
-
-  <fieldType name="uuid" class="solr.UUIDField" />
-
-    <!-- Try out some point types -->
-  <fieldType name="xy" class="solr.PointType" dimension="2" subFieldType="double"/>
-  <fieldType name="x" class="solr.PointType" dimension="1" subFieldType="double"/>
-  <fieldType name="tenD" class="solr.PointType" dimension="10" subFieldType="double"/>
-    <!-- Use the sub field suffix -->
-  <fieldType name="xyd" class="solr.PointType" dimension="2" subFieldSuffix="_d1"/>
-    <fieldtype name="geohash" class="solr.GeoHashField"/>
-
-
-  <fieldType name="latLon" class="solr.LatLonType" subFieldType="double"/>
-
-  <!--  some per-field similarity examples -->
-  
-  <!--  specify a Similarity classname directly -->
-  <fieldType name="sim1" class="solr.TextField">
-    <analyzer>
-      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-    </analyzer>
-    <similarity class="org.apache.lucene.misc.SweetSpotSimilarity"/>
-  </fieldType>
-
-  <!--  specify a Similarity factory -->  
-  <fieldType name="sim2" class="solr.TextField">
-    <analyzer>
-      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-    </analyzer>
-    <similarity class="org.apache.solr.schema.CustomSimilarityFactory">
-      <str name="echo">is there an echo?</str>
-    </similarity>
-  </fieldType>
-  
-  <!-- don't specify any sim at all: get the default  -->
-  <fieldType name="sim3" class="solr.TextField">
-    <analyzer>
-      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
-    </analyzer>
-  </fieldType>
- </types>
-
-
- <fields>
-   <field name="id" type="int" indexed="true" stored="true" multiValued="false" required="false"/>
-   <field name="signatureField" type="string" indexed="true" stored="false"/>
-   <field name="uuid" type="uuid" stored="true" />
-   <field name="name" type="nametext" indexed="true" stored="true"/>
-   <field name="text" type="text" indexed="true" stored="false"/>
-   <field name="subject" type="text" indexed="true" stored="true"/>
-   <field name="title" type="nametext" indexed="true" stored="true"/>
-   <field name="weight" type="float" indexed="true" stored="true" multiValued="false"/>
-   <field name="bday" type="date" indexed="true" stored="true" multiValued="false"/>
-
-   <field name="title_stemmed" type="text" indexed="true" stored="false"/>
-   <field name="title_lettertok" type="lettertok" indexed="true" stored="false"/>
-
-   <field name="syn" type="syn" indexed="true" stored="true"/>
-
-   <!-- to test property inheritance and overriding -->
-   <field name="shouldbeunstored" type="unstored" />
-   <field name="shouldbestored" type="unstored" stored="true"/>
-   <field name="shouldbeunindexed" type="unstored" indexed="false" stored="true"/>
-
-   <!-- Test points -->
-      <!-- Test points -->
-   <field name="home" type="xy" indexed="true" stored="true" multiValued="false"/>
-   <field name="x" type="x" indexed="true" stored="true" multiValued="false"/>
-   <field name="homed" type="xyd" indexed="true" stored="true" multiValued="false"/>
-   <field name="home_ns" type="xy" indexed="true" stored="false" multiValued="false"/>
-   <field name="work" type="xy" indexed="true" stored="true" multiValued="false"/>
-
-   <field name="home_ll" type="latLon" indexed="true" stored="true" multiValued="false"/>
-   <field name="home_gh" type="geohash" indexed="true" stored="true" multiValued="false"/>
-
-
-   <field name="point10" type="tenD" indexed="true" stored="true" multiValued="false"/>
-
-
-   <!-- test different combinations of indexed and stored -->
-   <field name="bind" type="boolean" indexed="true" stored="false"/>
-   <field name="bsto" type="boolean" indexed="false" stored="true"/>
-   <field name="bindsto" type="boolean" indexed="true" stored="true"/>
-   <field name="isto" type="int" indexed="false" stored="true"/>
-   <field name="iind" type="int" indexed="true" stored="false"/>
-   <field name="ssto" type="string" indexed="false" stored="true"/>
-   <field name="sind" type="string" indexed="true" stored="false"/>
-   <field name="sindsto" type="string" indexed="true" stored="true"/>
-
-   <!-- test combinations of term vector settings -->
-   <field name="test_basictv" type="text" termVectors="true"/>
-   <field name="test_notv" type="text" termVectors="false"/>
-   <field name="test_postv" type="text" termVectors="true" termPositions="true"/>
-   <field name="test_offtv" type="text" termVectors="true" termOffsets="true"/>
-   <field name="test_posofftv" type="text" termVectors="true"
-     termPositions="true" termOffsets="true"/>
-
-   <!-- test highlit field settings -->
-   <field name="test_hlt" type="highlittext" indexed="true" compressed="true"/>
-   <field name="test_hlt_off" type="highlittext" indexed="true" compressed="false"/>
-
-   <!-- fields to test individual tokenizers and tokenfilters -->
-   <field name="teststop" type="teststop" indexed="true" stored="true"/>
-   <field name="lowertok" type="lowertok" indexed="true" stored="true"/>
-   <field name="keywordtok" type="keywordtok" indexed="true" stored="true"/>
-   <field name="standardtok" type="standardtok" indexed="true" stored="true"/>
-   <field name="HTMLstandardtok" type="HTMLstandardtok" indexed="true" stored="true"/>
-   <field name="lettertok" type="lettertok" indexed="true" stored="true"/>
-   <field name="whitetok" type="whitetok" indexed="true" stored="true"/>
-   <field name="HTMLwhitetok" type="HTMLwhitetok" indexed="true" stored="true"/>
-   <field name="standardtokfilt" type="standardtokfilt" indexed="true" stored="true"/>
-   <field name="standardfilt" type="standardfilt" indexed="true" stored="true"/>
-   <field name="lowerfilt" type="lowerfilt" indexed="true" stored="true"/>
-   <field name="lowerfilt1" type="lowerfilt" indexed="true" stored="true"/>
-	 <field name="lowerfilt1and2" type="lowerfilt" indexed="true" stored="true"/>
-   <field name="patterntok" type="patterntok" indexed="true" stored="true"/>
-   <field name="patternreplacefilt" type="patternreplacefilt" indexed="true" stored="true"/>
-   <field name="porterfilt" type="porterfilt" indexed="true" stored="true"/>
-   <field name="engporterfilt" type="engporterfilt" indexed="true" stored="true"/>
-   <field name="custengporterfilt" type="custengporterfilt" indexed="true" stored="true"/>
-   <field name="stopfilt" type="stopfilt" indexed="true" stored="true"/>
-   <field name="custstopfilt" type="custstopfilt" indexed="true" stored="true"/>
-   <field name="lengthfilt" type="lengthfilt" indexed="true" stored="true"/>
-   <field name="dedup" type="dedup" indexed="true" stored="true"/>
-   <field name="wdf_nocase" type="wdf_nocase" indexed="true" stored="true"/>
-   <field name="wdf_preserve" type="wdf_preserve" indexed="true" stored="true"/>
-
-   <field name="numberpartfail" type="failtype1" indexed="true" stored="true"/>
-
-   <field name="nullfirst" type="string" indexed="true" stored="true" sortMissingFirst="true" multiValued="false"/>
-
-   <field name="subword" type="subword" indexed="true" stored="true"/>
-   <field name="subword_offsets" type="subword" indexed="true" stored="true" termOffsets="true"/>
-   <field name="numericsubword" type="numericsubword" indexed="true" stored="true"/>
-   <field name="protectedsubword" type="protectedsubword" indexed="true" stored="true"/>
-
-   <field name="sku1" type="skutype1" indexed="true" stored="true"/>
-   <field name="sku2" type="skutype2" indexed="true" stored="true"/>
-
-   <field name="textgap" type="textgap" indexed="true" stored="true"/>
-
-   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
-   <field name="multiDefault" type="string" indexed="true" stored="true" default="muLti-Default" multiValued="true"/>
-   <field name="intDefault" type="int" indexed="true" stored="true" default="42" multiValued="false"/>
-
-   <field name="sim1text" type="sim1" indexed="true" stored="true"/>
-   <field name="sim2text" type="sim2" indexed="true" stored="true"/>
-   <field name="sim3text" type="sim3" indexed="true" stored="true"/>
-
-   <field name="tlong" type="tlong" indexed="true" stored="true" />
-
-   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
-        will be used if the name matches any of the patterns.
-        RESTRICTION: the glob-like pattern in the name attribute must have
-        a "*" only at the start or the end.
-        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
-        Longer patterns will be matched first.  if equal size patterns
-        both match, the first appearing in the schema will be used.
-   -->
-   <dynamicField name="*_i"  type="int"    indexed="true"  stored="true"/>
-   <dynamicField name="*_i1"  type="int"    indexed="true" stored="true" multiValued="false"/>
-                 
-   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
-   <dynamicField name="*_s1"  type="string"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_l"  type="long"   indexed="true"  stored="true"/>
-   <dynamicField name="*_l1"  type="long"   indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
-   <dynamicField name="*_f"  type="float"  indexed="true"  stored="true"/>
-   <dynamicField name="*_f1"  type="float"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_d"  type="double" indexed="true"  stored="true"/>
-   <dynamicField name="*_d1"  type="double" indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
-   <dynamicField name="*_dt1" type="date"    indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_bcd" type="bcdstr" indexed="true"  stored="true"/>
-
-      <!-- some trie-coded dynamic fields for faster range queries -->
-   <dynamicField name="*_ti" type="tint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_ti1" type="tint"    indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_tl" type="tlong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_tl1" type="tlong"   indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_tf" type="tfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_tf1" type="tfloat"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_td" type="tdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_td1" type="tdouble" indexed="true" stored="true" multiValued="false"/>
-   <dynamicField name="*_tds" type="tdouble" indexed="true" stored="true" multiValued="false"/>
-   <dynamicField name="*_tdt" type="tdate"  indexed="true"  stored="true"/>
-   <dynamicField name="*_tdt1" type="tdate"  indexed="true"  stored="true" multiValued="false"/>
-
-   <dynamicField name="*_si"  type="sint"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_sl"  type="slong"  indexed="true"  stored="true"/>
-   <dynamicField name="*_sf"  type="sfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_sf1"  type="sfloat"  indexed="true"  stored="true" multiValued="false"/>
-   <dynamicField name="*_sd"  type="sdouble"  indexed="true"  stored="true"/>
-   <dynamicField name="*_sd1"  type="sdouble"  indexed="true"  stored="true" multiValued="false"/>
-
-   <dynamicField name="*_pi"  type="pint"    indexed="true"  stored="true"/>
-   <dynamicField name="*_pf"  type="pfloat"  indexed="true"  stored="true"/>
-   <dynamicField name="*_pl"  type="plong"   indexed="true"  stored="true"/>
-   <dynamicField name="*_pd"  type="pdouble" indexed="true"  stored="true"/>
-   <dynamicField name="*_pdt"  type="pdate" indexed="true"  stored="true"/>
-
-
-   <dynamicField name="*_sI" type="string"  indexed="true"  stored="false"/>
-   <dynamicField name="*_sS" type="string"  indexed="false" stored="true"/>
-   <dynamicField name="t_*"  type="text"    indexed="true"  stored="true"/>
-   <dynamicField name="tv_*"  type="text" indexed="true"  stored="true"
-      termVectors="true" termPositions="true" termOffsets="true"/>
-   <dynamicField name="tv_mv_*"  type="text" indexed="true"  stored="true" multiValued="true"
-      termVectors="true" termPositions="true" termOffsets="true"/>
-
-   <dynamicField name="*_p"  type="xyd" indexed="true"  stored="true" multiValued="false"/>
-
-   <!-- special fields for dynamic copyField test -->
-   <dynamicField name="dynamic_*" type="string" indexed="true" stored="true"/>
-   <dynamicField name="*_dynamic" type="string" indexed="true" stored="true"/>
-
-   <!-- for testing to ensure that longer patterns are matched first -->
-   <dynamicField name="*aa"  type="string"  indexed="true" stored="true"/>
-   <dynamicField name="*aaa" type="pint" indexed="false" stored="true"/>
-
-   <!-- ignored becuase not stored or indexed -->
-   <dynamicField name="*_ignored" type="text" indexed="false" stored="false"/>
-
-   <dynamicField name="*_mfacet" type="string" indexed="true" stored="false" multiValued="true" />
-
-   <!-- make sure custom sims work with dynamic fields -->
-   <dynamicField name="*_sim1" type="sim1" indexed="true" stored="true"/>
-   <dynamicField name="*_sim2" type="sim2" indexed="true" stored="true"/>
-   <dynamicField name="*_sim3" type="sim3" indexed="true" stored="true"/>
- </fields>
-
- <defaultSearchField>text</defaultSearchField>
- <uniqueKey>id</uniqueKey>
-
-  <!-- copyField commands copy one field to another at the time a document
-        is added to the index.  It's used either to index the same field different
-        ways, or to add multiple fields to the same field for easier/faster searching.
-   -->
-   <copyField source="title" dest="title_stemmed"/>
-   <copyField source="title" dest="title_lettertok"/>
-
-   <copyField source="title" dest="text"/>
-	 <copyField source="subject" dest="text"/>
-
-	 <copyField source="lowerfilt1" dest="lowerfilt1and2"/>
-	 <copyField source="lowerfilt" dest="lowerfilt1and2"/>
-
-	 <copyField source="*_t" dest="text"/>
-
-	 <copyField source="id"            dest="range_facet_si"/>
-	 <copyField source="id"            dest="range_facet_l"/>
-	 <copyField source="id"            dest="range_facet_sl"/>
-	 <copyField source="range_facet_f" dest="range_facet_sf"/>
-	 <copyField source="range_facet_f" dest="range_facet_d"/>
-	 <copyField source="range_facet_f" dest="range_facet_sd"/>
-
-	 <copyField source="bday" dest="bday_pdt"/>
-	 <copyField source="a_tdt" dest="a_pdt"/>
-
-   <!-- dynamic destination -->
-   <copyField source="*_dynamic" dest="dynamic_*"/>
-
- <!-- expert: SimilarityProvider contains scoring routines that are not field-specific,
-      such as coord() and queryNorm(). most scoring customization happens in the fieldtype.
-      A custom similarity provider may be specified here, but the default is fine
-      for most applications.
- -->
- <similarityProvider class="org.apache.solr.schema.CustomSimilarityProviderFactory">
-   <str name="echo">is there an echo?</str>
- </similarityProvider>
-
- <!-- default similarity, unless otherwise specified by the fieldType
-  -->
- <similarity class="org.apache.solr.schema.CustomSimilarityFactory">
-   <str name="echo">I am your default sim</str>
- </similarity>
-</schema>
diff --git a/solr/solrj/src/test-files/solr/conf/solrconfig-slave1.xml b/solr/solrj/src/test-files/solr/conf/solrconfig-slave1.xml
deleted file mode 100644
index 46c1cb4..0000000
--- a/solr/solrj/src/test-files/solr/conf/solrconfig-slave1.xml
+++ /dev/null
@@ -1,88 +0,0 @@
-<?xml version="1.0" ?>
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!-- $Id$
-     $Source$
-     $Name$
-  -->
-
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-  <dataDir>${solr.data.dir:}</dataDir>
-
-  <indexDefaults>
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <writeLockTimeout>1000</writeLockTimeout>
-    <commitLockTimeout>10000</commitLockTimeout>
-
-    <lockType>single</lockType>
-  </indexDefaults>
-
-  <mainIndex>
-    <useCompoundFile>false</useCompoundFile>
-    <mergeFactor>10</mergeFactor>
-    <ramBufferSizeMB>32</ramBufferSizeMB>
-    <maxMergeDocs>2147483647</maxMergeDocs>
-    <maxFieldLength>10000</maxFieldLength>
-
-    <unlockOnStartup>true</unlockOnStartup>
-  </mainIndex>
-
-  <updateHandler class="solr.DirectUpdateHandler2">
-  </updateHandler>
-
-  <requestHandler name="standard" class="solr.StandardRequestHandler">
-    <bool name="httpCaching">true</bool>
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="defaults" class="solr.StandardRequestHandler">
-
-  </requestHandler>
-
-  <!-- test query parameter defaults -->
-  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
-  </requestHandler>
-
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler"/>
-
-
-  <requestHandler name="/update/javabin" class="solr.BinaryUpdateRequestHandler"/>
-
-  <requestHandler name="/replication" class="solr.ReplicationHandler">
-
-  </requestHandler>
-
-
-  <!-- enable streaming for testing... -->
-  <requestDispatcher handleSelect="true">
-    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048"/>
-    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
-      <cacheControl>max-age=30, public</cacheControl>
-    </httpCaching>
-  </requestDispatcher>
-
-</config>
diff --git a/solr/solrj/src/test-files/solr/crazy-path-to-schema.xml b/solr/solrj/src/test-files/solr/crazy-path-to-schema.xml
deleted file mode 100644
index b71c9f4..0000000
--- a/solr/solrj/src/test-files/solr/crazy-path-to-schema.xml
+++ /dev/null
@@ -1,48 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<!--
-     Striped down schema used by SampleTest to demonstrate picking any
-     schema filename you want.
-
-     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
-     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
-  -->
-
-<schema name="test" version="1.0">
-  <types>
-    <fieldtype name="sint" class="solr.SortableIntField" />
-    <fieldtype name="text" class="solr.TextField">
-      <analyzer>
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.LowerCaseFilterFactory"/>
-        <filter class="solr.StopFilterFactory"/>
-        <filter class="solr.PorterStemFilterFactory"/>
-      </analyzer>
-    </fieldtype>
- </types>
-
-
- <fields>
-   <field name="id" type="sint" indexed="true" stored="true" multiValued="false"/>
-   <field name="subject" type="text" indexed="true" stored="true"/>
- </fields>
-
- <defaultSearchField>subject</defaultSearchField>
- <uniqueKey>id</uniqueKey>
-</schema>
diff --git a/solr/solrj/src/test-files/solr/shared/conf/schema.xml b/solr/solrj/src/test-files/solr/shared/conf/schema.xml
deleted file mode 100644
index da37f27..0000000
--- a/solr/solrj/src/test-files/solr/shared/conf/schema.xml
+++ /dev/null
@@ -1,69 +0,0 @@
-<?xml version="1.0" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<schema name="example core ${l10n}" version="1.1">
-  <types>
-    <fieldtype name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
-    <fieldType name="text-FR" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-fr.txt"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-fr.txt"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-    <fieldType name="text-EN" class="solr.TextField" positionIncrementGap="100">
-      <analyzer type="index">
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-en.txt"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-      <analyzer type="query">
-        <tokenizer class="solr.StandardTokenizerFactory"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-en.txt"/>
-        <filter class="solr.StandardFilterFactory"/>
-        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
-      </analyzer>
-    </fieldType>
-  </types>
-
-  <fields>
-    <!-- general -->
-    <field name="id" type="string" indexed="true" stored="true" multiValued="false" required="true"/>
-    <field name="type" type="string" indexed="true" stored="true" multiValued="false"/>
-    <field name="name" type="string" indexed="true" stored="true" multiValued="false"/>
-    <field name="${ctlField}" type="text-${l10n}" indexed="true" stored="true" multiValued="true"/>
-  </fields>
-
-  <!-- field to use to determine and enforce document uniqueness. -->
-  <uniqueKey>id</uniqueKey>
-
-  <!-- field for the QueryParser to use when an explicit fieldname is absent -->
-  <defaultSearchField>name</defaultSearchField>
-
-  <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
-  <solrQueryParser defaultOperator="OR"/>
-</schema>
-
diff --git a/solr/solrj/src/test-files/solr/shared/conf/solrconfig.xml b/solr/solrj/src/test-files/solr/shared/conf/solrconfig.xml
deleted file mode 100644
index 031fbb0..0000000
--- a/solr/solrj/src/test-files/solr/shared/conf/solrconfig.xml
+++ /dev/null
@@ -1,44 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--
- This is a stripped down config file used for a simple example...  
- It is *not* a good example to work from. 
--->
-<config>
-  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
-  <dataDir>${solr.solr.home}/data/${l10n}-${version}</dataDir>
-
-
-  <updateHandler class="solr.DirectUpdateHandler2" />
-
-  <requestDispatcher handleSelect="true" >
-    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
-  </requestDispatcher>
-  
-  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true" />
-  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />
-  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
-      
-  <!-- config for the admin interface --> 
-  <admin>
-    <defaultQuery>solr</defaultQuery>
-  </admin>
-
-</config>
-
diff --git a/solr/solrj/src/test-files/solr/shared/conf/stopwords-en.txt b/solr/solrj/src/test-files/solr/shared/conf/stopwords-en.txt
deleted file mode 100644
index 273cd77..0000000
--- a/solr/solrj/src/test-files/solr/shared/conf/stopwords-en.txt
+++ /dev/null
@@ -1,16 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-stopena
-stopenb
diff --git a/solr/solrj/src/test-files/solr/shared/conf/stopwords-fr.txt b/solr/solrj/src/test-files/solr/shared/conf/stopwords-fr.txt
deleted file mode 100644
index f9a2036..0000000
--- a/solr/solrj/src/test-files/solr/shared/conf/stopwords-fr.txt
+++ /dev/null
@@ -1,16 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-stopfra
-stopfrb
diff --git a/solr/solrj/src/test-files/solr/shared/solr.xml b/solr/solrj/src/test-files/solr/shared/solr.xml
deleted file mode 100644
index d8a5b05..0000000
--- a/solr/solrj/src/test-files/solr/shared/solr.xml
+++ /dev/null
@@ -1,47 +0,0 @@
-<?xml version="1.0" encoding="UTF-8" ?>
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-<!--
- All (relative) paths are relative to the installation path
-  
-  persistent: Save changes made via the API to this file
-  sharedLib: path to a lib directory that will be shared across all cores
--->
-<solr persistent="true">
-  <property name="version" value="1.3"/>
-  <property name="lang" value="english, french"/>
-
-  <!--
-  adminPath: RequestHandler path to manage cores.  
-    If 'null' (or absent), cores will not be manageable via REST
-  -->
-  <cores adminPath="/admin/cores" defaultCoreName="core0" host="127.0.0.1" hostPort="${hostPort:8983}" hostContext="solr" zkClientTimeout="8000">
-    <core name="core0" instanceDir="./">
-      <property name="version" value="3.5"/>
-      <property name="l10n" value="EN"/>
-      <property name="ctlField" value="core0"/>
-      <property name="comment" value="This is a sample"/>
-    </core>
-    <core name="core1" instanceDir="./">
-      <property name="version" value="2.4"/>
-      <property name="l10n" value="FR"/>
-      <property name="ctlField" value="core1"/>
-      <property name="comment" value="Ceci est un exemple"/>
-    </core>
-  </cores>
-</solr>
diff --git a/solr/solrj/src/test-files/solrj/README b/solr/solrj/src/test-files/solrj/README
new file mode 100644
index 0000000..10f878a
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/README
@@ -0,0 +1,21 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+This directory is where any non-transient, non-java files needed
+for the execution of tests should live.
+
+It is used as the CWD when running JUnit tests.
diff --git a/solr/solrj/src/test-files/solrj/books.csv b/solr/solrj/src/test-files/solrj/books.csv
new file mode 100644
index 0000000..36b20f5
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/books.csv
@@ -0,0 +1,11 @@
+id,cat,name,price,inStock,author_t,series_t,sequence_i,genre_s
+0553573403,book,A Game of Thrones,7.99,true,George R.R. Martin,"A Song of Ice and Fire",1,fantasy
+0553579908,book,A Clash of Kings,7.99,true,George R.R. Martin,"A Song of Ice and Fire",2,fantasy
+055357342X,book,A Storm of Swords,7.99,true,George R.R. Martin,"A Song of Ice and Fire",3,fantasy
+0553293354,book,Foundation,7.99,true,Isaac Asimov,Foundation Novels,1,scifi
+0812521390,book,The Black Company,6.99,false,Glen Cook,The Chronicles of The Black Company,1,fantasy
+0812550706,book,Ender's Game,6.99,true,Orson Scott Card,Ender,1,scifi
+0441385532,book,Jhereg,7.95,false,Steven Brust,Vlad Taltos,1,fantasy
+0380014300,book,Nine Princes In Amber,6.99,true,Roger Zelazny,the Chronicles of Amber,1,fantasy
+0805080481,book,The Book of Three,5.99,true,Lloyd Alexander,The Chronicles of Prydain,1,fantasy
+080508049X,book,The Black Cauldron,5.99,true,Lloyd Alexander,The Chronicles of Prydain,2,fantasy
diff --git a/solr/solrj/src/test-files/solrj/docs1.xml b/solr/solrj/src/test-files/solrj/docs1.xml
new file mode 100644
index 0000000..3c5448d
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/docs1.xml
@@ -0,0 +1,56 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<add>
+<doc>
+  <field name="id">SP2514N</field>
+  <field name="name">Samsung SpinPoint P120 SP2514N - hard drive - 250 GB - ATA-133</field>
+  <field name="manu">Samsung Electronics Co. Ltd.</field>
+  <!-- Join -->
+  <field name="manu_id_s">samsung</field>
+  <field name="cat">electronics</field>
+  <field name="cat">hard drive</field>
+  <field name="features">7200RPM, 8MB cache, IDE Ultra ATA-133</field>
+  <field name="features">NoiseGuard, SilentSeek technology, Fluid Dynamic Bearing (FDB) motor</field>
+  <field name="price">92</field>
+  <field name="popularity">6</field>
+  <field name="inStock">true</field>
+  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
+  <!-- Near Oklahoma city -->
+  <field name="store">35.0752,-97.032</field>
+</doc>
+
+<doc>
+  <field name="id">6H500F0</field>
+  <field name="name">Maxtor DiamondMax 11 - hard drive - 500 GB - SATA-300</field>
+  <field name="manu">Maxtor Corp.</field>
+  <!-- Join -->
+  <field name="manu_id_s">maxtor</field>
+  <field name="cat">electronics</field>
+  <field name="cat">hard drive</field>
+  <field name="features">SATA 3.0Gb/s, NCQ</field>
+  <field name="features">8.5ms seek</field>
+  <field name="features">16MB cache</field>
+  <field name="price">350</field>
+  <field name="popularity">6</field>
+  <field name="inStock">true</field>
+  <!-- Buffalo store -->
+  <field name="store">45.17614,-93.87341</field>
+  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
+</doc>
+</add>
+
diff --git a/solr/solrj/src/test-files/solrj/docs2.xml b/solr/solrj/src/test-files/solrj/docs2.xml
new file mode 100644
index 0000000..0b89d67
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/docs2.xml
@@ -0,0 +1,77 @@
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<add>
+<doc>
+  <field name="id">TWINX2048-3200PRO</field>
+  <field name="name">CORSAIR  XMS 2GB (2 x 1GB) 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) Dual Channel Kit System Memory - Retail</field>
+  <field name="manu">Corsair Microsystems Inc.</field>
+  <!-- Join -->
+  <field name="manu_id_s">corsair</field>
+  <field name="cat">electronics</field>
+  <field name="cat">memory</field>
+  <field name="features">CAS latency 2,	2-3-3-6 timing, 2.75v, unbuffered, heat-spreader</field>
+  <field name="price">185</field>
+  <field name="popularity">5</field>
+  <field name="inStock">true</field>
+  <!-- San Francisco store -->
+  <field name="store">37.7752,-122.4232</field>
+  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
+
+  <!-- a field for testing payload tagged text via DelimitedPayloadTokenFilter -->
+  <field name="payloads">electronics|6.0 memory|3.0</field>
+</doc>
+
+<doc>
+  <field name="id">VS1GB400C3</field>
+  <field name="name">CORSAIR ValueSelect 1GB 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) System Memory - Retail</field>
+  <field name="manu">Corsair Microsystems Inc.</field>
+  <!-- Join -->
+  <field name="manu_id_s">corsair</field>
+  <field name="cat">electronics</field>
+  <field name="cat">memory</field>
+  <field name="price">74.99</field>
+  <field name="popularity">7</field>
+  <field name="inStock">true</field>
+  <!-- Dodge City store -->
+  <field name="store">37.7752,-100.0232</field>
+  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
+
+  <field name="payloads">electronics|4.0 memory|2.0</field>
+</doc>
+
+<doc>
+  <field name="id">VDBDB1A16</field>
+  <field name="name">A-DATA V-Series 1GB 184-Pin DDR SDRAM Unbuffered DDR 400 (PC 3200) System Memory - OEM</field>
+  <field name="manu">A-DATA Technology Inc.</field>
+  <!-- Join -->
+  <field name="manu_id_s">corsair</field>
+  <field name="cat">electronics</field>
+  <field name="cat">memory</field>
+  <field name="features">CAS latency 3,	 2.7v</field>
+  <!-- note: price & popularity is missing on this one -->
+  <field name="popularity">0</field>
+  <field name="inStock">true</field>
+  <!-- Buffalo store -->
+  <field name="store">45.18414,-93.88141</field>
+  <field name="manufacturedate_dt">2006-02-13T15:26:37Z</field>
+
+  <field name="payloads">electronics|0.9 memory|0.1</field>
+</doc>
+
+</add>
+
diff --git a/solr/solrj/src/test-files/solrj/sampleDateFacetResponse.xml b/solr/solrj/src/test-files/solrj/sampleDateFacetResponse.xml
new file mode 100644
index 0000000..12e32c2
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/sampleDateFacetResponse.xml
@@ -0,0 +1,4 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<response>
+<lst name="responseHeader"><int name="status">0</int><int name="QTime">0</int><lst name="params"><str name="facet.date.start">NOW/DAY-5DAYS</str><str name="facet">true</str><str name="facet.date.hardend">true</str><str name="q">*:*</str><arr name="facet.date"><str>timestamp</str><str>timestamp2</str></arr><str name="facet.date.gap">+1DAY</str><str name="facet.date.other">ALL</str><str name="facet.date.end">NOW/DAY+1DAY</str><str name="rows">0</str></lst></lst><result name="response" numFound="16" start="0"/><lst name="facet_counts"><lst name="facet_queries"/><lst name="facet_fields"/><lst name="facet_dates"><lst name="timestamp"><int name="2008-03-06T00:00:00.000Z">0</int><int name="2008-03-07T00:00:00.000Z">0</int><int name="2008-03-08T00:00:00.000Z">0</int><int name="2008-03-09T00:00:00.000Z">0</int><int name="2008-03-10T00:00:00.000Z">0</int><int name="2008-03-11T00:00:00.000Z">0</int><str name="gap">+1DAY</str><date name="end">2008-03-12T00:00:00Z</date><int name="before">16</int><int name="after">0</int><int name="between">0</int></lst><lst name="timestamp2"><int name="2008-03-06T00:00:00.000Z">0</int><int name="2008-03-07T00:00:00.000Z">0</int><int name="2008-03-08T00:00:00.000Z">0</int><int name="2008-03-09T00:00:00.000Z">0</int><int name="2008-03-10T00:00:00.000Z">0</int><int name="2008-03-11T00:00:00.000Z">0</int><str name="gap">+1DAY</str><date name="end">2008-03-12T00:00:00Z</date><int name="before">0</int><int name="after">0</int><int name="between">0</int></lst></lst></lst>
+</response>
diff --git a/solr/solrj/src/test-files/solrj/solr/conf/schema-replication1.xml b/solr/solrj/src/test-files/solrj/solr/conf/schema-replication1.xml
new file mode 100644
index 0000000..48ecd9f
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/conf/schema-replication1.xml
@@ -0,0 +1,49 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- The Solr schema file. This file should be named "schema.xml" and
+     should be located where the classloader for the Solr webapp can find it.
+
+     This schema is used for testing, and as such has everything and the 
+     kitchen sink thrown in. See example/solr/conf/schema.xml for a 
+     more concise example.
+
+     $Id$
+     $Source$
+     $Name$
+  -->
+
+<schema name="test" version="1.2">
+  <types>
+
+    <fieldType name="integer" class="solr.IntField"/>
+    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
+
+
+  </types>
+
+
+  <fields>
+    <field name="id" type="integer" indexed="true" stored="true" multiValued="false" required="false"/>
+    <field name="name" type="string" indexed="true" stored="true"/>
+
+  </fields>
+
+  <uniqueKey>id</uniqueKey>
+
+</schema>
diff --git a/solr/solrj/src/test-files/solrj/solr/conf/schema.xml b/solr/solrj/src/test-files/solrj/solr/conf/schema.xml
new file mode 100644
index 0000000..f0fa272
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/conf/schema.xml
@@ -0,0 +1,657 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- The Solr schema file. This file should be named "schema.xml" and
+     should be located where the classloader for the Solr webapp can find it.
+
+     This schema is used for testing, and as such has everything and the
+     kitchen sink thrown in. See example/solr/conf/schema.xml for a
+     more concise example.
+
+     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
+     $Name:  $
+  -->
+
+<schema name="test" version="1.0">
+  <types>
+
+    <!-- field type definitions... note that the "name" attribute is
+         just a label to be used by field definitions.  The "class"
+         attribute and any other attributes determine the real type and
+         behavior of the fieldtype.
+      -->
+
+    <!-- numeric field types that store and index the text
+         value verbatim (and hence don't sort correctly or support range queries.)
+         These are provided more for backward compatability, allowing one
+         to create a schema that matches an existing lucene index.
+    -->
+    <fieldType name="pint" class="solr.IntField"/>
+    <fieldType name="plong" class="solr.LongField"/>
+    <fieldtype name="pfloat" class="solr.FloatField"/>
+    <fieldType name="pdouble" class="solr.DoubleField"/>
+
+    <fieldType name="int" class="solr.TrieIntField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="float" class="solr.TrieFloatField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="long" class="solr.TrieLongField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="double" class="solr.TrieDoubleField" precisionStep="0" omitNorms="true" positionIncrementGap="0"/>
+
+    <fieldType name="tint" class="solr.TrieIntField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="tfloat" class="solr.TrieFloatField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="tlong" class="solr.TrieLongField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
+    <fieldType name="tdouble" class="solr.TrieDoubleField" precisionStep="8" omitNorms="true" positionIncrementGap="0"/>
+
+    <!-- numeric field types that manipulate the value into
+       a string value that isn't human readable in it's internal form,
+       but sorts correctly and supports range queries.
+
+         If sortMissingLast="true" then a sort on this field will cause documents
+       without the field to come after documents with the field,
+       regardless of the requested sort order.
+         If sortMissingFirst="true" then a sort on this field will cause documents
+       without the field to come before documents with the field,
+       regardless of the requested sort order.
+         If sortMissingLast="false" and sortMissingFirst="false" (the default),
+       then default lucene sorting will be used which places docs without the field
+       first in an ascending sort and last in a descending sort.
+    -->
+    <fieldtype name="sint" class="solr.SortableIntField" sortMissingLast="true"/>
+    <fieldtype name="slong" class="solr.SortableLongField" sortMissingLast="true"/>
+    <fieldtype name="sfloat" class="solr.SortableFloatField" sortMissingLast="true"/>
+    <fieldtype name="sdouble" class="solr.SortableDoubleField" sortMissingLast="true"/>
+
+    <!-- bcd versions of sortable numeric type may provide smaller
+         storage space and support very large numbers.
+    -->
+    <fieldtype name="bcdint" class="solr.BCDIntField" sortMissingLast="true"/>
+    <fieldtype name="bcdlong" class="solr.BCDLongField" sortMissingLast="true"/>
+    <fieldtype name="bcdstr" class="solr.BCDStrField" sortMissingLast="true"/>
+
+    <!-- Field type demonstrating an Analyzer failure -->
+    <fieldtype name="failtype1" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- Demonstrating ignoreCaseChange -->
+    <fieldtype name="wdf_nocase" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+     <fieldtype name="wdf_preserve" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="0" preserveOriginal="1"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+
+    <!-- HighlitText optimizes storage for (long) columns which will be highlit -->
+    <fieldtype name="highlittext" class="solr.TextField" compressThreshold="345" />
+
+    <fieldtype name="boolean" class="solr.BoolField" sortMissingLast="true"/>
+    <fieldtype name="string" class="solr.StrField" sortMissingLast="true"/>
+
+    <!-- format for date is 1995-12-31T23:59:59.999Z and only the fractional
+         seconds part (.999) is optional.
+      -->
+    <fieldtype name="date" class="solr.TrieDateField" precisionStep="0"/>
+    <fieldtype name="tdate" class="solr.TrieDateField" precisionStep="6"/>
+    <fieldtype name="pdate" class="solr.DateField" sortMissingLast="true"/>
+
+
+    <!-- solr.TextField allows the specification of custom
+         text analyzers specified as a tokenizer and a list
+         of token filters.
+      -->
+    <fieldtype name="text" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+
+    <fieldtype name="nametext" class="solr.TextField">
+      <analyzer class="org.apache.lucene.analysis.core.WhitespaceAnalyzer"/>
+    </fieldtype>
+
+    <fieldtype name="teststop" class="solr.TextField">
+       <analyzer>
+        <tokenizer class="solr.LowerCaseTokenizerFactory"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- fieldtypes in this section isolate tokenizers and tokenfilters for testing -->
+    <fieldtype name="lowertok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.LowerCaseTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="keywordtok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.KeywordTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="standardtok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.StandardTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="lettertok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.LetterTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="whitetok" class="solr.TextField">
+      <analyzer><tokenizer class="solr.WhitespaceTokenizerFactory"/></analyzer>
+    </fieldtype>
+    <fieldtype name="HTMLstandardtok" class="solr.TextField">
+      <analyzer>
+      <charFilter class="solr.HTMLStripCharFilterFactory"/>
+      <tokenizer class="solr.StandardTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="HTMLwhitetok" class="solr.TextField">
+      <analyzer>
+      <charFilter class="solr.HTMLStripCharFilterFactory"/>
+      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="standardtokfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StandardFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="standardfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.StandardFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="lowerfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="lowerpunctfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter name="syn" class="solr.SynonymFilterFactory" synonyms="synonyms.txt" expand="true"/>
+        <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="1" splitOnCaseChange="1"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="patternreplacefilt" class="solr.TextField">
+      <analyzer type="index">
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+        <filter class="solr.PatternReplaceFilterFactory"
+                pattern="([^a-zA-Z])" replacement="_" replace="all"
+        />
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.KeywordTokenizerFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="patterntok" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.PatternTokenizerFactory" pattern=","/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="porterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <!-- fieldtype name="snowballfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.SnowballPorterFilterFactory"/>
+      </analyzer>
+    </fieldtype -->
+    <fieldtype name="engporterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="custengporterfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="stopfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="custstopfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" words="stopwords.txt"/>
+      </analyzer>
+    </fieldtype>
+    <fieldtype name="lengthfilt" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+        <filter class="solr.LengthFilterFactory" min="2" max="5"/>
+      </analyzer>
+    </fieldtype>
+    <fieldType name="charfilthtmlmap" class="solr.TextField">
+      <analyzer>
+        <charFilter class="solr.HTMLStripCharFilterFactory"/>
+        <charFilter class="solr.MappingCharFilterFactory" mapping="mapping-ISOLatin1Accent.txt"/>
+        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <fieldtype name="subword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype name="numericsubword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="0" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.StopFilterFactory"/>
+          <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype name="protectedsubword" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" protected="protwords.txt" splitOnNumerics="0" splitOnCaseChange="0" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+
+    <!-- more flexible in matching skus, but more chance of a false match -->
+    <fieldtype name="skutype1" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- less flexible in matching skus, but less chance of a false match -->
+    <fieldtype name="skutype2" class="solr.TextField">
+      <analyzer type="index">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- less flexible in matching skus, but less chance of a false match -->
+    <fieldtype name="syn" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter name="syn" class="solr.SynonymFilterFactory" synonyms="old_synonyms.txt"/>
+      </analyzer>
+    </fieldtype>
+
+    <!-- Demonstrates How RemoveDuplicatesTokenFilter makes stemmed
+         synonyms "better"
+      -->
+    <fieldtype name="dedup" class="solr.TextField">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.SynonymFilterFactory"
+                  synonyms="old_synonyms.txt" expand="true" />
+          <filter class="solr.PorterStemFilterFactory"/>
+          <filter class="solr.RemoveDuplicatesTokenFilterFactory" />
+      </analyzer>
+    </fieldtype>
+
+    <fieldtype  name="unstored" class="solr.StrField" indexed="true" stored="false"/>
+
+
+  <fieldtype name="textgap" class="solr.TextField" multiValued="true" positionIncrementGap="100">
+      <analyzer>
+          <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+          <filter class="solr.LowerCaseFilterFactory"/>
+      </analyzer>
+  </fieldtype>
+
+  <fieldType name="uuid" class="solr.UUIDField" />
+
+    <!-- Try out some point types -->
+  <fieldType name="xy" class="solr.PointType" dimension="2" subFieldType="double"/>
+  <fieldType name="x" class="solr.PointType" dimension="1" subFieldType="double"/>
+  <fieldType name="tenD" class="solr.PointType" dimension="10" subFieldType="double"/>
+    <!-- Use the sub field suffix -->
+  <fieldType name="xyd" class="solr.PointType" dimension="2" subFieldSuffix="_d1"/>
+    <fieldtype name="geohash" class="solr.GeoHashField"/>
+
+
+  <fieldType name="latLon" class="solr.LatLonType" subFieldType="double"/>
+
+  <!--  some per-field similarity examples -->
+  
+  <!--  specify a Similarity classname directly -->
+  <fieldType name="sim1" class="solr.TextField">
+    <analyzer>
+      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+    </analyzer>
+    <similarity class="org.apache.lucene.misc.SweetSpotSimilarity"/>
+  </fieldType>
+
+  <!--  specify a Similarity factory -->  
+  <fieldType name="sim2" class="solr.TextField">
+    <analyzer>
+      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+    </analyzer>
+    <similarity class="org.apache.solr.schema.CustomSimilarityFactory">
+      <str name="echo">is there an echo?</str>
+    </similarity>
+  </fieldType>
+  
+  <!-- don't specify any sim at all: get the default  -->
+  <fieldType name="sim3" class="solr.TextField">
+    <analyzer>
+      <tokenizer class="solr.WhitespaceTokenizerFactory"/>
+    </analyzer>
+  </fieldType>
+ </types>
+
+
+ <fields>
+   <field name="id" type="int" indexed="true" stored="true" multiValued="false" required="false"/>
+   <field name="signatureField" type="string" indexed="true" stored="false"/>
+   <field name="uuid" type="uuid" stored="true" />
+   <field name="name" type="nametext" indexed="true" stored="true"/>
+   <field name="text" type="text" indexed="true" stored="false"/>
+   <field name="subject" type="text" indexed="true" stored="true"/>
+   <field name="title" type="nametext" indexed="true" stored="true"/>
+   <field name="weight" type="float" indexed="true" stored="true" multiValued="false"/>
+   <field name="bday" type="date" indexed="true" stored="true" multiValued="false"/>
+
+   <field name="title_stemmed" type="text" indexed="true" stored="false"/>
+   <field name="title_lettertok" type="lettertok" indexed="true" stored="false"/>
+
+   <field name="syn" type="syn" indexed="true" stored="true"/>
+
+   <!-- to test property inheritance and overriding -->
+   <field name="shouldbeunstored" type="unstored" />
+   <field name="shouldbestored" type="unstored" stored="true"/>
+   <field name="shouldbeunindexed" type="unstored" indexed="false" stored="true"/>
+
+   <!-- Test points -->
+      <!-- Test points -->
+   <field name="home" type="xy" indexed="true" stored="true" multiValued="false"/>
+   <field name="x" type="x" indexed="true" stored="true" multiValued="false"/>
+   <field name="homed" type="xyd" indexed="true" stored="true" multiValued="false"/>
+   <field name="home_ns" type="xy" indexed="true" stored="false" multiValued="false"/>
+   <field name="work" type="xy" indexed="true" stored="true" multiValued="false"/>
+
+   <field name="home_ll" type="latLon" indexed="true" stored="true" multiValued="false"/>
+   <field name="home_gh" type="geohash" indexed="true" stored="true" multiValued="false"/>
+
+
+   <field name="point10" type="tenD" indexed="true" stored="true" multiValued="false"/>
+
+
+   <!-- test different combinations of indexed and stored -->
+   <field name="bind" type="boolean" indexed="true" stored="false"/>
+   <field name="bsto" type="boolean" indexed="false" stored="true"/>
+   <field name="bindsto" type="boolean" indexed="true" stored="true"/>
+   <field name="isto" type="int" indexed="false" stored="true"/>
+   <field name="iind" type="int" indexed="true" stored="false"/>
+   <field name="ssto" type="string" indexed="false" stored="true"/>
+   <field name="sind" type="string" indexed="true" stored="false"/>
+   <field name="sindsto" type="string" indexed="true" stored="true"/>
+
+   <!-- test combinations of term vector settings -->
+   <field name="test_basictv" type="text" termVectors="true"/>
+   <field name="test_notv" type="text" termVectors="false"/>
+   <field name="test_postv" type="text" termVectors="true" termPositions="true"/>
+   <field name="test_offtv" type="text" termVectors="true" termOffsets="true"/>
+   <field name="test_posofftv" type="text" termVectors="true"
+     termPositions="true" termOffsets="true"/>
+
+   <!-- test highlit field settings -->
+   <field name="test_hlt" type="highlittext" indexed="true" compressed="true"/>
+   <field name="test_hlt_off" type="highlittext" indexed="true" compressed="false"/>
+
+   <!-- fields to test individual tokenizers and tokenfilters -->
+   <field name="teststop" type="teststop" indexed="true" stored="true"/>
+   <field name="lowertok" type="lowertok" indexed="true" stored="true"/>
+   <field name="keywordtok" type="keywordtok" indexed="true" stored="true"/>
+   <field name="standardtok" type="standardtok" indexed="true" stored="true"/>
+   <field name="HTMLstandardtok" type="HTMLstandardtok" indexed="true" stored="true"/>
+   <field name="lettertok" type="lettertok" indexed="true" stored="true"/>
+   <field name="whitetok" type="whitetok" indexed="true" stored="true"/>
+   <field name="HTMLwhitetok" type="HTMLwhitetok" indexed="true" stored="true"/>
+   <field name="standardtokfilt" type="standardtokfilt" indexed="true" stored="true"/>
+   <field name="standardfilt" type="standardfilt" indexed="true" stored="true"/>
+   <field name="lowerfilt" type="lowerfilt" indexed="true" stored="true"/>
+   <field name="lowerfilt1" type="lowerfilt" indexed="true" stored="true"/>
+	 <field name="lowerfilt1and2" type="lowerfilt" indexed="true" stored="true"/>
+   <field name="patterntok" type="patterntok" indexed="true" stored="true"/>
+   <field name="patternreplacefilt" type="patternreplacefilt" indexed="true" stored="true"/>
+   <field name="porterfilt" type="porterfilt" indexed="true" stored="true"/>
+   <field name="engporterfilt" type="engporterfilt" indexed="true" stored="true"/>
+   <field name="custengporterfilt" type="custengporterfilt" indexed="true" stored="true"/>
+   <field name="stopfilt" type="stopfilt" indexed="true" stored="true"/>
+   <field name="custstopfilt" type="custstopfilt" indexed="true" stored="true"/>
+   <field name="lengthfilt" type="lengthfilt" indexed="true" stored="true"/>
+   <field name="dedup" type="dedup" indexed="true" stored="true"/>
+   <field name="wdf_nocase" type="wdf_nocase" indexed="true" stored="true"/>
+   <field name="wdf_preserve" type="wdf_preserve" indexed="true" stored="true"/>
+
+   <field name="numberpartfail" type="failtype1" indexed="true" stored="true"/>
+
+   <field name="nullfirst" type="string" indexed="true" stored="true" sortMissingFirst="true" multiValued="false"/>
+
+   <field name="subword" type="subword" indexed="true" stored="true"/>
+   <field name="subword_offsets" type="subword" indexed="true" stored="true" termOffsets="true"/>
+   <field name="numericsubword" type="numericsubword" indexed="true" stored="true"/>
+   <field name="protectedsubword" type="protectedsubword" indexed="true" stored="true"/>
+
+   <field name="sku1" type="skutype1" indexed="true" stored="true"/>
+   <field name="sku2" type="skutype2" indexed="true" stored="true"/>
+
+   <field name="textgap" type="textgap" indexed="true" stored="true"/>
+
+   <field name="timestamp" type="date" indexed="true" stored="true" default="NOW" multiValued="false"/>
+   <field name="multiDefault" type="string" indexed="true" stored="true" default="muLti-Default" multiValued="true"/>
+   <field name="intDefault" type="int" indexed="true" stored="true" default="42" multiValued="false"/>
+
+   <field name="sim1text" type="sim1" indexed="true" stored="true"/>
+   <field name="sim2text" type="sim2" indexed="true" stored="true"/>
+   <field name="sim3text" type="sim3" indexed="true" stored="true"/>
+
+   <field name="tlong" type="tlong" indexed="true" stored="true" />
+
+   <!-- Dynamic field definitions.  If a field name is not found, dynamicFields
+        will be used if the name matches any of the patterns.
+        RESTRICTION: the glob-like pattern in the name attribute must have
+        a "*" only at the start or the end.
+        EXAMPLE:  name="*_i" will match any field ending in _i (like myid_i, z_i)
+        Longer patterns will be matched first.  if equal size patterns
+        both match, the first appearing in the schema will be used.
+   -->
+   <dynamicField name="*_i"  type="int"    indexed="true"  stored="true"/>
+   <dynamicField name="*_i1"  type="int"    indexed="true" stored="true" multiValued="false"/>
+                 
+   <dynamicField name="*_s"  type="string"  indexed="true"  stored="true"/>
+   <dynamicField name="*_s1"  type="string"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_l"  type="long"   indexed="true"  stored="true"/>
+   <dynamicField name="*_l1"  type="long"   indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_t"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="*_b"  type="boolean" indexed="true"  stored="true"/>
+   <dynamicField name="*_f"  type="float"  indexed="true"  stored="true"/>
+   <dynamicField name="*_f1"  type="float"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_d"  type="double" indexed="true"  stored="true"/>
+   <dynamicField name="*_d1"  type="double" indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_dt" type="date"    indexed="true"  stored="true"/>
+   <dynamicField name="*_dt1" type="date"    indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_bcd" type="bcdstr" indexed="true"  stored="true"/>
+
+      <!-- some trie-coded dynamic fields for faster range queries -->
+   <dynamicField name="*_ti" type="tint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_ti1" type="tint"    indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_tl" type="tlong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_tl1" type="tlong"   indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_tf" type="tfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_tf1" type="tfloat"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_td" type="tdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_td1" type="tdouble" indexed="true" stored="true" multiValued="false"/>
+   <dynamicField name="*_tds" type="tdouble" indexed="true" stored="true" multiValued="false"/>
+   <dynamicField name="*_tdt" type="tdate"  indexed="true"  stored="true"/>
+   <dynamicField name="*_tdt1" type="tdate"  indexed="true"  stored="true" multiValued="false"/>
+
+   <dynamicField name="*_si"  type="sint"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_sl"  type="slong"  indexed="true"  stored="true"/>
+   <dynamicField name="*_sf"  type="sfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_sf1"  type="sfloat"  indexed="true"  stored="true" multiValued="false"/>
+   <dynamicField name="*_sd"  type="sdouble"  indexed="true"  stored="true"/>
+   <dynamicField name="*_sd1"  type="sdouble"  indexed="true"  stored="true" multiValued="false"/>
+
+   <dynamicField name="*_pi"  type="pint"    indexed="true"  stored="true"/>
+   <dynamicField name="*_pf"  type="pfloat"  indexed="true"  stored="true"/>
+   <dynamicField name="*_pl"  type="plong"   indexed="true"  stored="true"/>
+   <dynamicField name="*_pd"  type="pdouble" indexed="true"  stored="true"/>
+   <dynamicField name="*_pdt"  type="pdate" indexed="true"  stored="true"/>
+
+
+   <dynamicField name="*_sI" type="string"  indexed="true"  stored="false"/>
+   <dynamicField name="*_sS" type="string"  indexed="false" stored="true"/>
+   <dynamicField name="t_*"  type="text"    indexed="true"  stored="true"/>
+   <dynamicField name="tv_*"  type="text" indexed="true"  stored="true"
+      termVectors="true" termPositions="true" termOffsets="true"/>
+   <dynamicField name="tv_mv_*"  type="text" indexed="true"  stored="true" multiValued="true"
+      termVectors="true" termPositions="true" termOffsets="true"/>
+
+   <dynamicField name="*_p"  type="xyd" indexed="true"  stored="true" multiValued="false"/>
+
+   <!-- special fields for dynamic copyField test -->
+   <dynamicField name="dynamic_*" type="string" indexed="true" stored="true"/>
+   <dynamicField name="*_dynamic" type="string" indexed="true" stored="true"/>
+
+   <!-- for testing to ensure that longer patterns are matched first -->
+   <dynamicField name="*aa"  type="string"  indexed="true" stored="true"/>
+   <dynamicField name="*aaa" type="pint" indexed="false" stored="true"/>
+
+   <!-- ignored becuase not stored or indexed -->
+   <dynamicField name="*_ignored" type="text" indexed="false" stored="false"/>
+
+   <dynamicField name="*_mfacet" type="string" indexed="true" stored="false" multiValued="true" />
+
+   <!-- make sure custom sims work with dynamic fields -->
+   <dynamicField name="*_sim1" type="sim1" indexed="true" stored="true"/>
+   <dynamicField name="*_sim2" type="sim2" indexed="true" stored="true"/>
+   <dynamicField name="*_sim3" type="sim3" indexed="true" stored="true"/>
+ </fields>
+
+ <defaultSearchField>text</defaultSearchField>
+ <uniqueKey>id</uniqueKey>
+
+  <!-- copyField commands copy one field to another at the time a document
+        is added to the index.  It's used either to index the same field different
+        ways, or to add multiple fields to the same field for easier/faster searching.
+   -->
+   <copyField source="title" dest="title_stemmed"/>
+   <copyField source="title" dest="title_lettertok"/>
+
+   <copyField source="title" dest="text"/>
+	 <copyField source="subject" dest="text"/>
+
+	 <copyField source="lowerfilt1" dest="lowerfilt1and2"/>
+	 <copyField source="lowerfilt" dest="lowerfilt1and2"/>
+
+	 <copyField source="*_t" dest="text"/>
+
+	 <copyField source="id"            dest="range_facet_si"/>
+	 <copyField source="id"            dest="range_facet_l"/>
+	 <copyField source="id"            dest="range_facet_sl"/>
+	 <copyField source="range_facet_f" dest="range_facet_sf"/>
+	 <copyField source="range_facet_f" dest="range_facet_d"/>
+	 <copyField source="range_facet_f" dest="range_facet_sd"/>
+
+	 <copyField source="bday" dest="bday_pdt"/>
+	 <copyField source="a_tdt" dest="a_pdt"/>
+
+   <!-- dynamic destination -->
+   <copyField source="*_dynamic" dest="dynamic_*"/>
+
+ <!-- expert: SimilarityProvider contains scoring routines that are not field-specific,
+      such as coord() and queryNorm(). most scoring customization happens in the fieldtype.
+      A custom similarity provider may be specified here, but the default is fine
+      for most applications.
+ -->
+ <similarityProvider class="org.apache.solr.schema.CustomSimilarityProviderFactory">
+   <str name="echo">is there an echo?</str>
+ </similarityProvider>
+
+ <!-- default similarity, unless otherwise specified by the fieldType
+  -->
+ <similarity class="org.apache.solr.schema.CustomSimilarityFactory">
+   <str name="echo">I am your default sim</str>
+ </similarity>
+</schema>
diff --git a/solr/solrj/src/test-files/solrj/solr/conf/solrconfig-slave1.xml b/solr/solrj/src/test-files/solrj/solr/conf/solrconfig-slave1.xml
new file mode 100644
index 0000000..46c1cb4
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/conf/solrconfig-slave1.xml
@@ -0,0 +1,88 @@
+<?xml version="1.0" ?>
+
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!-- $Id$
+     $Source$
+     $Name$
+  -->
+
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+  <dataDir>${solr.data.dir:}</dataDir>
+
+  <indexDefaults>
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <writeLockTimeout>1000</writeLockTimeout>
+    <commitLockTimeout>10000</commitLockTimeout>
+
+    <lockType>single</lockType>
+  </indexDefaults>
+
+  <mainIndex>
+    <useCompoundFile>false</useCompoundFile>
+    <mergeFactor>10</mergeFactor>
+    <ramBufferSizeMB>32</ramBufferSizeMB>
+    <maxMergeDocs>2147483647</maxMergeDocs>
+    <maxFieldLength>10000</maxFieldLength>
+
+    <unlockOnStartup>true</unlockOnStartup>
+  </mainIndex>
+
+  <updateHandler class="solr.DirectUpdateHandler2">
+  </updateHandler>
+
+  <requestHandler name="standard" class="solr.StandardRequestHandler">
+    <bool name="httpCaching">true</bool>
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="defaults" class="solr.StandardRequestHandler">
+
+  </requestHandler>
+
+  <!-- test query parameter defaults -->
+  <requestHandler name="lazy" class="solr.StandardRequestHandler" startup="lazy">
+  </requestHandler>
+
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler"/>
+
+
+  <requestHandler name="/update/javabin" class="solr.BinaryUpdateRequestHandler"/>
+
+  <requestHandler name="/replication" class="solr.ReplicationHandler">
+
+  </requestHandler>
+
+
+  <!-- enable streaming for testing... -->
+  <requestDispatcher handleSelect="true">
+    <requestParsers enableRemoteStreaming="true" multipartUploadLimitInKB="2048"/>
+    <httpCaching lastModifiedFrom="openTime" etagSeed="Solr" never304="false">
+      <cacheControl>max-age=30, public</cacheControl>
+    </httpCaching>
+  </requestDispatcher>
+
+</config>
diff --git a/solr/solrj/src/test-files/solrj/solr/crazy-path-to-schema.xml b/solr/solrj/src/test-files/solrj/solr/crazy-path-to-schema.xml
new file mode 100644
index 0000000..b71c9f4
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/crazy-path-to-schema.xml
@@ -0,0 +1,48 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<!--
+     Striped down schema used by SampleTest to demonstrate picking any
+     schema filename you want.
+
+     $Id: schema.xml 382610 2006-03-03 01:43:03Z yonik $
+     $Source: /cvs/main/searching/solr-configs/test/WEB-INF/classes/schema.xml,v $
+  -->
+
+<schema name="test" version="1.0">
+  <types>
+    <fieldtype name="sint" class="solr.SortableIntField" />
+    <fieldtype name="text" class="solr.TextField">
+      <analyzer>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory"/>
+        <filter class="solr.PorterStemFilterFactory"/>
+      </analyzer>
+    </fieldtype>
+ </types>
+
+
+ <fields>
+   <field name="id" type="sint" indexed="true" stored="true" multiValued="false"/>
+   <field name="subject" type="text" indexed="true" stored="true"/>
+ </fields>
+
+ <defaultSearchField>subject</defaultSearchField>
+ <uniqueKey>id</uniqueKey>
+</schema>
diff --git a/solr/solrj/src/test-files/solrj/solr/shared/conf/schema.xml b/solr/solrj/src/test-files/solrj/solr/shared/conf/schema.xml
new file mode 100644
index 0000000..da37f27
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/shared/conf/schema.xml
@@ -0,0 +1,69 @@
+<?xml version="1.0" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<schema name="example core ${l10n}" version="1.1">
+  <types>
+    <fieldtype name="string" class="solr.StrField" sortMissingLast="true" omitNorms="true"/>
+    <fieldType name="text-FR" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-fr.txt"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-fr.txt"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    <fieldType name="text-EN" class="solr.TextField" positionIncrementGap="100">
+      <analyzer type="index">
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-en.txt"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+      <analyzer type="query">
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords-en.txt"/>
+        <filter class="solr.StandardFilterFactory"/>
+        <filter class="solr.RemoveDuplicatesTokenFilterFactory"/>
+      </analyzer>
+    </fieldType>
+  </types>
+
+  <fields>
+    <!-- general -->
+    <field name="id" type="string" indexed="true" stored="true" multiValued="false" required="true"/>
+    <field name="type" type="string" indexed="true" stored="true" multiValued="false"/>
+    <field name="name" type="string" indexed="true" stored="true" multiValued="false"/>
+    <field name="${ctlField}" type="text-${l10n}" indexed="true" stored="true" multiValued="true"/>
+  </fields>
+
+  <!-- field to use to determine and enforce document uniqueness. -->
+  <uniqueKey>id</uniqueKey>
+
+  <!-- field for the QueryParser to use when an explicit fieldname is absent -->
+  <defaultSearchField>name</defaultSearchField>
+
+  <!-- SolrQueryParser configuration: defaultOperator="AND|OR" -->
+  <solrQueryParser defaultOperator="OR"/>
+</schema>
+
diff --git a/solr/solrj/src/test-files/solrj/solr/shared/conf/solrconfig.xml b/solr/solrj/src/test-files/solrj/solr/shared/conf/solrconfig.xml
new file mode 100644
index 0000000..031fbb0
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/shared/conf/solrconfig.xml
@@ -0,0 +1,44 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--
+ This is a stripped down config file used for a simple example...  
+ It is *not* a good example to work from. 
+-->
+<config>
+  <luceneMatchVersion>${tests.luceneMatchVersion:LUCENE_CURRENT}</luceneMatchVersion>
+  <dataDir>${solr.solr.home}/data/${l10n}-${version}</dataDir>
+
+
+  <updateHandler class="solr.DirectUpdateHandler2" />
+
+  <requestDispatcher handleSelect="true" >
+    <requestParsers enableRemoteStreaming="false" multipartUploadLimitInKB="2048" />
+  </requestDispatcher>
+  
+  <requestHandler name="standard" class="solr.StandardRequestHandler" default="true" />
+  <requestHandler name="/update" class="solr.XmlUpdateRequestHandler" />
+  <requestHandler name="/admin/" class="org.apache.solr.handler.admin.AdminHandlers" />
+      
+  <!-- config for the admin interface --> 
+  <admin>
+    <defaultQuery>solr</defaultQuery>
+  </admin>
+
+</config>
+
diff --git a/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-en.txt b/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-en.txt
new file mode 100644
index 0000000..273cd77
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-en.txt
@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+stopena
+stopenb
diff --git a/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-fr.txt b/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-fr.txt
new file mode 100644
index 0000000..f9a2036
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/shared/conf/stopwords-fr.txt
@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+stopfra
+stopfrb
diff --git a/solr/solrj/src/test-files/solrj/solr/shared/solr.xml b/solr/solrj/src/test-files/solrj/solr/shared/solr.xml
new file mode 100644
index 0000000..d8a5b05
--- /dev/null
+++ b/solr/solrj/src/test-files/solrj/solr/shared/solr.xml
@@ -0,0 +1,47 @@
+<?xml version="1.0" encoding="UTF-8" ?>
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+
+<!--
+ All (relative) paths are relative to the installation path
+  
+  persistent: Save changes made via the API to this file
+  sharedLib: path to a lib directory that will be shared across all cores
+-->
+<solr persistent="true">
+  <property name="version" value="1.3"/>
+  <property name="lang" value="english, french"/>
+
+  <!--
+  adminPath: RequestHandler path to manage cores.  
+    If 'null' (or absent), cores will not be manageable via REST
+  -->
+  <cores adminPath="/admin/cores" defaultCoreName="core0" host="127.0.0.1" hostPort="${hostPort:8983}" hostContext="solr" zkClientTimeout="8000">
+    <core name="core0" instanceDir="./">
+      <property name="version" value="3.5"/>
+      <property name="l10n" value="EN"/>
+      <property name="ctlField" value="core0"/>
+      <property name="comment" value="This is a sample"/>
+    </core>
+    <core name="core1" instanceDir="./">
+      <property name="version" value="2.4"/>
+      <property name="l10n" value="FR"/>
+      <property name="ctlField" value="core1"/>
+      <property name="comment" value="Ceci est un exemple"/>
+    </core>
+  </cores>
+</solr>
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
index 60cad11..30e074d 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
@@ -441,7 +441,7 @@ abstract public class SolrExampleTests extends SolrJettyTestBase
     Assert.assertEquals( 0, rsp.getResults().getNumFound() );
 
     ContentStreamUpdateRequest up = new ContentStreamUpdateRequest("/update/csv");
-    up.addFile(getFile("books.csv"));
+    up.addFile(getFile("solrj/books.csv"));
     up.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
     NamedList<Object> result = server.request(up);
     assertNotNull("Couldn't upload books.csv", result);
@@ -458,8 +458,8 @@ abstract public class SolrExampleTests extends SolrJettyTestBase
     Assert.assertEquals( 0, rsp.getResults().getNumFound() );
 
     ContentStreamUpdateRequest up = new ContentStreamUpdateRequest("/update");
-    up.addFile(getFile("docs1.xml")); // 2
-    up.addFile(getFile("docs2.xml")); // 3
+    up.addFile(getFile("solrj/docs1.xml")); // 2
+    up.addFile(getFile("solrj/docs2.xml")); // 3
     up.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
     NamedList<Object> result = server.request(up);
     assertNotNull("Couldn't upload xml files", result);
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java b/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
index fd38bca..d5f3a59 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
@@ -214,7 +214,7 @@ public class TestLBHttpSolrServer extends LuceneTestCase {
     }
 
     public String getSchemaFile() {
-      return "." + File.separator + "solr" + File.separator + "conf" + File.separator + "schema-replication1.xml";
+      return "solrj/solr/conf/schema-replication1.xml";
     }
 
     public String getConfDir() {
@@ -226,9 +226,7 @@ public class TestLBHttpSolrServer extends LuceneTestCase {
     }
 
     public String getSolrConfigFile() {
-      String fname = "";
-      fname = "." + File.separator + "solr" + File.separator + "conf" + File.separator + "solrconfig-slave1.xml";
-      return fname;
+      return "solrj/solr/conf/solrconfig-slave1.xml";
     }
 
     public void setUp() throws Exception {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
index bf3c168..89905a9 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
@@ -62,7 +62,7 @@ public class TestSolrProperties extends LuceneTestCase {
   private static final XPathFactory xpathFactory = XPathFactory.newInstance();
 
   public String getSolrHome() {
-    return "solr/shared";
+    return "solrj/solr/shared";
   }
 
   public String getOrigSolrXml() {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/response/QueryResponseTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/response/QueryResponseTest.java
index 06fa809..75d8141 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/response/QueryResponseTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/response/QueryResponseTest.java
@@ -39,7 +39,7 @@ public class QueryResponseTest extends LuceneTestCase {
   @Test
   public void testDateFacets() throws Exception   {
     XMLResponseParser parser = new XMLResponseParser();
-    InputStream is = new SolrResourceLoader(null, null).openResource("sampleDateFacetResponse.xml");
+    InputStream is = new SolrResourceLoader(null, null).openResource("solrj/sampleDateFacetResponse.xml");
     assertNotNull(is);
     Reader in = new InputStreamReader(is, "UTF-8");
     NamedList<Object> response = parser.processResponse(in);
diff --git a/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java b/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java
index ec989f8..566233e 100755
--- a/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java
+++ b/solr/solrj/src/test/org/apache/solr/common/util/ContentStreamTest.java
@@ -49,7 +49,7 @@ public class ContentStreamTest extends LuceneTestCase
 
   public void testFileStream() throws IOException 
   {
-    InputStream is = new SolrResourceLoader(null, null).openResource( "README" );
+    InputStream is = new SolrResourceLoader(null, null).openResource( "solrj/README" );
     assertNotNull( is );
     File file = new File(TEMP_DIR, "README");
     FileOutputStream os = new FileOutputStream(file);
diff --git a/solr/solrj/src/test/org/apache/solr/common/util/TestSystemIdResolver.java b/solr/solrj/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
index d8ffdeb..c40ed4d 100644
--- a/solr/solrj/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
+++ b/solr/solrj/src/test/org/apache/solr/common/util/TestSystemIdResolver.java
@@ -38,9 +38,10 @@ public class TestSystemIdResolver extends LuceneTestCase {
   }
   
   public void testResolving() throws Exception {
-    final ResourceLoader loader = new SolrResourceLoader(SolrTestCaseJ4.TEST_HOME(), this.getClass().getClassLoader());
+    final String testHome = SolrTestCaseJ4.getFile("solrj/solr/conf").getParent();
+    final ResourceLoader loader = new SolrResourceLoader(testHome, this.getClass().getClassLoader());
     final SystemIdResolver resolver = new SystemIdResolver(loader);
-    final String fileUri = new File(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-config.xml").toURI().toASCIIString();
+    final String fileUri = new File(testHome+"/crazy-path-to-config.xml").toURI().toASCIIString();
     
     assertEquals("solrres:/test.xml", SystemIdResolver.createSystemIdFromResourceName("test.xml"));
     assertEquals("solrres://@/usr/local/etc/test.xml", SystemIdResolver.createSystemIdFromResourceName("/usr/local/etc/test.xml"));
@@ -60,10 +61,10 @@ public class TestSystemIdResolver extends LuceneTestCase {
     assertEntityResolving(resolver, "solrres:/schema.xml", "solrres:/solrconfig.xml", "schema.xml");
     assertEntityResolving(resolver, "solrres:/org/apache/solr/common/util/TestSystemIdResolver.class",
       "solrres:/org/apache/solr/common/ResourceLoader.class", "util/TestSystemIdResolver.class");
-    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/conf/schema.xml"),
-      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/conf/solrconfig.xml"), "schema.xml");
-    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-schema.xml"),
-      SystemIdResolver.createSystemIdFromResourceName(SolrTestCaseJ4.TEST_HOME()+"/crazy-path-to-config.xml"), "crazy-path-to-schema.xml");
+    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(testHome+"/conf/schema.xml"),
+      SystemIdResolver.createSystemIdFromResourceName(testHome+"/conf/solrconfig.xml"), "schema.xml");
+    assertEntityResolving(resolver, SystemIdResolver.createSystemIdFromResourceName(testHome+"/crazy-path-to-schema.xml"),
+      SystemIdResolver.createSystemIdFromResourceName(testHome+"/crazy-path-to-config.xml"), "crazy-path-to-schema.xml");
     
     // test, that resolving works if somebody uses an absolute file:-URI in a href attribute, the resolver should return null (default fallback)
     assertNull(resolver.resolveEntity(null, null, "solrres:/solrconfig.xml", fileUri));

