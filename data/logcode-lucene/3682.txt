GitDiffStart: c3209306cb44e0c318e8af144806b8a88c802e36 | Mon Apr 20 17:23:58 2015 +0000
diff --git a/lucene/build.xml b/lucene/build.xml
index cc7662d..6f1b4e0 100644
--- a/lucene/build.xml
+++ b/lucene/build.xml
@@ -53,7 +53,7 @@
   </target>
 
   <!-- "-clover.load" is *not* a useless dependency. do not remove -->
-  <target name="test" depends="-clover.load, -init-totals, test-core, test-modules, -check-totals"
+  <target name="test" depends="-clover.load, -init-totals, test-core, test-test-framework, test-modules, -check-totals"
           description="Runs all unit tests (core, modules and back-compat)"
   />
 
@@ -449,9 +449,18 @@
       <ant dir="core" target="compile-test" inheritall="false">
         <propertyset refid="uptodate.and.compiled.properties"/>
       </ant>
+      <ant dir="test-framework" target="compile-test" inheritall="false">
+        <propertyset refid="uptodate.and.compiled.properties"/>
+      </ant>
       <modules-crawl target="compile-test" failonerror="true"/>
     </sequential>
   </target>
+
+  <target name="test-test-framework">
+      <ant dir="test-framework" target="test" inheritall="false">
+        <propertyset refid="uptodate.and.compiled.properties"/>
+      </ant>
+  </target>
   
   <target name="test-modules">
     <modules-crawl target="test" failonerror="true"/>
@@ -470,6 +479,9 @@
     <ant dir="${common.dir}/core" target="jacoco" inheritAll="false">
       <propertyset refid="uptodate.and.compiled.properties"/>
     </ant>
+    <ant dir="${common.dir}/test-framework" target="jacoco" inheritAll="false">
+      <propertyset refid="uptodate.and.compiled.properties"/>
+    </ant>
     <modules-crawl target="jacoco" failonerror="true"/>
 
     <!-- produce aggregate report -->
@@ -486,7 +498,6 @@
         <classfiles>
           <fileset dir="${common.dir}/build">
              <include name="**/classes/java/**/*.class"/>
-             <exclude name="test-framework/**"/>
              <exclude name="tools/**"/>
           </fileset>
         </classfiles>
diff --git a/lucene/core/src/test/org/apache/lucene/TestWorstCaseTestBehavior.java b/lucene/core/src/test/org/apache/lucene/TestWorstCaseTestBehavior.java
deleted file mode 100644
index e9509ab..0000000
--- a/lucene/core/src/test/org/apache/lucene/TestWorstCaseTestBehavior.java
+++ /dev/null
@@ -1,98 +0,0 @@
-package org.apache.lucene;
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Ignore;
-
-import com.carrotsearch.randomizedtesting.RandomizedTest;
-import com.carrotsearch.randomizedtesting.annotations.Timeout;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestWorstCaseTestBehavior extends LuceneTestCase {
-  @Ignore
-  public void testThreadLeak() {
-    Thread t = new Thread() {
-      @Override
-      public void run() {
-        try {
-          Thread.sleep(10000);
-        } catch (InterruptedException e) {
-          // Ignore.
-        }
-      }
-    };
-    t.start();
-
-    while (!t.isAlive()) {
-      Thread.yield();
-    }
-
-    // once alive, leave it to run outside of the test scope.
-  }
-
-  @Ignore
-  public void testLaaaaaargeOutput() throws Exception {
-    String message = "I will not OOM on large output";
-    int howMuch = 250 * 1024 * 1024;
-    for (int i = 0; i < howMuch; i++) {
-      if (i > 0) System.out.print(",\n");
-      System.out.print(message);
-      howMuch -= message.length(); // approximately.
-    }
-    System.out.println(".");
-  }
-
-  @Ignore
-  public void testProgressiveOutput() throws Exception {
-    for (int i = 0; i < 20; i++) {
-      System.out.println("Emitting sysout line: " + i);
-      System.err.println("Emitting syserr line: " + i);
-      System.out.flush();
-      System.err.flush();
-      RandomizedTest.sleep(1000);
-    }
-  }
-
-  @Ignore
-  public void testUncaughtException() throws Exception {
-    Thread t = new Thread() {
-      @Override
-      public void run() {
-        throw new RuntimeException("foobar");
-      }
-    };
-    t.start();
-    t.join();
-  }
-  
-  @Ignore
-  @Timeout(millis = 500)
-  public void testTimeout() throws Exception {
-    Thread.sleep(5000);
-  }
-  
-  @Ignore
-  @Timeout(millis = 1000)
-  public void testZombie() throws Exception {
-    while (true) {
-      try {
-        Thread.sleep(1000);
-      } catch (InterruptedException e) {}
-    }
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java b/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java
deleted file mode 100644
index 838243c..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java
+++ /dev/null
@@ -1,589 +0,0 @@
-package org.apache.lucene.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.PrintWriter;
-import java.io.StringWriter;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Random;
-
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
-import org.apache.lucene.util.automaton.Automata;
-import org.apache.lucene.util.automaton.Automaton;
-import org.apache.lucene.util.automaton.Operations;
-
-import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-
-public class TestGraphTokenizers extends BaseTokenStreamTestCase {
-
-  // Makes a graph TokenStream from the string; separate
-  // positions with single space, multiple tokens at the same
-  // position with /, and add optional position length with
-  // :.  EG "a b c" is a simple chain, "a/x b c" adds 'x'
-  // over 'a' at position 0 with posLen=1, "a/x:3 b c" adds
-  // 'x' over a with posLen=3.  Tokens are in normal-form!
-  // So, offsets are computed based on the first token at a
-  // given position.  NOTE: each token must be a single
-  // character!  We assume this when computing offsets...
-  
-  // NOTE: all input tokens must be length 1!!!  This means
-  // you cannot turn on MockCharFilter when random
-  // testing...
-
-  private static class GraphTokenizer extends Tokenizer {
-    private List<Token> tokens;
-    private int upto;
-    private int inputLength;
-
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-    private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
-    private final PositionLengthAttribute posLengthAtt = addAttribute(PositionLengthAttribute.class);
-
-    @Override
-    public void reset() throws IOException {
-      super.reset();
-      tokens = null;
-      upto = 0;
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (tokens == null) {
-        fillTokens();
-      }
-      //System.out.println("graphTokenizer: incr upto=" + upto + " vs " + tokens.size());
-      if (upto == tokens.size()) {
-        //System.out.println("  END @ " + tokens.size());
-        return false;
-      } 
-      final Token t = tokens.get(upto++);
-      //System.out.println("  return token=" + t);
-      clearAttributes();
-      termAtt.append(t.toString());
-      offsetAtt.setOffset(t.startOffset(), t.endOffset());
-      posIncrAtt.setPositionIncrement(t.getPositionIncrement());
-      posLengthAtt.setPositionLength(t.getPositionLength());
-      return true;
-    }
-
-    @Override
-    public void end() throws IOException {
-      super.end();
-      // NOTE: somewhat... hackish, but we need this to
-      // satisfy BTSTC:
-      final int lastOffset;
-      if (tokens != null && !tokens.isEmpty()) {
-        lastOffset = tokens.get(tokens.size()-1).endOffset();
-      } else {
-        lastOffset = 0;
-      }
-      offsetAtt.setOffset(correctOffset(lastOffset),
-                          correctOffset(inputLength));
-    }
-
-    private void fillTokens() throws IOException {
-      final StringBuilder sb = new StringBuilder();
-      final char[] buffer = new char[256];
-      while (true) {
-        final int count = input.read(buffer);
-        if (count == -1) {
-          break;
-        }
-        sb.append(buffer, 0, count);
-        //System.out.println("got count=" + count);
-      }
-      //System.out.println("fillTokens: " + sb);
-
-      inputLength = sb.length();
-
-      final String[] parts = sb.toString().split(" ");
-
-      tokens = new ArrayList<>();
-      int pos = 0;
-      int maxPos = -1;
-      int offset = 0;
-      //System.out.println("again");
-      for(String part : parts) {
-        final String[] overlapped = part.split("/");
-        boolean firstAtPos = true;
-        int minPosLength = Integer.MAX_VALUE;
-        for(String part2 : overlapped) {
-          final int colonIndex = part2.indexOf(':');
-          final String token;
-          final int posLength;
-          if (colonIndex != -1) {
-            token = part2.substring(0, colonIndex);
-            posLength = Integer.parseInt(part2.substring(1+colonIndex));
-          } else {
-            token = part2;
-            posLength = 1;
-          }
-          maxPos = Math.max(maxPos, pos + posLength);
-          minPosLength = Math.min(minPosLength, posLength);
-          final Token t = new Token(token, offset, offset + 2*posLength - 1);
-          t.setPositionLength(posLength);
-          t.setPositionIncrement(firstAtPos ? 1:0);
-          firstAtPos = false;
-          //System.out.println("  add token=" + t + " startOff=" + t.startOffset() + " endOff=" + t.endOffset());
-          tokens.add(t);
-        }
-        pos += minPosLength;
-        offset = 2 * pos;
-      }
-      assert maxPos <= pos: "input string mal-formed: posLength>1 tokens hang over the end";
-    }
-  }
-
-  public void testMockGraphTokenFilterBasic() throws Exception {
-
-    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      checkAnalysisConsistency(random(), a, false, "a b c d e f g h i j k");
-    }
-  }
-
-  public void testMockGraphTokenFilterOnGraphInput() throws Exception {
-    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new GraphTokenizer();
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      checkAnalysisConsistency(random(), a, false, "a/x:3 c/y:2 d e f/z:4 g h i j k");
-    }
-  }
-
-  // Just deletes (leaving hole) token 'a':
-  private final static class RemoveATokens extends TokenFilter {
-    private int pendingPosInc;
-
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-
-    public RemoveATokens(TokenStream in) {
-      super(in);
-    }
-
-    @Override
-    public void reset() throws IOException {
-      super.reset();
-      pendingPosInc = 0;
-    }
-
-    @Override
-    public void end() throws IOException {
-      super.end();
-      posIncAtt.setPositionIncrement(pendingPosInc + posIncAtt.getPositionIncrement());
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      while (true) {
-        final boolean gotOne = input.incrementToken();
-        if (!gotOne) {
-          return false;
-        } else if (termAtt.toString().equals("a")) {
-          pendingPosInc += posIncAtt.getPositionIncrement();
-        } else {
-          posIncAtt.setPositionIncrement(pendingPosInc + posIncAtt.getPositionIncrement());
-          pendingPosInc = 0;
-          return true;
-        }
-      }
-    }
-  }
-
-  public void testMockGraphTokenFilterBeforeHoles() throws Exception {
-    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
-            final TokenStream t3 = new RemoveATokens(t2);
-            return new TokenStreamComponents(t, t3);
-          }
-        };
-
-      Random random = random();
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k");
-      checkAnalysisConsistency(random, a, false, "x y a b c d e f g h i j k");
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a");
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a x y");
-    }
-  }
-
-  public void testMockGraphTokenFilterAfterHoles() throws Exception {
-    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t2 = new RemoveATokens(t);
-            final TokenStream t3 = new MockGraphTokenFilter(random(), t2);
-            return new TokenStreamComponents(t, t3);
-          }
-        };
-
-      Random random = random();
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k");
-      checkAnalysisConsistency(random, a, false, "x y a b c d e f g h i j k");
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a");
-      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a x y");
-    }
-  }
-
-  public void testMockGraphTokenFilterRandom() throws Exception {
-    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      Random random = random();
-      checkRandomData(random, a, 5, atLeast(100));
-    }
-  }
-
-  // Two MockGraphTokenFilters
-  public void testDoubleMockGraphTokenFilterRandom() throws Exception {
-    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t1 = new MockGraphTokenFilter(random(), t);
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t1);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      Random random = random();
-      checkRandomData(random, a, 5, atLeast(100));
-    }
-  }
-
-  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {
-    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t1 = new MockGraphTokenFilter(random(), t);
-            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      Random random = random();
-      checkRandomData(random, a, 5, atLeast(100));
-    }
-  }
-
-  public void testMockGraphTokenFilterAfterHolesRandom() throws Exception {
-    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
-
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + iter);
-      }
-
-      // Make new analyzer each time, because MGTF has fixed
-      // seed:
-      final Analyzer a = new Analyzer() {
-          @Override
-          protected TokenStreamComponents createComponents(String fieldName) {
-            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-            final TokenStream t1 = new MockHoleInjectingTokenFilter(random(), t);
-            final TokenStream t2 = new MockGraphTokenFilter(random(), t1);
-            return new TokenStreamComponents(t, t2);
-          }
-        };
-      
-      Random random = random();
-      checkRandomData(random, a, 5, atLeast(100));
-    }
-  }
-
-  private static Token token(String term, int posInc, int posLength) {
-    final Token t = new Token(term, 0, 0);
-    t.setPositionIncrement(posInc);
-    t.setPositionLength(posLength);
-    return t;
-  }
-
-  private static Token token(String term, int posInc, int posLength, int startOffset, int endOffset) {
-    final Token t = new Token(term, startOffset, endOffset);
-    t.setPositionIncrement(posInc);
-    t.setPositionLength(posLength);
-    return t;
-  }
-
-  public void testSingleToken() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-      });
-    assertSameLanguage(s2a("abc"), ts);
-  }
-
-  public void testMultipleHoles() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("a", 1, 1),
-        token("b", 3, 1),
-      });
-    assertSameLanguage(join(s2a("a"), SEP_A, HOLE_A, SEP_A, HOLE_A, SEP_A, s2a("b")), ts);
-  }
-
-  public void testSynOverMultipleHoles() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("a", 1, 1),
-        token("x", 0, 3),
-        token("b", 3, 1),
-      });
-    final Automaton a1 = join(s2a("a"), SEP_A, HOLE_A, SEP_A, HOLE_A, SEP_A, s2a("b")); 
-    final Automaton a2 = join(s2a("x"), SEP_A, s2a("b")); 
-    assertSameLanguage(Operations.union(a1, a2), ts);
-  }
-
-  // for debugging!
-  /*
-  private static void toDot(Automaton a) throws IOException {
-    final String s = a.toDot();
-    Writer w = new OutputStreamWriter(new FileOutputStream("/x/tmp/out.dot"));
-    w.write(s);
-    w.close();
-    System.out.println("TEST: saved to /x/tmp/out.dot");
-  }
-  */
-
-  private static final Automaton SEP_A = Automata.makeChar(TokenStreamToAutomaton.POS_SEP);
-  private static final Automaton HOLE_A = Automata.makeChar(TokenStreamToAutomaton.HOLE);
-
-  private Automaton join(String ... strings) {
-    List<Automaton> as = new ArrayList<>();
-    for(String s : strings) {
-      as.add(s2a(s));
-      as.add(SEP_A);
-    }
-    as.remove(as.size()-1);
-    return Operations.concatenate(as);
-  }
-
-  private Automaton join(Automaton ... as) {
-    return Operations.concatenate(Arrays.asList(as));
-  }
-
-  private Automaton s2a(String s) {
-    return Automata.makeString(s);
-  }
-
-  public void testTwoTokens() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-        token("def", 1, 1),
-      });
-    assertSameLanguage(join("abc", "def"), ts);
-  }
-
-  public void testHole() throws Exception {
-
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-        token("def", 2, 1),
-      });
-    assertSameLanguage(join(s2a("abc"), SEP_A, HOLE_A, SEP_A, s2a("def")), ts);
-  }
-
-  public void testOverlappedTokensSausage() throws Exception {
-
-    // Two tokens on top of each other (sausage):
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-        token("xyz", 0, 1)
-      });
-    final Automaton a1 = s2a("abc");
-    final Automaton a2 = s2a("xyz");
-    assertSameLanguage(Operations.union(a1, a2), ts);
-  }
-
-  public void testOverlappedTokensLattice() throws Exception {
-
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-        token("xyz", 0, 2),
-        token("def", 1, 1),
-      });
-    final Automaton a1 = s2a("xyz");
-    final Automaton a2 = join("abc", "def");
-    assertSameLanguage(Operations.union(a1, a2), ts);
-  }
-
-  public void testSynOverHole() throws Exception {
-
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("a", 1, 1),
-        token("X", 0, 2),
-        token("b", 2, 1),
-      });
-    final Automaton a1 = Operations.union(join(s2a("a"), SEP_A, HOLE_A), s2a("X"));
-    final Automaton expected = Operations.concatenate(a1, join(SEP_A, s2a("b")));
-    assertSameLanguage(expected, ts);
-  }
-
-  public void testSynOverHole2() throws Exception {
-
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("xyz", 1, 1),
-        token("abc", 0, 3),
-        token("def", 2, 1),
-      });
-    final Automaton expected = Operations.union(
-      join(s2a("xyz"), SEP_A, HOLE_A, SEP_A, s2a("def")), s2a("abc"));
-    assertSameLanguage(expected, ts);
-  }
-
-  public void testOverlappedTokensLattice2() throws Exception {
-
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 1, 1),
-        token("xyz", 0, 3),
-        token("def", 1, 1),
-        token("ghi", 1, 1),
-      });
-    final Automaton a1 = s2a("xyz");
-    final Automaton a2 = join("abc", "def", "ghi");
-    assertSameLanguage(Operations.union(a1, a2), ts);
-  }
-
-  public void testToDot() throws Exception {
-    final TokenStream ts = new CannedTokenStream(new Token[] {token("abc", 1, 1, 0, 4)});
-    StringWriter w = new StringWriter();
-    new TokenStreamToDot("abcd", ts, new PrintWriter(w)).toDot();
-    assertTrue(w.toString().indexOf("abc / abcd") != -1);
-  }
-
-  public void testStartsWithHole() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("abc", 2, 1),
-      });
-    assertSameLanguage(join(HOLE_A, SEP_A, s2a("abc")), ts);
-  }
-
-  // TODO: testEndsWithHole... but we need posInc to set in TS.end()
-
-  public void testSynHangingOverEnd() throws Exception {
-    final TokenStream ts = new CannedTokenStream(
-      new Token[] {
-        token("a", 1, 1),
-        token("X", 0, 10),
-      });
-    assertSameLanguage(Operations.union(s2a("a"), s2a("X")), ts);
-  }
-
-  private void assertSameLanguage(Automaton expected, TokenStream ts) throws IOException {
-    assertSameLanguage(expected, new TokenStreamToAutomaton().toAutomaton(ts));
-  }
-
-  private void assertSameLanguage(Automaton expected, Automaton actual) {
-    assertTrue(Operations.sameLanguage(
-      Operations.determinize(Operations.removeDeadStates(expected), DEFAULT_MAX_DETERMINIZED_STATES),
-      Operations.determinize(Operations.removeDeadStates(actual), DEFAULT_MAX_DETERMINIZED_STATES)));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java
deleted file mode 100644
index 50539e5..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java
+++ /dev/null
@@ -1,98 +0,0 @@
-package org.apache.lucene.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.util.Random;
-
-public class TestLookaheadTokenFilter extends BaseTokenStreamTestCase {
-
-  public void testRandomStrings() throws Exception {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Random random = random();
-        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, random.nextBoolean());
-        TokenStream output = new MockRandomLookaheadTokenFilter(random, tokenizer);
-        return new TokenStreamComponents(tokenizer, output);
-      }
-    };
-    int maxLength = TEST_NIGHTLY ? 8192 : 1024;
-    checkRandomData(random(), a, 50*RANDOM_MULTIPLIER, maxLength);
-  }
-
-  private static class NeverPeeksLookaheadTokenFilter extends LookaheadTokenFilter<LookaheadTokenFilter.Position> {
-    public NeverPeeksLookaheadTokenFilter(TokenStream input) {
-      super(input);
-    }
-
-    @Override
-    public Position newPosition() {
-      return new Position();
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      return nextToken();
-    }
-  }
-
-  public void testNeverCallingPeek() throws Exception {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, random().nextBoolean());
-        TokenStream output = new NeverPeeksLookaheadTokenFilter(tokenizer);
-        return new TokenStreamComponents(tokenizer, output);
-      }
-    };
-    int maxLength = TEST_NIGHTLY ? 8192 : 1024;
-    checkRandomData(random(), a, 50*RANDOM_MULTIPLIER, maxLength);
-  }
-
-  public void testMissedFirstToken() throws Exception {
-    Analyzer analyzer = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Tokenizer source = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-        TrivialLookaheadFilter filter = new TrivialLookaheadFilter(source);
-        return new TokenStreamComponents(source, filter);
-     }
-    };
-
-    assertAnalyzesTo(analyzer,
-        "Only he who is running knows .",
-        new String[]{
-            "Only",
-            "Only-huh?",
-            "he",
-            "he-huh?",
-            "who",
-            "who-huh?",
-            "is",
-            "is-huh?",
-            "running",
-            "running-huh?",
-            "knows",
-            "knows-huh?",
-            ".",
-            ".-huh?"
-        });
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java b/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
deleted file mode 100644
index 5d3b756..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
+++ /dev/null
@@ -1,338 +0,0 @@
-package org.apache.lucene.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-import java.util.Arrays;
-import java.util.Random;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.index.PostingsEnum;
-import org.apache.lucene.index.Fields;
-import org.apache.lucene.index.IndexOptions;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.TestUtil;
-import org.apache.lucene.util.automaton.Automata;
-import org.apache.lucene.util.automaton.AutomatonTestUtil;
-import org.apache.lucene.util.automaton.CharacterRunAutomaton;
-import org.apache.lucene.util.automaton.Operations;
-import org.apache.lucene.util.automaton.RegExp;
-
-import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZED_STATES;
-
-public class TestMockAnalyzer extends BaseTokenStreamTestCase {
-
-  /** Test a configuration that behaves a lot like WhitespaceAnalyzer */
-  public void testWhitespace() throws Exception {
-    Analyzer a = new MockAnalyzer(random());
-    assertAnalyzesTo(a, "A bc defg hiJklmn opqrstuv wxy z ",
-        new String[] { "a", "bc", "defg", "hijklmn", "opqrstuv", "wxy", "z" });
-    assertAnalyzesTo(a, "aba cadaba shazam",
-        new String[] { "aba", "cadaba", "shazam" });
-    assertAnalyzesTo(a, "break on whitespace",
-        new String[] { "break", "on", "whitespace" });
-  }
-  
-  /** Test a configuration that behaves a lot like SimpleAnalyzer */
-  public void testSimple() throws Exception {
-    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);
-    assertAnalyzesTo(a, "a-bc123 defg+hijklmn567opqrstuv78wxy_z ",
-        new String[] { "a", "bc", "defg", "hijklmn", "opqrstuv", "wxy", "z" });
-    assertAnalyzesTo(a, "aba4cadaba-Shazam",
-        new String[] { "aba", "cadaba", "shazam" });
-    assertAnalyzesTo(a, "break+on/Letters",
-        new String[] { "break", "on", "letters" });
-  }
-  
-  /** Test a configuration that behaves a lot like KeywordAnalyzer */
-  public void testKeyword() throws Exception {
-    Analyzer a = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);
-    assertAnalyzesTo(a, "a-bc123 defg+hijklmn567opqrstuv78wxy_z ",
-        new String[] { "a-bc123 defg+hijklmn567opqrstuv78wxy_z " });
-    assertAnalyzesTo(a, "aba4cadaba-Shazam",
-        new String[] { "aba4cadaba-Shazam" });
-    assertAnalyzesTo(a, "break+on/Nothing",
-        new String[] { "break+on/Nothing" });
-    // currently though emits no tokens for empty string: maybe we can do it,
-    // but we don't want to emit tokens infinitely...
-    assertAnalyzesTo(a, "", new String[0]);
-  }
-  
-  // Test some regular expressions as tokenization patterns
-  /** Test a configuration where each character is a term */
-  public void testSingleChar() throws Exception {
-    CharacterRunAutomaton single =
-        new CharacterRunAutomaton(new RegExp(".").toAutomaton());
-    Analyzer a = new MockAnalyzer(random(), single, false);
-    assertAnalyzesTo(a, "foobar",
-        new String[] { "f", "o", "o", "b", "a", "r" },
-        new int[] { 0, 1, 2, 3, 4, 5 },
-        new int[] { 1, 2, 3, 4, 5, 6 }
-    );
-    checkRandomData(random(), a, 100);
-  }
-  
-  /** Test a configuration where two characters makes a term */
-  public void testTwoChars() throws Exception {
-    CharacterRunAutomaton single =
-        new CharacterRunAutomaton(new RegExp("..").toAutomaton());
-    Analyzer a = new MockAnalyzer(random(), single, false);
-    assertAnalyzesTo(a, "foobar",
-        new String[] { "fo", "ob", "ar"},
-        new int[] { 0, 2, 4 },
-        new int[] { 2, 4, 6 }
-    );
-    // make sure when last term is a "partial" match that end() is correct
-    assertTokenStreamContents(a.tokenStream("bogus", "fooba"),
-        new String[] { "fo", "ob" },
-        new int[] { 0, 2 },
-        new int[] { 2, 4 },
-        new int[] { 1, 1 },
-        new Integer(5)
-    );
-    checkRandomData(random(), a, 100);
-  }
-  
-  /** Test a configuration where three characters makes a term */
-  public void testThreeChars() throws Exception {
-    CharacterRunAutomaton single =
-        new CharacterRunAutomaton(new RegExp("...").toAutomaton());
-    Analyzer a = new MockAnalyzer(random(), single, false);
-    assertAnalyzesTo(a, "foobar",
-        new String[] { "foo", "bar"},
-        new int[] { 0, 3 },
-        new int[] { 3, 6 }
-    );
-    // make sure when last term is a "partial" match that end() is correct
-    assertTokenStreamContents(a.tokenStream("bogus", "fooba"),
-        new String[] { "foo" },
-        new int[] { 0 },
-        new int[] { 3 },
-        new int[] { 1 },
-        new Integer(5)
-    );
-    checkRandomData(random(), a, 100);
-  }
-  
-  /** Test a configuration where word starts with one uppercase */
-  public void testUppercase() throws Exception {
-    CharacterRunAutomaton single =
-        new CharacterRunAutomaton(new RegExp("[A-Z][a-z]*").toAutomaton());
-    Analyzer a = new MockAnalyzer(random(), single, false);
-    assertAnalyzesTo(a, "FooBarBAZ",
-        new String[] { "Foo", "Bar", "B", "A", "Z"},
-        new int[] { 0, 3, 6, 7, 8 },
-        new int[] { 3, 6, 7, 8, 9 }
-    );
-    assertAnalyzesTo(a, "aFooBar",
-        new String[] { "Foo", "Bar" },
-        new int[] { 1, 4 },
-        new int[] { 4, 7 }
-    );
-    checkRandomData(random(), a, 100);
-  }
-  
-  /** Test a configuration that behaves a lot like StopAnalyzer */
-  public void testStop() throws Exception {
-    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);
-    assertAnalyzesTo(a, "the quick brown a fox",
-        new String[] { "quick", "brown", "fox" },
-        new int[] { 2, 1, 2 });
-  }
-  
-  /** Test a configuration that behaves a lot like KeepWordFilter */
-  public void testKeep() throws Exception {
-    CharacterRunAutomaton keepWords = 
-      new CharacterRunAutomaton(
-          Operations.complement(
-              Operations.union(
-                  Arrays.asList(Automata.makeString("foo"), Automata.makeString("bar"))),
-              DEFAULT_MAX_DETERMINIZED_STATES));
-    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, keepWords);
-    assertAnalyzesTo(a, "quick foo brown bar bar fox foo",
-        new String[] { "foo", "bar", "bar", "foo" },
-        new int[] { 2, 2, 1, 2 });
-  }
-  
-  /** Test a configuration that behaves a lot like LengthFilter */
-  public void testLength() throws Exception {
-    CharacterRunAutomaton length5 = new CharacterRunAutomaton(new RegExp(".{5,}").toAutomaton());
-    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, length5);
-    assertAnalyzesTo(a, "ok toolong fine notfine",
-        new String[] { "ok", "fine" },
-        new int[] { 1, 2 });
-  }
-  
-  /** Test MockTokenizer encountering a too long token */
-  public void testTooLongToken() throws Exception {
-    Analyzer whitespace = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false, 5);
-        return new TokenStreamComponents(t, t);
-      }
-    };
-    
-    assertTokenStreamContents(whitespace.tokenStream("bogus", "test 123 toolong ok "),
-        new String[] { "test", "123", "toolo", "ng", "ok" },
-        new int[] { 0, 5, 9, 14, 17 },
-        new int[] { 4, 8, 14, 16, 19 },
-        new Integer(20));
-    
-    assertTokenStreamContents(whitespace.tokenStream("bogus", "test 123 toolo"),
-        new String[] { "test", "123", "toolo" },
-        new int[] { 0, 5, 9 },
-        new int[] { 4, 8, 14 },
-        new Integer(14));
-  }
-  
-  public void testLUCENE_3042() throws Exception {
-    String testString = "t";
-    
-    Analyzer analyzer = new MockAnalyzer(random());
-    try (TokenStream stream = analyzer.tokenStream("dummy", testString)) {
-      stream.reset();
-      while (stream.incrementToken()) {
-        // consume
-      }
-      stream.end();
-    }
-    
-    assertAnalyzesTo(analyzer, testString, new String[] { "t" });
-  }
-
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random(), new MockAnalyzer(random()), atLeast(1000));
-  }
-  
-  /** blast some random strings through differently configured tokenizers */
-  public void testRandomRegexps() throws Exception {
-    int iters = TEST_NIGHTLY ? atLeast(30) : atLeast(1);
-    for (int i = 0; i < iters; i++) {
-      final CharacterRunAutomaton dfa = new CharacterRunAutomaton(AutomatonTestUtil.randomAutomaton(random()), Integer.MAX_VALUE);
-      final boolean lowercase = random().nextBoolean();
-      final int limit = TestUtil.nextInt(random(), 0, 500);
-      Analyzer a = new Analyzer() {
-        @Override
-        protected TokenStreamComponents createComponents(String fieldName) {
-          Tokenizer t = new MockTokenizer(dfa, lowercase, limit);
-          return new TokenStreamComponents(t, t);
-        }
-      };
-      checkRandomData(random(), a, 100);
-      a.close();
-    }
-  }
-  
-  public void testForwardOffsets() throws Exception {
-    int num = atLeast(1000);
-    for (int i = 0; i < num; i++) {
-      String s = TestUtil.randomHtmlishString(random(), 20);
-      StringReader reader = new StringReader(s);
-      MockCharFilter charfilter = new MockCharFilter(reader, 2);
-      MockAnalyzer analyzer = new MockAnalyzer(random());
-      try (TokenStream ts = analyzer.tokenStream("bogus", charfilter)) {
-        ts.reset();
-        while (ts.incrementToken()) {
-          ;
-        }
-        ts.end();
-      }
-    }
-  }
-  
-  public void testWrapReader() throws Exception {
-    // LUCENE-5153: test that wrapping an analyzer's reader is allowed
-    final Random random = random();
-    
-    final Analyzer delegate = new MockAnalyzer(random);
-    Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {
-      
-      @Override
-      protected Reader wrapReader(String fieldName, Reader reader) {
-        return new MockCharFilter(reader, 7);
-      }
-      
-      @Override
-      protected Analyzer getWrappedAnalyzer(String fieldName) {
-        return delegate;
-      }
-    };
-    
-    checkOneTerm(a, "abc", "aabc");
-  }
-
-  public void testChangeGaps() throws Exception {
-    // LUCENE-5324: check that it is possible to change the wrapper's gaps
-    final int positionGap = random().nextInt(1000);
-    final int offsetGap = random().nextInt(1000);
-    final Analyzer delegate = new MockAnalyzer(random());
-    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {
-      @Override
-      protected Analyzer getWrappedAnalyzer(String fieldName) {
-        return delegate;
-      }
-      @Override
-      public int getPositionIncrementGap(String fieldName) {
-        return positionGap;
-      }
-      @Override
-      public int getOffsetGap(String fieldName) {
-        return offsetGap;
-      }
-    };
-
-    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);
-    final Document doc = new Document();
-    final FieldType ft = new FieldType();
-    ft.setIndexOptions(IndexOptions.DOCS);
-    ft.setTokenized(true);
-    ft.setStoreTermVectors(true);
-    ft.setStoreTermVectorPositions(true);
-    ft.setStoreTermVectorOffsets(true);
-    doc.add(new Field("f", "a", ft));
-    doc.add(new Field("f", "a", ft));
-    writer.addDocument(doc);
-    final LeafReader reader = getOnlySegmentReader(writer.getReader());
-    final Fields fields = reader.getTermVectors(0);
-    final Terms terms = fields.terms("f");
-    final TermsEnum te = terms.iterator();
-    assertEquals(new BytesRef("a"), te.next());
-    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);
-    assertEquals(0, dpe.nextDoc());
-    assertEquals(2, dpe.freq());
-    assertEquals(0, dpe.nextPosition());
-    assertEquals(0, dpe.startOffset());
-    final int endOffset = dpe.endOffset();
-    assertEquals(1 + positionGap, dpe.nextPosition());
-    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());
-    assertEquals(null, te.next());
-    reader.close();
-    writer.close();
-    writer.w.getDirectory().close();
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
deleted file mode 100644
index 617e6dc..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
+++ /dev/null
@@ -1,58 +0,0 @@
-package org.apache.lucene.analysis;
-
-import java.io.IOException;
-import java.io.Reader;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestMockCharFilter extends BaseTokenStreamTestCase {
-  
-  public void test() throws IOException {
-    Analyzer analyzer = new Analyzer() {
-
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName) {
-        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);
-        return new TokenStreamComponents(tokenizer, tokenizer);
-      }
-
-      @Override
-      protected Reader initReader(String fieldName, Reader reader) {
-        return new MockCharFilter(reader, 7);
-      }
-    };
-    
-    assertAnalyzesTo(analyzer, "ab",
-        new String[] { "aab" },
-        new int[] { 0 },
-        new int[] { 2 }
-    );
-    
-    assertAnalyzesTo(analyzer, "aba",
-        new String[] { "aabaa" },
-        new int[] { 0 },
-        new int[] { 3 }
-    );
-    
-    assertAnalyzesTo(analyzer, "abcdefga",
-        new String[] { "aabcdefgaa" },
-        new int[] { 0 },
-        new int[] { 8 }
-    );
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestPosition.java b/lucene/core/src/test/org/apache/lucene/analysis/TestPosition.java
deleted file mode 100644
index 389768b..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestPosition.java
+++ /dev/null
@@ -1,37 +0,0 @@
-package org.apache.lucene.analysis;
-
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.junit.Ignore;
-
-/**
- * Trivial position class.
- */
-@Ignore
-public class TestPosition extends LookaheadTokenFilter.Position {
-  private String fact;
-
-  public String getFact() {
-    return fact;
-  }
-
-  public void setFact(String fact) {
-    this.fact = fact;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java
deleted file mode 100644
index cf50927..0000000
--- a/lucene/core/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java
+++ /dev/null
@@ -1,104 +0,0 @@
-package org.apache.lucene.analysis;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-
-/**
- * Simple example of a filter that seems to show some problems with LookaheadTokenFilter.
- */
-final public class TrivialLookaheadFilter extends LookaheadTokenFilter<TestPosition> {
-
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-
-  private int insertUpto;
-
-  protected TrivialLookaheadFilter(TokenStream input) {
-    super(input);
-  }
-
-  @Override
-  protected TestPosition newPosition() {
-    return new TestPosition();
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    // At the outset, getMaxPos is -1. So we'll peek. When we reach the end of the sentence and go to the
-    // first token of the next sentence, maxPos will be the prev sentence's end token, and we'll go again.
-    if (positions.getMaxPos() < outputPos) {
-      peekSentence();
-    }
-
-    return nextToken();
-  }
-
-  @Override
-  public void reset() throws IOException {
-    super.reset();
-    insertUpto = -1;
-  }
-
-  @Override
-  protected void afterPosition() throws IOException {
-    if (insertUpto < outputPos) {
-      insertToken();
-      // replace term with 'improved' term.
-      clearAttributes();
-      termAtt.setEmpty();
-      posIncAtt.setPositionIncrement(0);
-      termAtt.append(positions.get(outputPos).getFact());
-      offsetAtt.setOffset(positions.get(outputPos).startOffset,
-                          positions.get(outputPos+1).endOffset);
-      insertUpto = outputPos;
-    }
-  }
-
-  private void peekSentence() throws IOException {
-    List<String> facts = new ArrayList<>();
-    boolean haveSentence = false;
-    do {
-      if (peekToken()) {
-
-        String term = new String(termAtt.buffer(), 0, termAtt.length());
-        facts.add(term + "-huh?");
-        if (".".equals(term)) {
-          haveSentence = true;
-        }
-
-      } else {
-        haveSentence = true;
-      }
-
-    } while (!haveSentence);
-
-    // attach the (now disambiguated) analyzed tokens to the positions.
-    for (int x = 0; x < facts.size(); x++) {
-      // sentenceTokens is just relative to sentence, positions is absolute.
-      positions.get(outputPos + x).setFact(facts.get(x));
-    }
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java
deleted file mode 100644
index b6a2c61..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java
+++ /dev/null
@@ -1,36 +0,0 @@
-package org.apache.lucene.codecs.asserting;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.BasePostingsFormatTestCase;
-
-/** Test AssertingPostingsFormat directly */
-public class TestAssertingDocValuesFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = new AssertingCodec();
-  
-  @Override
-  protected Codec getCodec() {
-    return codec;
-  }
-
-  @Override
-  protected boolean isPostingsEnumReuseImplemented() {
-    return false;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java
deleted file mode 100644
index d5adad0..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java
+++ /dev/null
@@ -1,31 +0,0 @@
-package org.apache.lucene.codecs.asserting;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.BaseNormsFormatTestCase;
-
-/** Test AssertingNormsFormat directly */
-public class TestAssertingNormsFormat extends BaseNormsFormatTestCase {
-  private final Codec codec = new AssertingCodec();
-  
-  @Override
-  protected Codec getCodec() {
-    return codec;
-  } 
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java
deleted file mode 100644
index 7c78596..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java
+++ /dev/null
@@ -1,36 +0,0 @@
-package org.apache.lucene.codecs.asserting;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.BasePostingsFormatTestCase;
-
-/** Test AssertingPostingsFormat directly */
-public class TestAssertingPostingsFormat extends BasePostingsFormatTestCase {
-  private final Codec codec = new AssertingCodec();
-  
-  @Override
-  protected Codec getCodec() {
-    return codec;
-  }
-
-  @Override
-  protected boolean isPostingsEnumReuseImplemented() {
-    return false;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java
deleted file mode 100644
index 73fcf93..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java
+++ /dev/null
@@ -1,31 +0,0 @@
-package org.apache.lucene.codecs.asserting;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.BaseTermVectorsFormatTestCase;
-
-/** Test AssertingTermVectorsFormat directly */
-public class TestAssertingStoredFieldsFormat extends BaseTermVectorsFormatTestCase {
-  private final Codec codec = new AssertingCodec();
-  
-  @Override
-  protected Codec getCodec() {
-    return codec;
-  } 
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java
deleted file mode 100644
index 2717efd..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java
+++ /dev/null
@@ -1,31 +0,0 @@
-package org.apache.lucene.codecs.asserting;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.index.BaseStoredFieldsFormatTestCase;
-
-/** Test AssertingStoredFieldsFormat directly */
-public class TestAssertingTermVectorsFormat extends BaseStoredFieldsFormatTestCase {
-  private final Codec codec = new AssertingCodec();
-  
-  @Override
-  protected Codec getCodec() {
-    return codec;
-  } 
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
deleted file mode 100644
index 2afda04..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
+++ /dev/null
@@ -1,322 +0,0 @@
-package org.apache.lucene.codecs.compressing;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Random;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.IntField;
-import org.apache.lucene.document.StoredField;
-import org.apache.lucene.index.BaseStoredFieldsFormatTestCase;
-import org.apache.lucene.index.CodecReader;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.store.ByteArrayDataInput;
-import org.apache.lucene.store.ByteArrayDataOutput;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.MockDirectoryWrapper;
-import org.junit.Test;
-
-import com.carrotsearch.randomizedtesting.generators.RandomInts;
-
-public class TestCompressingStoredFieldsFormat extends BaseStoredFieldsFormatTestCase {
-
-  static final long SECOND = 1000L;
-  static final long HOUR = 60 * 60 * SECOND;
-  static final long DAY = 24 * HOUR;
-
-  @Override
-  protected Codec getCodec() {
-    return CompressingCodec.randomInstance(random());
-  }
-
-  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {
-    Directory dir = newDirectory();
-    // test explicitly needs files to always be actually deleted
-    if (dir instanceof MockDirectoryWrapper) {
-      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);
-    }
-    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
-    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));
-    iwConf.setCodec(CompressingCodec.randomInstance(random()));
-    // disable CFS because this test checks file names
-    iwConf.setMergePolicy(newLogMergePolicy(false));
-    iwConf.setUseCompoundFile(false);
-
-    // Cannot use RIW because this test wants CFS to stay off:
-    IndexWriter iw = new IndexWriter(dir, iwConf);
-
-    final Document validDoc = new Document();
-    validDoc.add(new IntField("id", 0, Store.YES));
-    iw.addDocument(validDoc);
-    iw.commit();
-    
-    // make sure that #writeField will fail to trigger an abort
-    final Document invalidDoc = new Document();
-    FieldType fieldType = new FieldType();
-    fieldType.setStored(true);
-    invalidDoc.add(new Field("invalid", fieldType) {
-      
-      @Override
-      public String stringValue() {
-        // TODO: really bad & scary that this causes IW to
-        // abort the segment!!  We should fix this.
-        return null;
-      }
-      
-    });
-    
-    try {
-      iw.addDocument(invalidDoc);
-      iw.commit();
-    } catch(IllegalArgumentException iae) {
-      // expected
-      assertEquals(iae, iw.getTragicException());
-    }
-    // Writer should be closed by tragedy
-    assertFalse(iw.isOpen());
-    dir.close();
-  }
-
-  public void testZFloat() throws Exception {
-    byte buffer[] = new byte[5]; // we never need more than 5 bytes
-    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
-    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
-
-    // round-trip small integer values
-    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
-      float f = (float) i;
-      CompressingStoredFieldsWriter.writeZFloat(out, f);
-      in.reset(buffer, 0, out.getPosition());
-      float g = CompressingStoredFieldsReader.readZFloat(in);
-      assertTrue(in.eof());
-      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
-
-      // check that compression actually works
-      if (i >= -1 && i <= 123) {
-        assertEquals(1, out.getPosition()); // single byte compression
-      }
-      out.reset(buffer);
-    }
-
-    // round-trip special values
-    float special[] = {
-        -0.0f,
-        +0.0f,
-        Float.NEGATIVE_INFINITY,
-        Float.POSITIVE_INFINITY,
-        Float.MIN_VALUE,
-        Float.MAX_VALUE,
-        Float.NaN,
-    };
-
-    for (float f : special) {
-      CompressingStoredFieldsWriter.writeZFloat(out, f);
-      in.reset(buffer, 0, out.getPosition());
-      float g = CompressingStoredFieldsReader.readZFloat(in);
-      assertTrue(in.eof());
-      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
-      out.reset(buffer);
-    }
-
-    // round-trip random values
-    Random r = random();
-    for (int i = 0; i < 100000; i++) {
-      float f = r.nextFloat() * (random().nextInt(100) - 50);
-      CompressingStoredFieldsWriter.writeZFloat(out, f);
-      assertTrue("length=" + out.getPosition() + ", f=" + f, out.getPosition() <= ((Float.floatToIntBits(f) >>> 31) == 1 ? 5 : 4));
-      in.reset(buffer, 0, out.getPosition());
-      float g = CompressingStoredFieldsReader.readZFloat(in);
-      assertTrue(in.eof());
-      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
-      out.reset(buffer);
-    }
-  }
-
-  public void testZDouble() throws Exception {
-    byte buffer[] = new byte[9]; // we never need more than 9 bytes
-    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
-    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
-
-    // round-trip small integer values
-    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
-      double x = (double) i;
-      CompressingStoredFieldsWriter.writeZDouble(out, x);
-      in.reset(buffer, 0, out.getPosition());
-      double y = CompressingStoredFieldsReader.readZDouble(in);
-      assertTrue(in.eof());
-      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
-
-      // check that compression actually works
-      if (i >= -1 && i <= 124) {
-        assertEquals(1, out.getPosition()); // single byte compression
-      }
-      out.reset(buffer);
-    }
-
-    // round-trip special values
-    double special[] = {
-        -0.0d,
-        +0.0d,
-        Double.NEGATIVE_INFINITY,
-        Double.POSITIVE_INFINITY,
-        Double.MIN_VALUE,
-        Double.MAX_VALUE,
-        Double.NaN
-    };
-
-    for (double x : special) {
-      CompressingStoredFieldsWriter.writeZDouble(out, x);
-      in.reset(buffer, 0, out.getPosition());
-      double y = CompressingStoredFieldsReader.readZDouble(in);
-      assertTrue(in.eof());
-      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
-      out.reset(buffer);
-    }
-
-    // round-trip random values
-    Random r = random();
-    for (int i = 0; i < 100000; i++) {
-      double x = r.nextDouble() * (random().nextInt(100) - 50);
-      CompressingStoredFieldsWriter.writeZDouble(out, x);
-      assertTrue("length=" + out.getPosition() + ", d=" + x, out.getPosition() <= (x < 0 ? 9 : 8));
-      in.reset(buffer, 0, out.getPosition());
-      double y = CompressingStoredFieldsReader.readZDouble(in);
-      assertTrue(in.eof());
-      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
-      out.reset(buffer);
-    }
-
-    // same with floats
-    for (int i = 0; i < 100000; i++) {
-      double x = (double) (r.nextFloat() * (random().nextInt(100) - 50));
-      CompressingStoredFieldsWriter.writeZDouble(out, x);
-      assertTrue("length=" + out.getPosition() + ", d=" + x, out.getPosition() <= 5);
-      in.reset(buffer, 0, out.getPosition());
-      double y = CompressingStoredFieldsReader.readZDouble(in);
-      assertTrue(in.eof());
-      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
-      out.reset(buffer);
-    }
-  }
-
-  public void testTLong() throws Exception {
-    byte buffer[] = new byte[10]; // we never need more than 10 bytes
-    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
-    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
-
-    // round-trip small integer values
-    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
-      for (long mul : new long[] {SECOND, HOUR, DAY}) {
-        long l1 = (long) i * mul;
-        CompressingStoredFieldsWriter.writeTLong(out, l1);
-        in.reset(buffer, 0, out.getPosition());
-        long l2 = CompressingStoredFieldsReader.readTLong(in);
-        assertTrue(in.eof());
-        assertEquals(l1, l2);
-
-        // check that compression actually works
-        if (i >= -16 && i <= 15) {
-          assertEquals(1, out.getPosition()); // single byte compression
-        }
-        out.reset(buffer);
-      }
-    }
-
-    // round-trip random values
-    Random r = random();
-    for (int i = 0; i < 100000; i++) {
-      final int numBits = r.nextInt(65);
-      long l1 = r.nextLong() & ((1L << numBits) - 1);
-      switch (r.nextInt(4)) {
-        case 0:
-          l1 *= SECOND;
-          break;
-        case 1:
-          l1 *= HOUR;
-          break;
-        case 2:
-          l1 *= DAY;
-          break;
-        default:
-          break;
-      }
-      CompressingStoredFieldsWriter.writeTLong(out, l1);
-      in.reset(buffer, 0, out.getPosition());
-      long l2 = CompressingStoredFieldsReader.readTLong(in);
-      assertTrue(in.eof());
-      assertEquals(l1, l2);
-      out.reset(buffer);
-    }
-  }
-  
-  /**
-   * writes some tiny segments with incomplete compressed blocks,
-   * and ensures merge recompresses them.
-   */
-  public void testChunkCleanup() throws IOException {
-    Directory dir = newDirectory();
-    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
-    iwConf.setMergePolicy(NoMergePolicy.INSTANCE);
-    
-    // we have to enforce certain things like maxDocsPerChunk to cause dirty chunks to be created
-    // by this test.
-    iwConf.setCodec(CompressingCodec.randomInstance(random(), 4*1024, 100, false, 8));
-    IndexWriter iw = new IndexWriter(dir, iwConf);
-    DirectoryReader ir = DirectoryReader.open(iw, true);
-    for (int i = 0; i < 5; i++) {
-      Document doc = new Document();
-      doc.add(new StoredField("text", "not very long at all"));
-      iw.addDocument(doc);
-      // force flush
-      DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
-      assertNotNull(ir2);
-      ir.close();
-      ir = ir2;
-      // examine dirty counts:
-      for (LeafReaderContext leaf : ir2.leaves()) {
-        CodecReader sr = (CodecReader) leaf.reader();
-        CompressingStoredFieldsReader reader = (CompressingStoredFieldsReader)sr.getFieldsReader();
-        assertEquals(1, reader.getNumChunks());
-        assertEquals(1, reader.getNumDirtyChunks());
-      }
-    }
-    iw.getConfig().setMergePolicy(newLogMergePolicy());
-    iw.forceMerge(1);
-    DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
-    assertNotNull(ir2);
-    ir.close();
-    ir = ir2;
-    CodecReader sr = getOnlySegmentReader(ir);
-    CompressingStoredFieldsReader reader = (CompressingStoredFieldsReader)sr.getFieldsReader();
-    // we could get lucky, and have zero, but typically one.
-    assertTrue(reader.getNumDirtyChunks() <= 1);
-    ir.close();
-    iw.close();
-    dir.close();
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java b/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java
deleted file mode 100644
index 7cfbe21..0000000
--- a/lucene/core/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java
+++ /dev/null
@@ -1,130 +0,0 @@
-package org.apache.lucene.codecs.compressing;
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.codecs.Codec;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldType;
-import org.apache.lucene.document.StoredField;
-import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.CodecReader;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.BaseTermVectorsFormatTestCase;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.NoMergePolicy;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.TermsEnum.SeekStatus;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BytesRef;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestCompressingTermVectorsFormat extends BaseTermVectorsFormatTestCase {
-
-  @Override
-  protected Codec getCodec() {
-    return CompressingCodec.randomInstance(random());
-  }
-  
-  // https://issues.apache.org/jira/browse/LUCENE-5156
-  public void testNoOrds() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
-    ft.setStoreTermVectors(true);
-    doc.add(new Field("foo", "this is a test", ft));
-    iw.addDocument(doc);
-    LeafReader ir = getOnlySegmentReader(iw.getReader());
-    Terms terms = ir.getTermVector(0, "foo");
-    assertNotNull(terms);
-    TermsEnum termsEnum = terms.iterator();
-    assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef("this")));
-    try {
-      termsEnum.ord();
-      fail();
-    } catch (UnsupportedOperationException expected) {
-      // expected exception
-    }
-    
-    try {
-      termsEnum.seekExact(0);
-      fail();
-    } catch (UnsupportedOperationException expected) {
-      // expected exception
-    }
-    ir.close();
-    iw.close();
-    dir.close();
-  }
-  
-  /**
-   * writes some tiny segments with incomplete compressed blocks,
-   * and ensures merge recompresses them.
-   */
-  public void testChunkCleanup() throws IOException {
-    Directory dir = newDirectory();
-    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
-    iwConf.setMergePolicy(NoMergePolicy.INSTANCE);
-    
-    // we have to enforce certain things like maxDocsPerChunk to cause dirty chunks to be created
-    // by this test.
-    iwConf.setCodec(CompressingCodec.randomInstance(random(), 4*1024, 100, false, 8));
-    IndexWriter iw = new IndexWriter(dir, iwConf);
-    DirectoryReader ir = DirectoryReader.open(iw, true);
-    for (int i = 0; i < 5; i++) {
-      Document doc = new Document();
-      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
-      ft.setStoreTermVectors(true);
-      doc.add(new Field("text", "not very long at all", ft));
-      iw.addDocument(doc);
-      // force flush
-      DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
-      assertNotNull(ir2);
-      ir.close();
-      ir = ir2;
-      // examine dirty counts:
-      for (LeafReaderContext leaf : ir2.leaves()) {
-        CodecReader sr = (CodecReader) leaf.reader();
-        CompressingTermVectorsReader reader = (CompressingTermVectorsReader)sr.getTermVectorsReader();
-        assertEquals(1, reader.getNumChunks());
-        assertEquals(1, reader.getNumDirtyChunks());
-      }
-    }
-    iw.getConfig().setMergePolicy(newLogMergePolicy());
-    iw.forceMerge(1);
-    DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
-    assertNotNull(ir2);
-    ir.close();
-    ir = ir2;
-    CodecReader sr = getOnlySegmentReader(ir);
-    CompressingTermVectorsReader reader = (CompressingTermVectorsReader)sr.getTermVectorsReader();
-    // we could get lucky, and have zero, but typically one.
-    assertTrue(reader.getNumDirtyChunks() <= 1);
-    ir.close();
-    iw.close();
-    dir.close();
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java b/lucene/core/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java
deleted file mode 100644
index d3f6b90..0000000
--- a/lucene/core/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java
+++ /dev/null
@@ -1,379 +0,0 @@
-package org.apache.lucene.mockfile;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.net.URI;
-import java.nio.channels.AsynchronousFileChannel;
-import java.nio.channels.FileChannel;
-import java.nio.channels.SeekableByteChannel;
-import java.nio.charset.Charset;
-import java.nio.file.DirectoryStream;
-import java.nio.file.FileSystem;
-import java.nio.file.Files;
-import java.nio.file.NoSuchFileException;
-import java.nio.file.Path;
-import java.nio.file.StandardCopyOption;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-import org.apache.lucene.util.Constants;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.InfoStream;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestMockFilesystems extends LuceneTestCase {
-  
-  public void testLeakInputStream() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    InputStream leak = Files.newInputStream(wrapped.resolve("stillopen"));
-    try {
-      fs.close();
-      fail("should have gotten exception");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("file handle leaks"));
-    }
-    leak.close();
-  }
-  
-  public void testLeakOutputStream() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream leak = Files.newOutputStream(wrapped.resolve("leaky"));
-    try {
-      fs.close();
-      fail("should have gotten exception");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("file handle leaks"));
-    }
-    leak.close();
-  }
-  
-  public void testLeakFileChannel() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    FileChannel leak = FileChannel.open(wrapped.resolve("stillopen"));
-    try {
-      fs.close();
-      fail("should have gotten exception");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("file handle leaks"));
-    }
-    leak.close();
-  }
-  
-  public void testLeakAsyncFileChannel() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    AsynchronousFileChannel leak = AsynchronousFileChannel.open(wrapped.resolve("stillopen"));
-    try {
-      fs.close();
-      fail("should have gotten exception");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("file handle leaks"));
-    }
-    leak.close();
-  }
-  
-  public void testLeakByteChannel() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    SeekableByteChannel leak = Files.newByteChannel(wrapped.resolve("stillopen"));
-    try {
-      fs.close();
-      fail("should have gotten exception");
-    } catch (Exception e) {
-      assertTrue(e.getMessage().contains("file handle leaks"));
-    }
-    leak.close();
-  }
- 
-  public void testDeleteOpenFile() throws IOException {
-    assumeFalse("windows is not supported", Constants.WINDOWS);
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
-    try {
-      Files.delete(wrapped.resolve("stillopen"));
-      fail("should have gotten exception");
-    } catch (IOException e) {
-      assertTrue(e.getMessage().contains("access denied"));
-    }
-    is.close();
-  }
-  
-  public void testDeleteIfExistsOpenFile() throws IOException {
-    assumeFalse("windows is not supported", Constants.WINDOWS);
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
-    try {
-      Files.deleteIfExists(wrapped.resolve("stillopen"));
-      fail("should have gotten exception");
-    } catch (IOException e) {
-      assertTrue(e.getMessage().contains("access denied"));
-    }
-    is.close();
-  }
-  
-  public void testRenameOpenFile() throws IOException {
-    assumeFalse("windows is not supported", Constants.WINDOWS);
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
-    file.write(5);
-    file.close();
-    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
-    try {
-      Files.move(wrapped.resolve("stillopen"), wrapped.resolve("target"), StandardCopyOption.ATOMIC_MOVE);
-      fail("should have gotten exception");
-    } catch (IOException e) {
-      assertTrue(e.getMessage().contains("access denied"));
-    }
-    is.close();
-  }
-  
-  public void testVerboseWrite() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    final AtomicBoolean seenMessage = new AtomicBoolean(false);
-    InfoStream testStream = new InfoStream() {
-      @Override
-      public void close() throws IOException {}
-
-      @Override
-      public void message(String component, String message) {
-        if ("FS".equals(component) && message.startsWith("newOutputStream")) {
-          seenMessage.set(true);
-        }
-      }
-
-      @Override
-      public boolean isEnabled(String component) {
-        return true;
-      }
-    };
-    FileSystem fs = new VerboseFS(dir.getFileSystem(), testStream).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-    
-    OutputStream file = Files.newOutputStream(wrapped.resolve("output"));
-    assertTrue(seenMessage.get());
-    file.close();
-  }
-  
-  public void testVerboseFSNoSuchFileException() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new VerboseFS(dir.getFileSystem(), InfoStream.NO_OUTPUT).getFileSystem(URI.create("file:///"));    
-    Path wrapped = new FilterPath(dir, fs);
-    try {
-      AsynchronousFileChannel.open(wrapped.resolve("doesNotExist.rip"));
-      fail("did not hit exception");
-    } catch (NoSuchFileException nsfe) {
-      // expected
-    }
-    try {
-      FileChannel.open(wrapped.resolve("doesNotExist.rip"));
-      fail("did not hit exception");
-    } catch (NoSuchFileException nsfe) {
-      // expected
-    }
-    try {
-      Files.newByteChannel(wrapped.resolve("stillopen"));
-      fail("did not hit exception");
-    } catch (NoSuchFileException nsfe) {
-      // expected
-    }
-  }
-
-  public void testTooManyOpenFiles() throws IOException {
-    int n = 60;
-
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new HandleLimitFS(dir.getFileSystem(), n).getFileSystem(URI.create("file:///"));
-    dir = new FilterPath(dir, fs);
-    
-    // create open files to exact limit
-    List<Closeable> toClose = new ArrayList<>();
-    for (int i = 0; i < n; i++) {
-      Path p = Files.createTempFile(dir, null, null);
-      toClose.add(Files.newOutputStream(p));
-    }
-    
-    // now exceed
-    try {
-      Files.newOutputStream(Files.createTempFile(dir, null, null));
-      fail("didn't hit exception");
-    } catch (IOException e) {
-      assertTrue(e.getMessage().contains("Too many open files"));
-    }
-    
-    IOUtils.close(toClose);
-  }
-
-  public void testDirectoryStreamFiltered() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-
-    OutputStream file = Files.newOutputStream(wrapped.resolve("file1"));
-    file.write(5);
-    file.close();
-    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped)) {
-      int count = 0;
-      for (Path path : stream) {
-        assertTrue(path instanceof FilterPath);
-        if (!path.getFileName().toString().startsWith("extra")) {
-          count++;
-        }
-      }
-      assertEquals(1, count);
-    }
-
-    // check with LeakFS, a subclass of HandleTrackingFS which mucks with newDirectoryStream
-    dir = FilterPath.unwrap(createTempDir());
-    fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    wrapped = new FilterPath(dir, fs);
-
-    file = Files.newOutputStream(wrapped.resolve("file1"));
-    file.write(5);
-    file.close();
-    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped)) {
-      int count = 0;
-      for (Path path : stream) {
-        assertTrue(path instanceof FilterPath);
-        if (!path.getFileName().toString().startsWith("extra")) {
-          count++;
-        }
-      }
-      assertEquals(1, count);
-    }
-  }
-
-  public void testDirectoryStreamGlobFiltered() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-
-    OutputStream file = Files.newOutputStream(wrapped.resolve("foo"));
-    file.write(5);
-    file.close();
-    file = Files.newOutputStream(wrapped.resolve("bar"));
-    file.write(5);
-    file.close();
-    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped, "f*")) {
-      int count = 0;
-      for (Path path : stream) {
-        assertTrue(path instanceof FilterPath);
-        ++count;
-      }
-      assertEquals(1, count);
-    }
-
-    // check with LeakFS, a subclass of HandleTrackingFS which mucks with newDirectoryStream
-    dir = FilterPath.unwrap(createTempDir());
-    fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    wrapped = new FilterPath(dir, fs);
-
-    file = Files.newOutputStream(wrapped.resolve("foo"));
-    file.write(5);
-    file.close();
-    file = Files.newOutputStream(wrapped.resolve("bar"));
-    file.write(5);
-    file.close();
-    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped, "f*")) {
-      int count = 0;
-      for (Path path : stream) {
-        assertTrue(path instanceof FilterPath);
-        ++count;
-      }
-      assertEquals(1, count);
-    }
-  }
-  
-  public void testHashCodeEquals() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-
-    Path f1 = wrapped.resolve("file1");
-    Path f1Again = wrapped.resolve("file1");
-    Path f2 = wrapped.resolve("file2");
-    
-    assertEquals(f1, f1);
-    assertFalse(f1.equals(null));
-    assertEquals(f1, f1Again);
-    assertEquals(f1.hashCode(), f1Again.hashCode());
-    assertFalse(f1.equals(f2));
-  }
-  
-  public void testURI() throws IOException {
-    Path dir = FilterPath.unwrap(createTempDir());
-    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
-    Path wrapped = new FilterPath(dir, fs);
-
-    Path f1 = wrapped.resolve("file1");
-    URI uri = f1.toUri();
-    Path f2 = fs.provider().getPath(uri);
-    assertEquals(f1, f2);
-    
-    assumeTrue(Charset.defaultCharset().name() + " can't encode chinese", 
-               Charset.defaultCharset().newEncoder().canEncode("??"));
-    Path f3 = wrapped.resolve("??");
-    URI uri2 = f3.toUri();
-    Path f4 = fs.provider().getPath(uri2);
-    assertEquals(f3, f4);
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java b/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
index 2014b68..fdbdb11 100644
--- a/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
+++ b/lucene/core/src/test/org/apache/lucene/store/TestDirectory.java
@@ -24,29 +24,9 @@ import java.util.Arrays;
 import java.util.List;
 
 import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
 
-public class TestDirectory extends BaseDirectoryTestCase {
-
-  @Override
-  protected Directory getDirectory(Path path) throws IOException {
-    final Directory dir;
-    if (random().nextBoolean()) {
-      dir = newDirectory();
-    } else {
-      dir = newFSDirectory(path);
-    }
-    if (dir instanceof MockDirectoryWrapper) {
-      // test manipulates directory directly
-      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);
-    }
-    return dir;
-  }
-
-  // we wrap the directory in slow stuff, so only run nightly
-  @Override @Nightly
-  public void testThreadSafety() throws Exception {
-    super.testThreadSafety();
-  }
+public class TestDirectory extends LuceneTestCase {
 
   // Test that different instances of FSDirectory can coexist on the same
   // path, can read, write, and lock files.
diff --git a/lucene/core/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java b/lucene/core/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java
deleted file mode 100644
index a047d99..0000000
--- a/lucene/core/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java
+++ /dev/null
@@ -1,108 +0,0 @@
-package org.apache.lucene.store;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestMockDirectoryWrapper extends LuceneTestCase {
-  
-  public void testFailIfIndexWriterNotClosed() throws IOException {
-    MockDirectoryWrapper dir = newMockDirectory();
-    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
-    try {
-      dir.close();
-      fail();
-    } catch (Exception expected) {
-      assertTrue(expected.getMessage().contains("there are still open locks"));
-    } finally {
-      IOUtils.closeWhileHandlingException(iw);
-    }
-  }
-  
-  public void testFailIfIndexWriterNotClosedChangeLockFactory() throws IOException {
-    MockDirectoryWrapper dir = newMockDirectory(random(), new SingleInstanceLockFactory());
-    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
-    try {
-      dir.close();
-      fail();
-    } catch (Exception expected) {
-      assertTrue(expected.getMessage().contains("there are still open locks"));
-    } finally {
-      IOUtils.closeWhileHandlingException(iw);
-    }
-  }
-  
-  public void testDiskFull() throws IOException {
-    // test writeBytes
-    MockDirectoryWrapper dir = newMockDirectory();
-    dir.setMaxSizeInBytes(3);
-    final byte[] bytes = new byte[] { 1, 2};
-    IndexOutput out = dir.createOutput("foo", IOContext.DEFAULT);
-    out.writeBytes(bytes, bytes.length); // first write should succeed
-    // close() to ensure the written bytes are not buffered and counted
-    // against the directory size
-    out.close();
-    out = dir.createOutput("bar", IOContext.DEFAULT);
-    try {
-      out.writeBytes(bytes, bytes.length);
-      fail("should have failed on disk full");
-    } catch (IOException e) {
-      // expected
-    }
-    out.close();
-    dir.close();
-    
-    // test copyBytes
-    dir = newMockDirectory();
-    dir.setMaxSizeInBytes(3);
-    out = dir.createOutput("foo", IOContext.DEFAULT);
-    out.copyBytes(new ByteArrayDataInput(bytes), bytes.length); // first copy should succeed
-    // close() to ensure the written bytes are not buffered and counted
-    // against the directory size
-    out.close();
-    out = dir.createOutput("bar", IOContext.DEFAULT);
-    try {
-      out.copyBytes(new ByteArrayDataInput(bytes), bytes.length);
-      fail("should have failed on disk full");
-    } catch (IOException e) {
-      // expected
-    }
-    out.close();
-    dir.close();
-  }
-  
-  public void testMDWinsideOfMDW() throws Exception {
-    // add MDW inside another MDW
-    Directory dir = new MockDirectoryWrapper(random(), newMockDirectory());
-    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
-    for (int i = 0; i < 20; i++) {
-      iw.addDocument(new Document());
-    }
-    iw.commit();
-    iw.close();
-    dir.close();
-  }
-  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestMaxFailuresRule.java b/lucene/core/src/test/org/apache/lucene/util/TestMaxFailuresRule.java
deleted file mode 100644
index 2eb4a74..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/TestMaxFailuresRule.java
+++ /dev/null
@@ -1,184 +0,0 @@
-package org.apache.lucene.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.concurrent.CountDownLatch;
-
-import org.apache.lucene.util.junitcompat.WithNestedTests;
-import org.junit.Assert;
-import org.junit.BeforeClass;
-import org.junit.Test;
-import org.junit.runner.Description;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-import org.junit.runner.notification.RunListener;
-
-import com.carrotsearch.randomizedtesting.annotations.Repeat;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakAction;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope.Scope;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakZombies;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakZombies.Consequence;
-
-/**
- * @see TestRuleIgnoreAfterMaxFailures
- */
-public class TestMaxFailuresRule extends WithNestedTests {
-  public TestMaxFailuresRule() {
-    super(true);
-  }
-
-  public static class Nested extends WithNestedTests.AbstractNestedTest {
-    public static final int TOTAL_ITERS = 500;
-    public static final int DESIRED_FAILURES = TOTAL_ITERS / 10;
-    private int numFails = 0;
-    private int numIters = 0;
-
-    @Repeat(iterations = TOTAL_ITERS)
-    public void testFailSometimes() {
-      numIters++;
-      boolean fail = random().nextInt(5) == 0;
-      if (fail) numFails++;
-      // some seeds are really lucky ... so cheat.
-      if (numFails < DESIRED_FAILURES && 
-          DESIRED_FAILURES <= TOTAL_ITERS - numIters) {
-        fail = true;
-      }
-      assertFalse(fail);
-    }
-  }
-
-  @Test
-  public void testMaxFailures() {
-    LuceneTestCase.replaceMaxFailureRule(new TestRuleIgnoreAfterMaxFailures(2));
-    JUnitCore core = new JUnitCore();
-    final StringBuilder results = new StringBuilder();
-    core.addListener(new RunListener() {
-      char lastTest;
-
-      @Override
-      public void testStarted(Description description) throws Exception {
-        lastTest = 'S'; // success.
-      }
-
-      @Override
-      public void testAssumptionFailure(Failure failure) {
-        lastTest = 'A'; // assumption failure.
-      }
-
-      @Override
-      public void testFailure(Failure failure) throws Exception {
-        lastTest = 'F'; // failure
-      }
-
-      @Override
-      public void testFinished(Description description) throws Exception {
-        results.append(lastTest);
-      }
-    });
-
-    Result result = core.run(Nested.class);
-    Assert.assertEquals(500, result.getRunCount());
-    Assert.assertEquals(0, result.getIgnoreCount());
-    Assert.assertEquals(2, result.getFailureCount());
-
-    // Make sure we had exactly two failures followed by assumption-failures
-    // resulting from ignored tests.
-    Assert.assertTrue(results.toString(), 
-        results.toString().matches("(S*F){2}A+"));
-  }
-
-  @ThreadLeakZombies(Consequence.IGNORE_REMAINING_TESTS)
-  @ThreadLeakAction({ThreadLeakAction.Action.WARN})
-  @ThreadLeakScope(Scope.TEST)
-  @ThreadLeakLingering(linger = 500)
-  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
-    public static final int TOTAL_ITERS = 10;
-    public static CountDownLatch die;
-    public static Thread zombie;
-    public static int testNum;
-    
-    @BeforeClass
-    public static void setup() {
-      assert zombie == null;
-      die = new CountDownLatch(1);
-      testNum = 0;
-    }
-
-    @Repeat(iterations = TOTAL_ITERS)
-    public void testLeaveZombie() {
-      if (++testNum == 2) {
-        zombie = new Thread() {
-          @Override
-          public void run() {
-            while (true) {
-              try {
-                die.await();
-                return;
-              } catch (Exception e) { /* ignore */ }
-            }
-          }
-        };
-        zombie.start();
-      }
-    }
-  }
-
-  @Test
-  public void testZombieThreadFailures() throws Exception {
-    LuceneTestCase.replaceMaxFailureRule(new TestRuleIgnoreAfterMaxFailures(1));
-    JUnitCore core = new JUnitCore();
-    final StringBuilder results = new StringBuilder();
-    core.addListener(new RunListener() {
-      char lastTest;
-
-      @Override
-      public void testStarted(Description description) throws Exception {
-        lastTest = 'S'; // success.
-      }
-
-      @Override
-      public void testAssumptionFailure(Failure failure) {
-        lastTest = 'A'; // assumption failure.
-      }
-
-      @Override
-      public void testFailure(Failure failure) throws Exception {
-        lastTest = 'F'; // failure
-        System.out.println(failure.getMessage());
-      }
-
-      @Override
-      public void testFinished(Description description) throws Exception {
-        results.append(lastTest);
-      }
-    });
-
-    Result result = core.run(Nested2.class);
-    if (Nested2.die != null) {
-      Nested2.die.countDown();
-      Nested2.zombie.join();
-    }
-    
-    super.prevSysOut.println(results.toString());
-    Assert.assertEquals(Nested2.TOTAL_ITERS, result.getRunCount());
-    Assert.assertEquals(results.toString(), "SFAAAAAAAA", results.toString());
-  }  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/TestRamUsageEstimatorOnWildAnimals.java b/lucene/core/src/test/org/apache/lucene/util/TestRamUsageEstimatorOnWildAnimals.java
deleted file mode 100644
index aaaa2be..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/TestRamUsageEstimatorOnWildAnimals.java
+++ /dev/null
@@ -1,54 +0,0 @@
-package org.apache.lucene.util;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.junit.Assert;
-
-/**
- * Check large and special graphs. 
- */
-public class TestRamUsageEstimatorOnWildAnimals extends LuceneTestCase {
-  public static class ListElement {
-    ListElement next;
-  }
-
-  public void testOverflowMaxChainLength() {
-    int UPPERLIMIT = 100000;
-    int lower = 0;
-    int upper = UPPERLIMIT;
-    
-    while (lower + 1 < upper) {
-      int mid = (lower + upper) / 2;
-      try {
-        ListElement first = new ListElement();
-        ListElement last = first;
-        for (int i = 0; i < mid; i++) {
-          last = (last.next = new ListElement());
-        }
-        RamUsageTester.sizeOf(first); // cause SOE or pass.
-        lower = mid;
-      } catch (StackOverflowError e) {
-        upper = mid;
-      }
-    }
-
-    if (lower + 1 < UPPERLIMIT) {
-      Assert.fail("Max object chain length till stack overflow: " + lower);
-    }
-  }  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/SorePoint.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/SorePoint.java
deleted file mode 100644
index 5b86632..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/SorePoint.java
+++ /dev/null
@@ -1,33 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * A pointcut-like definition where we should trigger
- * an assumption or error.
- */
-public enum SorePoint {
-  // STATIC_INITIALIZER, // I assume this will result in JUnit failure to load a suite.
-  BEFORE_CLASS,
-  INITIALIZER,
-  RULE,
-  BEFORE,
-  TEST,
-  AFTER,
-  AFTER_CLASS
-}
\ No newline at end of file
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/SoreType.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/SoreType.java
deleted file mode 100644
index 27d9ca4..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/SoreType.java
+++ /dev/null
@@ -1,24 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public enum SoreType {
-  ASSUMPTION,
-  FAILURE,
-  ERROR
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestBeforeAfterOverrides.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestBeforeAfterOverrides.java
deleted file mode 100644
index 900c33b..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestBeforeAfterOverrides.java
+++ /dev/null
@@ -1,70 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestBeforeAfterOverrides extends WithNestedTests {
-  public TestBeforeAfterOverrides() {
-    super(true);
-  }
-
-  public static class Before1 extends WithNestedTests.AbstractNestedTest {
-    @Before
-    public void before() {}
-    
-    public void testEmpty() {}
-  }
-  public static class Before2 extends Before1 {}
-  public static class Before3 extends Before2 {
-    @Override
-    @Before
-    public void before() {}
-  }
-
-  public static class After1 extends WithNestedTests.AbstractNestedTest {
-    @After
-    public void after() {}
-    
-    public void testEmpty() {}
-  }
-  public static class After2 extends Before1 {}
-  public static class After3 extends Before2 {
-    @After
-    public void after() {}
-  }
-
-  @Test
-  public void testBefore() {
-    Result result = JUnitCore.runClasses(Before3.class);
-    Assert.assertEquals(1, result.getFailureCount());
-    Assert.assertTrue(result.getFailures().get(0).getTrace().contains("There are overridden methods"));
-  }
-  
-  @Test
-  public void testAfter() {
-    Result result = JUnitCore.runClasses(Before3.class);
-    Assert.assertEquals(1, result.getFailureCount());
-    Assert.assertTrue(result.getFailures().get(0).getTrace().contains("There are overridden methods"));
-  }  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestCodecReported.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestCodecReported.java
deleted file mode 100644
index 4d2b904..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestCodecReported.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-import org.apache.lucene.codecs.Codec;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestCodecReported extends WithNestedTests {
-  public TestCodecReported() {
-    super(true);
-  }
-  
-  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
-    public static String codecName;
-
-    public void testDummy() {
-      codecName = Codec.getDefault().getName();
-      fail();
-    }
-  }
-
-  @Test
-  public void testCorrectCodecReported() {
-    Result r = JUnitCore.runClasses(Nested1.class);
-    Assert.assertEquals(1, r.getFailureCount());
-    Assert.assertTrue(super.getSysErr(),
-        super.getSysErr().contains("codec=" + Nested1.codecName));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestExceptionInBeforeClassHooks.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestExceptionInBeforeClassHooks.java
deleted file mode 100644
index afdc560..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestExceptionInBeforeClassHooks.java
+++ /dev/null
@@ -1,141 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.*;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import junit.framework.Assert;
-
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-
-public class TestExceptionInBeforeClassHooks extends WithNestedTests {
-  public TestExceptionInBeforeClassHooks() {
-    super(true);
-  }
-
-  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
-    @BeforeClass
-    public static void beforeClass() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar");
-        }
-      };
-      t.start();
-      t.join();
-    }
-
-    public void test() {}
-  }
-
-  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
-    public void test1() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar1");
-        }
-      };
-      t.start();
-      t.join();
-    }
-
-    public void test2() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar2");
-        }
-      };
-      t.start();
-      t.join();
-    }
-    
-    public void test3() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar3");
-        }
-      };
-      t.start();
-      t.join();
-    }    
-  }
-
-  public static class Nested3 extends WithNestedTests.AbstractNestedTest {
-    @Before
-    public void runBeforeTest() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar");
-        }
-      };
-      t.start();
-      t.join();
-    }
-
-    public void test1() throws Exception {
-    }
-  }
-
-  @Test
-  public void testExceptionInBeforeClassFailsTheTest() {
-    Result runClasses = JUnitCore.runClasses(Nested1.class);
-    assertFailureCount(1, runClasses);
-    Assert.assertEquals(1, runClasses.getRunCount());
-    Assert.assertTrue(runClasses.getFailures().get(0).getTrace().contains("foobar"));
-  }
-
-  @Test
-  public void testExceptionWithinTestFailsTheTest() {
-    Result runClasses = JUnitCore.runClasses(Nested2.class);
-    assertFailureCount(3, runClasses);
-    Assert.assertEquals(3, runClasses.getRunCount());
-    
-    ArrayList<String> foobars = new ArrayList<>();
-    for (Failure f : runClasses.getFailures()) {
-      Matcher m = Pattern.compile("foobar[0-9]+").matcher(f.getTrace());
-      while (m.find()) {
-        foobars.add(m.group());
-      }
-    }
-
-    Collections.sort(foobars);
-    Assert.assertEquals("[foobar1, foobar2, foobar3]", 
-        Arrays.toString(foobars.toArray()));
-  }
-  
-  @Test
-  public void testExceptionWithinBefore() {
-    Result runClasses = JUnitCore.runClasses(Nested3.class);
-    assertFailureCount(1, runClasses);
-    Assert.assertEquals(1, runClasses.getRunCount());
-    Assert.assertTrue(runClasses.getFailures().get(0).getTrace().contains("foobar"));
-  }  
-  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java
deleted file mode 100644
index 88d6641..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfDirectoryNotClosed.java
+++ /dev/null
@@ -1,48 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.store.Directory;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-
-import com.carrotsearch.randomizedtesting.RandomizedTest;
-
-public class TestFailIfDirectoryNotClosed extends WithNestedTests {
-  public TestFailIfDirectoryNotClosed() {
-    super(true);
-  }
-
-  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
-    public void testDummy() throws Exception {
-      Directory dir = newDirectory();
-      System.out.println(dir.toString());
-    }
-  }
-
-  @Test
-  public void testFailIfDirectoryNotClosed() {
-    Result r = JUnitCore.runClasses(Nested1.class);
-    RandomizedTest.assumeTrue("Ignoring nested test, very likely zombie threads present.", 
-        r.getIgnoreCount() == 0);
-    assertFailureCount(1, r);
-    Assert.assertTrue(r.getFailures().get(0).toString().contains("Resource in scope SUITE failed to close"));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfUnreferencedFiles.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfUnreferencedFiles.java
deleted file mode 100644
index 3680e56..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestFailIfUnreferencedFiles.java
+++ /dev/null
@@ -1,72 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Collections;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.lucene.store.MockDirectoryWrapper;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-import com.carrotsearch.randomizedtesting.RandomizedTest;
-
-// LUCENE-4456: Test that we fail if there are unreferenced files
-public class TestFailIfUnreferencedFiles extends WithNestedTests {
-  public TestFailIfUnreferencedFiles() {
-    super(true);
-  }
-  
-  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
-    public void testDummy() throws Exception {
-      MockDirectoryWrapper dir = newMockDirectory();
-      dir.setAssertNoUnrefencedFilesOnClose(true);
-      IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
-      iw.addDocument(new Document());
-      iw.close();
-      IndexOutput output = dir.createOutput("_hello.world", IOContext.DEFAULT);
-      output.writeString("i am unreferenced!");
-      output.close();
-      dir.sync(Collections.singleton("_hello.world"));
-      dir.close();
-    }
-  }
-
-  @Test
-  public void testFailIfUnreferencedFiles() {
-    Result r = JUnitCore.runClasses(Nested1.class);
-    RandomizedTest.assumeTrue("Ignoring nested test, very likely zombie threads present.", 
-        r.getIgnoreCount() == 0);
-
-    // We are suppressing output anyway so dump the failures.
-    for (Failure f : r.getFailures()) {
-      System.out.println(f.getTrace());
-    }
-
-    Assert.assertEquals("Expected exactly one failure.", 
-        1, r.getFailureCount());
-    Assert.assertTrue("Expected unreferenced files assertion.", 
-        r.getFailures().get(0).getTrace().contains("unreferenced files:"));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestGroupFiltering.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestGroupFiltering.java
deleted file mode 100644
index 4aa9880..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestGroupFiltering.java
+++ /dev/null
@@ -1,61 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-import java.lang.annotation.Documented;
-import java.lang.annotation.Inherited;
-import java.lang.annotation.Retention;
-import java.lang.annotation.RetentionPolicy;
-
-import org.apache.lucene.util.LuceneTestCase;
-
-import com.carrotsearch.randomizedtesting.annotations.TestGroup;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class TestGroupFiltering extends LuceneTestCase {
-  @Documented
-  @Inherited
-  @Retention(RetentionPolicy.RUNTIME)
-  @TestGroup(enabled = false)
-  public @interface Foo {}
-  
-  @Documented
-  @Inherited
-  @Retention(RetentionPolicy.RUNTIME)
-  @TestGroup(enabled = false)
-  public @interface Bar {}
-
-  @Documented
-  @Inherited
-  @Retention(RetentionPolicy.RUNTIME)
-  @TestGroup(enabled = false)
-  public @interface Jira {
-    String bug();
-  }
-  
-  @Foo
-  public void testFoo() {}
-  
-  @Foo @Bar
-  public void testFooBar() {}
-
-  @Bar
-  public void testBar() {}
-
-  @Jira(bug = "JIRA bug reference")
-  public void testJira() {}
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestJUnitRuleOrder.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestJUnitRuleOrder.java
deleted file mode 100644
index 9d29c9f..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestJUnitRuleOrder.java
+++ /dev/null
@@ -1,93 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Arrays;
-import java.util.Stack;
-
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.TestRule;
-import org.junit.runner.Description;
-import org.junit.runner.JUnitCore;
-import org.junit.runners.model.Statement;
-
-/**
- * This verifies that JUnit {@link Rule}s are invoked before 
- * {@link Before} and {@link  After} hooks. This should be the
- * case from JUnit 4.10 on.
- */
-public class TestJUnitRuleOrder extends WithNestedTests {
-  static Stack<String> stack;
-
-  public TestJUnitRuleOrder() {
-    super(true);
-  }
-  
-  public static class Nested extends WithNestedTests.AbstractNestedTest {
-    @Before
-    public void before() {
-      stack.push("@Before");
-    }
-    
-    @After
-    public void after() {
-      stack.push("@After");
-    }
-
-    @Rule
-    public TestRule testRule = new TestRule() {
-      @Override
-      public Statement apply(final Statement base, Description description) {
-        return new Statement() {
-          @Override
-          public void evaluate() throws Throwable {
-            stack.push("@Rule before");
-            base.evaluate();
-            stack.push("@Rule after");
-          }
-        };
-      }
-    };
-
-    @Test
-    public void test() {/* empty */}
-
-    @BeforeClass
-    public static void beforeClassCleanup() {
-      stack = new Stack<>();
-    }
-
-    @AfterClass
-    public static void afterClassCheck() {
-      stack.push("@AfterClass");
-    }    
-  }
-
-  @Test
-  public void testRuleOrder() {
-    JUnitCore.runClasses(Nested.class);
-    Assert.assertEquals(
-        Arrays.toString(stack.toArray()), "[@Rule before, @Before, @After, @Rule after, @AfterClass]");
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java
deleted file mode 100644
index 1128107..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestLeaveFilesIfTestFails.java
+++ /dev/null
@@ -1,82 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.nio.channels.SeekableByteChannel;
-import java.nio.file.Files;
-import java.nio.file.Path;
-import java.nio.file.StandardOpenOption;
-
-import org.apache.lucene.util.Constants;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-
-import com.carrotsearch.randomizedtesting.RandomizedTest;
-
-public class TestLeaveFilesIfTestFails extends WithNestedTests {
-  public TestLeaveFilesIfTestFails() {
-    super(true);
-  }
-  
-  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
-    static Path file;
-    public void testDummy() {
-      file = createTempDir("leftover");
-      fail();
-    }
-  }
-
-  @Test
-  public void testLeaveFilesIfTestFails() throws IOException {
-    Result r = JUnitCore.runClasses(Nested1.class);
-    Assert.assertEquals(1, r.getFailureCount());
-    Assert.assertTrue(Nested1.file != null && Files.exists(Nested1.file));
-    IOUtils.rm(Nested1.file);
-  }
-  
-  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
-    static Path file;
-    static Path parent;
-    static SeekableByteChannel openFile;
-
-    @SuppressWarnings("deprecation")
-    public void testDummy() throws Exception {
-      file = createTempDir("leftover").resolve("child.locked");
-      openFile = Files.newByteChannel(file, StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
-
-      parent = LuceneTestCase.getBaseTempDirForTestClass();
-    }
-  }
-
-  @Test
-  public void testWindowsUnremovableFile() throws IOException {
-    RandomizedTest.assumeTrue("Requires Windows.", Constants.WINDOWS);
-    RandomizedTest.assumeFalse(LuceneTestCase.LEAVE_TEMPORARY);
-
-    Result r = JUnitCore.runClasses(Nested2.class);
-    Assert.assertEquals(1, r.getFailureCount());
-
-    Nested2.openFile.close();
-    IOUtils.rm(Nested2.parent);
-  }  
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessage.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessage.java
deleted file mode 100644
index 7b863b3..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessage.java
+++ /dev/null
@@ -1,305 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Arrays;
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.TestRule;
-import org.junit.runner.Description;
-import org.junit.runner.JUnitCore;
-import org.junit.runners.model.Statement;
-
-/**
- * Test reproduce message is right.
- */
-public class TestReproduceMessage extends WithNestedTests {
-  public static SorePoint where;
-  public static SoreType  type;
-  
-  public static class Nested extends AbstractNestedTest {
-    @BeforeClass
-    public static void beforeClass() {
-      if (isRunningNested()) {
-        triggerOn(SorePoint.BEFORE_CLASS);
-      }
-    }
-
-    @Rule
-    public TestRule rule = new TestRule() {
-      @Override
-      public Statement apply(final Statement base, Description description) {
-        return new Statement() {
-          @Override
-          public void evaluate() throws Throwable {
-            triggerOn(SorePoint.RULE);
-            base.evaluate();
-          }
-        };
-      }
-    };
-
-    /** Class initializer block/ default constructor. */
-    public Nested() {
-      triggerOn(SorePoint.INITIALIZER);
-    }
-
-    @Before
-    public void before() {
-      triggerOn(SorePoint.BEFORE);
-    }    
-
-    @Test
-    public void test() {
-      triggerOn(SorePoint.TEST);
-    }
-    
-    @After
-    public void after() {
-      triggerOn(SorePoint.AFTER);
-    }    
-
-    @AfterClass
-    public static void afterClass() {
-      if (isRunningNested()) {
-        triggerOn(SorePoint.AFTER_CLASS);
-      }
-    }    
-
-    /** */
-    private static void triggerOn(SorePoint pt) {
-      if (pt == where) {
-        switch (type) {
-          case ASSUMPTION:
-            LuceneTestCase.assumeTrue(pt.toString(), false);
-            throw new RuntimeException("unreachable");
-          case ERROR:
-            throw new RuntimeException(pt.toString());
-          case FAILURE:
-            Assert.assertTrue(pt.toString(), false);
-            throw new RuntimeException("unreachable");
-        }
-      }
-    }
-  }
-
-  /*
-   * ASSUMPTIONS.
-   */
-  
-  public TestReproduceMessage() {
-    super(true);
-  }
-
-  @Test
-  public void testAssumeBeforeClass() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.BEFORE_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  @Test
-  public void testAssumeInitializer() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.INITIALIZER;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  @Test
-  public void testAssumeRule() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.RULE;
-    Assert.assertEquals("", runAndReturnSyserr());
-  }
-
-  @Test
-  public void testAssumeBefore() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.BEFORE;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  @Test
-  public void testAssumeTest() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.TEST;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  @Test
-  public void testAssumeAfter() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.AFTER;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  @Test
-  public void testAssumeAfterClass() throws Exception { 
-    type = SoreType.ASSUMPTION; 
-    where = SorePoint.AFTER_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().isEmpty());
-  }
-
-  /*
-   * FAILURES
-   */
-  
-  @Test
-  public void testFailureBeforeClass() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.BEFORE_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  @Test
-  public void testFailureInitializer() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.INITIALIZER;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  @Test
-  public void testFailureRule() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.RULE;
-
-    final String syserr = runAndReturnSyserr();
-    
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testFailureBefore() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.BEFORE;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testFailureTest() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.TEST;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testFailureAfter() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.AFTER;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testFailureAfterClass() throws Exception { 
-    type = SoreType.FAILURE; 
-    where = SorePoint.AFTER_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  /*
-   * ERRORS
-   */
-  
-  @Test
-  public void testErrorBeforeClass() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.BEFORE_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  @Test
-  public void testErrorInitializer() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.INITIALIZER;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  @Test
-  public void testErrorRule() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.RULE;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testErrorBefore() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.BEFORE;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testErrorTest() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.TEST;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testErrorAfter() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.AFTER;
-    final String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
-    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
-  }
-
-  @Test
-  public void testErrorAfterClass() throws Exception { 
-    type = SoreType.ERROR; 
-    where = SorePoint.AFTER_CLASS;
-    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
-  }
-
-  private String runAndReturnSyserr() {
-    JUnitCore.runClasses(Nested.class);
-
-    String err = getSysErr();
-    // super.prevSysErr.println("Type: " + type + ", point: " + where + " resulted in:\n" + err);
-    // super.prevSysErr.println("---");
-    return err;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessageWithRepeated.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessageWithRepeated.java
deleted file mode 100644
index 8b07c6a..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestReproduceMessageWithRepeated.java
+++ /dev/null
@@ -1,53 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-
-import com.carrotsearch.randomizedtesting.annotations.Repeat;
-
-/**
- * Test reproduce message is right with {@link Repeat} annotation.
- */
-public class TestReproduceMessageWithRepeated extends WithNestedTests {
-  public static class Nested extends AbstractNestedTest {
-    @Test
-    @Repeat(iterations = 10)
-    public void testMe() {
-      throw new RuntimeException("bad");
-    }
-  }
-
-  public TestReproduceMessageWithRepeated() {
-    super(true);
-  }
-
-  @Test
-  public void testRepeatedMessage() throws Exception { 
-    String syserr = runAndReturnSyserr();
-    Assert.assertTrue(syserr.contains(" -Dtests.method=testMe "));
-  }
-
-  private String runAndReturnSyserr() {
-    JUnitCore.runClasses(Nested.class);
-    String err = getSysErr();
-    return err;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSeedFromUncaught.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSeedFromUncaught.java
deleted file mode 100644
index b1329cf..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSeedFromUncaught.java
+++ /dev/null
@@ -1,62 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-
-/**
- * Check that uncaught exceptions result in seed info being dumped to
- * console. 
- */
-public class TestSeedFromUncaught extends WithNestedTests {
-  public static class ThrowInUncaught extends AbstractNestedTest {
-    @Test
-    public void testFoo() throws Exception {
-      Thread t = new Thread() {
-        @Override
-        public void run() {
-          throw new RuntimeException("foobar");
-        }
-      };
-      t.start();
-      t.join();
-    }
-  }
-
-  public TestSeedFromUncaught() {
-    super(/* suppress normal output. */ true);
-  }
-
-  /**
-   * Verify super method calls on {@link LuceneTestCase#setUp()}.
-   */
-  @Test
-  public void testUncaughtDumpsSeed() {
-    Result result = JUnitCore.runClasses(ThrowInUncaught.class);
-    assertFailureCount(1, result);
-    Failure f = result.getFailures().get(0);
-    String trace = f.getTrace();
-    Assert.assertTrue(trace.contains("SeedInfo.seed("));
-    Assert.assertTrue(trace.contains("foobar"));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSetupTeardownChaining.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSetupTeardownChaining.java
deleted file mode 100644
index 807ec33..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/TestSetupTeardownChaining.java
+++ /dev/null
@@ -1,82 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.JUnitCore;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-
-/**
- * Ensures proper functions of {@link LuceneTestCase#setUp()}
- * and {@link LuceneTestCase#tearDown()}.
- */
-public class TestSetupTeardownChaining extends WithNestedTests {
-  public static class NestedSetupChain extends AbstractNestedTest {
-    @Override
-    public void setUp() throws Exception {
-      // missing call.
-      System.out.println("Hello.");
-    }
-
-    @Test
-    public void testMe() {
-    }
-  }
-
-  public static class NestedTeardownChain extends AbstractNestedTest {
-    @Override
-    public void tearDown() throws Exception {
-      // missing call.
-    }
-
-    @Test
-    public void testMe() {
-    }
-  }
-
-  public TestSetupTeardownChaining() {
-    super(true);
-  }
-  
-  /**
-   * Verify super method calls on {@link LuceneTestCase#setUp()}.
-   */
-  @Test
-  public void testSetupChaining() {
-    Result result = JUnitCore.runClasses(NestedSetupChain.class);
-    Assert.assertEquals(1, result.getFailureCount());
-    Failure failure = result.getFailures().get(0);
-    Assert.assertTrue(failure.getMessage()
-        .contains("One of the overrides of setUp does not propagate the call."));
-  }
-  
-  /**
-   * Verify super method calls on {@link LuceneTestCase#tearDown()}.
-   */
-  @Test
-  public void testTeardownChaining() {
-    Result result = JUnitCore.runClasses(NestedTeardownChain.class);
-    Assert.assertEquals(1, result.getFailureCount());
-    Failure failure = result.getFailures().get(0);
-    Assert.assertTrue(failure.getMessage()
-        .contains("One of the overrides of tearDown does not propagate the call."));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/util/junitcompat/WithNestedTests.java b/lucene/core/src/test/org/apache/lucene/util/junitcompat/WithNestedTests.java
deleted file mode 100644
index 0a7d12f..0000000
--- a/lucene/core/src/test/org/apache/lucene/util/junitcompat/WithNestedTests.java
+++ /dev/null
@@ -1,196 +0,0 @@
-package org.apache.lucene.util.junitcompat;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.ByteArrayOutputStream;
-import java.io.PrintStream;
-import java.io.UnsupportedEncodingException;
-import java.nio.charset.StandardCharsets;
-import java.util.List;
-
-import org.apache.lucene.util.FailureMarker;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures;
-import org.apache.lucene.util.TestRuleIgnoreTestSuites;
-import org.apache.lucene.util.TestRuleMarkFailure;
-import org.apache.lucene.util.TestRuleRestoreSystemProperties;
-import org.apache.lucene.util.LuceneTestCase.SuppressSysoutChecks;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Assume;
-import org.junit.Before;
-import org.junit.ClassRule;
-import org.junit.Rule;
-import org.junit.rules.RuleChain;
-import org.junit.rules.TestRule;
-import org.junit.runner.Result;
-import org.junit.runner.notification.Failure;
-
-import com.carrotsearch.randomizedtesting.RandomizedRunner;
-import com.carrotsearch.randomizedtesting.RandomizedTest;
-import com.carrotsearch.randomizedtesting.SysGlobals;
-import com.carrotsearch.randomizedtesting.rules.TestRuleAdapter;
-
-/**
- * An abstract test class that prepares nested test classes to run.
- * A nested test class will assume it's executed under control of this
- * class and be ignored otherwise. 
- * 
- * <p>The purpose of this is so that nested test suites don't run from
- * IDEs like Eclipse (where they are automatically detected).
- * 
- * <p>This class cannot extend {@link LuceneTestCase} because in case
- * there's a nested {@link LuceneTestCase} afterclass hooks run twice and
- * cause havoc (static fields).
- */
-public abstract class WithNestedTests {
-  @SuppressSysoutChecks(bugUrl = "WithNestedTests has its own stream capture.")
-  public static abstract class AbstractNestedTest extends LuceneTestCase 
-    implements TestRuleIgnoreTestSuites.NestedTestSuite {
-    protected static boolean isRunningNested() {
-      return TestRuleIgnoreTestSuites.isRunningNested();
-    }
-  }
-
-  private boolean suppressOutputStreams;
-
-  protected WithNestedTests(boolean suppressOutputStreams) {
-    this.suppressOutputStreams = suppressOutputStreams;
-  }
-  
-  protected PrintStream prevSysErr;
-  protected PrintStream prevSysOut;
-  private ByteArrayOutputStream sysout;
-  private ByteArrayOutputStream syserr;
-
-  @ClassRule
-  public static final TestRule classRules = RuleChain.outerRule(new TestRuleAdapter() {
-    private TestRuleIgnoreAfterMaxFailures prevRule;
-
-    protected void before() throws Throwable {
-      if (!isPropertyEmpty(SysGlobals.SYSPROP_TESTFILTER()) ||
-          !isPropertyEmpty(SysGlobals.SYSPROP_TESTCLASS())  ||
-          !isPropertyEmpty(SysGlobals.SYSPROP_TESTMETHOD()) ||
-          !isPropertyEmpty(SysGlobals.SYSPROP_ITERATIONS())) {
-        // We're running with a complex test filter that is properly handled by classes
-        // which are executed by RandomizedRunner. The "outer" classes testing LuceneTestCase
-        // itself are executed by the default JUnit runner and would be always executed.
-        // We thus always skip execution if any filtering is detected.
-        Assume.assumeTrue(false);
-      }
-      
-      // Check zombie threads from previous suites. Don't run if zombies are around.
-      RandomizedTest.assumeFalse(RandomizedRunner.hasZombieThreads());
-
-      TestRuleIgnoreAfterMaxFailures newRule = new TestRuleIgnoreAfterMaxFailures(Integer.MAX_VALUE);
-      prevRule = LuceneTestCase.replaceMaxFailureRule(newRule);
-      RandomizedTest.assumeFalse(FailureMarker.hadFailures());
-    }
-
-    protected void afterAlways(List<Throwable> errors) throws Throwable {
-      if (prevRule != null) {
-        LuceneTestCase.replaceMaxFailureRule(prevRule);
-      }
-      FailureMarker.resetFailures();
-    }
-
-    private boolean isPropertyEmpty(String propertyName) {
-      String value = System.getProperty(propertyName);
-      return value == null || value.trim().isEmpty();
-    }    
-  }); 
-
-  /**
-   * Restore properties after test.
-   */
-  @Rule
-  public final TestRule rules;
-  {
-    final TestRuleMarkFailure marker = new TestRuleMarkFailure();
-    rules = RuleChain
-      .outerRule(new TestRuleRestoreSystemProperties(TestRuleIgnoreTestSuites.PROPERTY_RUN_NESTED))
-      .around(new TestRuleAdapter() {
-        @Override
-        protected void afterAlways(List<Throwable> errors) throws Throwable {
-          if (marker.hadFailures() && suppressOutputStreams) {
-            System.out.println("sysout from nested test: " + getSysOut() + "\n");
-            System.out.println("syserr from nested test: " + getSysErr());
-          }
-        }
-      })
-      .around(marker);
-  }
-
-  @Before
-  public final void before() {
-    if (suppressOutputStreams) {
-      prevSysOut = System.out;
-      prevSysErr = System.err;
-
-      try {
-        sysout = new ByteArrayOutputStream();
-        System.setOut(new PrintStream(sysout, true, IOUtils.UTF_8));
-        syserr = new ByteArrayOutputStream();
-        System.setErr(new PrintStream(syserr, true, IOUtils.UTF_8));
-      } catch (UnsupportedEncodingException e) {
-        throw new RuntimeException(e);
-      }
-    }
-
-    FailureMarker.resetFailures();
-    System.setProperty(TestRuleIgnoreTestSuites.PROPERTY_RUN_NESTED, "true");
-  }
-
-  @After
-  public final void after() {
-    if (suppressOutputStreams) {
-      System.out.flush();
-      System.err.flush();
-
-      System.setOut(prevSysOut);
-      System.setErr(prevSysErr);
-    }
-  }
-
-  protected void assertFailureCount(int expected, Result result) {
-    if (result.getFailureCount() != expected) {
-      StringBuilder b = new StringBuilder();
-      for (Failure f : result.getFailures()) {
-        b.append("\n\n");
-        b.append(f.getMessage());
-        b.append("\n");
-        b.append(f.getTrace());
-      }
-      RandomizedTest.assertFalse("Expected failures: " + expected + " but was " + 
-          result.getFailureCount() + ", failures below: " + b.toString(), true);
-    }
-  }
-
-  protected String getSysOut() {
-    Assert.assertTrue(suppressOutputStreams);
-    System.out.flush();
-    return new String(sysout.toByteArray(), StandardCharsets.UTF_8);
-  }
-
-  protected String getSysErr() {
-    Assert.assertTrue(suppressOutputStreams);
-    System.err.flush();
-    return new String(syserr.toByteArray(), StandardCharsets.UTF_8);
-  }  
-}
diff --git a/lucene/test-framework/build.xml b/lucene/test-framework/build.xml
index 94d9905..d09a50f 100644
--- a/lucene/test-framework/build.xml
+++ b/lucene/test-framework/build.xml
@@ -30,7 +30,17 @@
     <fileset dir="lib"/>
   </path>
 
-  <path id="test.classpath"/>
+  <path id="test.classpath"> 
+    <pathelement location="${build.dir}/classes/java"/>
+    <pathelement location="${build.dir}/classes/test"/>
+    <path refid="classpath"/>
+    <path refid="junit-path"/>
+  </path>
+
+  <path id="junit.classpath">
+    <path refid="test.classpath"/>
+    <pathelement path="${java.class.path}"/>
+  </path>
 
   <!-- 
       Specialize compile-core to depend on lucene-core and lucene-codecs compilation.
@@ -38,16 +48,11 @@
   <target name="compile-core" depends="init,compile-lucene-core,compile-codecs,common.compile-core"
           description="Compiles test-framework classes"/>
 
-  <!-- redefine the clover setup, because we dont want to run clover for the test-framework -->
-  <target name="-clover.setup" if="run.clover"/>
-
-  <!-- redefine the test compilation, so it's just a no-op -->
-  <target name="compile-test"/>
-  
   <!-- redefine the forbidden apis for tests, as we check ourselves - no sysout testing -->
   <target name="-check-forbidden-tests" depends="-init-forbidden-apis,compile-core">
     <forbidden-apis suppressAnnotation="**.SuppressForbidden" signaturesFile="${common.dir}/tools/forbiddenApis/tests.txt" classpathref="forbidden-apis.allclasses.classpath"> 
       <fileset dir="${build.dir}/classes/java"/>
+      <fileset dir="${build.dir}/classes/test"/>
     </forbidden-apis>
   </target>
   <target name="-check-forbidden-sysout"/>
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java
new file mode 100644
index 0000000..838243c
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestGraphTokenizers.java
@@ -0,0 +1,589 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.io.StringWriter;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Random;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.util.automaton.Automata;
+import org.apache.lucene.util.automaton.Automaton;
+import org.apache.lucene.util.automaton.Operations;
+
+import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+
+public class TestGraphTokenizers extends BaseTokenStreamTestCase {
+
+  // Makes a graph TokenStream from the string; separate
+  // positions with single space, multiple tokens at the same
+  // position with /, and add optional position length with
+  // :.  EG "a b c" is a simple chain, "a/x b c" adds 'x'
+  // over 'a' at position 0 with posLen=1, "a/x:3 b c" adds
+  // 'x' over a with posLen=3.  Tokens are in normal-form!
+  // So, offsets are computed based on the first token at a
+  // given position.  NOTE: each token must be a single
+  // character!  We assume this when computing offsets...
+  
+  // NOTE: all input tokens must be length 1!!!  This means
+  // you cannot turn on MockCharFilter when random
+  // testing...
+
+  private static class GraphTokenizer extends Tokenizer {
+    private List<Token> tokens;
+    private int upto;
+    private int inputLength;
+
+    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+    private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
+    private final PositionLengthAttribute posLengthAtt = addAttribute(PositionLengthAttribute.class);
+
+    @Override
+    public void reset() throws IOException {
+      super.reset();
+      tokens = null;
+      upto = 0;
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      if (tokens == null) {
+        fillTokens();
+      }
+      //System.out.println("graphTokenizer: incr upto=" + upto + " vs " + tokens.size());
+      if (upto == tokens.size()) {
+        //System.out.println("  END @ " + tokens.size());
+        return false;
+      } 
+      final Token t = tokens.get(upto++);
+      //System.out.println("  return token=" + t);
+      clearAttributes();
+      termAtt.append(t.toString());
+      offsetAtt.setOffset(t.startOffset(), t.endOffset());
+      posIncrAtt.setPositionIncrement(t.getPositionIncrement());
+      posLengthAtt.setPositionLength(t.getPositionLength());
+      return true;
+    }
+
+    @Override
+    public void end() throws IOException {
+      super.end();
+      // NOTE: somewhat... hackish, but we need this to
+      // satisfy BTSTC:
+      final int lastOffset;
+      if (tokens != null && !tokens.isEmpty()) {
+        lastOffset = tokens.get(tokens.size()-1).endOffset();
+      } else {
+        lastOffset = 0;
+      }
+      offsetAtt.setOffset(correctOffset(lastOffset),
+                          correctOffset(inputLength));
+    }
+
+    private void fillTokens() throws IOException {
+      final StringBuilder sb = new StringBuilder();
+      final char[] buffer = new char[256];
+      while (true) {
+        final int count = input.read(buffer);
+        if (count == -1) {
+          break;
+        }
+        sb.append(buffer, 0, count);
+        //System.out.println("got count=" + count);
+      }
+      //System.out.println("fillTokens: " + sb);
+
+      inputLength = sb.length();
+
+      final String[] parts = sb.toString().split(" ");
+
+      tokens = new ArrayList<>();
+      int pos = 0;
+      int maxPos = -1;
+      int offset = 0;
+      //System.out.println("again");
+      for(String part : parts) {
+        final String[] overlapped = part.split("/");
+        boolean firstAtPos = true;
+        int minPosLength = Integer.MAX_VALUE;
+        for(String part2 : overlapped) {
+          final int colonIndex = part2.indexOf(':');
+          final String token;
+          final int posLength;
+          if (colonIndex != -1) {
+            token = part2.substring(0, colonIndex);
+            posLength = Integer.parseInt(part2.substring(1+colonIndex));
+          } else {
+            token = part2;
+            posLength = 1;
+          }
+          maxPos = Math.max(maxPos, pos + posLength);
+          minPosLength = Math.min(minPosLength, posLength);
+          final Token t = new Token(token, offset, offset + 2*posLength - 1);
+          t.setPositionLength(posLength);
+          t.setPositionIncrement(firstAtPos ? 1:0);
+          firstAtPos = false;
+          //System.out.println("  add token=" + t + " startOff=" + t.startOffset() + " endOff=" + t.endOffset());
+          tokens.add(t);
+        }
+        pos += minPosLength;
+        offset = 2 * pos;
+      }
+      assert maxPos <= pos: "input string mal-formed: posLength>1 tokens hang over the end";
+    }
+  }
+
+  public void testMockGraphTokenFilterBasic() throws Exception {
+
+    for(int iter=0;iter<10*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      checkAnalysisConsistency(random(), a, false, "a b c d e f g h i j k");
+    }
+  }
+
+  public void testMockGraphTokenFilterOnGraphInput() throws Exception {
+    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new GraphTokenizer();
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      checkAnalysisConsistency(random(), a, false, "a/x:3 c/y:2 d e f/z:4 g h i j k");
+    }
+  }
+
+  // Just deletes (leaving hole) token 'a':
+  private final static class RemoveATokens extends TokenFilter {
+    private int pendingPosInc;
+
+    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+    private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+
+    public RemoveATokens(TokenStream in) {
+      super(in);
+    }
+
+    @Override
+    public void reset() throws IOException {
+      super.reset();
+      pendingPosInc = 0;
+    }
+
+    @Override
+    public void end() throws IOException {
+      super.end();
+      posIncAtt.setPositionIncrement(pendingPosInc + posIncAtt.getPositionIncrement());
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      while (true) {
+        final boolean gotOne = input.incrementToken();
+        if (!gotOne) {
+          return false;
+        } else if (termAtt.toString().equals("a")) {
+          pendingPosInc += posIncAtt.getPositionIncrement();
+        } else {
+          posIncAtt.setPositionIncrement(pendingPosInc + posIncAtt.getPositionIncrement());
+          pendingPosInc = 0;
+          return true;
+        }
+      }
+    }
+  }
+
+  public void testMockGraphTokenFilterBeforeHoles() throws Exception {
+    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
+            final TokenStream t3 = new RemoveATokens(t2);
+            return new TokenStreamComponents(t, t3);
+          }
+        };
+
+      Random random = random();
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k");
+      checkAnalysisConsistency(random, a, false, "x y a b c d e f g h i j k");
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a");
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a x y");
+    }
+  }
+
+  public void testMockGraphTokenFilterAfterHoles() throws Exception {
+    for(int iter=0;iter<100*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t2 = new RemoveATokens(t);
+            final TokenStream t3 = new MockGraphTokenFilter(random(), t2);
+            return new TokenStreamComponents(t, t3);
+          }
+        };
+
+      Random random = random();
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k");
+      checkAnalysisConsistency(random, a, false, "x y a b c d e f g h i j k");
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a");
+      checkAnalysisConsistency(random, a, false, "a b c d e f g h i j k a x y");
+    }
+  }
+
+  public void testMockGraphTokenFilterRandom() throws Exception {
+    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      Random random = random();
+      checkRandomData(random, a, 5, atLeast(100));
+    }
+  }
+
+  // Two MockGraphTokenFilters
+  public void testDoubleMockGraphTokenFilterRandom() throws Exception {
+    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t1 = new MockGraphTokenFilter(random(), t);
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t1);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      Random random = random();
+      checkRandomData(random, a, 5, atLeast(100));
+    }
+  }
+
+  public void testMockGraphTokenFilterBeforeHolesRandom() throws Exception {
+    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t1 = new MockGraphTokenFilter(random(), t);
+            final TokenStream t2 = new MockHoleInjectingTokenFilter(random(), t1);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      Random random = random();
+      checkRandomData(random, a, 5, atLeast(100));
+    }
+  }
+
+  public void testMockGraphTokenFilterAfterHolesRandom() throws Exception {
+    for(int iter=0;iter<3*RANDOM_MULTIPLIER;iter++) {
+
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + iter);
+      }
+
+      // Make new analyzer each time, because MGTF has fixed
+      // seed:
+      final Analyzer a = new Analyzer() {
+          @Override
+          protected TokenStreamComponents createComponents(String fieldName) {
+            final Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+            final TokenStream t1 = new MockHoleInjectingTokenFilter(random(), t);
+            final TokenStream t2 = new MockGraphTokenFilter(random(), t1);
+            return new TokenStreamComponents(t, t2);
+          }
+        };
+      
+      Random random = random();
+      checkRandomData(random, a, 5, atLeast(100));
+    }
+  }
+
+  private static Token token(String term, int posInc, int posLength) {
+    final Token t = new Token(term, 0, 0);
+    t.setPositionIncrement(posInc);
+    t.setPositionLength(posLength);
+    return t;
+  }
+
+  private static Token token(String term, int posInc, int posLength, int startOffset, int endOffset) {
+    final Token t = new Token(term, startOffset, endOffset);
+    t.setPositionIncrement(posInc);
+    t.setPositionLength(posLength);
+    return t;
+  }
+
+  public void testSingleToken() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+      });
+    assertSameLanguage(s2a("abc"), ts);
+  }
+
+  public void testMultipleHoles() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("a", 1, 1),
+        token("b", 3, 1),
+      });
+    assertSameLanguage(join(s2a("a"), SEP_A, HOLE_A, SEP_A, HOLE_A, SEP_A, s2a("b")), ts);
+  }
+
+  public void testSynOverMultipleHoles() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("a", 1, 1),
+        token("x", 0, 3),
+        token("b", 3, 1),
+      });
+    final Automaton a1 = join(s2a("a"), SEP_A, HOLE_A, SEP_A, HOLE_A, SEP_A, s2a("b")); 
+    final Automaton a2 = join(s2a("x"), SEP_A, s2a("b")); 
+    assertSameLanguage(Operations.union(a1, a2), ts);
+  }
+
+  // for debugging!
+  /*
+  private static void toDot(Automaton a) throws IOException {
+    final String s = a.toDot();
+    Writer w = new OutputStreamWriter(new FileOutputStream("/x/tmp/out.dot"));
+    w.write(s);
+    w.close();
+    System.out.println("TEST: saved to /x/tmp/out.dot");
+  }
+  */
+
+  private static final Automaton SEP_A = Automata.makeChar(TokenStreamToAutomaton.POS_SEP);
+  private static final Automaton HOLE_A = Automata.makeChar(TokenStreamToAutomaton.HOLE);
+
+  private Automaton join(String ... strings) {
+    List<Automaton> as = new ArrayList<>();
+    for(String s : strings) {
+      as.add(s2a(s));
+      as.add(SEP_A);
+    }
+    as.remove(as.size()-1);
+    return Operations.concatenate(as);
+  }
+
+  private Automaton join(Automaton ... as) {
+    return Operations.concatenate(Arrays.asList(as));
+  }
+
+  private Automaton s2a(String s) {
+    return Automata.makeString(s);
+  }
+
+  public void testTwoTokens() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+        token("def", 1, 1),
+      });
+    assertSameLanguage(join("abc", "def"), ts);
+  }
+
+  public void testHole() throws Exception {
+
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+        token("def", 2, 1),
+      });
+    assertSameLanguage(join(s2a("abc"), SEP_A, HOLE_A, SEP_A, s2a("def")), ts);
+  }
+
+  public void testOverlappedTokensSausage() throws Exception {
+
+    // Two tokens on top of each other (sausage):
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+        token("xyz", 0, 1)
+      });
+    final Automaton a1 = s2a("abc");
+    final Automaton a2 = s2a("xyz");
+    assertSameLanguage(Operations.union(a1, a2), ts);
+  }
+
+  public void testOverlappedTokensLattice() throws Exception {
+
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+        token("xyz", 0, 2),
+        token("def", 1, 1),
+      });
+    final Automaton a1 = s2a("xyz");
+    final Automaton a2 = join("abc", "def");
+    assertSameLanguage(Operations.union(a1, a2), ts);
+  }
+
+  public void testSynOverHole() throws Exception {
+
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("a", 1, 1),
+        token("X", 0, 2),
+        token("b", 2, 1),
+      });
+    final Automaton a1 = Operations.union(join(s2a("a"), SEP_A, HOLE_A), s2a("X"));
+    final Automaton expected = Operations.concatenate(a1, join(SEP_A, s2a("b")));
+    assertSameLanguage(expected, ts);
+  }
+
+  public void testSynOverHole2() throws Exception {
+
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("xyz", 1, 1),
+        token("abc", 0, 3),
+        token("def", 2, 1),
+      });
+    final Automaton expected = Operations.union(
+      join(s2a("xyz"), SEP_A, HOLE_A, SEP_A, s2a("def")), s2a("abc"));
+    assertSameLanguage(expected, ts);
+  }
+
+  public void testOverlappedTokensLattice2() throws Exception {
+
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 1, 1),
+        token("xyz", 0, 3),
+        token("def", 1, 1),
+        token("ghi", 1, 1),
+      });
+    final Automaton a1 = s2a("xyz");
+    final Automaton a2 = join("abc", "def", "ghi");
+    assertSameLanguage(Operations.union(a1, a2), ts);
+  }
+
+  public void testToDot() throws Exception {
+    final TokenStream ts = new CannedTokenStream(new Token[] {token("abc", 1, 1, 0, 4)});
+    StringWriter w = new StringWriter();
+    new TokenStreamToDot("abcd", ts, new PrintWriter(w)).toDot();
+    assertTrue(w.toString().indexOf("abc / abcd") != -1);
+  }
+
+  public void testStartsWithHole() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("abc", 2, 1),
+      });
+    assertSameLanguage(join(HOLE_A, SEP_A, s2a("abc")), ts);
+  }
+
+  // TODO: testEndsWithHole... but we need posInc to set in TS.end()
+
+  public void testSynHangingOverEnd() throws Exception {
+    final TokenStream ts = new CannedTokenStream(
+      new Token[] {
+        token("a", 1, 1),
+        token("X", 0, 10),
+      });
+    assertSameLanguage(Operations.union(s2a("a"), s2a("X")), ts);
+  }
+
+  private void assertSameLanguage(Automaton expected, TokenStream ts) throws IOException {
+    assertSameLanguage(expected, new TokenStreamToAutomaton().toAutomaton(ts));
+  }
+
+  private void assertSameLanguage(Automaton expected, Automaton actual) {
+    assertTrue(Operations.sameLanguage(
+      Operations.determinize(Operations.removeDeadStates(expected), DEFAULT_MAX_DETERMINIZED_STATES),
+      Operations.determinize(Operations.removeDeadStates(actual), DEFAULT_MAX_DETERMINIZED_STATES)));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java
new file mode 100644
index 0000000..50539e5
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestLookaheadTokenFilter.java
@@ -0,0 +1,98 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Random;
+
+public class TestLookaheadTokenFilter extends BaseTokenStreamTestCase {
+
+  public void testRandomStrings() throws Exception {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Random random = random();
+        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, random.nextBoolean());
+        TokenStream output = new MockRandomLookaheadTokenFilter(random, tokenizer);
+        return new TokenStreamComponents(tokenizer, output);
+      }
+    };
+    int maxLength = TEST_NIGHTLY ? 8192 : 1024;
+    checkRandomData(random(), a, 50*RANDOM_MULTIPLIER, maxLength);
+  }
+
+  private static class NeverPeeksLookaheadTokenFilter extends LookaheadTokenFilter<LookaheadTokenFilter.Position> {
+    public NeverPeeksLookaheadTokenFilter(TokenStream input) {
+      super(input);
+    }
+
+    @Override
+    public Position newPosition() {
+      return new Position();
+    }
+
+    @Override
+    public boolean incrementToken() throws IOException {
+      return nextToken();
+    }
+  }
+
+  public void testNeverCallingPeek() throws Exception {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, random().nextBoolean());
+        TokenStream output = new NeverPeeksLookaheadTokenFilter(tokenizer);
+        return new TokenStreamComponents(tokenizer, output);
+      }
+    };
+    int maxLength = TEST_NIGHTLY ? 8192 : 1024;
+    checkRandomData(random(), a, 50*RANDOM_MULTIPLIER, maxLength);
+  }
+
+  public void testMissedFirstToken() throws Exception {
+    Analyzer analyzer = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer source = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+        TrivialLookaheadFilter filter = new TrivialLookaheadFilter(source);
+        return new TokenStreamComponents(source, filter);
+     }
+    };
+
+    assertAnalyzesTo(analyzer,
+        "Only he who is running knows .",
+        new String[]{
+            "Only",
+            "Only-huh?",
+            "he",
+            "he-huh?",
+            "who",
+            "who-huh?",
+            "is",
+            "is-huh?",
+            "running",
+            "running-huh?",
+            "knows",
+            "knows-huh?",
+            ".",
+            ".-huh?"
+        });
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
new file mode 100644
index 0000000..5d3b756
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
@@ -0,0 +1,338 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+import java.util.Arrays;
+import java.util.Random;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.index.PostingsEnum;
+import org.apache.lucene.index.Fields;
+import org.apache.lucene.index.IndexOptions;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.util.BytesRef;
+import org.apache.lucene.util.TestUtil;
+import org.apache.lucene.util.automaton.Automata;
+import org.apache.lucene.util.automaton.AutomatonTestUtil;
+import org.apache.lucene.util.automaton.CharacterRunAutomaton;
+import org.apache.lucene.util.automaton.Operations;
+import org.apache.lucene.util.automaton.RegExp;
+
+import static org.apache.lucene.util.automaton.Operations.DEFAULT_MAX_DETERMINIZED_STATES;
+
+public class TestMockAnalyzer extends BaseTokenStreamTestCase {
+
+  /** Test a configuration that behaves a lot like WhitespaceAnalyzer */
+  public void testWhitespace() throws Exception {
+    Analyzer a = new MockAnalyzer(random());
+    assertAnalyzesTo(a, "A bc defg hiJklmn opqrstuv wxy z ",
+        new String[] { "a", "bc", "defg", "hijklmn", "opqrstuv", "wxy", "z" });
+    assertAnalyzesTo(a, "aba cadaba shazam",
+        new String[] { "aba", "cadaba", "shazam" });
+    assertAnalyzesTo(a, "break on whitespace",
+        new String[] { "break", "on", "whitespace" });
+  }
+  
+  /** Test a configuration that behaves a lot like SimpleAnalyzer */
+  public void testSimple() throws Exception {
+    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true);
+    assertAnalyzesTo(a, "a-bc123 defg+hijklmn567opqrstuv78wxy_z ",
+        new String[] { "a", "bc", "defg", "hijklmn", "opqrstuv", "wxy", "z" });
+    assertAnalyzesTo(a, "aba4cadaba-Shazam",
+        new String[] { "aba", "cadaba", "shazam" });
+    assertAnalyzesTo(a, "break+on/Letters",
+        new String[] { "break", "on", "letters" });
+  }
+  
+  /** Test a configuration that behaves a lot like KeywordAnalyzer */
+  public void testKeyword() throws Exception {
+    Analyzer a = new MockAnalyzer(random(), MockTokenizer.KEYWORD, false);
+    assertAnalyzesTo(a, "a-bc123 defg+hijklmn567opqrstuv78wxy_z ",
+        new String[] { "a-bc123 defg+hijklmn567opqrstuv78wxy_z " });
+    assertAnalyzesTo(a, "aba4cadaba-Shazam",
+        new String[] { "aba4cadaba-Shazam" });
+    assertAnalyzesTo(a, "break+on/Nothing",
+        new String[] { "break+on/Nothing" });
+    // currently though emits no tokens for empty string: maybe we can do it,
+    // but we don't want to emit tokens infinitely...
+    assertAnalyzesTo(a, "", new String[0]);
+  }
+  
+  // Test some regular expressions as tokenization patterns
+  /** Test a configuration where each character is a term */
+  public void testSingleChar() throws Exception {
+    CharacterRunAutomaton single =
+        new CharacterRunAutomaton(new RegExp(".").toAutomaton());
+    Analyzer a = new MockAnalyzer(random(), single, false);
+    assertAnalyzesTo(a, "foobar",
+        new String[] { "f", "o", "o", "b", "a", "r" },
+        new int[] { 0, 1, 2, 3, 4, 5 },
+        new int[] { 1, 2, 3, 4, 5, 6 }
+    );
+    checkRandomData(random(), a, 100);
+  }
+  
+  /** Test a configuration where two characters makes a term */
+  public void testTwoChars() throws Exception {
+    CharacterRunAutomaton single =
+        new CharacterRunAutomaton(new RegExp("..").toAutomaton());
+    Analyzer a = new MockAnalyzer(random(), single, false);
+    assertAnalyzesTo(a, "foobar",
+        new String[] { "fo", "ob", "ar"},
+        new int[] { 0, 2, 4 },
+        new int[] { 2, 4, 6 }
+    );
+    // make sure when last term is a "partial" match that end() is correct
+    assertTokenStreamContents(a.tokenStream("bogus", "fooba"),
+        new String[] { "fo", "ob" },
+        new int[] { 0, 2 },
+        new int[] { 2, 4 },
+        new int[] { 1, 1 },
+        new Integer(5)
+    );
+    checkRandomData(random(), a, 100);
+  }
+  
+  /** Test a configuration where three characters makes a term */
+  public void testThreeChars() throws Exception {
+    CharacterRunAutomaton single =
+        new CharacterRunAutomaton(new RegExp("...").toAutomaton());
+    Analyzer a = new MockAnalyzer(random(), single, false);
+    assertAnalyzesTo(a, "foobar",
+        new String[] { "foo", "bar"},
+        new int[] { 0, 3 },
+        new int[] { 3, 6 }
+    );
+    // make sure when last term is a "partial" match that end() is correct
+    assertTokenStreamContents(a.tokenStream("bogus", "fooba"),
+        new String[] { "foo" },
+        new int[] { 0 },
+        new int[] { 3 },
+        new int[] { 1 },
+        new Integer(5)
+    );
+    checkRandomData(random(), a, 100);
+  }
+  
+  /** Test a configuration where word starts with one uppercase */
+  public void testUppercase() throws Exception {
+    CharacterRunAutomaton single =
+        new CharacterRunAutomaton(new RegExp("[A-Z][a-z]*").toAutomaton());
+    Analyzer a = new MockAnalyzer(random(), single, false);
+    assertAnalyzesTo(a, "FooBarBAZ",
+        new String[] { "Foo", "Bar", "B", "A", "Z"},
+        new int[] { 0, 3, 6, 7, 8 },
+        new int[] { 3, 6, 7, 8, 9 }
+    );
+    assertAnalyzesTo(a, "aFooBar",
+        new String[] { "Foo", "Bar" },
+        new int[] { 1, 4 },
+        new int[] { 4, 7 }
+    );
+    checkRandomData(random(), a, 100);
+  }
+  
+  /** Test a configuration that behaves a lot like StopAnalyzer */
+  public void testStop() throws Exception {
+    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);
+    assertAnalyzesTo(a, "the quick brown a fox",
+        new String[] { "quick", "brown", "fox" },
+        new int[] { 2, 1, 2 });
+  }
+  
+  /** Test a configuration that behaves a lot like KeepWordFilter */
+  public void testKeep() throws Exception {
+    CharacterRunAutomaton keepWords = 
+      new CharacterRunAutomaton(
+          Operations.complement(
+              Operations.union(
+                  Arrays.asList(Automata.makeString("foo"), Automata.makeString("bar"))),
+              DEFAULT_MAX_DETERMINIZED_STATES));
+    Analyzer a = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, keepWords);
+    assertAnalyzesTo(a, "quick foo brown bar bar fox foo",
+        new String[] { "foo", "bar", "bar", "foo" },
+        new int[] { 2, 2, 1, 2 });
+  }
+  
+  /** Test a configuration that behaves a lot like LengthFilter */
+  public void testLength() throws Exception {
+    CharacterRunAutomaton length5 = new CharacterRunAutomaton(new RegExp(".{5,}").toAutomaton());
+    Analyzer a = new MockAnalyzer(random(), MockTokenizer.WHITESPACE, true, length5);
+    assertAnalyzesTo(a, "ok toolong fine notfine",
+        new String[] { "ok", "fine" },
+        new int[] { 1, 2 });
+  }
+  
+  /** Test MockTokenizer encountering a too long token */
+  public void testTooLongToken() throws Exception {
+    Analyzer whitespace = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer t = new MockTokenizer(MockTokenizer.WHITESPACE, false, 5);
+        return new TokenStreamComponents(t, t);
+      }
+    };
+    
+    assertTokenStreamContents(whitespace.tokenStream("bogus", "test 123 toolong ok "),
+        new String[] { "test", "123", "toolo", "ng", "ok" },
+        new int[] { 0, 5, 9, 14, 17 },
+        new int[] { 4, 8, 14, 16, 19 },
+        new Integer(20));
+    
+    assertTokenStreamContents(whitespace.tokenStream("bogus", "test 123 toolo"),
+        new String[] { "test", "123", "toolo" },
+        new int[] { 0, 5, 9 },
+        new int[] { 4, 8, 14 },
+        new Integer(14));
+  }
+  
+  public void testLUCENE_3042() throws Exception {
+    String testString = "t";
+    
+    Analyzer analyzer = new MockAnalyzer(random());
+    try (TokenStream stream = analyzer.tokenStream("dummy", testString)) {
+      stream.reset();
+      while (stream.incrementToken()) {
+        // consume
+      }
+      stream.end();
+    }
+    
+    assertAnalyzesTo(analyzer, testString, new String[] { "t" });
+  }
+
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random(), new MockAnalyzer(random()), atLeast(1000));
+  }
+  
+  /** blast some random strings through differently configured tokenizers */
+  public void testRandomRegexps() throws Exception {
+    int iters = TEST_NIGHTLY ? atLeast(30) : atLeast(1);
+    for (int i = 0; i < iters; i++) {
+      final CharacterRunAutomaton dfa = new CharacterRunAutomaton(AutomatonTestUtil.randomAutomaton(random()), Integer.MAX_VALUE);
+      final boolean lowercase = random().nextBoolean();
+      final int limit = TestUtil.nextInt(random(), 0, 500);
+      Analyzer a = new Analyzer() {
+        @Override
+        protected TokenStreamComponents createComponents(String fieldName) {
+          Tokenizer t = new MockTokenizer(dfa, lowercase, limit);
+          return new TokenStreamComponents(t, t);
+        }
+      };
+      checkRandomData(random(), a, 100);
+      a.close();
+    }
+  }
+  
+  public void testForwardOffsets() throws Exception {
+    int num = atLeast(1000);
+    for (int i = 0; i < num; i++) {
+      String s = TestUtil.randomHtmlishString(random(), 20);
+      StringReader reader = new StringReader(s);
+      MockCharFilter charfilter = new MockCharFilter(reader, 2);
+      MockAnalyzer analyzer = new MockAnalyzer(random());
+      try (TokenStream ts = analyzer.tokenStream("bogus", charfilter)) {
+        ts.reset();
+        while (ts.incrementToken()) {
+          ;
+        }
+        ts.end();
+      }
+    }
+  }
+  
+  public void testWrapReader() throws Exception {
+    // LUCENE-5153: test that wrapping an analyzer's reader is allowed
+    final Random random = random();
+    
+    final Analyzer delegate = new MockAnalyzer(random);
+    Analyzer a = new AnalyzerWrapper(delegate.getReuseStrategy()) {
+      
+      @Override
+      protected Reader wrapReader(String fieldName, Reader reader) {
+        return new MockCharFilter(reader, 7);
+      }
+      
+      @Override
+      protected Analyzer getWrappedAnalyzer(String fieldName) {
+        return delegate;
+      }
+    };
+    
+    checkOneTerm(a, "abc", "aabc");
+  }
+
+  public void testChangeGaps() throws Exception {
+    // LUCENE-5324: check that it is possible to change the wrapper's gaps
+    final int positionGap = random().nextInt(1000);
+    final int offsetGap = random().nextInt(1000);
+    final Analyzer delegate = new MockAnalyzer(random());
+    final Analyzer a = new DelegatingAnalyzerWrapper(delegate.getReuseStrategy()) {
+      @Override
+      protected Analyzer getWrappedAnalyzer(String fieldName) {
+        return delegate;
+      }
+      @Override
+      public int getPositionIncrementGap(String fieldName) {
+        return positionGap;
+      }
+      @Override
+      public int getOffsetGap(String fieldName) {
+        return offsetGap;
+      }
+    };
+
+    final RandomIndexWriter writer = new RandomIndexWriter(random(), newDirectory(), a);
+    final Document doc = new Document();
+    final FieldType ft = new FieldType();
+    ft.setIndexOptions(IndexOptions.DOCS);
+    ft.setTokenized(true);
+    ft.setStoreTermVectors(true);
+    ft.setStoreTermVectorPositions(true);
+    ft.setStoreTermVectorOffsets(true);
+    doc.add(new Field("f", "a", ft));
+    doc.add(new Field("f", "a", ft));
+    writer.addDocument(doc);
+    final LeafReader reader = getOnlySegmentReader(writer.getReader());
+    final Fields fields = reader.getTermVectors(0);
+    final Terms terms = fields.terms("f");
+    final TermsEnum te = terms.iterator();
+    assertEquals(new BytesRef("a"), te.next());
+    final PostingsEnum dpe = te.postings(null, null, PostingsEnum.ALL);
+    assertEquals(0, dpe.nextDoc());
+    assertEquals(2, dpe.freq());
+    assertEquals(0, dpe.nextPosition());
+    assertEquals(0, dpe.startOffset());
+    final int endOffset = dpe.endOffset();
+    assertEquals(1 + positionGap, dpe.nextPosition());
+    assertEquals(1 + endOffset + offsetGap, dpe.endOffset());
+    assertEquals(null, te.next());
+    reader.close();
+    writer.close();
+    writer.w.getDirectory().close();
+  }
+
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockCharFilter.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
new file mode 100644
index 0000000..617e6dc
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
@@ -0,0 +1,58 @@
+package org.apache.lucene.analysis;
+
+import java.io.IOException;
+import java.io.Reader;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestMockCharFilter extends BaseTokenStreamTestCase {
+  
+  public void test() throws IOException {
+    Analyzer analyzer = new Analyzer() {
+
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName) {
+        Tokenizer tokenizer = new MockTokenizer(MockTokenizer.WHITESPACE, false);
+        return new TokenStreamComponents(tokenizer, tokenizer);
+      }
+
+      @Override
+      protected Reader initReader(String fieldName, Reader reader) {
+        return new MockCharFilter(reader, 7);
+      }
+    };
+    
+    assertAnalyzesTo(analyzer, "ab",
+        new String[] { "aab" },
+        new int[] { 0 },
+        new int[] { 2 }
+    );
+    
+    assertAnalyzesTo(analyzer, "aba",
+        new String[] { "aabaa" },
+        new int[] { 0 },
+        new int[] { 3 }
+    );
+    
+    assertAnalyzesTo(analyzer, "abcdefga",
+        new String[] { "aabcdefgaa" },
+        new int[] { 0 },
+        new int[] { 8 }
+    );
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TestPosition.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestPosition.java
new file mode 100644
index 0000000..389768b
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TestPosition.java
@@ -0,0 +1,37 @@
+package org.apache.lucene.analysis;
+
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.junit.Ignore;
+
+/**
+ * Trivial position class.
+ */
+@Ignore
+public class TestPosition extends LookaheadTokenFilter.Position {
+  private String fact;
+
+  public String getFact() {
+    return fact;
+  }
+
+  public void setFact(String fact) {
+    this.fact = fact;
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java b/lucene/test-framework/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java
new file mode 100644
index 0000000..cf50927
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/analysis/TrivialLookaheadFilter.java
@@ -0,0 +1,104 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+
+/**
+ * Simple example of a filter that seems to show some problems with LookaheadTokenFilter.
+ */
+final public class TrivialLookaheadFilter extends LookaheadTokenFilter<TestPosition> {
+
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+
+  private int insertUpto;
+
+  protected TrivialLookaheadFilter(TokenStream input) {
+    super(input);
+  }
+
+  @Override
+  protected TestPosition newPosition() {
+    return new TestPosition();
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    // At the outset, getMaxPos is -1. So we'll peek. When we reach the end of the sentence and go to the
+    // first token of the next sentence, maxPos will be the prev sentence's end token, and we'll go again.
+    if (positions.getMaxPos() < outputPos) {
+      peekSentence();
+    }
+
+    return nextToken();
+  }
+
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    insertUpto = -1;
+  }
+
+  @Override
+  protected void afterPosition() throws IOException {
+    if (insertUpto < outputPos) {
+      insertToken();
+      // replace term with 'improved' term.
+      clearAttributes();
+      termAtt.setEmpty();
+      posIncAtt.setPositionIncrement(0);
+      termAtt.append(positions.get(outputPos).getFact());
+      offsetAtt.setOffset(positions.get(outputPos).startOffset,
+                          positions.get(outputPos+1).endOffset);
+      insertUpto = outputPos;
+    }
+  }
+
+  private void peekSentence() throws IOException {
+    List<String> facts = new ArrayList<>();
+    boolean haveSentence = false;
+    do {
+      if (peekToken()) {
+
+        String term = new String(termAtt.buffer(), 0, termAtt.length());
+        facts.add(term + "-huh?");
+        if (".".equals(term)) {
+          haveSentence = true;
+        }
+
+      } else {
+        haveSentence = true;
+      }
+
+    } while (!haveSentence);
+
+    // attach the (now disambiguated) analyzed tokens to the positions.
+    for (int x = 0; x < facts.size(); x++) {
+      // sentenceTokens is just relative to sentence, positions is absolute.
+      positions.get(outputPos + x).setFact(facts.get(x));
+    }
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java
new file mode 100644
index 0000000..5705a2e
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingDocValuesFormat.java
@@ -0,0 +1,31 @@
+package org.apache.lucene.codecs.asserting;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BaseDocValuesFormatTestCase;
+
+/** Test AssertingDocValuesFormat directly */
+public class TestAssertingDocValuesFormat extends BaseDocValuesFormatTestCase {
+  private final Codec codec = new AssertingCodec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java
new file mode 100644
index 0000000..d5adad0
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingNormsFormat.java
@@ -0,0 +1,31 @@
+package org.apache.lucene.codecs.asserting;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BaseNormsFormatTestCase;
+
+/** Test AssertingNormsFormat directly */
+public class TestAssertingNormsFormat extends BaseNormsFormatTestCase {
+  private final Codec codec = new AssertingCodec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  } 
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java
new file mode 100644
index 0000000..7c78596
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingPostingsFormat.java
@@ -0,0 +1,36 @@
+package org.apache.lucene.codecs.asserting;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BasePostingsFormatTestCase;
+
+/** Test AssertingPostingsFormat directly */
+public class TestAssertingPostingsFormat extends BasePostingsFormatTestCase {
+  private final Codec codec = new AssertingCodec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  }
+
+  @Override
+  protected boolean isPostingsEnumReuseImplemented() {
+    return false;
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java
new file mode 100644
index 0000000..73fcf93
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingStoredFieldsFormat.java
@@ -0,0 +1,31 @@
+package org.apache.lucene.codecs.asserting;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BaseTermVectorsFormatTestCase;
+
+/** Test AssertingTermVectorsFormat directly */
+public class TestAssertingStoredFieldsFormat extends BaseTermVectorsFormatTestCase {
+  private final Codec codec = new AssertingCodec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  } 
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java
new file mode 100644
index 0000000..09fbb48
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/asserting/TestAssertingTermVectorsFormat.java
@@ -0,0 +1,31 @@
+package org.apache.lucene.codecs.asserting;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.index.BaseTermVectorsFormatTestCase;
+
+/** Test AssertingTermVectorsFormat directly */
+public class TestAssertingTermVectorsFormat extends BaseTermVectorsFormatTestCase {
+  private final Codec codec = new AssertingCodec();
+  
+  @Override
+  protected Codec getCodec() {
+    return codec;
+  } 
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
new file mode 100644
index 0000000..2afda04
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingStoredFieldsFormat.java
@@ -0,0 +1,322 @@
+package org.apache.lucene.codecs.compressing;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Random;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.IntField;
+import org.apache.lucene.document.StoredField;
+import org.apache.lucene.index.BaseStoredFieldsFormatTestCase;
+import org.apache.lucene.index.CodecReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.NoMergePolicy;
+import org.apache.lucene.store.ByteArrayDataInput;
+import org.apache.lucene.store.ByteArrayDataOutput;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.MockDirectoryWrapper;
+import org.junit.Test;
+
+import com.carrotsearch.randomizedtesting.generators.RandomInts;
+
+public class TestCompressingStoredFieldsFormat extends BaseStoredFieldsFormatTestCase {
+
+  static final long SECOND = 1000L;
+  static final long HOUR = 60 * 60 * SECOND;
+  static final long DAY = 24 * HOUR;
+
+  @Override
+  protected Codec getCodec() {
+    return CompressingCodec.randomInstance(random());
+  }
+
+  public void testDeletePartiallyWrittenFilesIfAbort() throws IOException {
+    Directory dir = newDirectory();
+    // test explicitly needs files to always be actually deleted
+    if (dir instanceof MockDirectoryWrapper) {
+      ((MockDirectoryWrapper)dir).setEnableVirusScanner(false);
+    }
+    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
+    iwConf.setMaxBufferedDocs(RandomInts.randomIntBetween(random(), 2, 30));
+    iwConf.setCodec(CompressingCodec.randomInstance(random()));
+    // disable CFS because this test checks file names
+    iwConf.setMergePolicy(newLogMergePolicy(false));
+    iwConf.setUseCompoundFile(false);
+
+    // Cannot use RIW because this test wants CFS to stay off:
+    IndexWriter iw = new IndexWriter(dir, iwConf);
+
+    final Document validDoc = new Document();
+    validDoc.add(new IntField("id", 0, Store.YES));
+    iw.addDocument(validDoc);
+    iw.commit();
+    
+    // make sure that #writeField will fail to trigger an abort
+    final Document invalidDoc = new Document();
+    FieldType fieldType = new FieldType();
+    fieldType.setStored(true);
+    invalidDoc.add(new Field("invalid", fieldType) {
+      
+      @Override
+      public String stringValue() {
+        // TODO: really bad & scary that this causes IW to
+        // abort the segment!!  We should fix this.
+        return null;
+      }
+      
+    });
+    
+    try {
+      iw.addDocument(invalidDoc);
+      iw.commit();
+    } catch(IllegalArgumentException iae) {
+      // expected
+      assertEquals(iae, iw.getTragicException());
+    }
+    // Writer should be closed by tragedy
+    assertFalse(iw.isOpen());
+    dir.close();
+  }
+
+  public void testZFloat() throws Exception {
+    byte buffer[] = new byte[5]; // we never need more than 5 bytes
+    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
+    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
+
+    // round-trip small integer values
+    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
+      float f = (float) i;
+      CompressingStoredFieldsWriter.writeZFloat(out, f);
+      in.reset(buffer, 0, out.getPosition());
+      float g = CompressingStoredFieldsReader.readZFloat(in);
+      assertTrue(in.eof());
+      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
+
+      // check that compression actually works
+      if (i >= -1 && i <= 123) {
+        assertEquals(1, out.getPosition()); // single byte compression
+      }
+      out.reset(buffer);
+    }
+
+    // round-trip special values
+    float special[] = {
+        -0.0f,
+        +0.0f,
+        Float.NEGATIVE_INFINITY,
+        Float.POSITIVE_INFINITY,
+        Float.MIN_VALUE,
+        Float.MAX_VALUE,
+        Float.NaN,
+    };
+
+    for (float f : special) {
+      CompressingStoredFieldsWriter.writeZFloat(out, f);
+      in.reset(buffer, 0, out.getPosition());
+      float g = CompressingStoredFieldsReader.readZFloat(in);
+      assertTrue(in.eof());
+      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
+      out.reset(buffer);
+    }
+
+    // round-trip random values
+    Random r = random();
+    for (int i = 0; i < 100000; i++) {
+      float f = r.nextFloat() * (random().nextInt(100) - 50);
+      CompressingStoredFieldsWriter.writeZFloat(out, f);
+      assertTrue("length=" + out.getPosition() + ", f=" + f, out.getPosition() <= ((Float.floatToIntBits(f) >>> 31) == 1 ? 5 : 4));
+      in.reset(buffer, 0, out.getPosition());
+      float g = CompressingStoredFieldsReader.readZFloat(in);
+      assertTrue(in.eof());
+      assertEquals(Float.floatToIntBits(f), Float.floatToIntBits(g));
+      out.reset(buffer);
+    }
+  }
+
+  public void testZDouble() throws Exception {
+    byte buffer[] = new byte[9]; // we never need more than 9 bytes
+    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
+    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
+
+    // round-trip small integer values
+    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
+      double x = (double) i;
+      CompressingStoredFieldsWriter.writeZDouble(out, x);
+      in.reset(buffer, 0, out.getPosition());
+      double y = CompressingStoredFieldsReader.readZDouble(in);
+      assertTrue(in.eof());
+      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
+
+      // check that compression actually works
+      if (i >= -1 && i <= 124) {
+        assertEquals(1, out.getPosition()); // single byte compression
+      }
+      out.reset(buffer);
+    }
+
+    // round-trip special values
+    double special[] = {
+        -0.0d,
+        +0.0d,
+        Double.NEGATIVE_INFINITY,
+        Double.POSITIVE_INFINITY,
+        Double.MIN_VALUE,
+        Double.MAX_VALUE,
+        Double.NaN
+    };
+
+    for (double x : special) {
+      CompressingStoredFieldsWriter.writeZDouble(out, x);
+      in.reset(buffer, 0, out.getPosition());
+      double y = CompressingStoredFieldsReader.readZDouble(in);
+      assertTrue(in.eof());
+      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
+      out.reset(buffer);
+    }
+
+    // round-trip random values
+    Random r = random();
+    for (int i = 0; i < 100000; i++) {
+      double x = r.nextDouble() * (random().nextInt(100) - 50);
+      CompressingStoredFieldsWriter.writeZDouble(out, x);
+      assertTrue("length=" + out.getPosition() + ", d=" + x, out.getPosition() <= (x < 0 ? 9 : 8));
+      in.reset(buffer, 0, out.getPosition());
+      double y = CompressingStoredFieldsReader.readZDouble(in);
+      assertTrue(in.eof());
+      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
+      out.reset(buffer);
+    }
+
+    // same with floats
+    for (int i = 0; i < 100000; i++) {
+      double x = (double) (r.nextFloat() * (random().nextInt(100) - 50));
+      CompressingStoredFieldsWriter.writeZDouble(out, x);
+      assertTrue("length=" + out.getPosition() + ", d=" + x, out.getPosition() <= 5);
+      in.reset(buffer, 0, out.getPosition());
+      double y = CompressingStoredFieldsReader.readZDouble(in);
+      assertTrue(in.eof());
+      assertEquals(Double.doubleToLongBits(x), Double.doubleToLongBits(y));
+      out.reset(buffer);
+    }
+  }
+
+  public void testTLong() throws Exception {
+    byte buffer[] = new byte[10]; // we never need more than 10 bytes
+    ByteArrayDataOutput out = new ByteArrayDataOutput(buffer);
+    ByteArrayDataInput in = new ByteArrayDataInput(buffer);
+
+    // round-trip small integer values
+    for (int i = Short.MIN_VALUE; i < Short.MAX_VALUE; i++) {
+      for (long mul : new long[] {SECOND, HOUR, DAY}) {
+        long l1 = (long) i * mul;
+        CompressingStoredFieldsWriter.writeTLong(out, l1);
+        in.reset(buffer, 0, out.getPosition());
+        long l2 = CompressingStoredFieldsReader.readTLong(in);
+        assertTrue(in.eof());
+        assertEquals(l1, l2);
+
+        // check that compression actually works
+        if (i >= -16 && i <= 15) {
+          assertEquals(1, out.getPosition()); // single byte compression
+        }
+        out.reset(buffer);
+      }
+    }
+
+    // round-trip random values
+    Random r = random();
+    for (int i = 0; i < 100000; i++) {
+      final int numBits = r.nextInt(65);
+      long l1 = r.nextLong() & ((1L << numBits) - 1);
+      switch (r.nextInt(4)) {
+        case 0:
+          l1 *= SECOND;
+          break;
+        case 1:
+          l1 *= HOUR;
+          break;
+        case 2:
+          l1 *= DAY;
+          break;
+        default:
+          break;
+      }
+      CompressingStoredFieldsWriter.writeTLong(out, l1);
+      in.reset(buffer, 0, out.getPosition());
+      long l2 = CompressingStoredFieldsReader.readTLong(in);
+      assertTrue(in.eof());
+      assertEquals(l1, l2);
+      out.reset(buffer);
+    }
+  }
+  
+  /**
+   * writes some tiny segments with incomplete compressed blocks,
+   * and ensures merge recompresses them.
+   */
+  public void testChunkCleanup() throws IOException {
+    Directory dir = newDirectory();
+    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
+    iwConf.setMergePolicy(NoMergePolicy.INSTANCE);
+    
+    // we have to enforce certain things like maxDocsPerChunk to cause dirty chunks to be created
+    // by this test.
+    iwConf.setCodec(CompressingCodec.randomInstance(random(), 4*1024, 100, false, 8));
+    IndexWriter iw = new IndexWriter(dir, iwConf);
+    DirectoryReader ir = DirectoryReader.open(iw, true);
+    for (int i = 0; i < 5; i++) {
+      Document doc = new Document();
+      doc.add(new StoredField("text", "not very long at all"));
+      iw.addDocument(doc);
+      // force flush
+      DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
+      assertNotNull(ir2);
+      ir.close();
+      ir = ir2;
+      // examine dirty counts:
+      for (LeafReaderContext leaf : ir2.leaves()) {
+        CodecReader sr = (CodecReader) leaf.reader();
+        CompressingStoredFieldsReader reader = (CompressingStoredFieldsReader)sr.getFieldsReader();
+        assertEquals(1, reader.getNumChunks());
+        assertEquals(1, reader.getNumDirtyChunks());
+      }
+    }
+    iw.getConfig().setMergePolicy(newLogMergePolicy());
+    iw.forceMerge(1);
+    DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
+    assertNotNull(ir2);
+    ir.close();
+    ir = ir2;
+    CodecReader sr = getOnlySegmentReader(ir);
+    CompressingStoredFieldsReader reader = (CompressingStoredFieldsReader)sr.getFieldsReader();
+    // we could get lucky, and have zero, but typically one.
+    assertTrue(reader.getNumDirtyChunks() <= 1);
+    ir.close();
+    iw.close();
+    dir.close();
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java
new file mode 100644
index 0000000..7cfbe21
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/codecs/compressing/TestCompressingTermVectorsFormat.java
@@ -0,0 +1,130 @@
+package org.apache.lucene.codecs.compressing;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.MockAnalyzer;
+import org.apache.lucene.codecs.Codec;
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.FieldType;
+import org.apache.lucene.document.StoredField;
+import org.apache.lucene.document.TextField;
+import org.apache.lucene.index.CodecReader;
+import org.apache.lucene.index.DirectoryReader;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReader;
+import org.apache.lucene.index.BaseTermVectorsFormatTestCase;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.NoMergePolicy;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Terms;
+import org.apache.lucene.index.TermsEnum;
+import org.apache.lucene.index.TermsEnum.SeekStatus;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.BytesRef;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestCompressingTermVectorsFormat extends BaseTermVectorsFormatTestCase {
+
+  @Override
+  protected Codec getCodec() {
+    return CompressingCodec.randomInstance(random());
+  }
+  
+  // https://issues.apache.org/jira/browse/LUCENE-5156
+  public void testNoOrds() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
+    ft.setStoreTermVectors(true);
+    doc.add(new Field("foo", "this is a test", ft));
+    iw.addDocument(doc);
+    LeafReader ir = getOnlySegmentReader(iw.getReader());
+    Terms terms = ir.getTermVector(0, "foo");
+    assertNotNull(terms);
+    TermsEnum termsEnum = terms.iterator();
+    assertEquals(SeekStatus.FOUND, termsEnum.seekCeil(new BytesRef("this")));
+    try {
+      termsEnum.ord();
+      fail();
+    } catch (UnsupportedOperationException expected) {
+      // expected exception
+    }
+    
+    try {
+      termsEnum.seekExact(0);
+      fail();
+    } catch (UnsupportedOperationException expected) {
+      // expected exception
+    }
+    ir.close();
+    iw.close();
+    dir.close();
+  }
+  
+  /**
+   * writes some tiny segments with incomplete compressed blocks,
+   * and ensures merge recompresses them.
+   */
+  public void testChunkCleanup() throws IOException {
+    Directory dir = newDirectory();
+    IndexWriterConfig iwConf = newIndexWriterConfig(new MockAnalyzer(random()));
+    iwConf.setMergePolicy(NoMergePolicy.INSTANCE);
+    
+    // we have to enforce certain things like maxDocsPerChunk to cause dirty chunks to be created
+    // by this test.
+    iwConf.setCodec(CompressingCodec.randomInstance(random(), 4*1024, 100, false, 8));
+    IndexWriter iw = new IndexWriter(dir, iwConf);
+    DirectoryReader ir = DirectoryReader.open(iw, true);
+    for (int i = 0; i < 5; i++) {
+      Document doc = new Document();
+      FieldType ft = new FieldType(TextField.TYPE_NOT_STORED);
+      ft.setStoreTermVectors(true);
+      doc.add(new Field("text", "not very long at all", ft));
+      iw.addDocument(doc);
+      // force flush
+      DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
+      assertNotNull(ir2);
+      ir.close();
+      ir = ir2;
+      // examine dirty counts:
+      for (LeafReaderContext leaf : ir2.leaves()) {
+        CodecReader sr = (CodecReader) leaf.reader();
+        CompressingTermVectorsReader reader = (CompressingTermVectorsReader)sr.getTermVectorsReader();
+        assertEquals(1, reader.getNumChunks());
+        assertEquals(1, reader.getNumDirtyChunks());
+      }
+    }
+    iw.getConfig().setMergePolicy(newLogMergePolicy());
+    iw.forceMerge(1);
+    DirectoryReader ir2 = DirectoryReader.openIfChanged(ir);
+    assertNotNull(ir2);
+    ir.close();
+    ir = ir2;
+    CodecReader sr = getOnlySegmentReader(ir);
+    CompressingTermVectorsReader reader = (CompressingTermVectorsReader)sr.getTermVectorsReader();
+    // we could get lucky, and have zero, but typically one.
+    assertTrue(reader.getNumDirtyChunks() <= 1);
+    ir.close();
+    iw.close();
+    dir.close();
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java b/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java
new file mode 100644
index 0000000..d3f6b90
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/mockfile/TestMockFilesystems.java
@@ -0,0 +1,379 @@
+package org.apache.lucene.mockfile;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Closeable;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.net.URI;
+import java.nio.channels.AsynchronousFileChannel;
+import java.nio.channels.FileChannel;
+import java.nio.channels.SeekableByteChannel;
+import java.nio.charset.Charset;
+import java.nio.file.DirectoryStream;
+import java.nio.file.FileSystem;
+import java.nio.file.Files;
+import java.nio.file.NoSuchFileException;
+import java.nio.file.Path;
+import java.nio.file.StandardCopyOption;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+import org.apache.lucene.util.Constants;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.InfoStream;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestMockFilesystems extends LuceneTestCase {
+  
+  public void testLeakInputStream() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    InputStream leak = Files.newInputStream(wrapped.resolve("stillopen"));
+    try {
+      fs.close();
+      fail("should have gotten exception");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("file handle leaks"));
+    }
+    leak.close();
+  }
+  
+  public void testLeakOutputStream() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream leak = Files.newOutputStream(wrapped.resolve("leaky"));
+    try {
+      fs.close();
+      fail("should have gotten exception");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("file handle leaks"));
+    }
+    leak.close();
+  }
+  
+  public void testLeakFileChannel() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    FileChannel leak = FileChannel.open(wrapped.resolve("stillopen"));
+    try {
+      fs.close();
+      fail("should have gotten exception");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("file handle leaks"));
+    }
+    leak.close();
+  }
+  
+  public void testLeakAsyncFileChannel() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    AsynchronousFileChannel leak = AsynchronousFileChannel.open(wrapped.resolve("stillopen"));
+    try {
+      fs.close();
+      fail("should have gotten exception");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("file handle leaks"));
+    }
+    leak.close();
+  }
+  
+  public void testLeakByteChannel() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    SeekableByteChannel leak = Files.newByteChannel(wrapped.resolve("stillopen"));
+    try {
+      fs.close();
+      fail("should have gotten exception");
+    } catch (Exception e) {
+      assertTrue(e.getMessage().contains("file handle leaks"));
+    }
+    leak.close();
+  }
+ 
+  public void testDeleteOpenFile() throws IOException {
+    assumeFalse("windows is not supported", Constants.WINDOWS);
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
+    try {
+      Files.delete(wrapped.resolve("stillopen"));
+      fail("should have gotten exception");
+    } catch (IOException e) {
+      assertTrue(e.getMessage().contains("access denied"));
+    }
+    is.close();
+  }
+  
+  public void testDeleteIfExistsOpenFile() throws IOException {
+    assumeFalse("windows is not supported", Constants.WINDOWS);
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
+    try {
+      Files.deleteIfExists(wrapped.resolve("stillopen"));
+      fail("should have gotten exception");
+    } catch (IOException e) {
+      assertTrue(e.getMessage().contains("access denied"));
+    }
+    is.close();
+  }
+  
+  public void testRenameOpenFile() throws IOException {
+    assumeFalse("windows is not supported", Constants.WINDOWS);
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new WindowsFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("stillopen"));
+    file.write(5);
+    file.close();
+    InputStream is = Files.newInputStream(wrapped.resolve("stillopen"));
+    try {
+      Files.move(wrapped.resolve("stillopen"), wrapped.resolve("target"), StandardCopyOption.ATOMIC_MOVE);
+      fail("should have gotten exception");
+    } catch (IOException e) {
+      assertTrue(e.getMessage().contains("access denied"));
+    }
+    is.close();
+  }
+  
+  public void testVerboseWrite() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    final AtomicBoolean seenMessage = new AtomicBoolean(false);
+    InfoStream testStream = new InfoStream() {
+      @Override
+      public void close() throws IOException {}
+
+      @Override
+      public void message(String component, String message) {
+        if ("FS".equals(component) && message.startsWith("newOutputStream")) {
+          seenMessage.set(true);
+        }
+      }
+
+      @Override
+      public boolean isEnabled(String component) {
+        return true;
+      }
+    };
+    FileSystem fs = new VerboseFS(dir.getFileSystem(), testStream).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+    
+    OutputStream file = Files.newOutputStream(wrapped.resolve("output"));
+    assertTrue(seenMessage.get());
+    file.close();
+  }
+  
+  public void testVerboseFSNoSuchFileException() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new VerboseFS(dir.getFileSystem(), InfoStream.NO_OUTPUT).getFileSystem(URI.create("file:///"));    
+    Path wrapped = new FilterPath(dir, fs);
+    try {
+      AsynchronousFileChannel.open(wrapped.resolve("doesNotExist.rip"));
+      fail("did not hit exception");
+    } catch (NoSuchFileException nsfe) {
+      // expected
+    }
+    try {
+      FileChannel.open(wrapped.resolve("doesNotExist.rip"));
+      fail("did not hit exception");
+    } catch (NoSuchFileException nsfe) {
+      // expected
+    }
+    try {
+      Files.newByteChannel(wrapped.resolve("stillopen"));
+      fail("did not hit exception");
+    } catch (NoSuchFileException nsfe) {
+      // expected
+    }
+  }
+
+  public void testTooManyOpenFiles() throws IOException {
+    int n = 60;
+
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new HandleLimitFS(dir.getFileSystem(), n).getFileSystem(URI.create("file:///"));
+    dir = new FilterPath(dir, fs);
+    
+    // create open files to exact limit
+    List<Closeable> toClose = new ArrayList<>();
+    for (int i = 0; i < n; i++) {
+      Path p = Files.createTempFile(dir, null, null);
+      toClose.add(Files.newOutputStream(p));
+    }
+    
+    // now exceed
+    try {
+      Files.newOutputStream(Files.createTempFile(dir, null, null));
+      fail("didn't hit exception");
+    } catch (IOException e) {
+      assertTrue(e.getMessage().contains("Too many open files"));
+    }
+    
+    IOUtils.close(toClose);
+  }
+
+  public void testDirectoryStreamFiltered() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+
+    OutputStream file = Files.newOutputStream(wrapped.resolve("file1"));
+    file.write(5);
+    file.close();
+    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped)) {
+      int count = 0;
+      for (Path path : stream) {
+        assertTrue(path instanceof FilterPath);
+        if (!path.getFileName().toString().startsWith("extra")) {
+          count++;
+        }
+      }
+      assertEquals(1, count);
+    }
+
+    // check with LeakFS, a subclass of HandleTrackingFS which mucks with newDirectoryStream
+    dir = FilterPath.unwrap(createTempDir());
+    fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    wrapped = new FilterPath(dir, fs);
+
+    file = Files.newOutputStream(wrapped.resolve("file1"));
+    file.write(5);
+    file.close();
+    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped)) {
+      int count = 0;
+      for (Path path : stream) {
+        assertTrue(path instanceof FilterPath);
+        if (!path.getFileName().toString().startsWith("extra")) {
+          count++;
+        }
+      }
+      assertEquals(1, count);
+    }
+  }
+
+  public void testDirectoryStreamGlobFiltered() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+
+    OutputStream file = Files.newOutputStream(wrapped.resolve("foo"));
+    file.write(5);
+    file.close();
+    file = Files.newOutputStream(wrapped.resolve("bar"));
+    file.write(5);
+    file.close();
+    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped, "f*")) {
+      int count = 0;
+      for (Path path : stream) {
+        assertTrue(path instanceof FilterPath);
+        ++count;
+      }
+      assertEquals(1, count);
+    }
+
+    // check with LeakFS, a subclass of HandleTrackingFS which mucks with newDirectoryStream
+    dir = FilterPath.unwrap(createTempDir());
+    fs = new LeakFS(dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    wrapped = new FilterPath(dir, fs);
+
+    file = Files.newOutputStream(wrapped.resolve("foo"));
+    file.write(5);
+    file.close();
+    file = Files.newOutputStream(wrapped.resolve("bar"));
+    file.write(5);
+    file.close();
+    try (DirectoryStream<Path> stream = Files.newDirectoryStream(wrapped, "f*")) {
+      int count = 0;
+      for (Path path : stream) {
+        assertTrue(path instanceof FilterPath);
+        ++count;
+      }
+      assertEquals(1, count);
+    }
+  }
+  
+  public void testHashCodeEquals() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+
+    Path f1 = wrapped.resolve("file1");
+    Path f1Again = wrapped.resolve("file1");
+    Path f2 = wrapped.resolve("file2");
+    
+    assertEquals(f1, f1);
+    assertFalse(f1.equals(null));
+    assertEquals(f1, f1Again);
+    assertEquals(f1.hashCode(), f1Again.hashCode());
+    assertFalse(f1.equals(f2));
+  }
+  
+  public void testURI() throws IOException {
+    Path dir = FilterPath.unwrap(createTempDir());
+    FileSystem fs = new FilterFileSystemProvider("test://", dir.getFileSystem()).getFileSystem(URI.create("file:///"));
+    Path wrapped = new FilterPath(dir, fs);
+
+    Path f1 = wrapped.resolve("file1");
+    URI uri = f1.toUri();
+    Path f2 = fs.provider().getPath(uri);
+    assertEquals(f1, f2);
+    
+    assumeTrue(Charset.defaultCharset().name() + " can't encode chinese", 
+               Charset.defaultCharset().newEncoder().canEncode("??"));
+    Path f3 = wrapped.resolve("??");
+    URI uri2 = f3.toUri();
+    Path f4 = fs.provider().getPath(uri2);
+    assertEquals(f3, f4);
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java b/lucene/test-framework/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java
new file mode 100644
index 0000000..3602e01
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/store/TestMockDirectoryWrapper.java
@@ -0,0 +1,126 @@
+package org.apache.lucene.store;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.nio.file.Path;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase.Nightly;
+
+public class TestMockDirectoryWrapper extends BaseDirectoryTestCase {
+  
+  @Override
+  protected Directory getDirectory(Path path) throws IOException {
+    final MockDirectoryWrapper dir;
+    if (random().nextBoolean()) {
+      dir = newMockDirectory();
+    } else {
+      dir = newMockFSDirectory(path);
+    }
+    dir.setEnableVirusScanner(false); // test manipulates filesystem directly
+    return dir;
+  }
+  
+  // we wrap the directory in slow stuff, so only run nightly
+  @Override @Nightly
+  public void testThreadSafety() throws Exception {
+    super.testThreadSafety();
+  }
+  
+  public void testFailIfIndexWriterNotClosed() throws IOException {
+    MockDirectoryWrapper dir = newMockDirectory();
+    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
+    try {
+      dir.close();
+      fail();
+    } catch (Exception expected) {
+      assertTrue(expected.getMessage().contains("there are still open locks"));
+    } finally {
+      IOUtils.closeWhileHandlingException(iw);
+    }
+  }
+  
+  public void testFailIfIndexWriterNotClosedChangeLockFactory() throws IOException {
+    MockDirectoryWrapper dir = newMockDirectory(random(), new SingleInstanceLockFactory());
+    IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
+    try {
+      dir.close();
+      fail();
+    } catch (Exception expected) {
+      assertTrue(expected.getMessage().contains("there are still open locks"));
+    } finally {
+      IOUtils.closeWhileHandlingException(iw);
+    }
+  }
+  
+  public void testDiskFull() throws IOException {
+    // test writeBytes
+    MockDirectoryWrapper dir = newMockDirectory();
+    dir.setMaxSizeInBytes(3);
+    final byte[] bytes = new byte[] { 1, 2};
+    IndexOutput out = dir.createOutput("foo", IOContext.DEFAULT);
+    out.writeBytes(bytes, bytes.length); // first write should succeed
+    // close() to ensure the written bytes are not buffered and counted
+    // against the directory size
+    out.close();
+    out = dir.createOutput("bar", IOContext.DEFAULT);
+    try {
+      out.writeBytes(bytes, bytes.length);
+      fail("should have failed on disk full");
+    } catch (IOException e) {
+      // expected
+    }
+    out.close();
+    dir.close();
+    
+    // test copyBytes
+    dir = newMockDirectory();
+    dir.setMaxSizeInBytes(3);
+    out = dir.createOutput("foo", IOContext.DEFAULT);
+    out.copyBytes(new ByteArrayDataInput(bytes), bytes.length); // first copy should succeed
+    // close() to ensure the written bytes are not buffered and counted
+    // against the directory size
+    out.close();
+    out = dir.createOutput("bar", IOContext.DEFAULT);
+    try {
+      out.copyBytes(new ByteArrayDataInput(bytes), bytes.length);
+      fail("should have failed on disk full");
+    } catch (IOException e) {
+      // expected
+    }
+    out.close();
+    dir.close();
+  }
+  
+  public void testMDWinsideOfMDW() throws Exception {
+    // add MDW inside another MDW
+    Directory dir = new MockDirectoryWrapper(random(), newMockDirectory());
+    RandomIndexWriter iw = new RandomIndexWriter(random(), dir);
+    for (int i = 0; i < 20; i++) {
+      iw.addDocument(new Document());
+    }
+    iw.commit();
+    iw.close();
+    dir.close();
+  }  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/SorePoint.java b/lucene/test-framework/src/test/org/apache/lucene/util/SorePoint.java
new file mode 100644
index 0000000..0b533c1
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/SorePoint.java
@@ -0,0 +1,33 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * A pointcut-like definition where we should trigger
+ * an assumption or error.
+ */
+public enum SorePoint {
+  // STATIC_INITIALIZER, // I assume this will result in JUnit failure to load a suite.
+  BEFORE_CLASS,
+  INITIALIZER,
+  RULE,
+  BEFORE,
+  TEST,
+  AFTER,
+  AFTER_CLASS
+}
\ No newline at end of file
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/SoreType.java b/lucene/test-framework/src/test/org/apache/lucene/util/SoreType.java
new file mode 100644
index 0000000..ef888f0
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/SoreType.java
@@ -0,0 +1,24 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public enum SoreType {
+  ASSUMPTION,
+  FAILURE,
+  ERROR
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestBeforeAfterOverrides.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestBeforeAfterOverrides.java
new file mode 100644
index 0000000..165057f
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestBeforeAfterOverrides.java
@@ -0,0 +1,70 @@
+package org.apache.lucene.util;
+
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestBeforeAfterOverrides extends WithNestedTests {
+  public TestBeforeAfterOverrides() {
+    super(true);
+  }
+
+  public static class Before1 extends WithNestedTests.AbstractNestedTest {
+    @Before
+    public void before() {}
+    
+    public void testEmpty() {}
+  }
+  public static class Before2 extends Before1 {}
+  public static class Before3 extends Before2 {
+    @Override
+    @Before
+    public void before() {}
+  }
+
+  public static class After1 extends WithNestedTests.AbstractNestedTest {
+    @After
+    public void after() {}
+    
+    public void testEmpty() {}
+  }
+  public static class After2 extends Before1 {}
+  public static class After3 extends Before2 {
+    @After
+    public void after() {}
+  }
+
+  @Test
+  public void testBefore() {
+    Result result = JUnitCore.runClasses(Before3.class);
+    Assert.assertEquals(1, result.getFailureCount());
+    Assert.assertTrue(result.getFailures().get(0).getTrace().contains("There are overridden methods"));
+  }
+  
+  @Test
+  public void testAfter() {
+    Result result = JUnitCore.runClasses(Before3.class);
+    Assert.assertEquals(1, result.getFailureCount());
+    Assert.assertTrue(result.getFailures().get(0).getTrace().contains("There are overridden methods"));
+  }  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestCodecReported.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestCodecReported.java
new file mode 100644
index 0000000..869d657
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestCodecReported.java
@@ -0,0 +1,47 @@
+package org.apache.lucene.util;
+
+import org.apache.lucene.codecs.Codec;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestCodecReported extends WithNestedTests {
+  public TestCodecReported() {
+    super(true);
+  }
+  
+  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
+    public static String codecName;
+
+    public void testDummy() {
+      codecName = Codec.getDefault().getName();
+      fail();
+    }
+  }
+
+  @Test
+  public void testCorrectCodecReported() {
+    Result r = JUnitCore.runClasses(Nested1.class);
+    Assert.assertEquals(1, r.getFailureCount());
+    Assert.assertTrue(super.getSysErr(),
+        super.getSysErr().contains("codec=" + Nested1.codecName));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestExceptionInBeforeClassHooks.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestExceptionInBeforeClassHooks.java
new file mode 100644
index 0000000..cb454be
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestExceptionInBeforeClassHooks.java
@@ -0,0 +1,141 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.*;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import junit.framework.Assert;
+
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+
+public class TestExceptionInBeforeClassHooks extends WithNestedTests {
+  public TestExceptionInBeforeClassHooks() {
+    super(true);
+  }
+
+  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
+    @BeforeClass
+    public static void beforeClass() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar");
+        }
+      };
+      t.start();
+      t.join();
+    }
+
+    public void test() {}
+  }
+
+  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
+    public void test1() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar1");
+        }
+      };
+      t.start();
+      t.join();
+    }
+
+    public void test2() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar2");
+        }
+      };
+      t.start();
+      t.join();
+    }
+    
+    public void test3() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar3");
+        }
+      };
+      t.start();
+      t.join();
+    }    
+  }
+
+  public static class Nested3 extends WithNestedTests.AbstractNestedTest {
+    @Before
+    public void runBeforeTest() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar");
+        }
+      };
+      t.start();
+      t.join();
+    }
+
+    public void test1() throws Exception {
+    }
+  }
+
+  @Test
+  public void testExceptionInBeforeClassFailsTheTest() {
+    Result runClasses = JUnitCore.runClasses(Nested1.class);
+    assertFailureCount(1, runClasses);
+    Assert.assertEquals(1, runClasses.getRunCount());
+    Assert.assertTrue(runClasses.getFailures().get(0).getTrace().contains("foobar"));
+  }
+
+  @Test
+  public void testExceptionWithinTestFailsTheTest() {
+    Result runClasses = JUnitCore.runClasses(Nested2.class);
+    assertFailureCount(3, runClasses);
+    Assert.assertEquals(3, runClasses.getRunCount());
+    
+    ArrayList<String> foobars = new ArrayList<>();
+    for (Failure f : runClasses.getFailures()) {
+      Matcher m = Pattern.compile("foobar[0-9]+").matcher(f.getTrace());
+      while (m.find()) {
+        foobars.add(m.group());
+      }
+    }
+
+    Collections.sort(foobars);
+    Assert.assertEquals("[foobar1, foobar2, foobar3]", 
+        Arrays.toString(foobars.toArray()));
+  }
+  
+  @Test
+  public void testExceptionWithinBefore() {
+    Result runClasses = JUnitCore.runClasses(Nested3.class);
+    assertFailureCount(1, runClasses);
+    Assert.assertEquals(1, runClasses.getRunCount());
+    Assert.assertTrue(runClasses.getFailures().get(0).getTrace().contains("foobar"));
+  }  
+  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfDirectoryNotClosed.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfDirectoryNotClosed.java
new file mode 100644
index 0000000..5014f36
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfDirectoryNotClosed.java
@@ -0,0 +1,48 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.store.Directory;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+
+import com.carrotsearch.randomizedtesting.RandomizedTest;
+
+public class TestFailIfDirectoryNotClosed extends WithNestedTests {
+  public TestFailIfDirectoryNotClosed() {
+    super(true);
+  }
+
+  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
+    public void testDummy() throws Exception {
+      Directory dir = newDirectory();
+      System.out.println(dir.toString());
+    }
+  }
+
+  @Test
+  public void testFailIfDirectoryNotClosed() {
+    Result r = JUnitCore.runClasses(Nested1.class);
+    RandomizedTest.assumeTrue("Ignoring nested test, very likely zombie threads present.", 
+        r.getIgnoreCount() == 0);
+    assertFailureCount(1, r);
+    Assert.assertTrue(r.getFailures().get(0).toString().contains("Resource in scope SUITE failed to close"));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfUnreferencedFiles.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfUnreferencedFiles.java
new file mode 100644
index 0000000..03b6f40
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestFailIfUnreferencedFiles.java
@@ -0,0 +1,72 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Collections;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.store.MockDirectoryWrapper;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import com.carrotsearch.randomizedtesting.RandomizedTest;
+
+// LUCENE-4456: Test that we fail if there are unreferenced files
+public class TestFailIfUnreferencedFiles extends WithNestedTests {
+  public TestFailIfUnreferencedFiles() {
+    super(true);
+  }
+  
+  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
+    public void testDummy() throws Exception {
+      MockDirectoryWrapper dir = newMockDirectory();
+      dir.setAssertNoUnrefencedFilesOnClose(true);
+      IndexWriter iw = new IndexWriter(dir, new IndexWriterConfig(null));
+      iw.addDocument(new Document());
+      iw.close();
+      IndexOutput output = dir.createOutput("_hello.world", IOContext.DEFAULT);
+      output.writeString("i am unreferenced!");
+      output.close();
+      dir.sync(Collections.singleton("_hello.world"));
+      dir.close();
+    }
+  }
+
+  @Test
+  public void testFailIfUnreferencedFiles() {
+    Result r = JUnitCore.runClasses(Nested1.class);
+    RandomizedTest.assumeTrue("Ignoring nested test, very likely zombie threads present.", 
+        r.getIgnoreCount() == 0);
+
+    // We are suppressing output anyway so dump the failures.
+    for (Failure f : r.getFailures()) {
+      System.out.println(f.getTrace());
+    }
+
+    Assert.assertEquals("Expected exactly one failure.", 
+        1, r.getFailureCount());
+    Assert.assertTrue("Expected unreferenced files assertion.", 
+        r.getFailures().get(0).getTrace().contains("unreferenced files:"));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestGroupFiltering.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestGroupFiltering.java
new file mode 100644
index 0000000..a5ab446
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestGroupFiltering.java
@@ -0,0 +1,61 @@
+package org.apache.lucene.util;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.Inherited;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+
+import org.apache.lucene.util.LuceneTestCase;
+
+import com.carrotsearch.randomizedtesting.annotations.TestGroup;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestGroupFiltering extends LuceneTestCase {
+  @Documented
+  @Inherited
+  @Retention(RetentionPolicy.RUNTIME)
+  @TestGroup(enabled = false)
+  public @interface Foo {}
+  
+  @Documented
+  @Inherited
+  @Retention(RetentionPolicy.RUNTIME)
+  @TestGroup(enabled = false)
+  public @interface Bar {}
+
+  @Documented
+  @Inherited
+  @Retention(RetentionPolicy.RUNTIME)
+  @TestGroup(enabled = false)
+  public @interface Jira {
+    String bug();
+  }
+  
+  @Foo
+  public void testFoo() {}
+  
+  @Foo @Bar
+  public void testFooBar() {}
+
+  @Bar
+  public void testBar() {}
+
+  @Jira(bug = "JIRA bug reference")
+  public void testJira() {}
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestJUnitRuleOrder.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestJUnitRuleOrder.java
new file mode 100644
index 0000000..e4888fd
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestJUnitRuleOrder.java
@@ -0,0 +1,93 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Arrays;
+import java.util.Stack;
+
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.TestRule;
+import org.junit.runner.Description;
+import org.junit.runner.JUnitCore;
+import org.junit.runners.model.Statement;
+
+/**
+ * This verifies that JUnit {@link Rule}s are invoked before 
+ * {@link Before} and {@link  After} hooks. This should be the
+ * case from JUnit 4.10 on.
+ */
+public class TestJUnitRuleOrder extends WithNestedTests {
+  static Stack<String> stack;
+
+  public TestJUnitRuleOrder() {
+    super(true);
+  }
+  
+  public static class Nested extends WithNestedTests.AbstractNestedTest {
+    @Before
+    public void before() {
+      stack.push("@Before");
+    }
+    
+    @After
+    public void after() {
+      stack.push("@After");
+    }
+
+    @Rule
+    public TestRule testRule = new TestRule() {
+      @Override
+      public Statement apply(final Statement base, Description description) {
+        return new Statement() {
+          @Override
+          public void evaluate() throws Throwable {
+            stack.push("@Rule before");
+            base.evaluate();
+            stack.push("@Rule after");
+          }
+        };
+      }
+    };
+
+    @Test
+    public void test() {/* empty */}
+
+    @BeforeClass
+    public static void beforeClassCleanup() {
+      stack = new Stack<>();
+    }
+
+    @AfterClass
+    public static void afterClassCheck() {
+      stack.push("@AfterClass");
+    }    
+  }
+
+  @Test
+  public void testRuleOrder() {
+    JUnitCore.runClasses(Nested.class);
+    Assert.assertEquals(
+        Arrays.toString(stack.toArray()), "[@Rule before, @Before, @After, @Rule after, @AfterClass]");
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestLeaveFilesIfTestFails.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestLeaveFilesIfTestFails.java
new file mode 100644
index 0000000..7410a5b
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestLeaveFilesIfTestFails.java
@@ -0,0 +1,82 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.nio.channels.SeekableByteChannel;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
+
+import org.apache.lucene.util.Constants;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+
+import com.carrotsearch.randomizedtesting.RandomizedTest;
+
+public class TestLeaveFilesIfTestFails extends WithNestedTests {
+  public TestLeaveFilesIfTestFails() {
+    super(true);
+  }
+  
+  public static class Nested1 extends WithNestedTests.AbstractNestedTest {
+    static Path file;
+    public void testDummy() {
+      file = createTempDir("leftover");
+      fail();
+    }
+  }
+
+  @Test
+  public void testLeaveFilesIfTestFails() throws IOException {
+    Result r = JUnitCore.runClasses(Nested1.class);
+    Assert.assertEquals(1, r.getFailureCount());
+    Assert.assertTrue(Nested1.file != null && Files.exists(Nested1.file));
+    IOUtils.rm(Nested1.file);
+  }
+  
+  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
+    static Path file;
+    static Path parent;
+    static SeekableByteChannel openFile;
+
+    @SuppressWarnings("deprecation")
+    public void testDummy() throws Exception {
+      file = createTempDir("leftover").resolve("child.locked");
+      openFile = Files.newByteChannel(file, StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.CREATE);
+
+      parent = LuceneTestCase.getBaseTempDirForTestClass();
+    }
+  }
+
+  @Test
+  public void testWindowsUnremovableFile() throws IOException {
+    RandomizedTest.assumeTrue("Requires Windows.", Constants.WINDOWS);
+    RandomizedTest.assumeFalse(LuceneTestCase.LEAVE_TEMPORARY);
+
+    Result r = JUnitCore.runClasses(Nested2.class);
+    Assert.assertEquals(1, r.getFailureCount());
+
+    Nested2.openFile.close();
+    IOUtils.rm(Nested2.parent);
+  }  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestMaxFailuresRule.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestMaxFailuresRule.java
new file mode 100644
index 0000000..f1fd2de
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestMaxFailuresRule.java
@@ -0,0 +1,184 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.concurrent.CountDownLatch;
+
+import org.apache.lucene.util.WithNestedTests;
+import org.junit.Assert;
+import org.junit.BeforeClass;
+import org.junit.Test;
+import org.junit.runner.Description;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+import org.junit.runner.notification.RunListener;
+
+import com.carrotsearch.randomizedtesting.annotations.Repeat;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakAction;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope.Scope;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakZombies;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakZombies.Consequence;
+
+/**
+ * @see TestRuleIgnoreAfterMaxFailures
+ */
+public class TestMaxFailuresRule extends WithNestedTests {
+  public TestMaxFailuresRule() {
+    super(true);
+  }
+
+  public static class Nested extends WithNestedTests.AbstractNestedTest {
+    public static final int TOTAL_ITERS = 500;
+    public static final int DESIRED_FAILURES = TOTAL_ITERS / 10;
+    private int numFails = 0;
+    private int numIters = 0;
+
+    @Repeat(iterations = TOTAL_ITERS)
+    public void testFailSometimes() {
+      numIters++;
+      boolean fail = random().nextInt(5) == 0;
+      if (fail) numFails++;
+      // some seeds are really lucky ... so cheat.
+      if (numFails < DESIRED_FAILURES && 
+          DESIRED_FAILURES <= TOTAL_ITERS - numIters) {
+        fail = true;
+      }
+      assertFalse(fail);
+    }
+  }
+
+  @Test
+  public void testMaxFailures() {
+    LuceneTestCase.replaceMaxFailureRule(new TestRuleIgnoreAfterMaxFailures(2));
+    JUnitCore core = new JUnitCore();
+    final StringBuilder results = new StringBuilder();
+    core.addListener(new RunListener() {
+      char lastTest;
+
+      @Override
+      public void testStarted(Description description) throws Exception {
+        lastTest = 'S'; // success.
+      }
+
+      @Override
+      public void testAssumptionFailure(Failure failure) {
+        lastTest = 'A'; // assumption failure.
+      }
+
+      @Override
+      public void testFailure(Failure failure) throws Exception {
+        lastTest = 'F'; // failure
+      }
+
+      @Override
+      public void testFinished(Description description) throws Exception {
+        results.append(lastTest);
+      }
+    });
+
+    Result result = core.run(Nested.class);
+    Assert.assertEquals(500, result.getRunCount());
+    Assert.assertEquals(0, result.getIgnoreCount());
+    Assert.assertEquals(2, result.getFailureCount());
+
+    // Make sure we had exactly two failures followed by assumption-failures
+    // resulting from ignored tests.
+    Assert.assertTrue(results.toString(), 
+        results.toString().matches("(S*F){2}A+"));
+  }
+
+  @ThreadLeakZombies(Consequence.IGNORE_REMAINING_TESTS)
+  @ThreadLeakAction({ThreadLeakAction.Action.WARN})
+  @ThreadLeakScope(Scope.TEST)
+  @ThreadLeakLingering(linger = 500)
+  public static class Nested2 extends WithNestedTests.AbstractNestedTest {
+    public static final int TOTAL_ITERS = 10;
+    public static CountDownLatch die;
+    public static Thread zombie;
+    public static int testNum;
+    
+    @BeforeClass
+    public static void setup() {
+      assert zombie == null;
+      die = new CountDownLatch(1);
+      testNum = 0;
+    }
+
+    @Repeat(iterations = TOTAL_ITERS)
+    public void testLeaveZombie() {
+      if (++testNum == 2) {
+        zombie = new Thread() {
+          @Override
+          public void run() {
+            while (true) {
+              try {
+                die.await();
+                return;
+              } catch (Exception e) { /* ignore */ }
+            }
+          }
+        };
+        zombie.start();
+      }
+    }
+  }
+
+  @Test
+  public void testZombieThreadFailures() throws Exception {
+    LuceneTestCase.replaceMaxFailureRule(new TestRuleIgnoreAfterMaxFailures(1));
+    JUnitCore core = new JUnitCore();
+    final StringBuilder results = new StringBuilder();
+    core.addListener(new RunListener() {
+      char lastTest;
+
+      @Override
+      public void testStarted(Description description) throws Exception {
+        lastTest = 'S'; // success.
+      }
+
+      @Override
+      public void testAssumptionFailure(Failure failure) {
+        lastTest = 'A'; // assumption failure.
+      }
+
+      @Override
+      public void testFailure(Failure failure) throws Exception {
+        lastTest = 'F'; // failure
+        System.out.println(failure.getMessage());
+      }
+
+      @Override
+      public void testFinished(Description description) throws Exception {
+        results.append(lastTest);
+      }
+    });
+
+    Result result = core.run(Nested2.class);
+    if (Nested2.die != null) {
+      Nested2.die.countDown();
+      Nested2.zombie.join();
+    }
+    
+    super.prevSysOut.println(results.toString());
+    Assert.assertEquals(Nested2.TOTAL_ITERS, result.getRunCount());
+    Assert.assertEquals(results.toString(), "SFAAAAAAAA", results.toString());
+  }  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestRamUsageTesterOnWildAnimals.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestRamUsageTesterOnWildAnimals.java
new file mode 100644
index 0000000..cf45cb9
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestRamUsageTesterOnWildAnimals.java
@@ -0,0 +1,54 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.junit.Assert;
+
+/**
+ * Check large and special graphs. 
+ */
+public class TestRamUsageTesterOnWildAnimals extends LuceneTestCase {
+  public static class ListElement {
+    ListElement next;
+  }
+
+  public void testOverflowMaxChainLength() {
+    int UPPERLIMIT = 100000;
+    int lower = 0;
+    int upper = UPPERLIMIT;
+    
+    while (lower + 1 < upper) {
+      int mid = (lower + upper) / 2;
+      try {
+        ListElement first = new ListElement();
+        ListElement last = first;
+        for (int i = 0; i < mid; i++) {
+          last = (last.next = new ListElement());
+        }
+        RamUsageTester.sizeOf(first); // cause SOE or pass.
+        lower = mid;
+      } catch (StackOverflowError e) {
+        upper = mid;
+      }
+    }
+
+    if (lower + 1 < UPPERLIMIT) {
+      Assert.fail("Max object chain length till stack overflow: " + lower);
+    }
+  }  
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessage.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessage.java
new file mode 100644
index 0000000..50fee7c
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessage.java
@@ -0,0 +1,305 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Arrays;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.TestRule;
+import org.junit.runner.Description;
+import org.junit.runner.JUnitCore;
+import org.junit.runners.model.Statement;
+
+/**
+ * Test reproduce message is right.
+ */
+public class TestReproduceMessage extends WithNestedTests {
+  public static SorePoint where;
+  public static SoreType  type;
+  
+  public static class Nested extends AbstractNestedTest {
+    @BeforeClass
+    public static void beforeClass() {
+      if (isRunningNested()) {
+        triggerOn(SorePoint.BEFORE_CLASS);
+      }
+    }
+
+    @Rule
+    public TestRule rule = new TestRule() {
+      @Override
+      public Statement apply(final Statement base, Description description) {
+        return new Statement() {
+          @Override
+          public void evaluate() throws Throwable {
+            triggerOn(SorePoint.RULE);
+            base.evaluate();
+          }
+        };
+      }
+    };
+
+    /** Class initializer block/ default constructor. */
+    public Nested() {
+      triggerOn(SorePoint.INITIALIZER);
+    }
+
+    @Before
+    public void before() {
+      triggerOn(SorePoint.BEFORE);
+    }    
+
+    @Test
+    public void test() {
+      triggerOn(SorePoint.TEST);
+    }
+    
+    @After
+    public void after() {
+      triggerOn(SorePoint.AFTER);
+    }    
+
+    @AfterClass
+    public static void afterClass() {
+      if (isRunningNested()) {
+        triggerOn(SorePoint.AFTER_CLASS);
+      }
+    }    
+
+    /** */
+    private static void triggerOn(SorePoint pt) {
+      if (pt == where) {
+        switch (type) {
+          case ASSUMPTION:
+            LuceneTestCase.assumeTrue(pt.toString(), false);
+            throw new RuntimeException("unreachable");
+          case ERROR:
+            throw new RuntimeException(pt.toString());
+          case FAILURE:
+            Assert.assertTrue(pt.toString(), false);
+            throw new RuntimeException("unreachable");
+        }
+      }
+    }
+  }
+
+  /*
+   * ASSUMPTIONS.
+   */
+  
+  public TestReproduceMessage() {
+    super(true);
+  }
+
+  @Test
+  public void testAssumeBeforeClass() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.BEFORE_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  @Test
+  public void testAssumeInitializer() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.INITIALIZER;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  @Test
+  public void testAssumeRule() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.RULE;
+    Assert.assertEquals("", runAndReturnSyserr());
+  }
+
+  @Test
+  public void testAssumeBefore() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.BEFORE;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  @Test
+  public void testAssumeTest() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.TEST;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  @Test
+  public void testAssumeAfter() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.AFTER;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  @Test
+  public void testAssumeAfterClass() throws Exception { 
+    type = SoreType.ASSUMPTION; 
+    where = SorePoint.AFTER_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().isEmpty());
+  }
+
+  /*
+   * FAILURES
+   */
+  
+  @Test
+  public void testFailureBeforeClass() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.BEFORE_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  @Test
+  public void testFailureInitializer() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.INITIALIZER;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  @Test
+  public void testFailureRule() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.RULE;
+
+    final String syserr = runAndReturnSyserr();
+    
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testFailureBefore() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.BEFORE;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testFailureTest() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.TEST;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testFailureAfter() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.AFTER;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testFailureAfterClass() throws Exception { 
+    type = SoreType.FAILURE; 
+    where = SorePoint.AFTER_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  /*
+   * ERRORS
+   */
+  
+  @Test
+  public void testErrorBeforeClass() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.BEFORE_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  @Test
+  public void testErrorInitializer() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.INITIALIZER;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  @Test
+  public void testErrorRule() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.RULE;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testErrorBefore() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.BEFORE;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testErrorTest() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.TEST;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testErrorAfter() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.AFTER;
+    final String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains("NOTE: reproduce with:"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtests.method=test"));
+    Assert.assertTrue(Arrays.asList(syserr.split("\\s")).contains("-Dtestcase=" + Nested.class.getSimpleName()));
+  }
+
+  @Test
+  public void testErrorAfterClass() throws Exception { 
+    type = SoreType.ERROR; 
+    where = SorePoint.AFTER_CLASS;
+    Assert.assertTrue(runAndReturnSyserr().contains("NOTE: reproduce with:"));
+  }
+
+  private String runAndReturnSyserr() {
+    JUnitCore.runClasses(Nested.class);
+
+    String err = getSysErr();
+    // super.prevSysErr.println("Type: " + type + ", point: " + where + " resulted in:\n" + err);
+    // super.prevSysErr.println("---");
+    return err;
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessageWithRepeated.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessageWithRepeated.java
new file mode 100644
index 0000000..5b845c6
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestReproduceMessageWithRepeated.java
@@ -0,0 +1,53 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+
+import com.carrotsearch.randomizedtesting.annotations.Repeat;
+
+/**
+ * Test reproduce message is right with {@link Repeat} annotation.
+ */
+public class TestReproduceMessageWithRepeated extends WithNestedTests {
+  public static class Nested extends AbstractNestedTest {
+    @Test
+    @Repeat(iterations = 10)
+    public void testMe() {
+      throw new RuntimeException("bad");
+    }
+  }
+
+  public TestReproduceMessageWithRepeated() {
+    super(true);
+  }
+
+  @Test
+  public void testRepeatedMessage() throws Exception { 
+    String syserr = runAndReturnSyserr();
+    Assert.assertTrue(syserr.contains(" -Dtests.method=testMe "));
+  }
+
+  private String runAndReturnSyserr() {
+    JUnitCore.runClasses(Nested.class);
+    String err = getSysErr();
+    return err;
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestSeedFromUncaught.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestSeedFromUncaught.java
new file mode 100644
index 0000000..fecffd9
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestSeedFromUncaught.java
@@ -0,0 +1,62 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+
+/**
+ * Check that uncaught exceptions result in seed info being dumped to
+ * console. 
+ */
+public class TestSeedFromUncaught extends WithNestedTests {
+  public static class ThrowInUncaught extends AbstractNestedTest {
+    @Test
+    public void testFoo() throws Exception {
+      Thread t = new Thread() {
+        @Override
+        public void run() {
+          throw new RuntimeException("foobar");
+        }
+      };
+      t.start();
+      t.join();
+    }
+  }
+
+  public TestSeedFromUncaught() {
+    super(/* suppress normal output. */ true);
+  }
+
+  /**
+   * Verify super method calls on {@link LuceneTestCase#setUp()}.
+   */
+  @Test
+  public void testUncaughtDumpsSeed() {
+    Result result = JUnitCore.runClasses(ThrowInUncaught.class);
+    assertFailureCount(1, result);
+    Failure f = result.getFailures().get(0);
+    String trace = f.getTrace();
+    Assert.assertTrue(trace.contains("SeedInfo.seed("));
+    Assert.assertTrue(trace.contains("foobar"));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestSetupTeardownChaining.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestSetupTeardownChaining.java
new file mode 100644
index 0000000..72d6695
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestSetupTeardownChaining.java
@@ -0,0 +1,82 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.JUnitCore;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+
+/**
+ * Ensures proper functions of {@link LuceneTestCase#setUp()}
+ * and {@link LuceneTestCase#tearDown()}.
+ */
+public class TestSetupTeardownChaining extends WithNestedTests {
+  public static class NestedSetupChain extends AbstractNestedTest {
+    @Override
+    public void setUp() throws Exception {
+      // missing call.
+      System.out.println("Hello.");
+    }
+
+    @Test
+    public void testMe() {
+    }
+  }
+
+  public static class NestedTeardownChain extends AbstractNestedTest {
+    @Override
+    public void tearDown() throws Exception {
+      // missing call.
+    }
+
+    @Test
+    public void testMe() {
+    }
+  }
+
+  public TestSetupTeardownChaining() {
+    super(true);
+  }
+  
+  /**
+   * Verify super method calls on {@link LuceneTestCase#setUp()}.
+   */
+  @Test
+  public void testSetupChaining() {
+    Result result = JUnitCore.runClasses(NestedSetupChain.class);
+    Assert.assertEquals(1, result.getFailureCount());
+    Failure failure = result.getFailures().get(0);
+    Assert.assertTrue(failure.getMessage()
+        .contains("One of the overrides of setUp does not propagate the call."));
+  }
+  
+  /**
+   * Verify super method calls on {@link LuceneTestCase#tearDown()}.
+   */
+  @Test
+  public void testTeardownChaining() {
+    Result result = JUnitCore.runClasses(NestedTeardownChain.class);
+    Assert.assertEquals(1, result.getFailureCount());
+    Failure failure = result.getFailures().get(0);
+    Assert.assertTrue(failure.getMessage()
+        .contains("One of the overrides of tearDown does not propagate the call."));
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/TestWorstCaseTestBehavior.java b/lucene/test-framework/src/test/org/apache/lucene/util/TestWorstCaseTestBehavior.java
new file mode 100644
index 0000000..deb44cf
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/TestWorstCaseTestBehavior.java
@@ -0,0 +1,98 @@
+package org.apache.lucene.util;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Ignore;
+
+import com.carrotsearch.randomizedtesting.RandomizedTest;
+import com.carrotsearch.randomizedtesting.annotations.Timeout;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class TestWorstCaseTestBehavior extends LuceneTestCase {
+  @Ignore
+  public void testThreadLeak() {
+    Thread t = new Thread() {
+      @Override
+      public void run() {
+        try {
+          Thread.sleep(10000);
+        } catch (InterruptedException e) {
+          // Ignore.
+        }
+      }
+    };
+    t.start();
+
+    while (!t.isAlive()) {
+      Thread.yield();
+    }
+
+    // once alive, leave it to run outside of the test scope.
+  }
+
+  @Ignore
+  public void testLaaaaaargeOutput() throws Exception {
+    String message = "I will not OOM on large output";
+    int howMuch = 250 * 1024 * 1024;
+    for (int i = 0; i < howMuch; i++) {
+      if (i > 0) System.out.print(",\n");
+      System.out.print(message);
+      howMuch -= message.length(); // approximately.
+    }
+    System.out.println(".");
+  }
+
+  @Ignore
+  public void testProgressiveOutput() throws Exception {
+    for (int i = 0; i < 20; i++) {
+      System.out.println("Emitting sysout line: " + i);
+      System.err.println("Emitting syserr line: " + i);
+      System.out.flush();
+      System.err.flush();
+      RandomizedTest.sleep(1000);
+    }
+  }
+
+  @Ignore
+  public void testUncaughtException() throws Exception {
+    Thread t = new Thread() {
+      @Override
+      public void run() {
+        throw new RuntimeException("foobar");
+      }
+    };
+    t.start();
+    t.join();
+  }
+  
+  @Ignore
+  @Timeout(millis = 500)
+  public void testTimeout() throws Exception {
+    Thread.sleep(5000);
+  }
+  
+  @Ignore
+  @Timeout(millis = 1000)
+  public void testZombie() throws Exception {
+    while (true) {
+      try {
+        Thread.sleep(1000);
+      } catch (InterruptedException e) {}
+    }
+  }
+}
diff --git a/lucene/test-framework/src/test/org/apache/lucene/util/WithNestedTests.java b/lucene/test-framework/src/test/org/apache/lucene/util/WithNestedTests.java
new file mode 100644
index 0000000..3c1044f
--- /dev/null
+++ b/lucene/test-framework/src/test/org/apache/lucene/util/WithNestedTests.java
@@ -0,0 +1,196 @@
+package org.apache.lucene.util;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.ByteArrayOutputStream;
+import java.io.PrintStream;
+import java.io.UnsupportedEncodingException;
+import java.nio.charset.StandardCharsets;
+import java.util.List;
+
+import org.apache.lucene.util.FailureMarker;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures;
+import org.apache.lucene.util.TestRuleIgnoreTestSuites;
+import org.apache.lucene.util.TestRuleMarkFailure;
+import org.apache.lucene.util.TestRuleRestoreSystemProperties;
+import org.apache.lucene.util.LuceneTestCase.SuppressSysoutChecks;
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Assume;
+import org.junit.Before;
+import org.junit.ClassRule;
+import org.junit.Rule;
+import org.junit.rules.RuleChain;
+import org.junit.rules.TestRule;
+import org.junit.runner.Result;
+import org.junit.runner.notification.Failure;
+
+import com.carrotsearch.randomizedtesting.RandomizedRunner;
+import com.carrotsearch.randomizedtesting.RandomizedTest;
+import com.carrotsearch.randomizedtesting.SysGlobals;
+import com.carrotsearch.randomizedtesting.rules.TestRuleAdapter;
+
+/**
+ * An abstract test class that prepares nested test classes to run.
+ * A nested test class will assume it's executed under control of this
+ * class and be ignored otherwise. 
+ * 
+ * <p>The purpose of this is so that nested test suites don't run from
+ * IDEs like Eclipse (where they are automatically detected).
+ * 
+ * <p>This class cannot extend {@link LuceneTestCase} because in case
+ * there's a nested {@link LuceneTestCase} afterclass hooks run twice and
+ * cause havoc (static fields).
+ */
+public abstract class WithNestedTests {
+  @SuppressSysoutChecks(bugUrl = "WithNestedTests has its own stream capture.")
+  public static abstract class AbstractNestedTest extends LuceneTestCase 
+    implements TestRuleIgnoreTestSuites.NestedTestSuite {
+    protected static boolean isRunningNested() {
+      return TestRuleIgnoreTestSuites.isRunningNested();
+    }
+  }
+
+  private boolean suppressOutputStreams;
+
+  protected WithNestedTests(boolean suppressOutputStreams) {
+    this.suppressOutputStreams = suppressOutputStreams;
+  }
+  
+  protected PrintStream prevSysErr;
+  protected PrintStream prevSysOut;
+  private ByteArrayOutputStream sysout;
+  private ByteArrayOutputStream syserr;
+
+  @ClassRule
+  public static final TestRule classRules = RuleChain.outerRule(new TestRuleAdapter() {
+    private TestRuleIgnoreAfterMaxFailures prevRule;
+
+    protected void before() throws Throwable {
+      if (!isPropertyEmpty(SysGlobals.SYSPROP_TESTFILTER()) ||
+          !isPropertyEmpty(SysGlobals.SYSPROP_TESTCLASS())  ||
+          !isPropertyEmpty(SysGlobals.SYSPROP_TESTMETHOD()) ||
+          !isPropertyEmpty(SysGlobals.SYSPROP_ITERATIONS())) {
+        // We're running with a complex test filter that is properly handled by classes
+        // which are executed by RandomizedRunner. The "outer" classes testing LuceneTestCase
+        // itself are executed by the default JUnit runner and would be always executed.
+        // We thus always skip execution if any filtering is detected.
+        Assume.assumeTrue(false);
+      }
+      
+      // Check zombie threads from previous suites. Don't run if zombies are around.
+      RandomizedTest.assumeFalse(RandomizedRunner.hasZombieThreads());
+
+      TestRuleIgnoreAfterMaxFailures newRule = new TestRuleIgnoreAfterMaxFailures(Integer.MAX_VALUE);
+      prevRule = LuceneTestCase.replaceMaxFailureRule(newRule);
+      RandomizedTest.assumeFalse(FailureMarker.hadFailures());
+    }
+
+    protected void afterAlways(List<Throwable> errors) throws Throwable {
+      if (prevRule != null) {
+        LuceneTestCase.replaceMaxFailureRule(prevRule);
+      }
+      FailureMarker.resetFailures();
+    }
+
+    private boolean isPropertyEmpty(String propertyName) {
+      String value = System.getProperty(propertyName);
+      return value == null || value.trim().isEmpty();
+    }    
+  }); 
+
+  /**
+   * Restore properties after test.
+   */
+  @Rule
+  public final TestRule rules;
+  {
+    final TestRuleMarkFailure marker = new TestRuleMarkFailure();
+    rules = RuleChain
+      .outerRule(new TestRuleRestoreSystemProperties(TestRuleIgnoreTestSuites.PROPERTY_RUN_NESTED))
+      .around(new TestRuleAdapter() {
+        @Override
+        protected void afterAlways(List<Throwable> errors) throws Throwable {
+          if (marker.hadFailures() && suppressOutputStreams) {
+            System.out.println("sysout from nested test: " + getSysOut() + "\n");
+            System.out.println("syserr from nested test: " + getSysErr());
+          }
+        }
+      })
+      .around(marker);
+  }
+
+  @Before
+  public final void before() {
+    if (suppressOutputStreams) {
+      prevSysOut = System.out;
+      prevSysErr = System.err;
+
+      try {
+        sysout = new ByteArrayOutputStream();
+        System.setOut(new PrintStream(sysout, true, IOUtils.UTF_8));
+        syserr = new ByteArrayOutputStream();
+        System.setErr(new PrintStream(syserr, true, IOUtils.UTF_8));
+      } catch (UnsupportedEncodingException e) {
+        throw new RuntimeException(e);
+      }
+    }
+
+    FailureMarker.resetFailures();
+    System.setProperty(TestRuleIgnoreTestSuites.PROPERTY_RUN_NESTED, "true");
+  }
+
+  @After
+  public final void after() {
+    if (suppressOutputStreams) {
+      System.out.flush();
+      System.err.flush();
+
+      System.setOut(prevSysOut);
+      System.setErr(prevSysErr);
+    }
+  }
+
+  protected void assertFailureCount(int expected, Result result) {
+    if (result.getFailureCount() != expected) {
+      StringBuilder b = new StringBuilder();
+      for (Failure f : result.getFailures()) {
+        b.append("\n\n");
+        b.append(f.getMessage());
+        b.append("\n");
+        b.append(f.getTrace());
+      }
+      RandomizedTest.assertFalse("Expected failures: " + expected + " but was " + 
+          result.getFailureCount() + ", failures below: " + b.toString(), true);
+    }
+  }
+
+  protected String getSysOut() {
+    Assert.assertTrue(suppressOutputStreams);
+    System.out.flush();
+    return new String(sysout.toByteArray(), StandardCharsets.UTF_8);
+  }
+
+  protected String getSysErr() {
+    Assert.assertTrue(suppressOutputStreams);
+    System.err.flush();
+    return new String(syserr.toByteArray(), StandardCharsets.UTF_8);
+  }  
+}

