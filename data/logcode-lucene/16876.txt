GitDiffStart: a58c26978f5c7a0dbbbe535c627ef5388fad550b | Tue Nov 30 11:22:39 2010 +0000
diff --git a/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiDocMaker.java b/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiDocMaker.java
deleted file mode 100644
index f202b0c..0000000
--- a/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/EnwikiDocMaker.java
+++ /dev/null
@@ -1,38 +0,0 @@
-package org.apache.lucene.benchmark.byTask.feeds;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.benchmark.byTask.utils.Config;
-
-/**
- * A {@link DocMaker} which reads the English Wikipedia dump. Uses
- * {@link EnwikiContentSource} as its content source, regardless if a different
- * content source was defined in the configuration.
- * @deprecated Please use {@link DocMaker} instead, with content.source=EnwikiContentSource
- */
-@Deprecated
-public class EnwikiDocMaker extends DocMaker {
-  @Override
-  public void setConfig(Config config) {
-    super.setConfig(config);
-    // Override whatever content source was set in the config
-    source = new EnwikiContentSource();
-    source.setConfig(config);
-    System.out.println("NOTE: EnwikiDocMaker is deprecated; please use DocMaker instead (which is the default if you don't specify doc.maker) with content.source=EnwikiContentSource");
-  }
-}
diff --git a/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocMaker.java b/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocMaker.java
deleted file mode 100644
index 5f54c0f..0000000
--- a/lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/LineDocMaker.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.lucene.benchmark.byTask.feeds;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.benchmark.byTask.utils.Config;
-
-/**
- * A DocMaker reading one line at a time as a Document from a single file. This
- * saves IO cost (over DirContentSource) of recursing through a directory and
- * opening a new file for every document. It also re-uses its Document and Field
- * instance to improve indexing speed.<br>
- * The expected format of each line is (arguments are separated by &lt;TAB&gt;):
- * <i>title, date, body</i>. If a line is read in a different format, a
- * {@link RuntimeException} will be thrown. In general, you should use this doc
- * maker with files that were created with 
- * {@link org.apache.lucene.benchmark.byTask.tasks.WriteLineDocTask}.<br>
- * <br>
- * Config properties:
- * <ul>
- * <li>doc.random.id.limit=N (default -1) -- create random docid in the range
- * 0..N; this is useful with UpdateDoc to test updating random documents; if
- * this is unspecified or -1, then docid is sequentially assigned
- * </ul>
- * @deprecated Please use {@link DocMaker} instead, with content.source=LineDocSource
- */
-@Deprecated
-public class LineDocMaker extends DocMaker {
-  @Override
-  public void setConfig(Config config) {
-    super.setConfig(config);
-    source = new LineDocSource();
-    source.setConfig(config);
-    System.out.println("NOTE: LineDocMaker is deprecated; please use DocMaker instead (which is the default if you don't specify doc.maker) with content.source=LineDocSource");
-  }
-}
diff --git a/lucene/contrib/db/bdb-je/src/java/org/apache/lucene/store/je/JEDirectory.java b/lucene/contrib/db/bdb-je/src/java/org/apache/lucene/store/je/JEDirectory.java
index 83c6b98..8e2e760 100644
--- a/lucene/contrib/db/bdb-je/src/java/org/apache/lucene/store/je/JEDirectory.java
+++ b/lucene/contrib/db/bdb-je/src/java/org/apache/lucene/store/je/JEDirectory.java
@@ -21,12 +21,7 @@ import java.io.ByteArrayInputStream;
 import java.io.DataInputStream;
 import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.IndexInput;
@@ -196,6 +191,10 @@ public class JEDirectory extends Directory {
     }
 
     @Override
+    public void sync(Collection<String> names) throws IOException {
+    }
+
+    @Override
     public Lock makeLock(String name) {
         return new JELock();
     }
diff --git a/lucene/contrib/db/bdb/src/java/org/apache/lucene/store/db/DbDirectory.java b/lucene/contrib/db/bdb/src/java/org/apache/lucene/store/db/DbDirectory.java
index 74478b1..829dbed 100644
--- a/lucene/contrib/db/bdb/src/java/org/apache/lucene/store/db/DbDirectory.java
+++ b/lucene/contrib/db/bdb/src/java/org/apache/lucene/store/db/DbDirectory.java
@@ -21,12 +21,7 @@ import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.ByteArrayInputStream;
 import java.io.DataInputStream;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.Collections;
+import java.util.*;
 
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.Lock;
@@ -211,6 +206,10 @@ public class DbDirectory extends Directory {
     }
 
     @Override
+    public void sync(Collection<String> names) throws IOException {
+    }
+
+  @Override
     public IndexInput openInput(String name)
         throws IOException
     {
diff --git a/lucene/contrib/demo/src/java/org/apache/lucene/demo/html/SimpleCharStream.java b/lucene/contrib/demo/src/java/org/apache/lucene/demo/html/SimpleCharStream.java
index fedf92d..a1727ff 100644
--- a/lucene/contrib/demo/src/java/org/apache/lucene/demo/html/SimpleCharStream.java
+++ b/lucene/contrib/demo/src/java/org/apache/lucene/demo/html/SimpleCharStream.java
@@ -204,7 +204,7 @@ public class SimpleCharStream
   }
 
   /**
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndColumn
    */
 
@@ -213,7 +213,7 @@ public class SimpleCharStream
   }
 
   /**
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndLine
    */
 
diff --git a/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TextFragment.java b/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TextFragment.java
index 4829cd2..11d8e53 100644
--- a/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TextFragment.java
+++ b/lucene/contrib/highlighter/src/java/org/apache/lucene/search/highlight/TextFragment.java
@@ -37,17 +37,7 @@ public class TextFragment
 		this.textStartPos = textStartPos;
 		this.fragNum = fragNum;
 	}
-  /** 
-   * @deprecated Use {@link #TextFragment(CharSequence, int, int)} instead.
-   * This constructor will be removed in Lucene 4.0
-   */
-	@Deprecated
-	public TextFragment(StringBuffer markedUpText,int textStartPos, int fragNum)
-	{
-		this.markedUpText=markedUpText;
-		this.textStartPos = textStartPos;
-		this.fragNum = fragNum;
-	}
+
 	void setScore(float score)
 	{
 		this.score=score;
diff --git a/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java b/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
index 2d90077..064f1da 100644
--- a/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
+++ b/lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/BaseFragmentsBuilder.java
@@ -107,25 +107,12 @@ public abstract class BaseFragmentsBuilder implements FragmentsBuilder {
     return fragments.toArray( new String[fragments.size()] );
   }
   
-  @Deprecated
-  protected String[] getFieldValues( IndexReader reader, int docId, String fieldName) throws IOException {
-    Document doc = reader.document( docId, new MapFieldSelector( new String[]{ fieldName } ) );
-    return doc.getValues( fieldName ); // according to Document class javadoc, this never returns null
-  }
-  
   protected Field[] getFields( IndexReader reader, int docId, String fieldName) throws IOException {
     // according to javadoc, doc.getFields(fieldName) cannot be used with lazy loaded field???
-    Document doc = reader.document( docId, new MapFieldSelector( new String[]{ fieldName } ) );
+    Document doc = reader.document( docId, new MapFieldSelector(fieldName) );
     return doc.getFields( fieldName ); // according to Document class javadoc, this never returns null
   }
 
-  @Deprecated
-  protected String makeFragment( StringBuilder buffer, int[] index, String[] values, WeightedFragInfo fragInfo ){
-    final int s = fragInfo.startOffset;
-    return makeFragment( fragInfo, getFragmentSource( buffer, index, values, s, fragInfo.endOffset ), s,
-        preTags, postTags, NULL_ENCODER );
-  }
-
   protected String makeFragment( StringBuilder buffer, int[] index, Field[] values, WeightedFragInfo fragInfo,
       String[] preTags, String[] postTags, Encoder encoder ){
     final int s = fragInfo.startOffset;
@@ -151,18 +138,6 @@ public abstract class BaseFragmentsBuilder implements FragmentsBuilder {
     return fragment.toString();
   }
   
-  @Deprecated
-  protected String getFragmentSource( StringBuilder buffer, int[] index, String[] values,
-      int startOffset, int endOffset ){
-    while( buffer.length() < endOffset && index[0] < values.length ){
-      buffer.append( values[index[0]] );
-      buffer.append( multiValuedSeparator );
-      index[0]++;
-    }
-    int eo = buffer.length() < endOffset ? buffer.length() : endOffset;
-    return buffer.substring( startOffset, eo );
-  }
-
   protected String getFragmentSource( StringBuilder buffer, int[] index, Field[] values,
       int startOffset, int endOffset ){
     while( buffer.length() < endOffset && index[0] < values.length ){
diff --git a/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index 51b2d27..b42fa17 100644
--- a/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -70,12 +70,7 @@ import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.highlight.SynonymTokenizer.TestHighlightRunner;
 import org.apache.lucene.search.regex.RegexQuery;
-import org.apache.lucene.search.regex.SpanRegexQuery;
-import org.apache.lucene.search.spans.SpanNearQuery;
-import org.apache.lucene.search.spans.SpanNotQuery;
-import org.apache.lucene.search.spans.SpanOrQuery;
-import org.apache.lucene.search.spans.SpanQuery;
-import org.apache.lucene.search.spans.SpanTermQuery;
+import org.apache.lucene.search.spans.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.automaton.BasicAutomata;
 import org.apache.lucene.util.automaton.CharacterRunAutomaton;
@@ -300,8 +295,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
   }
   
   public void testSpanRegexQuery() throws Exception {
-    query = new SpanOrQuery(new SpanQuery [] {
-        new SpanRegexQuery(new Term(FIELD_NAME, "ken.*")) });
+    query = new SpanOrQuery(new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(new Term(FIELD_NAME, "ken.*"))));
     searcher = new IndexSearcher(ramDir, true);
     hits = searcher.search(query, 100);
     int maxNumFragmentsRequired = 2;
@@ -698,8 +692,8 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);
       int maxNumFragmentsRequired = 2;
       String fragmentSeparator = "...";
-      QueryScorer scorer = null;
-      TokenStream tokenStream = null;
+      QueryScorer scorer;
+      TokenStream tokenStream;
 
       tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));
       
@@ -726,8 +720,8 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);
       int maxNumFragmentsRequired = 2;
       String fragmentSeparator = "...";
-      QueryScorer scorer = null;
-      TokenStream tokenStream = null;
+      QueryScorer scorer;
+      TokenStream tokenStream;
 
       tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));
       
@@ -754,8 +748,8 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       String text = searcher.doc(hits.scoreDocs[i].doc).get(HighlighterTest.FIELD_NAME);
       int maxNumFragmentsRequired = 2;
       String fragmentSeparator = "...";
-      QueryScorer scorer = null;
-      TokenStream tokenStream = null;
+      QueryScorer scorer;
+      TokenStream tokenStream;
 
       tokenStream = analyzer.tokenStream(HighlighterTest.FIELD_NAME, new StringReader(text));
       
@@ -820,8 +814,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
         Highlighter hg = new Highlighter(new SimpleHTMLFormatter(), new QueryTermScorer(query));
         hg.setTextFragmenter(new NullFragmenter());
 
-        String match = null;
-        match = hg.getBestFragment(analyzer, "data", "help me [54-65]");
+        String match = hg.getBestFragment(analyzer, "data", "help me [54-65]");
         assertEquals("<B>help</B> me [54-65]", match);
 
       }
@@ -1133,7 +1126,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
 
         TermQuery query = new TermQuery(new Term("data", goodWord));
 
-        String match = null;
+        String match;
         StringBuilder sb = new StringBuilder();
         sb.append(goodWord);
         for (int i = 0; i < 10000; i++) {
@@ -1246,8 +1239,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
       public void run() throws Exception {
         doSearching("AnInvalidQueryWhichShouldYieldNoResults");
 
-        for (int i = 0; i < texts.length; i++) {
-          String text = texts[i];
+        for (String text : texts) {
           TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(text));
           Highlighter highlighter = getHighlighter(query, FIELD_NAME, tokenStream,
               HighlighterTest.this);
@@ -1716,8 +1708,8 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
     ramDir = newDirectory();
     IndexWriter writer = new IndexWriter(ramDir, newIndexWriterConfig(
         TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true)));
-    for (int i = 0; i < texts.length; i++) {
-      addDoc(writer, texts[i]);
+    for (String text : texts) {
+      addDoc(writer, text);
     }
     Document doc = new Document();
     NumericField nfield = new NumericField(NUMERIC_FIELD_NAME, Store.YES, true);
@@ -1881,7 +1873,7 @@ final class SynonymTokenizer extends TokenStream {
     }
     
     public Highlighter getHighlighter(Query query, String fieldName, TokenStream stream, Formatter formatter, boolean expanMultiTerm) {
-      Scorer scorer = null;
+      Scorer scorer;
       if (mode == QUERY) {
         scorer = new QueryScorer(query, fieldName);
         if(!expanMultiTerm) {
diff --git a/lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java b/lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
index 9feb9c7..59a3b45 100644
--- a/lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
+++ b/lucene/contrib/instantiated/src/java/org/apache/lucene/store/instantiated/InstantiatedIndexWriter.java
@@ -64,8 +64,6 @@ public class InstantiatedIndexWriter implements Closeable {
 
   private PrintStream infoStream = null;
 
-  private int maxFieldLength = IndexWriter.DEFAULT_MAX_FIELD_LENGTH;
-
   private final InstantiatedIndex index;
   private final Analyzer analyzer;
 
@@ -431,9 +429,7 @@ public class InstantiatedIndexWriter implements Closeable {
   };
 
   /**
-   * Adds a document to this index.  If the document contains more than
-   * {@link #setMaxFieldLength(int)} terms for a given field, the remainder are
-   * discarded.
+   * Adds a document to this index.
    */
   public void addDocument(Document doc) throws IOException {
     addDocument(doc, getAnalyzer());
@@ -441,9 +437,7 @@ public class InstantiatedIndexWriter implements Closeable {
 
   /**
    * Adds a document to this index, using the provided analyzer instead of the
-   * value of {@link #getAnalyzer()}.  If the document contains more than
-   * {@link #setMaxFieldLength(int)} terms for a given field, the remainder are
-   * discarded.
+   * value of {@link #getAnalyzer()}.
    *
    * @param doc
    * @param analyzer
@@ -555,9 +549,6 @@ public class InstantiatedIndexWriter implements Closeable {
             }
             tokens.add(token); // the vector will be built on commit.
             fieldSetting.fieldLength++;
-            if (fieldSetting.fieldLength > maxFieldLength) {
-              break;
-            }
           }
           tokenStream.end();
           tokenStream.close();
@@ -666,14 +657,6 @@ public class InstantiatedIndexWriter implements Closeable {
     addDocument(doc, analyzer);
   }
 
-  public int getMaxFieldLength() {
-    return maxFieldLength;
-  }
-
-  public void setMaxFieldLength(int maxFieldLength) {
-    this.maxFieldLength = maxFieldLength;
-  }
-
   public Similarity getSimilarity() {
     return similarity;
   }
diff --git a/lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java b/lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
index bf4804e..9cfd568 100644
--- a/lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
+++ b/lucene/contrib/misc/src/java/org/apache/lucene/index/FieldNormModifier.java
@@ -22,6 +22,7 @@ import java.util.Date;
 import java.util.List;
 import java.util.ArrayList;
 
+import org.apache.lucene.search.DefaultSimilarity;
 import org.apache.lucene.search.Similarity;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
@@ -52,19 +53,21 @@ public class FieldNormModifier {
    */
   public static void main(String[] args) throws IOException {
     if (args.length < 3) {
-      System.err.println("Usage: FieldNormModifier <index> <package.SimilarityClassName | -n> <field1> [field2] ...");
+      System.err.println("Usage: FieldNormModifier <index> <package.SimilarityClassName | -d> <field1> [field2] ...");
       System.exit(1);
     }
 
     Similarity s = null;
-    if (!args[1].equals("-n")) {
-      try {
-        s = Class.forName(args[1]).asSubclass(Similarity.class).newInstance();
-      } catch (Exception e) {
-        System.err.println("Couldn't instantiate similarity with empty constructor: " + args[1]);
-        e.printStackTrace(System.err);
-        System.exit(1);
-      }
+
+    if (args[1].equals("-d"))
+      args[1] = DefaultSimilarity.class.getName();
+
+    try {
+      s = Class.forName(args[1]).asSubclass(Similarity.class).newInstance();
+    } catch (Exception e) {
+      System.err.println("Couldn't instantiate similarity with empty constructor: " + args[1]);
+      e.printStackTrace(System.err);
+      System.exit(1);
     }
 
     Directory d = FSDirectory.open(new File(args[0]));
@@ -142,11 +145,7 @@ public class FieldNormModifier {
 
         for (int d = 0; d < termCounts.length; d++) {
           if (delDocs == null || !delDocs.get(d)) {
-            if (sim == null) {
-              subReader.setNorm(d, fieldName, Similarity.encodeNorm(1.0f));
-            } else {
-              subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));
-            }
+            subReader.setNorm(d, fieldName, sim.encodeNormValue(sim.lengthNorm(fieldName, termCounts[d])));
           }
         }
       }
diff --git a/lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java b/lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java
index 8526af8..ce42d8b 100644
--- a/lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java
+++ b/lucene/contrib/misc/src/java/org/apache/lucene/index/MultiPassIndexSplitter.java
@@ -96,7 +96,7 @@ public class MultiPassIndexSplitter {
           new WhitespaceAnalyzer(Version.LUCENE_CURRENT))
           .setOpenMode(OpenMode.CREATE));
       System.err.println("Writing part " + (i + 1) + " ...");
-      w.addIndexes(new IndexReader[]{input});
+      w.addIndexes(input);
       w.close();
     }
     System.err.println("Done.");
diff --git a/lucene/contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java b/lucene/contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java
deleted file mode 100644
index fecc5b0..0000000
--- a/lucene/contrib/misc/src/java/org/apache/lucene/misc/LengthNormModifier.java
+++ /dev/null
@@ -1,144 +0,0 @@
-package org.apache.lucene.misc;
-
-/**
- * Copyright 2006 The Apache Software Foundation
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.MultiFields;
-import org.apache.lucene.index.Terms;
-import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.index.DocsEnum;
-import org.apache.lucene.search.Similarity;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.FSDirectory;
-import org.apache.lucene.util.StringHelper;
-import org.apache.lucene.util.Bits;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.Date;
-
-/**
- * Given a directory, a Similarity, and a list of fields, updates the
- * fieldNorms in place for every document using the Similarity.lengthNorm.
- *
- * <p>
- * NOTE: This only works if you do <b>not</b> use field/document boosts in your
- * index.
- * </p>
- *
- * @version $Id$
- * @deprecated Use {@link org.apache.lucene.index.FieldNormModifier}
- */
-@Deprecated
-public class LengthNormModifier {
-  
-  /**
-   * Command Line Execution method.
-   *
-   * <pre>
-   * Usage: LengthNormModifier /path/index package.SimilarityClassName field1 field2 ...
-   * </pre>
-   */
-  public static void main(String[] args) throws IOException {
-    if (args.length < 3) {
-      System.err.println("Usage: LengthNormModifier <index> <package.SimilarityClassName> <field1> [field2] ...");
-      System.exit(1);
-    }
-    
-    Similarity s = null;
-    try {
-      s = Class.forName(args[1]).asSubclass(Similarity.class).newInstance();
-    } catch (Exception e) {
-      System.err.println("Couldn't instantiate similarity with empty constructor: " + args[1]);
-      e.printStackTrace(System.err);
-    }
-    
-    File index = new File(args[0]);
-    Directory d = FSDirectory.open(index);
-    
-    LengthNormModifier lnm = new LengthNormModifier(d, s);
-    
-    for (int i = 2; i < args.length; i++) {
-      System.out.print("Updating field: " + args[i] + " " + (new Date()).toString() + " ... ");
-      lnm.reSetNorms(args[i]);
-      System.out.println(new Date().toString());
-    }
-    
-    d.close();
-  }
-  
-  
-  private Directory dir;
-  private Similarity sim;
-  
-  /**
-   * Constructor for code that wishes to use this class progaomatically.
-   *
-   * @param d The Directory to modify
-   * @param s The Similarity to use in <code>reSetNorms</code>
-   */
-  public LengthNormModifier(Directory d, Similarity s) {
-    dir = d;
-    sim = s;
-  }
-  
-  /**
-   * Resets the norms for the specified field.
-   *
-   * <p>
-   * Opens a new IndexReader on the Directory given to this instance,
-   * modifies the norms using the Similarity given to this instance,
-   * and closes the IndexReader.
-   * </p>
-   *
-   * @param field the field whose norms should be reset
-   */
-  public void reSetNorms(String field) throws IOException {
-    String fieldName = StringHelper.intern(field);
-    int[] termCounts = new int[0];
-    
-    IndexReader reader = IndexReader.open(dir, false);
-    try {
-
-      termCounts = new int[reader.maxDoc()];
-      Bits delDocs = MultiFields.getDeletedDocs(reader);
-      DocsEnum docs = null;
-
-      Terms terms = MultiFields.getTerms(reader, field);
-      if (terms != null) {
-        TermsEnum termsEnum = terms.iterator();
-        while(termsEnum.next() != null) {
-          docs = termsEnum.docs(delDocs, docs);
-          int doc;
-          while ((doc = docs.nextDoc()) != DocsEnum.NO_MORE_DOCS) {
-            termCounts[doc] += docs.freq();
-          }
-        }
-      }
-
-      for (int d = 0; d < termCounts.length; d++) {
-        if (!delDocs.get(d)) {
-          byte norm = Similarity.encodeNorm(sim.lengthNorm(fieldName, termCounts[d]));
-          reader.setNorm(d, fieldName, norm);
-        }
-      }
-    } finally {
-      reader.close();
-    }
-  }
-  
-}
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java
index a514c38..2e6868e 100644
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java
+++ b/lucene/contrib/queries/src/java/org/apache/lucene/search/BooleanFilter.java
@@ -106,27 +106,15 @@ public class BooleanFilter extends Filter
     }
     
     if (res !=null)
-      return finalResult(res, reader.maxDoc());
+      return res;
 
     return DocIdSet.EMPTY_DOCIDSET;
   }
 
-  /** Provide a SortedVIntList when it is definitely smaller
-   * than an OpenBitSet.
-   * @deprecated Either use CachingWrapperFilter, or
-   * switch to a different DocIdSet implementation yourself.
-   * This method will be removed in Lucene 4.0 
-   */
-  @Deprecated
-  protected final DocIdSet finalResult(OpenBitSetDISI result, int maxDocs) {
-    return result;
-  }
-
   /**
   * Adds a new FilterClause to the Boolean Filter container
   * @param filterClause A FilterClause object containing a Filter and an Occur parameter
   */
-  
   public void add(FilterClause filterClause)
   {
     if (filterClause.getOccur().equals(Occur.MUST)) {
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java
index f06d0e2..e95b506 100644
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java
+++ b/lucene/contrib/queries/src/java/org/apache/lucene/search/ChainedFilter.java
@@ -149,18 +149,6 @@ public class ChainedFilter extends Filter
         return result;
     }
 
-    /** Provide a SortedVIntList when it is definitely
-     *  smaller than an OpenBitSet
-     *  @deprecated Either use CachingWrapperFilter, or
-     *  switch to a different DocIdSet implementation yourself.
-     *  This method will be removed in Lucene 4.0 
-     **/
-    @Deprecated
-    protected final DocIdSet finalResult(OpenBitSetDISI result, int maxDocs) {
-        return result;
-    }
-        
-
     /**
      * Delegates to each filter in the chain.
      * @param reader IndexReader
@@ -175,7 +163,7 @@ public class ChainedFilter extends Filter
         {
             doChain(result, logic, chain[index[0]].getDocIdSet(reader));
         }
-        return finalResult(result, reader.maxDoc());
+        return result;
     }
 
     /**
@@ -195,7 +183,7 @@ public class ChainedFilter extends Filter
         {
             doChain(result, logic[index[0]], chain[index[0]].getDocIdSet(reader));
         }
-        return finalResult(result, reader.maxDoc());
+        return result;
     }
 
     @Override
diff --git a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/SpanRegexQuery.java b/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/SpanRegexQuery.java
deleted file mode 100644
index 818a949..0000000
--- a/lucene/contrib/queries/src/java/org/apache/lucene/search/regex/SpanRegexQuery.java
+++ /dev/null
@@ -1,46 +0,0 @@
-package org.apache.lucene.search.regex;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
-
-/**
- * A SpanQuery version of {@link RegexQuery} allowing regular expression
- * queries to be nested within other SpanQuery subclasses.
- * @deprecated Use <code>new SpanMultiTermQueryWrapper&lt;RegexQuery&gt;(new RegexQuery())</code> instead.
- * This query will be removed in Lucene 4.0
- */
-@Deprecated
-public class SpanRegexQuery extends SpanMultiTermQueryWrapper<RegexQuery> implements RegexQueryCapable {
-  private final RegexCapabilities regexImpl = new JavaUtilRegexCapabilities();
-
-  public SpanRegexQuery(Term term) {
-    super(new RegexQuery(term));
-  }
-
-  public Term getTerm() { return query.getTerm(); }
-
-  public void setRegexImplementation(RegexCapabilities impl) {
-    query.setRegexImplementation(impl);
-  }
-
-  public RegexCapabilities getRegexImplementation() {
-    return query.getRegexImplementation();
-  }
-}
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
index e0baef7..8fa1ba8 100644
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
+++ b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestRegexQuery.java
@@ -17,6 +17,7 @@ package org.apache.lucene.search.regex;
  * limitations under the License.
  */
 
+import org.apache.lucene.search.spans.SpanMultiTermQueryWrapper;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.MultiFields;
@@ -73,10 +74,10 @@ public class TestRegexQuery extends LuceneTestCase {
   }
 
   private int  spanRegexQueryNrHits(String regex1, String regex2, int slop, boolean ordered) throws Exception {
-    SpanRegexQuery srq1 = new SpanRegexQuery( newTerm(regex1));
-    SpanRegexQuery srq2 = new SpanRegexQuery( newTerm(regex2));
+    SpanQuery srq1 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex1)));
+    SpanQuery srq2 = new SpanMultiTermQueryWrapper<RegexQuery>(new RegexQuery(newTerm(regex2)));
     SpanNearQuery query = new SpanNearQuery( new SpanQuery[]{srq1, srq2}, slop, ordered);
-    
+
     return searcher.search(query, null, 1000).totalHits;
   }
 
diff --git a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
index 7624786..3ce218c 100644
--- a/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
+++ b/lucene/contrib/queries/src/test/org/apache/lucene/search/regex/TestSpanRegexQuery.java
@@ -112,67 +112,6 @@ public class TestSpanRegexQuery extends LuceneTestCase {
     indexStoreB.close();
   }
   
-  /** remove in lucene 4.0 */
-  @Deprecated
-  public void testSpanRegexOld() throws Exception {
-    Directory directory = newDirectory();
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
-    Document doc = new Document();
-    // doc.add(newField("field", "the quick brown fox jumps over the lazy dog",
-    // Field.Store.NO, Field.Index.ANALYZED));
-    // writer.addDocument(doc);
-    // doc = new Document();
-    doc.add(newField("field", "auto update", Field.Store.NO,
-        Field.Index.ANALYZED));
-    writer.addDocument(doc);
-    doc = new Document();
-    doc.add(newField("field", "first auto update", Field.Store.NO,
-        Field.Index.ANALYZED));
-    writer.addDocument(doc);
-    writer.optimize();
-    writer.close();
-
-    IndexSearcher searcher = new IndexSearcher(directory, true);
-    SpanRegexQuery srq = new SpanRegexQuery(new Term("field", "aut.*"));
-    SpanFirstQuery sfq = new SpanFirstQuery(srq, 1);
-    // SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {srq, stq}, 6,
-    // true);
-    int numHits = searcher.search(sfq, null, 1000).totalHits;
-    assertEquals(1, numHits);
-    searcher.close();
-    directory.close();
-  }
-
-  /** remove in lucene 4.0 */
-  @Deprecated
-  public void testSpanRegexBugOld() throws CorruptIndexException, IOException {
-    createRAMDirectories();
-
-    SpanRegexQuery srq = new SpanRegexQuery(new Term("field", "a.*"));
-    SpanRegexQuery stq = new SpanRegexQuery(new Term("field", "b.*"));
-    SpanNearQuery query = new SpanNearQuery(new SpanQuery[] { srq, stq }, 6,
-        true);
-
-    // 1. Search the same store which works
-    IndexSearcher[] arrSearcher = new IndexSearcher[2];
-    arrSearcher[0] = new IndexSearcher(indexStoreA, true);
-    arrSearcher[1] = new IndexSearcher(indexStoreB, true);
-    MultiSearcher searcher = new MultiSearcher(arrSearcher);
-    int numHits = searcher.search(query, null, 1000).totalHits;
-    arrSearcher[0].close();
-    arrSearcher[1].close();
-
-    // Will fail here
-    // We expect 2 but only one matched
-    // The rewriter function only write it once on the first IndexSearcher
-    // So it's using term: a1 b1 to search on the second IndexSearcher
-    // As a result, it won't match the document in the second IndexSearcher
-    assertEquals(2, numHits);
-    indexStoreA.close();
-    indexStoreB.close();
-  }
-
   private void createRAMDirectories() throws CorruptIndexException,
       LockObtainFailedException, IOException {
     // creating a document to store
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/processors/QueryNodeProcessorPipeline.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/processors/QueryNodeProcessorPipeline.java
index 7e00e1a..68d3638 100644
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/processors/QueryNodeProcessorPipeline.java
+++ b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/core/processors/QueryNodeProcessorPipeline.java
@@ -17,11 +17,7 @@ package org.apache.lucene.queryParser.core.processors;
  * limitations under the License.
  */
 
-import java.util.Collection;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.ListIterator;
+import java.util.*;
 
 import org.apache.lucene.queryParser.core.QueryNodeException;
 import org.apache.lucene.queryParser.core.config.QueryConfigHandler;
@@ -97,23 +93,6 @@ public class QueryNodeProcessorPipeline implements QueryNodeProcessor,
   }
 
   /**
-   * Adds a processor to the pipeline, it's always added to the end of the
-   * pipeline.
-   * 
-   * @deprecated this class now conforms to {@link List} interface, so use
-   *             {@link #add(QueryNodeProcessor)} instead
-   * 
-   * @param processor the processor to be added
-   */
-  @Deprecated
-  public void addProcessor(QueryNodeProcessor processor) {
-    this.processors.add(processor);
-
-    processor.setQueryConfigHandler(this.queryConfig);
-
-  }
-
-  /**
    * For reference about this method check:
    * {@link QueryNodeProcessor#setQueryConfigHandler(QueryConfigHandler)}.
    * 
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/MultiFieldQueryParserWrapper.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/MultiFieldQueryParserWrapper.java
deleted file mode 100644
index 46eb864..0000000
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/MultiFieldQueryParserWrapper.java
+++ /dev/null
@@ -1,269 +0,0 @@
-package org.apache.lucene.queryParser.standard;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Query;
-
-/**
- * This class behaves as the as the lucene 2.4 MultiFieldQueryParser class, but uses the new
- * query parser interface instead of the old one. <br/>
- * <br/>
- * This class should be used when the new query parser features are needed and
- * also keep at the same time the old query parser interface. <br/>
- * 
- * @deprecated this class will be removed soon, it's a temporary class to be
- *             used along the transition from the old query parser to the new
- *             one
- */
-@Deprecated
-public class MultiFieldQueryParserWrapper extends QueryParserWrapper {
-
-  /**
-   * Creates a MultiFieldQueryParser. Allows passing of a map with term to
-   * Boost, and the boost to apply to each term.
-   * 
-   * <p>
-   * It will, when parse(String query) is called, construct a query like this
-   * (assuming the query consists of two terms and you specify the two fields
-   * <code>title</code> and <code>body</code>):
-   * </p>
-   * 
-   * <code>
-     * (title:term1 body:term1) (title:term2 body:term2)
-     * </code>
-   * 
-   * <p>
-   * When setDefaultOperator(AND_OPERATOR) is set, the result will be:
-   * </p>
-   * 
-   * <code>
-     * +(title:term1 body:term1) +(title:term2 body:term2)
-     * </code>
-   * 
-   * <p>
-   * When you pass a boost (title=>5 body=>10) you can get
-   * </p>
-   * 
-   * <code>
-     * +(title:term1^5.0 body:term1^10.0) +(title:term2^5.0 body:term2^10.0)
-     * </code>
-   * 
-   * <p>
-   * In other words, all the query's terms must appear, but it doesn't matter in
-   * what fields they appear.
-   * </p>
-   */
-public MultiFieldQueryParserWrapper(String[] fields, Analyzer analyzer, Map<String, Float> boosts) {
-    this(fields, analyzer);
-    StandardQueryParser qpHelper = getQueryParserHelper();
-
-    qpHelper.setMultiFields(fields);
-    qpHelper.setFieldsBoost(boosts);
-
-  }
-
-  /**
-   * Creates a MultiFieldQueryParser.
-   * 
-   * <p>
-   * It will, when parse(String query) is called, construct a query like this
-   * (assuming the query consists of two terms and you specify the two fields
-   * <code>title</code> and <code>body</code>):
-   * </p>
-   * 
-   * <code>
-     * (title:term1 body:term1) (title:term2 body:term2)
-     * </code>
-   * 
-   * <p>
-   * When setDefaultOperator(AND_OPERATOR) is set, the result will be:
-   * </p>
-   * 
-   * <code>
-     * +(title:term1 body:term1) +(title:term2 body:term2)
-     * </code>
-   * 
-   * <p>
-   * In other words, all the query's terms must appear, but it doesn't matter in
-   * what fields they appear.
-   * </p>
-   */
-  public MultiFieldQueryParserWrapper(String[] fields, Analyzer analyzer) {
-    super(null, analyzer);
-
-    StandardQueryParser qpHelper = getQueryParserHelper();
-    qpHelper.setAnalyzer(analyzer);
-
-    qpHelper.setMultiFields(fields);
-  }
-
-  /**
-   * Parses a query which searches on the fields specified.
-   * <p>
-   * If x fields are specified, this effectively constructs:
-   * 
-   * <pre>
-   * &lt;code&gt;
-   * (field1:query1) (field2:query2) (field3:query3)...(fieldx:queryx)
-   * &lt;/code&gt;
-   * </pre>
-   * 
-   * @param queries
-   *          Queries strings to parse
-   * @param fields
-   *          Fields to search on
-   * @param analyzer
-   *          Analyzer to use
-   * @throws ParseException
-   *           if query parsing fails
-   * @throws IllegalArgumentException
-   *           if the length of the queries array differs from the length of the
-   *           fields array
-   */
-  public static Query parse(String[] queries, String[] fields, Analyzer analyzer)
-      throws ParseException {
-    if (queries.length != fields.length)
-      throw new IllegalArgumentException("queries.length != fields.length");
-    BooleanQuery bQuery = new BooleanQuery();
-    for (int i = 0; i < fields.length; i++) {
-      QueryParserWrapper qp = new QueryParserWrapper(fields[i], analyzer);
-      Query q = qp.parse(queries[i]);
-      if (q != null && // q never null, just being defensive
-          (!(q instanceof BooleanQuery) || ((BooleanQuery) q).getClauses().length > 0)) {
-        bQuery.add(q, BooleanClause.Occur.SHOULD);
-      }
-    }
-    return bQuery;
-  }
-
-  /**
-   * Parses a query, searching on the fields specified. Use this if you need to
-   * specify certain fields as required, and others as prohibited.
-   * <p>
-   * 
-   * <pre>
-   * Usage:
-   * &lt;code&gt;
-   * String[] fields = {&quot;filename&quot;, &quot;contents&quot;, &quot;description&quot;};
-   * BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
-   *                BooleanClause.Occur.MUST,
-   *                BooleanClause.Occur.MUST_NOT};
-   * MultiFieldQueryParser.parse(&quot;query&quot;, fields, flags, analyzer);
-   * &lt;/code&gt;
-   * </pre>
-   *<p>
-   * The code above would construct a query:
-   * 
-   * <pre>
-   * &lt;code&gt;
-   * (filename:query) +(contents:query) -(description:query)
-   * &lt;/code&gt;
-   * </pre>
-   * 
-   * @param query
-   *          Query string to parse
-   * @param fields
-   *          Fields to search on
-   * @param flags
-   *          Flags describing the fields
-   * @param analyzer
-   *          Analyzer to use
-   * @throws ParseException
-   *           if query parsing fails
-   * @throws IllegalArgumentException
-   *           if the length of the fields array differs from the length of the
-   *           flags array
-   */
-  public static Query parse(String query, String[] fields,
-      BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
-    if (fields.length != flags.length)
-      throw new IllegalArgumentException("fields.length != flags.length");
-    BooleanQuery bQuery = new BooleanQuery();
-    for (int i = 0; i < fields.length; i++) {
-      QueryParserWrapper qp = new QueryParserWrapper(fields[i], analyzer);
-      Query q = qp.parse(query);
-      if (q != null && // q never null, just being defensive
-          (!(q instanceof BooleanQuery) || ((BooleanQuery) q).getClauses().length > 0)) {
-        bQuery.add(q, flags[i]);
-      }
-    }
-    return bQuery;
-  }
-
-  /**
-   * Parses a query, searching on the fields specified. Use this if you need to
-   * specify certain fields as required, and others as prohibited.
-   * <p>
-   * 
-   * <pre>
-   * Usage:
-   * &lt;code&gt;
-   * String[] query = {&quot;query1&quot;, &quot;query2&quot;, &quot;query3&quot;};
-   * String[] fields = {&quot;filename&quot;, &quot;contents&quot;, &quot;description&quot;};
-   * BooleanClause.Occur[] flags = {BooleanClause.Occur.SHOULD,
-   *                BooleanClause.Occur.MUST,
-   *                BooleanClause.Occur.MUST_NOT};
-   * MultiFieldQueryParser.parse(query, fields, flags, analyzer);
-   * &lt;/code&gt;
-   * </pre>
-   *<p>
-   * The code above would construct a query:
-   * 
-   * <pre>
-   * &lt;code&gt;
-   * (filename:query1) +(contents:query2) -(description:query3)
-   * &lt;/code&gt;
-   * </pre>
-   * 
-   * @param queries
-   *          Queries string to parse
-   * @param fields
-   *          Fields to search on
-   * @param flags
-   *          Flags describing the fields
-   * @param analyzer
-   *          Analyzer to use
-   * @throws ParseException
-   *           if query parsing fails
-   * @throws IllegalArgumentException
-   *           if the length of the queries, fields, and flags array differ
-   */
-  public static Query parse(String[] queries, String[] fields,
-      BooleanClause.Occur[] flags, Analyzer analyzer) throws ParseException {
-    if (!(queries.length == fields.length && queries.length == flags.length))
-      throw new IllegalArgumentException(
-          "queries, fields, and flags array have have different length");
-    BooleanQuery bQuery = new BooleanQuery();
-    for (int i = 0; i < fields.length; i++) {
-      QueryParserWrapper qp = new QueryParserWrapper(fields[i], analyzer);
-      Query q = qp.parse(queries[i]);
-      if (q != null && // q never null, just being defensive
-          (!(q instanceof BooleanQuery) || ((BooleanQuery) q).getClauses().length > 0)) {
-        bQuery.add(q, flags[i]);
-      }
-    }
-    return bQuery;
-  }
-
-}
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
deleted file mode 100644
index 839cfa3..0000000
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/QueryParserWrapper.java
+++ /dev/null
@@ -1,491 +0,0 @@
-package org.apache.lucene.queryParser.standard;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.text.Collator;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.document.DateTools;
-import org.apache.lucene.document.DateTools.Resolution;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.queryParser.core.QueryNodeException;
-import org.apache.lucene.queryParser.core.config.FieldConfig;
-import org.apache.lucene.queryParser.core.config.QueryConfigHandler;
-import org.apache.lucene.queryParser.core.nodes.QueryNode;
-import org.apache.lucene.queryParser.core.parser.SyntaxParser;
-import org.apache.lucene.queryParser.core.processors.QueryNodeProcessor;
-import org.apache.lucene.queryParser.standard.builders.StandardQueryBuilder;
-import org.apache.lucene.queryParser.standard.builders.StandardQueryTreeBuilder;
-import org.apache.lucene.queryParser.standard.config.AllowLeadingWildcardAttribute;
-import org.apache.lucene.queryParser.standard.config.AnalyzerAttribute;
-import org.apache.lucene.queryParser.standard.config.DateResolutionAttribute;
-import org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute;
-import org.apache.lucene.queryParser.standard.config.DefaultPhraseSlopAttribute;
-import org.apache.lucene.queryParser.standard.config.LocaleAttribute;
-import org.apache.lucene.queryParser.standard.config.LowercaseExpandedTermsAttribute;
-import org.apache.lucene.queryParser.standard.config.MultiTermRewriteMethodAttribute;
-import org.apache.lucene.queryParser.standard.config.PositionIncrementsAttribute;
-import org.apache.lucene.queryParser.standard.config.RangeCollatorAttribute;
-import org.apache.lucene.queryParser.standard.config.StandardQueryConfigHandler;
-import org.apache.lucene.queryParser.standard.parser.StandardSyntaxParser;
-import org.apache.lucene.queryParser.standard.processors.StandardQueryNodeProcessorPipeline;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.Query;
-
-/**
- * This class performs the query parsing using the new query parser
- * implementation, but keeps the old {@link QueryParser} API. <br/>
- * <br/>
- * This class should be used when the new query parser features are and the old
- * {@link QueryParser} API are needed at the same time. <br/>
- * 
- * @deprecated this class will be removed soon, it's a temporary class to be
- *             used along the transition from the old query parser to the new
- *             one
- */
-@Deprecated
-public class QueryParserWrapper {
-
-  /**
-   * The default operator for parsing queries. Use
-   * {@link QueryParserWrapper#setDefaultOperator} to change it.
-   */
-  static public enum Operator { OR, AND }
-
-  // the nested class:
-  /** Alternative form of QueryParser.Operator.AND */
-  public static final Operator AND_OPERATOR = Operator.AND;
-
-  /** Alternative form of QueryParser.Operator.OR */
-  public static final Operator OR_OPERATOR = Operator.OR;
-
-  /**
-   * Returns a String where those characters that QueryParser expects to be
-   * escaped are escaped by a preceding <code>\</code>.
-   */
-  public static String escape(String s) {
-    StringBuilder sb = new StringBuilder();
-    for (int i = 0; i < s.length(); i++) {
-      char c = s.charAt(i);
-      // These characters are part of the query syntax and must be escaped
-      if (c == '\\' || c == '+' || c == '-' || c == '!' || c == '(' || c == ')'
-          || c == ':' || c == '^' || c == '[' || c == ']' || c == '\"'
-          || c == '{' || c == '}' || c == '~' || c == '*' || c == '?'
-          || c == '|' || c == '&') {
-        sb.append('\\');
-      }
-      sb.append(c);
-    }
-    return sb.toString();
-  }
-
-  private SyntaxParser syntaxParser = new StandardSyntaxParser();
-
-  private StandardQueryConfigHandler config;
-
-  private StandardQueryParser qpHelper;
-
-  private QueryNodeProcessor processorPipeline;
-
-  private StandardQueryBuilder builder = new StandardQueryTreeBuilder();
-
-  private String defaultField;
-
-  public QueryParserWrapper(String defaultField, Analyzer analyzer) {
-    this.defaultField = defaultField;
-
-    this.qpHelper = new StandardQueryParser();
-
-    this.config = (StandardQueryConfigHandler) qpHelper.getQueryConfigHandler();
-
-    this.qpHelper.setAnalyzer(analyzer);
-
-    this.processorPipeline = new StandardQueryNodeProcessorPipeline(this.config);
-
-  }
-
-  StandardQueryParser getQueryParserHelper() {
-    return qpHelper;
-  }
-
-  public String getField() {
-    return this.defaultField;
-  }
-
-  public Analyzer getAnalyzer() {
-
-    if (this.config != null
-        && this.config.hasAttribute(AnalyzerAttribute.class)) {
-
-      return this.config.getAttribute(AnalyzerAttribute.class).getAnalyzer();
-
-    }
-
-    return null;
-
-  }
-
-  /**
-   * Sets the {@link StandardQueryBuilder} used to generate a {@link Query}
-   * object from the parsed and processed query node tree.
-   * 
-   * @param builder the builder
-   */
-  public void setQueryBuilder(StandardQueryBuilder builder) {
-    this.builder = builder;
-  }
-
-  /**
-   * Sets the {@link QueryNodeProcessor} used to process the query node tree
-   * generated by the
-   * {@link org.apache.lucene.queryParser.standard.parser.StandardSyntaxParser}.
-   * 
-   * @param processor the processor
-   */
-  public void setQueryProcessor(QueryNodeProcessor processor) {
-    this.processorPipeline = processor;
-    this.processorPipeline.setQueryConfigHandler(this.config);
-
-  }
-
-  /**
-   * Sets the {@link QueryConfigHandler} used by the {@link QueryNodeProcessor}
-   * set to this object.
-   * 
-   * @param queryConfig the query config handler
-   */
-  public void setQueryConfig(StandardQueryConfigHandler queryConfig) {
-    this.config = queryConfig;
-
-    if (this.processorPipeline != null) {
-      this.processorPipeline.setQueryConfigHandler(this.config);
-    }
-
-  }
-
-  /**
-   * Returns the query config handler used by this query parser
-   * 
-   * @return the query config handler
-   */
-  public QueryConfigHandler getQueryConfigHandler() {
-    return this.config;
-  }
-
-  /**
-   * Returns {@link QueryNodeProcessor} used to process the query node tree
-   * generated by the
-   * {@link org.apache.lucene.queryParser.standard.parser.StandardSyntaxParser}.
-   * 
-   * @return the query processor
-   */
-  public QueryNodeProcessor getQueryProcessor() {
-    return this.processorPipeline;
-  }
-
-  public ParseException generateParseException() {
-    return null;
-  }
-
-  public boolean getAllowLeadingWildcard() {
-
-    if (this.config != null
-        && this.config.hasAttribute(AllowLeadingWildcardAttribute.class)) {
-
-      return this.config.getAttribute(AllowLeadingWildcardAttribute.class)
-          .isAllowLeadingWildcard();
-
-    }
-
-    return false;
-
-  }
-
-  public MultiTermQuery.RewriteMethod getMultiTermRewriteMethod() {
-
-    if (this.config != null
-        && this.config.hasAttribute(MultiTermRewriteMethodAttribute.class)) {
-
-      return this.config.getAttribute(MultiTermRewriteMethodAttribute.class)
-          .getMultiTermRewriteMethod();
-
-    }
-
-    return MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT;
-
-  }
-
-  public Resolution getDateResolution(String fieldName) {
-
-    if (this.config != null) {
-      FieldConfig fieldConfig = this.config.getFieldConfig(fieldName);
-
-      if (fieldConfig != null) {
-
-        if (this.config.hasAttribute(DateResolutionAttribute.class)) {
-
-          return this.config.getAttribute(DateResolutionAttribute.class)
-              .getDateResolution();
-
-        }
-
-      }
-
-    }
-
-    return null;
-
-  }
-
-  public boolean getEnablePositionIncrements() {
-
-    if (this.config != null
-        && this.config.hasAttribute(PositionIncrementsAttribute.class)) {
-
-      return this.config.getAttribute(PositionIncrementsAttribute.class)
-          .isPositionIncrementsEnabled();
-
-    }
-
-    return false;
-
-  }
-
-  public float getFuzzyMinSim() {
-    return FuzzyQuery.defaultMinSimilarity;
-  }
-
-  public int getFuzzyPrefixLength() {
-    return FuzzyQuery.defaultPrefixLength;
-  }
-
-  public Locale getLocale() {
-
-    if (this.config != null && this.config.hasAttribute(LocaleAttribute.class)) {
-      return this.config.getAttribute(LocaleAttribute.class).getLocale();
-    }
-
-    return Locale.getDefault();
-
-  }
-
-  public boolean getLowercaseExpandedTerms() {
-
-    if (this.config != null
-        && this.config.hasAttribute(LowercaseExpandedTermsAttribute.class)) {
-
-      return this.config.getAttribute(LowercaseExpandedTermsAttribute.class)
-          .isLowercaseExpandedTerms();
-
-    }
-
-    return true;
-
-  }
-
-  public int getPhraseSlop() {
-
-    if (this.config != null
-        && this.config.hasAttribute(AllowLeadingWildcardAttribute.class)) {
-
-      return this.config.getAttribute(DefaultPhraseSlopAttribute.class)
-          .getDefaultPhraseSlop();
-
-    }
-
-    return 0;
-
-  }
-
-  public Collator getRangeCollator() {
-
-    if (this.config != null
-        && this.config.hasAttribute(RangeCollatorAttribute.class)) {
-
-      return this.config.getAttribute(RangeCollatorAttribute.class)
-          .getRangeCollator();
-
-    }
-
-    return null;
-
-  }
-
-  public boolean getUseOldRangeQuery() {
-    if (getMultiTermRewriteMethod() == MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE) {
-      return true;
-    } else {
-      return false;
-    }
-  }
-
-  public Query parse(String query) throws ParseException {
-
-    try {
-      QueryNode queryTree = this.syntaxParser.parse(query, getField());
-      queryTree = this.processorPipeline.process(queryTree);
-      return this.builder.build(queryTree);
-
-    } catch (QueryNodeException e) {
-      throw new ParseException("parse exception");
-    }
-
-  }
-
-  public void setAllowLeadingWildcard(boolean allowLeadingWildcard) {
-    this.qpHelper.setAllowLeadingWildcard(allowLeadingWildcard);
-  }
-
-  public void setMultiTermRewriteMethod(MultiTermQuery.RewriteMethod method) {
-    this.qpHelper.setMultiTermRewriteMethod(method);
-  }
-
-  public void setDateResolution(Resolution dateResolution) {
-    this.qpHelper.setDateResolution(dateResolution);
-  }
-
-  private Map<CharSequence, DateTools.Resolution> dateRes = new HashMap<CharSequence, DateTools.Resolution>();
-
-  public void setDateResolution(String fieldName, Resolution dateResolution) {
-    dateRes.put(fieldName, dateResolution);
-    this.qpHelper.setDateResolution(dateRes);
-  }
-
-  public void setDefaultOperator(Operator op) {
-
-    this.qpHelper
-        .setDefaultOperator(OR_OPERATOR.equals(op) ? org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute.Operator.OR
-            : org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute.Operator.AND);
-
-  }
-
-  public Operator getDefaultOperator() {
-
-    if (this.config != null
-        && this.config.hasAttribute(DefaultOperatorAttribute.class)) {
-
-      return (this.config.getAttribute(DefaultOperatorAttribute.class)
-          .getOperator() == org.apache.lucene.queryParser.standard.config.DefaultOperatorAttribute.Operator.AND) ? AND_OPERATOR
-          : OR_OPERATOR;
-
-    }
-
-    return OR_OPERATOR;
-
-  }
-
-  public void setEnablePositionIncrements(boolean enable) {
-    this.qpHelper.setEnablePositionIncrements(enable);
-  }
-
-  public void setFuzzyMinSim(float fuzzyMinSim) {
-    // TODO Auto-generated method stub
-
-  }
-
-  public void setFuzzyPrefixLength(int fuzzyPrefixLength) {
-    // TODO Auto-generated method stub
-
-  }
-
-  public void setLocale(Locale locale) {
-    this.qpHelper.setLocale(locale);
-  }
-
-  public void setLowercaseExpandedTerms(boolean lowercaseExpandedTerms) {
-    this.qpHelper.setLowercaseExpandedTerms(lowercaseExpandedTerms);
-  }
-
-  public void setPhraseSlop(int phraseSlop) {
-    this.qpHelper.setDefaultPhraseSlop(phraseSlop);
-  }
-
-  public void setRangeCollator(Collator rc) {
-    this.qpHelper.setRangeCollator(rc);
-  }
-
-  public void setUseOldRangeQuery(boolean useOldRangeQuery) {
-    if (useOldRangeQuery) {
-      setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);
-    } else {
-      setMultiTermRewriteMethod(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT);
-    }
-  }
-
-  protected Query getPrefixQuery(String field, String termStr)
-      throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  protected Query getWildcardQuery(String field, String termStr)
-      throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  protected Query getFuzzyQuery(String field, String termStr,
-      float minSimilarity) throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  /** @deprecated Use {@link #getFieldQuery(String, String, boolean)} instead */
-  @Deprecated
-  protected Query getFieldQuery(String field, String queryText) throws ParseException {
-    return getFieldQuery(field, queryText, true);
-  }
-
-  /**
-   * @exception ParseException throw in overridden method to disallow
-   */
-  protected Query getFieldQuery(String field, String queryText, boolean quoted)
-      throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  protected Query getBooleanQuery(List<BooleanClause> clauses, boolean disableCoord)
-      throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  /**
-   * Base implementation delegates to {@link #getFieldQuery(String,String)}.
-   * This method may be overridden, for example, to return a SpanNearQuery
-   * instead of a PhraseQuery.
-   * 
-   * @exception ParseException throw in overridden method to disallow
-   */
-  protected Query getFieldQuery(String field, String queryText, int slop)
-      throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-  /**
-   * @exception ParseException throw in overridden method to disallow
-   */
-  protected Query getRangeQuery(String field, String part1, String part2,
-      boolean inclusive) throws ParseException {
-    throw new UnsupportedOperationException();
-  }
-
-}
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/package.html b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/package.html
index 27ba181..5b5075f 100644
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/package.html
+++ b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/package.html
@@ -39,12 +39,5 @@ are used to reproduce the same behavior as the old query parser.
 Check <tt>org.apache.lucene.queryParser.standard.StandardQueryParser</tt> to quick start using the Lucene query parser. 
 </p>
 
-<p>
-There are 2 wrapper classes that extends QueryParser and MultiFieldQueryParser.
-The classes implement internally the new query parser structure. These 2 
-classes are deprecated and should only be used when there is a need to use the
-old query parser interface.  
-</p>
-
 </body>
 </html>
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/parser/JavaCharStream.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/parser/JavaCharStream.java
index 6c0bab9..94cd1c9 100644
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/parser/JavaCharStream.java
+++ b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/parser/JavaCharStream.java
@@ -347,7 +347,7 @@ public class JavaCharStream
 
   @Deprecated
   /**
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndColumn
    */
   public int getColumn() {
@@ -356,7 +356,7 @@ public class JavaCharStream
 
   @Deprecated
   /**
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndLine
    */
   public int getLine() {
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
index 5207ed7..0947475 100644
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
+++ b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/standard/processors/ParametricRangeQueryNodeProcessor.java
@@ -24,7 +24,6 @@ import java.util.Date;
 import java.util.List;
 import java.util.Locale;
 
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.document.DateTools.Resolution;
 import org.apache.lucene.queryParser.core.QueryNodeException;
@@ -140,17 +139,8 @@ public class ParametricRangeQueryNodeProcessor extends QueryNodeProcessorImpl {
           d2 = cal.getTime();
         }
 
-        if (dateRes == null) {
-          // no default or field specific date resolution has been set,
-          // use deprecated DateField to maintain compatibilty with
-          // pre-1.9 Lucene versions.
-          part1 = DateField.dateToString(d1);
-          part2 = DateField.dateToString(d2);
-
-        } else {
-          part1 = DateTools.dateToString(d1, dateRes);
-          part2 = DateTools.dateToString(d2, dateRes);
-        }
+        part1 = DateTools.dateToString(d1, dateRes);
+        part2 = DateTools.dateToString(d2, dateRes);
       } catch (Exception e) {
         // do nothing
       }
diff --git a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/surround/parser/CharStream.java b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/surround/parser/CharStream.java
index 5bf92d4..7c2d5f2 100644
--- a/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/surround/parser/CharStream.java
+++ b/lucene/contrib/queryparser/src/java/org/apache/lucene/queryParser/surround/parser/CharStream.java
@@ -28,14 +28,14 @@ public interface CharStream {
 
   /**
    * Returns the column position of the character last read.
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndColumn
    */
   int getColumn();
 
   /**
    * Returns the line number of the character last read.
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndLine
    */
   int getLine();
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java
index fc434fd..23d4fb4 100644
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java
+++ b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/core/nodes/TestQueryNode.java
@@ -25,11 +25,11 @@ public class TestQueryNode extends LuceneTestCase {
  
   /* LUCENE-2227 bug in QueryNodeImpl.add() */
   public void testAddChildren() throws Exception {
-    FieldQueryNode nodeA = new FieldQueryNode("foo", "A", 0, 1);
-    FieldQueryNode nodeB = new FieldQueryNode("foo", "B", 1, 2);
+    QueryNode nodeA = new FieldQueryNode("foo", "A", 0, 1);
+    QueryNode nodeB = new FieldQueryNode("foo", "B", 1, 2);
     BooleanQueryNode bq = new BooleanQueryNode(
-        Arrays.asList(new QueryNode[] { nodeA }));
-    bq.add(Arrays.asList(new QueryNode[] { nodeB }));
+        Arrays.asList(nodeA));
+    bq.add(Arrays.asList(nodeB));
     assertEquals(2, bq.getChildren().size());
   }
 }
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
index b68ab0b..cf0c887 100644
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
+++ b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/precedence/TestPrecedenceQueryParser.java
@@ -34,7 +34,6 @@ import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.queryParser.TestQueryParser;
 import org.apache.lucene.queryParser.core.QueryNodeException;
@@ -405,19 +404,11 @@ public class TestPrecedenceQueryParser extends LuceneTestCase {
     final String hourField = "hour";
     PrecedenceQueryParser qp = new PrecedenceQueryParser(new MockAnalyzer());
 
-    // Don't set any date resolution and verify if DateField is used
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
     Map<CharSequence, DateTools.Resolution> fieldMap = new HashMap<CharSequence,DateTools.Resolution>();
     // set a field specific date resolution
     fieldMap.put(monthField, DateTools.Resolution.MONTH);
     qp.setDateResolution(fieldMap);
 
-    // DateField should still be used for defaultField
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
     // set default date resolution to MILLISECOND
     qp.setDateResolution(DateTools.Resolution.MILLISECOND);
 
@@ -439,20 +430,14 @@ public class TestPrecedenceQueryParser extends LuceneTestCase {
   }
 
   /** for testing DateTools support */
-  private String getDate(String s, DateTools.Resolution resolution)
-      throws Exception {
+  private String getDate(String s, DateTools.Resolution resolution) throws Exception {
     DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
     return getDate(df.parse(s), resolution);
   }
 
   /** for testing DateTools support */
-  private String getDate(Date d, DateTools.Resolution resolution)
-      throws Exception {
-    if (resolution == null) {
-      return DateField.dateToString(d);
-    } else {
-      return DateTools.dateToString(d, resolution);
-    }
+  private String getDate(Date d, DateTools.Resolution resolution) throws Exception {
+    return DateTools.dateToString(d, resolution);
   }
 
   public void assertQueryEquals(PrecedenceQueryParser qp, String field, String query,
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java
deleted file mode 100644
index 4f3b14a..0000000
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiAnalyzerWrapper.java
+++ /dev/null
@@ -1,245 +0,0 @@
-package org.apache.lucene.queryParser.standard;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.util.LuceneTestCase;
-
-/**
- * This test case is a copy of the core Lucene query parser test, it was adapted
- * to use new QueryParserWrapper instead of the old query parser.
- * 
- * Test QueryParser's ability to deal with Analyzers that return more than one
- * token per position or that return tokens with a position increment &gt; 1.
- * 
- */
-public class TestMultiAnalyzerWrapper extends LuceneTestCase {
-
-  private static int multiToken = 0;
-
-  public void testMultiAnalyzer() throws ParseException {
-
-    QueryParserWrapper qp = new QueryParserWrapper("", new MultiAnalyzer());
-
-    // trivial, no multiple tokens:
-    assertEquals("foo", qp.parse("foo").toString());
-    assertEquals("foo", qp.parse("\"foo\"").toString());
-    assertEquals("foo foobar", qp.parse("foo foobar").toString());
-    assertEquals("\"foo foobar\"", qp.parse("\"foo foobar\"").toString());
-    assertEquals("\"foo foobar blah\"", qp.parse("\"foo foobar blah\"")
-        .toString());
-
-    // two tokens at the same position:
-    assertEquals("(multi multi2) foo", qp.parse("multi foo").toString());
-    assertEquals("foo (multi multi2)", qp.parse("foo multi").toString());
-    assertEquals("(multi multi2) (multi multi2)", qp.parse("multi multi")
-        .toString());
-    assertEquals("+(foo (multi multi2)) +(bar (multi multi2))", qp.parse(
-        "+(foo multi) +(bar multi)").toString());
-    assertEquals("+(foo (multi multi2)) field:\"bar (multi multi2)\"", qp
-        .parse("+(foo multi) field:\"bar multi\"").toString());
-
-    // phrases:
-    assertEquals("\"(multi multi2) foo\"", qp.parse("\"multi foo\"").toString());
-    assertEquals("\"foo (multi multi2)\"", qp.parse("\"foo multi\"").toString());
-    assertEquals("\"foo (multi multi2) foobar (multi multi2)\"", qp.parse(
-        "\"foo multi foobar multi\"").toString());
-
-    // fields:
-    assertEquals("(field:multi field:multi2) field:foo", qp.parse(
-        "field:multi field:foo").toString());
-    assertEquals("field:\"(multi multi2) foo\"", qp
-        .parse("field:\"multi foo\"").toString());
-
-    // three tokens at one position:
-    assertEquals("triplemulti multi3 multi2", qp.parse("triplemulti")
-        .toString());
-    assertEquals("foo (triplemulti multi3 multi2) foobar", qp.parse(
-        "foo triplemulti foobar").toString());
-
-    // phrase with non-default slop:
-    assertEquals("\"(multi multi2) foo\"~10", qp.parse("\"multi foo\"~10")
-        .toString());
-
-    // phrase with non-default boost:
-    assertEquals("\"(multi multi2) foo\"^2.0", qp.parse("\"multi foo\"^2")
-        .toString());
-
-    // phrase after changing default slop
-    qp.setPhraseSlop(99);
-    assertEquals("\"(multi multi2) foo\"~99 bar", qp.parse("\"multi foo\" bar")
-        .toString());
-    assertEquals("\"(multi multi2) foo\"~99 \"foo bar\"~2", qp.parse(
-        "\"multi foo\" \"foo bar\"~2").toString());
-    qp.setPhraseSlop(0);
-
-    // non-default operator:
-    qp.setDefaultOperator(QueryParserWrapper.AND_OPERATOR);
-    assertEquals("+(multi multi2) +foo", qp.parse("multi foo").toString());
-
-  }
-
-  // public void testMultiAnalyzerWithSubclassOfQueryParser() throws
-  // ParseException {
-  // this test doesn't make sense when using the new QueryParser API
-  // DumbQueryParser qp = new DumbQueryParser("", new MultiAnalyzer());
-  // qp.setPhraseSlop(99); // modified default slop
-  //
-  // // direct call to (super's) getFieldQuery to demonstrate differnce
-  // // between phrase and multiphrase with modified default slop
-  // assertEquals("\"foo bar\"~99",
-  // qp.getSuperFieldQuery("","foo bar").toString());
-  // assertEquals("\"(multi multi2) bar\"~99",
-  // qp.getSuperFieldQuery("","multi bar").toString());
-  //
-  //    
-  // // ask sublcass to parse phrase with modified default slop
-  // assertEquals("\"(multi multi2) foo\"~99 bar",
-  // qp.parse("\"multi foo\" bar").toString());
-  //    
-  // }
-
-  public void testPosIncrementAnalyzer() throws ParseException {
-    QueryParserWrapper qp = new QueryParserWrapper("",
-        new PosIncrementAnalyzer());
-    assertEquals("quick brown", qp.parse("the quick brown").toString());
-    assertEquals("\"quick brown\"", qp.parse("\"the quick brown\"").toString());
-    assertEquals("quick brown fox", qp.parse("the quick brown fox").toString());
-    assertEquals("\"quick brown fox\"", qp.parse("\"the quick brown fox\"")
-        .toString());
-  }
-
-  /**
-   * Expands "multi" to "multi" and "multi2", both at the same position, and
-   * expands "triplemulti" to "triplemulti", "multi3", and "multi2".
-   */
-  private class MultiAnalyzer extends Analyzer {
-
-    public MultiAnalyzer() {
-    }
-
-    @Override
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      TokenStream result = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);
-      result = new TestFilter(result);
-      return result;
-    }
-  }
-
-  private final class TestFilter extends TokenFilter {
-
-    private String prevType;
-    private int prevStartOffset;
-    private int prevEndOffset;
-
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
-    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-    private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);
-
-    public TestFilter(TokenStream in) {
-      super(in);
-    }
-
-    @Override
-    public final boolean incrementToken() throws java.io.IOException {
-      if (multiToken > 0) {
-        termAtt.setEmpty().append("multi" + (multiToken + 1));
-        offsetAtt.setOffset(prevStartOffset, prevEndOffset);
-        typeAtt.setType(prevType);
-        posIncrAtt.setPositionIncrement(0);
-        multiToken--;
-        return true;
-      } else {
-        boolean next = input.incrementToken();
-        if (next == false) {
-          return false;
-        }
-        prevType = typeAtt.type();
-        prevStartOffset = offsetAtt.startOffset();
-        prevEndOffset = offsetAtt.endOffset();
-        String text = termAtt.toString();
-        if (text.equals("triplemulti")) {
-          multiToken = 2;
-          return true;
-        } else if (text.equals("multi")) {
-          multiToken = 1;
-          return true;
-        } else {
-          return true;
-        }
-      }
-    }
-
-  }
-
-  /**
-   * Analyzes "the quick brown" as: quick(incr=2) brown(incr=1). Does not work
-   * correctly for input other than "the quick brown ...".
-   */
-  private class PosIncrementAnalyzer extends Analyzer {
-
-    public PosIncrementAnalyzer() {
-    }
-
-    @Override
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      TokenStream result = new MockTokenizer(reader, MockTokenizer.WHITESPACE, true);
-      result = new TestPosIncrementFilter(result);
-      return result;
-    }
-  }
-
-  private class TestPosIncrementFilter extends TokenFilter {
-
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
-
-    public TestPosIncrementFilter(TokenStream in) {
-      super(in);
-    }
-
-    @Override
-    public final boolean incrementToken() throws java.io.IOException {
-      while (input.incrementToken()) {
-        if (termAtt.toString().equals("the")) {
-          // stopword, do nothing
-        } else if (termAtt.toString().equals("quick")) {
-          posIncrAtt.setPositionIncrement(2);
-          return true;
-        } else {
-          posIncrAtt.setPositionIncrement(1);
-          return true;
-        }
-      }
-      return false;
-    }
-
-  }
-
-}
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java
deleted file mode 100644
index bded5f2..0000000
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestMultiFieldQueryParserWrapper.java
+++ /dev/null
@@ -1,370 +0,0 @@
-package org.apache.lucene.queryParser.standard;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.util.HashMap;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.queryParser.standard.MultiFieldQueryParserWrapper;
-import org.apache.lucene.queryParser.standard.QueryParserWrapper;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-/**
- * Tests multi field query parsing using the
- * {@link MultiFieldQueryParserWrapper}.
- * 
- * @deprecated this tests test the deprecated MultiFieldQueryParserWrapper, so
- *             when the latter is gone, so should this test.
- */
-@Deprecated
-public class TestMultiFieldQueryParserWrapper extends LuceneTestCase {
-
-  /**
-   * test stop words parsing for both the non static form, and for the
-   * corresponding static form (qtxt, fields[]).
-   */
-  public void testStopwordsParsing() throws Exception {
-    assertStopQueryEquals("one", "b:one t:one");
-    assertStopQueryEquals("one stop", "b:one t:one");
-    assertStopQueryEquals("one (stop)", "b:one t:one");
-    assertStopQueryEquals("one ((stop))", "b:one t:one");
-    assertStopQueryEquals("stop", "");
-    assertStopQueryEquals("(stop)", "");
-    assertStopQueryEquals("((stop))", "");
-  }
-
-  // verify parsing of query using a stopping analyzer
-  private void assertStopQueryEquals(String qtxt, String expectedRes)
-      throws Exception {
-    String[] fields = { "b", "t" };
-    Occur occur[] = { Occur.SHOULD, Occur.SHOULD };
-    TestQueryParserWrapper.QPTestAnalyzer a = new TestQueryParserWrapper.QPTestAnalyzer();
-    MultiFieldQueryParserWrapper mfqp = new MultiFieldQueryParserWrapper(
-        fields, a);
-
-    Query q = mfqp.parse(qtxt);
-    assertEquals(expectedRes, q.toString());
-
-    q = MultiFieldQueryParserWrapper.parse(qtxt, fields, occur, a);
-    assertEquals(expectedRes, q.toString());
-  }
-
-  public void testSimple() throws Exception {
-    String[] fields = { "b", "t" };
-    MultiFieldQueryParserWrapper mfqp = new MultiFieldQueryParserWrapper(
-        fields, new MockAnalyzer());
-
-    Query q = mfqp.parse("one");
-    assertEquals("b:one t:one", q.toString());
-
-    q = mfqp.parse("one two");
-    assertEquals("(b:one t:one) (b:two t:two)", q.toString());
-
-    q = mfqp.parse("+one +two");
-    assertEquals("+(b:one t:one) +(b:two t:two)", q.toString());
-
-    q = mfqp.parse("+one -two -three");
-    assertEquals("+(b:one t:one) -(b:two t:two) -(b:three t:three)", q
-        .toString());
-
-    q = mfqp.parse("one^2 two");
-    assertEquals("((b:one t:one)^2.0) (b:two t:two)", q.toString());
-
-    q = mfqp.parse("one~ two");
-    assertEquals("(b:one~2.0 t:one~2.0) (b:two t:two)", q.toString());
-
-    q = mfqp.parse("one~0.8 two^2");
-    assertEquals("(b:one~0.8 t:one~0.8) ((b:two t:two)^2.0)", q.toString());
-
-    q = mfqp.parse("one* two*");
-    assertEquals("(b:one* t:one*) (b:two* t:two*)", q.toString());
-
-    q = mfqp.parse("[a TO c] two");
-    assertEquals("(b:[a TO c] t:[a TO c]) (b:two t:two)", q.toString());
-
-    q = mfqp.parse("w?ldcard");
-    assertEquals("b:w?ldcard t:w?ldcard", q.toString());
-
-    q = mfqp.parse("\"foo bar\"");
-    assertEquals("b:\"foo bar\" t:\"foo bar\"", q.toString());
-
-    q = mfqp.parse("\"aa bb cc\" \"dd ee\"");
-    assertEquals("(b:\"aa bb cc\" t:\"aa bb cc\") (b:\"dd ee\" t:\"dd ee\")", q
-        .toString());
-
-    q = mfqp.parse("\"foo bar\"~4");
-    assertEquals("b:\"foo bar\"~4 t:\"foo bar\"~4", q.toString());
-
-    // LUCENE-1213: MultiFieldQueryParserWrapper was ignoring slop when phrase
-    // had a field.
-    q = mfqp.parse("b:\"foo bar\"~4");
-    assertEquals("b:\"foo bar\"~4", q.toString());
-
-    // make sure that terms which have a field are not touched:
-    q = mfqp.parse("one f:two");
-    assertEquals("(b:one t:one) f:two", q.toString());
-
-    // AND mode:
-    mfqp.setDefaultOperator(QueryParserWrapper.AND_OPERATOR);
-    q = mfqp.parse("one two");
-    assertEquals("+(b:one t:one) +(b:two t:two)", q.toString());
-    q = mfqp.parse("\"aa bb cc\" \"dd ee\"");
-    assertEquals("+(b:\"aa bb cc\" t:\"aa bb cc\") +(b:\"dd ee\" t:\"dd ee\")",
-        q.toString());
-
-  }
-
-  public void testBoostsSimple() throws Exception {
-    Map<String,Float> boosts = new HashMap<String,Float>();
-    boosts.put("b", Float.valueOf(5));
-    boosts.put("t", Float.valueOf(10));
-    String[] fields = { "b", "t" };
-    MultiFieldQueryParserWrapper mfqp = new MultiFieldQueryParserWrapper(
-        fields, new MockAnalyzer(), boosts);
-
-    // Check for simple
-    Query q = mfqp.parse("one");
-    assertEquals("b:one^5.0 t:one^10.0", q.toString());
-
-    // Check for AND
-    q = mfqp.parse("one AND two");
-    assertEquals("+(b:one^5.0 t:one^10.0) +(b:two^5.0 t:two^10.0)", q
-        .toString());
-
-    // Check for OR
-    q = mfqp.parse("one OR two");
-    assertEquals("(b:one^5.0 t:one^10.0) (b:two^5.0 t:two^10.0)", q.toString());
-
-    // Check for AND and a field
-    q = mfqp.parse("one AND two AND foo:test");
-    assertEquals("+(b:one^5.0 t:one^10.0) +(b:two^5.0 t:two^10.0) +foo:test", q
-        .toString());
-
-    q = mfqp.parse("one^3 AND two^4");
-    assertEquals("+((b:one^5.0 t:one^10.0)^3.0) +((b:two^5.0 t:two^10.0)^4.0)",
-        q.toString());
-  }
-
-  public void testStaticMethod1() throws ParseException {
-    String[] fields = { "b", "t" };
-    String[] queries = { "one", "two" };
-    Query q = MultiFieldQueryParserWrapper.parse(queries, fields,
-        new MockAnalyzer());
-    assertEquals("b:one t:two", q.toString());
-
-    String[] queries2 = { "+one", "+two" };
-    q = MultiFieldQueryParserWrapper.parse(queries2, fields,
-        new MockAnalyzer());
-    assertEquals("(+b:one) (+t:two)", q.toString());
-
-    String[] queries3 = { "one", "+two" };
-    q = MultiFieldQueryParserWrapper.parse(queries3, fields,
-        new MockAnalyzer());
-    assertEquals("b:one (+t:two)", q.toString());
-
-    String[] queries4 = { "one +more", "+two" };
-    q = MultiFieldQueryParserWrapper.parse(queries4, fields,
-        new MockAnalyzer());
-    assertEquals("(b:one +b:more) (+t:two)", q.toString());
-
-    String[] queries5 = { "blah" };
-    try {
-      q = MultiFieldQueryParserWrapper.parse(queries5, fields,
-          new MockAnalyzer());
-      fail();
-    } catch (IllegalArgumentException e) {
-      // expected exception, array length differs
-    }
-
-    // check also with stop words for this static form (qtxts[], fields[]).
-    TestQueryParserWrapper.QPTestAnalyzer stopA = new TestQueryParserWrapper.QPTestAnalyzer();
-
-    String[] queries6 = { "((+stop))", "+((stop))" };
-    q = MultiFieldQueryParserWrapper.parse(queries6, fields, stopA);
-    assertEquals("", q.toString());
-
-    String[] queries7 = { "one ((+stop)) +more", "+((stop)) +two" };
-    q = MultiFieldQueryParserWrapper.parse(queries7, fields, stopA);
-    assertEquals("(b:one +b:more) (+t:two)", q.toString());
-
-  }
-
-  public void testStaticMethod2() throws ParseException {
-    String[] fields = { "b", "t" };
-    BooleanClause.Occur[] flags = { BooleanClause.Occur.MUST,
-        BooleanClause.Occur.MUST_NOT };
-    Query q = MultiFieldQueryParserWrapper.parse("one", fields, flags,
-        new MockAnalyzer());
-    assertEquals("+b:one -t:one", q.toString());
-
-    q = MultiFieldQueryParserWrapper.parse("one two", fields, flags,
-        new MockAnalyzer());
-    assertEquals("+(b:one b:two) -(t:one t:two)", q.toString());
-
-    try {
-      BooleanClause.Occur[] flags2 = { BooleanClause.Occur.MUST };
-      q = MultiFieldQueryParserWrapper.parse("blah", fields, flags2,
-          new MockAnalyzer());
-      fail();
-    } catch (IllegalArgumentException e) {
-      // expected exception, array length differs
-    }
-  }
-
-  public void testStaticMethod2Old() throws ParseException {
-    String[] fields = { "b", "t" };
-    // int[] flags = {MultiFieldQueryParserWrapper.REQUIRED_FIELD,
-    // MultiFieldQueryParserWrapper.PROHIBITED_FIELD};
-    BooleanClause.Occur[] flags = { BooleanClause.Occur.MUST,
-        BooleanClause.Occur.MUST_NOT };
-
-    Query q = MultiFieldQueryParserWrapper.parse("one", fields, flags,
-        new MockAnalyzer());// , fields, flags, new MockAnalyzer());
-    assertEquals("+b:one -t:one", q.toString());
-
-    q = MultiFieldQueryParserWrapper.parse("one two", fields, flags,
-        new MockAnalyzer());
-    assertEquals("+(b:one b:two) -(t:one t:two)", q.toString());
-
-    try {
-      BooleanClause.Occur[] flags2 = { BooleanClause.Occur.MUST };
-      q = MultiFieldQueryParserWrapper.parse("blah", fields, flags2,
-          new MockAnalyzer());
-      fail();
-    } catch (IllegalArgumentException e) {
-      // expected exception, array length differs
-    }
-  }
-
-  public void testStaticMethod3() throws ParseException {
-    String[] queries = { "one", "two", "three" };
-    String[] fields = { "f1", "f2", "f3" };
-    BooleanClause.Occur[] flags = { BooleanClause.Occur.MUST,
-        BooleanClause.Occur.MUST_NOT, BooleanClause.Occur.SHOULD };
-    Query q = MultiFieldQueryParserWrapper.parse(queries, fields, flags,
-        new MockAnalyzer());
-    assertEquals("+f1:one -f2:two f3:three", q.toString());
-
-    try {
-      BooleanClause.Occur[] flags2 = { BooleanClause.Occur.MUST };
-      q = MultiFieldQueryParserWrapper.parse(queries, fields, flags2,
-          new MockAnalyzer());
-      fail();
-    } catch (IllegalArgumentException e) {
-      // expected exception, array length differs
-    }
-  }
-
-  public void testStaticMethod3Old() throws ParseException {
-    String[] queries = { "one", "two" };
-    String[] fields = { "b", "t" };
-    BooleanClause.Occur[] flags = { BooleanClause.Occur.MUST,
-        BooleanClause.Occur.MUST_NOT };
-    Query q = MultiFieldQueryParserWrapper.parse(queries, fields, flags,
-        new MockAnalyzer());
-    assertEquals("+b:one -t:two", q.toString());
-
-    try {
-      BooleanClause.Occur[] flags2 = { BooleanClause.Occur.MUST };
-      q = MultiFieldQueryParserWrapper.parse(queries, fields, flags2,
-          new MockAnalyzer());
-      fail();
-    } catch (IllegalArgumentException e) {
-      // expected exception, array length differs
-    }
-  }
-
-  public void testAnalyzerReturningNull() throws ParseException {
-    String[] fields = new String[] { "f1", "f2", "f3" };
-    MultiFieldQueryParserWrapper parser = new MultiFieldQueryParserWrapper(
-        fields, new AnalyzerReturningNull());
-    Query q = parser.parse("bla AND blo");
-    assertEquals("+(f2:bla f3:bla) +(f2:blo f3:blo)", q.toString());
-    // the following queries are not affected as their terms are not analyzed
-    // anyway:
-    q = parser.parse("bla*");
-    assertEquals("f1:bla* f2:bla* f3:bla*", q.toString());
-    q = parser.parse("bla~");
-    assertEquals("f1:bla~2.0 f2:bla~2.0 f3:bla~2.0", q.toString());
-    q = parser.parse("[a TO c]");
-    assertEquals("f1:[a TO c] f2:[a TO c] f3:[a TO c]", q.toString());
-  }
-
-  public void testStopWordSearching() throws Exception {
-    Analyzer analyzer = new MockAnalyzer();
-    Directory ramDir = newDirectory();
-    IndexWriter iw = new IndexWriter(ramDir, analyzer, true,
-        IndexWriter.MaxFieldLength.LIMITED);
-    Document doc = new Document();
-    doc.add(newField("body", "blah the footest blah", Field.Store.NO,
-        Field.Index.ANALYZED));
-    iw.addDocument(doc);
-    iw.close();
-
-    MultiFieldQueryParserWrapper mfqp = new MultiFieldQueryParserWrapper(
-        new String[] { "body" }, analyzer);
-    mfqp.setDefaultOperator(QueryParserWrapper.Operator.AND);
-    Query q = mfqp.parse("the footest");
-    IndexSearcher is = new IndexSearcher(ramDir, true);
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
-    assertEquals(1, hits.length);
-    is.close();
-    ramDir.close();
-  }
-
-  /**
-   * Return empty tokens for field "f1".
-   */
-  private static class AnalyzerReturningNull extends Analyzer {
-    MockAnalyzer stdAnalyzer = new MockAnalyzer();
-
-    public AnalyzerReturningNull() {
-    }
-
-    @Override
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      if ("f1".equals(fieldName)) {
-        return new EmptyTokenStream();
-      } else {
-        return stdAnalyzer.tokenStream(fieldName, reader);
-      }
-    }
-
-    private static class EmptyTokenStream extends TokenStream {
-      @Override
-      public boolean incrementToken() {
-        return false;
-      }
-    }
-  }
-
-}
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
index 1f2e636..a0a02a9 100644
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
+++ b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQPHelper.java
@@ -39,7 +39,6 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -692,12 +691,6 @@ public class TestQPHelper extends LuceneTestCase {
     ramDir.close();
   }
 
-  /** for testing legacy DateField support */
-  private String getLegacyDate(String s) throws Exception {
-    DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
-    return DateField.dateToString(df.parse(s));
-  }
-
   /** for testing DateTools support */
   private String getDate(String s, DateTools.Resolution resolution)
       throws Exception {
@@ -708,11 +701,7 @@ public class TestQPHelper extends LuceneTestCase {
   /** for testing DateTools support */
   private String getDate(Date d, DateTools.Resolution resolution)
       throws Exception {
-    if (resolution == null) {
-      return DateField.dateToString(d);
-    } else {
-      return DateTools.dateToString(d, resolution);
-    }
+    return DateTools.dateToString(d, resolution);
   }
   
   private String escapeDateString(String s) {
@@ -735,21 +724,6 @@ public class TestQPHelper extends LuceneTestCase {
     return df.format(calendar.getTime());
   }
 
-  /** for testing legacy DateField support */
-  public void testLegacyDateRange() throws Exception {
-    String startDate = getLocalizedDate(2002, 1, 1);
-    String endDate = getLocalizedDate(2002, 1, 4);
-    Calendar endDateExpected = new GregorianCalendar();
-    endDateExpected.clear();
-    endDateExpected.set(2002, 1, 4, 23, 59, 59);
-    endDateExpected.set(Calendar.MILLISECOND, 999);
-    assertQueryEquals("[ " + escapeDateString(startDate) + " TO " + escapeDateString(endDate) + "]", null, "["
-        + getLegacyDate(startDate) + " TO "
-        + DateField.dateToString(endDateExpected.getTime()) + "]");
-    assertQueryEquals("{  " + escapeDateString(startDate) + "    " + escapeDateString(endDate) + "   }", null, "{"
-        + getLegacyDate(startDate) + " TO " + getLegacyDate(endDate) + "}");
-  }
-
   public void testDateRange() throws Exception {
     String startDate = getLocalizedDate(2002, 1, 1);
     String endDate = getLocalizedDate(2002, 1, 4);
@@ -762,20 +736,12 @@ public class TestQPHelper extends LuceneTestCase {
     final String hourField = "hour";
     StandardQueryParser qp = new StandardQueryParser();
 
-    // Don't set any date resolution and verify if DateField is used
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
     Map<CharSequence, DateTools.Resolution> dateRes =  new HashMap<CharSequence, DateTools.Resolution>();
     
     // set a field specific date resolution    
     dateRes.put(monthField, DateTools.Resolution.MONTH);
     qp.setDateResolution(dateRes);
 
-    // DateField should still be used for defaultField
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
     // set default date resolution to MILLISECOND
     qp.setDateResolution(DateTools.Resolution.MILLISECOND);
 
@@ -1075,22 +1041,35 @@ public class TestQPHelper extends LuceneTestCase {
     assertEquals(query1, query2);
   }
 
-  public void testLocalDateFormat() throws IOException, QueryNodeException {
-    Directory ramDir = newDirectory();
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
-    addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
-    addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
-    iw.close();
-    IndexSearcher is = new IndexSearcher(ramDir, true);
-    assertHits(1, "[12/1/2005 TO 12/3/2005]", is);
-    assertHits(2, "[12/1/2005 TO 12/4/2005]", is);
-    assertHits(1, "[12/3/2005 TO 12/4/2005]", is);
-    assertHits(1, "{12/1/2005 TO 12/3/2005}", is);
-    assertHits(1, "{12/1/2005 TO 12/4/2005}", is);
-    assertHits(0, "{12/3/2005 TO 12/4/2005}", is);
-    is.close();
-    ramDir.close();
-  }
+// Todo (nocommit): Convert from DateField to DateUtil
+//  public void testLocalDateFormat() throws IOException, QueryNodeException {
+//    Directory ramDir = newDirectory();
+//    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+//    addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
+//    addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
+//    iw.close();
+//    IndexSearcher is = new IndexSearcher(ramDir, true);
+//    assertHits(1, "[12/1/2005 TO 12/3/2005]", is);
+//    assertHits(2, "[12/1/2005 TO 12/4/2005]", is);
+//    assertHits(1, "[12/3/2005 TO 12/4/2005]", is);
+//    assertHits(1, "{12/1/2005 TO 12/3/2005}", is);
+//    assertHits(1, "{12/1/2005 TO 12/4/2005}", is);
+//    assertHits(0, "{12/3/2005 TO 12/4/2005}", is);
+//    is.close();
+//    ramDir.close();
+//  }
+//
+//  private void addDateDoc(String content, int year, int month, int day,
+//                          int hour, int minute, int second, IndexWriter iw) throws IOException {
+//    Document d = new Document();
+//    d.add(newField("f", content, Field.Store.YES, Field.Index.ANALYZED));
+//    Calendar cal = Calendar.getInstance(Locale.ENGLISH);
+//    cal.set(year, month - 1, day, hour, minute, second);
+//    d.add(newField("date", DateField.dateToString(cal.getTime()),
+//        Field.Store.YES, Field.Index.NOT_ANALYZED));
+//    iw.addDocument(d);
+//  }
+
 
   public void testStarParsing() throws Exception {
     // final int[] type = new int[1];
@@ -1251,17 +1230,6 @@ public class TestQPHelper extends LuceneTestCase {
     assertEquals(expected, hits.length);
   }
 
-  private void addDateDoc(String content, int year, int month, int day,
-      int hour, int minute, int second, IndexWriter iw) throws IOException {
-    Document d = new Document();
-    d.add(newField("f", content, Field.Store.YES, Field.Index.ANALYZED));
-    Calendar cal = Calendar.getInstance(Locale.ENGLISH);
-    cal.set(year, month - 1, day, hour, minute, second);
-    d.add(newField("date", DateField.dateToString(cal.getTime()),
-        Field.Store.YES, Field.Index.NOT_ANALYZED));
-    iw.addDocument(d);
-  }
-
   @Override
   public void tearDown() throws Exception {
     BooleanQuery.setMaxClauseCount(originalMaxClauses);
diff --git a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java b/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
deleted file mode 100644
index 1432f71..0000000
--- a/lucene/contrib/queryparser/src/test/org/apache/lucene/queryParser/standard/TestQueryParserWrapper.java
+++ /dev/null
@@ -1,1212 +0,0 @@
-package org.apache.lucene.queryParser.standard;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.text.Collator;
-import java.text.DateFormat;
-import java.util.Calendar;
-import java.util.Date;
-import java.util.GregorianCalendar;
-import java.util.List;
-import java.util.Locale;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.analysis.MockTokenFilter;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.document.DateField;
-import org.apache.lucene.document.DateTools;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.messages.MessageImpl;
-import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.queryParser.core.QueryNodeException;
-import org.apache.lucene.queryParser.core.messages.QueryParserMessages;
-import org.apache.lucene.queryParser.core.nodes.FuzzyQueryNode;
-import org.apache.lucene.queryParser.core.nodes.QueryNode;
-import org.apache.lucene.queryParser.core.processors.QueryNodeProcessorImpl;
-import org.apache.lucene.queryParser.core.processors.QueryNodeProcessorPipeline;
-import org.apache.lucene.queryParser.standard.nodes.WildcardQueryNode;
-import org.apache.lucene.queryParser.standard.processors.WildcardQueryNodeProcessor;
-import org.apache.lucene.search.BooleanClause;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.FuzzyQuery;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.MatchAllDocsQuery;
-import org.apache.lucene.search.MultiTermQuery;
-import org.apache.lucene.search.PhraseQuery;
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermQuery;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.search.WildcardQuery;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.automaton.BasicAutomata;
-import org.apache.lucene.util.automaton.CharacterRunAutomaton;
-import org.apache.lucene.util.automaton.RegExp;
-
-/**
- * This test case is a copy of the core Lucene query parser test, it was adapted
- * to use new {@link QueryParserWrapper} instead of the old query parser.
- * 
- * Tests QueryParser.
- * 
- * @deprecated this entire test case tests QueryParserWrapper which is
- *             deprecated. When QPW is gone, so will the test.
- */
-@Deprecated
-public class TestQueryParserWrapper extends LuceneTestCase {
-  
-  public static Analyzer qpAnalyzer = new QPTestAnalyzer();
-
-  public static final class QPTestFilter extends TokenFilter {
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-
-    /**
-     * Filter which discards the token 'stop' and which expands the token
-     * 'phrase' into 'phrase1 phrase2'
-     */
-    public QPTestFilter(TokenStream in) {
-      super(in);
-    }
-
-    boolean inPhrase = false;
-    int savedStart = 0, savedEnd = 0;
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      if (inPhrase) {
-        inPhrase = false;
-        clearAttributes();
-        termAtt.setEmpty().append("phrase2");
-        offsetAtt.setOffset(savedStart, savedEnd);
-        return true;
-      } else
-        while (input.incrementToken()) {
-          if (termAtt.toString().equals("phrase")) {
-            inPhrase = true;
-            savedStart = offsetAtt.startOffset();
-            savedEnd = offsetAtt.endOffset();
-            termAtt.setEmpty().append("phrase1");
-            offsetAtt.setOffset(savedStart, savedEnd);
-            return true;
-          } else if (!termAtt.toString().equals("stop"))
-            return true;
-        }
-      return false;
-    }
-  }
-
-  public static final class QPTestAnalyzer extends Analyzer {
-
-    /** Filters MockTokenizer with StopFilter. */
-    @Override
-    public final TokenStream tokenStream(String fieldName, Reader reader) {
-      return new QPTestFilter(new MockTokenizer(reader, MockTokenizer.SIMPLE, true));
-    }
-  }
-
-  public static class QPTestParser extends QueryParserWrapper {
-    public QPTestParser(String f, Analyzer a) {
-      super(f, a);
-
-      QueryNodeProcessorPipeline newProcessorPipeline = new QueryNodeProcessorPipeline(
-          getQueryProcessor().getQueryConfigHandler());
-      newProcessorPipeline.add(new WildcardQueryNodeProcessor());
-      newProcessorPipeline.add(new QPTestParserQueryNodeProcessor());
-      newProcessorPipeline.add(getQueryProcessor());
-
-      setQueryProcessor(newProcessorPipeline);
-
-    }
-
-    @Override
-    protected Query getFuzzyQuery(String field, String termStr,
-        float minSimilarity) throws ParseException {
-      throw new ParseException("Fuzzy queries not allowed");
-    }
-
-    @Override
-    protected Query getWildcardQuery(String field, String termStr)
-        throws ParseException {
-      throw new ParseException("Wildcard queries not allowed");
-    }
-
-    private static class QPTestParserQueryNodeProcessor extends
-        QueryNodeProcessorImpl {
-
-      @Override
-      protected QueryNode postProcessNode(QueryNode node)
-          throws QueryNodeException {
-
-        return node;
-
-      }
-
-      @Override
-      protected QueryNode preProcessNode(QueryNode node)
-          throws QueryNodeException {
-
-        if (node instanceof WildcardQueryNode || node instanceof FuzzyQueryNode) {
-
-          throw new QueryNodeException(new MessageImpl(
-              QueryParserMessages.EMPTY_MESSAGE));
-
-        }
-
-        return node;
-
-      }
-
-      @Override
-      protected List<QueryNode> setChildrenOrder(List<QueryNode> children)
-          throws QueryNodeException {
-
-        return children;
-
-      }
-
-    }
-
-  }
-
-  private int originalMaxClauses;
-
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    originalMaxClauses = BooleanQuery.getMaxClauseCount();
-  }
-
-  public QueryParserWrapper getParser(Analyzer a) throws Exception {
-    if (a == null)
-      a = new MockAnalyzer(MockTokenizer.SIMPLE, true);
-    QueryParserWrapper qp = new QueryParserWrapper("field", a);
-    qp.setDefaultOperator(QueryParserWrapper.OR_OPERATOR);
-    return qp;
-  }
-
-  public Query getQuery(String query, Analyzer a) throws Exception {
-    return getParser(a).parse(query);
-  }
-
-  public Query getQueryAllowLeadingWildcard(String query, Analyzer a) throws Exception {
-    QueryParserWrapper parser = getParser(a);
-    parser.setAllowLeadingWildcard(true);
-    return parser.parse(query);
-  }
-
-  public void assertQueryEquals(String query, Analyzer a, String result)
-      throws Exception {
-    Query q = getQuery(query, a);
-    String s = q.toString("field");
-    if (!s.equals(result)) {
-      fail("Query /" + query + "/ yielded /" + s + "/, expecting /" + result
-          + "/");
-    }
-  }
-
-  public void assertQueryEqualsAllowLeadingWildcard(String query, Analyzer a, String result)
-      throws Exception {
-    Query q = getQueryAllowLeadingWildcard(query, a);
-    String s = q.toString("field");
-    if (!s.equals(result)) {
-      fail("Query /" + query + "/ yielded /" + s + "/, expecting /" + result
-          + "/");
-    }
-  }
-  public void assertQueryEquals(QueryParserWrapper qp, String field,
-      String query, String result) throws Exception {
-    Query q = qp.parse(query);
-    String s = q.toString(field);
-    if (!s.equals(result)) {
-      fail("Query /" + query + "/ yielded /" + s + "/, expecting /" + result
-          + "/");
-    }
-  }
-
-  public void assertEscapedQueryEquals(String query, Analyzer a, String result)
-      throws Exception {
-    String escapedQuery = QueryParserWrapper.escape(query);
-    if (!escapedQuery.equals(result)) {
-      fail("Query /" + query + "/ yielded /" + escapedQuery + "/, expecting /"
-          + result + "/");
-    }
-  }
-
-  public void assertWildcardQueryEquals(String query, boolean lowercase,
-      String result, boolean allowLeadingWildcard) throws Exception {
-    QueryParserWrapper qp = getParser(null);
-    qp.setLowercaseExpandedTerms(lowercase);
-    qp.setAllowLeadingWildcard(allowLeadingWildcard);
-    Query q = qp.parse(query);
-    String s = q.toString("field");
-    if (!s.equals(result)) {
-      fail("WildcardQuery /" + query + "/ yielded /" + s + "/, expecting /"
-          + result + "/");
-    }
-  }
-
-  public void assertWildcardQueryEquals(String query, boolean lowercase,
-      String result) throws Exception {
-    assertWildcardQueryEquals(query, lowercase, result, false);
-  }
-
-  public void assertWildcardQueryEquals(String query, String result)
-      throws Exception {
-    QueryParserWrapper qp = getParser(null);
-    Query q = qp.parse(query);
-    String s = q.toString("field");
-    if (!s.equals(result)) {
-      fail("WildcardQuery /" + query + "/ yielded /" + s + "/, expecting /"
-          + result + "/");
-    }
-  }
-
-  public Query getQueryDOA(String query, Analyzer a) throws Exception {
-    if (a == null)
-      a = new MockAnalyzer(MockTokenizer.SIMPLE, true);
-    QueryParserWrapper qp = new QueryParserWrapper("field", a);
-    qp.setDefaultOperator(QueryParserWrapper.AND_OPERATOR);
-    return qp.parse(query);
-  }
-
-  public void assertQueryEqualsDOA(String query, Analyzer a, String result)
-      throws Exception {
-    Query q = getQueryDOA(query, a);
-    String s = q.toString("field");
-    if (!s.equals(result)) {
-      fail("Query /" + query + "/ yielded /" + s + "/, expecting /" + result
-          + "/");
-    }
-  }
-
-  public void testCJK() throws Exception {
-    // Test Ideographic Space - As wide as a CJK character cell (fullwidth)
-    // used google to translate the word "term" to japanese -> ??
-    assertQueryEquals("term\u3000term\u3000term", null,
-        "term\u0020term\u0020term");
-    assertQueryEqualsAllowLeadingWildcard("??\u3000??\u3000??", null, "??\u0020??\u0020??");
-  }
-
-  //individual CJK chars as terms, like StandardAnalyzer
-  private class SimpleCJKTokenizer extends Tokenizer {
-    private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-
-    public SimpleCJKTokenizer(Reader input) {
-      super(input);
-    }
-
-    @Override
-    public boolean incrementToken() throws IOException {
-      int ch = input.read();
-      if (ch < 0)
-        return false;
-      clearAttributes();
-      termAtt.setEmpty().append((char) ch);
-      return true;
-    }
-  }
-
-  private class SimpleCJKAnalyzer extends Analyzer {
-    @Override
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      return new SimpleCJKTokenizer(reader);
-    }
-  }
-  
-  public void testCJKTerm() throws Exception {
-    // individual CJK chars as terms
-    SimpleCJKAnalyzer analyzer = new SimpleCJKAnalyzer();
-    
-    BooleanQuery expected = new BooleanQuery();
-    expected.add(new TermQuery(new Term("field", "?")), BooleanClause.Occur.SHOULD);
-    expected.add(new TermQuery(new Term("field", "??")), BooleanClause.Occur.SHOULD);
-    
-    assertEquals(expected, getQuery("??", analyzer));
-  }
-  
-  public void testCJKBoostedTerm() throws Exception {
-    // individual CJK chars as terms
-    SimpleCJKAnalyzer analyzer = new SimpleCJKAnalyzer();
-    
-    BooleanQuery expected = new BooleanQuery();
-    expected.setBoost(0.5f);
-    expected.add(new TermQuery(new Term("field", "?")), BooleanClause.Occur.SHOULD);
-    expected.add(new TermQuery(new Term("field", "??")), BooleanClause.Occur.SHOULD);
-    
-    assertEquals(expected, getQuery("??^0.5", analyzer));
-  }
-  
-  public void testCJKPhrase() throws Exception {
-    // individual CJK chars as terms
-    SimpleCJKAnalyzer analyzer = new SimpleCJKAnalyzer();
-    
-    PhraseQuery expected = new PhraseQuery();
-    expected.add(new Term("field", "?"));
-    expected.add(new Term("field", "??"));
-    
-    assertEquals(expected, getQuery("\"??\"", analyzer));
-  }
-  
-  public void testCJKBoostedPhrase() throws Exception {
-    // individual CJK chars as terms
-    SimpleCJKAnalyzer analyzer = new SimpleCJKAnalyzer();
-    
-    PhraseQuery expected = new PhraseQuery();
-    expected.setBoost(0.5f);
-    expected.add(new Term("field", "?"));
-    expected.add(new Term("field", "??"));
-    
-    assertEquals(expected, getQuery("\"??\"^0.5", analyzer));
-  }
-  
-  public void testCJKSloppyPhrase() throws Exception {
-    // individual CJK chars as terms
-    SimpleCJKAnalyzer analyzer = new SimpleCJKAnalyzer();
-    
-    PhraseQuery expected = new PhraseQuery();
-    expected.setSlop(3);
-    expected.add(new Term("field", "?"));
-    expected.add(new Term("field", "??"));
-    
-    assertEquals(expected, getQuery("\"??\"~3", analyzer));
-  }
-  
-  public void testSimple() throws Exception {
-    assertQueryEquals("\"term germ\"~2", null, "\"term germ\"~2");
-    assertQueryEquals("term term term", null, "term term term");
-    assertQueryEquals("t?m term term", new MockAnalyzer(MockTokenizer.WHITESPACE, false),
-        "t?m term term");
-    assertQueryEquals("?laut", new MockAnalyzer(MockTokenizer.WHITESPACE, false), "?laut");
-
-    //FIXME: Change MockAnalyzer to not extend CharTokenizer for this test
-    //assertQueryEquals("\"\"", new KeywordAnalyzer(), "");
-    //assertQueryEquals("foo:\"\"", new KeywordAnalyzer(), "foo:");
-
-    assertQueryEquals("a AND b", null, "+a +b");
-    assertQueryEquals("(a AND b)", null, "+a +b");
-    assertQueryEquals("c OR (a AND b)", null, "c (+a +b)");
-
-    assertQueryEquals("a AND NOT b", null, "+a -b");
-
-    assertQueryEquals("a AND -b", null, "+a -b");
-
-    assertQueryEquals("a AND !b", null, "+a -b");
-
-    assertQueryEquals("a && b", null, "+a +b");
-
-    assertQueryEquals("a && ! b", null, "+a -b");
-
-    assertQueryEquals("a OR b", null, "a b");
-    assertQueryEquals("a || b", null, "a b");
-
-    assertQueryEquals("a OR !b", null, "a -b");
-
-    assertQueryEquals("a OR ! b", null, "a -b");
-
-    assertQueryEquals("a OR -b", null, "a -b");
-
-    assertQueryEquals("+term -term term", null, "+term -term term");
-    assertQueryEquals("foo:term AND field:anotherTerm", null,
-        "+foo:term +anotherterm");
-    assertQueryEquals("term AND \"phrase phrase\"", null,
-        "+term +\"phrase phrase\"");
-    assertQueryEquals("\"hello there\"", null, "\"hello there\"");
-    assertTrue(getQuery("a AND b", null) instanceof BooleanQuery);
-    assertTrue(getQuery("hello", null) instanceof TermQuery);
-    assertTrue(getQuery("\"hello there\"", null) instanceof PhraseQuery);
-
-    assertQueryEquals("germ term^2.0", null, "germ term^2.0");
-    assertQueryEquals("(term)^2.0", null, "term^2.0");
-    assertQueryEquals("(germ term)^2.0", null, "(germ term)^2.0");
-    assertQueryEquals("term^2.0", null, "term^2.0");
-    assertQueryEquals("term^2", null, "term^2.0");
-    assertQueryEquals("\"germ term\"^2.0", null, "\"germ term\"^2.0");
-    assertQueryEquals("\"term germ\"^2", null, "\"term germ\"^2.0");
-
-    assertQueryEquals("(foo OR bar) AND (baz OR boo)", null,
-        "+(foo bar) +(baz boo)");
-    assertQueryEquals("((a OR b) AND NOT c) OR d", null, "(+(a b) -c) d");
-    assertQueryEquals("+(apple \"steve jobs\") -(foo bar baz)", null,
-        "+(apple \"steve jobs\") -(foo bar baz)");
-    assertQueryEquals("+title:(dog OR cat) -author:\"bob dole\"", null,
-        "+(title:dog title:cat) -author:\"bob dole\"");
-
-    QueryParserWrapper qp = new QueryParserWrapper("field",
-        new MockAnalyzer());
-    // make sure OR is the default:
-    assertEquals(QueryParserWrapper.OR_OPERATOR, qp.getDefaultOperator());
-    qp.setDefaultOperator(QueryParserWrapper.AND_OPERATOR);
-    assertEquals(QueryParserWrapper.AND_OPERATOR, qp.getDefaultOperator());
-    qp.setDefaultOperator(QueryParserWrapper.OR_OPERATOR);
-    assertEquals(QueryParserWrapper.OR_OPERATOR, qp.getDefaultOperator());
-  }
-
-  public void testPunct() throws Exception {
-    Analyzer a = new MockAnalyzer(MockTokenizer.WHITESPACE, false);
-    assertQueryEquals("a&b", a, "a&b");
-    assertQueryEquals("a&&b", a, "a&&b");
-    assertQueryEquals(".NET", a, ".NET");
-  }
-
-  public void testSlop() throws Exception {
-
-    assertQueryEquals("\"term germ\"~2", null, "\"term germ\"~2");
-    assertQueryEquals("\"term germ\"~2 flork", null, "\"term germ\"~2 flork");
-    assertQueryEquals("\"term\"~2", null, "term");
-    assertQueryEquals("\" \"~2 germ", null, "germ");
-    assertQueryEquals("\"term germ\"~2^2", null, "\"term germ\"~2^2.0");
-  }
-
-  public void testNumber() throws Exception {
-    // The numbers go away because SimpleAnalzyer ignores them
-    assertQueryEquals("3", null, "");
-    assertQueryEquals("term 1.0 1 2", null, "term");
-    assertQueryEquals("term term1 term2", null, "term term term");
-
-    Analyzer a = new MockAnalyzer(MockTokenizer.WHITESPACE, false);
-    assertQueryEquals("3", a, "3");
-    assertQueryEquals("term 1.0 1 2", a, "term 1.0 1 2");
-    assertQueryEquals("term term1 term2", a, "term term1 term2");
-  }
-
-  public void testWildcard() throws Exception {
-    assertQueryEquals("term*", null, "term*");
-    assertQueryEquals("term*^2", null, "term*^2.0");
-    assertQueryEquals("term~", null, "term~2.0");
-    assertQueryEquals("term~0.7", null, "term~0.7");
-
-    assertQueryEquals("term~^3", null, "term~2.0^3.0");
-
-    assertQueryEquals("term^3~", null, "term~2.0^3.0");
-    assertQueryEquals("term*germ", null, "term*germ");
-    assertQueryEquals("term*germ^3", null, "term*germ^3.0");
-
-    assertTrue(getQuery("term*", null) instanceof PrefixQuery);
-    assertTrue(getQuery("term*^2", null) instanceof PrefixQuery);
-    assertTrue(getQuery("term~", null) instanceof FuzzyQuery);
-    assertTrue(getQuery("term~0.7", null) instanceof FuzzyQuery);
-    FuzzyQuery fq = (FuzzyQuery) getQuery("term~0.7", null);
-    assertEquals(0.7f, fq.getMinSimilarity(), 0.1f);
-    assertEquals(FuzzyQuery.defaultPrefixLength, fq.getPrefixLength());
-    fq = (FuzzyQuery) getQuery("term~", null);
-    assertEquals(2.0f, fq.getMinSimilarity(), 0.1f);
-    assertEquals(FuzzyQuery.defaultPrefixLength, fq.getPrefixLength());
-
-    assertParseException("term~1.1"); // value > 1, throws exception
-
-    assertTrue(getQuery("term*germ", null) instanceof WildcardQuery);
-
-    /*
-     * Tests to see that wild card terms are (or are not) properly lower-cased
-     * with propery parser configuration
-     */
-    // First prefix queries:
-    // by default, convert to lowercase:
-    assertWildcardQueryEquals("Term*", true, "term*");
-    // explicitly set lowercase:
-    assertWildcardQueryEquals("term*", true, "term*");
-    assertWildcardQueryEquals("Term*", true, "term*");
-    assertWildcardQueryEquals("TERM*", true, "term*");
-    // explicitly disable lowercase conversion:
-    assertWildcardQueryEquals("term*", false, "term*");
-    assertWildcardQueryEquals("Term*", false, "Term*");
-    assertWildcardQueryEquals("TERM*", false, "TERM*");
-    // Then 'full' wildcard queries:
-    // by default, convert to lowercase:
-    assertWildcardQueryEquals("Te?m", "te?m");
-    // explicitly set lowercase:
-    assertWildcardQueryEquals("te?m", true, "te?m");
-    assertWildcardQueryEquals("Te?m", true, "te?m");
-    assertWildcardQueryEquals("TE?M", true, "te?m");
-    assertWildcardQueryEquals("Te?m*gerM", true, "te?m*germ");
-    // explicitly disable lowercase conversion:
-    assertWildcardQueryEquals("te?m", false, "te?m");
-    assertWildcardQueryEquals("Te?m", false, "Te?m");
-    assertWildcardQueryEquals("TE?M", false, "TE?M");
-    assertWildcardQueryEquals("Te?m*gerM", false, "Te?m*gerM");
-    // Fuzzy queries:
-    assertWildcardQueryEquals("Term~", "term~2.0");
-    assertWildcardQueryEquals("Term~", true, "term~2.0");
-    assertWildcardQueryEquals("Term~", false, "Term~2.0");
-    // Range queries:
-
-    // TODO: implement this on QueryParser
-    // Q0002E_INVALID_SYNTAX_CANNOT_PARSE: Syntax Error, cannot parse '[A TO
-    // C]': Lexical error at line 1, column 1. Encountered: "[" (91), after : ""
-    assertWildcardQueryEquals("[A TO C]", "[a TO c]");
-    assertWildcardQueryEquals("[A TO C]", true, "[a TO c]");
-    assertWildcardQueryEquals("[A TO C]", false, "[A TO C]");
-    // Test suffix queries: first disallow
-    try {
-      assertWildcardQueryEquals("*Term", true, "*term");
-      fail();
-    } catch (ParseException pe) {
-      // expected exception
-    }
-    try {
-      assertWildcardQueryEquals("?Term", true, "?term");
-      fail();
-    } catch (ParseException pe) {
-      // expected exception
-    }
-    // Test suffix queries: then allow
-    assertWildcardQueryEquals("*Term", true, "*term", true);
-    assertWildcardQueryEquals("?Term", true, "?term", true);
-  }
-
-  public void testLeadingWildcardType() throws Exception {
-    QueryParserWrapper qp = getParser(null);
-    qp.setAllowLeadingWildcard(true);
-    assertEquals(WildcardQuery.class, qp.parse("t*erm*").getClass());
-    assertEquals(WildcardQuery.class, qp.parse("?term*").getClass());
-    assertEquals(WildcardQuery.class, qp.parse("*term*").getClass());
-  }
-
-  public void testQPA() throws Exception {
-    assertQueryEquals("term term^3.0 term", qpAnalyzer, "term term^3.0 term");
-    assertQueryEquals("term stop^3.0 term", qpAnalyzer, "term term");
-
-    assertQueryEquals("term term term", qpAnalyzer, "term term term");
-    assertQueryEquals("term +stop term", qpAnalyzer, "term term");
-    assertQueryEquals("term -stop term", qpAnalyzer, "term term");
-
-    assertQueryEquals("drop AND (stop) AND roll", qpAnalyzer, "+drop +roll");
-    assertQueryEquals("term +(stop) term", qpAnalyzer, "term term");
-    assertQueryEquals("term -(stop) term", qpAnalyzer, "term term");
-
-    assertQueryEquals("drop AND stop AND roll", qpAnalyzer, "+drop +roll");
-    assertQueryEquals("term phrase term", qpAnalyzer,
-        "term phrase1 phrase2 term");
-
-    assertQueryEquals("term AND NOT phrase term", qpAnalyzer,
-        "+term -(phrase1 phrase2) term");
-
-    assertQueryEquals("stop^3", qpAnalyzer, "");
-    assertQueryEquals("stop", qpAnalyzer, "");
-    assertQueryEquals("(stop)^3", qpAnalyzer, "");
-    assertQueryEquals("((stop))^3", qpAnalyzer, "");
-    assertQueryEquals("(stop^3)", qpAnalyzer, "");
-    assertQueryEquals("((stop)^3)", qpAnalyzer, "");
-    assertQueryEquals("(stop)", qpAnalyzer, "");
-    assertQueryEquals("((stop))", qpAnalyzer, "");
-    assertTrue(getQuery("term term term", qpAnalyzer) instanceof BooleanQuery);
-    assertTrue(getQuery("term +stop", qpAnalyzer) instanceof TermQuery);
-  }
-
-  public void testRange() throws Exception {
-    assertQueryEquals("[ a TO z]", null, "[a TO z]");
-    assertEquals(MultiTermQuery.CONSTANT_SCORE_AUTO_REWRITE_DEFAULT, ((TermRangeQuery)getQuery("[ a TO z]", null)).getRewriteMethod());
-
-    QueryParserWrapper qp = new QueryParserWrapper("field",
-        new MockAnalyzer(MockTokenizer.SIMPLE, true));
-    
-    qp.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);
-    assertEquals(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE,((TermRangeQuery)qp.parse("[ a TO z]")).getRewriteMethod());
-
-    assertQueryEquals("[ a TO z ]", null, "[a TO z]");
-    assertQueryEquals("{ a TO z}", null, "{a TO z}");
-    assertQueryEquals("{ a TO z }", null, "{a TO z}");
-    assertQueryEquals("{ a TO z }^2.0", null, "{a TO z}^2.0");
-    assertQueryEquals("[ a TO z] OR bar", null, "[a TO z] bar");
-    assertQueryEquals("[ a TO z] AND bar", null, "+[a TO z] +bar");
-    assertQueryEquals("( bar blar { a TO z}) ", null, "bar blar {a TO z}");
-    assertQueryEquals("gack ( bar blar { a TO z}) ", null,
-        "gack (bar blar {a TO z})");
-  }
-
-  public void testFarsiRangeCollating() throws Exception {
-
-    Directory ramDir = newDirectory();
-    IndexWriter iw = new IndexWriter(ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), true,
-        IndexWriter.MaxFieldLength.LIMITED);
-    Document doc = new Document();
-    doc.add(newField("content", "\u0633\u0627\u0628", Field.Store.YES,
-        Field.Index.NOT_ANALYZED));
-    iw.addDocument(doc);
-    iw.close();
-    IndexSearcher is = new IndexSearcher(ramDir, true);
-
-    QueryParserWrapper qp = new QueryParserWrapper("content",
-        new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-
-    // Neither Java 1.4.2 nor 1.5.0 has Farsi Locale collation available in
-    // RuleBasedCollator. However, the Arabic Locale seems to order the Farsi
-    // characters properly.
-    Collator c = Collator.getInstance(new Locale("ar"));
-    qp.setRangeCollator(c);
-
-    // Unicode order would include U+0633 in [ U+062F - U+0698 ], but Farsi
-    // orders the U+0698 character before the U+0633 character, so the single
-    // index Term below should NOT be returned by a ConstantScoreRangeQuery
-    // with a Farsi Collator (or an Arabic one for the case when Farsi is not
-    // supported).
-
-    // Test ConstantScoreRangeQuery
-    qp.setMultiTermRewriteMethod(MultiTermQuery.CONSTANT_SCORE_FILTER_REWRITE);
-    ScoreDoc[] result = is.search(qp.parse("[ \u062F TO \u0698 ]"), null, 1000).scoreDocs;
-    assertEquals("The index Term should not be included.", 0, result.length);
-
-    result = is.search(qp.parse("[ \u0633 TO \u0638 ]"), null, 1000).scoreDocs;
-    assertEquals("The index Term should be included.", 1, result.length);
-
-    // Test RangeQuery
-    qp.setMultiTermRewriteMethod(MultiTermQuery.SCORING_BOOLEAN_QUERY_REWRITE);
-    result = is.search(qp.parse("[ \u062F TO \u0698 ]"), null, 1000).scoreDocs;
-    assertEquals("The index Term should not be included.", 0, result.length);
-
-    result = is.search(qp.parse("[ \u0633 TO \u0638 ]"), null, 1000).scoreDocs;
-    assertEquals("The index Term should be included.", 1, result.length);
-
-    is.close();
-    ramDir.close();
-  }
-  
-  private String escapeDateString(String s) {
-    if (s.contains(" ")) {
-      return "\"" + s + "\"";
-    } else {
-      return s;
-    }
-  }
-
-  /** for testing legacy DateField support */
-  private String getLegacyDate(String s) throws Exception {
-    DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
-    return DateField.dateToString(df.parse(s));
-  }
-
-  /** for testing DateTools support */
-  private String getDate(String s, DateTools.Resolution resolution)
-      throws Exception {
-    DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
-    return getDate(df.parse(s), resolution);
-  }
-
-  /** for testing DateTools support */
-  private String getDate(Date d, DateTools.Resolution resolution)
-      throws Exception {
-    if (resolution == null) {
-      return DateField.dateToString(d);
-    } else {
-      return DateTools.dateToString(d, resolution);
-    }
-  }
-
-  private String getLocalizedDate(int year, int month, int day) {
-    DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
-    Calendar calendar = new GregorianCalendar();
-    calendar.clear();
-    calendar.set(year, month, day);
-    calendar.set(Calendar.HOUR_OF_DAY, 23);
-    calendar.set(Calendar.MINUTE, 59);
-    calendar.set(Calendar.SECOND, 59);
-    calendar.set(Calendar.MILLISECOND, 999);
-    return df.format(calendar.getTime());
-  }
-
-  /** for testing legacy DateField support */
-  public void testLegacyDateRange() throws Exception {
-    String startDate = getLocalizedDate(2002, 1, 1);
-    String endDate = getLocalizedDate(2002, 1, 4);
-    Calendar endDateExpected = new GregorianCalendar();
-    endDateExpected.clear();
-    endDateExpected.set(2002, 1, 4, 23, 59, 59);
-    endDateExpected.set(Calendar.MILLISECOND, 999);
-    assertQueryEquals("[ " + escapeDateString(startDate) + " TO " + escapeDateString(endDate) + "]", null, "["
-        + getLegacyDate(startDate) + " TO "
-        + DateField.dateToString(endDateExpected.getTime()) + "]");
-    assertQueryEquals("{  " + escapeDateString(startDate) + "    " + escapeDateString(endDate) + "   }", null, "{"
-        + getLegacyDate(startDate) + " TO " + getLegacyDate(endDate) + "}");
-  }
-
-  public void testDateRange() throws Exception {
-    String startDate = getLocalizedDate(2002, 1, 1);
-    String endDate = getLocalizedDate(2002, 1, 4);
-    Calendar endDateExpected = new GregorianCalendar();
-    endDateExpected.clear();
-    endDateExpected.set(2002, 1, 4, 23, 59, 59);
-    endDateExpected.set(Calendar.MILLISECOND, 999);
-    final String defaultField = "default";
-    final String monthField = "month";
-    final String hourField = "hour";
-    QueryParserWrapper qp = new QueryParserWrapper("field",
-        new MockAnalyzer(MockTokenizer.SIMPLE, true));
-
-    // Don't set any date resolution and verify if DateField is used
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
-    // set a field specific date resolution
-    qp.setDateResolution(monthField, DateTools.Resolution.MONTH);
-
-    // DateField should still be used for defaultField
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), null);
-
-    // set default date resolution to MILLISECOND
-    qp.setDateResolution(DateTools.Resolution.MILLISECOND);
-
-    // set second field specific date resolution
-    qp.setDateResolution(hourField, DateTools.Resolution.HOUR);
-
-    // for this field no field specific date resolution has been set,
-    // so verify if the default resolution is used
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate,
-        endDateExpected.getTime(), DateTools.Resolution.MILLISECOND);
-
-    // verify if field specific date resolutions are used for these two fields
-    assertDateRangeQueryEquals(qp, monthField, startDate, endDate,
-        endDateExpected.getTime(), DateTools.Resolution.MONTH);
-
-    assertDateRangeQueryEquals(qp, hourField, startDate, endDate,
-        endDateExpected.getTime(), DateTools.Resolution.HOUR);
-  }
-
-  public void assertDateRangeQueryEquals(QueryParserWrapper qp, String field,
-      String startDate, String endDate, Date endDateInclusive,
-      DateTools.Resolution resolution) throws Exception {
-    assertQueryEquals(qp, field, field + ":[" + escapeDateString(startDate) + " TO " + escapeDateString(endDate)
-        + "]", "[" + getDate(startDate, resolution) + " TO "
-        + getDate(endDateInclusive, resolution) + "]");
-    assertQueryEquals(qp, field, field + ":{" + escapeDateString(startDate) + " TO " + escapeDateString(endDate)
-        + "}", "{" + getDate(startDate, resolution) + " TO "
-        + getDate(endDate, resolution) + "}");
-  }
-
-  public void testEscaped() throws Exception {
-    Analyzer a = new MockAnalyzer(MockTokenizer.WHITESPACE, false);
-
-    /*
-     * assertQueryEquals("\\[brackets", a, "\\[brackets");
-     * assertQueryEquals("\\[brackets", null, "brackets");
-     * assertQueryEquals("\\\\", a, "\\\\"); assertQueryEquals("\\+blah", a,
-     * "\\+blah"); assertQueryEquals("\\(blah", a, "\\(blah");
-     * 
-     * assertQueryEquals("\\-blah", a, "\\-blah"); assertQueryEquals("\\!blah",
-     * a, "\\!blah"); assertQueryEquals("\\{blah", a, "\\{blah");
-     * assertQueryEquals("\\}blah", a, "\\}blah"); assertQueryEquals("\\:blah",
-     * a, "\\:blah"); assertQueryEquals("\\^blah", a, "\\^blah");
-     * assertQueryEquals("\\[blah", a, "\\[blah"); assertQueryEquals("\\]blah",
-     * a, "\\]blah"); assertQueryEquals("\\\"blah", a, "\\\"blah");
-     * assertQueryEquals("\\(blah", a, "\\(blah"); assertQueryEquals("\\)blah",
-     * a, "\\)blah"); assertQueryEquals("\\~blah", a, "\\~blah");
-     * assertQueryEquals("\\*blah", a, "\\*blah"); assertQueryEquals("\\?blah",
-     * a, "\\?blah"); //assertQueryEquals("foo \\&\\& bar", a,
-     * "foo \\&\\& bar"); //assertQueryEquals("foo \\|| bar", a,
-     * "foo \\|| bar"); //assertQueryEquals("foo \\AND bar", a,
-     * "foo \\AND bar");
-     */
-
-    assertQueryEquals("\\a", a, "a");
-
-    assertQueryEquals("a\\-b:c", a, "a-b:c");
-    assertQueryEquals("a\\+b:c", a, "a+b:c");
-    assertQueryEquals("a\\:b:c", a, "a:b:c");
-    assertQueryEquals("a\\\\b:c", a, "a\\b:c");
-
-    assertQueryEquals("a:b\\-c", a, "a:b-c");
-    assertQueryEquals("a:b\\+c", a, "a:b+c");
-    assertQueryEquals("a:b\\:c", a, "a:b:c");
-    assertQueryEquals("a:b\\\\c", a, "a:b\\c");
-
-    assertQueryEquals("a:b\\-c*", a, "a:b-c*");
-    assertQueryEquals("a:b\\+c*", a, "a:b+c*");
-    assertQueryEquals("a:b\\:c*", a, "a:b:c*");
-
-    assertQueryEquals("a:b\\\\c*", a, "a:b\\c*");
-
-    assertQueryEquals("a:b\\-?c", a, "a:b-?c");
-    assertQueryEquals("a:b\\+?c", a, "a:b+?c");
-    assertQueryEquals("a:b\\:?c", a, "a:b:?c");
-
-    assertQueryEquals("a:b\\\\?c", a, "a:b\\?c");
-
-    assertQueryEquals("a:b\\-c~", a, "a:b-c~2.0");
-    assertQueryEquals("a:b\\+c~", a, "a:b+c~2.0");
-    assertQueryEquals("a:b\\:c~", a, "a:b:c~2.0");
-    assertQueryEquals("a:b\\\\c~", a, "a:b\\c~2.0");
-
-    // TODO: implement Range queries on QueryParser
-    assertQueryEquals("[ a\\- TO a\\+ ]", null, "[a- TO a+]");
-    assertQueryEquals("[ a\\: TO a\\~ ]", null, "[a: TO a~]");
-    assertQueryEquals("[ a\\\\ TO a\\* ]", null, "[a\\ TO a*]");
-
-    assertQueryEquals(
-        "[\"c\\:\\\\temp\\\\\\~foo0.txt\" TO \"c\\:\\\\temp\\\\\\~foo9.txt\"]",
-        a, "[c:\\temp\\~foo0.txt TO c:\\temp\\~foo9.txt]");
-
-    assertQueryEquals("a\\\\\\+b", a, "a\\+b");
-
-    assertQueryEquals("a \\\"b c\\\" d", a, "a \"b c\" d");
-    assertQueryEquals("\"a \\\"b c\\\" d\"", a, "\"a \"b c\" d\"");
-    assertQueryEquals("\"a \\+b c d\"", a, "\"a +b c d\"");
-
-    assertQueryEquals("c\\:\\\\temp\\\\\\~foo.txt", a, "c:\\temp\\~foo.txt");
-
-    assertParseException("XY\\"); // there must be a character after the escape
-                                  // char
-
-    // test unicode escaping
-    assertQueryEquals("a\\u0062c", a, "abc");
-    assertQueryEquals("XY\\u005a", a, "XYZ");
-    assertQueryEquals("XY\\u005A", a, "XYZ");
-    assertQueryEquals("\"a \\\\\\u0028\\u0062\\\" c\"", a, "\"a \\(b\" c\"");
-
-    assertParseException("XY\\u005G"); // test non-hex character in escaped
-                                       // unicode sequence
-    assertParseException("XY\\u005"); // test incomplete escaped unicode
-                                      // sequence
-
-    // Tests bug LUCENE-800
-    assertQueryEquals("(item:\\\\ item:ABCD\\\\)", a, "item:\\ item:ABCD\\");
-    assertParseException("(item:\\\\ item:ABCD\\\\))"); // unmatched closing
-                                                        // paranthesis
-    assertQueryEquals("\\*", a, "*");
-    assertQueryEquals("\\\\", a, "\\"); // escaped backslash
-
-    assertParseException("\\"); // a backslash must always be escaped
-
-    // LUCENE-1189
-    assertQueryEquals("(\"a\\\\\") or (\"b\")", a, "a\\ or b");
-  }
-
-  public void testQueryStringEscaping() throws Exception {
-    Analyzer a = new MockAnalyzer(MockTokenizer.WHITESPACE, false);
-
-    assertEscapedQueryEquals("a-b:c", a, "a\\-b\\:c");
-    assertEscapedQueryEquals("a+b:c", a, "a\\+b\\:c");
-    assertEscapedQueryEquals("a:b:c", a, "a\\:b\\:c");
-    assertEscapedQueryEquals("a\\b:c", a, "a\\\\b\\:c");
-
-    assertEscapedQueryEquals("a:b-c", a, "a\\:b\\-c");
-    assertEscapedQueryEquals("a:b+c", a, "a\\:b\\+c");
-    assertEscapedQueryEquals("a:b:c", a, "a\\:b\\:c");
-    assertEscapedQueryEquals("a:b\\c", a, "a\\:b\\\\c");
-
-    assertEscapedQueryEquals("a:b-c*", a, "a\\:b\\-c\\*");
-    assertEscapedQueryEquals("a:b+c*", a, "a\\:b\\+c\\*");
-    assertEscapedQueryEquals("a:b:c*", a, "a\\:b\\:c\\*");
-
-    assertEscapedQueryEquals("a:b\\\\c*", a, "a\\:b\\\\\\\\c\\*");
-
-    assertEscapedQueryEquals("a:b-?c", a, "a\\:b\\-\\?c");
-    assertEscapedQueryEquals("a:b+?c", a, "a\\:b\\+\\?c");
-    assertEscapedQueryEquals("a:b:?c", a, "a\\:b\\:\\?c");
-
-    assertEscapedQueryEquals("a:b?c", a, "a\\:b\\?c");
-
-    assertEscapedQueryEquals("a:b-c~", a, "a\\:b\\-c\\~");
-    assertEscapedQueryEquals("a:b+c~", a, "a\\:b\\+c\\~");
-    assertEscapedQueryEquals("a:b:c~", a, "a\\:b\\:c\\~");
-    assertEscapedQueryEquals("a:b\\c~", a, "a\\:b\\\\c\\~");
-
-    assertEscapedQueryEquals("[ a - TO a+ ]", null, "\\[ a \\- TO a\\+ \\]");
-    assertEscapedQueryEquals("[ a : TO a~ ]", null, "\\[ a \\: TO a\\~ \\]");
-    assertEscapedQueryEquals("[ a\\ TO a* ]", null, "\\[ a\\\\ TO a\\* \\]");
-
-    // LUCENE-881
-    assertEscapedQueryEquals("|| abc ||", a, "\\|\\| abc \\|\\|");
-    assertEscapedQueryEquals("&& abc &&", a, "\\&\\& abc \\&\\&");
-  }
-
-  public void testTabNewlineCarriageReturn() throws Exception {
-    assertQueryEqualsDOA("+weltbank +worlbank", null, "+weltbank +worlbank");
-
-    assertQueryEqualsDOA("+weltbank\n+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \n+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \n +worlbank", null, "+weltbank +worlbank");
-
-    assertQueryEqualsDOA("+weltbank\r+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \r+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \r +worlbank", null, "+weltbank +worlbank");
-
-    assertQueryEqualsDOA("+weltbank\r\n+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \r\n+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \r\n +worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \r \n +worlbank", null,
-        "+weltbank +worlbank");
-
-    assertQueryEqualsDOA("+weltbank\t+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \t+worlbank", null, "+weltbank +worlbank");
-    assertQueryEqualsDOA("weltbank \t +worlbank", null, "+weltbank +worlbank");
-  }
-
-  public void testSimpleDAO() throws Exception {
-    assertQueryEqualsDOA("term term term", null, "+term +term +term");
-    assertQueryEqualsDOA("term +term term", null, "+term +term +term");
-    assertQueryEqualsDOA("term term +term", null, "+term +term +term");
-    assertQueryEqualsDOA("term +term +term", null, "+term +term +term");
-    assertQueryEqualsDOA("-term term term", null, "-term +term +term");
-  }
-
-  public void testBoost() throws Exception {
-    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(BasicAutomata.makeString("on"));
-    Analyzer oneStopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, stopSet, true);
-    QueryParserWrapper qp = new QueryParserWrapper("field", oneStopAnalyzer);
-    Query q = qp.parse("on^1.0");
-    assertNotNull(q);
-    q = qp.parse("\"hello\"^2.0");
-    assertNotNull(q);
-    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);
-    q = qp.parse("hello^2.0");
-    assertNotNull(q);
-    assertEquals(q.getBoost(), (float) 2.0, (float) 0.5);
-    q = qp.parse("\"on\"^1.0");
-    assertNotNull(q);
-
-    QueryParserWrapper qp2 = new QueryParserWrapper("field",
-        new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));
-    q = qp2.parse("the^3");
-    // "the" is a stop word so the result is an empty query:
-    assertNotNull(q);
-    assertEquals("", q.toString());
-    assertEquals(1.0f, q.getBoost(), 0.01f);
-  }
-
-  public void assertParseException(String queryString) throws Exception {
-    try {
-      getQuery(queryString, null);
-    } catch (ParseException expected) {
-      return;
-    }
-    fail("ParseException expected, not thrown");
-  }
-
-  public void testException() throws Exception {
-    assertParseException("\"some phrase");
-    assertParseException("(foo bar");
-    assertParseException("foo bar))");
-    assertParseException("field:term:with:colon some more terms");
-    assertParseException("(sub query)^5.0^2.0 plus more");
-    assertParseException("secret AND illegal) AND access:confidential");
-  }
-
-  public void testCustomQueryParserWildcard() {
-    try {
-      new QPTestParser("contents", new MockAnalyzer(MockTokenizer.WHITESPACE, false)).parse("a?t");
-      fail("Wildcard queries should not be allowed");
-    } catch (ParseException expected) {
-      // expected exception
-    }
-  }
-
-  public void testCustomQueryParserFuzzy() throws Exception {
-    try {
-      new QPTestParser("contents", new MockAnalyzer(MockTokenizer.WHITESPACE, false)).parse("xunit~");
-      fail("Fuzzy queries should not be allowed");
-    } catch (ParseException expected) {
-      // expected exception
-    }
-  }
-
-  public void testBooleanQuery() throws Exception {
-    BooleanQuery.setMaxClauseCount(2);
-    try {
-      QueryParserWrapper qp = new QueryParserWrapper("field",
-          new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-      qp.parse("one two three");
-      fail("ParseException expected due to too many boolean clauses");
-    } catch (ParseException expected) {
-      // too many boolean clauses, so ParseException is expected
-    }
-  }
-
-  /**
-   * This test differs from TestPrecedenceQueryParser
-   */
-  public void testPrecedence() throws Exception {
-    QueryParserWrapper qp = new QueryParserWrapper("field",
-        new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-    Query query1 = qp.parse("A AND B OR C AND D");
-    Query query2 = qp.parse("+A +B +C +D");
-
-    assertEquals(query1, query2);
-  }
-
-  public void testLocalDateFormat() throws IOException, ParseException {
-
-    Directory ramDir = newDirectory();
-    IndexWriter iw = new IndexWriter(ramDir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), true,
-        IndexWriter.MaxFieldLength.LIMITED);
-    addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
-    addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
-    iw.close();
-    IndexSearcher is = new IndexSearcher(ramDir, true);
-    assertHits(1, "[12/1/2005 TO 12/3/2005]", is);
-    assertHits(2, "[12/1/2005 TO 12/4/2005]", is);
-    assertHits(1, "[12/3/2005 TO 12/4/2005]", is);
-    assertHits(1, "{12/1/2005 TO 12/3/2005}", is);
-    assertHits(1, "{12/1/2005 TO 12/4/2005}", is);
-    assertHits(0, "{12/3/2005 TO 12/4/2005}", is);
-    is.close();
-    ramDir.close();
-  }
-
-  public void testStarParsing() throws Exception {
-    // final int[] type = new int[1];
-    // QueryParser qp = new QueryParserWrapper("field", new
-    // WhitespaceAnalyzer()) {
-    // protected Query getWildcardQuery(String field, String termStr) throws
-    // ParseException {
-    // // override error checking of superclass
-    // type[0]=1;
-    // return new TermQuery(new Term(field,termStr));
-    // }
-    // protected Query getPrefixQuery(String field, String termStr) throws
-    // ParseException {
-    // // override error checking of superclass
-    // type[0]=2;
-    // return new TermQuery(new Term(field,termStr));
-    // }
-    //
-    // protected Query getFieldQuery(String field, String queryText) throws
-    // ParseException {
-    // type[0]=3;
-    // return super.getFieldQuery(field, queryText);
-    // }
-    // };
-    //
-    // TermQuery tq;
-    //
-    // tq = (TermQuery)qp.parse("foo:zoo*");
-    // assertEquals("zoo",tq.getTerm().text());
-    // assertEquals(2,type[0]);
-    //
-    // tq = (TermQuery)qp.parse("foo:zoo*^2");
-    // assertEquals("zoo",tq.getTerm().text());
-    // assertEquals(2,type[0]);
-    // assertEquals(tq.getBoost(),2,0);
-    //
-    // tq = (TermQuery)qp.parse("foo:*");
-    // assertEquals("*",tq.getTerm().text());
-    // assertEquals(1,type[0]); // could be a valid prefix query in the future
-    // too
-    //
-    // tq = (TermQuery)qp.parse("foo:*^2");
-    // assertEquals("*",tq.getTerm().text());
-    // assertEquals(1,type[0]);
-    // assertEquals(tq.getBoost(),2,0);
-    //
-    // tq = (TermQuery)qp.parse("*:foo");
-    // assertEquals("*",tq.getTerm().field());
-    // assertEquals("foo",tq.getTerm().text());
-    // assertEquals(3,type[0]);
-    //
-    // tq = (TermQuery)qp.parse("*:*");
-    // assertEquals("*",tq.getTerm().field());
-    // assertEquals("*",tq.getTerm().text());
-    // assertEquals(1,type[0]); // could be handled as a prefix query in the
-    // future
-    //
-    // tq = (TermQuery)qp.parse("(*:*)");
-    // assertEquals("*",tq.getTerm().field());
-    // assertEquals("*",tq.getTerm().text());
-    // assertEquals(1,type[0]);
-
-  }
-
-  public void testStopwords() throws Exception {
-    CharacterRunAutomaton stopSet = new CharacterRunAutomaton(new RegExp("the|foo").toAutomaton());
-    QueryParserWrapper qp = new QueryParserWrapper("a", new MockAnalyzer(MockTokenizer.SIMPLE, true, stopSet, true));
-    Query result = qp.parse("a:the OR a:foo");
-    assertNotNull("result is null and it shouldn't be", result);
-    assertTrue("result is not a BooleanQuery", result instanceof BooleanQuery);
-    assertTrue(((BooleanQuery) result).clauses().size() + " does not equal: "
-        + 0, ((BooleanQuery) result).clauses().size() == 0);
-    result = qp.parse("a:woo OR a:the");
-    assertNotNull("result is null and it shouldn't be", result);
-    assertTrue("result is not a TermQuery", result instanceof TermQuery);
-    result = qp
-        .parse("(fieldX:xxxxx OR fieldy:xxxxxxxx)^2 AND (fieldx:the OR fieldy:foo)");
-    assertNotNull("result is null and it shouldn't be", result);
-    assertTrue("result is not a BooleanQuery", result instanceof BooleanQuery);
-    if (VERBOSE) System.out.println("Result: " + result);
-    assertTrue(((BooleanQuery) result).clauses().size() + " does not equal: "
-        + 2, ((BooleanQuery) result).clauses().size() == 2);
-  }
-
-  public void testPositionIncrement() throws Exception {
-    QueryParserWrapper qp = new QueryParserWrapper("a", new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, true));
-    qp.setEnablePositionIncrements(true);
-    String qtxt = "\"the words in poisitions pos02578 are stopped in this phrasequery\"";
-    // 0 2 5 7 8
-    int expectedPositions[] = { 1, 3, 4, 6, 9 };
-    PhraseQuery pq = (PhraseQuery) qp.parse(qtxt);
-    // System.out.println("Query text: "+qtxt);
-    // System.out.println("Result: "+pq);
-    Term t[] = pq.getTerms();
-    int pos[] = pq.getPositions();
-    for (int i = 0; i < t.length; i++) {
-      // System.out.println(i+". "+t[i]+"  pos: "+pos[i]);
-      assertEquals("term " + i + " = " + t[i] + " has wrong term-position!",
-          expectedPositions[i], pos[i]);
-    }
-  }
-
-  public void testMatchAllDocs() throws Exception {
-    QueryParserWrapper qp = new QueryParserWrapper("field",
-        new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-    assertEquals(new MatchAllDocsQuery(), qp.parse("*:*"));
-    assertEquals(new MatchAllDocsQuery(), qp.parse("(*:*)"));
-    BooleanQuery bq = (BooleanQuery) qp.parse("+*:* -*:*");
-    assertTrue(bq.getClauses()[0].getQuery() instanceof MatchAllDocsQuery);
-    assertTrue(bq.getClauses()[1].getQuery() instanceof MatchAllDocsQuery);
-  }
-
-  private void assertHits(int expected, String query, IndexSearcher is)
-      throws ParseException, IOException {
-    QueryParserWrapper qp = new QueryParserWrapper("date",
-        new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-    qp.setLocale(Locale.ENGLISH);
-    Query q = qp.parse(query);
-    ScoreDoc[] hits = is.search(q, null, 1000).scoreDocs;
-    assertEquals(expected, hits.length);
-  }
-
-  private void addDateDoc(String content, int year, int month, int day,
-      int hour, int minute, int second, IndexWriter iw) throws IOException {
-    Document d = new Document();
-    d.add(newField("f", content, Field.Store.YES, Field.Index.ANALYZED));
-    Calendar cal = Calendar.getInstance(Locale.ENGLISH);
-    cal.set(year, month - 1, day, hour, minute, second);
-    d.add(newField("date", DateField.dateToString(cal.getTime()),
-        Field.Store.YES, Field.Index.NOT_ANALYZED));
-    iw.addDocument(d);
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    BooleanQuery.setMaxClauseCount(originalMaxClauses);
-    super.tearDown();
-  }
-
-}
diff --git a/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java b/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java
index 101220a..dc1c815 100644
--- a/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java
+++ b/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSearchable.java
@@ -76,7 +76,7 @@ public class TestRemoteSearchable extends RemoteTestCase {
     document = searcher.doc(0, fs);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 1, document.getFields().size() == 1);
-    fs = new MapFieldSelector(new String[]{"other"});
+    fs = new MapFieldSelector("other");
     document = searcher.doc(0, fs);
     assertTrue("document is null and it shouldn't be", document != null);
     assertTrue("document.getFields() Size: " + document.getFields().size() + " is not: " + 1, document.getFields().size() == 1);
diff --git a/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java b/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java
index 7da14d8..88bf2bc 100644
--- a/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java
+++ b/lucene/contrib/remote/src/test/org/apache/lucene/search/TestRemoteSort.java
@@ -84,10 +84,12 @@ public class TestRemoteSort extends RemoteTestCase {
   @BeforeClass
   public static void beforeClass() throws Exception {
     indexStore = newDirectory();
-    IndexWriter writer = new IndexWriter(indexStore, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);
+    IndexWriter writer = new IndexWriter(
+        indexStore,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(1000))
+    );
     for (int i=0; i<data.length; ++i) {
         Document doc = new Document();
         doc.add (new Field ("tracer",   data[i][0], Field.Store.YES, Field.Index.NO));
@@ -217,7 +219,7 @@ public class TestRemoteSort extends RemoteTestCase {
   @Test
   public void testRemoteSort() throws Exception {
     Searchable searcher = lookupRemote();
-    MultiSearcher multi = new MultiSearcher (new Searchable[] { searcher });
+    MultiSearcher multi = new MultiSearcher (searcher);
     runMultiSorts(multi, true); // this runs on the full index
   }
 
@@ -255,7 +257,7 @@ public class TestRemoteSort extends RemoteTestCase {
     HashMap<String,Float> scoresA = getScores (full.search (queryA, null, 1000).scoreDocs, full);
 
     // we'll test searching locally, remote and multi
-    MultiSearcher remote = new MultiSearcher (new Searchable[] { lookupRemote() });
+    MultiSearcher remote = new MultiSearcher (lookupRemote());
 
     // change sorting and make sure relevancy stays the same
 
diff --git a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/DistanceApproximation.java b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/DistanceApproximation.java
deleted file mode 100644
index acf6ab0..0000000
--- a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/geometry/shape/DistanceApproximation.java
+++ /dev/null
@@ -1,126 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.spatial.geometry.shape;
-
-/**
- * Imported from mq java client.  No changes made.
- *
- * <p><font color="red"><b>NOTE:</b> This API is still in
- * flux and might change in incompatible ways in the next
- * release.</font>
- *
- * @deprecated This has been replaced with more accurate
- * math in {@link LLRect}. This class will be removed in a future release.
- */
-@Deprecated
-public class DistanceApproximation
-{
-  private double m_testLat;
-  private double m_testLng;
-  private double m_mpd;
-  private static final double m_milesPerLngDeg[]={
-     69.170976f, 69.160441f, 69.128838f, 69.076177f, 69.002475f,
-     68.907753f, 68.792041f, 68.655373f, 68.497792f, 68.319345f,
-     68.120088f, 67.900079f, 67.659387f, 67.398085f, 67.116253f,
-     66.813976f, 66.491346f, 66.148462f, 65.785428f, 65.402355f,
-     64.999359f, 64.576564f, 64.134098f, 63.672096f, 63.190698f,
-     62.690052f, 62.170310f, 61.631630f, 61.074176f, 60.498118f,
-     59.903632f, 59.290899f, 58.660106f, 58.011443f, 57.345111f,
-     56.661310f, 55.960250f, 55.242144f, 54.507211f, 53.755675f,
-     52.987764f, 52.203713f, 51.403761f, 50.588151f, 49.757131f,
-     48.910956f, 48.049882f, 47.174172f, 46.284093f, 45.379915f,
-     44.461915f, 43.530372f, 42.585570f, 41.627796f, 40.657342f,
-     39.674504f, 38.679582f, 37.672877f, 36.654698f, 35.625354f,
-     34.585159f, 33.534429f, 32.473485f, 31.402650f, 30.322249f,
-     29.232613f, 28.134073f, 27.026963f, 25.911621f, 24.788387f,
-     23.657602f, 22.519612f, 21.374762f, 20.223401f, 19.065881f,
-     17.902554f, 16.733774f, 15.559897f, 14.381280f, 13.198283f,
-     12.011266f, 10.820591f,  9.626619f,  8.429716f,  7.230245f,
-      6.028572f,  4.825062f,  3.620083f,  2.414002f,  1.207185f,
-      1.000000f};
-
-  public static final double MILES_PER_LATITUDE   = 69.170976f;
-  public static final double KILOMETERS_PER_MILE  = 1.609347f;
-
-
-  public DistanceApproximation()
-  {
-  }
-
-  public void setTestPoint(double lat, double lng)
-  {
-    m_testLat = lat;
-    m_testLng = lng;
-    m_mpd     = m_milesPerLngDeg[(int)(Math.abs(lat) + 0.5f)];
-  }
-
-  // Approximate arc distance between 2 lat,lng positions using miles per
-  //    latitude and longitude degree
-  public double getDistanceSq(double lat, double lng)
-  {
-    double latMiles = (lat - m_testLat) * MILES_PER_LATITUDE;
-
-    // Approximate longitude miles using the miles per degree assuming the
-    //    middle latitude/longitude.  This is less accurate at high (near
-    //    polar) latitudes but no road network is present at the poles!
-    //    If we ever have any roads crossing the international date we will
-    //    have to worry about that case.
-    double lngMiles = (lng - m_testLng) * m_mpd;
-
-     // Find the squared distance by the Pythagorean theorem (without sqrt)
-    return (latMiles * latMiles + lngMiles * lngMiles);
-  }
-
-  // Approximate arc distance between a segment (with lat,lng endpoints) and
-  //    the test position
-  public double getDistanceSq(double lat1, double lng1, double lat2, double lng2)
-  {
-     // Check if lat1,lng1 is closest point.  Construct a vector from point1
-     //    to point2 (v1) and another from point 1 to the test point (v2).
-     //    If dot product is negative then point 1 is the closest point
-     double v1y = lat2 - lat1;
-     double v1x = lng2 - lng1;
-     double v2y = m_testLat - lat1;
-     double v2x = m_testLng - lng1;
-     double dot = v1x * v2x + v1y * v2y;
-     if (dot <= 0.0f)
-        return getDistanceSq(lat1, lng1);
-
-     // Get the component of vector v2 along v1.  If component is greater
-     //    than 1 then the endpoint is the closest point.
-     double c = dot / (v1x * v1x + v1y * v1y);
-     if (c >= 1.0f)
-        return getDistanceSq(lat2, lng2);
-
-     // Since we are working io lat,lng space we need to find the point
-     //    along p1->p2 such that q->pt is perpendicular to p1->p2.  We
-     //    then find the distance squared between Q and pt.
-     return getDistanceSq((lat1 + v1y * c), (lng1 + v1x * c));
-  }
-
-  // Return the number of miles per degree of longitude
-  public static double getMilesPerLngDeg(double lat)
-  {
-     return (Math.abs(lat) <= 90.0) ? m_milesPerLngDeg[(int)(Math.abs(lat) + 0.5f)] : 69.170976f;
-  }
-  
-  public static double getMilesPerLatDeg() {
-    return MILES_PER_LATITUDE;
-  }
-}
-
diff --git a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
index ea7694b..8cc151d 100644
--- a/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
+++ b/lucene/contrib/spatial/src/java/org/apache/lucene/spatial/tier/projections/SinusoidalProjector.java
@@ -28,7 +28,7 @@ package org.apache.lucene.spatial.tier.projections;
  * flux and might change in incompatible ways in the next
  * release.</font>
  *
- * @deprecated Until we can put in place proper tests and a proper fix. 
+ * @deprecated (3.1) Until we can put in place proper tests and a proper fix. 
  */
 @Deprecated
 public class SinusoidalProjector implements IProjector {
diff --git a/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java b/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java
index a463aeb..9b656c2 100644
--- a/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java
+++ b/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/TestParser.java
@@ -58,7 +58,7 @@ public class TestParser extends LuceneTestCase {
 		
 			BufferedReader d = new BufferedReader(new InputStreamReader(TestParser.class.getResourceAsStream("reuters21578.txt"))); 
 			dir=newDirectory();
-			IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_24, analyzer));
+			IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(Version.LUCENE_40, analyzer));
 			String line = d.readLine();		
 			while(line!=null)
 			{
diff --git a/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java b/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java
index b74eb65..dca574d 100644
--- a/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java
+++ b/lucene/contrib/xml-query-parser/src/test/org/apache/lucene/xmlparser/builders/TestNumericRangeFilterBuilder.java
@@ -29,7 +29,6 @@ import org.apache.lucene.util.LuceneTestCase;
 
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriter.MaxFieldLength;
 import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.NumericRangeFilter;
 import org.apache.lucene.store.Directory;
diff --git a/lucene/src/java/org/apache/lucene/analysis/CharTokenizer.java b/lucene/src/java/org/apache/lucene/analysis/CharTokenizer.java
index e1ade4e..3055d19 100644
--- a/lucene/src/java/org/apache/lucene/analysis/CharTokenizer.java
+++ b/lucene/src/java/org/apache/lucene/analysis/CharTokenizer.java
@@ -25,7 +25,6 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.CharacterUtils;
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util.VirtualMethod;
 import org.apache.lucene.util.CharacterUtils.CharacterBuffer;
 
 /**
@@ -78,8 +77,6 @@ public abstract class CharTokenizer extends Tokenizer {
   public CharTokenizer(Version matchVersion, Reader input) {
     super(input);
     charUtils = CharacterUtils.getInstance(matchVersion);
-    useOldAPI = useOldAPI(matchVersion);
-
   }
   
   /**
@@ -96,7 +93,6 @@ public abstract class CharTokenizer extends Tokenizer {
       Reader input) {
     super(source, input);
     charUtils = CharacterUtils.getInstance(matchVersion);
-    useOldAPI = useOldAPI(matchVersion);
   }
   
   /**
@@ -113,147 +109,30 @@ public abstract class CharTokenizer extends Tokenizer {
       Reader input) {
     super(factory, input);
     charUtils = CharacterUtils.getInstance(matchVersion);
-    useOldAPI = useOldAPI(matchVersion);
-  }
-  
-  /**
-   * Creates a new {@link CharTokenizer} instance
-   * @param input the input to split up into tokens
-   * @deprecated use {@link #CharTokenizer(Version, Reader)} instead. This will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated
-  public CharTokenizer(Reader input) {
-    this(Version.LUCENE_30, input);
-  }
-
-  /**
-   * Creates a new {@link CharTokenizer} instance
-   * @param input the input to split up into tokens
-   * @param source the attribute source to use for this {@link Tokenizer}
-   * @deprecated use {@link #CharTokenizer(Version, AttributeSource, Reader)} instead. This will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated
-  public CharTokenizer(AttributeSource source, Reader input) {
-    this(Version.LUCENE_30, source, input);
-  }
-
-  /**
-   * Creates a new {@link CharTokenizer} instance
-   * @param input the input to split up into tokens
-   * @param factory the attribute factory to use for this {@link Tokenizer}
-   * @deprecated use {@link #CharTokenizer(Version, AttributeSource.AttributeFactory, Reader)} instead. This will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated
-  public CharTokenizer(AttributeFactory factory, Reader input) {
-    this(Version.LUCENE_30, factory, input);
   }
   
   private int offset = 0, bufferIndex = 0, dataLen = 0, finalOffset = 0;
   private static final int MAX_WORD_LEN = 255;
   private static final int IO_BUFFER_SIZE = 4096;
   
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);;
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
   private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
   
   private final CharacterUtils charUtils;
   private final CharacterBuffer ioBuffer = CharacterUtils.newCharacterBuffer(IO_BUFFER_SIZE);
   
   /**
-   * @deprecated this will be removed in lucene 4.0
-   */
-  @Deprecated
-  private final boolean useOldAPI;
-  
-  /**
-   * @deprecated this will be removed in lucene 4.0
-   */
-  @Deprecated
-  private static final VirtualMethod<CharTokenizer> isTokenCharMethod =
-    new VirtualMethod<CharTokenizer>(CharTokenizer.class, "isTokenChar", char.class);
-  
-  /**
-   * @deprecated this will be removed in lucene 4.0
-   */
-  @Deprecated
-  private static final VirtualMethod<CharTokenizer> normalizeMethod =
-    new VirtualMethod<CharTokenizer>(CharTokenizer.class, "normalize", char.class);
-
-  /**
-   * Returns true iff a UTF-16 code unit should be included in a token. This
-   * tokenizer generates as tokens adjacent sequences of characters which
-   * satisfy this predicate. Characters for which this is <code>false</code> are
-   * used to define token boundaries and are not included in tokens.
-   * <p>
-   * Note: This method cannot handle <a href=
-   * "http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Character.html#supplementary"
-   * >supplementary characters</a>. To support all Unicode characters, including
-   * supplementary characters, use the {@link #isTokenChar(int)} method.
-   * </p>
-   * 
-   * @deprecated use {@link #isTokenChar(int)} instead. This method will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated  
-  protected boolean isTokenChar(char c) {
-    return isTokenChar((int)c); 
-  }
-
-  /**
-   * Called on each token UTF-16 code unit to normalize it before it is added to the
-   * token. The default implementation does nothing. Subclasses may use this to,
-   * e.g., lowercase tokens.
-   * <p>
-   * Note: This method cannot handle <a href=
-   * "http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Character.html#supplementary"
-   * >supplementary characters</a>. To support all Unicode characters, including
-   * supplementary characters, use the {@link #normalize(int)} method.
-   * </p>
-   * 
-   * @deprecated use {@link #normalize(int)} instead. This method will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated 
-  protected char normalize(char c) {
-    return (char) normalize((int) c);
-  }
-
-  /**
    * Returns true iff a codepoint should be included in a token. This tokenizer
    * generates as tokens adjacent sequences of codepoints which satisfy this
    * predicate. Codepoints for which this is false are used to define token
    * boundaries and are not included in tokens.
-   * <p>
-   * As of Lucene 3.1 the char based API ({@link #isTokenChar(char)} and
-   * {@link #normalize(char)}) has been depreciated in favor of a Unicode 4.0
-   * compatible int based API to support codepoints instead of UTF-16 code
-   * units. Subclasses of {@link CharTokenizer} must not override the char based
-   * methods if a {@link Version} >= 3.1 is passed to the constructor.
-   * <p>
-   * <p>
-   * NOTE: This method will be marked <i>abstract</i> in Lucene 4.0.
-   * </p>
    */
-  protected boolean isTokenChar(int c) {
-    throw new UnsupportedOperationException("since LUCENE_31 subclasses of CharTokenizer must implement isTokenChar(int)");
-  }
+  protected abstract boolean isTokenChar(int c);
 
   /**
    * Called on each token character to normalize it before it is added to the
    * token. The default implementation does nothing. Subclasses may use this to,
    * e.g., lowercase tokens.
-   * <p>
-   * As of Lucene 3.1 the char based API ({@link #isTokenChar(char)} and
-   * {@link #normalize(char)}) has been depreciated in favor of a Unicode 4.0
-   * compatible int based API to support codepoints instead of UTF-16 code
-   * units. Subclasses of {@link CharTokenizer} must not override the char based
-   * methods if a {@link Version} >= 3.1 is passed to the constructor.
-   * <p>
-   * <p>
-   * NOTE: This method will be marked <i>abstract</i> in Lucene 4.0.
-   * </p>
    */
   protected int normalize(int c) {
     return c;
@@ -262,8 +141,6 @@ public abstract class CharTokenizer extends Tokenizer {
   @Override
   public final boolean incrementToken() throws IOException {
     clearAttributes();
-    if(useOldAPI) // TODO remove this in LUCENE 4.0
-      return incrementTokenOld();
     int length = 0;
     int start = -1; // this variable is always initialized
     char[] buffer = termAtt.buffer();
@@ -307,62 +184,6 @@ public abstract class CharTokenizer extends Tokenizer {
     
   }
   
-  /**
-   * The <= 3.0 version of incrementToken. This is a backwards compat implementation used
-   * if a version <= 3.0 is provided to the ctor. 
-   * @deprecated remove in 4.0
-   */
-  @Deprecated
-  private boolean incrementTokenOld() throws IOException {
-    int length = 0;
-    int start = -1; // this variable is always initialized
-    char[] buffer = termAtt.buffer();
-    final char[] oldIoBuffer = ioBuffer.getBuffer();
-    while (true) {
-
-      if (bufferIndex >= dataLen) {
-        offset += dataLen;
-        dataLen = input.read(oldIoBuffer);
-        if (dataLen == -1) {
-          dataLen = 0;                            // so next offset += dataLen won't decrement offset
-          if (length > 0) {
-            break;
-          } else {
-            finalOffset = correctOffset(offset);
-            return false;
-          }
-        }
-        bufferIndex = 0;
-      }
-
-      final char c = oldIoBuffer[bufferIndex++];
-
-      if (isTokenChar(c)) {               // if it's a token char
-
-        if (length == 0) {                // start of token
-          assert start == -1;
-          start = offset + bufferIndex - 1;
-        } else if (length == buffer.length) {
-          buffer = termAtt.resizeBuffer(1+length);
-        }
-
-        buffer[length++] = normalize(c); // buffer it, normalized
-
-        if (length == MAX_WORD_LEN)      // buffer overflow!
-          break;
-
-      } else if (length > 0)             // at non-Letter w/ chars
-        break;                           // return 'em
-    }
-
-    termAtt.setLength(length);
-    assert start != -1;
-    offsetAtt.setOffset(correctOffset(start), correctOffset(start+length));
-    return true;
-  }  
-  
-  
-  
   @Override
   public final void end() {
     // set final offset
@@ -378,17 +199,4 @@ public abstract class CharTokenizer extends Tokenizer {
     finalOffset = 0;
     ioBuffer.reset(); // make sure to reset the IO buffer!!
   }
-
-  /**
-   * @deprecated this will be removed in lucene 4.0
-   */
-  @Deprecated
-  private boolean useOldAPI(Version matchVersion) {
-    final Class<? extends CharTokenizer> clazz = this.getClass();
-    if (matchVersion.onOrAfter(Version.LUCENE_31)
-        && (isTokenCharMethod.isOverriddenAsOf(clazz) || normalizeMethod
-            .isOverriddenAsOf(clazz))) throw new IllegalArgumentException(
-        "For matchVersion >= LUCENE_31, CharTokenizer subclasses must not override isTokenChar(char) or normalize(char).");
-    return !matchVersion.onOrAfter(Version.LUCENE_31);
-  } 
 }
\ No newline at end of file
diff --git a/lucene/src/java/org/apache/lucene/document/DateField.java b/lucene/src/java/org/apache/lucene/document/DateField.java
deleted file mode 100644
index 508cc3d..0000000
--- a/lucene/src/java/org/apache/lucene/document/DateField.java
+++ /dev/null
@@ -1,123 +0,0 @@
-package org.apache.lucene.document;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.search.PrefixQuery;
-import org.apache.lucene.search.TermRangeQuery;
-import org.apache.lucene.search.NumericRangeQuery; // for javadocs
-import org.apache.lucene.util.NumericUtils; // for javadocs
-
-import java.util.Date;   // for javadoc
-import java.util.Calendar;   // for javadoc
-
-// do not remove in 3.0, needed for reading old indexes!
-
-/**
- * Provides support for converting dates to strings and vice-versa.
- * The strings are structured so that lexicographic sorting orders by date,
- * which makes them suitable for use as field values and search terms.
- *
- * <P>Note that this class saves dates with millisecond granularity,
- * which is bad for {@link TermRangeQuery} and {@link PrefixQuery}, as those
- * queries are expanded to a BooleanQuery with a potentially large number
- * of terms when searching. Thus you might want to use
- * {@link DateTools} instead.
- *
- * <P>
- * Note: dates before 1970 cannot be used, and therefore cannot be
- * indexed when using this class. See {@link DateTools} for an
- * alternative without such a limitation.
- *
- * <P>
- * Another approach is {@link NumericUtils}, which provides
- * a sortable binary representation (prefix encoded) of numeric values, which
- * date/time are.
- * For indexing a {@link Date} or {@link Calendar}, just get the unix timestamp as
- * <code>long</code> using {@link Date#getTime} or {@link Calendar#getTimeInMillis} and
- * index this as a numeric value with {@link NumericField}
- * and use {@link NumericRangeQuery} to query it.
- *
- * @deprecated If you build a new index, use {@link DateTools} or 
- * {@link NumericField} instead.
- * This class is included for use with existing
- * indices and will be removed in a future release (possibly Lucene 4.0).
- */
-@Deprecated
-public class DateField {
-  
-  private DateField() {}
-
-  // make date strings long enough to last a millenium
-  private static int DATE_LEN = Long.toString(1000L*365*24*60*60*1000,
-					       Character.MAX_RADIX).length();
-
-  public static String MIN_DATE_STRING() {
-    return timeToString(0);
-  }
-
-  public static String MAX_DATE_STRING() {
-    char[] buffer = new char[DATE_LEN];
-    char c = Character.forDigit(Character.MAX_RADIX-1, Character.MAX_RADIX);
-    for (int i = 0 ; i < DATE_LEN; i++)
-      buffer[i] = c;
-    return new String(buffer);
-  }
-
-  /**
-   * Converts a Date to a string suitable for indexing.
-   * @throws RuntimeException if the date specified in the
-   * method argument is before 1970
-   */
-  public static String dateToString(Date date) {
-    return timeToString(date.getTime());
-  }
-  /**
-   * Converts a millisecond time to a string suitable for indexing.
-   * @throws RuntimeException if the time specified in the
-   * method argument is negative, that is, before 1970
-   */
-  public static String timeToString(long time) {
-    if (time < 0)
-      throw new RuntimeException("time '" + time + "' is too early, must be >= 0");
-
-    String s = Long.toString(time, Character.MAX_RADIX);
-
-    if (s.length() > DATE_LEN)
-      throw new RuntimeException("time '" + time + "' is too late, length of string " +
-          "representation must be <= " + DATE_LEN);
-
-    // Pad with leading zeros
-    if (s.length() < DATE_LEN) {
-      StringBuilder sb = new StringBuilder(s);
-      while (sb.length() < DATE_LEN)
-        sb.insert(0, 0);
-      s = sb.toString();
-    }
-
-    return s;
-  }
-
-  /** Converts a string-encoded date into a millisecond time. */
-  public static long stringToTime(String s) {
-    return Long.parseLong(s, Character.MAX_RADIX);
-  }
-  /** Converts a string-encoded date into a Date object. */
-  public static Date stringToDate(String s) {
-    return new Date(stringToTime(s));
-  }
-}
diff --git a/lucene/src/java/org/apache/lucene/document/DateTools.java b/lucene/src/java/org/apache/lucene/document/DateTools.java
index 27d3a41..68cb2df 100644
--- a/lucene/src/java/org/apache/lucene/document/DateTools.java
+++ b/lucene/src/java/org/apache/lucene/document/DateTools.java
@@ -36,10 +36,6 @@ import org.apache.lucene.util.NumericUtils; // for javadocs
  * save dates with a finer resolution than you really need, as then
  * RangeQuery and PrefixQuery will require more memory and become slower.
  * 
- * <P>Compared to {@link DateField} the strings generated by the methods
- * in this class take slightly more space, unless your selected resolution
- * is set to <code>Resolution.DAY</code> or lower.
- *
  * <P>
  * Another approach is {@link NumericUtils}, which provides
  * a sortable binary representation (prefix encoded) of numeric values, which
diff --git a/lucene/src/java/org/apache/lucene/document/Field.java b/lucene/src/java/org/apache/lucene/document/Field.java
index 32ccd46..8ab55f3 100644
--- a/lucene/src/java/org/apache/lucene/document/Field.java
+++ b/lucene/src/java/org/apache/lucene/document/Field.java
@@ -17,13 +17,13 @@ package org.apache.lucene.document;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.index.IndexWriter;   // for javadoc
-import org.apache.lucene.util.StringHelper;
-
 import java.io.Reader;
 import java.io.Serializable;
 
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.util.StringHelper;
+
 /**
   A field is a section of a Document.  Each field has two parts, a name and a
   value.  Values may be free text, provided as a String or as a Reader, or they
@@ -521,24 +521,6 @@ public final class Field extends AbstractField implements Fieldable, Serializabl
    * 
    * @param name The name of the field
    * @param value The binary value
-   * @param store Must be Store.YES
-   * @throws IllegalArgumentException if store is <code>Store.NO</code> 
-   * @deprecated Use {@link #Field(String, byte[]) instead}
-   */
-  @Deprecated
-  public Field(String name, byte[] value, Store store) {
-    this(name, value, 0, value.length);
-
-    if (store == Store.NO) {
-      throw new IllegalArgumentException("binary values can't be unstored");
-    }
-  }
-
-  /**
-   * Create a stored field with binary value. Optionally the value may be compressed.
-   * 
-   * @param name The name of the field
-   * @param value The binary value
    */
   public Field(String name, byte[] value) {
     this(name, value, 0, value.length);
@@ -551,26 +533,6 @@ public final class Field extends AbstractField implements Fieldable, Serializabl
    * @param value The binary value
    * @param offset Starting offset in value where this Field's bytes are
    * @param length Number of bytes to use for this Field, starting at offset
-   * @param store How <code>value</code> should be stored (compressed or not)
-   * @throws IllegalArgumentException if store is <code>Store.NO</code> 
-   * @deprecated Use {@link #Field(String, byte[], int, int) instead}
-   */
-  @Deprecated
-  public Field(String name, byte[] value, int offset, int length, Store store) {
-    this(name, value, offset, length);
-
-    if (store == Store.NO) {
-      throw new IllegalArgumentException("binary values can't be unstored");
-    }
-  }
-
-  /**
-   * Create a stored field with binary value. Optionally the value may be compressed.
-   * 
-   * @param name The name of the field
-   * @param value The binary value
-   * @param offset Starting offset in value where this Field's bytes are
-   * @param length Number of bytes to use for this Field, starting at offset
    */
   public Field(String name, byte[] value, int offset, int length) {
 
diff --git a/lucene/src/java/org/apache/lucene/document/NumberTools.java b/lucene/src/java/org/apache/lucene/document/NumberTools.java
deleted file mode 100644
index 4f29ae9..0000000
--- a/lucene/src/java/org/apache/lucene/document/NumberTools.java
+++ /dev/null
@@ -1,140 +0,0 @@
-package org.apache.lucene.document;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.document.NumericField; // for javadocs
-import org.apache.lucene.search.NumericRangeQuery; // for javadocs
-import org.apache.lucene.util.NumericUtils; // for javadocs
-
-// do not remove this class in 3.0, it may be needed to decode old indexes!
-
-/**
- * Provides support for converting longs to Strings, and back again. The strings
- * are structured so that lexicographic sorting order is preserved.
- * 
- * <p>
- * That is, if l1 is less than l2 for any two longs l1 and l2, then
- * NumberTools.longToString(l1) is lexicographically less than
- * NumberTools.longToString(l2). (Similarly for "greater than" and "equals".)
- * 
- * <p>
- * This class handles <b>all</b> long values (unlike
- * {@link org.apache.lucene.document.DateField}).
- * 
- * @deprecated For new indexes use {@link NumericUtils} instead, which
- * provides a sortable binary representation (prefix encoded) of numeric
- * values.
- * To index and efficiently query numeric values use {@link NumericField}
- * and {@link NumericRangeQuery}.
- * This class is included for use with existing
- * indices and will be removed in a future release (possibly Lucene 4.0).
- */
-@Deprecated
-public class NumberTools {
-
-    private static final int RADIX = 36;
-
-    private static final char NEGATIVE_PREFIX = '-';
-
-    // NB: NEGATIVE_PREFIX must be < POSITIVE_PREFIX
-    private static final char POSITIVE_PREFIX = '0';
-
-    //NB: this must be less than
-    /**
-     * Equivalent to longToString(Long.MIN_VALUE)
-     */
-    public static final String MIN_STRING_VALUE = NEGATIVE_PREFIX
-            + "0000000000000";
-
-    /**
-     * Equivalent to longToString(Long.MAX_VALUE)
-     */
-    public static final String MAX_STRING_VALUE = POSITIVE_PREFIX
-            + "1y2p0ij32e8e7";
-
-    /**
-     * The length of (all) strings returned by {@link #longToString}
-     */
-    public static final int STR_SIZE = MIN_STRING_VALUE.length();
-
-    /**
-     * Converts a long to a String suitable for indexing.
-     */
-    public static String longToString(long l) {
-
-        if (l == Long.MIN_VALUE) {
-            // special case, because long is not symmetric around zero
-            return MIN_STRING_VALUE;
-        }
-
-        StringBuilder buf = new StringBuilder(STR_SIZE);
-
-        if (l < 0) {
-            buf.append(NEGATIVE_PREFIX);
-            l = Long.MAX_VALUE + l + 1;
-        } else {
-            buf.append(POSITIVE_PREFIX);
-        }
-        String num = Long.toString(l, RADIX);
-
-        int padLen = STR_SIZE - num.length() - buf.length();
-        while (padLen-- > 0) {
-            buf.append('0');
-        }
-        buf.append(num);
-
-        return buf.toString();
-    }
-
-    /**
-     * Converts a String that was returned by {@link #longToString} back to a
-     * long.
-     * 
-     * @throws IllegalArgumentException
-     *             if the input is null
-     * @throws NumberFormatException
-     *             if the input does not parse (it was not a String returned by
-     *             longToString()).
-     */
-    public static long stringToLong(String str) {
-        if (str == null) {
-            throw new NullPointerException("string cannot be null");
-        }
-        if (str.length() != STR_SIZE) {
-            throw new NumberFormatException("string is the wrong size");
-        }
-
-        if (str.equals(MIN_STRING_VALUE)) {
-            return Long.MIN_VALUE;
-        }
-
-        char prefix = str.charAt(0);
-        long l = Long.parseLong(str.substring(1), RADIX);
-
-        if (prefix == POSITIVE_PREFIX) {
-            // nop
-        } else if (prefix == NEGATIVE_PREFIX) {
-            l = l - Long.MAX_VALUE - 1;
-        } else {
-            throw new NumberFormatException(
-                    "string does not begin with the correct prefix");
-        }
-
-        return l;
-    }
-}
\ No newline at end of file
diff --git a/lucene/src/java/org/apache/lucene/index/CompoundFileReader.java b/lucene/src/java/org/apache/lucene/index/CompoundFileReader.java
index 72813ae..c596eb0 100644
--- a/lucene/src/java/org/apache/lucene/index/CompoundFileReader.java
+++ b/lucene/src/java/org/apache/lucene/index/CompoundFileReader.java
@@ -23,6 +23,7 @@ import org.apache.lucene.store.BufferedIndexInput;
 import org.apache.lucene.store.IndexOutput;
 import org.apache.lucene.store.Lock;
 
+import java.util.Collection;
 import java.util.HashMap;
 import java.io.FileNotFoundException;
 import java.io.IOException;
@@ -227,6 +228,10 @@ public class CompoundFileReader extends Directory {
         throw new UnsupportedOperationException();
     }
 
+    @Override
+    public void sync(Collection<String> names) throws IOException {
+    }
+
     /** Not implemented
      * @throws UnsupportedOperationException */
     @Override
diff --git a/lucene/src/java/org/apache/lucene/index/IndexWriter.java b/lucene/src/java/org/apache/lucene/index/IndexWriter.java
index 1f69074..e7e7812 100644
--- a/lucene/src/java/org/apache/lucene/index/IndexWriter.java
+++ b/lucene/src/java/org/apache/lucene/index/IndexWriter.java
@@ -180,69 +180,12 @@ import java.util.Date;
  * keeps track of the last non commit checkpoint.
  */
 public class IndexWriter implements Closeable {
-
-  /**
-   * Default value for the write lock timeout (1,000).
-   * @see #setDefaultWriteLockTimeout
-   * @deprecated use {@link IndexWriterConfig#WRITE_LOCK_TIMEOUT} instead
-   */
-  @Deprecated
-  public static long WRITE_LOCK_TIMEOUT = IndexWriterConfig.WRITE_LOCK_TIMEOUT;
-
-  private long writeLockTimeout;
-
   /**
    * Name of the write lock in the index.
    */
   public static final String WRITE_LOCK_NAME = "write.lock";
 
   /**
-   * Value to denote a flush trigger is disabled
-   * @deprecated use {@link IndexWriterConfig#DISABLE_AUTO_FLUSH} instead
-   */
-  @Deprecated
-  public final static int DISABLE_AUTO_FLUSH = IndexWriterConfig.DISABLE_AUTO_FLUSH;
-
-  /**
-   * Disabled by default (because IndexWriter flushes by RAM usage
-   * by default). Change using {@link #setMaxBufferedDocs(int)}.
-   * @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DOCS} instead.
-   */
-  @Deprecated
-  public final static int DEFAULT_MAX_BUFFERED_DOCS = IndexWriterConfig.DEFAULT_MAX_BUFFERED_DOCS;
-
-  /**
-   * Default value is 16 MB (which means flush when buffered
-   * docs consume 16 MB RAM).  Change using {@link #setRAMBufferSizeMB}.
-   * @deprecated use {@link IndexWriterConfig#DEFAULT_RAM_BUFFER_SIZE_MB} instead.
-   */
-  @Deprecated
-  public final static double DEFAULT_RAM_BUFFER_SIZE_MB = IndexWriterConfig.DEFAULT_RAM_BUFFER_SIZE_MB;
-
-  /**
-   * Disabled by default (because IndexWriter flushes by RAM usage
-   * by default). Change using {@link #setMaxBufferedDeleteTerms(int)}.
-   * @deprecated use {@link IndexWriterConfig#DEFAULT_MAX_BUFFERED_DELETE_TERMS} instead
-   */
-  @Deprecated
-  public final static int DEFAULT_MAX_BUFFERED_DELETE_TERMS = IndexWriterConfig.DEFAULT_MAX_BUFFERED_DELETE_TERMS;
-
-  /**
-   * Default value is 10,000. Change using {@link #setMaxFieldLength(int)}.
-   * 
-   * @deprecated see {@link IndexWriterConfig}
-   */
-  @Deprecated
-  public final static int DEFAULT_MAX_FIELD_LENGTH = 10000;
-
-  /**
-   * Default value is 128. Change using {@link #setTermIndexInterval(int)}.
-   * @deprecated use {@link IndexWriterConfig#DEFAULT_TERM_INDEX_INTERVAL} instead.
-   */
-  @Deprecated
-  public final static int DEFAULT_TERM_INDEX_INTERVAL = IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL;
-
-  /**
    * Absolute hard maximum length for a term, in bytes once
    * encoded as UTF8.  If a term arrives from the analyzer
    * longer than this length, it is skipped and a message is
@@ -268,9 +211,6 @@ public class IndexWriter implements Closeable {
   private final Directory directory;  // where this index resides
   private final Analyzer analyzer;    // how to analyze text
 
-  // TODO 4.0: this should be made final once the setter is out
-  private /*final*/Similarity similarity = Similarity.getDefault(); // how to normalize
-
   private volatile long changeCount; // increments every time a change is completed
   private long lastCommitChangeCount; // last changeCount that was committed
 
@@ -290,8 +230,7 @@ public class IndexWriter implements Closeable {
 
   private Lock writeLock;
 
-  // TODO 4.0: this should be made final once the setter is out
-  private /*final*/int termIndexInterval;
+  private final int termIndexInterval;
 
   private boolean closed;
   private boolean closing;
@@ -301,8 +240,7 @@ public class IndexWriter implements Closeable {
   private HashSet<SegmentInfo> mergingSegments = new HashSet<SegmentInfo>();
 
   private MergePolicy mergePolicy;
-  // TODO 4.0: this should be made final once the setter is removed
-  private /*final*/MergeScheduler mergeScheduler;
+  private final MergeScheduler mergeScheduler;
   private LinkedList<MergePolicy.OneMerge> pendingMerges = new LinkedList<MergePolicy.OneMerge>();
   private Set<MergePolicy.OneMerge> runningMerges = new HashSet<MergePolicy.OneMerge>();
   private List<MergePolicy.OneMerge> mergeExceptions = new ArrayList<MergePolicy.OneMerge>();
@@ -730,276 +668,6 @@ public class IndexWriter implements Closeable {
       throw new IllegalArgumentException("this method can only be called when the merge policy is the default LogMergePolicy");
   }
 
-  /** <p>Get the current setting of whether newly flushed
-   *  segments will use the compound file format.  Note that
-   *  this just returns the value previously set with
-   *  setUseCompoundFile(boolean), or the default value
-   *  (true).  You cannot use this to query the status of
-   *  previously flushed segments.</p>
-   *
-   *  <p>Note that this method is a convenience method: it
-   *  just calls mergePolicy.getUseCompoundFile as long as
-   *  mergePolicy is an instance of {@link LogMergePolicy}.
-   *  Otherwise an IllegalArgumentException is thrown.</p>
-   *
-   *  @see #setUseCompoundFile(boolean)
-   *  @deprecated use {@link LogMergePolicy#getUseCompoundDocStore()} and
-   *  {@link LogMergePolicy#getUseCompoundFile()} directly.
-   */
-  @Deprecated
-  public boolean getUseCompoundFile() {
-    return getLogMergePolicy().getUseCompoundFile();
-  }
-
-  /**
-   * <p>
-   * Setting to turn on usage of a compound file. When on, multiple files for
-   * each segment are merged into a single file when a new segment is flushed.
-   * </p>
-   * 
-   * <p>
-   * Note that this method is a convenience method: it just calls
-   * mergePolicy.setUseCompoundFile as long as mergePolicy is an instance of
-   * {@link LogMergePolicy}. Otherwise an IllegalArgumentException is thrown.
-   * </p>
-   * 
-   * @deprecated use {@link LogMergePolicy#setUseCompoundDocStore(boolean)} and
-   *             {@link LogMergePolicy#setUseCompoundFile(boolean)} directly.
-   *             Note that this method set the given value on both, therefore
-   *             you should consider doing the same.
-   */
-  @Deprecated
-  public void setUseCompoundFile(boolean value) {
-    getLogMergePolicy().setUseCompoundFile(value);
-    getLogMergePolicy().setUseCompoundDocStore(value);
-  }
-
-  /** Expert: Set the Similarity implementation used by this IndexWriter.
-   *
-   * @see Similarity#setDefault(Similarity)
-   * @deprecated use {@link IndexWriterConfig#setSimilarity(Similarity)} instead
-   */
-  @Deprecated
-  public void setSimilarity(Similarity similarity) {
-    ensureOpen();
-    this.similarity = similarity;
-    docWriter.setSimilarity(similarity);
-    // Required so config.getSimilarity returns the right value. But this will
-    // go away together with the method in 4.0.
-    config.setSimilarity(similarity);
-  }
-
-  /** Expert: Return the Similarity implementation used by this IndexWriter.
-   *
-   * <p>This defaults to the current value of {@link Similarity#getDefault()}.
-   * @deprecated use {@link IndexWriterConfig#getSimilarity()} instead
-   */
-  @Deprecated
-  public Similarity getSimilarity() {
-    ensureOpen();
-    return similarity;
-  }
-
-  /** Expert: Set the interval between indexed terms.  Large values cause less
-   * memory to be used by IndexReader, but slow random-access to terms.  Small
-   * values cause more memory to be used by an IndexReader, and speed
-   * random-access to terms.
-   *
-   * This parameter determines the amount of computation required per query
-   * term, regardless of the number of documents that contain that term.  In
-   * particular, it is the maximum number of other terms that must be
-   * scanned before a term is located and its frequency and position information
-   * may be processed.  In a large index with user-entered query terms, query
-   * processing time is likely to be dominated not by term lookup but rather
-   * by the processing of frequency and positional data.  In a small index
-   * or when many uncommon query terms are generated (e.g., by wildcard
-   * queries) term lookup may become a dominant cost.
-   *
-   * In particular, <code>numUniqueTerms/interval</code> terms are read into
-   * memory by an IndexReader, and, on average, <code>interval/2</code> terms
-   * must be scanned for each random term access.
-   *
-   * @see #DEFAULT_TERM_INDEX_INTERVAL
-   * @deprecated use {@link IndexWriterConfig#setTermIndexInterval(int)}
-   */
-  @Deprecated
-  public void setTermIndexInterval(int interval) {
-    ensureOpen();
-    this.termIndexInterval = interval;
-    // Required so config.getTermIndexInterval returns the right value. But this
-    // will go away together with the method in 4.0.
-    config.setTermIndexInterval(interval);
-  }
-
-  /** Expert: Return the interval between indexed terms.
-   *
-   * @see #setTermIndexInterval(int)
-   * @deprecated use {@link IndexWriterConfig#getTermIndexInterval()}
-   */
-  @Deprecated
-  public int getTermIndexInterval() {
-    // We pass false because this method is called by SegmentMerger while we are in the process of closing
-    ensureOpen(false);
-    return termIndexInterval;
-  }
-
-  /**
-   * Constructs an IndexWriter for the index in <code>d</code>.
-   * Text will be analyzed with <code>a</code>.  If <code>create</code>
-   * is true, then a new, empty index will be created in
-   * <code>d</code>, replacing the index already there, if any.
-   *
-   * @param d the index directory
-   * @param a the analyzer to use
-   * @param create <code>true</code> to create the index or overwrite
-   *  the existing one; <code>false</code> to append to the existing
-   *  index
-   * @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
-   *   via the MaxFieldLength constructor.
-   * @throws CorruptIndexException if the index is corrupt
-   * @throws LockObtainFailedException if another writer
-   *  has this index open (<code>write.lock</code> could not
-   *  be obtained)
-   * @throws IOException if the directory cannot be read/written to, or
-   *  if it does not exist and <code>create</code> is
-   *  <code>false</code> or if there is any other low-level
-   *  IO error
-   *  @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead
-   */
-  @Deprecated
-  public IndexWriter(Directory d, Analyzer a, boolean create, MaxFieldLength mfl)
-       throws CorruptIndexException, LockObtainFailedException, IOException {
-    this(d, new IndexWriterConfig(Version.LUCENE_31, a).setOpenMode(
-        create ? OpenMode.CREATE : OpenMode.APPEND).setMaxFieldLength(
-        mfl.getLimit()));
-  }
-
-  /**
-   * Constructs an IndexWriter for the index in
-   * <code>d</code>, first creating it if it does not
-   * already exist.  Text will be analyzed with
-   * <code>a</code>.
-   *
-   * @param d the index directory
-   * @param a the analyzer to use
-   * @param mfl Maximum field length in number of terms/tokens: LIMITED, UNLIMITED, or user-specified
-   *   via the MaxFieldLength constructor.
-   * @throws CorruptIndexException if the index is corrupt
-   * @throws LockObtainFailedException if another writer
-   *  has this index open (<code>write.lock</code> could not
-   *  be obtained)
-   * @throws IOException if the directory cannot be
-   *  read/written to or if there is any other low-level
-   *  IO error
-   *  @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead
-   */
-  @Deprecated
-  public IndexWriter(Directory d, Analyzer a, MaxFieldLength mfl)
-    throws CorruptIndexException, LockObtainFailedException, IOException {
-    this(d, new IndexWriterConfig(Version.LUCENE_31, a)
-        .setMaxFieldLength(mfl.getLimit()));
-  }
-
-  /**
-   * Expert: constructs an IndexWriter with a custom {@link
-   * IndexDeletionPolicy}, for the index in <code>d</code>,
-   * first creating it if it does not already exist.  Text
-   * will be analyzed with <code>a</code>.
-   *
-   * @param d the index directory
-   * @param a the analyzer to use
-   * @param deletionPolicy see <a href="#deletionPolicy">above</a>
-   * @param mfl whether or not to limit field lengths
-   * @throws CorruptIndexException if the index is corrupt
-   * @throws LockObtainFailedException if another writer
-   *  has this index open (<code>write.lock</code> could not
-   *  be obtained)
-   * @throws IOException if the directory cannot be
-   *  read/written to or if there is any other low-level
-   *  IO error
-   *  @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead
-   */
-  @Deprecated
-  public IndexWriter(Directory d, Analyzer a, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl)
-    throws CorruptIndexException, LockObtainFailedException, IOException {
-    this(d, new IndexWriterConfig(Version.LUCENE_31, a).setMaxFieldLength(
-        mfl.getLimit()).setIndexDeletionPolicy(deletionPolicy));
-  }
-
-  /**
-   * Expert: constructs an IndexWriter with a custom {@link
-   * IndexDeletionPolicy}, for the index in <code>d</code>.
-   * Text will be analyzed with <code>a</code>.  If
-   * <code>create</code> is true, then a new, empty index
-   * will be created in <code>d</code>, replacing the index
-   * already there, if any.
-   *
-   * @param d the index directory
-   * @param a the analyzer to use
-   * @param create <code>true</code> to create the index or overwrite
-   *  the existing one; <code>false</code> to append to the existing
-   *  index
-   * @param deletionPolicy see <a href="#deletionPolicy">above</a>
-   * @param mfl {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}, whether or not to limit field lengths.  Value is in number of terms/tokens
-   * @throws CorruptIndexException if the index is corrupt
-   * @throws LockObtainFailedException if another writer
-   *  has this index open (<code>write.lock</code> could not
-   *  be obtained)
-   * @throws IOException if the directory cannot be read/written to, or
-   *  if it does not exist and <code>create</code> is
-   *  <code>false</code> or if there is any other low-level
-   *  IO error
-   *  @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead
-   */
-  @Deprecated
-  public IndexWriter(Directory d, Analyzer a, boolean create, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl)
-       throws CorruptIndexException, LockObtainFailedException, IOException {
-    this(d, new IndexWriterConfig(Version.LUCENE_31, a).setOpenMode(
-        create ? OpenMode.CREATE : OpenMode.APPEND).setMaxFieldLength(
-        mfl.getLimit()).setIndexDeletionPolicy(deletionPolicy));
-  }
-  
-  /**
-   * Expert: constructs an IndexWriter on specific commit
-   * point, with a custom {@link IndexDeletionPolicy}, for
-   * the index in <code>d</code>.  Text will be analyzed
-   * with <code>a</code>.
-   *
-   * <p> This is only meaningful if you've used a {@link
-   * IndexDeletionPolicy} in that past that keeps more than
-   * just the last commit.
-   * 
-   * <p>This operation is similar to {@link #rollback()},
-   * except that method can only rollback what's been done
-   * with the current instance of IndexWriter since its last
-   * commit, whereas this method can rollback to an
-   * arbitrary commit point from the past, assuming the
-   * {@link IndexDeletionPolicy} has preserved past
-   * commits.
-   *
-   * @param d the index directory
-   * @param a the analyzer to use
-   * @param deletionPolicy see <a href="#deletionPolicy">above</a>
-   * @param mfl whether or not to limit field lengths, value is in number of terms/tokens.  See {@link org.apache.lucene.index.IndexWriter.MaxFieldLength}.
-   * @param commit which commit to open
-   * @throws CorruptIndexException if the index is corrupt
-   * @throws LockObtainFailedException if another writer
-   *  has this index open (<code>write.lock</code> could not
-   *  be obtained)
-   * @throws IOException if the directory cannot be read/written to, or
-   *  if it does not exist and <code>create</code> is
-   *  <code>false</code> or if there is any other low-level
-   *  IO error
-   *  @deprecated use {@link #IndexWriter(Directory, IndexWriterConfig)} instead
-   */
-  @Deprecated
-  public IndexWriter(Directory d, Analyzer a, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl, IndexCommit commit)
-       throws CorruptIndexException, LockObtainFailedException, IOException {
-    this(d, new IndexWriterConfig(Version.LUCENE_31, a)
-        .setOpenMode(OpenMode.APPEND).setMaxFieldLength(mfl.getLimit())
-        .setIndexDeletionPolicy(deletionPolicy).setIndexCommit(commit));
-  }
-  
   CodecProvider codecs;
 
   /**
@@ -1038,8 +706,6 @@ public class IndexWriter implements Closeable {
     setMessageID(defaultInfoStream);
     maxFieldLength = conf.getMaxFieldLength();
     termIndexInterval = conf.getTermIndexInterval();
-    writeLockTimeout = conf.getWriteLockTimeout();
-    similarity = conf.getSimilarity();
     mergePolicy = conf.getMergePolicy();
     mergePolicy.setIndexWriter(this);
     mergeScheduler = conf.getMergeScheduler();
@@ -1061,7 +727,7 @@ public class IndexWriter implements Closeable {
 
     writeLock = directory.makeLock(WRITE_LOCK_NAME);
 
-    if (!writeLock.obtain(writeLockTimeout)) // obtain write lock
+    if (!writeLock.obtain(conf.getWriteLockTimeout())) // obtain write lock
       throw new LockObtainFailedException("Index locked for write: " + writeLock);
 
     boolean success = false;
@@ -1177,202 +843,12 @@ public class IndexWriter implements Closeable {
   }
   
   /**
-   * Expert: set the merge policy used by this writer.
-   * 
-   * @deprecated use {@link IndexWriterConfig#setMergePolicy(MergePolicy)} instead.
-   */
-  @Deprecated
-  public void setMergePolicy(MergePolicy mp) {
-    ensureOpen();
-    if (mp == null)
-      throw new NullPointerException("MergePolicy must be non-null");
-
-    if (mergePolicy != mp)
-      mergePolicy.close();
-    mergePolicy = mp;
-    mergePolicy.setIndexWriter(this);
-    pushMaxBufferedDocs();
-    if (infoStream != null)
-      message("setMergePolicy " + mp);
-    // Required so config.getMergePolicy returns the right value. But this will
-    // go away together with the method in 4.0.
-    config.setMergePolicy(mp);
-  }
-
-  /**
-   * Expert: returns the current MergePolicy in use by this writer.
-   * @see #setMergePolicy
-   * 
-   * @deprecated use {@link IndexWriterConfig#getMergePolicy()} instead
-   */
-  @Deprecated
-  public MergePolicy getMergePolicy() {
-    ensureOpen();
-    return mergePolicy;
-  }
-
-  /**
-   * Expert: set the merge scheduler used by this writer.
-   * @deprecated use {@link IndexWriterConfig#setMergeScheduler(MergeScheduler)} instead
-   */
-  @Deprecated
-  synchronized public void setMergeScheduler(MergeScheduler mergeScheduler) throws CorruptIndexException, IOException {
-    ensureOpen();
-    if (mergeScheduler == null)
-      throw new NullPointerException("MergeScheduler must be non-null");
-
-    if (this.mergeScheduler != mergeScheduler) {
-      finishMerges(true);
-      this.mergeScheduler.close();
-    }
-    this.mergeScheduler = mergeScheduler;
-    if (infoStream != null)
-      message("setMergeScheduler " + mergeScheduler);
-    // Required so config.getMergeScheduler returns the right value. But this will
-    // go away together with the method in 4.0.
-    config.setMergeScheduler(mergeScheduler);
-  }
-
-  /**
-   * Expert: returns the current MergeScheduler in use by this
-   * writer.
-   * @see #setMergeScheduler(MergeScheduler)
-   * @deprecated use {@link IndexWriterConfig#getMergeScheduler()} instead
-   */
-  @Deprecated
-  public MergeScheduler getMergeScheduler() {
-    ensureOpen();
-    return mergeScheduler;
-  }
-
-  /** <p>Determines the largest segment (measured by
-   * document count) that may be merged with other segments.
-   * Small values (e.g., less than 10,000) are best for
-   * interactive indexing, as this limits the length of
-   * pauses while indexing to a few seconds.  Larger values
-   * are best for batched indexing and speedier
-   * searches.</p>
-   *
-   * <p>The default value is {@link Integer#MAX_VALUE}.</p>
-   *
-   * <p>Note that this method is a convenience method: it
-   * just calls mergePolicy.setMaxMergeDocs as long as
-   * mergePolicy is an instance of {@link LogMergePolicy}.
-   * Otherwise an IllegalArgumentException is thrown.</p>
-   *
-   * <p>The default merge policy ({@link
-   * LogByteSizeMergePolicy}) also allows you to set this
-   * limit by net size (in MB) of the segment, using {@link
-   * LogByteSizeMergePolicy#setMaxMergeMB}.</p>
-   * @deprecated use {@link LogMergePolicy#setMaxMergeDocs(int)} directly.
-   */
-  @Deprecated
-  public void setMaxMergeDocs(int maxMergeDocs) {
-    getLogMergePolicy().setMaxMergeDocs(maxMergeDocs);
-  }
-
-  /**
-   * <p>Returns the largest segment (measured by document
-   * count) that may be merged with other segments.</p>
-   *
-   * <p>Note that this method is a convenience method: it
-   * just calls mergePolicy.getMaxMergeDocs as long as
-   * mergePolicy is an instance of {@link LogMergePolicy}.
-   * Otherwise an IllegalArgumentException is thrown.</p>
-   *
-   * @see #setMaxMergeDocs
-   * @deprecated use {@link LogMergePolicy#getMaxMergeDocs()} directly.
-   */
-  @Deprecated
-  public int getMaxMergeDocs() {
-    return getLogMergePolicy().getMaxMergeDocs();
-  }
-
-  /**
-   * The maximum number of terms that will be indexed for a single field in a
-   * document.  This limits the amount of memory required for indexing, so that
-   * collections with very large files will not crash the indexing process by
-   * running out of memory.  This setting refers to the number of running terms,
-   * not to the number of different terms.<p/>
-   * <strong>Note:</strong> this silently truncates large documents, excluding from the
-   * index all terms that occur further in the document.  If you know your source
-   * documents are large, be sure to set this value high enough to accomodate
-   * the expected size.  If you set it to Integer.MAX_VALUE, then the only limit
-   * is your memory, but you should anticipate an OutOfMemoryError.<p/>
-   * By default, no more than {@link #DEFAULT_MAX_FIELD_LENGTH} terms
-   * will be indexed for a field.
-   * @deprecated use {@link IndexWriterConfig#setMaxFieldLength(int)} instead
-   */
-  @Deprecated
-  public void setMaxFieldLength(int maxFieldLength) {
-    ensureOpen();
-    this.maxFieldLength = maxFieldLength;
-    docWriter.setMaxFieldLength(maxFieldLength);
-    if (infoStream != null)
-      message("setMaxFieldLength " + maxFieldLength);
-    // Required so config.getMaxFieldLength returns the right value. But this
-    // will go away together with the method in 4.0.
-    config.setMaxFieldLength(maxFieldLength);
-  }
-
-  /**
-   * Returns the maximum number of terms that will be
-   * indexed for a single field in a document.
-   * @see #setMaxFieldLength
-   * @deprecated use {@link IndexWriterConfig#getMaxFieldLength()} instead
-   */
-  @Deprecated
-  public int getMaxFieldLength() {
-    ensureOpen();
-    return maxFieldLength;
-  }
-
-  /** Determines the minimal number of documents required
-   * before the buffered in-memory documents are flushed as
-   * a new Segment.  Large values generally gives faster
-   * indexing.
-   *
-   * <p>When this is set, the writer will flush every
-   * maxBufferedDocs added documents.  Pass in {@link
-   * #DISABLE_AUTO_FLUSH} to prevent triggering a flush due
-   * to number of buffered documents.  Note that if flushing
-   * by RAM usage is also enabled, then the flush will be
-   * triggered by whichever comes first.</p>
-   *
-   * <p>Disabled by default (writer flushes by RAM usage).</p>
-   *
-   * @throws IllegalArgumentException if maxBufferedDocs is
-   * enabled but smaller than 2, or it disables maxBufferedDocs
-   * when ramBufferSize is already disabled
-   * @see #setRAMBufferSizeMB
-   * @deprecated use {@link IndexWriterConfig#setMaxBufferedDocs(int)} instead.
-   */
-  @Deprecated
-  public void setMaxBufferedDocs(int maxBufferedDocs) {
-    ensureOpen();
-    if (maxBufferedDocs != DISABLE_AUTO_FLUSH && maxBufferedDocs < 2)
-      throw new IllegalArgumentException(
-          "maxBufferedDocs must at least be 2 when enabled");
-    if (maxBufferedDocs == DISABLE_AUTO_FLUSH
-        && getRAMBufferSizeMB() == DISABLE_AUTO_FLUSH)
-      throw new IllegalArgumentException(
-          "at least one of ramBufferSize and maxBufferedDocs must be enabled");
-    docWriter.setMaxBufferedDocs(maxBufferedDocs);
-    pushMaxBufferedDocs();
-    if (infoStream != null)
-      message("setMaxBufferedDocs " + maxBufferedDocs);
-    // Required so config.getMaxBufferedDocs returns the right value. But this
-    // will go away together with the method in 4.0.
-    config.setMaxBufferedDocs(maxBufferedDocs);
-  }
-
-  /**
    * If we are flushing by doc count (not by RAM usage), and
    * using LogDocMergePolicy then push maxBufferedDocs down
    * as its minMergeDocs, to keep backwards compatibility.
    */
   private void pushMaxBufferedDocs() {
-    if (docWriter.getMaxBufferedDocs() != DISABLE_AUTO_FLUSH) {
+    if (docWriter.getMaxBufferedDocs() != IndexWriterConfig.DISABLE_AUTO_FLUSH) {
       final MergePolicy mp = mergePolicy;
       if (mp instanceof LogDocMergePolicy) {
         LogDocMergePolicy lmp = (LogDocMergePolicy) mp;
@@ -1386,164 +862,6 @@ public class IndexWriter implements Closeable {
     }
   }
 
-  /**
-   * Returns the number of buffered added documents that will
-   * trigger a flush if enabled.
-   * @see #setMaxBufferedDocs
-   * @deprecated use {@link IndexWriterConfig#getMaxBufferedDocs()} instead.
-   */
-  @Deprecated
-  public int getMaxBufferedDocs() {
-    ensureOpen();
-    return docWriter.getMaxBufferedDocs();
-  }
-
-  /** Determines the amount of RAM that may be used for
-   * buffering added documents and deletions before they are
-   * flushed to the Directory.  Generally for faster
-   * indexing performance it's best to flush by RAM usage
-   * instead of document count and use as large a RAM buffer
-   * as you can.
-   *
-   * <p>When this is set, the writer will flush whenever
-   * buffered documents and deletions use this much RAM.
-   * Pass in {@link #DISABLE_AUTO_FLUSH} to prevent
-   * triggering a flush due to RAM usage.  Note that if
-   * flushing by document count is also enabled, then the
-   * flush will be triggered by whichever comes first.</p>
-   *
-   * <p> <b>NOTE</b>: the account of RAM usage for pending
-   * deletions is only approximate.  Specifically, if you
-   * delete by Query, Lucene currently has no way to measure
-   * the RAM usage if individual Queries so the accounting
-   * will under-estimate and you should compensate by either
-   * calling commit() periodically yourself, or by using
-   * {@link #setMaxBufferedDeleteTerms} to flush by count
-   * instead of RAM usage (each buffered delete Query counts
-   * as one).
-   *
-   * <p> <b>NOTE</b>: because IndexWriter uses
-   * <code>int</code>s when managing its internal storage,
-   * the absolute maximum value for this setting is somewhat
-   * less than 2048 MB.  The precise limit depends on
-   * various factors, such as how large your documents are,
-   * how many fields have norms, etc., so it's best to set
-   * this value comfortably under 2048.</p>
-   *
-   * <p> The default value is {@link #DEFAULT_RAM_BUFFER_SIZE_MB}.</p>
-   * 
-   * @throws IllegalArgumentException if ramBufferSize is
-   * enabled but non-positive, or it disables ramBufferSize
-   * when maxBufferedDocs is already disabled
-   * @deprecated use {@link IndexWriterConfig#setRAMBufferSizeMB(double)} instead.
-   */
-  @Deprecated
-  public void setRAMBufferSizeMB(double mb) {
-    if (mb > 2048.0) {
-      throw new IllegalArgumentException("ramBufferSize " + mb + " is too large; should be comfortably less than 2048");
-    }
-    if (mb != DISABLE_AUTO_FLUSH && mb <= 0.0)
-      throw new IllegalArgumentException(
-          "ramBufferSize should be > 0.0 MB when enabled");
-    if (mb == DISABLE_AUTO_FLUSH && getMaxBufferedDocs() == DISABLE_AUTO_FLUSH)
-      throw new IllegalArgumentException(
-          "at least one of ramBufferSize and maxBufferedDocs must be enabled");
-    docWriter.setRAMBufferSizeMB(mb);
-    if (infoStream != null)
-      message("setRAMBufferSizeMB " + mb);
-    // Required so config.getRAMBufferSizeMB returns the right value. But this
-    // will go away together with the method in 4.0.
-    config.setRAMBufferSizeMB(mb);
-  }
-
-  /**
-   * Returns the value set by {@link #setRAMBufferSizeMB} if enabled.
-   * @deprecated use {@link IndexWriterConfig#getRAMBufferSizeMB()} instead.
-   */
-  @Deprecated
-  public double getRAMBufferSizeMB() {
-    return docWriter.getRAMBufferSizeMB();
-  }
-
-  /**
-   * <p>Determines the minimal number of delete terms required before the buffered
-   * in-memory delete terms are applied and flushed. If there are documents
-   * buffered in memory at the time, they are merged and a new segment is
-   * created.</p>
-
-   * <p>Disabled by default (writer flushes by RAM usage).</p>
-   * 
-   * @throws IllegalArgumentException if maxBufferedDeleteTerms
-   * is enabled but smaller than 1
-   * @see #setRAMBufferSizeMB
-   * @deprecated use {@link IndexWriterConfig#setMaxBufferedDeleteTerms(int)} instead.
-   */
-  @Deprecated
-  public void setMaxBufferedDeleteTerms(int maxBufferedDeleteTerms) {
-    ensureOpen();
-    if (maxBufferedDeleteTerms != DISABLE_AUTO_FLUSH
-        && maxBufferedDeleteTerms < 1)
-      throw new IllegalArgumentException(
-          "maxBufferedDeleteTerms must at least be 1 when enabled");
-    docWriter.setMaxBufferedDeleteTerms(maxBufferedDeleteTerms);
-    if (infoStream != null)
-      message("setMaxBufferedDeleteTerms " + maxBufferedDeleteTerms);
-    // Required so config.getMaxBufferedDeleteTerms returns the right value. But
-    // this will go away together with the method in 4.0.
-    config.setMaxBufferedDeleteTerms(maxBufferedDeleteTerms);
-  }
-
-  /**
-   * Returns the number of buffered deleted terms that will
-   * trigger a flush if enabled.
-   * @see #setMaxBufferedDeleteTerms
-   * @deprecated use {@link IndexWriterConfig#getMaxBufferedDeleteTerms()} instead
-   */
-  @Deprecated
-  public int getMaxBufferedDeleteTerms() {
-    ensureOpen();
-    return docWriter.getMaxBufferedDeleteTerms();
-  }
-
-  /** Determines how often segment indices are merged by addDocument().  With
-   * smaller values, less RAM is used while indexing, and searches on
-   * unoptimized indices are faster, but indexing speed is slower.  With larger
-   * values, more RAM is used during indexing, and while searches on unoptimized
-   * indices are slower, indexing is faster.  Thus larger values (> 10) are best
-   * for batch index creation, and smaller values (< 10) for indices that are
-   * interactively maintained.
-   *
-   * <p>Note that this method is a convenience method: it
-   * just calls mergePolicy.setMergeFactor as long as
-   * mergePolicy is an instance of {@link LogMergePolicy}.
-   * Otherwise an IllegalArgumentException is thrown.</p>
-   *
-   * <p>This must never be less than 2.  The default value is 10.
-   * @deprecated use {@link LogMergePolicy#setMergeFactor(int)} directly.
-   */
-  @Deprecated
-  public void setMergeFactor(int mergeFactor) {
-    getLogMergePolicy().setMergeFactor(mergeFactor);
-  }
-
-  /**
-   * <p>Returns the number of segments that are merged at
-   * once and also controls the total number of segments
-   * allowed to accumulate in the index.</p>
-   *
-   * <p>Note that this method is a convenience method: it
-   * just calls mergePolicy.getMergeFactor as long as
-   * mergePolicy is an instance of {@link LogMergePolicy}.
-   * Otherwise an IllegalArgumentException is thrown.</p>
-   *
-   * @see #setMergeFactor
-   * @deprecated use {@link LogMergePolicy#getMergeFactor()} directly.
-   */
-  @Deprecated
-  public int getMergeFactor() {
-    return getLogMergePolicy().getMergeFactor();
-  }
-
   /** If non-null, this will be the default infoStream used
    * by a newly instantiated IndexWriter.
    * @see #setInfoStream
@@ -1596,52 +914,6 @@ public class IndexWriter implements Closeable {
   }
   
   /**
-   * Sets the maximum time to wait for a write lock (in milliseconds) for this instance of IndexWriter.  @see
-   * @see #setDefaultWriteLockTimeout to change the default value for all instances of IndexWriter.
-   * @deprecated use {@link IndexWriterConfig#setWriteLockTimeout(long)} instead
-   */
-  @Deprecated
-  public void setWriteLockTimeout(long writeLockTimeout) {
-    ensureOpen();
-    this.writeLockTimeout = writeLockTimeout;
-    // Required so config.getWriteLockTimeout returns the right value. But this
-    // will go away together with the method in 4.0.
-    config.setWriteLockTimeout(writeLockTimeout);
-  }
-
-  /**
-   * Returns allowed timeout when acquiring the write lock.
-   * @see #setWriteLockTimeout
-   * @deprecated use {@link IndexWriterConfig#getWriteLockTimeout()}
-   */
-  @Deprecated
-  public long getWriteLockTimeout() {
-    ensureOpen();
-    return writeLockTimeout;
-  }
-
-  /**
-   * Sets the default (for any instance of IndexWriter) maximum time to wait for a write lock (in
-   * milliseconds).
-   * @deprecated use {@link IndexWriterConfig#setDefaultWriteLockTimeout(long)} instead
-   */
-  @Deprecated
-  public static void setDefaultWriteLockTimeout(long writeLockTimeout) {
-    IndexWriterConfig.setDefaultWriteLockTimeout(writeLockTimeout);
-  }
-
-  /**
-   * Returns default write lock timeout for newly
-   * instantiated IndexWriters.
-   * @see #setDefaultWriteLockTimeout
-   * @deprecated use {@link IndexWriterConfig#getDefaultWriteLockTimeout()} instead
-   */
-  @Deprecated
-  public static long getDefaultWriteLockTimeout() {
-    return IndexWriterConfig.getDefaultWriteLockTimeout();
-  }
-
-  /**
    * Commits all changes to an index and closes all
    * associated files.  Note that this may be a costly
    * operation, so, try to re-use a single writer instead of
@@ -3030,7 +2302,7 @@ public class IndexWriter implements Closeable {
       }
       
       // Now create the compound file if needed
-      if (mergePolicy instanceof LogMergePolicy && getUseCompoundFile()) {
+      if (mergePolicy instanceof LogMergePolicy && ((LogMergePolicy) mergePolicy).getUseCompoundFile()) {
 
         List<String> files = null;
 
@@ -3998,7 +3270,7 @@ public class IndexWriter implements Closeable {
     }
   }
 
-  private final synchronized void closeMergeReaders(MergePolicy.OneMerge merge, boolean suppressExceptions) throws IOException {
+  private synchronized void closeMergeReaders(MergePolicy.OneMerge merge, boolean suppressExceptions) throws IOException {
     final int numSegments = merge.segments.size();
     if (suppressExceptions) {
       // Suppress any new exceptions so we throw the
@@ -4043,7 +3315,7 @@ public class IndexWriter implements Closeable {
   /** Does the actual (time-consuming) work of the merge,
    *  but without holding synchronized lock on IndexWriter
    *  instance */
-  final private int mergeMiddle(MergePolicy.OneMerge merge) 
+  private int mergeMiddle(MergePolicy.OneMerge merge)
     throws CorruptIndexException, IOException {
     
     merge.checkAborted(directory);
@@ -4507,63 +3779,6 @@ public class IndexWriter implements Closeable {
     directory.makeLock(IndexWriter.WRITE_LOCK_NAME).release();
   }
 
-  /**
-   * Specifies maximum field length (in number of tokens/terms) in
-   * {@link IndexWriter} constructors. {@link #setMaxFieldLength(int)} overrides
-   * the value set by the constructor.
-   * 
-   * @deprecated use {@link IndexWriterConfig} and pass
-   *             {@link IndexWriterConfig#UNLIMITED_FIELD_LENGTH} or your own
-   *             value.
-   */
-  @Deprecated
-  public static final class MaxFieldLength {
-
-    private int limit;
-    private String name;
-
-    /**
-     * Private type-safe-enum-pattern constructor.
-     * 
-     * @param name instance name
-     * @param limit maximum field length
-     */
-    private MaxFieldLength(String name, int limit) {
-      this.name = name;
-      this.limit = limit;
-    }
-
-    /**
-     * Public constructor to allow users to specify the maximum field size limit.
-     * 
-     * @param limit The maximum field length
-     */
-    public MaxFieldLength(int limit) {
-      this("User-specified", limit);
-    }
-    
-    public int getLimit() {
-      return limit;
-    }
-    
-    @Override
-    public String toString()
-    {
-      return name + ":" + limit;
-    }
-
-    /** Sets the maximum field length to {@link Integer#MAX_VALUE}. */
-    public static final MaxFieldLength UNLIMITED
-        = new MaxFieldLength("UNLIMITED", Integer.MAX_VALUE);
-
-    /**
-     *  Sets the maximum field length to 
-     * {@link #DEFAULT_MAX_FIELD_LENGTH} 
-     * */
-    public static final MaxFieldLength LIMITED
-        = new MaxFieldLength("LIMITED", DEFAULT_MAX_FIELD_LENGTH);
-  }
-
   /** If {@link #getReader} has been called (ie, this writer
    *  is in near real-time mode), then after a merge
    *  completes, this class can be invoked to warm the
@@ -4582,31 +3797,6 @@ public class IndexWriter implements Closeable {
 
   private IndexReaderWarmer mergedSegmentWarmer;
 
-  /**
-   * Set the merged segment warmer. See {@link IndexReaderWarmer}.
-   * 
-   * @deprecated use
-   *             {@link IndexWriterConfig#setMergedSegmentWarmer}
-   *             instead.
-   */
-  @Deprecated
-  public void setMergedSegmentWarmer(IndexReaderWarmer warmer) {
-    mergedSegmentWarmer = warmer;
-    // Required so config.getMergedSegmentWarmer returns the right value. But
-    // this will go away together with the method in 4.0.
-    config.setMergedSegmentWarmer(mergedSegmentWarmer);
-  }
-
-  /**
-   * Returns the current merged segment warmer. See {@link IndexReaderWarmer}.
-   * 
-   * @deprecated use {@link IndexWriterConfig#getMergedSegmentWarmer()} instead.
-   */
-  @Deprecated
-  public IndexReaderWarmer getMergedSegmentWarmer() {
-    return mergedSegmentWarmer;
-  }
-
   private void handleOOM(OutOfMemoryError oom, String location) {
     if (infoStream != null) {
       message("hit OutOfMemoryError inside " + location);
diff --git a/lucene/src/java/org/apache/lucene/index/SegmentReader.java b/lucene/src/java/org/apache/lucene/index/SegmentReader.java
index 8758ea5..996a96f 100644
--- a/lucene/src/java/org/apache/lucene/index/SegmentReader.java
+++ b/lucene/src/java/org/apache/lucene/index/SegmentReader.java
@@ -1240,33 +1240,6 @@ public class SegmentReader extends IndexReader implements Cloneable {
   public final Object getCoreCacheKey() {
     return core;
   }
-  
-  /**
-   * Lotsa tests did hacks like:<br/>
-   * SegmentReader reader = (SegmentReader) IndexReader.open(dir);<br/>
-   * They broke. This method serves as a hack to keep hacks working
-   * We do it with R/W access for the tests (BW compatibility)
-   * @deprecated Remove this when tests are fixed!
-   */
-  @Deprecated
-  static SegmentReader getOnlySegmentReader(Directory dir) throws IOException {
-    return getOnlySegmentReader(IndexReader.open(dir, false));
-  }
-
-  static SegmentReader getOnlySegmentReader(IndexReader reader) {
-    if (reader instanceof SegmentReader)
-      return (SegmentReader) reader;
-
-    if (reader instanceof DirectoryReader) {
-      IndexReader[] subReaders = reader.getSequentialSubReaders();
-      if (subReaders.length != 1)
-        throw new IllegalArgumentException(reader + " has " + subReaders.length + " segments instead of exactly one");
-
-      return (SegmentReader) subReaders[0];
-    }
-
-    throw new IllegalArgumentException(reader + " is not a SegmentReader or a single-segment DirectoryReader");
-  }
 
   @Override
   public int getTermInfosIndexDivisor() {
diff --git a/lucene/src/java/org/apache/lucene/index/Term.java b/lucene/src/java/org/apache/lucene/index/Term.java
index 3903255..04e275e 100644
--- a/lucene/src/java/org/apache/lucene/index/Term.java
+++ b/lucene/src/java/org/apache/lucene/index/Term.java
@@ -168,7 +168,7 @@ public final class Term implements Comparable<Term>, java.io.Serializable {
     BytesRef.getUTF8SortedAsUTF16Comparator();
 
   /** 
-   * @deprecated For internal backwards compatibility use only
+   * @deprecated (4.0) For internal backwards compatibility use only
    * @lucene.internal
    */
   @Deprecated
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
index 7cbee48..a550963 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexCodec.java
@@ -32,7 +32,7 @@ import org.apache.lucene.index.codecs.FieldsProducer;
  *  format.  It does not provide a writer because newly
  *  written segments should use StandardCodec.
  *
- * @deprecated This is only used to read indexes created
+ * @deprecated (4.0) This is only used to read indexes created
  * before 4.0.
  * @lucene.experimental
  */
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
index f389366..c94e53b 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/PreFlexFields.java
@@ -44,7 +44,10 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.UnicodeUtil;
 
 /** Exposes flex API on a pre-flex index, as a codec. 
- * @lucene.experimental */
+ * @lucene.experimental
+ * @deprecated (4.0)
+ */
+@Deprecated
 public class PreFlexFields extends FieldsProducer {
   
   private static final boolean DEBUG_SURROGATES = false;
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermDocs.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermDocs.java
index eba65b2..e4ef40a 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermDocs.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermDocs.java
@@ -26,7 +26,7 @@ import org.apache.lucene.index.codecs.standard.DefaultSkipListReader;
 import org.apache.lucene.store.IndexInput;
 import org.apache.lucene.util.Bits;
 
-/** @deprecated 
+/** @deprecated (4.0)
  *  @lucene.experimental */
 @Deprecated
 public class SegmentTermDocs {
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
index d3bd5f1..a8703ae 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermEnum.java
@@ -26,7 +26,7 @@ import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.index.IndexFormatTooNewException;
 
 /**
- * @deprecated No longer used with flex indexing, except for
+ * @deprecated (4.0) No longer used with flex indexing, except for
  * reading old segments 
  * @lucene.experimental */
 
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermPositions.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermPositions.java
index d7492df..f50d226 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermPositions.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/SegmentTermPositions.java
@@ -23,7 +23,11 @@ import org.apache.lucene.index.FieldInfos;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.IndexInput;
 
-/** @lucene.experimental */
+/**
+ * @lucene.experimental
+ * @deprecated (4.0)
+ */
+@Deprecated
 public final class SegmentTermPositions
 extends SegmentTermDocs  {
   private IndexInput proxStream;
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
index 679469d..3880d59 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermBuffer.java
@@ -25,6 +25,11 @@ import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.FieldInfos;
 
+/**
+ * @lucene.experimental
+ * @deprecated (4.0)
+ */
+@Deprecated
 final class TermBuffer implements Cloneable {
 
   private String field;
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
index bcc12e8..8f91569 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfo.java
@@ -19,7 +19,7 @@ package org.apache.lucene.index.codecs.preflex;
 
 /** A TermInfo is the record of information stored for a
  * term
- * @deprecated This class is no longer used in flexible
+ * @deprecated (4.0) This class is no longer used in flexible
  * indexing. */
 
 @Deprecated
diff --git a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
index b633a6a..adf0535 100644
--- a/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
+++ b/lucene/src/java/org/apache/lucene/index/codecs/preflex/TermInfosReader.java
@@ -30,7 +30,7 @@ import org.apache.lucene.util.DoubleBarrelLRUCache;
 /** This stores a monotonically increasing set of <Term, TermInfo> pairs in a
  * Directory.  Pairs are accessed either by Term or by ordinal position the
  * set
- * @deprecated This class has been replaced by
+ * @deprecated (4.0) This class has been replaced by
  * FormatPostingsTermsDictReader, except for reading old segments. 
  * @lucene.experimental
  */
diff --git a/lucene/src/java/org/apache/lucene/queryParser/CharStream.java b/lucene/src/java/org/apache/lucene/queryParser/CharStream.java
index 4423996..fe1c9e7 100644
--- a/lucene/src/java/org/apache/lucene/queryParser/CharStream.java
+++ b/lucene/src/java/org/apache/lucene/queryParser/CharStream.java
@@ -28,14 +28,14 @@ public interface CharStream {
 
   /**
    * Returns the column position of the character last read.
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndColumn
    */
   int getColumn();
 
   /**
    * Returns the line number of the character last read.
-   * @deprecated
+   * @deprecated (gen)
    * @see #getEndLine
    */
   int getLine();
diff --git a/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java b/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
index d8b1610..1ac58a2 100644
--- a/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
+++ b/lucene/src/java/org/apache/lucene/queryParser/QueryParser.java
@@ -18,7 +18,6 @@ import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
@@ -77,10 +76,8 @@ import org.apache.lucene.util.VirtualMethod;
  * <tt>date:[6/1/2005 TO 6/4/2005]</tt> produces a range query that searches
  * for "date" fields between 2005-06-01 and 2005-06-04. Note that the format
  * of the accepted input depends on {@link #setLocale(Locale) the locale}.
- * By default a date is converted into a search term using the deprecated
- * {@link DateField} for compatibility reasons.
- * To use the new {@link DateTools} to convert dates, a
- * {@link org.apache.lucene.document.DateTools.Resolution} has to be set.
+ * A {@link org.apache.lucene.document.DateTools.Resolution} has to be set,
+ * if you want to use {@link DateTools} for date conversion.
  * </p>
  * <p>
  * The date resolution that shall be used for RangeQueries can be set
@@ -91,10 +88,9 @@ import org.apache.lucene.util.VirtualMethod;
  * resolutions take, if set, precedence over the default date resolution.
  * </p>
  * <p>
- * If you use neither {@link DateField} nor {@link DateTools} in your
- * index, you can create your own
+ * If you don't use {@link DateTools} in your index, you can create your own
  * query parser that inherits QueryParser and overwrites
- * {@link #getRangeQuery(String, String, String, boolean)} to
+ * {@link #getRangeQuery(String, String, String, boolean, boolean)} to
  * use a different method for date conversion.
  * </p>
  *
@@ -108,8 +104,6 @@ import org.apache.lucene.util.VirtualMethod;
  * <p><b>NOTE</b>: You must specify the required {@link Version}
  * compatibility when creating QueryParser:
  * <ul>
- *    <li> As of 2.9, {@link #setEnablePositionIncrements} is true by
- *         default.
  *    <li> As of 3.1, {@link #setAutoGeneratePhraseQueries} is false by
  *         default.
  * </ul>
diff --git a/lucene/src/java/org/apache/lucene/queryParser/QueryParser.jj b/lucene/src/java/org/apache/lucene/queryParser/QueryParser.jj
index 60568bb..dfc4ebf 100644
--- a/lucene/src/java/org/apache/lucene/queryParser/QueryParser.jj
+++ b/lucene/src/java/org/apache/lucene/queryParser/QueryParser.jj
@@ -42,7 +42,6 @@ import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
@@ -101,10 +100,8 @@ import org.apache.lucene.util.VirtualMethod;
  * <tt>date:[6/1/2005 TO 6/4/2005]</tt> produces a range query that searches
  * for "date" fields between 2005-06-01 and 2005-06-04. Note that the format
  * of the accepted input depends on {@link #setLocale(Locale) the locale}.
- * By default a date is converted into a search term using the deprecated
- * {@link DateField} for compatibility reasons.
- * To use the new {@link DateTools} to convert dates, a
- * {@link org.apache.lucene.document.DateTools.Resolution} has to be set.
+ * A {@link org.apache.lucene.document.DateTools.Resolution} has to be set,
+ * if you want to use {@link DateTools} for date conversion.
  * </p>
  * <p>
  * The date resolution that shall be used for RangeQueries can be set
@@ -115,10 +112,9 @@ import org.apache.lucene.util.VirtualMethod;
  * resolutions take, if set, precedence over the default date resolution.
  * </p>
  * <p>
- * If you use neither {@link DateField} nor {@link DateTools} in your
- * index, you can create your own
+ * If you don't use {@link DateTools} in your index, you can create your own
  * query parser that inherits QueryParser and overwrites
- * {@link #getRangeQuery(String, String, String, boolean)} to
+ * {@link #getRangeQuery(String, String, String, boolean, boolean)} to
  * use a different method for date conversion.
  * </p>
  *
@@ -132,8 +128,6 @@ import org.apache.lucene.util.VirtualMethod;
  * <p><b>NOTE</b>: You must specify the required {@link Version}
  * compatibility when creating QueryParser:
  * <ul>
- *    <li> As of 2.9, {@link #setEnablePositionIncrements} is true by
- *         default.
  *    <li> As of 3.1, {@link #setAutoGeneratePhraseQueries} is false by
  *         default.
  * </ul>
diff --git a/lucene/src/java/org/apache/lucene/queryParser/QueryParserBase.java b/lucene/src/java/org/apache/lucene/queryParser/QueryParserBase.java
index 8422df7..c9e0a34 100644
--- a/lucene/src/java/org/apache/lucene/queryParser/QueryParserBase.java
+++ b/lucene/src/java/org/apache/lucene/queryParser/QueryParserBase.java
@@ -17,25 +17,23 @@
 
 package org.apache.lucene.queryParser;
 
+import java.io.IOException;
+import java.io.StringReader;
+import java.text.Collator;
+import java.text.DateFormat;
+import java.util.*;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.index.Term;
+import org.apache.lucene.queryParser.QueryParser.Operator;
 import org.apache.lucene.search.*;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.Version;
-import org.apache.lucene.util.VirtualMethod;
-import org.apache.lucene.queryParser.QueryParser.Operator;
-
-import java.io.IOException;
-import java.io.StringReader;
-import java.text.Collator;
-import java.text.DateFormat;
-import java.util.*;
 
 /** This class is overridden by QueryParser in QueryParser.jj
  * and acts to eparate the majority of the Java code from the .jj grammar file. 
@@ -84,20 +82,6 @@ public abstract class QueryParserBase {
   // for use when constructing RangeQuerys.
   Collator rangeCollator = null;
 
-  /** @deprecated remove when getFieldQuery is removed */
-  @Deprecated
-  static final VirtualMethod<QueryParserBase> getFieldQueryMethod =
-    new VirtualMethod<QueryParserBase>(QueryParserBase.class, "getFieldQuery", String.class, String.class);
-  /** @deprecated remove when getFieldQuery is removed */
-  @Deprecated
-  static final VirtualMethod<QueryParserBase> getFieldQueryWithQuotedMethod =
-    new VirtualMethod<QueryParserBase>(QueryParserBase.class, "getFieldQuery", String.class, String.class, boolean.class);
-  /** @deprecated remove when getFieldQuery is removed */
-  @Deprecated
-  final boolean hasNewAPI =
-    VirtualMethod.compareImplementationDistance(getClass(),
-        getFieldQueryWithQuotedMethod, getFieldQueryMethod) >= 0; // its ok for both to be overridden
-
   boolean autoGeneratePhraseQueries;
 
   // So the generated QueryParser(CharStream) won't error out
@@ -112,11 +96,6 @@ public abstract class QueryParserBase {
   public void init(Version matchVersion, String f, Analyzer a) {
     analyzer = a;
     field = f;
-    if (matchVersion.onOrAfter(Version.LUCENE_29)) {
-      enablePositionIncrements = true;
-    } else {
-      enablePositionIncrements = false;
-    }
     if (matchVersion.onOrAfter(Version.LUCENE_31)) {
       setAutoGeneratePhraseQueries(false);
     } else {
@@ -190,9 +169,6 @@ public abstract class QueryParserBase {
    * surrounded by double quotes.
    */
   public final void setAutoGeneratePhraseQueries(boolean value) {
-    if (value == false && !hasNewAPI)
-      throw new IllegalArgumentException("You must implement the new API: getFieldQuery(String,String,boolean)"
-       + " to use setAutoGeneratePhraseQueries(false)");
     this.autoGeneratePhraseQueries = value;
   }
 
@@ -272,7 +248,7 @@ public abstract class QueryParserBase {
    * Useful when e.g. a StopFilter increases the position increment of
    * the token that follows an omitted token.
    * <p>
-   * Default: false.
+   * Default: true.
    */
   public void setEnablePositionIncrements(boolean enable) {
     this.enablePositionIncrements = enable;
@@ -489,15 +465,6 @@ public abstract class QueryParserBase {
   }
 
   /**
-   * @deprecated Use {@link #getFieldQuery(String,String,boolean)} instead.
-   */
-  @Deprecated
-  protected Query getFieldQuery(String field, String queryText) throws ParseException {
-    // treat the text as if it was quoted, to drive phrase logic with old versions.
-    return getFieldQuery(field, queryText, true);
-  }
-
-  /**
    * @exception org.apache.lucene.queryParser.ParseException throw in overridden method to disallow
    */
   protected Query getFieldQuery(String field, String queryText, boolean quoted)  throws ParseException {
@@ -684,7 +651,7 @@ public abstract class QueryParserBase {
    */
   protected Query getFieldQuery(String field, String queryText, int slop)
         throws ParseException {
-    Query query = hasNewAPI ? getFieldQuery(field, queryText, true) : getFieldQuery(field, queryText);
+    Query query = getFieldQuery(field, queryText, true);
 
     if (query instanceof PhraseQuery) {
       ((PhraseQuery) query).setSlop(slop);
@@ -696,11 +663,6 @@ public abstract class QueryParserBase {
     return query;
   }
 
-
-  @Deprecated
-  protected final Query getRangeQuery(String field, String part1, String part2, boolean inclusive) throws MethodRemovedUseAnother {return null;}
-
-
   /**
    *
    * @exception org.apache.lucene.queryParser.ParseException
@@ -722,15 +684,7 @@ public abstract class QueryParserBase {
     DateTools.Resolution resolution = getDateResolution(field);
     
     try {
-      Date d1 = df.parse(part1);
-      if (resolution == null) {
-        // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibility with
-        // pre-1.9 Lucene versions.
-        part1 = DateField.dateToString(d1);
-      } else {
-        part1 = DateTools.dateToString(d1, resolution);
-      }
+      part1 = DateTools.dateToString(df.parse(part1), resolution);
     } catch (Exception e) { }
 
     try {
@@ -747,14 +701,7 @@ public abstract class QueryParserBase {
         cal.set(Calendar.MILLISECOND, 999);
         d2 = cal.getTime();
       }
-      if (resolution == null) {
-        // no default or field specific date resolution has been set,
-        // use deprecated DateField to maintain compatibility with
-        // pre-1.9 Lucene versions.
-        part2 = DateField.dateToString(d2);
-      } else {
-        part2 = DateTools.dateToString(d2, resolution);
-      }
+      part2 = DateTools.dateToString(d2, resolution);
     } catch (Exception e) { }
 
     return newRangeQuery(field, part1, part2, startInclusive, endInclusive);
@@ -838,10 +785,6 @@ public abstract class QueryParserBase {
     return new FuzzyQuery(term,minimumSimilarity,prefixLength);
   }
 
-  @Deprecated
-  protected final Query newRangeQuery(String field, String part1, String part2, boolean inclusive) throws MethodRemovedUseAnother {return null;}
-
-
   /**
    * Builds a new TermRangeQuery instance
    * @param field Field
@@ -1064,7 +1007,7 @@ public abstract class QueryParserBase {
       }
       q = getFuzzyQuery(qfield, termImage, fms);
     } else {
-      q = hasNewAPI ? getFieldQuery(qfield, termImage, false) : getFieldQuery(qfield, termImage);
+      q = getFieldQuery(qfield, termImage, false);
     }
     return q;
   }
diff --git a/lucene/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java b/lucene/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
index 7aa46a1..8fedc1f 100644
--- a/lucene/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
+++ b/lucene/src/java/org/apache/lucene/queryParser/QueryParserTokenManager.java
@@ -16,7 +16,6 @@ import org.apache.lucene.analysis.CachingTokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TermToBytesRefAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
diff --git a/lucene/src/java/org/apache/lucene/search/BooleanScorer2.java b/lucene/src/java/org/apache/lucene/search/BooleanScorer2.java
index 74d277d..c8dcf2e 100644
--- a/lucene/src/java/org/apache/lucene/search/BooleanScorer2.java
+++ b/lucene/src/java/org/apache/lucene/search/BooleanScorer2.java
@@ -193,7 +193,7 @@ class BooleanScorer2 extends Scorer {
   }
 
   private Scorer dualConjunctionSumScorer(Scorer req1, Scorer req2) throws IOException { // non counting.
-    return new ConjunctionScorer(defaultSimilarity, new Scorer[]{req1, req2});
+    return new ConjunctionScorer(defaultSimilarity, req1, req2);
     // All scorers match, so defaultSimilarity always has 1 as
     // the coordination factor.
     // Therefore the sum of the scores of two scorers
diff --git a/lucene/src/java/org/apache/lucene/search/Similarity.java b/lucene/src/java/org/apache/lucene/search/Similarity.java
index 4fe51bf..d97095c 100644
--- a/lucene/src/java/org/apache/lucene/search/Similarity.java
+++ b/lucene/src/java/org/apache/lucene/search/Similarity.java
@@ -18,15 +18,15 @@ package org.apache.lucene.search;
  */
 
 
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.Collection;
+
 import org.apache.lucene.index.FieldInvertState;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.Explanation.IDFExplanation;
 import org.apache.lucene.util.SmallFloat;
 
-import java.io.IOException;
-import java.io.Serializable;
-import java.util.Collection;
-
 
 /** 
  * Expert: Scoring API.
@@ -562,16 +562,6 @@ public abstract class Similarity implements Serializable {
       NORM_TABLE[i] = SmallFloat.byte315ToFloat((byte)i);
   }
 
-  /**
-   * Decodes a normalization factor stored in an index.
-   * @see #decodeNormValue(byte)
-   * @deprecated Use {@link #decodeNormValue} instead.
-   */
-  @Deprecated
-  public static float decodeNorm(byte b) {
-    return NORM_TABLE[b & 0xFF];  // & 0xFF maps negative bytes to positive above 127
-  }
-
   /** Decodes a normalization factor stored in an index.
    * @see #encodeNormValue(float)
    */
@@ -579,17 +569,6 @@ public abstract class Similarity implements Serializable {
     return NORM_TABLE[b & 0xFF];  // & 0xFF maps negative bytes to positive above 127
   }
 
-  /** Returns a table for decoding normalization bytes.
-   * @see #encodeNormValue(float)
-   * @see #decodeNormValue(byte)
-   * 
-   * @deprecated Use instance methods for encoding/decoding norm values to enable customization.
-   */
-  @Deprecated
-  public static float[] getNormDecoder() {
-    return NORM_TABLE;
-  }
-
   /**
    * Compute the normalization value for a field, given the accumulated
    * state of term processing for this field (see {@link FieldInvertState}).
@@ -670,20 +649,6 @@ public abstract class Similarity implements Serializable {
     return SmallFloat.floatToByte315(f);
   }
   
-  /**
-   * Static accessor kept for backwards compability reason, use encodeNormValue instead.
-   * @param f norm-value to encode
-   * @return byte representing the given float
-   * @deprecated Use {@link #encodeNormValue} instead.
-   * 
-   * @see #encodeNormValue(float)
-   */
-  @Deprecated
-  public static byte encodeNorm(float f) {
-    return SmallFloat.floatToByte315(f);
-  }
-
-
   /** Computes a score factor based on a term or phrase's frequency in a
    * document.  This value is multiplied by the {@link #idf(int, int)}
    * factor for each term in the query and these products are then summed to
diff --git a/lucene/src/java/org/apache/lucene/search/SortField.java b/lucene/src/java/org/apache/lucene/search/SortField.java
index 58c4582..e058002 100644
--- a/lucene/src/java/org/apache/lucene/search/SortField.java
+++ b/lucene/src/java/org/apache/lucene/search/SortField.java
@@ -21,13 +21,7 @@ import java.io.IOException;
 import java.io.Serializable;
 import java.util.Locale;
 
-import org.apache.lucene.search.cache.ByteValuesCreator;
-import org.apache.lucene.search.cache.CachedArrayCreator;
-import org.apache.lucene.search.cache.DoubleValuesCreator;
-import org.apache.lucene.search.cache.FloatValuesCreator;
-import org.apache.lucene.search.cache.IntValuesCreator;
-import org.apache.lucene.search.cache.LongValuesCreator;
-import org.apache.lucene.search.cache.ShortValuesCreator;
+import org.apache.lucene.search.cache.*;
 import org.apache.lucene.util.StringHelper;
 
 /**
@@ -138,7 +132,7 @@ implements Serializable {
    * @throws IllegalArgumentException if the parser fails to
    *  subclass an existing numeric parser, or field is null
    *  
-   *  @deprecated use EntryCreator version
+   *  @deprecated (4.0) use EntryCreator version
    */
   @Deprecated
   public SortField (String field, FieldCache.Parser parser) {
@@ -156,7 +150,7 @@ implements Serializable {
    * @throws IllegalArgumentException if the parser fails to
    *  subclass an existing numeric parser, or field is null
    *  
-   *  @deprecated use EntryCreator version
+   *  @deprecated (4.0) use EntryCreator version
    */
   @Deprecated
   public SortField (String field, FieldCache.Parser parser, boolean reverse) {
@@ -314,7 +308,7 @@ implements Serializable {
   /** Returns the instance of a {@link FieldCache} parser that fits to the given sort type.
    * May return <code>null</code> if no parser was specified. Sorting is using the default parser then.
    * @return An instance of a {@link FieldCache} parser, or <code>null</code>.
-   * @deprecated use getEntryCreator()
+   * @deprecated (4.0) use getEntryCreator()
    */
   @Deprecated
   public FieldCache.Parser getParser() {
diff --git a/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java b/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
index 5c00388..5b9ab4e 100644
--- a/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
+++ b/lucene/src/java/org/apache/lucene/search/TermRangeQuery.java
@@ -20,10 +20,10 @@ package org.apache.lucene.search;
 import java.io.IOException;
 import java.text.Collator;
 
-import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.index.Terms;
-import org.apache.lucene.util.ToStringUtils;
+import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.util.AttributeSource;
+import org.apache.lucene.util.ToStringUtils;
 
 /**
  * A Query that matches documents within an range of terms.
@@ -143,12 +143,6 @@ public class TermRangeQuery extends MultiTermQuery {
         lowerTerm, upperTerm, includeLower, includeUpper, collator);
   }
 
-  /** @deprecated */
-  @Deprecated
-  public String field() {
-    return getField();
-  }
-
   /** Prints a user-readable version of this query. */
   @Override
   public String toString(String field) {
diff --git a/lucene/src/java/org/apache/lucene/search/function/MultiValueSource.java b/lucene/src/java/org/apache/lucene/search/function/MultiValueSource.java
index 39991fa..534cd12 100644
--- a/lucene/src/java/org/apache/lucene/search/function/MultiValueSource.java
+++ b/lucene/src/java/org/apache/lucene/search/function/MultiValueSource.java
@@ -19,9 +19,9 @@ package org.apache.lucene.search.function;
 
 import java.io.IOException;
 
-import org.apache.lucene.util.ReaderUtil;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.search.Explanation;
+import org.apache.lucene.util.ReaderUtil;
 
 /** This class wraps another ValueSource, but protects
  *  against accidental double RAM usage in FieldCache when
@@ -31,7 +31,7 @@ import org.apache.lucene.search.Explanation;
  *  lookup, as it must resolve the incoming document to the
  *  right sub-reader using a binary search.</p>
  *
- *  @deprecated This class is temporary, to ease the
+ *  @deprecated (4.0) This class is temporary, to ease the
  *  migration to segment-based searching. Please change your
  *  code to not pass composite readers to these APIs. */
 
diff --git a/lucene/src/java/org/apache/lucene/store/DataOutput.java b/lucene/src/java/org/apache/lucene/store/DataOutput.java
index 8a3f995..1db4d90 100644
--- a/lucene/src/java/org/apache/lucene/store/DataOutput.java
+++ b/lucene/src/java/org/apache/lucene/store/DataOutput.java
@@ -105,59 +105,6 @@ public abstract class DataOutput {
     writeBytes(utf8Result.bytes, 0, utf8Result.length);
   }
 
-  /** Writes a sub sequence of characters from s as the old
-   *  format (modified UTF-8 encoded bytes).
-   * @param s the source of the characters
-   * @param start the first character in the sequence
-   * @param length the number of characters in the sequence
-   * @deprecated -- please pre-convert to utf8 bytes
-   * instead or use {@link #writeString}
-   */
-  @Deprecated
-  public void writeChars(String s, int start, int length)
-       throws IOException {
-    final int end = start + length;
-    for (int i = start; i < end; i++) {
-      final int code = s.charAt(i);
-      if (code >= 0x01 && code <= 0x7F)
-        writeByte((byte)code);
-      else if (((code >= 0x80) && (code <= 0x7FF)) || code == 0) {
-        writeByte((byte)(0xC0 | (code >> 6)));
-        writeByte((byte)(0x80 | (code & 0x3F)));
-      } else {
-        writeByte((byte)(0xE0 | (code >>> 12)));
-        writeByte((byte)(0x80 | ((code >> 6) & 0x3F)));
-        writeByte((byte)(0x80 | (code & 0x3F)));
-      }
-    }
-  }
-
-  /** Writes a sub sequence of characters from char[] as
-   *  the old format (modified UTF-8 encoded bytes).
-   * @param s the source of the characters
-   * @param start the first character in the sequence
-   * @param length the number of characters in the sequence
-   * @deprecated -- please pre-convert to utf8 bytes instead or use {@link #writeString}
-   */
-  @Deprecated
-  public void writeChars(char[] s, int start, int length)
-    throws IOException {
-    final int end = start + length;
-    for (int i = start; i < end; i++) {
-      final int code = s[i];
-      if (code >= 0x01 && code <= 0x7F)
-        writeByte((byte)code);
-      else if (((code >= 0x80) && (code <= 0x7FF)) || code == 0) {
-        writeByte((byte)(0xC0 | (code >> 6)));
-        writeByte((byte)(0x80 | (code & 0x3F)));
-      } else {
-        writeByte((byte)(0xE0 | (code >>> 12)));
-        writeByte((byte)(0x80 | ((code >> 6) & 0x3F)));
-        writeByte((byte)(0x80 | (code & 0x3F)));
-      }
-    }
-  }
-
   private static int COPY_BUFFER_SIZE = 16384;
   private byte[] copyBuffer;
 
diff --git a/lucene/src/java/org/apache/lucene/store/Directory.java b/lucene/src/java/org/apache/lucene/store/Directory.java
index 348aa96..1dc59ad 100644
--- a/lucene/src/java/org/apache/lucene/store/Directory.java
+++ b/lucene/src/java/org/apache/lucene/store/Directory.java
@@ -95,19 +95,6 @@ public abstract class Directory implements Closeable {
        throws IOException;
 
   /**
-   * Ensure that any writes to this file are moved to
-   * stable storage.  Lucene uses this to properly commit
-   * changes to the index, to prevent a machine/OS crash
-   * from corrupting the index.
-   * @deprecated use {@link #sync(Collection)} instead.
-   * For easy migration you can change your code to call
-   * sync(Collections.singleton(name))
-   */
-  @Deprecated
-  public void sync(String name) throws IOException { // TODO 4.0 kill me
-  }
-
-  /**
    * Ensure that any writes to these files are moved to
    * stable storage.  Lucene uses this to properly commit
    * changes to the index, to prevent a machine/OS crash
@@ -118,10 +105,7 @@ public abstract class Directory implements Closeable {
    * For other impls the operation can be a noop, for various
    * reasons.
    */
-  public void sync(Collection<String> names) throws IOException { // TODO 4.0 make me abstract
-    for (String name : names)
-      sync(name);
-  }
+  public abstract void sync(Collection<String> names) throws IOException;
 
   /** Returns a stream reading an existing file. */
   public abstract IndexInput openInput(String name)
@@ -233,41 +217,6 @@ public abstract class Directory implements Closeable {
   }
 
   /**
-   * Copy contents of a directory src to a directory dest. If a file in src
-   * already exists in dest then the one in dest will be blindly overwritten.
-   * <p>
-   * <b>NOTE:</b> the source directory cannot change while this method is
-   * running. Otherwise the results are undefined and you could easily hit a
-   * FileNotFoundException.
-   * <p>
-   * <b>NOTE:</b> this method only copies files that look like index files (ie,
-   * have extensions matching the known extensions of index files).
-   * 
-   * @param src source directory
-   * @param dest destination directory
-   * @param closeDirSrc if <code>true</code>, call {@link #close()} method on 
-   *        source directory
-   * @deprecated should be replaced with calls to
-   *             {@link #copy(Directory, String, String)} for every file that
-   *             needs copying. You can use the following code:
-   * 
-   * <pre>
-   * for (String file : src.listAll()) {
-   *   src.copy(dest, file, file);
-   * }
-   * </pre>
-   */
-  @Deprecated
-  public static void copy(Directory src, Directory dest, boolean closeDirSrc) throws IOException {
-    for (String file : src.listAll()) {
-      src.copy(dest, file, file);
-    }
-    if (closeDirSrc) {
-      src.close();
-    }
-  }
-
-  /**
    * @throws AlreadyClosedException if this Directory is closed
    */
   protected final void ensureOpen() throws AlreadyClosedException {
diff --git a/lucene/src/java/org/apache/lucene/store/FSDirectory.java b/lucene/src/java/org/apache/lucene/store/FSDirectory.java
index 0a84803..2083086 100644
--- a/lucene/src/java/org/apache/lucene/store/FSDirectory.java
+++ b/lucene/src/java/org/apache/lucene/store/FSDirectory.java
@@ -321,12 +321,6 @@ public abstract class FSDirectory extends Directory {
     staleFiles.add(io.name);
   }
 
-  @Deprecated
-  @Override
-  public void sync(String name) throws IOException {
-    sync(Collections.singleton(name));
-  }
-
   @Override
   public void sync(Collection<String> names) throws IOException {
     ensureOpen();
@@ -383,12 +377,6 @@ public abstract class FSDirectory extends Directory {
     isOpen = false;
   }
 
-  /** @deprecated Use {@link #getDirectory} instead. */
-  @Deprecated
-  public File getFile() {
-    return getDirectory();
-  }
-
   /** @return the underlying filesystem directory */
   public File getDirectory() {
     ensureOpen();
diff --git a/lucene/src/java/org/apache/lucene/store/FileSwitchDirectory.java b/lucene/src/java/org/apache/lucene/store/FileSwitchDirectory.java
index fe00c61..2e473be 100644
--- a/lucene/src/java/org/apache/lucene/store/FileSwitchDirectory.java
+++ b/lucene/src/java/org/apache/lucene/store/FileSwitchDirectory.java
@@ -135,12 +135,6 @@ public class FileSwitchDirectory extends Directory {
     return getDirectory(name).createOutput(name);
   }
 
-  @Deprecated
-  @Override
-  public void sync(String name) throws IOException {
-    sync(Collections.singleton(name));
-  }
-
   @Override
   public void sync(Collection<String> names) throws IOException {
     List<String> primaryNames = new ArrayList<String>();
diff --git a/lucene/src/java/org/apache/lucene/store/NoLockFactory.java b/lucene/src/java/org/apache/lucene/store/NoLockFactory.java
index 242e782..70c835a 100755
--- a/lucene/src/java/org/apache/lucene/store/NoLockFactory.java
+++ b/lucene/src/java/org/apache/lucene/store/NoLockFactory.java
@@ -33,14 +33,7 @@ public class NoLockFactory extends LockFactory {
   private static NoLock singletonLock = new NoLock();
   private static NoLockFactory singleton = new NoLockFactory();
   
-  /**
-   * @deprecated This constructor was not intended to be public and should not be used.
-   *  It will be made private in Lucene 4.0
-   * @see #getNoLockFactory()
-   */
-  // make private in 4.0!
-  @Deprecated
-  public NoLockFactory() {}
+  private NoLockFactory() {}
 
   public static NoLockFactory getNoLockFactory() {
     return singleton;
diff --git a/lucene/src/java/org/apache/lucene/store/RAMDirectory.java b/lucene/src/java/org/apache/lucene/store/RAMDirectory.java
index 4c3073a..8be9ddd 100644
--- a/lucene/src/java/org/apache/lucene/store/RAMDirectory.java
+++ b/lucene/src/java/org/apache/lucene/store/RAMDirectory.java
@@ -20,6 +20,7 @@ package org.apache.lucene.store;
 import java.io.IOException;
 import java.io.FileNotFoundException;
 import java.io.Serializable;
+import java.util.Collection;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.atomic.AtomicLong;
@@ -187,6 +188,9 @@ public class RAMDirectory extends Directory implements Serializable {
     return new RAMFile(this);
   }
 
+  public void sync(Collection<String> names) throws IOException {
+  }
+
   /** Returns a stream reading an existing file. */
   @Override
   public IndexInput openInput(String name) throws IOException {
diff --git a/lucene/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java b/lucene/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
index 8950cc8..d7f4c92 100644
--- a/lucene/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
+++ b/lucene/src/java/org/apache/lucene/util/IndexableBinaryStringTools.java
@@ -37,19 +37,6 @@ import java.nio.ByteBuffer;
  * problem, a char is appended, indicating the number of encoded bytes in the
  * final content char.
  * <p/>
- * Some methods in this class are defined over CharBuffers and ByteBuffers, but
- * these are deprecated in favor of methods that operate directly on byte[] and
- * char[] arrays.  Note that this class calls array() and arrayOffset()
- * on the CharBuffers and ByteBuffers it uses, so only wrapped arrays may be
- * used.  This class interprets the arrayOffset() and limit() values returned 
- * by its input buffers as beginning and end+1 positions on the wrapped array,
- * respectively; similarly, on the output buffer, arrayOffset() is the first
- * position written to, and limit() is set to one past the final output array
- * position.
- * <p/>
- * WARNING: This means that the deprecated Buffer-based methods 
- * only work correctly with buffers that have an offset of 0. For example, they
- * will not correctly interpret buffers returned by {@link ByteBuffer#slice}.  
  *
  * @lucene.experimental
  */
@@ -72,28 +59,6 @@ public final class IndexableBinaryStringTools {
   private IndexableBinaryStringTools() {}
 
   /**
-   * Returns the number of chars required to encode the given byte sequence.
-   * 
-   * @param original The byte sequence to be encoded. Must be backed by an
-   *        array.
-   * @return The number of chars required to encode the given byte sequence
-   * @throws IllegalArgumentException If the given ByteBuffer is not backed by
-   *         an array
-   * @deprecated Use {@link #getEncodedLength(byte[], int, int)} instead. This
-   *             method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static int getEncodedLength(ByteBuffer original)
-    throws IllegalArgumentException {
-    if (original.hasArray()) {
-      return getEncodedLength(original.array(), original.arrayOffset(),
-          original.limit() - original.arrayOffset());
-    } else {
-      throw new IllegalArgumentException("original argument must have a backing array");
-    }
-  }
-  
-  /**
    * Returns the number of chars required to encode the given bytes.
    * 
    * @param inputArray byte sequence to be encoded
@@ -107,28 +72,6 @@ public final class IndexableBinaryStringTools {
     return (int)((8L * inputLength + 14L) / 15L) + 1;
   }
 
-
-  /**
-   * Returns the number of bytes required to decode the given char sequence.
-   * 
-   * @param encoded The char sequence to be decoded. Must be backed by an array.
-   * @return The number of bytes required to decode the given char sequence
-   * @throws IllegalArgumentException If the given CharBuffer is not backed by
-   *         an array
-   * @deprecated Use {@link #getDecodedLength(char[], int, int)} instead. This
-   *             method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static int getDecodedLength(CharBuffer encoded) 
-    throws IllegalArgumentException {
-    if (encoded.hasArray()) {
-      return getDecodedLength(encoded.array(), encoded.arrayOffset(), 
-          encoded.limit() - encoded.arrayOffset());
-    } else {
-      throw new IllegalArgumentException("encoded argument must have a backing array");
-    }
-  }
-  
   /**
    * Returns the number of bytes required to decode the given char sequence.
    * 
@@ -150,36 +93,6 @@ public final class IndexableBinaryStringTools {
   }
 
   /**
-   * Encodes the input byte sequence into the output char sequence. Before
-   * calling this method, ensure that the output CharBuffer has sufficient
-   * capacity by calling {@link #getEncodedLength(java.nio.ByteBuffer)}.
-   * 
-   * @param input The byte sequence to encode
-   * @param output Where the char sequence encoding result will go. The limit is
-   *        set to one past the position of the final char.
-   * @throws IllegalArgumentException If either the input or the output buffer
-   *         is not backed by an array
-   * @deprecated Use {@link #encode(byte[], int, int, char[], int, int)}
-   *             instead. This method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static void encode(ByteBuffer input, CharBuffer output) {
-    if (input.hasArray() && output.hasArray()) {
-      final int inputOffset = input.arrayOffset();
-      final int inputLength = input.limit() - inputOffset;
-      final int outputOffset = output.arrayOffset();
-      final int outputLength = getEncodedLength(input.array(), inputOffset,
-          inputLength);
-      output.limit(outputLength + outputOffset);
-      output.position(0);
-      encode(input.array(), inputOffset, inputLength, output.array(),
-          outputOffset, outputLength);
-    } else {
-      throw new IllegalArgumentException("Arguments must have backing arrays");
-    }
-  }
-  
-  /**
    * Encodes the input byte sequence into the output char sequence.  Before
    * calling this method, ensure that the output array has sufficient
    * capacity by calling {@link #getEncodedLength(byte[], int, int)}.
@@ -235,36 +148,6 @@ public final class IndexableBinaryStringTools {
 
   /**
    * Decodes the input char sequence into the output byte sequence. Before
-   * calling this method, ensure that the output ByteBuffer has sufficient
-   * capacity by calling {@link #getDecodedLength(java.nio.CharBuffer)}.
-   * 
-   * @param input The char sequence to decode
-   * @param output Where the byte sequence decoding result will go. The limit is
-   *        set to one past the position of the final char.
-   * @throws IllegalArgumentException If either the input or the output buffer
-   *         is not backed by an array
-   * @deprecated Use {@link #decode(char[], int, int, byte[], int, int)}
-   *             instead. This method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static void decode(CharBuffer input, ByteBuffer output) {
-    if (input.hasArray() && output.hasArray()) {
-      final int inputOffset = input.arrayOffset();
-      final int inputLength = input.limit() - inputOffset;
-      final int outputOffset = output.arrayOffset();
-      final int outputLength = getDecodedLength(input.array(), inputOffset,
-          inputLength);
-      output.limit(outputLength + outputOffset);
-      output.position(0);
-      decode(input.array(), inputOffset, inputLength, output.array(),
-          outputOffset, outputLength);
-    } else {
-      throw new IllegalArgumentException("Arguments must have backing arrays");
-    }
-  }
-
-  /**
-   * Decodes the input char sequence into the output byte sequence. Before
    * calling this method, ensure that the output array has sufficient capacity
    * by calling {@link #getDecodedLength(char[], int, int)}.
    * 
@@ -330,46 +213,6 @@ public final class IndexableBinaryStringTools {
     }
   }
 
-  /**
-   * Decodes the given char sequence, which must have been encoded by
-   * {@link #encode(java.nio.ByteBuffer)} or
-   * {@link #encode(java.nio.ByteBuffer, java.nio.CharBuffer)}.
-   * 
-   * @param input The char sequence to decode
-   * @return A byte sequence containing the decoding result. The limit is set to
-   *         one past the position of the final char.
-   * @throws IllegalArgumentException If the input buffer is not backed by an
-   *         array
-   * @deprecated Use {@link #decode(char[], int, int, byte[], int, int)}
-   *             instead. This method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static ByteBuffer decode(CharBuffer input) {
-    byte[] outputArray = new byte[getDecodedLength(input)];
-    ByteBuffer output = ByteBuffer.wrap(outputArray);
-    decode(input, output);
-    return output;
-  }
-
-  /**
-   * Encodes the input byte sequence.
-   * 
-   * @param input The byte sequence to encode
-   * @return A char sequence containing the encoding result. The limit is set to
-   *         one past the position of the final char.
-   * @throws IllegalArgumentException If the input buffer is not backed by an
-   *         array
-   * @deprecated Use {@link #encode(byte[], int, int, char[], int, int)}
-   *             instead. This method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static CharBuffer encode(ByteBuffer input) {
-    char[] outputArray = new char[getEncodedLength(input)];
-    CharBuffer output = CharBuffer.wrap(outputArray);
-    encode(input, output);
-    return output;
-  }
-  
   static class CodingCase {
     int numBytes, initialShift, middleShift, finalShift, advanceBytes = 2;
     short middleMask, finalMask;
diff --git a/lucene/src/java/org/apache/lucene/util/NumericUtils.java b/lucene/src/java/org/apache/lucene/util/NumericUtils.java
index 7d2a5c2..000de67 100644
--- a/lucene/src/java/org/apache/lucene/util/NumericUtils.java
+++ b/lucene/src/java/org/apache/lucene/util/NumericUtils.java
@@ -17,10 +17,10 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.NumericTokenStream; // for javadocs
-import org.apache.lucene.document.NumericField; // for javadocs
+import org.apache.lucene.analysis.NumericTokenStream;
+import org.apache.lucene.document.NumericField;
+import org.apache.lucene.search.NumericRangeFilter;
 import org.apache.lucene.search.NumericRangeQuery; // for javadocs
-import org.apache.lucene.search.NumericRangeFilter; // for javadocs
 
 // TODO: Remove the commented out methods before release!
 
@@ -130,32 +130,6 @@ public final class NumericUtils {
     return hash;
   }
 
-  /*
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link LongRangeBuilder}.
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String longToPrefixCoded(final long val, final int shift) {
-    final BytesRef buffer = new BytesRef(BUF_SIZE_LONG);
-    longToPrefixCoded(val, shift, buffer);
-    return buffer.utf8ToString();
-  }*/
-
-  /*
-   * This is a convenience method, that returns prefix coded bits of a long without
-   * reducing the precision. It can be used to store the full precision value as a
-   * stored field in index.
-   * <p>To decode, use {@link #prefixCodedToLong}.
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String longToPrefixCoded(final long val) {
-    return longToPrefixCoded(val, 0);
-  }*/
-  
   /**
    * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
    * This is method is used by {@link NumericTokenStream}.
@@ -190,46 +164,6 @@ public final class NumericUtils {
     return hash;
   }
 
-  /*
-   * Returns prefix coded bits after reducing the precision by <code>shift</code> bits.
-   * This is method is used by {@link IntRangeBuilder}.
-   * @param val the numeric value
-   * @param shift how many bits to strip from the right
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String intToPrefixCoded(final int val, final int shift) {
-    final BytesRef buffer = new BytesRef(BUF_SIZE_INT);
-    intToPrefixCoded(val, shift, buffer);
-    return buffer.utf8ToString();
-  }*/
-
-  /*
-   * This is a convenience method, that returns prefix coded bits of an int without
-   * reducing the precision. It can be used to store the full precision value as a
-   * stored field in index.
-   * <p>To decode, use {@link #prefixCodedToInt}.
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String intToPrefixCoded(final int val) {
-    return intToPrefixCoded(val, 0);
-  }*/
-
-  /*
-   * Returns a long from prefixCoded characters.
-   * Rightmost bits will be zero for lower precision codes.
-   * This method can be used to decode e.g. a stored field.
-   * @throws NumberFormatException if the supplied string is
-   * not correctly prefix encoded.
-   * @see #longToPrefixCoded(long)
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static long prefixCodedToLong(final String prefixCoded) {
-    return prefixCodedToLong(new BytesRef(prefixCoded));
-  }*/
-
   /**
    * Returns the shift value from a prefix encoded {@code long}.
    * @throws NumberFormatException if the supplied {@link BytesRef} is
@@ -278,21 +212,7 @@ public final class NumericUtils {
     return (sortableBits << getPrefixCodedLongShift(val)) ^ 0x8000000000000000L;
   }
 
-  /*
-   * Returns an int from prefixCoded characters.
-   * Rightmost bits will be zero for lower precision codes.
-   * This method can be used to decode a term's value.
-   * @throws NumberFormatException if the supplied string is
-   * not correctly prefix encoded.
-   * @see #intToPrefixCoded(int)
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static int prefixCodedToInt(final String prefixCoded) {
-    return prefixCodedToInt(new BytesRef(prefixCoded));
-  }*/
-
-  /*
+  /**
    * Returns an int from prefixCoded bytes.
    * Rightmost bits will be zero for lower precision codes.
    * This method can be used to decode a term's value.
@@ -329,16 +249,6 @@ public final class NumericUtils {
     return f;
   }
 
-  /*
-   * Convenience method: this just returns:
-   *   longToPrefixCoded(doubleToSortableLong(val))
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String doubleToPrefixCoded(double val) {
-    return longToPrefixCoded(doubleToSortableLong(val));
-  }*/
-
   /**
    * Converts a sortable <code>long</code> back to a <code>double</code>.
    * @see #doubleToSortableLong
@@ -348,16 +258,6 @@ public final class NumericUtils {
     return Double.longBitsToDouble(val);
   }
 
-  /*
-   * Convenience method: this just returns:
-   *    sortableLongToDouble(prefixCodedToLong(val))
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static double prefixCodedToDouble(String val) {
-    return sortableLongToDouble(prefixCodedToLong(val));
-  }*/
-
   /**
    * Converts a <code>float</code> value to a sortable signed <code>int</code>.
    * The value is converted by getting their IEEE 754 floating-point &quot;float format&quot;
@@ -371,16 +271,6 @@ public final class NumericUtils {
     return f;
   }
 
-  /*
-   * Convenience method: this just returns:
-   *   intToPrefixCoded(floatToSortableInt(val))
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static String floatToPrefixCoded(float val) {
-    return intToPrefixCoded(floatToSortableInt(val));
-  }*/
-
   /**
    * Converts a sortable <code>int</code> back to a <code>float</code>.
    * @see #floatToSortableInt
@@ -390,16 +280,6 @@ public final class NumericUtils {
     return Float.intBitsToFloat(val);
   }
 
-  /*
-   * Convenience method: this just returns:
-   *    sortableIntToFloat(prefixCodedToInt(val))
-   * @deprecated This method is no longer needed!
-   *
-  @Deprecated
-  public static float prefixCodedToFloat(String val) {
-    return sortableIntToFloat(prefixCodedToInt(val));
-  }*/
-
   /**
    * Splits a long range recursively.
    * You may implement a builder that adds clauses to a
diff --git a/lucene/src/java/org/apache/lucene/util/StringHelper.java b/lucene/src/java/org/apache/lucene/util/StringHelper.java
index 498f53e..c2555d3 100644
--- a/lucene/src/java/org/apache/lucene/util/StringHelper.java
+++ b/lucene/src/java/org/apache/lucene/util/StringHelper.java
@@ -44,7 +44,7 @@ public abstract class StringHelper {
    * @param bytes2 The second byte[] to compare
    * @return The number of common elements.
    */
-  public static final int bytesDifference(byte[] bytes1, int len1, byte[] bytes2, int len2) {
+  public static int bytesDifference(byte[] bytes1, int len1, byte[] bytes2, int len2) {
     int len = len1 < len2 ? len1 : len2;
     for (int i = 0; i < len; i++)
       if (bytes1[i] != bytes2[i])
@@ -52,29 +52,6 @@ public abstract class StringHelper {
     return len;
   }
 
-  /**
-   * Compares two strings, character by character, and returns the
-   * first position where the two strings differ from one another.
-   *
-   * @param s1 The first string to compare
-   * @param s2 The second string to compare
-   * @return The first position where the two strings differ.
-   * 
-   * @deprecated This method cannot handle supplementary characters.
-   */
-  @Deprecated
-  public static final int stringDifference(String s1, String s2) {
-    int len1 = s1.length();
-    int len2 = s2.length();
-    int len = len1 < len2 ? len1 : len2;
-    for (int i = 0; i < len; i++) {
-      if (s1.charAt(i) != s2.charAt(i)) {
-	      return i;
-      }
-    }
-    return len;
-  }
-
   private StringHelper() {
   }
 }
diff --git a/lucene/src/java/org/apache/lucene/util/Version.java b/lucene/src/java/org/apache/lucene/util/Version.java
index e202db7..09b1f8b 100644
--- a/lucene/src/java/org/apache/lucene/util/Version.java
+++ b/lucene/src/java/org/apache/lucene/util/Version.java
@@ -28,29 +28,18 @@ package org.apache.lucene.util;
  * your indexing code to match, and re-index.
  */
 public enum Version {
-
-  /** Match settings and bugs in Lucene's 2.0 release. */
-  LUCENE_20,
-
-  /** Match settings and bugs in Lucene's 2.1 release. */
-  LUCENE_21,
-
-  /** Match settings and bugs in Lucene's 2.2 release. */
-  LUCENE_22,
-
-  /** Match settings and bugs in Lucene's 2.3 release. */
-  LUCENE_23,
-
-  /** Match settings and bugs in Lucene's 2.4 release. */
-  LUCENE_24,
-
-  /** Match settings and bugs in Lucene's 2.9 release. */
-  LUCENE_29,
-
-  /** Match settings and bugs in Lucene's 3.0 release. */
+  /**
+   * Match settings and bugs in Lucene's 3.0 release.
+   * @deprecated (4.0) Use latest
+   */
+  @Deprecated
   LUCENE_30,
 
-  /** Match settings and bugs in Lucene's 3.1 release. */
+  /**
+   * Match settings and bugs in Lucene's 3.1 release.
+   * @deprecated (4.0) Use latest
+   */
+  @Deprecated
   LUCENE_31,
 
   /** Match settings and bugs in Lucene's 4.0 release. 
diff --git a/lucene/src/test/org/apache/lucene/TestExternalCodecs.java b/lucene/src/test/org/apache/lucene/TestExternalCodecs.java
index 57373d6..8c5f7bc 100644
--- a/lucene/src/test/org/apache/lucene/TestExternalCodecs.java
+++ b/lucene/src/test/org/apache/lucene/TestExternalCodecs.java
@@ -620,10 +620,12 @@ public class TestExternalCodecs extends LuceneTestCase {
     
     final int NUM_DOCS = 173;
     Directory dir = newDirectory();
-    IndexWriter w = new IndexWriter(dir,
-                                    newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, true)).setCodecProvider(provider));
-
-    w.setMergeFactor(3);
+    IndexWriter w = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, true)).
+            setCodecProvider(provider).
+            setMergePolicy(newLogMergePolicy(3))
+    );
     Document doc = new Document();
     // uses default codec:
     doc.add(newField("field1", "this field uses the standard codec as the test", Field.Store.NO, Field.Index.ANALYZED));
diff --git a/lucene/src/test/org/apache/lucene/TestSearch.java b/lucene/src/test/org/apache/lucene/TestSearch.java
index 6341258..4db9a1a 100644
--- a/lucene/src/test/org/apache/lucene/TestSearch.java
+++ b/lucene/src/test/org/apache/lucene/TestSearch.java
@@ -114,29 +114,15 @@ public class TestSearch extends LuceneTestCase {
         Query query = parser.parse(queries[j]);
         out.println("Query: " + query.toString("contents"));
 
-      //DateFilter filter =
-      //  new DateFilter("modified", Time(1997,0,1), Time(1998,0,1));
-      //DateFilter filter = DateFilter.Before("modified", Time(1997,00,01));
-      //System.out.println(filter);
-
         hits = searcher.search(query, null, 1000).scoreDocs;
 
         out.println(hits.length + " total results");
         for (int i = 0 ; i < hits.length && i < 10; i++) {
           Document d = searcher.doc(hits[i].doc);
-          out.println(i + " " + hits[i].score
-// 			   + " " + DateField.stringToDate(d.get("modified"))
-                             + " " + d.get("contents"));
+          out.println(i + " " + hits[i].score + " " + d.get("contents"));
         }
       }
       searcher.close();
       directory.close();
   }
-
-  static long Time(int year, int month, int day) {
-    GregorianCalendar calendar = new GregorianCalendar();
-    calendar.clear();
-    calendar.set(year, month, day);
-    return calendar.getTime().getTime();
-  }
 }
diff --git a/lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java b/lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java
index 28111b7..adb902d 100644
--- a/lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java
+++ b/lucene/src/test/org/apache/lucene/analysis/TestCharTokenizers.java
@@ -18,10 +18,8 @@ package org.apache.lucene.analysis;
  */
 
 import java.io.IOException;
-import java.io.Reader;
 import java.io.StringReader;
 
-import org.apache.lucene.util.Version;
 
 /**
  * Testcase for {@link CharTokenizer} subclasses
@@ -92,96 +90,4 @@ public class TestCharTokenizers extends BaseTokenStreamTestCase {
     MockTokenizer tokenizer = new MockTokenizer(new StringReader(builder.toString() + builder.toString()), MockTokenizer.SIMPLE, true);
     assertTokenStreamContents(tokenizer, new String[] {builder.toString().toLowerCase(), builder.toString().toLowerCase()});
   }
-
-  public void testIsTokenCharCharInSubclass() {
-    new TestingCharTokenizer(Version.LUCENE_30, new StringReader(""));
-    try {
-      new TestingCharTokenizer(TEST_VERSION_CURRENT, new StringReader(""));
-      fail("version 3.1 is not permitted if char based method is implemented");
-    } catch (IllegalArgumentException e) {
-      // expected
-    }
-  }
-
-  public void testNormalizeCharInSubclass() {
-    new TestingCharTokenizerNormalize(Version.LUCENE_30, new StringReader(""));
-    try {
-      new TestingCharTokenizerNormalize(TEST_VERSION_CURRENT,
-          new StringReader(""));
-      fail("version 3.1 is not permitted if char based method is implemented");
-    } catch (IllegalArgumentException e) {
-      // expected
-    }
-  }
-
-  public void testNormalizeAndIsTokenCharCharInSubclass() {
-    new TestingCharTokenizerNormalizeIsTokenChar(Version.LUCENE_30,
-        new StringReader(""));
-    try {
-      new TestingCharTokenizerNormalizeIsTokenChar(TEST_VERSION_CURRENT,
-          new StringReader(""));
-      fail("version 3.1 is not permitted if char based method is implemented");
-    } catch (IllegalArgumentException e) {
-      // expected
-    }
-  }
-
-  static final class TestingCharTokenizer extends CharTokenizer {
-    public TestingCharTokenizer(Version matchVersion, Reader input) {
-      super(matchVersion, input);
-    }
-
-    @Override
-    protected boolean isTokenChar(int c) {
-      return Character.isLetter(c);
-    }
-
-    @Deprecated @Override
-    protected boolean isTokenChar(char c) {
-      return Character.isLetter(c);
-    }
-  }
-
-  static final class TestingCharTokenizerNormalize extends CharTokenizer {
-    public TestingCharTokenizerNormalize(Version matchVersion, Reader input) {
-      super(matchVersion, input);
-    }
-
-    @Deprecated @Override
-    protected char normalize(char c) {
-      return c;
-    }
-
-    @Override
-    protected int normalize(int c) {
-      return c;
-    }
-  }
-
-  static final class TestingCharTokenizerNormalizeIsTokenChar extends CharTokenizer {
-    public TestingCharTokenizerNormalizeIsTokenChar(Version matchVersion,
-        Reader input) {
-      super(matchVersion, input);
-    }
-
-    @Deprecated @Override
-    protected char normalize(char c) {
-      return c;
-    }
-
-    @Override
-    protected int normalize(int c) {
-      return c;
-    }
-
-    @Override
-    protected boolean isTokenChar(int c) {
-      return Character.isLetter(c);
-    }
-
-    @Deprecated @Override
-    protected boolean isTokenChar(char c) {
-      return Character.isLetter(c);
-    }
-  }
 }
diff --git a/lucene/src/test/org/apache/lucene/analysis/TestToken.java b/lucene/src/test/org/apache/lucene/analysis/TestToken.java
index ccd0c20..94ab03d 100644
--- a/lucene/src/test/org/apache/lucene/analysis/TestToken.java
+++ b/lucene/src/test/org/apache/lucene/analysis/TestToken.java
@@ -176,20 +176,20 @@ public class TestToken extends LuceneTestCase {
     char[] content = "hello".toCharArray();
     t.copyBuffer(content, 0, 5);
     char[] buf = t.buffer();
-    Token copy = (Token) TestSimpleAttributeImpls.assertCloneIsEqual(t);
+    Token copy = assertCloneIsEqual(t);
     assertEquals(t.toString(), copy.toString());
     assertNotSame(buf, copy.buffer());
 
     Payload pl = new Payload(new byte[]{1,2,3,4});
     t.setPayload(pl);
-    copy = (Token) TestSimpleAttributeImpls.assertCloneIsEqual(t);
+    copy = assertCloneIsEqual(t);
     assertEquals(pl, copy.getPayload());
     assertNotSame(pl, copy.getPayload());
   }
   
   public void testCopyTo() throws Exception {
     Token t = new Token();
-    Token copy = (Token) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    Token copy = assertCopyIsEqual(t);
     assertEquals("", t.toString());
     assertEquals("", copy.toString());
 
@@ -197,13 +197,13 @@ public class TestToken extends LuceneTestCase {
     char[] content = "hello".toCharArray();
     t.copyBuffer(content, 0, 5);
     char[] buf = t.buffer();
-    copy = (Token) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    copy = assertCopyIsEqual(t);
     assertEquals(t.toString(), copy.toString());
     assertNotSame(buf, copy.buffer());
 
     Payload pl = new Payload(new byte[]{1,2,3,4});
     t.setPayload(pl);
-    copy = (Token) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    copy = assertCopyIsEqual(t);
     assertEquals(pl, copy.getPayload());
     assertNotSame(pl, copy.getPayload());
   }
@@ -240,4 +240,21 @@ public class TestToken extends LuceneTestCase {
     assertTrue("TypeAttribute is not implemented by Token",
       ts.addAttribute(TypeAttribute.class) instanceof Token);
   }
+
+  public static <T extends AttributeImpl> T assertCloneIsEqual(T att) {
+    @SuppressWarnings("unchecked")
+    T clone = (T) att.clone();
+    assertEquals("Clone must be equal", att, clone);
+    assertEquals("Clone's hashcode must be equal", att.hashCode(), clone.hashCode());
+    return clone;
+  }
+
+  public static <T extends AttributeImpl> T assertCopyIsEqual(T att) throws Exception {
+    @SuppressWarnings("unchecked")
+    T copy = (T) att.getClass().newInstance();
+    att.copyTo(copy);
+    assertEquals("Copied instance must be equal", att, copy);
+    assertEquals("Copied instance's hashcode must be equal", att.hashCode(), copy.hashCode());
+    return copy;
+  }
 }
diff --git a/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java b/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
index 76ca831..e7255db 100644
--- a/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
+++ b/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestCharTermAttributeImpl.java
@@ -17,6 +17,7 @@ package org.apache.lucene.analysis.tokenattributes;
  * limitations under the License.
  */
 
+import org.apache.lucene.analysis.TestToken;
 import org.apache.lucene.util.LuceneTestCase;
 import java.nio.CharBuffer;
 import java.util.Formatter;
@@ -91,7 +92,7 @@ public class TestCharTermAttributeImpl extends LuceneTestCase {
     char[] content = "hello".toCharArray();
     t.copyBuffer(content, 0, 5);
     char[] buf = t.buffer();
-    CharTermAttributeImpl copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCloneIsEqual(t);
+    CharTermAttributeImpl copy = TestToken.assertCloneIsEqual(t);
     assertEquals(t.toString(), copy.toString());
     assertNotSame(buf, copy.buffer());
   }
@@ -113,7 +114,7 @@ public class TestCharTermAttributeImpl extends LuceneTestCase {
   
   public void testCopyTo() throws Exception {
     CharTermAttributeImpl t = new CharTermAttributeImpl();
-    CharTermAttributeImpl copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    CharTermAttributeImpl copy = TestToken.assertCopyIsEqual(t);
     assertEquals("", t.toString());
     assertEquals("", copy.toString());
 
@@ -121,7 +122,7 @@ public class TestCharTermAttributeImpl extends LuceneTestCase {
     char[] content = "hello".toCharArray();
     t.copyBuffer(content, 0, 5);
     char[] buf = t.buffer();
-    copy = (CharTermAttributeImpl) TestSimpleAttributeImpls.assertCopyIsEqual(t);
+    copy = TestToken.assertCopyIsEqual(t);
     assertEquals(t.toString(), copy.toString());
     assertNotSame(buf, copy.buffer());
   }
diff --git a/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java b/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java
deleted file mode 100644
index 590c8e8..0000000
--- a/lucene/src/test/org/apache/lucene/analysis/tokenattributes/TestSimpleAttributeImpls.java
+++ /dev/null
@@ -1,153 +0,0 @@
-package org.apache.lucene.analysis.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.Payload;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.AttributeSource.AttributeFactory;
-
-@Deprecated
-public class TestSimpleAttributeImpls extends LuceneTestCase {
-  
-  public void testFlagsAttribute() throws Exception {
-    FlagsAttributeImpl att = new FlagsAttributeImpl();
-    assertEquals(0, att.getFlags());
-
-    att.setFlags(1234);
-    assertEquals("flags=1234", att.toString());
-
-    FlagsAttributeImpl att2 = (FlagsAttributeImpl) assertCloneIsEqual(att);
-    assertEquals(1234, att2.getFlags());
-
-    att2 = (FlagsAttributeImpl) assertCopyIsEqual(att);
-    assertEquals(1234, att2.getFlags());
-    
-    att.clear();
-    assertEquals(0, att.getFlags());
-  }
-  
-  public void testPositionIncrementAttribute() throws Exception {
-    PositionIncrementAttributeImpl att = new PositionIncrementAttributeImpl();
-    assertEquals(1, att.getPositionIncrement());
-
-    att.setPositionIncrement(1234);
-    assertEquals("positionIncrement=1234", att.toString());
-
-    PositionIncrementAttributeImpl att2 = (PositionIncrementAttributeImpl) assertCloneIsEqual(att);
-    assertEquals(1234, att2.getPositionIncrement());
-
-    att2 = (PositionIncrementAttributeImpl) assertCopyIsEqual(att);
-    assertEquals(1234, att2.getPositionIncrement());
-    
-    att.clear();
-    assertEquals(1, att.getPositionIncrement());
-  }
-  
-  public void testTypeAttribute() throws Exception {
-    TypeAttributeImpl att = new TypeAttributeImpl();
-    assertEquals(TypeAttribute.DEFAULT_TYPE, att.type());
-
-    att.setType("hallo");
-    assertEquals("type=hallo", att.toString());
-
-    TypeAttributeImpl att2 = (TypeAttributeImpl) assertCloneIsEqual(att);
-    assertEquals("hallo", att2.type());
-
-    att2 = (TypeAttributeImpl) assertCopyIsEqual(att);
-    assertEquals("hallo", att2.type());
-    
-    att.clear();
-    assertEquals(TypeAttribute.DEFAULT_TYPE, att.type());
-  }
-  
-  public void testPayloadAttribute() throws Exception {
-    PayloadAttributeImpl att = new PayloadAttributeImpl();
-    assertNull(att.getPayload());
-
-    Payload pl = new Payload(new byte[]{1,2,3,4});
-    att.setPayload(pl);
-
-    PayloadAttributeImpl att2 = (PayloadAttributeImpl) assertCloneIsEqual(att);
-    assertEquals(pl, att2.getPayload());
-    assertNotSame(pl, att2.getPayload());
-
-    att2 = (PayloadAttributeImpl) assertCopyIsEqual(att);
-    assertEquals(pl, att2.getPayload());
-    assertNotSame(pl, att2.getPayload());
-    
-    att.clear();
-    assertNull(att.getPayload());
-  }
-  
-  public void testOffsetAttribute() throws Exception {
-    OffsetAttributeImpl att = new OffsetAttributeImpl();
-    assertEquals(0, att.startOffset());
-    assertEquals(0, att.endOffset());
-
-    att.setOffset(12, 34);
-    // no string test here, because order unknown
-
-    OffsetAttributeImpl att2 = (OffsetAttributeImpl) assertCloneIsEqual(att);
-    assertEquals(12, att2.startOffset());
-    assertEquals(34, att2.endOffset());
-
-    att2 = (OffsetAttributeImpl) assertCopyIsEqual(att);
-    assertEquals(12, att2.startOffset());
-    assertEquals(34, att2.endOffset());
-    
-    att.clear();
-    assertEquals(0, att.startOffset());
-    assertEquals(0, att.endOffset());
-  }
-  
-  public void testKeywordAttribute() {
-    AttributeImpl attrImpl = AttributeFactory.DEFAULT_ATTRIBUTE_FACTORY.createAttributeInstance(KeywordAttribute.class);
-    assertSame(KeywordAttributeImpl.class, attrImpl.getClass());
-    KeywordAttributeImpl att = (KeywordAttributeImpl) attrImpl;
-    assertFalse(att.isKeyword());
-    att.setKeyword(true);
-    assertTrue(att.isKeyword());
-    
-    KeywordAttributeImpl assertCloneIsEqual = (KeywordAttributeImpl) assertCloneIsEqual(att);
-    assertTrue(assertCloneIsEqual.isKeyword());
-    assertCloneIsEqual.clear();
-    assertFalse(assertCloneIsEqual.isKeyword());
-    assertTrue(att.isKeyword());
-    
-    att.copyTo(assertCloneIsEqual);
-    assertTrue(assertCloneIsEqual.isKeyword());
-    assertTrue(att.isKeyword());
-  }
-  
-  public static final AttributeImpl assertCloneIsEqual(AttributeImpl att) {
-    AttributeImpl clone = (AttributeImpl) att.clone();
-    assertEquals("Clone must be equal", att, clone);
-    assertEquals("Clone's hashcode must be equal", att.hashCode(), clone.hashCode());
-    return clone;
-  }
-
-  public static final AttributeImpl assertCopyIsEqual(AttributeImpl att) throws Exception {
-    AttributeImpl copy = att.getClass().newInstance();
-    att.copyTo(copy);
-    assertEquals("Copied instance must be equal", att, copy);
-    assertEquals("Copied instance's hashcode must be equal", att.hashCode(), copy.hashCode());
-    return copy;
-  }
-
-}
diff --git a/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java b/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
index 20d6db6..d11d817 100644
--- a/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
+++ b/lucene/src/test/org/apache/lucene/document/TestBinaryDocument.java
@@ -37,14 +37,6 @@ public class TestBinaryDocument extends LuceneTestCase {
     Fieldable binaryFldStored = new Field("binaryStored", binaryValStored.getBytes());
     Fieldable stringFldStored = new Field("stringStored", binaryValStored, Field.Store.YES, Field.Index.NO, Field.TermVector.NO);
 
-    try {
-      // binary fields with store off are not allowed
-      new Field("fail", binaryValStored.getBytes(), Field.Store.NO);
-      fail();
-    }
-    catch (IllegalArgumentException iae) {
-    }
-    
     Document doc = new Document();
     
     doc.add(binaryFldStored);
diff --git a/lucene/src/test/org/apache/lucene/document/TestNumberTools.java b/lucene/src/test/org/apache/lucene/document/TestNumberTools.java
deleted file mode 100644
index 12734d9..0000000
--- a/lucene/src/test/org/apache/lucene/document/TestNumberTools.java
+++ /dev/null
@@ -1,82 +0,0 @@
-package org.apache.lucene.document;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestNumberTools extends LuceneTestCase {
-    public void testNearZero() {
-        for (int i = -100; i <= 100; i++) {
-            for (int j = -100; j <= 100; j++) {
-                subtestTwoLongs(i, j);
-            }
-        }
-    }
-
-    public void testMax() {
-        // make sure the constants convert to their equivalents
-        assertEquals(Long.MAX_VALUE, NumberTools
-                .stringToLong(NumberTools.MAX_STRING_VALUE));
-        assertEquals(NumberTools.MAX_STRING_VALUE, NumberTools
-                .longToString(Long.MAX_VALUE));
-
-        // test near MAX, too
-        for (long l = Long.MAX_VALUE; l > Long.MAX_VALUE - 10000; l--) {
-            subtestTwoLongs(l, l - 1);
-        }
-    }
-
-    public void testMin() {
-        // make sure the constants convert to their equivelents
-        assertEquals(Long.MIN_VALUE, NumberTools
-                .stringToLong(NumberTools.MIN_STRING_VALUE));
-        assertEquals(NumberTools.MIN_STRING_VALUE, NumberTools
-                .longToString(Long.MIN_VALUE));
-
-        // test near MIN, too
-        for (long l = Long.MIN_VALUE; l < Long.MIN_VALUE + 10000; l++) {
-            subtestTwoLongs(l, l + 1);
-        }
-    }
-
-    private static void subtestTwoLongs(long i, long j) {
-        // convert to strings
-        String a = NumberTools.longToString(i);
-        String b = NumberTools.longToString(j);
-
-        // are they the right length?
-        assertEquals(NumberTools.STR_SIZE, a.length());
-        assertEquals(NumberTools.STR_SIZE, b.length());
-
-        // are they the right order?
-        if (i < j) {
-            assertTrue(a.compareTo(b) < 0);
-        } else if (i > j) {
-            assertTrue(a.compareTo(b) > 0);
-        } else {
-            assertEquals(a, b);
-        }
-
-        // can we convert them back to longs?
-        long i2 = NumberTools.stringToLong(a);
-        long j2 = NumberTools.stringToLong(b);
-
-        assertEquals(i, i2);
-        assertEquals(j, j2);
-    }
-}
\ No newline at end of file
diff --git a/lucene/src/test/org/apache/lucene/index/Test2BTerms.java b/lucene/src/test/org/apache/lucene/index/Test2BTerms.java
index 4e7897d..261804c 100644
--- a/lucene/src/test/org/apache/lucene/index/Test2BTerms.java
+++ b/lucene/src/test/org/apache/lucene/index/Test2BTerms.java
@@ -132,13 +132,14 @@ public class Test2BTerms extends LuceneTestCase {
     int TERMS_PER_DOC = 1000000;
 
     Directory dir = FSDirectory.open(_TestUtil.getTempDir("2BTerms"));
-    IndexWriter w = new IndexWriter(dir,
-                                    new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
-                                                  .setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH)
-                                                .setRAMBufferSizeMB(256.0).setMergeScheduler(new ConcurrentMergeScheduler()));
-    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundFile(false);
-    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
-    ((LogMergePolicy) w.getConfig().getMergePolicy()).setMergeFactor(10);
+    IndexWriter w = new IndexWriter(
+        dir,
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH).
+            setRAMBufferSizeMB(256.0).
+            setMergeScheduler(new ConcurrentMergeScheduler()).
+            setMergePolicy(newLogMergePolicy(false, 10))
+    );
 
     Document doc = new Document();
     Field field = new Field("field", new MyTokenStream(TERMS_PER_DOC));
diff --git a/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java b/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
index 7d72a8b..6b2714d 100755
--- a/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
+++ b/lucene/src/test/org/apache/lucene/index/TestAddIndexes.java
@@ -58,9 +58,12 @@ public class TestAddIndexes extends LuceneTestCase {
     writer.close();
     _TestUtil.checkIndex(dir);
 
-    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
+    writer = newWriter(
+        aux,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     // add 40 documents in separate files
     addDocs(writer, 40);
     assertEquals(40, writer.maxDoc());
@@ -75,7 +78,7 @@ public class TestAddIndexes extends LuceneTestCase {
     // test doc count before segments are merged
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(100, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux, aux2 });
+    writer.addIndexes(aux, aux2);
     assertEquals(190, writer.maxDoc());
     writer.close();
     _TestUtil.checkIndex(dir);
@@ -97,7 +100,7 @@ public class TestAddIndexes extends LuceneTestCase {
     // test doc count before segments are merged/index is optimized
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(190, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux3 });
+    writer.addIndexes(aux3);
     assertEquals(230, writer.maxDoc());
     writer.close();
 
@@ -128,7 +131,7 @@ public class TestAddIndexes extends LuceneTestCase {
 
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     assertEquals(230, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux4 });
+    writer.addIndexes(aux4);
     assertEquals(231, writer.maxDoc());
     writer.close();
 
@@ -150,7 +153,7 @@ public class TestAddIndexes extends LuceneTestCase {
 
     setUpDirs(dir, aux);
     IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
-    writer.addIndexes(new Directory[] {aux});
+    writer.addIndexes(aux);
 
     // Adds 10 docs, then replaces them with another 10
     // docs, so 10 pending deletes:
@@ -197,7 +200,7 @@ public class TestAddIndexes extends LuceneTestCase {
       writer.updateDocument(new Term("id", "" + (i%10)), doc);
     }
     
-    writer.addIndexes(new Directory[] {aux});
+    writer.addIndexes(aux);
     
     // Deletes one of the 10 added docs, leaving 9:
     PhraseQuery q = new PhraseQuery();
@@ -242,7 +245,7 @@ public class TestAddIndexes extends LuceneTestCase {
     q.add(new Term("content", "14"));
     writer.deleteDocuments(q);
 
-    writer.addIndexes(new Directory[] {aux});
+    writer.addIndexes(aux);
 
     writer.optimize();
     writer.commit();
@@ -271,22 +274,30 @@ public class TestAddIndexes extends LuceneTestCase {
     assertEquals(100, writer.maxDoc());
     writer.close();
 
-    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
+    writer = newWriter(
+        aux,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(1000).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     // add 140 documents in separate files
     addDocs(writer, 40);
     writer.close();
-    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(1000));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
+    writer = newWriter(
+        aux,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(1000).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     addDocs(writer, 100);
     writer.close();
 
     writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
     try {
       // cannot add self
-      writer.addIndexes(new Directory[] { aux, dir });
+      writer.addIndexes(aux, dir);
       assertTrue(false);
     }
     catch (IllegalArgumentException e) {
@@ -311,13 +322,16 @@ public class TestAddIndexes extends LuceneTestCase {
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig( 
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+    IndexWriter writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(4))
+    );
     addDocs(writer, 10);
 
-    writer.addIndexes(new Directory[] { aux });
+    writer.addIndexes(aux);
     assertEquals(1040, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -337,11 +351,16 @@ public class TestAddIndexes extends LuceneTestCase {
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(9));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+    IndexWriter writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(9).
+            setMergePolicy(newLogMergePolicy(4))
+    );
     addDocs(writer, 2);
 
-    writer.addIndexes(new Directory[] { aux });
+    writer.addIndexes(aux);
     assertEquals(1032, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -361,12 +380,15 @@ public class TestAddIndexes extends LuceneTestCase {
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+    IndexWriter writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(4))
+    );
 
-    writer.addIndexes(new Directory[] { aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)) });
+    writer.addIndexes(aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)));
     assertEquals(1060, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -393,12 +415,15 @@ public class TestAddIndexes extends LuceneTestCase {
     assertEquals(10, reader.numDocs());
     reader.close();
 
-    IndexWriter writer = newWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(4));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+    IndexWriter writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(4).
+            setMergePolicy(newLogMergePolicy(4))
+    );
 
-    writer.addIndexes(new Directory[] { aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)) });
+    writer.addIndexes(aux, new MockDirectoryWrapper(random, new RAMDirectory(aux)));
     assertEquals(1060, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -416,11 +441,14 @@ public class TestAddIndexes extends LuceneTestCase {
 
     setUpDirs(dir, aux);
 
-    IndexWriter writer = newWriter(aux2, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
-    writer.addIndexes(new Directory[] { aux });
+    IndexWriter writer = newWriter(
+        aux2,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(100).
+            setMergePolicy(newLogMergePolicy(10))
+    );
+    writer.addIndexes(aux);
     assertEquals(30, writer.maxDoc());
     assertEquals(3, writer.getSegmentCount());
     writer.close();
@@ -439,11 +467,15 @@ public class TestAddIndexes extends LuceneTestCase {
     assertEquals(22, reader.numDocs());
     reader.close();
 
-    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(6));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+    writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(6).
+            setMergePolicy(newLogMergePolicy(4))
+    );
 
-    writer.addIndexes(new Directory[] { aux, aux2 });
+    writer.addIndexes(aux, aux2);
     assertEquals(1060, writer.maxDoc());
     assertEquals(1000, writer.getDocCount(0));
     writer.close();
@@ -505,18 +537,24 @@ public class TestAddIndexes extends LuceneTestCase {
     assertEquals(1, writer.getSegmentCount());
     writer.close();
 
-    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+    writer = newWriter(
+        aux,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(1000).
+            setMergePolicy(newLogMergePolicy(false, 10))
+    );
     // add 30 documents in 3 segments
     for (int i = 0; i < 3; i++) {
       addDocs(writer, 10);
       writer.close();
-      writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(100));
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false); // use one without a compound file
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false); // use one without a compound file
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+      writer = newWriter(
+          aux,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.APPEND).
+              setMaxBufferedDocs(1000).
+              setMergePolicy(newLogMergePolicy(false, 10))
+      );
     }
     assertEquals(30, writer.maxDoc());
     assertEquals(3, writer.getSegmentCount());
@@ -563,7 +601,7 @@ public class TestAddIndexes extends LuceneTestCase {
     writer = new IndexWriter(dir2, newIndexWriterConfig(TEST_VERSION_CURRENT,
         new MockAnalyzer())
         .setMergeScheduler(new SerialMergeScheduler()).setMergePolicy(lmp));
-    writer.addIndexes(new Directory[] {dir});
+    writer.addIndexes(dir);
     writer.close();
     dir.close();
     dir2.close();
@@ -920,22 +958,26 @@ public class TestAddIndexes extends LuceneTestCase {
     writer.close();
     _TestUtil.checkIndex(dir, provider);
 
-    writer = newWriter(aux, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(
-        provider));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy())
-        .setUseCompoundFile(false); // use one without a compound file
-    ((LogMergePolicy) writer.getConfig().getMergePolicy())
-        .setUseCompoundDocStore(false); // use one without a compound file
+    writer = newWriter(
+        aux,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setCodecProvider(provider).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     // add 40 documents in separate files
     addDocs(writer, 40);
     assertEquals(40, writer.maxDoc());
     writer.commit();
     writer.close();
 
-    writer = newWriter(aux2, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer()).setOpenMode(OpenMode.CREATE).setCodecProvider(
-        provider));
+    writer = newWriter(
+        aux2,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setCodecProvider(provider)
+    );
     // add 40 documents in compound files
     addDocs2(writer, 50);
     assertEquals(50, writer.maxDoc());
@@ -943,11 +985,14 @@ public class TestAddIndexes extends LuceneTestCase {
     writer.close();
 
     // test doc count before segments are merged
-    writer = newWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer()).setOpenMode(OpenMode.APPEND).setCodecProvider(
-        provider));
+    writer = newWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.APPEND).
+            setCodecProvider(provider)
+    );
     assertEquals(100, writer.maxDoc());
-    writer.addIndexes(new Directory[] { aux, aux2 });
+    writer.addIndexes(aux, aux2);
     assertEquals(190, writer.maxDoc());
     writer.close();
     _TestUtil.checkIndex(dir, provider);
diff --git a/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java b/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
index 9b8eae8..cef3c30 100644
--- a/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
+++ b/lucene/src/test/org/apache/lucene/index/TestBackwardsCompatibility.java
@@ -235,7 +235,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       Directory targetDir = newDirectory();
       IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()));
-      w.addIndexes(new Directory[] { dir });
+      w.addIndexes(dir);
       w.close();
 
       _TestUtil.checkIndex(targetDir);
@@ -256,7 +256,7 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
       Directory targetDir = newDirectory();
       IndexWriter w = new IndexWriter(targetDir, newIndexWriterConfig(
           TEST_VERSION_CURRENT, new MockAnalyzer()));
-      w.addIndexes(new IndexReader[] { reader });
+      w.addIndexes(reader);
       w.close();
       reader.close();
       
@@ -527,9 +527,13 @@ public class TestBackwardsCompatibility extends LuceneTestCase {
     try {
       Directory dir = FSDirectory.open(new File(fullDir(outputDir)));
 
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1).setRAMBufferSizeMB(16.0));
-      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(-1).
+              setRAMBufferSizeMB(16.0).
+              setMergePolicy(newLogMergePolicy(true, 10))
+      );
       for(int i=0;i<35;i++) {
         addDoc(writer, i);
       }
diff --git a/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java b/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
index 6c46713..7a3dc9a 100644
--- a/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
+++ b/lucene/src/test/org/apache/lucene/index/TestConcurrentMergeScheduler.java
@@ -184,8 +184,12 @@ public class TestConcurrentMergeScheduler extends LuceneTestCase {
     Field idField = newField("id", "", Field.Store.YES, Field.Index.NOT_ANALYZED);
     doc.add(idField);
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
+    IndexWriter writer = new IndexWriter(
+        directory,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(100))
+    );
 
     for(int iter=0;iter<10;iter++) {
 
@@ -213,8 +217,12 @@ public class TestConcurrentMergeScheduler extends LuceneTestCase {
       reader.close();
 
       // Reopen
-      writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
+      writer = new IndexWriter(
+          directory,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.APPEND).
+              setMergePolicy(newLogMergePolicy(100))
+      );
     }
     writer.close();
 
diff --git a/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java b/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
index ca21579..72c438d 100644
--- a/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
+++ b/lucene/src/test/org/apache/lucene/index/TestDeletionPolicy.java
@@ -373,10 +373,13 @@ public class TestDeletionPolicy extends LuceneTestCase {
     Directory dir = newDirectory();
     policy.dir = dir;
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setIndexDeletionPolicy(policy).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setIndexDeletionPolicy(policy).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     for(int i=0;i<10;i++) {
       addDoc(writer);
       if ((1+i)%2 == 0)
diff --git a/lucene/src/test/org/apache/lucene/index/TestDoc.java b/lucene/src/test/org/apache/lucene/index/TestDoc.java
index 0836102..7981a74 100644
--- a/lucene/src/test/org/apache/lucene/index/TestDoc.java
+++ b/lucene/src/test/org/apache/lucene/index/TestDoc.java
@@ -111,10 +111,13 @@ public class TestDoc extends LuceneTestCase {
       PrintWriter out = new PrintWriter(sw, true);
       
       Directory directory = FSDirectory.open(indexDir);
-      IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-                                           .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(-1));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer = new IndexWriter(
+          directory,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.CREATE).
+              setMaxBufferedDocs(-1).
+              setMergePolicy(newLogMergePolicy(10))
+      );
 
       SegmentInfo si1 = indexDoc(writer, "test.txt");
       printSegment(out, si1);
@@ -142,10 +145,13 @@ public class TestDoc extends LuceneTestCase {
       out = new PrintWriter(sw, true);
 
       directory = FSDirectory.open(indexDir);
-      writer = new IndexWriter(directory, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-                               .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(-1));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      writer = new IndexWriter(
+          directory,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.CREATE).
+              setMaxBufferedDocs(-1).
+              setMergePolicy(newLogMergePolicy(10))
+      );
 
       si1 = indexDoc(writer, "test.txt");
       printSegment(out, si1);
@@ -188,7 +194,7 @@ public class TestDoc extends LuceneTestCase {
       SegmentReader r1 = SegmentReader.get(true, si1, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
       SegmentReader r2 = SegmentReader.get(true, si2, IndexReader.DEFAULT_TERMS_INDEX_DIVISOR);
 
-      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriter.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null);
+      SegmentMerger merger = new SegmentMerger(si1.dir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, merged, null, CodecProvider.getDefault(), null);
 
       merger.add(r1);
       merger.add(r2);
diff --git a/lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java b/lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java
index 0cb8a0d..fa51319 100644
--- a/lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java
+++ b/lucene/src/test/org/apache/lucene/index/TestDocumentWriter.java
@@ -314,7 +314,7 @@ public class TestDocumentWriter extends LuceneTestCase {
 
     _TestUtil.checkIndex(dir);
 
-    SegmentReader reader = SegmentReader.getOnlySegmentReader(dir);
+    SegmentReader reader = getOnlySegmentReader(IndexReader.open(dir, false));
     FieldInfos fi = reader.fieldInfos();
     // f1
     assertFalse("f1 should have no norms", reader.hasNorms("f1"));
diff --git a/lucene/src/test/org/apache/lucene/index/TestFieldsReader.java b/lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
index a0a0f2d..8e7ae4d 100644
--- a/lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
+++ b/lucene/src/test/org/apache/lucene/index/TestFieldsReader.java
@@ -19,10 +19,7 @@ package org.apache.lucene.index;
 
 import java.io.File;
 import java.io.IOException;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -429,6 +426,10 @@ public class TestFieldsReader extends LuceneTestCase {
       return fsDir.createOutput(name);
     }
     @Override
+    public void sync(Collection<String> names) throws IOException {
+      fsDir.sync(names);
+    }
+    @Override
     public void close() throws IOException {
       fsDir.close();
     }
diff --git a/lucene/src/test/org/apache/lucene/index/TestFlex.java b/lucene/src/test/org/apache/lucene/index/TestFlex.java
index 7106c91..1f53114 100644
--- a/lucene/src/test/org/apache/lucene/index/TestFlex.java
+++ b/lucene/src/test/org/apache/lucene/index/TestFlex.java
@@ -30,12 +30,14 @@ public class TestFlex extends LuceneTestCase {
 
     final int DOC_COUNT = 177;
 
-    IndexWriter w = new IndexWriter(d, new MockAnalyzer(),
-                                    IndexWriter.MaxFieldLength.UNLIMITED);
+    IndexWriter w = new IndexWriter(
+        d,
+        new IndexWriterConfig(Version.LUCENE_31, new MockAnalyzer()).
+            setMaxBufferedDocs(7)
+    );
 
     for(int iter=0;iter<2;iter++) {
       if (iter == 0) {
-        w.setMaxBufferedDocs(7);
         Document doc = new Document();
         doc.add(newField("field1", "this is field1", Field.Store.NO, Field.Index.ANALYZED));
         doc.add(newField("field2", "this is field2", Field.Store.NO, Field.Index.ANALYZED));
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java b/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
index 432cf2f..0ff5d34 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexFileDeleter.java
@@ -40,11 +40,12 @@ public class TestIndexFileDeleter extends LuceneTestCase {
   public void testDeleteLeftoverFiles() throws IOException {
     MockDirectoryWrapper dir = newDirectory();
     dir.setPreventDoubleWrite(false);
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(10));
-    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
-    ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(true, 10))
+    );
     int i;
     for(i=0;i<35;i++) {
       addDoc(writer, i);
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java b/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
index 42b6163..0f6f2ba 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexReader.java
@@ -146,8 +146,10 @@ public class TestIndexReader extends LuceneTestCase
     public void testGetFieldNames() throws Exception {
         Directory d = newDirectory();
         // set up writer
-        IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
-            TEST_VERSION_CURRENT, new MockAnalyzer()));
+        IndexWriter writer = new IndexWriter(
+            d,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer())
+        );
 
         Document doc = new Document();
         doc.add(new Field("keyword","test1", Field.Store.YES, Field.Index.NOT_ANALYZED));
@@ -166,8 +168,12 @@ public class TestIndexReader extends LuceneTestCase
         assertTrue(fieldNames.contains("unstored"));
         reader.close();
         // add more documents
-        writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
-            new MockAnalyzer()).setOpenMode(OpenMode.APPEND));
+        writer = new IndexWriter(
+            d,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+                setOpenMode(OpenMode.APPEND).
+                setMergePolicy(newLogMergePolicy())
+        );
         // want to get some more segments here
         int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();
         for (int i = 0; i < 5*mergeFactor; i++) {
@@ -261,8 +267,11 @@ public class TestIndexReader extends LuceneTestCase
   public void testTermVectors() throws Exception {
     Directory d = newDirectory();
     // set up writer
-    IndexWriter writer = new IndexWriter(d, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(
+        d,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy())
+    );
     // want to get some more segments here
     // new termvector fields
     int mergeFactor = ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor();
@@ -566,9 +575,11 @@ public class TestIndexReader extends LuceneTestCase
         Term searchTerm = new Term("content", "aaa");
 
         //  add 1 documents with term : aaa
-        writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
+        writer  = new IndexWriter(
+            dir,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+                setMergePolicy(newLogMergePolicy(false))
+        );
         addDoc(writer, searchTerm.text());
         writer.close();
 
@@ -1410,10 +1421,12 @@ public class TestIndexReader extends LuceneTestCase
       Directory d = newDirectory();
 
       // set up writer
-      IndexWriter writer = new IndexWriter(d, newIndexWriterConfig( 
-          TEST_VERSION_CURRENT, new MockAnalyzer())
-      .setMaxBufferedDocs(2));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer = new IndexWriter(
+          d,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(2).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       for(int i=0;i<27;i++)
         addDocumentWithFields(writer);
       writer.close();
@@ -1428,10 +1441,13 @@ public class TestIndexReader extends LuceneTestCase
       assertTrue(c.equals(r.getIndexCommit()));
 
       // Change the index
-      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
-          new MockAnalyzer()).setOpenMode(
-              OpenMode.APPEND).setMaxBufferedDocs(2));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      writer = new IndexWriter(
+          d,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.APPEND).
+              setMaxBufferedDocs(2).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       for(int i=0;i<7;i++)
         addDocumentWithFields(writer);
       writer.close();
@@ -1471,11 +1487,13 @@ public class TestIndexReader extends LuceneTestCase
       } catch (UnsupportedOperationException uoe) {
         // expected
       }
-      
-      writer = new IndexWriter(d, newIndexWriterConfig(TEST_VERSION_CURRENT,
-        new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+
+      writer = new IndexWriter(
+          d,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.APPEND).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       addDocumentWithFields(writer);
       writer.close();
 
@@ -1619,7 +1637,7 @@ public class TestIndexReader extends LuceneTestCase
     writer.close();
 
     // Open reader
-    IndexReader r = SegmentReader.getOnlySegmentReader(dir);
+    IndexReader r = getOnlySegmentReader(IndexReader.open(dir, false));
     final int[] ints = FieldCache.DEFAULT.getInts(r, "number");
     assertEquals(1, ints.length);
     assertEquals(17, ints[0]);
@@ -1643,16 +1661,19 @@ public class TestIndexReader extends LuceneTestCase
   // FieldCache
   public void testFieldCacheReuseAfterReopen() throws Exception {
     Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     Document doc = new Document();
     doc.add(newField("number", "17", Field.Store.NO, Field.Index.NOT_ANALYZED));
-    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
     writer.addDocument(doc);
     writer.commit();
 
     // Open reader1
     IndexReader r = IndexReader.open(dir, false);
-    IndexReader r1 = SegmentReader.getOnlySegmentReader(r);
+    IndexReader r1 = getOnlySegmentReader(r);
     final int[] ints = FieldCache.DEFAULT.getInts(r1, "number");
     assertEquals(1, ints.length);
     assertEquals(17, ints[0]);
@@ -1676,8 +1697,12 @@ public class TestIndexReader extends LuceneTestCase
   // reopen switches readOnly
   public void testReopenChangeReadonly() throws Exception {
     Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(-1));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(-1).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     Document doc = new Document();
     doc.add(newField("number", "17", Field.Store.NO, Field.Index.NOT_ANALYZED));
     writer.addDocument(doc);
@@ -1686,7 +1711,7 @@ public class TestIndexReader extends LuceneTestCase
     // Open reader1
     IndexReader r = IndexReader.open(dir, false);
     assertTrue(r instanceof DirectoryReader);
-    IndexReader r1 = SegmentReader.getOnlySegmentReader(r);
+    IndexReader r1 = getOnlySegmentReader(r);
     final int[] ints = FieldCache.DEFAULT.getInts(r1, "number");
     assertEquals(1, ints.length);
     assertEquals(17, ints[0]);
@@ -1727,7 +1752,7 @@ public class TestIndexReader extends LuceneTestCase
     writer.commit();
 
     IndexReader r = IndexReader.open(dir, false);
-    IndexReader r1 = SegmentReader.getOnlySegmentReader(r);
+    IndexReader r1 = getOnlySegmentReader(r);
     assertEquals(36, r1.getUniqueTermCount());
     writer.addDocument(doc);
     writer.commit();
@@ -1768,8 +1793,12 @@ public class TestIndexReader extends LuceneTestCase
     }
 
     assertEquals(-1, ((SegmentReader) r.getSequentialSubReaders()[0]).getTermInfosIndexDivisor());
-    writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
-    ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+    writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setCodecProvider(_TestUtil.alwaysCodec("Standard")).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     writer.addDocument(doc);
     writer.close();
 
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java b/lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
index a287385..00f53f6 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexReaderClone.java
@@ -302,7 +302,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
     IndexReader r1 = IndexReader.open(dir1, false);
     IndexReader r2 = IndexReader.open(dir2, false);
 
-    MultiReader multiReader = new MultiReader(new IndexReader[] { r1, r2 });
+    MultiReader multiReader = new MultiReader(r1, r2);
     performDefaultTests(multiReader);
     multiReader.close();
     dir1.close();
@@ -312,7 +312,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
   public void testSegmentReaderUndeleteall() throws Exception {
     final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
-    SegmentReader origSegmentReader = SegmentReader.getOnlySegmentReader(dir1);
+    SegmentReader origSegmentReader = getOnlySegmentReader(IndexReader.open(dir1, false));
     origSegmentReader.deleteDocument(10);
     assertDelDocsRefCountEquals(1, origSegmentReader);
     origSegmentReader.undeleteAll();
@@ -325,7 +325,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
   public void testSegmentReaderCloseReferencing() throws Exception {
     final Directory dir1 = newDirectory();
     TestIndexReaderReopen.createIndex(random, dir1, false);
-    SegmentReader origSegmentReader = SegmentReader.getOnlySegmentReader(dir1);
+    SegmentReader origSegmentReader = getOnlySegmentReader(IndexReader.open(dir1, false));
     origSegmentReader.deleteDocument(1);
     origSegmentReader.setNorm(4, "field1", 0.5f);
 
@@ -346,7 +346,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
     TestIndexReaderReopen.createIndex(random, dir1, false);
 
     IndexReader origReader = IndexReader.open(dir1, false);
-    SegmentReader origSegmentReader = SegmentReader.getOnlySegmentReader(origReader);
+    SegmentReader origSegmentReader = getOnlySegmentReader(origReader);
     // deletedDocsRef should be null because nothing has updated yet
     assertNull(origSegmentReader.deletedDocsRef);
 
@@ -358,7 +358,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
     // the cloned segmentreader should have 2 references, 1 to itself, and 1 to
     // the original segmentreader
     IndexReader clonedReader = (IndexReader) origReader.clone();
-    SegmentReader clonedSegmentReader = SegmentReader.getOnlySegmentReader(clonedReader);
+    SegmentReader clonedSegmentReader = getOnlySegmentReader(clonedReader);
     assertDelDocsRefCountEquals(2, origSegmentReader);
     // deleting a document creates a new deletedDocs bitvector, the refs goes to
     // 1
@@ -395,7 +395,7 @@ public class TestIndexReaderClone extends LuceneTestCase {
     // test a reopened reader
     IndexReader reopenedReader = clonedReader.reopen();
     IndexReader cloneReader2 = (IndexReader) reopenedReader.clone();
-    SegmentReader cloneSegmentReader2 = SegmentReader.getOnlySegmentReader(cloneReader2);
+    SegmentReader cloneSegmentReader2 = getOnlySegmentReader(cloneReader2);
     assertDelDocsRefCountEquals(2, cloneSegmentReader2);
     clonedReader.close();
     reopenedReader.close();
@@ -490,10 +490,11 @@ public class TestIndexReaderClone extends LuceneTestCase {
 
   public void testCloseStoredFields() throws Exception {
     final Directory dir = newDirectory();
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()));
-    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundFile(false);
-    ((LogMergePolicy) w.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
+    IndexWriter w = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     Document doc = new Document();
     doc.add(newField("field", "yes it's stored", Field.Store.YES, Field.Index.ANALYZED));
     w.addDocument(doc);
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java b/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
index b25d0e5..74fc7c3 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexReaderCloneNorms.java
@@ -109,11 +109,14 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
     Directory dir3 = FSDirectory.open(indexDir3);
 
     createIndex(random, dir3);
-    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
-        .setMaxBufferedDocs(5));
-    ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
-    iw.addIndexes(new Directory[] { dir1, dir2 });
+    IndexWriter iw = new IndexWriter(
+        dir3,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, anlzr).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(5).
+            setMergePolicy(newLogMergePolicy(3))
+    );
+    iw.addIndexes(dir1, dir2);
     iw.optimize();
     iw.close();
 
@@ -128,9 +131,13 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
     doTestNorms(random, dir3);
 
     // now with optimize
-    iw = new IndexWriter(dir3, newIndexWriterConfig( TEST_VERSION_CURRENT,
-        anlzr).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(5));
-    ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
+    iw = new IndexWriter(
+        dir3,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, anlzr).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(5).
+            setMergePolicy(newLogMergePolicy(3))
+    );
     iw.optimize();
     iw.close();
     verifyIndex(dir3);
@@ -162,7 +169,7 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
   public void testNormsClose() throws IOException { 
     Directory dir1 = newDirectory(); 
     TestIndexReaderReopen.createIndex(random, dir1, false);
-    SegmentReader reader1 = SegmentReader.getOnlySegmentReader(dir1);
+    SegmentReader reader1 = getOnlySegmentReader(IndexReader.open(dir1, false));
     reader1.norms("field1");
     Norm r1norm = reader1.norms.get("field1");
     AtomicInteger r1BytesRef = r1norm.bytesRef();
@@ -181,7 +188,7 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
     IndexReader reader1 = IndexReader.open(dir1, false);
         
     IndexReader reader2C = (IndexReader) reader1.clone();
-    SegmentReader segmentReader2C = SegmentReader.getOnlySegmentReader(reader2C);
+    SegmentReader segmentReader2C = getOnlySegmentReader(reader2C);
     segmentReader2C.norms("field1"); // load the norms for the field
     Norm reader2CNorm = segmentReader2C.norms.get("field1");
     assertTrue("reader2CNorm.bytesRef()=" + reader2CNorm.bytesRef(), reader2CNorm.bytesRef().get() == 2);
@@ -189,13 +196,13 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
     
     
     IndexReader reader3C = (IndexReader) reader2C.clone();
-    SegmentReader segmentReader3C = SegmentReader.getOnlySegmentReader(reader3C);
+    SegmentReader segmentReader3C = getOnlySegmentReader(reader3C);
     Norm reader3CCNorm = segmentReader3C.norms.get("field1");
     assertEquals(3, reader3CCNorm.bytesRef().get());
     
     // edit a norm and the refcount should be 1
     IndexReader reader4C = (IndexReader) reader3C.clone();
-    SegmentReader segmentReader4C = SegmentReader.getOnlySegmentReader(reader4C);
+    SegmentReader segmentReader4C = getOnlySegmentReader(reader4C);
     assertEquals(4, reader3CCNorm.bytesRef().get());
     reader4C.setNorm(5, "field1", 0.33f);
     
@@ -215,7 +222,7 @@ public class TestIndexReaderCloneNorms extends LuceneTestCase {
     assertEquals(1, reader4CCNorm.bytesRef().get());
         
     IndexReader reader5C = (IndexReader) reader4C.clone();
-    SegmentReader segmentReader5C = SegmentReader.getOnlySegmentReader(reader5C);
+    SegmentReader segmentReader5C = getOnlySegmentReader(reader5C);
     Norm reader5CCNorm = segmentReader5C.norms.get("field1");
     reader5C.setNorm(5, "field1", 0.7f);
     assertEquals(1, reader5CCNorm.bytesRef().get());
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java b/lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
index ee2821a..6221304 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexReaderReopen.java
@@ -230,9 +230,8 @@ public class TestIndexReaderReopen extends LuceneTestCase {
 
       @Override
       protected IndexReader openReader() throws IOException {
-        return new MultiReader(new IndexReader[] 
-                        {IndexReader.open(dir1, false), 
-                         IndexReader.open(dir2, false)});
+        return new MultiReader(IndexReader.open(dir1, false),
+            IndexReader.open(dir2, false));
       }
       
     });
@@ -256,12 +255,11 @@ public class TestIndexReaderReopen extends LuceneTestCase {
 
       @Override
       protected IndexReader openReader() throws IOException {
-        return new MultiReader(new IndexReader[] 
-                        {IndexReader.open(dir3, false), 
-                         IndexReader.open(dir4, false),
-                         // Does not implement reopen, so
-                         // hits exception:
-                         new FilterIndexReader(IndexReader.open(dir3, false))});
+        return new MultiReader(IndexReader.open(dir3, false),
+            IndexReader.open(dir4, false),
+            // Does not implement reopen, so
+            // hits exception:
+            new FilterIndexReader(IndexReader.open(dir3, false)));
       }
       
     });
@@ -297,10 +295,8 @@ public class TestIndexReaderReopen extends LuceneTestCase {
         ParallelReader pr = new ParallelReader();
         pr.add(IndexReader.open(dir1, false));
         pr.add(IndexReader.open(dir2, false));
-        MultiReader mr = new MultiReader(new IndexReader[] {
-            IndexReader.open(dir3, false), IndexReader.open(dir4, false)});
-        return new MultiReader(new IndexReader[] {
-           pr, mr, IndexReader.open(dir5, false)});
+        MultiReader mr = new MultiReader(IndexReader.open(dir3, false), IndexReader.open(dir4, false));
+        return new MultiReader(pr, mr, IndexReader.open(dir5, false));
       }
     });
     dir1.close();
@@ -612,7 +608,7 @@ public class TestIndexReaderReopen extends LuceneTestCase {
     createIndex(random, dir1, false);
     
     IndexReader reader1 = IndexReader.open(dir1, false);
-    SegmentReader segmentReader1 = SegmentReader.getOnlySegmentReader(reader1);
+    SegmentReader segmentReader1 = getOnlySegmentReader(reader1);
     IndexReader modifier = IndexReader.open(dir1, false);
     modifier.deleteDocument(0);
     modifier.close();
@@ -624,7 +620,7 @@ public class TestIndexReaderReopen extends LuceneTestCase {
     modifier.close();
     
     IndexReader reader3 = reader2.reopen();
-    SegmentReader segmentReader3 = SegmentReader.getOnlySegmentReader(reader3);
+    SegmentReader segmentReader3 = getOnlySegmentReader(reader3);
     modifier = IndexReader.open(dir1, false);
     modifier.deleteDocument(2);
     modifier.close();
@@ -1167,7 +1163,7 @@ public class TestIndexReaderReopen extends LuceneTestCase {
 
     IndexReader[] rs2 = r2.getSequentialSubReaders();
 
-    SegmentReader sr1 = SegmentReader.getOnlySegmentReader(r1);
+    SegmentReader sr1 = getOnlySegmentReader(r1);
     SegmentReader sr2 = (SegmentReader) rs2[0];
 
     // At this point they share the same BitVector
@@ -1190,9 +1186,13 @@ public class TestIndexReaderReopen extends LuceneTestCase {
 
   public void testReopenOnCommit() throws Throwable {
     Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-                                                                   TEST_VERSION_CURRENT, new MockAnalyzer()).setIndexDeletionPolicy(new KeepAllCommits()).setMaxBufferedDocs(-1));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setIndexDeletionPolicy(new KeepAllCommits()).
+            setMaxBufferedDocs(-1).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     for(int i=0;i<4;i++) {
       Document doc = new Document();
       doc.add(newField("id", ""+i, Field.Store.NO, Field.Index.NOT_ANALYZED));
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
index 35031e0..c41c765 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriter.java
@@ -495,8 +495,13 @@ public class TestIndexWriter extends LuceneTestCase {
      */
     public void testCommitOnCloseDiskUsage() throws IOException {
       MockDirectoryWrapper dir = newDirectory();      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10).setReaderPooling(false));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer  = new IndexWriter(
+          dir,
+          newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(10).
+              setReaderPooling(false).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       for(int j=0;j<30;j++) {
         addDocWithIndex(writer, j);
       }
@@ -505,10 +510,16 @@ public class TestIndexWriter extends LuceneTestCase {
 
       dir.setTrackDiskUsage(true);
       long startDiskUsage = dir.getMaxUsedSizeInBytes();
-      writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(10).setMergeScheduler(
-                               new SerialMergeScheduler()).setReaderPooling(false));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
+              .setOpenMode(OpenMode.APPEND).
+              setMaxBufferedDocs(10).
+              setMergeScheduler(new SerialMergeScheduler()).
+              setReaderPooling(false).
+              setMergePolicy(newLogMergePolicy(10))
+
+      );
       for(int j=0;j<1470;j++) {
         addDocWithIndex(writer, j);
       }
@@ -546,8 +557,12 @@ public class TestIndexWriter extends LuceneTestCase {
       // test uses IW.rollback which easily results in
       // writing to same file more than once
       dir.setPreventDoubleWrite(false);
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(10).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       for(int j=0;j<17;j++) {
         addDocWithIndex(writer, j);
       }
@@ -657,8 +672,12 @@ public class TestIndexWriter extends LuceneTestCase {
 
     public void testSmallRAMBuffer() throws IOException {
       MockDirectoryWrapper dir = newDirectory();      
-      IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.000001));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer  = new IndexWriter(
+          dir,
+          newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setRAMBufferSizeMB(0.000001).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       int lastNumFile = dir.listAll().length;
       for(int j=0;j<9;j++) {
         Document doc = new Document();
@@ -674,133 +693,6 @@ public class TestIndexWriter extends LuceneTestCase {
       dir.close();
     }
 
-    /**
-     * Make sure it's OK to change RAM buffer size and // maxBufferedDocs in a
-     * write session
-     * 
-     * @deprecated after all the setters on IW go away (4.0), this test can be
-     *             removed because changing ram buffer settings during a write
-     *             session won't be possible.
-     */
-    @Deprecated
-    public void testChangingRAMBuffer() throws IOException {
-      MockDirectoryWrapper dir = newDirectory();      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10).setRAMBufferSizeMB(
-        IndexWriterConfig.DISABLE_AUTO_FLUSH));
-
-      int lastFlushCount = -1;
-      for(int j=1;j<52;j++) {
-        Document doc = new Document();
-        doc.add(newField("field", "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
-        writer.addDocument(doc);
-        _TestUtil.syncConcurrentMerges(writer);
-        int flushCount = writer.getFlushCount();
-        if (j == 1)
-          lastFlushCount = flushCount;
-        else if (j < 10)
-          // No new files should be created
-          assertEquals(flushCount, lastFlushCount);
-        else if (10 == j) {
-          assertTrue(flushCount > lastFlushCount);
-          lastFlushCount = flushCount;
-          writer.setRAMBufferSizeMB(0.000001);
-          writer.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-        } else if (j < 20) {
-          assertTrue(flushCount > lastFlushCount);
-          lastFlushCount = flushCount;
-        } else if (20 == j) {
-          writer.setRAMBufferSizeMB(16);
-          writer.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-          lastFlushCount = flushCount;
-        } else if (j < 30) {
-          assertEquals(flushCount, lastFlushCount);
-        } else if (30 == j) {
-          writer.setRAMBufferSizeMB(0.000001);
-          writer.setMaxBufferedDocs(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-        } else if (j < 40) {
-          assertTrue(flushCount> lastFlushCount);
-          lastFlushCount = flushCount;
-        } else if (40 == j) {
-          writer.setMaxBufferedDocs(10);
-          writer.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-          lastFlushCount = flushCount;
-        } else if (j < 50) {
-          assertEquals(flushCount, lastFlushCount);
-          writer.setMaxBufferedDocs(10);
-          writer.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-        } else if (50 == j) {
-          assertTrue(flushCount > lastFlushCount);
-        }
-      }
-      writer.close();
-      dir.close();
-    }
-
-    /**
-     * @deprecated after setters on IW go away, this test can be deleted because
-     *             changing those settings on IW won't be possible.
-     */
-    @Deprecated
-    public void testChangingRAMBuffer2() throws IOException {
-      MockDirectoryWrapper dir = newDirectory();      
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10).setMaxBufferedDeleteTerms(
-        10).setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH));
-
-      for(int j=1;j<52;j++) {
-        Document doc = new Document();
-        doc.add(newField("field", "aaa" + j, Field.Store.YES, Field.Index.ANALYZED));
-        writer.addDocument(doc);
-      }
-      
-      int lastFlushCount = -1;
-      for(int j=1;j<52;j++) {
-        writer.deleteDocuments(new Term("field", "aaa" + j));
-        _TestUtil.syncConcurrentMerges(writer);
-        int flushCount = writer.getFlushCount();
-        if (j == 1)
-          lastFlushCount = flushCount;
-        else if (j < 10) {
-          // No new files should be created
-          assertEquals(flushCount, lastFlushCount);
-        } else if (10 == j) {
-          assertTrue(flushCount > lastFlushCount);
-          lastFlushCount = flushCount;
-          writer.setRAMBufferSizeMB(0.000001);
-          writer.setMaxBufferedDeleteTerms(1);
-        } else if (j < 20) {
-          assertTrue(flushCount > lastFlushCount);
-          lastFlushCount = flushCount;
-        } else if (20 == j) {
-          writer.setRAMBufferSizeMB(16);
-          writer.setMaxBufferedDeleteTerms(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-          lastFlushCount = flushCount;
-        } else if (j < 30) {
-          assertEquals(flushCount, lastFlushCount);
-        } else if (30 == j) {
-          writer.setRAMBufferSizeMB(0.000001);
-          writer.setMaxBufferedDeleteTerms(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-          writer.setMaxBufferedDeleteTerms(1);
-        } else if (j < 40) {
-          assertTrue(flushCount> lastFlushCount);
-          lastFlushCount = flushCount;
-        } else if (40 == j) {
-          writer.setMaxBufferedDeleteTerms(10);
-          writer.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-          lastFlushCount = flushCount;
-        } else if (j < 50) {
-          assertEquals(flushCount, lastFlushCount);
-          writer.setMaxBufferedDeleteTerms(10);
-          writer.setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH);
-        } else if (50 == j) {
-          assertTrue(flushCount > lastFlushCount);
-        }
-      }
-      writer.close();
-      dir.close();
-    }
-
     public void testDiverseDocs() throws IOException {
       MockDirectoryWrapper dir = newDirectory();      
       IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.5));
@@ -968,11 +860,14 @@ public class TestIndexWriter extends LuceneTestCase {
 
     public void testFlushWithNoMerging() throws IOException {
       Directory dir = newDirectory();
-      IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
-        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
-      ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(2).
+              setMergePolicy(newLogMergePolicy(10))
+      );
       Document doc = new Document();
-      doc.add(newField("field", "aaa", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
+      doc.add(newField("field", "aaa", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
       for(int i=0;i<19;i++)
         writer.addDocument(doc);
       writer.flush(false, true, true);
@@ -1010,12 +905,15 @@ public class TestIndexWriter extends LuceneTestCase {
 
       Directory dir = newDirectory();
       for(int pass=0;pass<2;pass++) {
-        IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-          TEST_VERSION_CURRENT, new MockAnalyzer())
-          .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2));
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(101);
+        IndexWriter writer = new IndexWriter(
+            dir,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+                setOpenMode(OpenMode.CREATE).
+                setMaxBufferedDocs(2).
+                setMergePolicy(newLogMergePolicy(101))
+        );
         Document doc = new Document();
-        doc.add(newField("field", "aaa", Field.Store.YES, Field.Index.ANALYZED, Field.TermVector.WITH_POSITIONS_OFFSETS));
+        doc.add(newField("field", "aaa", Store.YES, Index.ANALYZED, TermVector.WITH_POSITIONS_OFFSETS));
         for(int i=0;i<200;i++)
           writer.addDocument(doc);
         writer.optimize(false);
@@ -1200,20 +1098,17 @@ public class TestIndexWriter extends LuceneTestCase {
 
     for(int pass=0;pass<2;pass++) {
 
-      IndexWriterConfig conf = newIndexWriterConfig(
-          TEST_VERSION_CURRENT, new MockAnalyzer()).setOpenMode(OpenMode.CREATE)
-          .setMaxBufferedDocs(2);
-      if (pass == 2) {
-        conf.setMergeScheduler(new SerialMergeScheduler());
-      }
-      IndexWriter writer = new IndexWriter(directory, conf);
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
+      IndexWriter writer = new IndexWriter(
+          directory,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setOpenMode(OpenMode.CREATE).
+              setMaxBufferedDocs(2).
+              // have to use compound file to prevent running out of
+              // descripters when newDirectory returns a file-system
+              // backed directory:
+              setMergePolicy(newLogMergePolicy(false, 10))
+      );
 
-      // have to use compound file to prevent running out of
-      // descripters when newDirectory returns a file-system
-      // backed directory:
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(true);
-      
       //System.out.println("TEST: pass=" + pass + " cms=" + (pass >= 2));
       for(int iter=0;iter<10;iter++) {
         //System.out.println("TEST: iter=" + iter);
@@ -1309,10 +1204,12 @@ public class TestIndexWriter extends LuceneTestCase {
   public void testForceCommit() throws IOException {
     Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(5))
+    );
     writer.commit();
     
     for (int i = 0; i < 23; i++)
@@ -1412,21 +1309,23 @@ public class TestIndexWriter extends LuceneTestCase {
   // LUCENE-325: test expungeDeletes, when many adjacent merges are required
   public void testExpungeDeletes2() throws IOException {
     Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2).setRAMBufferSizeMB(
-            IndexWriterConfig.DISABLE_AUTO_FLUSH));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(50);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).
+            setMergePolicy(newLogMergePolicy(50))
+    );
 
     Document document = new Document();
 
     document = new Document();
-    Field storedField = newField("stored", "stored", Field.Store.YES,
-                                  Field.Index.NO);
+    Field storedField = newField("stored", "stored", Store.YES,
+                                  Index.NO);
     document.add(storedField);
     Field termVectorField = newField("termVector", "termVector",
-                                      Field.Store.NO, Field.Index.NOT_ANALYZED,
-                                      Field.TermVector.WITH_POSITIONS_OFFSETS);
+                                      Store.NO, Index.NOT_ANALYZED,
+                                      TermVector.WITH_POSITIONS_OFFSETS);
     document.add(termVectorField);
     for(int i=0;i<98;i++)
       writer.addDocument(document);
@@ -1440,9 +1339,11 @@ public class TestIndexWriter extends LuceneTestCase {
     assertEquals(49, ir.numDocs());
     ir.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT,
-        new MockAnalyzer()));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(3);
+    writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(3))
+    );
     assertEquals(49, writer.numDocs());
     writer.expungeDeletes();
     writer.close();
@@ -1457,11 +1358,13 @@ public class TestIndexWriter extends LuceneTestCase {
   // many adjacent merges are required
   public void testExpungeDeletes3() throws IOException {
     Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( 
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2).setRAMBufferSizeMB(
-            IndexWriterConfig.DISABLE_AUTO_FLUSH));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(50);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setRAMBufferSizeMB(IndexWriterConfig.DISABLE_AUTO_FLUSH).
+            setMergePolicy(newLogMergePolicy(50))
+    );
 
     Document document = new Document();
 
@@ -1485,9 +1388,11 @@ public class TestIndexWriter extends LuceneTestCase {
     assertEquals(49, ir.numDocs());
     ir.close();
 
-    writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-    // Force many merges to happen
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(3);
+    writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(3))
+    );
     writer.expungeDeletes(false);
     writer.close();
     ir = IndexReader.open(dir, true);
@@ -1836,8 +1741,12 @@ public class TestIndexWriter extends LuceneTestCase {
   public void testPrepareCommit() throws IOException {
     Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(5))
+    );
     writer.commit();
     
     for (int i = 0; i < 23; i++)
@@ -1888,8 +1797,12 @@ public class TestIndexWriter extends LuceneTestCase {
     MockDirectoryWrapper dir = newDirectory();
     dir.setPreventDoubleWrite(false);
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(5))
+    );
     writer.commit();
     
     for (int i = 0; i < 23; i++)
@@ -2091,7 +2004,7 @@ public class TestIndexWriter extends LuceneTestCase {
 
     IndexReader r1 = IndexReader.open(dir2, true);
     IndexReader r2 = (IndexReader) r1.clone();
-    writer.addIndexes(new IndexReader[] {r1, r2});
+    writer.addIndexes(r1, r2);
     writer.close();
 
     IndexReader r3 = IndexReader.open(dir, true);
@@ -2564,11 +2477,13 @@ public class TestIndexWriter extends LuceneTestCase {
   }
 
   public void testDeleteUnusedFiles() throws Exception {
-
     for(int iter=0;iter<2;iter++) {
       Directory dir = newDirectory();
-      IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-      ((LogMergePolicy) w.getMergePolicy()).setUseCompoundFile(true);
+      IndexWriter w = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMergePolicy(newLogMergePolicy(true))
+      );
       Document doc = new Document();
       doc.add(newField("field", "go", Field.Store.NO, Field.Index.ANALYZED));
       w.addDocument(doc);
@@ -2965,7 +2880,7 @@ public class TestIndexWriter extends LuceneTestCase {
 
     Directory dir = newDirectory();
     IndexWriter indexWriter = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setRAMBufferSizeMB(0.01));
-    ((LogMergePolicy) indexWriter.getMergePolicy()).setUseCompoundFile(false);
+    ((LogMergePolicy) indexWriter.getConfig().getMergePolicy()).setUseCompoundFile(false);
 
     String BIG="alskjhlaksjghlaksjfhalksvjepgjioefgjnsdfjgefgjhelkgjhqewlrkhgwlekgrhwelkgjhwelkgrhwlkejg";
     BIG=BIG+BIG+BIG+BIG;
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
index 0ccfda2..29ea32d 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterConfig.java
@@ -249,52 +249,4 @@ public class TestIndexWriterConfig extends LuceneTestCase {
     conf.setMergePolicy(null);
     assertEquals(LogByteSizeMergePolicy.class, conf.getMergePolicy().getClass());
   }
-
-  /**
-   * @deprecated should be removed once all the deprecated setters are removed
-   *             from IndexWriter.
-   */
-  @Test @Deprecated
-  public void testIndexWriterSetters() throws Exception {
-    // This test intentionally tests deprecated methods. The purpose is to pass
-    // whatever the user set on IW to IWC, so that if the user calls
-    // iw.getConfig().getXYZ(), he'll get the same value he passed to
-    // iw.setXYZ().
-    IndexWriterConfig conf = new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer());
-    Directory dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, conf);
-
-    writer.setSimilarity(new MySimilarity());
-    assertEquals(MySimilarity.class, writer.getConfig().getSimilarity().getClass());
-
-    writer.setMaxBufferedDeleteTerms(4);
-    assertEquals(4, writer.getConfig().getMaxBufferedDeleteTerms());
-
-    writer.setMaxBufferedDocs(10);
-    assertEquals(10, writer.getConfig().getMaxBufferedDocs());
-
-    writer.setMaxFieldLength(10);
-    assertEquals(10, writer.getConfig().getMaxFieldLength());
-    
-    writer.setMergeScheduler(new SerialMergeScheduler());
-    assertEquals(SerialMergeScheduler.class, writer.getConfig().getMergeScheduler().getClass());
-    
-    writer.setRAMBufferSizeMB(1.5);
-    assertEquals(1.5, writer.getConfig().getRAMBufferSizeMB(), 0.0);
-    
-    writer.setTermIndexInterval(40);
-    assertEquals(40, writer.getConfig().getTermIndexInterval());
-    
-    writer.setWriteLockTimeout(100);
-    assertEquals(100, writer.getConfig().getWriteLockTimeout());
-    
-    writer.setMergedSegmentWarmer(new MyWarmer());
-    assertEquals(MyWarmer.class, writer.getConfig().getMergedSegmentWarmer().getClass());
-    
-    writer.setMergePolicy(new LogDocMergePolicy());
-    assertEquals(LogDocMergePolicy.class, writer.getConfig().getMergePolicy().getClass());
-    writer.close();
-    dir.close();
-  }
-
 }
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
index fd9428e..8c171ba 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterDelete.java
@@ -794,7 +794,7 @@ public class TestIndexWriterDelete extends LuceneTestCase {
 
   public void testDeleteNullQuery() throws IOException {
     Directory dir = newDirectory();
-    IndexWriter modifier = new IndexWriter(dir, new MockAnalyzer(MockTokenizer.WHITESPACE, false), IndexWriter.MaxFieldLength.UNLIMITED);
+    IndexWriter modifier = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
 
     for (int i = 0; i < 5; i++) {
       addDoc(modifier, i, 2*i);
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
index dfbca0a..790f949 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterExceptions.java
@@ -612,8 +612,12 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
       MockDirectoryWrapper dir = newDirectory();
 
       {
-        final IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(-1));
-        ((LogMergePolicy) writer.getMergePolicy()).setMergeFactor(10);
+        final  IndexWriter writer = new IndexWriter(
+            dir,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
+                setMaxBufferedDocs(-1).
+                setMergePolicy(newLogMergePolicy(10))
+        );
         final int finalI = i;
 
         Thread[] threads = new Thread[NUM_THREAD];
@@ -740,10 +744,14 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
     FailOnlyInSync failure = new FailOnlyInSync();
     dir.failOn(failure);
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergeScheduler(new ConcurrentMergeScheduler()).
+            setMergePolicy(newLogMergePolicy(5))
+    );
     failure.setDoFail();
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(5);
 
     for (int i = 0; i < 23; i++) {
       addDoc(writer);
@@ -1005,9 +1013,12 @@ public class TestIndexWriterExceptions extends LuceneTestCase {
 
       IndexWriter writer = null;
 
-      writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-      ((LogMergePolicy) writer.getMergePolicy()).setUseCompoundFile(true);
-      ((LogMergePolicy) writer.getMergePolicy()).setNoCFSRatio(1.0);
+      writer  = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMergePolicy(newLogMergePolicy(true))
+      );
+      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setNoCFSRatio(1.0);
 
       // add 100 documents
       for (int i = 0; i < 100; i++) {
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
index 7d77696..ecb44b9 100755
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterMergePolicy.java
@@ -100,9 +100,12 @@ public class TestIndexWriterMergePolicy extends LuceneTestCase {
   public void testMergeFactorChange() throws IOException {
     Directory dir = newDirectory();
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(10).setMergePolicy(new LogDocMergePolicy()));
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy())
+    );
 
     for (int i = 0; i < 250; i++) {
       addDoc(writer);
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
index 7b6412b..804db65 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterMerging.java
@@ -55,10 +55,13 @@ public class TestIndexWriterMerging extends LuceneTestCase
 
     Directory merged = newDirectory();
 
-    IndexWriter writer = new IndexWriter(merged, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
+    IndexWriter writer = new IndexWriter(
+        merged,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(2))
+    );
 
-    writer.addIndexes(new Directory[]{indexA, indexB});
+    writer.addIndexes(indexA, indexB);
     writer.optimize();
     writer.close();
 
@@ -94,11 +97,13 @@ public class TestIndexWriterMerging extends LuceneTestCase
 
   private void fillIndex(Random random, Directory dir, int start, int numDocs) throws IOException {
 
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, 
-        new MockAnalyzer())
-        .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(2))
+    );
 
     for (int i = start; i < (start + numDocs); i++)
     {
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
index 0eefee1..1192bf0 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull.java
@@ -441,9 +441,13 @@ public class TestIndexWriterOnDiskFull extends LuceneTestCase {
   public void testCorruptionAfterDiskFullDuringMerge() throws IOException {
     MockDirectoryWrapper dir = newDirectory();
     //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));
-
-    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);
+    IndexWriter w = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergeScheduler(new SerialMergeScheduler()).
+            setReaderPooling(true).
+            setMergePolicy(newLogMergePolicy(2))
+    );
 
     Document doc = new Document();
     doc.add(newField("f", "doctor who", Field.Store.YES, Field.Index.ANALYZED));
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
index 8a551cd..692dda6 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterReader.java
@@ -163,7 +163,7 @@ public class TestIndexWriterReader extends LuceneTestCase {
 
     IndexReader r0 = writer.getReader();
     assertTrue(r0.isCurrent());
-    writer.addIndexes(new Directory[] { dir2 });
+    writer.addIndexes(dir2);
     assertFalse(r0.isCurrent());
     r0.close();
 
@@ -204,11 +204,11 @@ public class TestIndexWriterReader extends LuceneTestCase {
     createIndexNoClose(!optimize, "index2", writer2);
     writer2.close();
 
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
-    writer.addIndexes(new Directory[] { dir2 });
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
+    writer.addIndexes(dir2);
 
     IndexReader r1 = writer.getReader();
     assertEquals(500, r1.maxDoc());
@@ -547,9 +547,14 @@ public class TestIndexWriterReader extends LuceneTestCase {
     Directory dir1 = newDirectory();
     // Enroll warmer
     MyWarmer warmer = new MyWarmer();
-    IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2).setMergedSegmentWarmer(warmer).setMergeScheduler(new ConcurrentMergeScheduler()));
+    IndexWriter writer = new IndexWriter(
+        dir1,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergedSegmentWarmer(warmer).
+            setMergeScheduler(new ConcurrentMergeScheduler()).
+            setMergePolicy(newLogMergePolicy())
+    );
     writer.setInfoStream(infoStream);
 
     // create the index
@@ -642,9 +647,12 @@ public class TestIndexWriterReader extends LuceneTestCase {
   // Stress test reopen during addIndexes
   public void testDuringAddIndexes() throws Exception {
     MockDirectoryWrapper dir1 = newDirectory();
-    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
+    final IndexWriter writer = new IndexWriter(
+        dir1,
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(2))
+    );
     writer.setInfoStream(infoStream);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
 
     // create the index
     createIndexNoClose(false, "test", writer);
@@ -722,9 +730,12 @@ public class TestIndexWriterReader extends LuceneTestCase {
   // Stress test reopen during add/delete
   public void testDuringAddDelete() throws Exception {
     Directory dir1 = newDirectory();
-    final IndexWriter writer = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
+    final IndexWriter writer = new IndexWriter(
+        dir1,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(2))
+    );
     writer.setInfoStream(infoStream);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
 
     // create the index
     createIndexNoClose(false, "test", writer);
@@ -867,18 +878,22 @@ public class TestIndexWriterReader extends LuceneTestCase {
   public void testSegmentWarmer() throws Exception {
     Directory dir = newDirectory();
     final AtomicBoolean didWarm = new AtomicBoolean();
-    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-                                    .setMaxBufferedDocs(2).setReaderPooling(true));
-    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(10);
-    w.setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {
-        public void warm(IndexReader r) throws IOException {
-          final IndexSearcher s = new IndexSearcher(r);
-          final TopDocs hits = s.search(new TermQuery(new Term("foo", "bar")), 10);
-          assertEquals(20, hits.totalHits);
-          didWarm.set(true);
-        }
-      });
-    
+    IndexWriter w = new IndexWriter(
+        dir,
+        newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setReaderPooling(true).
+            setMergedSegmentWarmer(new IndexWriter.IndexReaderWarmer() {
+              public void warm(IndexReader r) throws IOException {
+                IndexSearcher s = new IndexSearcher(r);
+                TopDocs hits = s.search(new TermQuery(new Term("foo", "bar")), 10);
+                assertEquals(20, hits.totalHits);
+                didWarm.set(true);
+              }
+            }).
+            setMergePolicy(newLogMergePolicy(10))
+    );
+
     Document doc = new Document();
     doc.add(newField("foo", "bar", Field.Store.YES, Field.Index.NOT_ANALYZED));
     for(int i=0;i<20;i++) {
diff --git a/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java b/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
index 44673af..35d4ce3 100644
--- a/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
+++ b/lucene/src/test/org/apache/lucene/index/TestIndexWriterWithThreads.java
@@ -107,12 +107,14 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
 
     for(int iter=0;iter<10;iter++) {
       MockDirectoryWrapper dir = newDirectory();
-      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler());
-      // We expect disk full exceptions in the merge threads
-      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
-      IndexWriter writer = new IndexWriter(dir, conf);
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(2).
+              setMergeScheduler(new ConcurrentMergeScheduler()).
+              setMergePolicy(newLogMergePolicy(4))
+      );
+      ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
       dir.setMaxSizeInBytes(4*1024+20*iter);
 
       IndexerThread[] threads = new IndexerThread[NUM_THREADS];
@@ -148,12 +150,15 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
 
     for(int iter=0;iter<7;iter++) {
       Directory dir = newDirectory();
-      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-        .setMaxBufferedDocs(10).setMergeScheduler(new ConcurrentMergeScheduler());
-      // We expect AlreadyClosedException
-      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
-      IndexWriter writer = new IndexWriter(dir, conf);
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(10).
+              setMergeScheduler(new ConcurrentMergeScheduler()).
+              setMergePolicy(newLogMergePolicy(4))
+      );
+      ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
 
       IndexerThread[] threads = new IndexerThread[NUM_THREADS];
 
@@ -210,12 +215,15 @@ public class TestIndexWriterWithThreads extends LuceneTestCase {
 
     for(int iter=0;iter<2;iter++) {
       MockDirectoryWrapper dir = newDirectory();
-      IndexWriterConfig conf = newIndexWriterConfig( TEST_VERSION_CURRENT,
-          new MockAnalyzer()).setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler());
-      // We expect disk full exceptions in the merge threads
-      ((ConcurrentMergeScheduler) conf.getMergeScheduler()).setSuppressExceptions();
-      IndexWriter writer = new IndexWriter(dir, conf);
-      ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(4);
+
+      IndexWriter writer = new IndexWriter(
+          dir,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(2).
+              setMergeScheduler(new ConcurrentMergeScheduler()).
+              setMergePolicy(newLogMergePolicy(4))
+      );
+      ((ConcurrentMergeScheduler) writer.getConfig().getMergeScheduler()).setSuppressExceptions();
 
       IndexerThread[] threads = new IndexerThread[NUM_THREADS];
 
diff --git a/lucene/src/test/org/apache/lucene/index/TestLazyBug.java b/lucene/src/test/org/apache/lucene/index/TestLazyBug.java
index 617d841..a27983b 100755
--- a/lucene/src/test/org/apache/lucene/index/TestLazyBug.java
+++ b/lucene/src/test/org/apache/lucene/index/TestLazyBug.java
@@ -17,19 +17,12 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import java.util.Arrays;
-import java.util.HashSet;
 import java.util.Iterator;
 import java.util.List;
-import java.util.Random;
 import java.util.Set;
 
 import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.FieldSelector;
-import org.apache.lucene.document.FieldSelectorResult;
-import org.apache.lucene.document.Fieldable;
+import org.apache.lucene.document.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -53,7 +46,7 @@ public class TestLazyBug extends LuceneTestCase {
     "this string is a bigger string, mary had a little lamb, little lamb, little lamb!"
   };
 
-  private static Set<String> dataset = new HashSet<String>(Arrays.asList(data));
+  private static Set<String> dataset = asSet(data);
   
   private static String MAGIC_FIELD = "f"+(NUM_FIELDS/3);
   
diff --git a/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java b/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
index beca845..fd1dc56 100755
--- a/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
+++ b/lucene/src/test/org/apache/lucene/index/TestLazyProxSkipping.java
@@ -69,9 +69,12 @@ public class TestLazyProxSkipping extends LuceneTestCase {
         int numDocs = 500;
         
         Directory directory = new SeekCountingDirectory(new RAMDirectory());
-        IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).setMaxBufferedDocs(10));
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
+        IndexWriter writer = new IndexWriter(
+            directory,
+            newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, true, false)).
+                setMaxBufferedDocs(10).
+                setMergePolicy(newLogMergePolicy(false))
+        );
         for (int i = 0; i < numDocs; i++) {
             Document doc = new Document();
             String content;
@@ -93,8 +96,8 @@ public class TestLazyProxSkipping extends LuceneTestCase {
         // make sure the index has only a single segment
         writer.optimize();
         writer.close();
-        
-        SegmentReader reader = SegmentReader.getOnlySegmentReader(directory);
+
+      SegmentReader reader = getOnlySegmentReader(IndexReader.open(directory, false));
 
         this.searcher = new IndexSearcher(reader);        
     }
diff --git a/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java b/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
index ca1dca0..10dbc4f 100644
--- a/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
+++ b/lucene/src/test/org/apache/lucene/index/TestMultiLevelSkipList.java
@@ -80,7 +80,7 @@ public class TestMultiLevelSkipList extends LuceneTestCase {
     writer.optimize();
     writer.close();
 
-    IndexReader reader = SegmentReader.getOnlySegmentReader(IndexReader.open(dir));
+    IndexReader reader = getOnlySegmentReader(IndexReader.open(dir));
     
     for (int i = 0; i < 2; i++) {
       counter = 0;
diff --git a/lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java b/lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java
index cf62fd4..3b84e2d 100644
--- a/lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java
+++ b/lucene/src/test/org/apache/lucene/index/TestNRTReaderWithThreads.java
@@ -31,10 +31,12 @@ public class TestNRTReaderWithThreads extends LuceneTestCase {
 
   public void testIndexing() throws Exception {
     Directory mainDir = newDirectory();
-    IndexWriter writer = new IndexWriter(mainDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(10));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
+    IndexWriter writer = new IndexWriter(
+        mainDir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(false,2))
+    );
     IndexReader reader = writer.getReader(); // start pooling readers
     reader.close();
     RunThread[] indexThreads = new RunThread[4];
diff --git a/lucene/src/test/org/apache/lucene/index/TestNorms.java b/lucene/src/test/org/apache/lucene/index/TestNorms.java
index 77ab215..33a7baa 100755
--- a/lucene/src/test/org/apache/lucene/index/TestNorms.java
+++ b/lucene/src/test/org/apache/lucene/index/TestNorms.java
@@ -96,11 +96,14 @@ public class TestNorms extends LuceneTestCase {
     Directory dir3 = newDirectory();
 
     createIndex(random, dir3);
-    IndexWriter iw = new IndexWriter(dir3, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, anlzr).setOpenMode(OpenMode.APPEND)
-        .setMaxBufferedDocs(5));
-    ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
-    iw.addIndexes(new Directory[]{dir1,dir2});
+    IndexWriter iw = new IndexWriter(
+        dir3,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, anlzr).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(5).
+            setMergePolicy(newLogMergePolicy(3))
+    );
+    iw.addIndexes(dir1,dir2);
     iw.optimize();
     iw.close();
     
@@ -115,9 +118,13 @@ public class TestNorms extends LuceneTestCase {
     doTestNorms(random, dir3);
     
     // now with optimize
-    iw = new IndexWriter(dir3, newIndexWriterConfig( TEST_VERSION_CURRENT,
-        anlzr).setOpenMode(OpenMode.APPEND).setMaxBufferedDocs(5));
-    ((LogMergePolicy) iw.getConfig().getMergePolicy()).setMergeFactor(3);
+    iw = new IndexWriter(
+        dir3,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, anlzr).
+            setOpenMode(OpenMode.APPEND).
+            setMaxBufferedDocs(5).
+            setMergePolicy(newLogMergePolicy(3))
+    );
     iw.optimize();
     iw.close();
     verifyIndex(dir3);
diff --git a/lucene/src/test/org/apache/lucene/index/TestOmitTf.java b/lucene/src/test/org/apache/lucene/index/TestOmitTf.java
index cacf4d6..b094423 100644
--- a/lucene/src/test/org/apache/lucene/index/TestOmitTf.java
+++ b/lucene/src/test/org/apache/lucene/index/TestOmitTf.java
@@ -93,7 +93,7 @@ public class TestOmitTf extends LuceneTestCase {
     writer.close();
     _TestUtil.checkIndex(ram);
 
-    SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
+    SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
     FieldInfos fi = reader.fieldInfos();
     assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f1").omitTermFreqAndPositions);
     assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f2").omitTermFreqAndPositions);
@@ -107,9 +107,12 @@ public class TestOmitTf extends LuceneTestCase {
   public void testMixedMerge() throws Exception {
     Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(3));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
+    IndexWriter writer = new IndexWriter(
+        ram,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
+            setMaxBufferedDocs(3).
+            setMergePolicy(newLogMergePolicy(2))
+    );
     Document d = new Document();
         
     // this field will have Tf
@@ -145,7 +148,7 @@ public class TestOmitTf extends LuceneTestCase {
 
     _TestUtil.checkIndex(ram);
 
-    SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
+    SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
     FieldInfos fi = reader.fieldInfos();
     assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f1").omitTermFreqAndPositions);
     assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f2").omitTermFreqAndPositions);
@@ -160,9 +163,12 @@ public class TestOmitTf extends LuceneTestCase {
   public void testMixedRAM() throws Exception {
     Directory ram = newDirectory();
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(ram, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(10));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
+    IndexWriter writer = new IndexWriter(
+        ram,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
+            setMaxBufferedDocs(10).
+            setMergePolicy(newLogMergePolicy(2))
+    );
     Document d = new Document();
         
     // this field will have Tf
@@ -189,7 +195,7 @@ public class TestOmitTf extends LuceneTestCase {
 
     _TestUtil.checkIndex(ram);
 
-    SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
+    SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
     FieldInfos fi = reader.fieldInfos();
     assertTrue("OmitTermFreqAndPositions field bit should not be set.", !fi.fieldInfo("f1").omitTermFreqAndPositions);
     assertTrue("OmitTermFreqAndPositions field bit should be set.", fi.fieldInfo("f2").omitTermFreqAndPositions);
@@ -241,10 +247,13 @@ public class TestOmitTf extends LuceneTestCase {
   public void testBasic() throws Exception {
     Directory dir = newDirectory();  
     Analyzer analyzer = new MockAnalyzer();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, analyzer).setMaxBufferedDocs(2)
-        .setSimilarity(new SimpleSimilarity()));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(2);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
+            setMaxBufferedDocs(2).
+            setSimilarity(new SimpleSimilarity()).
+            setMergePolicy(newLogMergePolicy(2))
+    );
         
     StringBuilder sb = new StringBuilder(265);
     String term = "term";
diff --git a/lucene/src/test/org/apache/lucene/index/TestParallelReader.java b/lucene/src/test/org/apache/lucene/index/TestParallelReader.java
index a9a20f3..319b6ce 100644
--- a/lucene/src/test/org/apache/lucene/index/TestParallelReader.java
+++ b/lucene/src/test/org/apache/lucene/index/TestParallelReader.java
@@ -26,12 +26,8 @@ import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.MapFieldSelector;
-import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ScoreDoc;
-import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -98,9 +94,9 @@ public class TestParallelReader extends LuceneTestCase {
     pr.add(IndexReader.open(dir1, false));
     pr.add(IndexReader.open(dir2, false));
 
-    Document doc11 = pr.document(0, new MapFieldSelector(new String[] {"f1"}));
-    Document doc24 = pr.document(1, new MapFieldSelector(Arrays.asList(new String[] {"f4"})));
-    Document doc223 = pr.document(1, new MapFieldSelector(new String[] {"f2", "f3"}));
+    Document doc11 = pr.document(0, new MapFieldSelector("f1"));
+    Document doc24 = pr.document(1, new MapFieldSelector(Arrays.asList("f4")));
+    Document doc223 = pr.document(1, new MapFieldSelector("f2", "f3"));
     
     assertEquals(1, doc11.getFields().size());
     assertEquals(1, doc24.getFields().size());
@@ -174,15 +170,21 @@ public class TestParallelReader extends LuceneTestCase {
     Directory dir2 = getDir2(random);
     
     // add another document to ensure that the indexes are not optimized
-    IndexWriter modifier = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-    ((LogMergePolicy) modifier.getMergePolicy()).setMergeFactor(10);
+    IndexWriter modifier = new IndexWriter(
+        dir1,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     Document d = new Document();
     d.add(newField("f1", "v1", Field.Store.YES, Field.Index.ANALYZED));
     modifier.addDocument(d);
     modifier.close();
-    
-    modifier = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()));
-    ((LogMergePolicy) modifier.getMergePolicy()).setMergeFactor(10);
+
+    modifier = new IndexWriter(
+        dir2,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     d = new Document();
     d.add(newField("f2", "v2", Field.Store.YES, Field.Index.ANALYZED));
     modifier.addDocument(d);
diff --git a/lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java b/lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
index cd718b5..9161b60 100644
--- a/lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
+++ b/lucene/src/test/org/apache/lucene/index/TestParallelReaderEmptyIndex.java
@@ -59,7 +59,7 @@ public class TestParallelReaderEmptyIndex extends LuceneTestCase {
     pr.add(IndexReader.open(rd2,true));
 		
     // When unpatched, Lucene crashes here with a NoSuchElementException (caused by ParallelTermEnum)
-    iwOut.addIndexes(new IndexReader[] { pr });
+    iwOut.addIndexes(pr);
 		
     iwOut.optimize();
     iwOut.close();
@@ -112,7 +112,7 @@ public class TestParallelReaderEmptyIndex extends LuceneTestCase {
     pr.add(IndexReader.open(rd2,true));
 
     // When unpatched, Lucene crashes here with an ArrayIndexOutOfBoundsException (caused by TermVectorsWriter)
-    iwOut.addIndexes(new IndexReader[] { pr });
+    iwOut.addIndexes(pr);
 
     // ParallelReader closes any IndexReader you added to it:
     pr.close();
diff --git a/lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java b/lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java
index 7909aed..9c342fd 100644
--- a/lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java
+++ b/lucene/src/test/org/apache/lucene/index/TestPayloadProcessorProvider.java
@@ -17,8 +17,6 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import static org.junit.Assert.*;
-
 import java.io.IOException;
 import java.util.HashMap;
 import java.util.Map;
@@ -118,10 +116,6 @@ public class TestPayloadProcessorProvider extends LuceneTestCase {
 
   private static final int NUM_DOCS = 10;
 
-  private IndexWriterConfig getConfig(Random random) {
-    return newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false));
-  }
-
   private void populateDirs(Random random, Directory[] dirs, boolean multipleCommits)
       throws IOException {
     for (int i = 0; i < dirs.length; i++) {
@@ -134,8 +128,11 @@ public class TestPayloadProcessorProvider extends LuceneTestCase {
 
   private void populateDocs(Random random, Directory dir, boolean multipleCommits)
       throws IOException {
-    IndexWriter writer = new IndexWriter(dir, getConfig(random));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)).
+            setMergePolicy(newLogMergePolicy(10))
+    );
     TokenStream payloadTS1 = new PayloadTokenStream("p1");
     TokenStream payloadTS2 = new PayloadTokenStream("p2");
     for (int i = 0; i < NUM_DOCS; i++) {
@@ -191,7 +188,7 @@ public class TestPayloadProcessorProvider extends LuceneTestCase {
     for (Directory d : dirs) {
       processors.put(d, new PerTermPayloadProcessor());
     }
-    IndexWriter writer = new IndexWriter(dir, getConfig(random));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));
 
     IndexReader[] readers = new IndexReader[dirs.length];
@@ -245,7 +242,7 @@ public class TestPayloadProcessorProvider extends LuceneTestCase {
     // won't get processed.
     Map<Directory, DirPayloadProcessor> processors = new HashMap<Directory, DirPayloadProcessor>();
     processors.put(dir, new PerTermPayloadProcessor());
-    IndexWriter writer = new IndexWriter(dir, getConfig(random));
+    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
     writer.setPayloadProcessorProvider(new PerDirPayloadProcessor(processors));
     writer.optimize();
     writer.close();
diff --git a/lucene/src/test/org/apache/lucene/index/TestPayloads.java b/lucene/src/test/org/apache/lucene/index/TestPayloads.java
index 39df363..e366714 100644
--- a/lucene/src/test/org/apache/lucene/index/TestPayloads.java
+++ b/lucene/src/test/org/apache/lucene/index/TestPayloads.java
@@ -115,9 +115,9 @@ public class TestPayloads extends LuceneTestCase {
         analyzer.setPayloadData("f2", 1, "somedata".getBytes(), 0, 1);
         writer.addDocument(d);
         // flush
-        writer.close();        
-        
-        SegmentReader reader = SegmentReader.getOnlySegmentReader(ram);
+        writer.close();
+
+      SegmentReader reader = getOnlySegmentReader(IndexReader.open(ram, false));
         FieldInfos fi = reader.fieldInfos();
         assertFalse("Payload field bit should not be set.", fi.fieldInfo("f1").storePayloads);
         assertTrue("Payload field bit should be set.", fi.fieldInfo("f2").storePayloads);
@@ -143,7 +143,7 @@ public class TestPayloads extends LuceneTestCase {
         // flush
         writer.close();
 
-        reader = SegmentReader.getOnlySegmentReader(ram);
+      reader = getOnlySegmentReader(IndexReader.open(ram, false));
         fi = reader.fieldInfos();
         assertFalse("Payload field bit should not be set.", fi.fieldInfo("f1").storePayloads);
         assertTrue("Payload field bit should be set.", fi.fieldInfo("f2").storePayloads);
diff --git a/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java b/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
index c9f5ef2..f7ddaf6 100644
--- a/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
+++ b/lucene/src/test/org/apache/lucene/index/TestSegmentMerger.java
@@ -73,7 +73,7 @@ public class TestSegmentMerger extends LuceneTestCase {
   }
   
   public void testMerge() throws IOException {                             
-    SegmentMerger merger = new SegmentMerger(mergedDir, IndexWriter.DEFAULT_TERM_INDEX_INTERVAL, mergedSegment, null, CodecProvider.getDefault(), null);
+    SegmentMerger merger = new SegmentMerger(mergedDir, IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL, mergedSegment, null, CodecProvider.getDefault(), null);
     merger.add(reader1);
     merger.add(reader2);
     int docsMerged = merger.merge();
diff --git a/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java b/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
index 5a4568f..31557cc 100644
--- a/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
+++ b/lucene/src/test/org/apache/lucene/index/TestSegmentTermEnum.java
@@ -77,7 +77,7 @@ public class TestSegmentTermEnum extends LuceneTestCase {
     IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setCodecProvider(_TestUtil.alwaysCodec("Standard")));
     addDoc(writer, "aaa bbb");
     writer.close();
-    SegmentReader reader = SegmentReader.getOnlySegmentReader(dir);
+    SegmentReader reader = getOnlySegmentReader(IndexReader.open(dir, false));
     TermsEnum terms = reader.fields().terms("content").iterator();
     assertNotNull(terms.next());
     assertEquals("aaa", terms.term().utf8ToString());
diff --git a/lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java b/lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
index 0fa2391..c48e571 100644
--- a/lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
+++ b/lucene/src/test/org/apache/lucene/index/TestTermVectorsReader.java
@@ -90,10 +90,12 @@ public class TestTermVectorsReader extends LuceneTestCase {
     Arrays.sort(tokens);
 
     dir = newDirectory();
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MyAnalyzer()).setMaxBufferedDocs(-1));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(10);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MyAnalyzer()).
+            setMaxBufferedDocs(-1).
+            setMergePolicy(newLogMergePolicy(false, 10))
+    );
 
     Document doc = new Document();
     for(int i=0;i<testFields.length;i++) {
diff --git a/lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java b/lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java
index a2db7aa..9d819ae 100644
--- a/lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java
+++ b/lucene/src/test/org/apache/lucene/index/TestTermdocPerf.java
@@ -70,10 +70,13 @@ public class TestTermdocPerf extends LuceneTestCase {
 
     Document doc = new Document();
     doc.add(newField(field,val, Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS));
-    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, analyzer)
-        .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(100));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(100);
+    IndexWriter writer = new IndexWriter(
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, analyzer).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(100).
+            setMergePolicy(newLogMergePolicy(100))
+    );
 
     for (int i=0; i<ndocs; i++) {
       writer.addDocument(doc);
diff --git a/lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java b/lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java
index 96b398a..974ae60 100644
--- a/lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java
+++ b/lucene/src/test/org/apache/lucene/index/TestThreadedOptimize.java
@@ -52,10 +52,14 @@ public class TestThreadedOptimize extends LuceneTestCase {
 
   public void runTest(Random random, Directory directory, MergeScheduler merger) throws Exception {
 
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig(
-        TEST_VERSION_CURRENT, ANALYZER)
-        .setOpenMode(OpenMode.CREATE).setMaxBufferedDocs(2).setMergeScheduler(
-            merger));
+    IndexWriter writer = new IndexWriter(
+        directory,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, ANALYZER).
+            setOpenMode(OpenMode.CREATE).
+            setMaxBufferedDocs(2).
+            setMergeScheduler(merger).
+            setMergePolicy(newLogMergePolicy())
+    );
 
     for(int iter=0;iter<NUM_ITER;iter++) {
       final int iterFinal = iter;
diff --git a/lucene/src/test/org/apache/lucene/index/TestTransactions.java b/lucene/src/test/org/apache/lucene/index/TestTransactions.java
index ce3a719..467bed7 100644
--- a/lucene/src/test/org/apache/lucene/index/TestTransactions.java
+++ b/lucene/src/test/org/apache/lucene/index/TestTransactions.java
@@ -91,16 +91,24 @@ public class TestTransactions extends LuceneTestCase {
     @Override
     public void doWork() throws Throwable {
 
-      IndexWriter writer1 = new IndexWriter(dir1, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-          .setMaxBufferedDocs(3).setMergeScheduler(new ConcurrentMergeScheduler()));
-      ((LogMergePolicy) writer1.getConfig().getMergePolicy()).setMergeFactor(2);
+      IndexWriter writer1 = new IndexWriter(
+          dir1,
+          newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(3).
+              setMergeScheduler(new ConcurrentMergeScheduler()).
+              setMergePolicy(newLogMergePolicy(2))
+      );
       ((ConcurrentMergeScheduler) writer1.getConfig().getMergeScheduler()).setSuppressExceptions();
 
       // Intentionally use different params so flush/merge
       // happen @ different times
-      IndexWriter writer2 = new IndexWriter(dir2, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer())
-          .setMaxBufferedDocs(2).setMergeScheduler(new ConcurrentMergeScheduler()));
-      ((LogMergePolicy) writer2.getConfig().getMergePolicy()).setMergeFactor(3);
+      IndexWriter writer2 = new IndexWriter(
+          dir2,
+          newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).
+              setMaxBufferedDocs(2).
+              setMergeScheduler(new ConcurrentMergeScheduler()).
+              setMergePolicy(newLogMergePolicy(3))
+      );
       ((ConcurrentMergeScheduler) writer2.getConfig().getMergeScheduler()).setSuppressExceptions();
 
       update(writer1);
diff --git a/lucene/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java b/lucene/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
index 061086c..56246fb 100644
--- a/lucene/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
+++ b/lucene/src/test/org/apache/lucene/queryParser/TestMultiAnalyzer.java
@@ -116,11 +116,9 @@ public class TestMultiAnalyzer extends BaseTokenStreamTestCase {
   }
     
   public void testPosIncrementAnalyzer() throws ParseException {
-    QueryParser qp = new QueryParser(Version.LUCENE_24, "", new PosIncrementAnalyzer());
+    QueryParser qp = new QueryParser(Version.LUCENE_40, "", new PosIncrementAnalyzer());
     assertEquals("quick brown", qp.parse("the quick brown").toString());
-    assertEquals("\"quick brown\"", qp.parse("\"the quick brown\"").toString());
     assertEquals("quick brown fox", qp.parse("the quick brown fox").toString());
-    assertEquals("\"quick brown fox\"", qp.parse("\"the quick brown fox\"").toString());
   }
   
   /**
diff --git a/lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java b/lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java
index cb758cd..ea1a820 100644
--- a/lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java
+++ b/lucene/src/test/org/apache/lucene/queryParser/TestQueryParser.java
@@ -35,7 +35,6 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.document.DateField;
 import org.apache.lucene.document.DateTools;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
@@ -628,12 +627,6 @@ public class TestQueryParser extends LuceneTestCase {
     }
   }
   
-  /** for testing legacy DateField support */
-  private String getLegacyDate(String s) throws Exception {
-    DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
-    return DateField.dateToString(df.parse(s));
-  }
-
   /** for testing DateTools support */
   private String getDate(String s, DateTools.Resolution resolution) throws Exception {
     DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
@@ -642,12 +635,8 @@ public class TestQueryParser extends LuceneTestCase {
   
   /** for testing DateTools support */
   private String getDate(Date d, DateTools.Resolution resolution) throws Exception {
-      if (resolution == null) {
-        return DateField.dateToString(d);      
-      } else {
-        return DateTools.dateToString(d, resolution);
-      }
-    }
+     return DateTools.dateToString(d, resolution);
+  }
   
   private String getLocalizedDate(int year, int month, int day) {
     DateFormat df = DateFormat.getDateInstance(DateFormat.SHORT);
@@ -661,20 +650,6 @@ public class TestQueryParser extends LuceneTestCase {
     return df.format(calendar.getTime());
   }
 
-  /** for testing legacy DateField support */
-  public void testLegacyDateRange() throws Exception {
-    String startDate = getLocalizedDate(2002, 1, 1);
-    String endDate = getLocalizedDate(2002, 1, 4);
-    Calendar endDateExpected = new GregorianCalendar();
-    endDateExpected.clear();
-    endDateExpected.set(2002, 1, 4, 23, 59, 59);
-    endDateExpected.set(Calendar.MILLISECOND, 999);
-    assertQueryEquals("[ " + escapeDateString(startDate) + " TO " + escapeDateString(endDate) + "]", null,
-                      "[" + getLegacyDate(startDate) + " TO " + DateField.dateToString(endDateExpected.getTime()) + "]");
-    assertQueryEquals("{  " + escapeDateString(startDate) + "    " + escapeDateString(endDate) + "   }", null,
-                      "{" + getLegacyDate(startDate) + " TO " + getLegacyDate(endDate) + "}");
-  }
-  
   public void testDateRange() throws Exception {
     String startDate = getLocalizedDate(2002, 1, 1);
     String endDate = getLocalizedDate(2002, 1, 4);
@@ -687,18 +662,10 @@ public class TestQueryParser extends LuceneTestCase {
     final String hourField = "hour";
     QueryParser qp = new QueryParser(TEST_VERSION_CURRENT, "field", new MockAnalyzer(MockTokenizer.SIMPLE, true));
     
-    // Don't set any date resolution and verify if DateField is used
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate, 
-                               endDateExpected.getTime(), null);
-    
     // set a field specific date resolution
     qp.setDateResolution(monthField, DateTools.Resolution.MONTH);
     
-    // DateField should still be used for defaultField
-    assertDateRangeQueryEquals(qp, defaultField, startDate, endDate, 
-                               endDateExpected.getTime(), null);
-    
-    // set default date resolution to MILLISECOND 
+    // set default date resolution to MILLISECOND
     qp.setDateResolution(DateTools.Resolution.MILLISECOND);
     
     // set second field specific date resolution    
@@ -985,22 +952,33 @@ public class TestQueryParser extends LuceneTestCase {
     assertEquals(query1, query2);
   }
 
-  public void testLocalDateFormat() throws IOException, ParseException {
-    Directory ramDir = newDirectory();
-    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
-    addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
-    addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
-    iw.close();
-    IndexSearcher is = new IndexSearcher(ramDir, true);
-    assertHits(1, "[12/1/2005 TO 12/3/2005]", is);
-    assertHits(2, "[12/1/2005 TO 12/4/2005]", is);
-    assertHits(1, "[12/3/2005 TO 12/4/2005]", is);
-    assertHits(1, "{12/1/2005 TO 12/3/2005}", is);
-    assertHits(1, "{12/1/2005 TO 12/4/2005}", is);
-    assertHits(0, "{12/3/2005 TO 12/4/2005}", is);
-    is.close();
-    ramDir.close();
-  }
+// Todo (nocommit): convert this from DateField to DateUtil
+//  public void testLocalDateFormat() throws IOException, ParseException {
+//    Directory ramDir = newDirectory();
+//    IndexWriter iw = new IndexWriter(ramDir, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer(MockTokenizer.WHITESPACE, false)));
+//    addDateDoc("a", 2005, 12, 2, 10, 15, 33, iw);
+//    addDateDoc("b", 2005, 12, 4, 22, 15, 00, iw);
+//    iw.close();
+//    IndexSearcher is = new IndexSearcher(ramDir, true);
+//    assertHits(1, "[12/1/2005 TO 12/3/2005]", is);
+//    assertHits(2, "[12/1/2005 TO 12/4/2005]", is);
+//    assertHits(1, "[12/3/2005 TO 12/4/2005]", is);
+//    assertHits(1, "{12/1/2005 TO 12/3/2005}", is);
+//    assertHits(1, "{12/1/2005 TO 12/4/2005}", is);
+//    assertHits(0, "{12/3/2005 TO 12/4/2005}", is);
+//    is.close();
+//    ramDir.close();
+//  }
+//
+//  private void addDateDoc(String content, int year, int month,
+//                          int day, int hour, int minute, int second, IndexWriter iw) throws IOException {
+//    Document d = new Document();
+//    d.add(newField("f", content, Field.Store.YES, Field.Index.ANALYZED));
+//    Calendar cal = Calendar.getInstance(Locale.ENGLISH);
+//    cal.set(year, month - 1, day, hour, minute, second);
+//    d.add(newField("date", DateField.dateToString(cal.getTime()), Field.Store.YES, Field.Index.NOT_ANALYZED));
+//    iw.addDocument(d);
+//  }
 
   public void testStarParsing() throws Exception {
     final int[] type = new int[1];
@@ -1146,16 +1124,6 @@ public class TestQueryParser extends LuceneTestCase {
     assertEquals(expected, hits.length);
   }
 
-  private void addDateDoc(String content, int year, int month,
-      int day, int hour, int minute, int second, IndexWriter iw) throws IOException {
-    Document d = new Document();
-    d.add(newField("f", content, Field.Store.YES, Field.Index.ANALYZED));
-    Calendar cal = Calendar.getInstance(Locale.ENGLISH);
-    cal.set(year, month-1, day, hour, minute, second);
-    d.add(newField("date", DateField.dateToString(cal.getTime()), Field.Store.YES, Field.Index.NOT_ANALYZED));
-    iw.addDocument(d);
-  }
-
   @Override
   public void tearDown() throws Exception {
     BooleanQuery.setMaxClauseCount(originalMaxClauses);
diff --git a/lucene/src/test/org/apache/lucene/search/CheckHits.java b/lucene/src/test/org/apache/lucene/search/CheckHits.java
index a9078b1..0efa525 100644
--- a/lucene/src/test/org/apache/lucene/search/CheckHits.java
+++ b/lucene/src/test/org/apache/lucene/search/CheckHits.java
@@ -454,13 +454,6 @@ public class CheckHits {
    */
   public static class ExplanationAsserter extends Collector {
 
-    /**
-     * @deprecated
-     * @see CheckHits#EXPLAIN_SCORE_TOLERANCE_DELTA
-     */
-    @Deprecated
-    public static float SCORE_TOLERANCE_DELTA = 0.00005f;
-
     Query q;
     Searcher s;
     String d;
diff --git a/lucene/src/test/org/apache/lucene/search/QueryUtils.java b/lucene/src/test/org/apache/lucene/search/QueryUtils.java
index f9437da..f464301 100644
--- a/lucene/src/test/org/apache/lucene/search/QueryUtils.java
+++ b/lucene/src/test/org/apache/lucene/search/QueryUtils.java
@@ -153,18 +153,14 @@ public class QueryUtils {
     IndexReader[] readers = new IndexReader[] {
       edge < 0 ? r : IndexReader.open(makeEmptyIndex(random, 0), true),
       IndexReader.open(makeEmptyIndex(random, 0), true),
-      new MultiReader(new IndexReader[] {
-        IndexReader.open(makeEmptyIndex(random, edge < 0 ? 4 : 0), true),
-        IndexReader.open(makeEmptyIndex(random, 0), true),
-        0 == edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)
-      }),
+      new MultiReader(IndexReader.open(makeEmptyIndex(random, edge < 0 ? 4 : 0), true),
+          IndexReader.open(makeEmptyIndex(random, 0), true),
+          0 == edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)),
       IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 7), true),
       IndexReader.open(makeEmptyIndex(random, 0), true),
-      new MultiReader(new IndexReader[] {
-        IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 5), true),
-        IndexReader.open(makeEmptyIndex(random, 0), true),
-        0 < edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true)
-      })
+      new MultiReader(IndexReader.open(makeEmptyIndex(random, 0 < edge ? 0 : 5), true),
+          IndexReader.open(makeEmptyIndex(random, 0), true),
+          0 < edge ? r : IndexReader.open(makeEmptyIndex(random, 0), true))
     };
     IndexSearcher out = new IndexSearcher(new MultiReader(readers));
     out.setSimilarity(s.getSimilarity());
diff --git a/lucene/src/test/org/apache/lucene/search/TestBoolean2.java b/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
index 1330e47..0cfa103 100644
--- a/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
+++ b/lucene/src/test/org/apache/lucene/search/TestBoolean2.java
@@ -74,7 +74,7 @@ public class TestBoolean2 extends LuceneTestCase {
     do {
       final Directory copy = new MockDirectoryWrapper(random, new RAMDirectory(dir2));
       RandomIndexWriter w = new RandomIndexWriter(random, dir2);
-      w.addIndexes(new Directory[] {copy});
+      w.addIndexes(copy);
       docCount = w.maxDoc();
       w.close();
       mulFactor *= 2;
diff --git a/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java b/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
index c8f426b..68f97c1 100644
--- a/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
+++ b/lucene/src/test/org/apache/lucene/search/TestCachingSpanFilter.java
@@ -35,10 +35,14 @@ public class TestCachingSpanFilter extends LuceneTestCase {
 
   public void testEnforceDeletions() throws Exception {
     Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
-                                                     newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
-    // asserts below requires no unexpected merges:
-    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);
+    RandomIndexWriter writer = new RandomIndexWriter(
+        random,
+        dir,
+        newIndexWriterConfig(random, TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergeScheduler(new SerialMergeScheduler()).
+            // asserts below requires no unexpected merges:
+            setMergePolicy(newLogMergePolicy(10))
+    );
 
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
diff --git a/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java b/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
index 0d94baa..3c0fe93 100644
--- a/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
+++ b/lucene/src/test/org/apache/lucene/search/TestCachingWrapperFilter.java
@@ -152,10 +152,14 @@ public class TestCachingWrapperFilter extends LuceneTestCase {
 
   public void testEnforceDeletions() throws Exception {
     Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random, dir,
-                                                     newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()));
-    // asserts below requires no unexpected merges:
-    ((LogMergePolicy) writer.w.getMergePolicy()).setMergeFactor(10);
+    RandomIndexWriter writer = new RandomIndexWriter(
+        random,
+        dir,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergeScheduler(new SerialMergeScheduler()).
+            // asserts below requires no unexpected merges:
+            setMergePolicy(newLogMergePolicy(10))
+    );
 
     // NOTE: cannot use writer.getReader because RIW (on
     // flipping a coin) may give us a newly opened reader,
diff --git a/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java b/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
index 062afc6..076a557 100644
--- a/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
+++ b/lucene/src/test/org/apache/lucene/search/TestCustomSearcherSort.java
@@ -118,8 +118,7 @@ public class TestCustomSearcherSort extends LuceneTestCase implements Serializab
     Sort custSort = new Sort(
         new SortField("publicationDate_", SortField.STRING),
         SortField.FIELD_SCORE);
-    Searcher searcher = new MultiSearcher(new Searchable[] {
-        new CustomSearcher(reader, 0), new CustomSearcher(reader, 2)});
+    Searcher searcher = new MultiSearcher(new CustomSearcher(reader, 0), new CustomSearcher(reader, 2));
     // search and check hits
     matchHits(searcher, custSort);
   }
diff --git a/lucene/src/test/org/apache/lucene/search/TestElevationComparator.java b/lucene/src/test/org/apache/lucene/search/TestElevationComparator.java
index c929319..a99d2d0 100644
--- a/lucene/src/test/org/apache/lucene/search/TestElevationComparator.java
+++ b/lucene/src/test/org/apache/lucene/search/TestElevationComparator.java
@@ -36,8 +36,12 @@ public class TestElevationComparator extends LuceneTestCase {
   //@Test
   public void testSorting() throws Throwable {
     Directory directory = newDirectory();
-    IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig( TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(2));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(1000);
+    IndexWriter writer = new IndexWriter(
+        directory,
+        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(2).
+            setMergePolicy(newLogMergePolicy(1000))
+    );
     writer.addDocument(adoc(new String[] {"id", "a", "title", "ipod", "str_s", "a"}));
     writer.addDocument(adoc(new String[] {"id", "b", "title", "ipod ipod", "str_s", "b"}));
     writer.addDocument(adoc(new String[] {"id", "c", "title", "ipod ipod ipod", "str_s","c"}));
diff --git a/lucene/src/test/org/apache/lucene/search/TestExplanations.java b/lucene/src/test/org/apache/lucene/search/TestExplanations.java
index 8fa6e3c..2960a4e 100644
--- a/lucene/src/test/org/apache/lucene/search/TestExplanations.java
+++ b/lucene/src/test/org/apache/lucene/search/TestExplanations.java
@@ -165,7 +165,7 @@ public class TestExplanations extends LuceneTestCase {
   }
   /** MACRO for SpanOrQuery containing two SpanQueries */
   public SpanOrQuery sor(SpanQuery s, SpanQuery e) {
-    return new SpanOrQuery(new SpanQuery[] { s, e });
+    return new SpanOrQuery(s, e);
   }
   
   /** MACRO for SpanOrQuery containing three SpanTerm queries */
@@ -174,7 +174,7 @@ public class TestExplanations extends LuceneTestCase {
   }
   /** MACRO for SpanOrQuery containing two SpanQueries */
   public SpanOrQuery sor(SpanQuery s, SpanQuery m, SpanQuery e) {
-    return new SpanOrQuery(new SpanQuery[] { s, m, e });
+    return new SpanOrQuery(s, m, e);
   }
   
   /** MACRO for SpanNearQuery containing two SpanTerm queries */
diff --git a/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java b/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
index 927e859..cd5595b 100644
--- a/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/TestPhraseQuery.java
@@ -214,7 +214,7 @@ public class TestPhraseQuery extends LuceneTestCase {
     Directory directory = newDirectory();
     Analyzer stopAnalyzer = new MockAnalyzer(MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);
     RandomIndexWriter writer = new RandomIndexWriter(random, directory, 
-        newIndexWriterConfig( Version.LUCENE_24, stopAnalyzer));
+        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));
     Document doc = new Document();
     doc.add(newField("field", "the stop words are here", Field.Store.YES, Field.Index.ANALYZED));
     writer.addDocument(doc);
diff --git a/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java b/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
index 843c4d6..254246b 100644
--- a/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/TestRegexpQuery.java
@@ -99,9 +99,9 @@ public class TestRegexpQuery extends LuceneTestCase {
     AutomatonProvider myProvider = new AutomatonProvider() {
       // automaton that matches quick or brown
       private Automaton quickBrownAutomaton = BasicOperations.union(Arrays
-          .asList(new Automaton[] {BasicAutomata.makeString("quick"),
-              BasicAutomata.makeString("brown"),
-              BasicAutomata.makeString("bob")}));
+          .asList(BasicAutomata.makeString("quick"),
+          BasicAutomata.makeString("brown"),
+          BasicAutomata.makeString("bob")));
       
       public Automaton getAutomaton(String name) throws IOException {
         if (name.equals("quickBrown")) return quickBrownAutomaton;
diff --git a/lucene/src/test/org/apache/lucene/search/TestSort.java b/lucene/src/test/org/apache/lucene/search/TestSort.java
index 77b7859..78eb48d 100644
--- a/lucene/src/test/org/apache/lucene/search/TestSort.java
+++ b/lucene/src/test/org/apache/lucene/search/TestSort.java
@@ -155,9 +155,12 @@ public class TestSort extends LuceneTestCase implements Serializable {
   private IndexSearcher getFullStrings() throws CorruptIndexException, LockObtainFailedException, IOException {
     Directory indexStore = newDirectory();
     dirs.add(indexStore);
-    IndexWriter writer = new IndexWriter(indexStore, new IndexWriterConfig(
-        TEST_VERSION_CURRENT, new MockAnalyzer()).setMaxBufferedDocs(4));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setMergeFactor(97);
+    IndexWriter writer = new IndexWriter(
+        indexStore,
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMaxBufferedDocs(4).
+            setMergePolicy(newLogMergePolicy(97))
+    );
     for (int i=0; i<NUM_STRINGS; i++) {
         Document doc = new Document();
         String num = getRandomCharString(getRandomNumber(2, 8), 48, 52);
@@ -597,7 +600,7 @@ public class TestSort extends LuceneTestCase implements Serializable {
     assertMatches (full, queryG, sort, "ZYXW");
 
     // Do the same for a MultiSearcher
-    Searcher multiSearcher=new MultiSearcher (new Searchable[] { full });
+    Searcher multiSearcher=new MultiSearcher (full);
 
     sort.setSort (new SortField ("int", SortField.INT),
                                 new SortField ("string", SortField.STRING),
@@ -611,7 +614,7 @@ public class TestSort extends LuceneTestCase implements Serializable {
     // Don't close the multiSearcher. it would close the full searcher too!
 
     // Do the same for a ParallelMultiSearcher
-                Searcher parallelSearcher=new ParallelMultiSearcher (new Searchable[] { full });
+                Searcher parallelSearcher=new ParallelMultiSearcher (full);
 
     sort.setSort (new SortField ("int", SortField.INT),
                                 new SortField ("string", SortField.STRING),
@@ -670,7 +673,7 @@ public class TestSort extends LuceneTestCase implements Serializable {
     // Test the MultiSearcher's ability to preserve locale-sensitive ordering
     // by wrapping it around a single searcher
   public void testInternationalMultiSearcherSort() throws Exception {
-    Searcher multiSearcher = new MultiSearcher (new Searchable[] { full });
+    Searcher multiSearcher = new MultiSearcher (full);
     
     sort.setSort (new SortField ("i18n", new Locale("sv", "se")));
     assertMatches (multiSearcher, queryY, sort, "BJDFH");
@@ -684,13 +687,13 @@ public class TestSort extends LuceneTestCase implements Serializable {
 
   // test a variety of sorts using more than one searcher
   public void testMultiSort() throws Exception {
-    MultiSearcher searcher = new MultiSearcher (new Searchable[] { searchX, searchY });
+    MultiSearcher searcher = new MultiSearcher (searchX, searchY);
     runMultiSorts(searcher, false);
   }
 
   // test a variety of sorts using a parallel multisearcher
   public void testParallelMultiSort() throws Exception {
-    Searcher searcher = new ParallelMultiSearcher (new Searchable[] { searchX, searchY });
+    Searcher searcher = new ParallelMultiSearcher (searchX, searchY);
     runMultiSorts(searcher, false);
   }
 
@@ -705,7 +708,7 @@ public class TestSort extends LuceneTestCase implements Serializable {
 
     // we'll test searching locally, remote and multi
     
-    MultiSearcher multi  = new MultiSearcher (new Searchable[] { searchX, searchY });
+    MultiSearcher multi  = new MultiSearcher (searchX, searchY);
 
     // change sorting and make sure relevancy stays the same
 
diff --git a/lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java b/lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java
index f2e7c5c..f5e5eda 100644
--- a/lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/TestTermRangeQuery.java
@@ -17,6 +17,14 @@ package org.apache.lucene.search;
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+import java.text.Collator;
+import java.util.Locale;
+import java.util.Set;
+
+import org.apache.lucene.analysis.*;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
@@ -24,21 +32,7 @@ import org.apache.lucene.index.MultiFields;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.IndexWriterConfig.OpenMode;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.MockAnalyzer;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
 import org.apache.lucene.util.LuceneTestCase;
-import java.io.IOException;
-import java.io.Reader;
-import java.util.Locale;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.Arrays;
-import java.text.Collator;
 
 
 public class TestTermRangeQuery extends LuceneTestCase {
@@ -143,7 +137,7 @@ public class TestTermRangeQuery extends LuceneTestCase {
   private void checkBooleanTerms(Searcher searcher, TermRangeQuery query, String... terms) throws IOException {
     query.setRewriteMethod(new MultiTermQuery.TopTermsScoringBooleanQueryRewrite(50));
     final BooleanQuery bq = (BooleanQuery) searcher.rewrite(query);
-    final Set<String> allowedTerms = new HashSet<String>(Arrays.asList(terms));
+    final Set<String> allowedTerms = asSet(terms);
     assertEquals(allowedTerms.size(), bq.clauses().size());
     for (BooleanClause c : bq.clauses()) {
       assertTrue(c.getQuery() instanceof TermQuery);
diff --git a/lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java b/lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java
index b1578e4..fed6491 100755
--- a/lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/function/TestCustomScoreQuery.java
@@ -122,7 +122,7 @@ public class TestCustomScoreQuery extends FunctionTestSetup {
   private static class CustomMulAddQuery extends CustomScoreQuery {
     // constructor
     CustomMulAddQuery(Query q, ValueSourceQuery qValSrc1, ValueSourceQuery qValSrc2) {
-      super(q, new ValueSourceQuery[]{qValSrc1, qValSrc2});
+      super(q, qValSrc1, qValSrc2);
     }
 
     /*(non-Javadoc) @see org.apache.lucene.search.function.CustomScoreQuery#name() */
diff --git a/lucene/src/test/org/apache/lucene/search/function/TestValueSource.java b/lucene/src/test/org/apache/lucene/search/function/TestValueSource.java
index fd309f7..38b6e9c 100644
--- a/lucene/src/test/org/apache/lucene/search/function/TestValueSource.java
+++ b/lucene/src/test/org/apache/lucene/search/function/TestValueSource.java
@@ -28,7 +28,7 @@ public class TestValueSource extends LuceneTestCase {
 
   public void testMultiValueSource() throws Exception {
     Directory dir = newDirectory();
-    IndexWriter w = new IndexWriter(dir, new MockAnalyzer(), IndexWriter.MaxFieldLength.UNLIMITED);
+    IndexWriter w = new IndexWriter(dir, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
     Document doc = new Document();
     Field f = newField("field", "", Field.Store.NO, Field.Index.NOT_ANALYZED);
     doc.add(f);
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java b/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
index 21f403b..74b878d 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestBasics.java
@@ -227,7 +227,7 @@ public class TestBasics extends LuceneTestCase {
                                            4, true);
     SpanTermQuery term3 = new SpanTermQuery(new Term("field", "forty"));
 
-    SpanOrQuery or = new SpanOrQuery(new SpanQuery[] {term3});
+    SpanOrQuery or = new SpanOrQuery(term3);
 
     SpanNotQuery query = new SpanNotQuery(near, or);
 
@@ -249,7 +249,7 @@ public class TestBasics extends LuceneTestCase {
     SpanTermQuery term4 = new SpanTermQuery(new Term("field", "sixty"));
     SpanTermQuery term5 = new SpanTermQuery(new Term("field", "eighty"));
 
-    SpanOrQuery or = new SpanOrQuery(new SpanQuery[] {term3, term4, term5});
+    SpanOrQuery or = new SpanOrQuery(term3, term4, term5);
 
     SpanNotQuery query = new SpanNotQuery(near, or);
 
@@ -436,7 +436,7 @@ public class TestBasics extends LuceneTestCase {
     SpanNearQuery near2 = new SpanNearQuery(new SpanQuery[] {term3, term4},
                                             0, true);
 
-    SpanOrQuery query = new SpanOrQuery(new SpanQuery[] {near1, near2});
+    SpanOrQuery query = new SpanOrQuery(near1, near2);
 
     checkHits(query, new int[]
       {33, 47, 133, 147, 233, 247, 333, 347, 433, 447, 533, 547, 633, 647, 733,
@@ -475,8 +475,8 @@ public class TestBasics extends LuceneTestCase {
     SpanTermQuery t5 = new SpanTermQuery(new Term("field","seven"));
     SpanTermQuery t6 = new SpanTermQuery(new Term("field","six"));
 
-    SpanOrQuery to1 = new SpanOrQuery(new SpanQuery[] {t1, t3});
-    SpanOrQuery to2 = new SpanOrQuery(new SpanQuery[] {t5, t6});
+    SpanOrQuery to1 = new SpanOrQuery(t1, t3);
+    SpanOrQuery to2 = new SpanOrQuery(t5, t6);
     
     SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {to1, to2},
                                             10, true);
@@ -505,8 +505,8 @@ public class TestBasics extends LuceneTestCase {
     SpanTermQuery t5 = new SpanTermQuery(new Term("field","seven"));
     SpanTermQuery t6 = new SpanTermQuery(new Term("field","six"));
 
-    SpanOrQuery to1 = new SpanOrQuery(new SpanQuery[] {tt1, tt2});
-    SpanOrQuery to2 = new SpanOrQuery(new SpanQuery[] {t5, t6});
+    SpanOrQuery to1 = new SpanOrQuery(tt1, tt2);
+    SpanOrQuery to2 = new SpanOrQuery(t5, t6);
     
     SpanNearQuery query = new SpanNearQuery(new SpanQuery[] {to1, to2},
                                             100, true);
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java b/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
index 176ea72..a9fe8dd 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestFieldMaskingSpanQuery.java
@@ -146,9 +146,8 @@ public class TestFieldMaskingSpanQuery extends LuceneTestCase {
       (new SpanTermQuery(new Term("last", "sally")) {
           @Override
           public Query rewrite(IndexReader reader) {
-            return new SpanOrQuery(new SpanQuery[] {
-              new SpanTermQuery(new Term("first", "sally")),
-              new SpanTermQuery(new Term("first", "james")) });
+            return new SpanOrQuery(new SpanTermQuery(new Term("first", "sally")),
+                new SpanTermQuery(new Term("first", "james")));
           }
         }, "first");
 
@@ -252,8 +251,7 @@ public class TestFieldMaskingSpanQuery extends LuceneTestCase {
   public void testSpans0() throws Exception {
     SpanQuery q1 = new SpanTermQuery(new Term("gender", "female"));
     SpanQuery q2 = new SpanTermQuery(new Term("first",  "james"));
-    SpanQuery q  = new SpanOrQuery(new SpanQuery[]
-      { q1, new FieldMaskingSpanQuery(q2, "gender")});
+    SpanQuery q  = new SpanOrQuery(q1, new FieldMaskingSpanQuery(q2, "gender"));
     check(q, new int[] { 0, 1, 2, 3, 4 });
   
     Spans span = q.getSpans(new SlowMultiReaderWrapper(searcher.getIndexReader()));
@@ -291,7 +289,7 @@ public class TestFieldMaskingSpanQuery extends LuceneTestCase {
   public void testSpans1() throws Exception {
     SpanQuery q1 = new SpanTermQuery(new Term("first", "sally"));
     SpanQuery q2 = new SpanTermQuery(new Term("first", "james"));
-    SpanQuery qA = new SpanOrQuery(new SpanQuery[] { q1, q2 });
+    SpanQuery qA = new SpanOrQuery(q1, q2);
     SpanQuery qB = new FieldMaskingSpanQuery(qA, "id");
                                             
     check(qA, new int[] { 0, 1, 2, 4 });
@@ -311,8 +309,7 @@ public class TestFieldMaskingSpanQuery extends LuceneTestCase {
   public void testSpans2() throws Exception {
     SpanQuery qA1 = new SpanTermQuery(new Term("gender", "female"));
     SpanQuery qA2 = new SpanTermQuery(new Term("first",  "james"));
-    SpanQuery qA  = new SpanOrQuery(new SpanQuery[]
-      { qA1, new FieldMaskingSpanQuery(qA2, "gender")});
+    SpanQuery qA  = new SpanOrQuery(qA1, new FieldMaskingSpanQuery(qA2, "gender"));
     SpanQuery qB  = new SpanTermQuery(new Term("last",   "jones"));
     SpanQuery q   = new SpanNearQuery(new SpanQuery[]
       { new FieldMaskingSpanQuery(qA, "id"),
diff --git a/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java b/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
index 7971b75..92d0742 100644
--- a/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
+++ b/lucene/src/test/org/apache/lucene/search/spans/TestSpans.java
@@ -331,8 +331,8 @@ public class TestSpans extends LuceneTestCase {
     Spans spans = orSpans(new String[0]);
     assertFalse("empty next", spans.next());
 
-    SpanOrQuery a = new SpanOrQuery( new SpanQuery[0] );
-    SpanOrQuery b = new SpanOrQuery( new SpanQuery[0] );
+    SpanOrQuery a = new SpanOrQuery();
+    SpanOrQuery b = new SpanOrQuery();
     assertTrue("empty should equal", a.equals(b));
   }
 
diff --git a/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java b/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
index bea2c6e..3bb807a 100644
--- a/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
+++ b/lucene/src/test/org/apache/lucene/store/MockDirectoryWrapper.java
@@ -97,17 +97,6 @@ public class MockDirectoryWrapper extends Directory {
     preventDoubleWrite = value;
   }
 
-  @Deprecated
-  @Override
-  public void sync(String name) throws IOException {
-    maybeYield();
-    maybeThrowDeterministicException();
-    if (crashed)
-      throw new IOException("cannot sync after crash");
-    unSyncedFiles.remove(name);
-    delegate.sync(name);
-  }
-
   @Override
   public synchronized void sync(Collection<String> names) throws IOException {
     maybeYield();
diff --git a/lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java b/lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
index 868332d..73e4e0a 100755
--- a/lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
+++ b/lucene/src/test/org/apache/lucene/store/TestBufferedIndexInput.java
@@ -22,6 +22,7 @@ import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.OutputStream;
 import java.util.ArrayList;
+import java.util.Collection;
 import java.util.List;
 import java.util.Random;
 
@@ -243,10 +244,12 @@ public class TestBufferedIndexInput extends LuceneTestCase {
       File indexDir = new File(TEMP_DIR, "testSetBufferSize");
       MockFSDirectory dir = new MockFSDirectory(indexDir, random);
       try {
-        IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(
-          TEST_VERSION_CURRENT, new MockAnalyzer())
-          .setOpenMode(OpenMode.CREATE));
-        ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
+        IndexWriter writer = new IndexWriter(
+            dir,
+            new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+                setOpenMode(OpenMode.CREATE).
+                setMergePolicy(newLogMergePolicy(false))
+        );
         for(int i=0;i<37;i++) {
           Document doc = new Document();
           doc.add(newField("content", "aaa bbb ccc ddd" + i, Field.Store.YES, Field.Index.ANALYZED));
@@ -366,12 +369,13 @@ public class TestBufferedIndexInput extends LuceneTestCase {
       {
         return dir.listAll();
       }
-
+      @Override
+      public void sync(Collection<String> names) throws IOException {
+        dir.sync(names);
+      }
       @Override
       public long fileLength(String name) throws IOException {
         return dir.fileLength(name);
       }
-
-
     }
 }
diff --git a/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java b/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
index d5afbb2..e9cf2b6 100644
--- a/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
+++ b/lucene/src/test/org/apache/lucene/store/TestFileSwitchDirectory.java
@@ -44,9 +44,11 @@ public class TestFileSwitchDirectory extends LuceneTestCase {
     Directory secondaryDir = new MockDirectoryWrapper(random, new RAMDirectory());
     
     FileSwitchDirectory fsd = new FileSwitchDirectory(fileExtensions, primaryDir, secondaryDir, true);
-    IndexWriter writer = new IndexWriter(fsd, new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()));
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundFile(false);
-    ((LogMergePolicy) writer.getConfig().getMergePolicy()).setUseCompoundDocStore(false);
+    IndexWriter writer = new IndexWriter(
+        fsd,
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).
+            setMergePolicy(newLogMergePolicy(false))
+    );
     TestIndexWriterReader.createIndexNoClose(true, "ram", writer);
     IndexReader reader = IndexReader.open(writer);
     assertEquals(100, reader.maxDoc());
diff --git a/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java b/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
index 807f22f..565d804 100644
--- a/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
+++ b/lucene/src/test/org/apache/lucene/util/LuceneTestCase.java
@@ -17,16 +17,26 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
+import java.io.File;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.lang.annotation.Documented;
+import java.lang.annotation.Inherited;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.*;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.Field.Index;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.Field.TermVector;
-import org.apache.lucene.index.ConcurrentMergeScheduler;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.LogDocMergePolicy;
-import org.apache.lucene.index.LogMergePolicy;
-import org.apache.lucene.index.SerialMergeScheduler;
+import org.apache.lucene.index.*;
 import org.apache.lucene.index.codecs.Codec;
 import org.apache.lucene.index.codecs.CodecProvider;
 import org.apache.lucene.index.codecs.mockintblock.MockFixedIntBlockCodec;
@@ -43,15 +53,7 @@ import org.apache.lucene.search.FieldCache.CacheEntry;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.FieldCacheSanityChecker.Insanity;
-import org.junit.Assume;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.junit.Ignore;
-import org.junit.Rule;
-import org.junit.Test;
+import org.junit.*;
 import org.junit.rules.TestWatchman;
 import org.junit.runner.Description;
 import org.junit.runner.RunWith;
@@ -62,30 +64,6 @@ import org.junit.runners.BlockJUnit4ClassRunner;
 import org.junit.runners.model.FrameworkMethod;
 import org.junit.runners.model.InitializationError;
 
-import java.io.File;
-import java.io.IOException;
-import java.io.PrintStream;
-import java.lang.annotation.Documented;
-import java.lang.annotation.Inherited;
-import java.lang.annotation.Retention;
-import java.lang.annotation.RetentionPolicy;
-import java.lang.reflect.Constructor;
-import java.lang.reflect.Method;
-import java.lang.reflect.Modifier;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.IdentityHashMap;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Random;
-import java.util.TimeZone;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
 /**
  * Base class for all Lucene unit tests, Junit3 or Junit4 variant.
  * <p>
@@ -177,6 +155,21 @@ public abstract class LuceneTestCase extends Assert {
   /** Used to track if setUp and tearDown are called correctly from subclasses */
   private boolean setup;
 
+  /**
+   * Some tests expect the directory to contain a single segment, and want to do tests on that segment's reader.
+   * This is an utility method to help them.
+   */
+  public static SegmentReader getOnlySegmentReader(IndexReader reader) {
+    if (reader instanceof SegmentReader)
+      return (SegmentReader) reader;
+
+    IndexReader[] subReaders = reader.getSequentialSubReaders();
+    if (subReaders.length != 1)
+      throw new IllegalArgumentException(reader + " has " + subReaders.length + " segments instead of exactly one");
+
+    return (SegmentReader) subReaders[0];
+  }
+
   private static class UncaughtExceptionEntry {
     public final Thread thread;
     public final Throwable exception;
@@ -308,7 +301,7 @@ public abstract class LuceneTestCase extends Assert {
     }
   }
 
-  /** @deprecated: until we fix no-fork problems in solr tests */
+  /** @deprecated (4.0) until we fix no-fork problems in solr tests */
   @Deprecated
   private static List<String> testClassesRun = new ArrayList<String>();
   
@@ -543,8 +536,7 @@ public abstract class LuceneTestCase extends Assert {
     }
   }
   
-  // These deprecated methods should be removed soon, when all tests using no Epsilon are fixed:
-  
+  // @deprecated (4.0) These deprecated methods should be removed soon, when all tests using no Epsilon are fixed:
   @Deprecated
   static public void assertEquals(double expected, double actual) {
     assertEquals(null, expected, actual);
@@ -608,6 +600,10 @@ public abstract class LuceneTestCase extends Assert {
     Assume.assumeNoException(e == null ? null : new TestIgnoredException(msg, e));
   }
  
+  public static <T> Set<T> asSet(T... args) {
+    return new HashSet<T>(Arrays.asList(args));
+  }
+
   /**
    * Convinience method for logging an iterator.
    *
@@ -647,9 +643,6 @@ public abstract class LuceneTestCase extends Assert {
   public static IndexWriterConfig newIndexWriterConfig(Random r, Version v, Analyzer a) {
     IndexWriterConfig c = new IndexWriterConfig(v, a);
     if (r.nextBoolean()) {
-      c.setMergePolicy(new LogDocMergePolicy());
-    }
-    if (r.nextBoolean()) {
       c.setMergeScheduler(new SerialMergeScheduler());
     }
     if (r.nextBoolean()) {
@@ -665,24 +658,52 @@ public abstract class LuceneTestCase extends Assert {
     if (r.nextBoolean()) {
       c.setMaxThreadStates(_TestUtil.nextInt(r, 1, 20));
     }
-    
-    if (c.getMergePolicy() instanceof LogMergePolicy) {
-      LogMergePolicy logmp = (LogMergePolicy) c.getMergePolicy();
-      logmp.setUseCompoundDocStore(r.nextBoolean());
-      logmp.setUseCompoundFile(r.nextBoolean());
-      logmp.setCalibrateSizeByDeletes(r.nextBoolean());
-      if (r.nextInt(3) == 2) {
-        logmp.setMergeFactor(2);
-      } else {
-        logmp.setMergeFactor(_TestUtil.nextInt(r, 2, 20));
-      }
-    }
-    
+
+    c.setMergePolicy(newLogMergePolicy(r));
+
     c.setReaderPooling(r.nextBoolean());
     c.setReaderTermsIndexDivisor(_TestUtil.nextInt(r, 1, 4));
     return c;
   }
 
+  public static LogMergePolicy newLogMergePolicy() {
+    return newLogMergePolicy(random);
+  }
+
+  public static LogMergePolicy newLogMergePolicy(Random r) {
+    LogMergePolicy logmp = r.nextBoolean() ? new LogDocMergePolicy() : new LogByteSizeMergePolicy();
+    logmp.setUseCompoundDocStore(r.nextBoolean());
+    logmp.setUseCompoundFile(r.nextBoolean());
+    logmp.setCalibrateSizeByDeletes(r.nextBoolean());
+    if (r.nextInt(3) == 2) {
+      logmp.setMergeFactor(2);
+    } else {
+      logmp.setMergeFactor(_TestUtil.nextInt(r, 2, 20));
+    }
+    return logmp;
+  }
+
+  public static LogMergePolicy newLogMergePolicy(boolean useCFS) {
+    LogMergePolicy logmp = newLogMergePolicy();
+    logmp.setUseCompoundFile(useCFS);
+    logmp.setUseCompoundDocStore(useCFS);
+    return logmp;
+  }
+
+  public static LogMergePolicy newLogMergePolicy(boolean useCFS, int mergeFactor) {
+    LogMergePolicy logmp = newLogMergePolicy();
+    logmp.setUseCompoundFile(useCFS);
+    logmp.setUseCompoundDocStore(useCFS);
+    logmp.setMergeFactor(mergeFactor);
+    return logmp;
+  }
+
+  public static LogMergePolicy newLogMergePolicy(int mergeFactor) {
+    LogMergePolicy logmp = newLogMergePolicy();
+    logmp.setMergeFactor(mergeFactor);
+    return logmp;
+  }
+
   /**
    * Returns a new Dictionary instance. Use this when the test does not
    * care about the specific Directory implementation (most tests).
diff --git a/lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java b/lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java
index 0018139..672edc3 100644
--- a/lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java
+++ b/lucene/src/test/org/apache/lucene/util/TestFieldCacheSanityChecker.java
@@ -70,7 +70,7 @@ public class TestFieldCacheSanityChecker extends LuceneTestCase {
     wB.close();
     readerA = IndexReader.open(dirA, true);
     readerB = IndexReader.open(dirB, true);
-    readerX = new MultiReader(new IndexReader[] { readerA, readerB });
+    readerX = new MultiReader(readerA, readerB);
   }
 
   @Override
diff --git a/lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java b/lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java
index 2642e70..dd17278 100644
--- a/lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java
+++ b/lucene/src/test/org/apache/lucene/util/TestIndexableBinaryStringTools.java
@@ -17,33 +17,10 @@ package org.apache.lucene.util;
  * limitations under the License.
  */
 
-import java.nio.CharBuffer;
-import java.nio.ByteBuffer;
-
 public class TestIndexableBinaryStringTools extends LuceneTestCase {
   private static final int NUM_RANDOM_TESTS = 2000 * RANDOM_MULTIPLIER;
   private static final int MAX_RANDOM_BINARY_LENGTH = 300 * RANDOM_MULTIPLIER;
   
-  /** @deprecated remove this test for Lucene 4.0 */
-  @Deprecated
-  public void testSingleBinaryRoundTripNIO() {
-    byte[] binary = new byte[] 
-      { (byte)0x23, (byte)0x98, (byte)0x13, (byte)0xE4, (byte)0x76, (byte)0x41,
-        (byte)0xB2, (byte)0xC9, (byte)0x7F, (byte)0x0A, (byte)0xA6, (byte)0xD8 };
-
-    ByteBuffer binaryBuf = ByteBuffer.wrap(binary);
-    CharBuffer encoded = IndexableBinaryStringTools.encode(binaryBuf);
-    ByteBuffer decoded = IndexableBinaryStringTools.decode(encoded);
-    assertEquals("Round trip decode/decode returned different results:"
-                 + System.getProperty("line.separator")
-                 + "original: " + binaryDumpNIO(binaryBuf)
-                 + System.getProperty("line.separator")
-                 + " encoded: " + charArrayDumpNIO(encoded)
-                 + System.getProperty("line.separator")
-                 + " decoded: " + binaryDumpNIO(decoded),
-                 binaryBuf, decoded);
-  }
-  
   public void testSingleBinaryRoundTrip() {
     byte[] binary = new byte[] { (byte) 0x23, (byte) 0x98, (byte) 0x13,
         (byte) 0xE4, (byte) 0x76, (byte) 0x41, (byte) 0xB2, (byte) 0xC9,
@@ -71,64 +48,6 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
         binaryDump(binary, binary.length), binaryDump(decoded, decoded.length));
   }
   
-  /** @deprecated remove this test for Lucene 4.0 */
-  @Deprecated
-  public void testEncodedSortabilityNIO() {
-    byte[] originalArray1 = new byte[MAX_RANDOM_BINARY_LENGTH];
-    ByteBuffer originalBuf1 = ByteBuffer.wrap(originalArray1);
-    char[] originalString1 = new char[MAX_RANDOM_BINARY_LENGTH];
-    CharBuffer originalStringBuf1 = CharBuffer.wrap(originalString1);
-    char[] encoded1 = new char[IndexableBinaryStringTools.getEncodedLength(originalBuf1)];
-    CharBuffer encodedBuf1 = CharBuffer.wrap(encoded1);
-    byte[] original2 = new byte[MAX_RANDOM_BINARY_LENGTH];
-    ByteBuffer originalBuf2 = ByteBuffer.wrap(original2);
-    char[] originalString2 = new char[MAX_RANDOM_BINARY_LENGTH];
-    CharBuffer originalStringBuf2 = CharBuffer.wrap(originalString2);
-    char[] encoded2 = new char[IndexableBinaryStringTools.getEncodedLength(originalBuf2)];
-    CharBuffer encodedBuf2 = CharBuffer.wrap(encoded2);
-    for (int testNum = 0 ; testNum < NUM_RANDOM_TESTS ; ++testNum) {
-      int numBytes1 = random.nextInt(MAX_RANDOM_BINARY_LENGTH - 1) + 1; // Min == 1
-      originalBuf1.limit(numBytes1);
-      originalStringBuf1.limit(numBytes1);
-      
-      for (int byteNum = 0 ; byteNum < numBytes1 ; ++byteNum) {
-        int randomInt = random.nextInt(0x100);
-        originalArray1[byteNum] = (byte) randomInt;
-        originalString1[byteNum] = (char)randomInt;
-      }
-      
-      int numBytes2 = random.nextInt(MAX_RANDOM_BINARY_LENGTH - 1) + 1; // Min == 1
-      originalBuf2.limit(numBytes2);
-      originalStringBuf2.limit(numBytes2);
-      for (int byteNum = 0 ; byteNum < numBytes2 ; ++byteNum) {
-        int randomInt = random.nextInt(0x100);
-        original2[byteNum] = (byte)randomInt;
-        originalString2[byteNum] = (char)randomInt;
-      }
-      int originalComparison = originalStringBuf1.compareTo(originalStringBuf2);
-      originalComparison = originalComparison < 0 ? -1 : originalComparison > 0 ? 1 : 0;
-      
-      IndexableBinaryStringTools.encode(originalBuf1, encodedBuf1);
-      IndexableBinaryStringTools.encode(originalBuf2, encodedBuf2);
-      
-      int encodedComparison = encodedBuf1.compareTo(encodedBuf2);
-      encodedComparison = encodedComparison < 0 ? -1 : encodedComparison > 0 ? 1 : 0;
-      
-      assertEquals("Test #" + (testNum + 1) 
-                   + ": Original bytes and encoded chars compare differently:"
-                   + System.getProperty("line.separator")
-                   + " binary 1: " + binaryDumpNIO(originalBuf1)
-                   + System.getProperty("line.separator")
-                   + " binary 2: " + binaryDumpNIO(originalBuf2)
-                   + System.getProperty("line.separator")
-                   + "encoded 1: " + charArrayDumpNIO(encodedBuf1)
-                   + System.getProperty("line.separator")
-                   + "encoded 2: " + charArrayDumpNIO(encodedBuf2)
-                   + System.getProperty("line.separator"),
-                   originalComparison, encodedComparison);
-    }
-  }
-
   public void testEncodedSortability() {
     byte[] originalArray1 = new byte[MAX_RANDOM_BINARY_LENGTH];
     char[] originalString1 = new char[MAX_RANDOM_BINARY_LENGTH];
@@ -192,16 +111,6 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
     }
   }
 
-  /** @deprecated remove this test for Lucene 4.0 */
-  @Deprecated
-  public void testEmptyInputNIO() {
-    byte[] binary = new byte[0];
-    CharBuffer encoded = IndexableBinaryStringTools.encode(ByteBuffer.wrap(binary));
-    ByteBuffer decoded = IndexableBinaryStringTools.decode(encoded);
-    assertNotNull("decode() returned null", decoded);
-    assertEquals("decoded empty input was not empty", decoded.limit(), 0);
-  }
-  
   public void testEmptyInput() {
     byte[] binary = new byte[0];
 
@@ -220,23 +129,6 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
     assertEquals("decoded empty input was not empty", decoded.length, 0);
   }
   
-  /** @deprecated remove this test for Lucene 4.0 */
-  @Deprecated
-  public void testAllNullInputNIO() {
-    byte[] binary = new byte[] { 0, 0, 0, 0, 0, 0, 0, 0, 0 };
-    ByteBuffer binaryBuf = ByteBuffer.wrap(binary);
-    CharBuffer encoded = IndexableBinaryStringTools.encode(binaryBuf);
-    assertNotNull("encode() returned null", encoded);
-    ByteBuffer decodedBuf = IndexableBinaryStringTools.decode(encoded);
-    assertNotNull("decode() returned null", decodedBuf);
-    assertEquals("Round trip decode/decode returned different results:"
-                 + System.getProperty("line.separator")
-                 + "  original: " + binaryDumpNIO(binaryBuf)
-                 + System.getProperty("line.separator")
-                 + "decodedBuf: " + binaryDumpNIO(decodedBuf),
-                 binaryBuf, decodedBuf);
-  }
-  
   public void testAllNullInput() {
     byte[] binary = new byte[] { 0, 0, 0, 0, 0, 0, 0, 0, 0 };
 
@@ -260,35 +152,6 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
         binaryDump(binary, binary.length), binaryDump(decoded, decoded.length));
   }
   
-  /** @deprecated remove this test for Lucene 4.0 */
-  @Deprecated
-  public void testRandomBinaryRoundTripNIO() {
-    byte[] binary = new byte[MAX_RANDOM_BINARY_LENGTH];
-    ByteBuffer binaryBuf = ByteBuffer.wrap(binary);
-    char[] encoded = new char[IndexableBinaryStringTools.getEncodedLength(binaryBuf)];
-    CharBuffer encodedBuf = CharBuffer.wrap(encoded);
-    byte[] decoded = new byte[MAX_RANDOM_BINARY_LENGTH];
-    ByteBuffer decodedBuf = ByteBuffer.wrap(decoded);
-    for (int testNum = 0 ; testNum < NUM_RANDOM_TESTS ; ++testNum) {
-      int numBytes = random.nextInt(MAX_RANDOM_BINARY_LENGTH - 1) + 1 ; // Min == 1
-      binaryBuf.limit(numBytes);
-      for (int byteNum = 0 ; byteNum < numBytes ; ++byteNum) {
-        binary[byteNum] = (byte)random.nextInt(0x100);
-      }
-      IndexableBinaryStringTools.encode(binaryBuf, encodedBuf);
-      IndexableBinaryStringTools.decode(encodedBuf, decodedBuf);
-      assertEquals("Test #" + (testNum + 1) 
-                   + ": Round trip decode/decode returned different results:"
-                   + System.getProperty("line.separator")
-                   + "  original: " + binaryDumpNIO(binaryBuf)
-                   + System.getProperty("line.separator")
-                   + "encodedBuf: " + charArrayDumpNIO(encodedBuf)
-                   + System.getProperty("line.separator")
-                   + "decodedBuf: " + binaryDumpNIO(decodedBuf),
-                   binaryBuf, decodedBuf);
-    }
-  }
-
   public void testRandomBinaryRoundTrip() {
     byte[] binary = new byte[MAX_RANDOM_BINARY_LENGTH];
     char[] encoded = new char[MAX_RANDOM_BINARY_LENGTH * 10];
@@ -323,13 +186,6 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
     }
   }
   
-  /** @deprecated remove this method for Lucene 4.0 */
-  @Deprecated
-  public String binaryDumpNIO(ByteBuffer binaryBuf) {
-    return binaryDump(binaryBuf.array(), 
-        binaryBuf.limit() - binaryBuf.arrayOffset());
-  }
-
   public String binaryDump(byte[] binary, int numBytes) {
     StringBuilder buf = new StringBuilder();
     for (int byteNum = 0 ; byteNum < numBytes ; ++byteNum) {
@@ -344,13 +200,7 @@ public class TestIndexableBinaryStringTools extends LuceneTestCase {
     }
     return buf.toString();
   }
-  /** @deprecated remove this method for Lucene 4.0 */
-  @Deprecated
-  public String charArrayDumpNIO(CharBuffer charBuf) {
-    return charArrayDump(charBuf.array(), 
-        charBuf.limit() - charBuf.arrayOffset());
-  }
-  
+
   public String charArrayDump(char[] charArray, int numBytes) {
     StringBuilder buf = new StringBuilder();
     for (int charNum = 0 ; charNum < numBytes ; ++charNum) {
diff --git a/lucene/src/test/org/apache/lucene/util/TestStringHelper.java b/lucene/src/test/org/apache/lucene/util/TestStringHelper.java
deleted file mode 100644
index 9793f56..0000000
--- a/lucene/src/test/org/apache/lucene/util/TestStringHelper.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.lucene.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestStringHelper extends LuceneTestCase {
-
-
-  public void testStringDifference() {
-    String test1 = "test";
-    String test2 = "testing";
-    
-    int result = StringHelper.stringDifference(test1, test2);
-    assertTrue(result == 4);
-    
-    test2 = "foo";
-    result = StringHelper.stringDifference(test1, test2);
-    assertTrue(result == 0);
-    
-    test2 = "test";
-    result = StringHelper.stringDifference(test1, test2);
-    assertTrue(result == 4);
-  }
-}
diff --git a/lucene/src/test/org/apache/lucene/util/TestVersion.java b/lucene/src/test/org/apache/lucene/util/TestVersion.java
index b2e8540..6a48569 100644
--- a/lucene/src/test/org/apache/lucene/util/TestVersion.java
+++ b/lucene/src/test/org/apache/lucene/util/TestVersion.java
@@ -23,9 +23,9 @@ public class TestVersion extends LuceneTestCase {
     for (Version v : Version.values()) {
       assertTrue("LUCENE_CURRENT must be always onOrAfter("+v+")", Version.LUCENE_CURRENT.onOrAfter(v));
     }
-    assertTrue(Version.LUCENE_30.onOrAfter(Version.LUCENE_29));
-    assertTrue(Version.LUCENE_30.onOrAfter(Version.LUCENE_30));
-    assertFalse(Version.LUCENE_29.onOrAfter(Version.LUCENE_30));
+    assertTrue(Version.LUCENE_40.onOrAfter(Version.LUCENE_31));
+    assertTrue(Version.LUCENE_40.onOrAfter(Version.LUCENE_40));
+    assertFalse(Version.LUCENE_30.onOrAfter(Version.LUCENE_31));
   }
 
 }
diff --git a/lucene/src/test/org/apache/lucene/util/_TestUtil.java b/lucene/src/test/org/apache/lucene/util/_TestUtil.java
index 7ae6f4e..70af1de 100644
--- a/lucene/src/test/org/apache/lucene/util/_TestUtil.java
+++ b/lucene/src/test/org/apache/lucene/util/_TestUtil.java
@@ -229,7 +229,7 @@ public class _TestUtil {
   // count lowish
   public static void reduceOpenFiles(IndexWriter w) {
     // keep number of open files lowish
-    LogMergePolicy lmp = (LogMergePolicy) w.getMergePolicy();
+    LogMergePolicy lmp = (LogMergePolicy) w.getConfig().getMergePolicy();
     lmp.setMergeFactor(Math.min(5, lmp.getMergeFactor()));
 
     MergeScheduler ms = w.getConfig().getMergeScheduler();
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
index 10879b8..43d64b9 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicAnalyzer.java
@@ -62,14 +62,6 @@ public final class ArabicAnalyzer extends StopwordAnalyzerBase {
   public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
 
   /**
-   * The comment character in the stopwords file.  All lines prefixed with this will be ignored
-   * @deprecated use {@link WordlistLoader#getWordSet(File, String)} directly  
-   */
-  // TODO make this private 
-  @Deprecated
-  public static final String STOPWORDS_COMMENT = "#";
-  
-  /**
    * Returns an unmodifiable instance of the default stop-words set.
    * @return an unmodifiable instance of the default stop-words set.
    */
@@ -86,7 +78,7 @@ public final class ArabicAnalyzer extends StopwordAnalyzerBase {
 
     static {
       try {
-        DEFAULT_STOP_SET = loadStopwordSet(false, ArabicAnalyzer.class, DEFAULT_STOPWORD_FILE, STOPWORDS_COMMENT);
+        DEFAULT_STOP_SET = loadStopwordSet(false, ArabicAnalyzer.class, DEFAULT_STOPWORD_FILE, "#");
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
@@ -135,33 +127,6 @@ public final class ArabicAnalyzer extends StopwordAnalyzerBase {
   }
 
   /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #ArabicAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public ArabicAnalyzer( Version matchVersion, String... stopwords ) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords ));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #ArabicAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public ArabicAnalyzer( Version matchVersion, Hashtable<?,?> stopwords ) {
-    this(matchVersion, stopwords.keySet());
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.  Lines can be commented out using {@link #STOPWORDS_COMMENT}
-   * @deprecated use {@link #ArabicAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public ArabicAnalyzer( Version matchVersion, File stopwords ) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet( stopwords, STOPWORDS_COMMENT));
-  }
-
-  /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
index 09ccecd..243b0c7 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/ar/ArabicLetterTokenizer.java
@@ -40,8 +40,6 @@ import org.apache.lucene.util.Version;
  * </ul>
  */
 public class ArabicLetterTokenizer extends LetterTokenizer {
-
-  
   /**
    * Construct a new ArabicLetterTokenizer.
    * @param matchVersion Lucene version
@@ -84,41 +82,6 @@ public class ArabicLetterTokenizer extends LetterTokenizer {
   }
   
   /**
-   * Construct a new ArabicLetterTokenizer.
-   * 
-   * @deprecated use {@link #ArabicLetterTokenizer(Version, Reader)} instead. This will
-   *             be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public ArabicLetterTokenizer(Reader in) {
-    super(in);
-  }
-
-  /**
-   * Construct a new ArabicLetterTokenizer using a given {@link AttributeSource}.
-   * 
-   * @deprecated use {@link #ArabicLetterTokenizer(Version, AttributeSource, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public ArabicLetterTokenizer(AttributeSource source, Reader in) {
-    super(source, in);
-  }
-
-  /**
-   * Construct a new ArabicLetterTokenizer using a given
-   * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
-   * 
-   * @deprecated use {@link #ArabicLetterTokenizer(Version, AttributeSource.AttributeFactory, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public ArabicLetterTokenizer(AttributeFactory factory, Reader in) {
-    super(factory, in);
-  }
-  
-  
-  /** 
    * Allows for Letter category or NonspacingMark category
    * @see org.apache.lucene.analysis.core.LetterTokenizer#isTokenChar(int)
    */
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
index 729009e..400c8e6 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/bg/BulgarianAnalyzer.java
@@ -17,7 +17,6 @@ package org.apache.lucene.analysis.bg;
  * limitations under the License.
  */
 
-import java.io.File;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Set;
@@ -32,7 +31,6 @@ import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
-import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
 
 /**
@@ -44,7 +42,6 @@ import org.apache.lucene.util.Version;
  * <p>
  */
 public final class BulgarianAnalyzer extends StopwordAnalyzerBase {
-  
   /**
    * File containing default Bulgarian stopwords.
    * 
@@ -53,16 +50,7 @@ public final class BulgarianAnalyzer extends StopwordAnalyzerBase {
    * BSD-Licensed.
    */
   public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
-  
-  /**
-   * The comment character in the stopwords file. All lines prefixed with this
-   * will be ignored
-   * @deprecated use {@link WordlistLoader#getWordSet(File, String)} directly
-   */
-  //TODO make this private
-  @Deprecated
-  public static final String STOPWORDS_COMMENT = "#";
-  
+
   /**
    * Returns an unmodifiable instance of the default stop-words set.
    * 
@@ -81,7 +69,7 @@ public final class BulgarianAnalyzer extends StopwordAnalyzerBase {
     
     static {
       try {
-        DEFAULT_STOP_SET = loadStopwordSet(false, BulgarianAnalyzer.class, DEFAULT_STOPWORD_FILE, STOPWORDS_COMMENT);
+        DEFAULT_STOP_SET = loadStopwordSet(false, BulgarianAnalyzer.class, DEFAULT_STOPWORD_FILE, "#");
       } catch (IOException ex) {
         // default set should always be present as it is part of the
         // distribution (JAR)
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
index 94b0300..1b144b4 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianAnalyzer.java
@@ -17,20 +17,17 @@ package org.apache.lucene.analysis.br;
  * limitations under the License.
  */
 
-import java.io.File;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Collections;
-import java.util.HashSet;
-import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
@@ -51,34 +48,6 @@ import org.apache.lucene.util.Version;
  * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public final class BrazilianAnalyzer extends StopwordAnalyzerBase {
-
-	/**
-	 * List of typical Brazilian Portuguese stopwords.
-	 * @deprecated use {@link #getDefaultStopSet()} instead
-	 */
-  // TODO make this private in 3.1
-	@Deprecated
-	public final static String[] BRAZILIAN_STOP_WORDS = {
-      "a","ainda","alem","ambas","ambos","antes",
-      "ao","aonde","aos","apos","aquele","aqueles",
-      "as","assim","com","como","contra","contudo",
-      "cuja","cujas","cujo","cujos","da","das","de",
-      "dela","dele","deles","demais","depois","desde",
-      "desta","deste","dispoe","dispoem","diversa",
-      "diversas","diversos","do","dos","durante","e",
-      "ela","elas","ele","eles","em","entao","entre",
-      "essa","essas","esse","esses","esta","estas",
-      "este","estes","ha","isso","isto","logo","mais",
-      "mas","mediante","menos","mesma","mesmas","mesmo",
-      "mesmos","na","nas","nao","nas","nem","nesse","neste",
-      "nos","o","os","ou","outra","outras","outro","outros",
-      "pelas","pelas","pelo","pelos","perante","pois","por",
-      "porque","portanto","proprio","propios","quais","qual",
-      "qualquer","quando","quanto","que","quem","quer","se",
-      "seja","sem","sendo","seu","seus","sob","sobre","sua",
-      "suas","tal","tambem","teu","teus","toda","todas","todo",
-      "todos","tua","tuas","tudo","um","uma","umas","uns"};
-
   /** File containing default Brazilian Portuguese stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
   
@@ -110,7 +79,6 @@ public final class BrazilianAnalyzer extends StopwordAnalyzerBase {
 	/**
 	 * Contains words that should be indexed but not stemmed.
 	 */
-	// TODO make this private in 3.1
 	private Set<?> excltable = Collections.emptySet();
 	
 	/**
@@ -147,62 +115,6 @@ public final class BrazilianAnalyzer extends StopwordAnalyzerBase {
         .copy(matchVersion, stemExclusionSet));
   }
 
-	/**
-	 * Builds an analyzer with the given stop words.
-	 * @deprecated use {@link #BrazilianAnalyzer(Version, Set)} instead
-	 */
-  @Deprecated
-  public BrazilianAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words. 
-   * @deprecated use {@link #BrazilianAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public BrazilianAnalyzer(Version matchVersion, Map<?,?> stopwords) {
-    this(matchVersion, stopwords.keySet());
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #BrazilianAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public BrazilianAnalyzer(Version matchVersion, File stopwords)
-      throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
-  }
-
-	/**
-	 * Builds an exclusionlist from an array of Strings.
-	 * @deprecated use {@link #BrazilianAnalyzer(Version, Set, Set)} instead
-	 */
-	@Deprecated
-	public void setStemExclusionTable( String... exclusionlist ) {
-		excltable = StopFilter.makeStopSet( matchVersion, exclusionlist );
-		setPreviousTokenStream(null); // force a new stemmer to be created
-	}
-	/**
-	 * Builds an exclusionlist from a {@link Map}.
-	 * @deprecated use {@link #BrazilianAnalyzer(Version, Set, Set)} instead
-	 */
-	@Deprecated
-	public void setStemExclusionTable( Map<?,?> exclusionlist ) {
-		excltable = new HashSet<Object>(exclusionlist.keySet());
-		setPreviousTokenStream(null); // force a new stemmer to be created
-	}
-	/**
-	 * Builds an exclusionlist from the words contained in the given file.
-	 * @deprecated use {@link #BrazilianAnalyzer(Version, Set, Set)} instead
-	 */
-	@Deprecated
-	public void setStemExclusionTable( File exclusionlist ) throws IOException {
-		excltable = WordlistLoader.getWordSet( exclusionlist );
-		setPreviousTokenStream(null); // force a new stemmer to be created
-	}
-
   /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
index a6c42eb..c7ef2f6 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/br/BrazilianStemFilter.java
@@ -20,11 +20,11 @@ package org.apache.lucene.analysis.br;
 import java.io.IOException;
 import java.util.Set;
 
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
 
 /**
  * A {@link TokenFilter} that applies {@link BrazilianStemmer}.
@@ -55,19 +55,6 @@ public final class BrazilianStemFilter extends TokenFilter {
     super(in);
   }
   
-  /**
-   * Creates a new BrazilianStemFilter 
-   * 
-   * @param in the source {@link TokenStream} 
-   * @param exclusiontable a set of terms that should be prevented from being stemmed.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-   */
-  @Deprecated
-  public BrazilianStemFilter(TokenStream in, Set<?> exclusiontable) {
-    this(in);
-    this.exclusions = exclusiontable;
-  }
-
   @Override
   public boolean incrementToken() throws IOException {
     if (input.incrementToken()) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
index 00a7911..d579681 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/cjk/CJKAnalyzer.java
@@ -17,17 +17,16 @@ package org.apache.lucene.analysis.cjk;
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Set;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
 
-import java.io.Reader;
-import java.util.Arrays;
-import java.util.Set;
-
 
 /**
  * An {@link Analyzer} that tokenizes text with {@link CJKTokenizer} and
@@ -35,28 +34,13 @@ import java.util.Set;
  *
  */
 public final class CJKAnalyzer extends StopwordAnalyzerBase {
-  //~ Static fields/initializers ---------------------------------------------
-
   /**
-   * An array containing some common English words that are not usually
+   * File containing default CJK stopwords.
+   * <p/>
+   * Currently it concains some common English words that are not usually
    * useful for searching and some double-byte interpunctions.
-   * @deprecated use {@link #getDefaultStopSet()} instead
    */
-  // TODO make this final in 3.1 -
-  // this might be revised and merged with StopFilter stop words too
-  @Deprecated
-  public final static String[] STOP_WORDS = {
-    "a", "and", "are", "as", "at", "be",
-    "but", "by", "for", "if", "in",
-    "into", "is", "it", "no", "not",
-    "of", "on", "or", "s", "such", "t",
-    "that", "the", "their", "then",
-    "there", "these", "they", "this",
-    "to", "was", "will", "with", "",
-    "www"
-  };
-
-  //~ Instance fields --------------------------------------------------------
+  public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
 
   /**
    * Returns an unmodifiable instance of the default stop-words set.
@@ -67,12 +51,18 @@ public final class CJKAnalyzer extends StopwordAnalyzerBase {
   }
   
   private static class DefaultSetHolder {
-    static final Set<?> DEFAULT_STOP_SET = CharArraySet
-        .unmodifiableSet(new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(STOP_WORDS),
-            false));
-  }
+    static final Set<?> DEFAULT_STOP_SET;
 
-  //~ Constructors -----------------------------------------------------------
+    static {
+      try {
+        DEFAULT_STOP_SET = loadStopwordSet(false, CJKAnalyzer.class, DEFAULT_STOPWORD_FILE, "#");
+      } catch (IOException ex) {
+        // default set should always be present as it is part of the
+        // distribution (JAR)
+        throw new RuntimeException("Unable to load default stopword set");
+      }
+    }
+  }
 
   /**
    * Builds an analyzer which removes words in {@link #STOP_WORDS}.
@@ -93,19 +83,6 @@ public final class CJKAnalyzer extends StopwordAnalyzerBase {
     super(matchVersion, stopwords);
   }
 
-  /**
-   * Builds an analyzer which removes words in the provided array.
-   *
-   * @param stopWords stop word array
-   * @deprecated use {@link #CJKAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public CJKAnalyzer(Version matchVersion, String... stopWords) {
-    super(matchVersion, StopFilter.makeStopSet(matchVersion, stopWords));
-  }
-
-  //~ Methods ----------------------------------------------------------------
-
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
       Reader reader) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
index c04c349..90d7194 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseAnalyzer.java
@@ -27,8 +27,8 @@ import org.apache.lucene.analysis.Tokenizer;
 /**
  * An {@link Analyzer} that tokenizes text with {@link ChineseTokenizer} and
  * filters with {@link ChineseFilter}
- * @deprecated Use {@link StandardAnalyzer} instead, which has the same functionality.
- * This analyzer will be removed in Lucene 4.0
+ * @deprecated (3.1) Use {@link StandardAnalyzer} instead, which has the same functionality.
+ * This analyzer will be removed in Lucene 5.0
  */
 @Deprecated
 public final class ChineseAnalyzer extends ReusableAnalyzerBase {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
index 22cd6cd..60503da 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseFilter.java
@@ -42,8 +42,8 @@ import org.apache.lucene.util.Version;
  * </ol>
  * 
  * @version 1.0
- * @deprecated Use {@link StopFilter} instead, which has the same functionality.
- * This filter will be removed in Lucene 4.0
+ * @deprecated (3.1) Use {@link StopFilter} instead, which has the same functionality.
+ * This filter will be removed in Lucene 5.0
  */
 @Deprecated
 public final class ChineseFilter extends TokenFilter {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
index c3f5099..1389003 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/cn/ChineseTokenizer.java
@@ -53,8 +53,8 @@ import org.apache.lucene.util.AttributeSource;
  * CJKTokenizer will not work.
  * </p>
  * @version 1.0
- * @deprecated Use {@link StandardTokenizer} instead, which has the same functionality.
- * This filter will be removed in Lucene 4.0
+ * @deprecated (3.1) Use {@link StandardTokenizer} instead, which has the same functionality.
+ * This filter will be removed in Lucene 5.0
  */
 @Deprecated
 public final class ChineseTokenizer extends Tokenizer {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java
index 7942f44..a9bbfa8 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/commongrams/CommonGramsFilter.java
@@ -61,18 +61,6 @@ public final class CommonGramsFilter extends TokenFilter {
   private boolean lastWasCommon;
   private State savedState;
 
-  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, Set<?> commonWords) {
-    this(Version.LUCENE_29, input, commonWords);
-  }
-  
-  /** @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, Set<?> commonWords, boolean ignoreCase) {
-    this(Version.LUCENE_29, input, commonWords, ignoreCase);
-  }
-  
   /**
    * Construct a token stream filtering the given input using a Set of common
    * words to create bigrams. Outputs both unigrams with position increment and
@@ -114,66 +102,6 @@ public final class CommonGramsFilter extends TokenFilter {
   }
 
   /**
-   * Construct a token stream filtering the given input using an Array of common
-   * words to create bigrams.
-   * 
-   * @param input Tokenstream in filter chain
-   * @param commonWords words to be used in constructing bigrams
-   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set)} instead.
-   */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, String[] commonWords) {
-    this(input, commonWords, false);
-  }
-
-  /**
-   * Construct a token stream filtering the given input using an Array of common
-   * words to create bigrams and is case-sensitive if ignoreCase is false.
-   * 
-   * @param input Tokenstream in filter chain
-   * @param commonWords words to be used in constructing bigrams
-   * @param ignoreCase -Ignore case when constructing bigrams for common words.
-   * @deprecated Use {@link #CommonGramsFilter(Version, TokenStream, Set, boolean)} instead.
-   */
-  @Deprecated
-  public CommonGramsFilter(TokenStream input, String[] commonWords, boolean ignoreCase) {
-    super(input);
-    this.commonWords = makeCommonSet(commonWords, ignoreCase);
-  }
-
-  /**
-   * Build a CharArraySet from an array of common words, appropriate for passing
-   * into the CommonGramsFilter constructor. This permits this commonWords
-   * construction to be cached once when an Analyzer is constructed.
-   *
-   * @param commonWords Array of common words which will be converted into the CharArraySet
-   * @return CharArraySet of the given words, appropriate for passing into the CommonGramFilter constructor
-   * @see #makeCommonSet(java.lang.String[], boolean) passing false to ignoreCase
-   * @deprecated create a CharArraySet with CharArraySet instead
-   */
-  @Deprecated
-  public static CharArraySet makeCommonSet(String[] commonWords) {
-    return makeCommonSet(commonWords, false);
-  }
-
-  /**
-   * Build a CharArraySet from an array of common words, appropriate for passing
-   * into the CommonGramsFilter constructor,case-sensitive if ignoreCase is
-   * false.
-   * 
-   * @param commonWords Array of common words which will be converted into the CharArraySet
-   * @param ignoreCase If true, all words are lower cased first.
-   * @return a Set containing the words
-   * @deprecated create a CharArraySet with CharArraySet instead
-   */
-  @Deprecated
-  public static CharArraySet makeCommonSet(String[] commonWords, boolean ignoreCase) {
-    CharArraySet commonSet = new CharArraySet(commonWords.length, ignoreCase);
-    commonSet.addAll(Arrays.asList(commonWords));
-    return commonSet;
-  }
-
-  /**
    * Inserts bigrams for common words into a token stream. For each input token,
    * output the token. If the token and/or the following token are in the list
    * of common words also output a bigram with position increment 0 and
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
index a98da16..4e595f0 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/CompoundWordTokenFilterBase.java
@@ -78,54 +78,7 @@ public abstract class CompoundWordTokenFilterBase extends TokenFilter {
   private final PayloadAttribute payloadAtt = addAttribute(PayloadAttribute.class);
   
   private final Token wrapper = new Token();
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, String[], int, int, int, boolean)} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, String[] dictionary, int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    this(Version.LUCENE_30, input, makeDictionary(dictionary),minWordSize,minSubwordSize,maxSubwordSize, onlyLongestMatch);
-  }
-  
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, String[], boolean)} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, String[] dictionary, boolean onlyLongestMatch) {
-    this(Version.LUCENE_30, input, makeDictionary(dictionary),DEFAULT_MIN_WORD_SIZE,DEFAULT_MIN_SUBWORD_SIZE,DEFAULT_MAX_SUBWORD_SIZE, onlyLongestMatch);
-  }
-  
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, Set, boolean)} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, Set<?> dictionary, boolean onlyLongestMatch) {
-    this(Version.LUCENE_30, input, dictionary,DEFAULT_MIN_WORD_SIZE,DEFAULT_MIN_SUBWORD_SIZE,DEFAULT_MAX_SUBWORD_SIZE, onlyLongestMatch);
-  }
-  
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, String[])} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, String[] dictionary) {
-    this(Version.LUCENE_30, input, makeDictionary(dictionary),DEFAULT_MIN_WORD_SIZE,DEFAULT_MIN_SUBWORD_SIZE,DEFAULT_MAX_SUBWORD_SIZE, false);
-  }
-  
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, Set<?> dictionary) {
-    this(Version.LUCENE_30, input, dictionary,DEFAULT_MIN_WORD_SIZE,DEFAULT_MIN_SUBWORD_SIZE,DEFAULT_MAX_SUBWORD_SIZE, false);
-  }
 
-  /**
-   * @deprecated use {@link #CompoundWordTokenFilterBase(Version, TokenStream, Set, int, int, int, boolean)} instead
-   */
-  @Deprecated
-  protected CompoundWordTokenFilterBase(TokenStream input, Set<?> dictionary, int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    this(Version.LUCENE_30, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);
-  }
-  
   protected CompoundWordTokenFilterBase(Version matchVersion, TokenStream input, String[] dictionary, int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
     this(matchVersion, input,makeDictionary(dictionary),minWordSize,minSubwordSize,maxSubwordSize, onlyLongestMatch);
   }
@@ -170,11 +123,11 @@ public abstract class CompoundWordTokenFilterBase extends TokenFilter {
    * @param dictionary 
    * @return {@link Set} of lowercased terms 
    */
-  public static final Set<?> makeDictionary(final String[] dictionary) {
+  public static Set<?> makeDictionary(final String[] dictionary) {
     return makeDictionary(Version.LUCENE_30, dictionary);
   }
   
-  public static final Set<?> makeDictionary(final Version matchVersion, final String[] dictionary) {
+  public static Set<?> makeDictionary(final Version matchVersion, final String[] dictionary) {
     if (dictionary == null) {
       return null;
     }
@@ -184,7 +137,7 @@ public abstract class CompoundWordTokenFilterBase extends TokenFilter {
     return dict;
   }
   
-  private final void setToken(final Token token) throws IOException {
+  private void setToken(final Token token) throws IOException {
     clearAttributes();
     termAtt.copyBuffer(token.buffer(), 0, token.length());
     flagsAtt.setFlags(token.getFlags());
@@ -222,7 +175,7 @@ public abstract class CompoundWordTokenFilterBase extends TokenFilter {
     }
   }
   
-  protected static final void addAllLowerCase(CharArraySet target, Collection<?> col) {
+  protected static void addAllLowerCase(CharArraySet target, Collection<?> col) {
     for (Object obj : col) {
       String string = (String) obj;
       target.add(string.toLowerCase(Locale.ENGLISH));
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter.java
index ade9b31..405c1af 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/DictionaryCompoundWordTokenFilter.java
@@ -21,7 +21,7 @@ package org.apache.lucene.analysis.compound;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenFilter; // for javadocs
+import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.util.Version;
 
@@ -34,67 +34,6 @@ import org.apache.lucene.util.Version;
  * </p>
  */
 public class DictionaryCompoundWordTokenFilter extends CompoundWordTokenFilterBase {
-  
-  /**
-   * Creates a new {@link DictionaryCompoundWordTokenFilter}
-   * 
-   * @param input the {@link TokenStream} to process
-   * @param dictionary the word dictionary to match against
-   * @param minWordSize only words longer than this get processed
-   * @param minSubwordSize only subwords longer than this get to the output stream
-   * @param maxSubwordSize only subwords shorter than this get to the output stream
-   * @param onlyLongestMatch Add only the longest matching subword to the stream
-   * @deprecated use {@link #DictionaryCompoundWordTokenFilter(Version, TokenStream, String[], int, int, int, boolean)} instead
-   */
-  @Deprecated
-  public DictionaryCompoundWordTokenFilter(TokenStream input, String[] dictionary,
-      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    super(Version.LUCENE_30, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);
-  }
-
-  /**
-   * Creates a new {@link DictionaryCompoundWordTokenFilter}
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param dictionary the word dictionary to match against
-   * @deprecated use {@link #DictionaryCompoundWordTokenFilter(Version, TokenStream, String[])} instead 
-   */
-  @Deprecated
-  public DictionaryCompoundWordTokenFilter(TokenStream input, String[] dictionary) {
-    super(Version.LUCENE_30, input, dictionary);
-  }
-
-  /**
-   * Creates a new {@link DictionaryCompoundWordTokenFilter}
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param dictionary the word dictionary to match against. If this is a {@link org.apache.lucene.analysis.util.CharArraySet CharArraySet} it must have set ignoreCase=false and only contain
-   *        lower case strings.
-   * @deprecated use {@link #DictionaryCompoundWordTokenFilter(Version, TokenStream, Set)} instead 
-   */
-  @Deprecated
-  public DictionaryCompoundWordTokenFilter(TokenStream input, Set dictionary) {
-    super(Version.LUCENE_30, input, dictionary);
-  }
-
-  /**
-   * Creates a new {@link DictionaryCompoundWordTokenFilter}
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param dictionary the word dictionary to match against. If this is a {@link org.apache.lucene.analysis.util.CharArraySet CharArraySet} it must have set ignoreCase=false and only contain
-   *        lower case strings. 
-   * @param minWordSize only words longer than this get processed
-   * @param minSubwordSize only subwords longer than this get to the output stream
-   * @param maxSubwordSize only subwords shorter than this get to the output stream
-   * @param onlyLongestMatch Add only the longest matching subword to the stream
-   * @deprecated use {@link #DictionaryCompoundWordTokenFilter(Version, TokenStream, Set, int, int, int, boolean)} instead
-   */
-  @Deprecated
-  public DictionaryCompoundWordTokenFilter(TokenStream input, Set dictionary,
-      int minWordSize, int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    super(Version.LUCENE_30, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize, onlyLongestMatch);
-  }
-  
   /**
    * Creates a new {@link DictionaryCompoundWordTokenFilter}
    * 
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
index 4e46b16..b821fd1 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/compound/HyphenationCompoundWordTokenFilter.java
@@ -18,12 +18,10 @@ package org.apache.lucene.analysis.compound;
  */
 
 import java.io.File;
-import java.io.FileInputStream;
-import java.io.Reader;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenFilter; // for javadocs
+import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.compound.hyphenation.Hyphenation;
 import org.apache.lucene.analysis.compound.hyphenation.HyphenationTree;
@@ -68,8 +66,10 @@ public class HyphenationCompoundWordTokenFilter extends
   public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,
       HyphenationTree hyphenator, String[] dictionary, int minWordSize,
       int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    this(input, hyphenator, makeDictionary(dictionary), minWordSize,
-        minSubwordSize, maxSubwordSize, onlyLongestMatch);
+    super(matchVersion, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,
+        onlyLongestMatch);
+
+    this.hyphenator = hyphenator;
   }
 
   /**
@@ -89,7 +89,7 @@ public class HyphenationCompoundWordTokenFilter extends
    */
   public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,
       HyphenationTree hyphenator, String[] dictionary) {
-    this(input, hyphenator, makeDictionary(dictionary), DEFAULT_MIN_WORD_SIZE,
+    this(matchVersion, input, hyphenator, makeDictionary(dictionary), DEFAULT_MIN_WORD_SIZE,
         DEFAULT_MIN_SUBWORD_SIZE, DEFAULT_MAX_SUBWORD_SIZE, false);
   }
 
@@ -113,7 +113,7 @@ public class HyphenationCompoundWordTokenFilter extends
    */
   public HyphenationCompoundWordTokenFilter(Version matchVersion, TokenStream input,
       HyphenationTree hyphenator, Set<?> dictionary) {
-    this(input, hyphenator, dictionary, DEFAULT_MIN_WORD_SIZE,
+    this(matchVersion, input, hyphenator, dictionary, DEFAULT_MIN_WORD_SIZE,
         DEFAULT_MIN_SUBWORD_SIZE, DEFAULT_MAX_SUBWORD_SIZE, false);
   }
 
@@ -180,84 +180,6 @@ public class HyphenationCompoundWordTokenFilter extends
   }
 
   /**
-   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.
-   * 
-   * @param input the {@link TokenStream} to process
-   * @param hyphenator the hyphenation pattern tree to use for hyphenation
-   * @param dictionary the word dictionary to match against
-   * @param minWordSize only words longer than this get processed
-   * @param minSubwordSize only subwords longer than this get to the output
-   *        stream
-   * @param maxSubwordSize only subwords shorter than this get to the output
-   *        stream
-   * @param onlyLongestMatch Add only the longest matching subword to the stream
-   * @deprecated use {@link #HyphenationCompoundWordTokenFilter(Version, TokenStream, HyphenationTree, String[], int, int, int, boolean)} instead. 
-   */
-  @Deprecated
-  public HyphenationCompoundWordTokenFilter(TokenStream input,
-      HyphenationTree hyphenator, String[] dictionary, int minWordSize,
-      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    this(Version.LUCENE_30, input, hyphenator, makeDictionary(dictionary), minWordSize,
-        minSubwordSize, maxSubwordSize, onlyLongestMatch);
-  }
-
-  /**
-   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param hyphenator the hyphenation pattern tree to use for hyphenation
-   * @param dictionary the word dictionary to match against
-   * @deprecated use {@link #HyphenationCompoundWordTokenFilter(Version, TokenStream, HyphenationTree, String[])} instead.
-   */
-  @Deprecated
-  public HyphenationCompoundWordTokenFilter(TokenStream input,
-      HyphenationTree hyphenator, String[] dictionary) {
-    this(Version.LUCENE_30, input, hyphenator, makeDictionary(dictionary), DEFAULT_MIN_WORD_SIZE,
-        DEFAULT_MIN_SUBWORD_SIZE, DEFAULT_MAX_SUBWORD_SIZE, false);
-  }
-
-  /**
-   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param hyphenator the hyphenation pattern tree to use for hyphenation
-   * @param dictionary the word dictionary to match against. If this is a {@link org.apache.lucene.analysis.util.CharArraySet CharArraySet} it must have set ignoreCase=false and only contain
-   *        lower case strings. 
-   * @deprecated use {@link #HyphenationCompoundWordTokenFilter(Version, TokenStream, HyphenationTree, Set)} instead.        
-   */
-  @Deprecated
-  public HyphenationCompoundWordTokenFilter(TokenStream input,
-      HyphenationTree hyphenator, Set<?> dictionary) {
-    this(Version.LUCENE_30, input, hyphenator, dictionary, DEFAULT_MIN_WORD_SIZE,
-        DEFAULT_MIN_SUBWORD_SIZE, DEFAULT_MAX_SUBWORD_SIZE, false);
-  }
-
-  /**
-   * Creates a new {@link HyphenationCompoundWordTokenFilter} instance.
-   *  
-   * @param input the {@link TokenStream} to process
-   * @param hyphenator the hyphenation pattern tree to use for hyphenation
-   * @param dictionary the word dictionary to match against. If this is a {@link org.apache.lucene.analysis.util.CharArraySet CharArraySet} it must have set ignoreCase=false and only contain
-   *        lower case strings. 
-   * @param minWordSize only words longer than this get processed
-   * @param minSubwordSize only subwords longer than this get to the output
-   *        stream
-   * @param maxSubwordSize only subwords shorter than this get to the output
-   *        stream
-   * @param onlyLongestMatch Add only the longest matching subword to the stream
-   * @deprecated use {@link #HyphenationCompoundWordTokenFilter(Version, TokenStream, HyphenationTree, Set, int, int, int, boolean)} instead.
-   */
-  @Deprecated
-  public HyphenationCompoundWordTokenFilter(TokenStream input,
-      HyphenationTree hyphenator, Set<?> dictionary, int minWordSize,
-      int minSubwordSize, int maxSubwordSize, boolean onlyLongestMatch) {
-    super(Version.LUCENE_30, input, dictionary, minWordSize, minSubwordSize, maxSubwordSize,
-        onlyLongestMatch);
-
-    this.hyphenator = hyphenator;
-  }
-
-  /**
    * Create a hyphenator tree
    * 
    * @param hyphenationFilename the filename of the XML grammar to load
@@ -284,27 +206,6 @@ public class HyphenationCompoundWordTokenFilter extends
   /**
    * Create a hyphenator tree
    * 
-   * @param hyphenationReader the reader of the XML grammar to load from
-   * @return An object representing the hyphenation patterns
-   * @throws Exception
-   * @deprecated Don't use Readers with fixed charset to load XML files, unless programatically created.
-   * Use {@link #getHyphenationTree(InputSource)} instead, where you can supply default charset and input
-   * stream, if you like.
-   */
-  @Deprecated
-  public static HyphenationTree getHyphenationTree(Reader hyphenationReader)
-      throws Exception {
-    final InputSource is = new InputSource(hyphenationReader);
-    // we need this to load the DTD in very old parsers (like the one in JDK 1.4).
-    // The DTD itsself is provided via EntityResolver, so it should always load, but
-    // some parsers still want to have a base URL (Crimson).
-    is.setSystemId("urn:java:" + HyphenationTree.class.getName());
-    return getHyphenationTree(is);
-  }
-
-  /**
-   * Create a hyphenator tree
-   * 
    * @param hyphenationSource the InputSource pointing to the XML grammar
    * @return An object representing the hyphenation patterns
    * @throws Exception
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
index 9b1d5c9..a985338 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LetterTokenizer.java
@@ -87,40 +87,6 @@ public class LetterTokenizer extends CharTokenizer {
     super(matchVersion, factory, in);
   }
   
-  /**
-   * Construct a new LetterTokenizer.
-   * 
-   * @deprecated use {@link #LetterTokenizer(Version, Reader)} instead. This
-   *             will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LetterTokenizer(Reader in) {
-    super(Version.LUCENE_30, in);
-  }
-  
-  /**
-   * Construct a new LetterTokenizer using a given {@link AttributeSource}. 
-   * @deprecated
-   * use {@link #LetterTokenizer(Version, AttributeSource, Reader)} instead.
-   * This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LetterTokenizer(AttributeSource source, Reader in) {
-    super(Version.LUCENE_30, source, in);
-  }
-  
-  /**
-   * Construct a new LetterTokenizer using a given
-   * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
-   * 
-   * @deprecated use {@link #LetterTokenizer(Version, AttributeSource.AttributeFactory, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LetterTokenizer(AttributeFactory factory, Reader in) {
-    super(Version.LUCENE_30, factory, in);
-  }
-  
   /** Collects only characters which satisfy
    * {@link Character#isLetter(int)}.*/
   @Override
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilter.java
index e44e388..c10972b 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseFilter.java
@@ -49,14 +49,6 @@ public final class LowerCaseFilter extends TokenFilter {
     charUtils = CharacterUtils.getInstance(matchVersion);
   }
   
-  /**
-   * @deprecated Use {@link #LowerCaseFilter(Version, TokenStream)} instead.
-   */
-  @Deprecated
-  public LowerCaseFilter(TokenStream in) {
-    this(Version.LUCENE_30, in);
-  }
-
   @Override
   public final boolean incrementToken() throws IOException {
     if (input.incrementToken()) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
index 0c8e594..a65d90b 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/LowerCaseTokenizer.java
@@ -89,40 +89,6 @@ public final class LowerCaseTokenizer extends LetterTokenizer {
     super(matchVersion, factory, in);
   }
   
-  /**
-   * Construct a new LowerCaseTokenizer.
-   * 
-   * @deprecated use {@link #LowerCaseTokenizer(Reader)} instead. This will be
-   *             removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LowerCaseTokenizer(Reader in) {
-    super(Version.LUCENE_30, in);
-  }
-
-  /**
-   * Construct a new LowerCaseTokenizer using a given {@link AttributeSource}.
-   * 
-   * @deprecated use {@link #LowerCaseTokenizer(AttributeSource, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LowerCaseTokenizer(AttributeSource source, Reader in) {
-    super(Version.LUCENE_30, source, in);
-  }
-
-  /**
-   * Construct a new LowerCaseTokenizer using a given
-   * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
-   * 
-   * @deprecated use {@link #LowerCaseTokenizer(AttributeSource.AttributeFactory, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public LowerCaseTokenizer(AttributeFactory factory, Reader in) {
-    super(Version.LUCENE_30, factory, in);
-  }
-  
   /** Converts char to lower case
    * {@link Character#toLowerCase(int)}.*/
   @Override
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java
index 64e2c6c..ce2bc6a 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/SimpleAnalyzer.java
@@ -22,7 +22,6 @@ import java.io.Reader;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.CharTokenizer;
 import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents;
 import org.apache.lucene.util.Version;
 
 /** An {@link Analyzer} that filters {@link LetterTokenizer} 
@@ -49,13 +48,6 @@ public final class SimpleAnalyzer extends ReusableAnalyzerBase {
     this.matchVersion = matchVersion;
   }
   
-  /**
-   * Creates a new {@link SimpleAnalyzer}
-   * @deprecated use {@link #SimpleAnalyzer(Version)} instead 
-   */
-  @Deprecated  public SimpleAnalyzer() {
-    this(Version.LUCENE_30);
-  }
   @Override
   protected TokenStreamComponents createComponents(final String fieldName,
       final Reader reader) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilter.java
index 9d81e75..0aba57f 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/StopFilter.java
@@ -19,15 +19,15 @@ package org.apache.lucene.analysis.core;
 
 import java.io.IOException;
 import java.util.Arrays;
-import java.util.Set;
 import java.util.List;
+import java.util.Set;
 
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.queryParser.QueryParser; // for javadoc
+import org.apache.lucene.queryParser.QueryParser;
 import org.apache.lucene.util.Version;
 
 /**
@@ -45,34 +45,12 @@ import org.apache.lucene.util.Version;
 public final class StopFilter extends TokenFilter {
 
   private final CharArraySet stopWords;
-  private boolean enablePositionIncrements = false;
+  private boolean enablePositionIncrements = true;
 
   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
   private final PositionIncrementAttribute posIncrAtt = addAttribute(PositionIncrementAttribute.class);
 
-  /**
-   * Construct a token stream filtering the given input.
-   * If <code>stopWords</code> is an instance of {@link CharArraySet} (true if
-   * <code>makeStopSet()</code> was used to construct the set) it will be directly used
-   * and <code>ignoreCase</code> will be ignored since <code>CharArraySet</code>
-   * directly controls case sensitivity.
-   * <p/>
-   * If <code>stopWords</code> is not an instance of {@link CharArraySet},
-   * a new CharArraySet will be constructed and <code>ignoreCase</code> will be
-   * used to specify the case sensitivity of that set.
-   *
-   * @param enablePositionIncrements true if token positions should record the removed stop words
-   * @param input Input TokenStream
-   * @param stopWords A Set of Strings or char[] or any other toString()-able set representing the stopwords
-   * @param ignoreCase if true, all words are lower cased first
-   * @deprecated use {@link #StopFilter(Version, TokenStream, Set, boolean)} instead
-   */
-  @Deprecated
-  public StopFilter(boolean enablePositionIncrements, TokenStream input, Set<?> stopWords, boolean ignoreCase)
-  {
-    this(Version.LUCENE_30, enablePositionIncrements, input, stopWords, ignoreCase);
-  }
-  
+
   /**
    * Construct a token stream filtering the given input. If
    * <code>stopWords</code> is an instance of {@link CharArraySet} (true if
@@ -97,31 +75,8 @@ public final class StopFilter extends TokenFilter {
    */
   public StopFilter(Version matchVersion, TokenStream input, Set<?> stopWords, boolean ignoreCase)
   {
-   this(matchVersion, matchVersion.onOrAfter(Version.LUCENE_29), input, stopWords, ignoreCase);
-  }
-  
-  /*
-   * convenience ctor to enable deprecated ctors to set posInc explicitly
-   */
-  private StopFilter(Version matchVersion, boolean enablePositionIncrements, TokenStream input, Set<?> stopWords, boolean ignoreCase){
     super(input);
-    this.stopWords = stopWords instanceof CharArraySet ? (CharArraySet)stopWords : new CharArraySet(matchVersion, stopWords, ignoreCase);  
-    this.enablePositionIncrements = enablePositionIncrements;
-  }
-
-  /**
-   * Constructs a filter which removes words from the input
-   * TokenStream that are named in the Set.
-   *
-   * @param enablePositionIncrements true if token positions should record the removed stop words
-   * @param in Input stream
-   * @param stopWords A Set of Strings or char[] or any other toString()-able set representing the stopwords
-   * @see #makeStopSet(Version, java.lang.String[])
-   * @deprecated use {@link #StopFilter(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  public StopFilter(boolean enablePositionIncrements, TokenStream in, Set<?> stopWords) {
-    this(Version.LUCENE_CURRENT, enablePositionIncrements, in, stopWords, false);
+    this.stopWords = stopWords instanceof CharArraySet ? (CharArraySet) stopWords : new CharArraySet(matchVersion, stopWords, ignoreCase);
   }
   
   /**
@@ -136,7 +91,7 @@ public final class StopFilter extends TokenFilter {
    * @param stopWords
    *          A Set of Strings or char[] or any other toString()-able set
    *          representing the stopwords
-   * @see #makeStopSet(Version, java.lang.String[])
+   * @see #makeStopSet(Version, java.lang.String...)
    */
   public StopFilter(Version matchVersion, TokenStream in, Set<?> stopWords) {
     this(matchVersion, in, stopWords, false);
@@ -148,25 +103,11 @@ public final class StopFilter extends TokenFilter {
    * This permits this stopWords construction to be cached once when
    * an Analyzer is constructed.
    * 
-   * @see #makeStopSet(Version, java.lang.String[], boolean) passing false to ignoreCase
-   * @deprecated use {@link #makeStopSet(Version, String...)} instead
-   */
-  @Deprecated
-  public static final Set<Object> makeStopSet(String... stopWords) {
-    return makeStopSet(Version.LUCENE_30, stopWords, false);
-  }
-
-  /**
-   * Builds a Set from an array of stop words,
-   * appropriate for passing into the StopFilter constructor.
-   * This permits this stopWords construction to be cached once when
-   * an Analyzer is constructed.
-   * 
    * @param matchVersion Lucene version to enable correct Unicode 4.0 behavior in the returned set if Version > 3.0
    * @param stopWords An array of stopwords
    * @see #makeStopSet(Version, java.lang.String[], boolean) passing false to ignoreCase
    */
-  public static final Set<Object> makeStopSet(Version matchVersion, String... stopWords) {
+  public static Set<Object> makeStopSet(Version matchVersion, String... stopWords) {
     return makeStopSet(matchVersion, stopWords, false);
   }
   
@@ -175,51 +116,25 @@ public final class StopFilter extends TokenFilter {
    * appropriate for passing into the StopFilter constructor.
    * This permits this stopWords construction to be cached once when
    * an Analyzer is constructed.
-   * @param stopWords A List of Strings or char[] or any other toString()-able list representing the stopwords
-   * @return A Set ({@link CharArraySet}) containing the words
-   * @see #makeStopSet(Version, java.lang.String[], boolean) passing false to ignoreCase
-   * @deprecated use {@link #makeStopSet(Version, List)} instead
-   */
-  @Deprecated
-  public static final Set<Object> makeStopSet(List<?> stopWords) {
-    return makeStopSet(Version.LUCENE_30, stopWords, false);
-  }
-
-  /**
-   * Builds a Set from an array of stop words,
-   * appropriate for passing into the StopFilter constructor.
-   * This permits this stopWords construction to be cached once when
-   * an Analyzer is constructed.
    * 
    * @param matchVersion Lucene version to enable correct Unicode 4.0 behavior in the returned set if Version > 3.0
    * @param stopWords A List of Strings or char[] or any other toString()-able list representing the stopwords
    * @return A Set ({@link CharArraySet}) containing the words
    * @see #makeStopSet(Version, java.lang.String[], boolean) passing false to ignoreCase
    */
-  public static final Set<Object> makeStopSet(Version matchVersion, List<?> stopWords) {
+  public static Set<Object> makeStopSet(Version matchVersion, List<?> stopWords) {
     return makeStopSet(matchVersion, stopWords, false);
   }
     
   /**
    * Creates a stopword set from the given stopword array.
-   * @param stopWords An array of stopwords
-   * @param ignoreCase If true, all words are lower cased first.  
-   * @return a Set containing the words
-   * @deprecated use {@link #makeStopSet(Version, String[], boolean)} instead;
-   */  
-  @Deprecated
-  public static final Set<Object> makeStopSet(String[] stopWords, boolean ignoreCase) {
-    return makeStopSet(Version.LUCENE_30, stopWords, ignoreCase);
-  }
-  /**
-   * Creates a stopword set from the given stopword array.
    * 
    * @param matchVersion Lucene version to enable correct Unicode 4.0 behavior in the returned set if Version > 3.0
    * @param stopWords An array of stopwords
    * @param ignoreCase If true, all words are lower cased first.  
    * @return a Set containing the words
    */    
-  public static final Set<Object> makeStopSet(Version matchVersion, String[] stopWords, boolean ignoreCase) {
+  public static Set<Object> makeStopSet(Version matchVersion, String[] stopWords, boolean ignoreCase) {
     CharArraySet stopSet = new CharArraySet(matchVersion, stopWords.length, ignoreCase);
     stopSet.addAll(Arrays.asList(stopWords));
     return stopSet;
@@ -227,24 +142,12 @@ public final class StopFilter extends TokenFilter {
   
   /**
    * Creates a stopword set from the given stopword list.
-   * @param stopWords A List of Strings or char[] or any other toString()-able list representing the stopwords
-   * @param ignoreCase if true, all words are lower cased first
-   * @return A Set ({@link CharArraySet}) containing the words
-   * @deprecated use {@link #makeStopSet(Version, List, boolean)} instead
-   */
-  @Deprecated
-  public static final Set<Object> makeStopSet(List<?> stopWords, boolean ignoreCase){
-    return makeStopSet(Version.LUCENE_30, stopWords, ignoreCase);
-  }
-
-  /**
-   * Creates a stopword set from the given stopword list.
    * @param matchVersion Lucene version to enable correct Unicode 4.0 behavior in the returned set if Version > 3.0
    * @param stopWords A List of Strings or char[] or any other toString()-able list representing the stopwords
    * @param ignoreCase if true, all words are lower cased first
    * @return A Set ({@link CharArraySet}) containing the words
    */
-  public static final Set<Object> makeStopSet(Version matchVersion, List<?> stopWords, boolean ignoreCase){
+  public static Set<Object> makeStopSet(Version matchVersion, List<?> stopWords, boolean ignoreCase){
     CharArraySet stopSet = new CharArraySet(matchVersion, stopWords.size(), ignoreCase);
     stopSet.addAll(stopWords);
     return stopSet;
@@ -271,19 +174,6 @@ public final class StopFilter extends TokenFilter {
   }
 
   /**
-   * Returns version-dependent default for
-   * enablePositionIncrements.  Analyzers that embed
-   * StopFilter use this method when creating the
-   * StopFilter.  Prior to 2.9, this returns false.  On 2.9
-   * or later, it returns true.
-   * @deprecated use {@link #StopFilter(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  public static boolean getEnablePositionIncrementsVersionDefault(Version matchVersion) {
-    return matchVersion.onOrAfter(Version.LUCENE_29);
-  }
-
-  /**
    * @see #setEnablePositionIncrements(boolean)
    */
   public boolean getEnablePositionIncrements() {
@@ -297,6 +187,8 @@ public final class StopFilter extends TokenFilter {
    * Generally, <code>true</code> is best as it does not
    * lose information (positions of the original tokens)
    * during indexing.
+   *
+   * Default is true.
    * 
    * <p> When set, when a token is stopped
    * (omitted), the position increment of the following
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java
index 300a021..85ce28e 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceAnalyzer.java
@@ -21,7 +21,6 @@ import java.io.Reader;
 
 import org.apache.lucene.analysis.CharTokenizer;
 import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents;
 import org.apache.lucene.util.Version;
 
 /**
@@ -48,15 +47,6 @@ public final class WhitespaceAnalyzer extends ReusableAnalyzerBase {
     this.matchVersion = matchVersion;
   }
   
-  /**
-   * Creates a new {@link WhitespaceAnalyzer}
-   * @deprecated use {@link #WhitespaceAnalyzer(Version)} instead 
-   */
-  @Deprecated
-  public WhitespaceAnalyzer() {
-    this(Version.LUCENE_30);
-  }
-  
   @Override
   protected TokenStreamComponents createComponents(final String fieldName,
       final Reader reader) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
index d3d6b5e..4bf4f04 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/core/WhitespaceTokenizer.java
@@ -80,40 +80,6 @@ public final class WhitespaceTokenizer extends CharTokenizer {
     super(matchVersion, factory, in);
   }
   
-  /**
-   * Construct a new WhitespaceTokenizer.
-   * 
-   * @deprecated use {@link #WhitespaceTokenizer(Version, Reader)} instead. This will
-   *             be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public WhitespaceTokenizer(Reader in) {
-    super(in);
-  }
-
-  /**
-   * Construct a new WhitespaceTokenizer using a given {@link AttributeSource}.
-   * 
-   * @deprecated use {@link #WhitespaceTokenizer(Version, AttributeSource, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public WhitespaceTokenizer(AttributeSource source, Reader in) {
-    super(source, in);
-  }
-
-  /**
-   * Construct a new WhitespaceTokenizer using a given
-   * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
-   * 
-   * @deprecated use {@link #WhitespaceTokenizer(Version, AttributeSource.AttributeFactory, Reader)}
-   *             instead. This will be removed in Lucene 4.0.
-   */
-  @Deprecated
-  public WhitespaceTokenizer(AttributeFactory factory, Reader in) {
-    super(factory, in);
-  }
-  
   /** Collects only characters which do not satisfy
    * {@link Character#isWhitespace(int)}.*/
   @Override
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
index 68204b2..7d906f0 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/cz/CzechAnalyzer.java
@@ -27,6 +27,7 @@ import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
+import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
 
@@ -54,35 +55,7 @@ import java.util.Set;
  * <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1068</a>)
  * </ul>
  */
-public final class CzechAnalyzer extends ReusableAnalyzerBase {
-
-  /**
-	 * List of typical stopwords.
-	 * @deprecated use {@link #getDefaultStopSet()} instead
-	 */
-  // TODO make this private in 3.1
-	@Deprecated
-	public final static String[] CZECH_STOP_WORDS = {
-        "a","s","k","o","i","u","v","z","dnes","cz","t\u00edmto","bude\u0161","budem",
-        "byli","jse\u0161","m\u016fj","sv\u00fdm","ta","tomto","tohle","tuto","tyto",
-        "jej","zda","pro\u010d","m\u00e1te","tato","kam","tohoto","kdo","kte\u0159\u00ed",
-        "mi","n\u00e1m","tom","tomuto","m\u00edt","nic","proto","kterou","byla",
-        "toho","proto\u017ee","asi","ho","na\u0161i","napi\u0161te","re","co\u017e","t\u00edm",
-        "tak\u017ee","sv\u00fdch","jej\u00ed","sv\u00fdmi","jste","aj","tu","tedy","teto",
-        "bylo","kde","ke","prav\u00e9","ji","nad","nejsou","\u010di","pod","t\u00e9ma",
-        "mezi","p\u0159es","ty","pak","v\u00e1m","ani","kdy\u017e","v\u0161ak","neg","jsem",
-        "tento","\u010dl\u00e1nku","\u010dl\u00e1nky","aby","jsme","p\u0159ed","pta","jejich",
-        "byl","je\u0161t\u011b","a\u017e","bez","tak\u00e9","pouze","prvn\u00ed","va\u0161e","kter\u00e1",
-        "n\u00e1s","nov\u00fd","tipy","pokud","m\u016f\u017ee","strana","jeho","sv\u00e9","jin\u00e9",
-        "zpr\u00e1vy","nov\u00e9","nen\u00ed","v\u00e1s","jen","podle","zde","u\u017e","b\u00fdt","v\u00edce",
-        "bude","ji\u017e","ne\u017e","kter\u00fd","by","kter\u00e9","co","nebo","ten","tak",
-        "m\u00e1","p\u0159i","od","po","jsou","jak","dal\u0161\u00ed","ale","si","se","ve",
-        "to","jako","za","zp\u011bt","ze","do","pro","je","na","atd","atp",
-        "jakmile","p\u0159i\u010dem\u017e","j\u00e1","on","ona","ono","oni","ony","my","vy",
-        "j\u00ed","ji","m\u011b","mne","jemu","tomu","t\u011bm","t\u011bmu","n\u011bmu","n\u011bmu\u017e",
-        "jeho\u017e","j\u00ed\u017e","jeliko\u017e","je\u017e","jako\u017e","na\u010de\u017e",
-    };
-	
+public final class CzechAnalyzer extends StopwordAnalyzerBase {
   /** File containing default Czech stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
   
@@ -112,27 +85,21 @@ public final class CzechAnalyzer extends ReusableAnalyzerBase {
 	}
 
  
-  /**
-   * Contains the stopwords used with the {@link StopFilter}.
-   */
-	// TODO once loadStopWords is gone those member should be removed too in favor of StopwordAnalyzerBase
-	private Set<?> stoptable;
-  private final Version matchVersion;
   private final Set<?> stemExclusionTable;
 
   /**
    * Builds an analyzer with the default stop words ({@link #CZECH_STOP_WORDS}).
-   * 
+   *
    * @param matchVersion Lucene version to match See
    *          {@link <a href="#version">above</a>}
    */
 	public CzechAnalyzer(Version matchVersion) {
     this(matchVersion, DefaultSetHolder.DEFAULT_SET);
 	}
-	
+
   /**
    * Builds an analyzer with the given stop words.
-   * 
+   *
    * @param matchVersion Lucene version to match See
    *          {@link <a href="#version">above</a>}
    * @param stopwords a stopword set
@@ -140,7 +107,7 @@ public final class CzechAnalyzer extends ReusableAnalyzerBase {
   public CzechAnalyzer(Version matchVersion, Set<?> stopwords) {
     this(matchVersion, stopwords, CharArraySet.EMPTY_SET);
   }
-  
+
   /**
    * Builds an analyzer with the given stop words and a set of work to be
    * excluded from the {@link CzechStemFilter}.
@@ -151,84 +118,10 @@ public final class CzechAnalyzer extends ReusableAnalyzerBase {
    * @param stemExclusionTable a stemming exclusion set
    */
   public CzechAnalyzer(Version matchVersion, Set<?> stopwords, Set<?> stemExclusionTable) {
-    this.matchVersion = matchVersion;
-    this.stoptable = CharArraySet.unmodifiableSet(CharArraySet.copy(matchVersion, stopwords));
+    super(matchVersion, stopwords);
     this.stemExclusionTable = CharArraySet.unmodifiableSet(CharArraySet.copy(matchVersion, stemExclusionTable));
   }
 
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * 
-   * @param matchVersion Lucene version to match See
-   *          {@link <a href="#version">above</a>}
-   * @param stopwords a stopword set
-   * @deprecated use {@link #CzechAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public CzechAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet( matchVersion, stopwords ));
-	}
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * 
-   * @param matchVersion Lucene version to match See
-   *          {@link <a href="#version">above</a>}
-   * @param stopwords a stopword set
-   * @deprecated use {@link #CzechAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public CzechAnalyzer(Version matchVersion, HashSet<?> stopwords) {
-    this(matchVersion, (Set<?>)stopwords);
-	}
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * 
-   * @param matchVersion Lucene version to match See
-   *          {@link <a href="#version">above</a>}
-   * @param stopwords a file containing stopwords
-   * @deprecated use {@link #CzechAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public CzechAnalyzer(Version matchVersion, File stopwords ) throws IOException {
-    this(matchVersion, (Set<?>)WordlistLoader.getWordSet( stopwords ));
-	}
-
-    /**
-     * Loads stopwords hash from resource stream (file, database...).
-     * @param   wordfile    File containing the wordlist
-     * @param   encoding    Encoding used (win-1250, iso-8859-2, ...), null for default system encoding
-     * @deprecated use {@link WordlistLoader#getWordSet(Reader, String) }
-     *             and {@link #CzechAnalyzer(Version, Set)} instead
-     */
-    // TODO extend StopwordAnalyzerBase once this method is gone!
-    @Deprecated
-    public void loadStopWords( InputStream wordfile, String encoding ) {
-        setPreviousTokenStream(null); // force a new stopfilter to be created
-        if ( wordfile == null ) {
-            stoptable = Collections.emptySet();
-            return;
-        }
-        try {
-            // clear any previous table (if present)
-            stoptable = Collections.emptySet();
-
-            InputStreamReader isr;
-            if (encoding == null)
-                isr = new InputStreamReader(wordfile);
-            else
-                isr = new InputStreamReader(wordfile, encoding);
-
-            stoptable = WordlistLoader.getWordSet(isr);
-        } catch ( IOException e ) {
-          // clear any previous table (if present)
-          // TODO: throw IOException
-          stoptable = Collections.emptySet();
-        }
-    }
-
   /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
@@ -244,12 +137,12 @@ public final class CzechAnalyzer extends ReusableAnalyzerBase {
    *         {@link CzechStemFilter}.
    */
   @Override
-  protected TokenStreamComponents createComponents(String fieldName,
+  protected ReusableAnalyzerBase.TokenStreamComponents createComponents(String fieldName,
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
     TokenStream result = new StandardFilter(matchVersion, source);
     result = new LowerCaseFilter(matchVersion, result);
-    result = new StopFilter( matchVersion, result, stoptable);
+    result = new StopFilter( matchVersion, result, stopwords);
     if (matchVersion.onOrAfter(Version.LUCENE_31)) {
       if(!this.stemExclusionTable.isEmpty())
         result = new KeywordMarkerFilter(result, stemExclusionTable);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
index cb10fcf..78bf7c8 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
@@ -18,12 +18,9 @@ package org.apache.lucene.analysis.de;
  * limitations under the License.
  */
 
-import java.io.File;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Arrays;
-import java.util.HashSet;
-import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -67,13 +64,9 @@ import org.tartarus.snowball.ext.German2Stemmer;
  */
 public final class GermanAnalyzer extends StopwordAnalyzerBase {
   
-  /**
-   * List of typical german stopwords.
-   * @deprecated use {@link #getDefaultStopSet()} instead
-   */
-  //TODO make this private in 3.1, remove in 4.0
+  /** @deprecated in 3.1, remove in Lucene 5.0 (index bw compat) */
   @Deprecated
-  public final static String[] GERMAN_STOP_WORDS = {
+  private final static String[] GERMAN_STOP_WORDS = {
     "einer", "eine", "eines", "einem", "einen",
     "der", "die", "das", "dass", "da?",
     "du", "er", "sie", "es",
@@ -100,7 +93,7 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
   }
   
   private static class DefaultSetHolder {
-    /** @deprecated remove in Lucene 4.0 */
+    /** @deprecated in 3.1, remove in Lucene 5.0 (index bw compat) */
     @Deprecated
     private static final Set<?> DEFAULT_SET_30 = CharArraySet.unmodifiableSet(new CharArraySet(
         Version.LUCENE_CURRENT, Arrays.asList(GERMAN_STOP_WORDS), false));
@@ -124,8 +117,7 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
   /**
    * Contains words that should be indexed but not stemmed.
    */
-  // TODO make this final in 3.1
-  private Set<?> exclusionSet;
+  private final Set<?> exclusionSet;
 
   /**
    * Builds an analyzer with the default stop words:
@@ -165,64 +157,6 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
   }
 
   /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #GermanAnalyzer(Version, Set)}
-   */
-  @Deprecated
-  public GermanAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #GermanAnalyzer(Version, Set)}
-   */
-  @Deprecated
-  public GermanAnalyzer(Version matchVersion, Map<?,?> stopwords) {
-    this(matchVersion, stopwords.keySet());
-    
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #GermanAnalyzer(Version, Set)}
-   */
-  @Deprecated
-  public GermanAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
-  }
-
-  /**
-   * Builds an exclusionlist from an array of Strings.
-   * @deprecated use {@link #GermanAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(String[] exclusionlist) {
-    exclusionSet = StopFilter.makeStopSet(matchVersion, exclusionlist);
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from a {@link Map}
-   * @deprecated use {@link #GermanAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(Map<?,?> exclusionlist) {
-    exclusionSet = new HashSet<Object>(exclusionlist.keySet());
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from the words contained in the given file.
-   * @deprecated use {@link #GermanAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(File exclusionlist) throws IOException {
-    exclusionSet = WordlistLoader.getWordSet(exclusionlist);
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
index be40832..e5461d7 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanStemFilter.java
@@ -18,13 +18,12 @@ package org.apache.lucene.analysis.de;
  */
 
 import java.io.IOException;
-import java.util.Set;
 
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
 
 /**
  * A {@link TokenFilter} that stems German words. 
@@ -46,7 +45,6 @@ public final class GermanStemFilter extends TokenFilter
      * The actual token in the input stream.
      */
     private GermanStemmer stemmer = new GermanStemmer();
-    private Set<?> exclusionSet = null;
 
     private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
     private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
@@ -61,25 +59,14 @@ public final class GermanStemFilter extends TokenFilter
     }
 
     /**
-     * Builds a GermanStemFilter that uses an exclusion table.
-     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-     */
-    @Deprecated
-    public GermanStemFilter( TokenStream in, Set<?> exclusionSet )
-    {
-      this( in );
-      this.exclusionSet = exclusionSet;
-    }
-
-    /**
      * @return  Returns true for next token in the stream, or false at EOS
      */
     @Override
     public boolean incrementToken() throws IOException {
       if (input.incrementToken()) {
         String term = termAtt.toString();
-        // Check the exclusion table.
-        if (!keywordAttr.isKeyword() && (exclusionSet == null || !exclusionSet.contains(term))) {
+
+        if (!keywordAttr.isKeyword()) {
           String s = stemmer.stem(term);
           // If not stemmed, don't waste the time adjusting the token.
           if ((s != null) && !s.equals(term))
@@ -100,15 +87,4 @@ public final class GermanStemFilter extends TokenFilter
         this.stemmer = stemmer;
       }
     }
-
-
-    /**
-     * Set an alternative exclusion list for this filter.
-     * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-     */
-    @Deprecated
-    public void setExclusionSet( Set<?> exclusionSet )
-    {
-      this.exclusionSet = exclusionSet;
-    }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
index 1ff1d77..629912f 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekAnalyzer.java
@@ -16,21 +16,20 @@ package org.apache.lucene.analysis.el;
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Set;
+
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.StopFilter;
+import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;  // for javadoc
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
 
-import java.io.IOException;
-import java.io.Reader;
-import java.util.Map;
-import java.util.Set;
-
 /**
  * {@link Analyzer} for the Greek language. 
  * <p>
@@ -101,25 +100,6 @@ public final class GreekAnalyzer extends StopwordAnalyzerBase {
   }
   
   /**
-   * Builds an analyzer with the given stop words.
-   * @param stopwords Array of stopwords to use.
-   * @deprecated use {@link #GreekAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public GreekAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-  
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #GreekAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public GreekAnalyzer(Version matchVersion, Map<?,?> stopwords) {
-    this(matchVersion, stopwords.keySet());
-  }
-  
-  /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
index d93860e..1fed103 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/el/GreekLowerCaseFilter.java
@@ -38,12 +38,6 @@ public final class GreekLowerCaseFilter extends TokenFilter {
   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
   private final CharacterUtils charUtils;
 
-  /** @deprecated Use {@link #GreekLowerCaseFilter(Version, TokenStream)} instead. */
-  @Deprecated
-  public GreekLowerCaseFilter(TokenStream in) {
-    this(Version.LUCENE_30, in);
-  }
-  
   /**
    * Create a GreekLowerCaseFilter that normalizes Greek token text.
    * 
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
index 6e9a5f8..1435c83 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/en/EnglishAnalyzer.java
@@ -21,11 +21,11 @@ import java.io.Reader;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
@@ -103,7 +103,7 @@ public final class EnglishAnalyzer extends StopwordAnalyzerBase {
   protected TokenStreamComponents createComponents(String fieldName,
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
-    TokenStream result = new StandardFilter(source);
+    TokenStream result = new StandardFilter(matchVersion, source);
     // prior to this we get the classic behavior, standardfilter does it for us.
     if (matchVersion.onOrAfter(Version.LUCENE_31))
       result = new EnglishPossessiveFilter(result);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
index 88eea5b..09e0618 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -17,10 +17,8 @@ package org.apache.lucene.analysis.fa;
  * limitations under the License.
  */
 
-import java.io.File;
 import java.io.IOException;
 import java.io.Reader;
-import java.util.Hashtable;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -31,7 +29,6 @@ import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
-import org.apache.lucene.analysis.util.WordlistLoader;
 import org.apache.lucene.util.Version;
 
 /**
@@ -107,34 +104,6 @@ public final class PersianAnalyzer extends StopwordAnalyzerBase {
   }
 
   /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #PersianAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public PersianAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #PersianAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public PersianAnalyzer(Version matchVersion, Hashtable<?, ?> stopwords) {
-    this(matchVersion, stopwords.keySet());
-  }
-
-  /**
-   * Builds an analyzer with the given stop words. Lines can be commented out
-   * using {@link #STOPWORDS_COMMENT}
-   * @deprecated use {@link #PersianAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public PersianAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords, STOPWORDS_COMMENT));
-  }
-
-  /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
    * used to tokenize all the text in the provided {@link Reader}.
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
index 97b7922..b43a5c3 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/ElisionFilter.java
@@ -18,11 +18,12 @@ package org.apache.lucene.analysis.fr;
  */
 
 import java.io.IOException;
-import java.util.Set;
 import java.util.Arrays;
-import org.apache.lucene.analysis.standard.StandardTokenizer; // for javadocs
-import org.apache.lucene.analysis.TokenStream;
+import java.util.Set;
+
 import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.util.Version;
@@ -45,27 +46,6 @@ public final class ElisionFilter extends TokenFilter {
   private static char[] apostrophes = {'\'', '\u2019'};
   
   /**
-   * Set the stopword articles
-   * @param matchVersion the lucene backwards compatibility version
-   * @param articles a set of articles
-   * @deprecated use {@link #ElisionFilter(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  public void setArticles(Version matchVersion, Set<?> articles) {
-    this.articles = CharArraySet.unmodifiableSet(
-        CharArraySet.copy(matchVersion, articles));
-  }
-
-  /**
-   * Set the stopword articles
-   * @param articles a set of articles
-   * @deprecated use {@link #setArticles(Version, Set)} instead
-   */
-  @Deprecated
-  public void setArticles(Set<?> articles) {
-    setArticles(Version.LUCENE_CURRENT, articles);
-  }
-  /**
    * Constructs an elision filter with standard stop words
    */
   public ElisionFilter(Version matchVersion, TokenStream input) {
@@ -73,24 +53,6 @@ public final class ElisionFilter extends TokenFilter {
   }
 
   /**
-   * Constructs an elision filter with standard stop words
-   * @deprecated use {@link #ElisionFilter(Version, TokenStream)} instead
-   */
-  @Deprecated
-  public ElisionFilter(TokenStream input) {
-    this(Version.LUCENE_30, input);
-  }
-
-  /**
-   * Constructs an elision filter with a Set of stop words
-   * @deprecated use {@link #ElisionFilter(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  public ElisionFilter(TokenStream input, Set<?> articles) {
-    this(Version.LUCENE_30, input, articles);
-  }
-  
-  /**
    * Constructs an elision filter with a Set of stop words
    * @param matchVersion the lucene backwards compatibility version
    * @param input the source {@link TokenStream}
@@ -103,17 +65,6 @@ public final class ElisionFilter extends TokenFilter {
   }
 
   /**
-   * Constructs an elision filter with an array of stop words
-   * @deprecated use {@link #ElisionFilter(Version, TokenStream, Set)} instead
-   */
-  @Deprecated
-  public ElisionFilter(TokenStream input, String[] articles) {
-    this(Version.LUCENE_CURRENT, input,
-        new CharArraySet(Version.LUCENE_CURRENT,
-            Arrays.asList(articles), true));
-  }
-
-  /**
    * Increments the {@link TokenStream} with a {@link CharTermAttribute} without elisioned start
    */
   @Override
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
index f630eab..836b5cd 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
@@ -69,11 +69,10 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
 
   /**
    * Extended list of typical French stopwords.
-   * @deprecated use {@link #getDefaultStopSet()} instead
+   * @deprecated (3.1) remove in Lucene 5.0 (index bw compat)
    */
-  // TODO make this private in 3.1, remove in 4.0
   @Deprecated
-  public final static String[] FRENCH_STOP_WORDS = {
+  private final static String[] FRENCH_STOP_WORDS = {
     "a", "afin", "ai", "ainsi", "aprs", "attendu", "au", "aujourd", "auquel", "aussi",
     "autre", "autres", "aux", "auxquelles", "auxquels", "avait", "avant", "avec", "avoir",
     "c", "car", "ce", "ceci", "cela", "celle", "celles", "celui", "cependant", "certain",
@@ -104,8 +103,7 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
   /**
    * Contains words that should be indexed but not stemmed.
    */
-  //TODO make this final in 3.0
-  private Set<?> excltable = Collections.<Object>emptySet();
+  private final Set<?> excltable;
 
   /**
    * Returns an unmodifiable instance of the default stop-words set.
@@ -116,7 +114,7 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
   }
   
   private static class DefaultSetHolder {
-    /** @deprecated remove this in Lucene 4.0 */
+    /** @deprecated (3.1) remove this in Lucene 5.0, index bw compat */
     @Deprecated
     static final Set<?> DEFAULT_STOP_SET_30 = CharArraySet
         .unmodifiableSet(new CharArraySet(Version.LUCENE_CURRENT, Arrays.asList(FRENCH_STOP_WORDS),
@@ -171,57 +169,6 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
     this.excltable = CharArraySet.unmodifiableSet(CharArraySet
         .copy(matchVersion, stemExclutionSet));
   }
- 
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @deprecated use {@link #FrenchAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public FrenchAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   * @throws IOException
-   * @deprecated use {@link #FrenchAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public FrenchAnalyzer(Version matchVersion, File stopwords) throws IOException {
-    this(matchVersion, WordlistLoader.getWordSet(stopwords));
-  }
-
-  /**
-   * Builds an exclusionlist from an array of Strings.
-   * @deprecated use {@link #FrenchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(String... exclusionlist) {
-    excltable = StopFilter.makeStopSet(matchVersion, exclusionlist);
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from a Map.
-   * @deprecated use {@link #FrenchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(Map<?,?> exclusionlist) {
-    excltable = new HashSet<Object>(exclusionlist.keySet());
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from the words contained in the given file.
-   * @throws IOException
-   * @deprecated use {@link #FrenchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(File exclusionlist) throws IOException {
-    excltable = new HashSet<Object>(WordlistLoader.getWordSet(exclusionlist));
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
 
   /**
    * Creates
@@ -250,7 +197,7 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
       return new TokenStreamComponents(source, result);
     } else {
       final Tokenizer source = new StandardTokenizer(matchVersion, reader);
-      TokenStream result = new StandardFilter(source);
+      TokenStream result = new StandardFilter(matchVersion, source);
       result = new StopFilter(matchVersion, result, stopwords);
       if(!excltable.isEmpty())
         result = new KeywordMarkerFilter(result, excltable);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
index d048cc1..4110dbe 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchStemFilter.java
@@ -41,9 +41,9 @@ import java.util.Set;
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
  * @see KeywordMarkerFilter
- * @deprecated Use {@link SnowballFilter} with 
+ * @deprecated (3.1) Use {@link SnowballFilter} with 
  * {@link org.tartarus.snowball.ext.FrenchStemmer} instead, which has the
- * same functionality. This filter will be removed in Lucene 4.0
+ * same functionality. This filter will be removed in Lucene 5.0
  */
 @Deprecated
 public final class FrenchStemFilter extends TokenFilter {
@@ -52,7 +52,6 @@ public final class FrenchStemFilter extends TokenFilter {
 	 * The actual token in the input stream.
 	 */
 	private FrenchStemmer stemmer = new FrenchStemmer();
-	private Set<?> exclusions = null;
 	
 	private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
   private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
@@ -61,18 +60,6 @@ public final class FrenchStemFilter extends TokenFilter {
     super(in);
 	}
 
-  /**
-   * 
-   * @param in the {@link TokenStream} to filter
-   * @param exclusiontable a set of terms not to be stemmed
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-   */
-	@Deprecated // TODO remove in 3.2
-	public FrenchStemFilter( TokenStream in, Set<?> exclusiontable ) {
-		this( in );
-		exclusions = exclusiontable;
-	}
-
 	/**
 	 * @return  Returns true for the next token in the stream, or false at EOS
 	 */
@@ -82,7 +69,7 @@ public final class FrenchStemFilter extends TokenFilter {
 	    String term = termAtt.toString();
 
 	    // Check the exclusion table
-	    if ( !keywordAttr.isKeyword() && (exclusions == null || !exclusions.contains( term )) ) {
+	    if (!keywordAttr.isKeyword()) {
 	      String s = stemmer.stem( term );
 	      // If not stemmed, don't waste the time  adjusting the token.
 	      if ((s != null) && !s.equals( term ) )
@@ -101,14 +88,6 @@ public final class FrenchStemFilter extends TokenFilter {
 			this.stemmer = stemmer;
 		}
 	}
-	/**
-	 * Set an alternative exclusion list for this filter.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-	 */
-	@Deprecated // TODO remove in 3.2
-	public void setExclusionTable( Map<?,?> exclusiontable ) {
-		exclusions = exclusiontable.keySet();
-	}
 }
 
 
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
index 558aad2..74d885e 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ASCIIFoldingFilter.java
@@ -54,10 +54,7 @@ import org.apache.lucene.util.RamUsageEstimator;
  *  
  * See: <a href="http://en.wikipedia.org/wiki/Latin_characters_in_Unicode">http://en.wikipedia.org/wiki/Latin_characters_in_Unicode</a>
  *
- * The set of character conversions supported by this class is a superset of
- * those supported by Lucene's {@link ISOLatin1AccentFilter} which strips
- * accents from Latin1 characters.  For example, '&agrave;' will be replaced by
- * 'a'.
+ * For example, '&agrave;' will be replaced by 'a'.
  */
 public final class ASCIIFoldingFilter extends TokenFilter {
   public ASCIIFoldingFilter(TokenStream input)
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ISOLatin1AccentFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ISOLatin1AccentFilter.java
deleted file mode 100644
index 3a14b73..0000000
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/ISOLatin1AccentFilter.java
+++ /dev/null
@@ -1,262 +0,0 @@
-package org.apache.lucene.analysis.miscellaneous;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-/**
- * A filter that replaces accented characters in the ISO Latin 1 character set 
- * (ISO-8859-1) by their unaccented equivalent. The case will not be altered.
- * <p>
- * For instance, '&agrave;' will be replaced by 'a'.
- * <p>
- * 
- * @deprecated If you build a new index, use {@link ASCIIFoldingFilter}
- * which covers a superset of Latin 1.
- * This class is included for use with existing
- * indexes and will be removed in a future release (possibly Lucene 4.0).
- */
-@Deprecated
-public final class ISOLatin1AccentFilter extends TokenFilter {
-  public ISOLatin1AccentFilter(TokenStream input) {
-    super(input);
-  }
-
-  private char[] output = new char[256];
-  private int outputPos;
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    
-  @Override
-  public final boolean incrementToken() throws java.io.IOException {    
-    if (input.incrementToken()) {
-      final char[] buffer = termAtt.buffer();
-      final int length = termAtt.length();
-      // If no characters actually require rewriting then we
-      // just return token as-is:
-      for(int i=0;i<length;i++) {
-        final char c = buffer[i];
-        if (c >= '\u00c0' && c <= '\uFB06') {
-          removeAccents(buffer, length);
-          termAtt.copyBuffer(output, 0, outputPos);
-          break;
-        }
-      }
-      return true;
-    } else
-      return false;
-  }
-
-  /**
-   * To replace accented characters in a String by unaccented equivalents.
-   */
-  public final void removeAccents(char[] input, int length) {
-
-    // Worst-case length required:
-    final int maxSizeNeeded = 2*length;
-
-    int size = output.length;
-    while (size < maxSizeNeeded)
-      size *= 2;
-
-    if (size != output.length)
-      output = new char[size];
-
-    outputPos = 0;
-
-    int pos = 0;
-
-    for (int i=0; i<length; i++, pos++) {
-      final char c = input[pos];
-
-      // Quick test: if it's not in range then just keep
-      // current character
-      if (c < '\u00c0' || c > '\uFB06')
-        output[outputPos++] = c;
-      else {
-        switch (c) {
-        case '\u00C0' : // ?
-        case '\u00C1' : // ?
-        case '\u00C2' : // ?
-        case '\u00C3' : // ?
-        case '\u00C4' : // ?
-        case '\u00C5' : // ?
-          output[outputPos++] = 'A';
-          break;
-        case '\u00C6' : // ?
-          output[outputPos++] = 'A';
-          output[outputPos++] = 'E';
-          break;
-        case '\u00C7' : // ?
-          output[outputPos++] = 'C';
-          break;
-        case '\u00C8' : // ?
-        case '\u00C9' : // ?
-        case '\u00CA' : // ?
-        case '\u00CB' : // ?
-          output[outputPos++] = 'E';
-          break;
-        case '\u00CC' : // ?
-        case '\u00CD' : // ?
-        case '\u00CE' : // ?
-        case '\u00CF' : // ?
-          output[outputPos++] = 'I';
-          break;
-        case '\u0132' : // 
-            output[outputPos++] = 'I';
-            output[outputPos++] = 'J';
-            break;
-        case '\u00D0' : // ?
-          output[outputPos++] = 'D';
-          break;
-        case '\u00D1' : // ?
-          output[outputPos++] = 'N';
-          break;
-        case '\u00D2' : // ?
-        case '\u00D3' : // ?
-        case '\u00D4' : // ?
-        case '\u00D5' : // ?
-        case '\u00D6' : // ?
-        case '\u00D8' : // ?
-          output[outputPos++] = 'O';
-          break;
-        case '\u0152' : // ?
-          output[outputPos++] = 'O';
-          output[outputPos++] = 'E';
-          break;
-        case '\u00DE' : // ?
-          output[outputPos++] = 'T';
-          output[outputPos++] = 'H';
-          break;
-        case '\u00D9' : // ?
-        case '\u00DA' : // ?
-        case '\u00DB' : // ?
-        case '\u00DC' : // ?
-          output[outputPos++] = 'U';
-          break;
-        case '\u00DD' : // ?
-        case '\u0178' : // 
-          output[outputPos++] = 'Y';
-          break;
-        case '\u00E0' : // ?
-        case '\u00E1' : // 
-        case '\u00E2' : // 
-        case '\u00E3' : // 
-        case '\u00E4' : // 
-        case '\u00E5' : // 
-          output[outputPos++] = 'a';
-          break;
-        case '\u00E6' : // 
-          output[outputPos++] = 'a';
-          output[outputPos++] = 'e';
-          break;
-        case '\u00E7' : // 
-          output[outputPos++] = 'c';
-          break;
-        case '\u00E8' : // 
-        case '\u00E9' : // 
-        case '\u00EA' : // 
-        case '\u00EB' : // 
-          output[outputPos++] = 'e';
-          break;
-        case '\u00EC' : // 
-        case '\u00ED' : // 
-        case '\u00EE' : // 
-        case '\u00EF' : // 
-          output[outputPos++] = 'i';
-          break;
-        case '\u0133' : // 
-            output[outputPos++] = 'i';
-            output[outputPos++] = 'j';
-            break;
-        case '\u00F0' : // 
-          output[outputPos++] = 'd';
-          break;
-        case '\u00F1' : // 
-          output[outputPos++] = 'n';
-          break;
-        case '\u00F2' : // 
-        case '\u00F3' : // 
-        case '\u00F4' : // 
-        case '\u00F5' : // 
-        case '\u00F6' : // 
-        case '\u00F8' : // 
-          output[outputPos++] = 'o';
-          break;
-        case '\u0153' : // ?
-          output[outputPos++] = 'o';
-          output[outputPos++] = 'e';
-          break;
-        case '\u00DF' : // ?
-          output[outputPos++] = 's';
-          output[outputPos++] = 's';
-          break;
-        case '\u00FE' : // 
-          output[outputPos++] = 't';
-          output[outputPos++] = 'h';
-          break;
-        case '\u00F9' : // 
-        case '\u00FA' : // 
-        case '\u00FB' : // 
-        case '\u00FC' : // 
-          output[outputPos++] = 'u';
-          break;
-        case '\u00FD' : // 
-        case '\u00FF' : // 
-          output[outputPos++] = 'y';
-          break;
-        case '\uFB00': // ?
-            output[outputPos++] = 'f';
-            output[outputPos++] = 'f';
-            break;
-        case '\uFB01': // ?
-            output[outputPos++] = 'f';
-            output[outputPos++] = 'i';
-            break;
-        case '\uFB02': // ?
-            output[outputPos++] = 'f';
-            output[outputPos++] = 'l';
-            break;
-        // following 2 are commented as they can break the maxSizeNeeded (and doing *3 could be expensive)
-//        case '\uFB03': // ?
-//            output[outputPos++] = 'f';
-//            output[outputPos++] = 'f';
-//            output[outputPos++] = 'i';
-//            break;
-//        case '\uFB04': // ?
-//            output[outputPos++] = 'f';
-//            output[outputPos++] = 'f';
-//            output[outputPos++] = 'l';
-//            break;
-        case '\uFB05': // ?
-            output[outputPos++] = 'f';
-            output[outputPos++] = 't';
-            break;
-        case '\uFB06': // ?
-            output[outputPos++] = 's';
-            output[outputPos++] = 't';
-          break;
-        default :
-          output[outputPos++] = c;
-          break;
-        }
-      }
-    }
-  }
-}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java
index 08794d0..e488fe4 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/KeepWordFilter.java
@@ -17,14 +17,13 @@
 
 package org.apache.lucene.analysis.miscellaneous;
 
+import java.io.IOException;
+
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
 
-import java.io.IOException;
-import java.util.Set;
-
 /**
  * A TokenFilter that only keeps tokens with text contained in the
  * required words.  This filter behaves like the inverse of StopFilter.
@@ -35,12 +34,6 @@ public final class KeepWordFilter extends TokenFilter {
   private final CharArraySet words;
   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
 
-  /** @deprecated Use {@link #KeepWordFilter(TokenStream, CharArraySet)} instead */
-  @Deprecated
-  public KeepWordFilter(TokenStream in, Set<String> words, boolean ignoreCase ) {
-    this(in, new CharArraySet(words, ignoreCase));
-  }
-
   /** The words set passed to this constructor will be directly used by this filter
    * and should not be modified, */
   public KeepWordFilter(TokenStream in, CharArraySet words) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
index 4d17af0..19378da 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/PatternAnalyzer.java
@@ -62,8 +62,7 @@ import org.apache.lucene.util.Version;
  *     pat.tokenStream("content", "James is running round in the woods"), 
  *     "English"));
  * </pre>
- * @deprecated use the pattern-based analysis in the analysis/pattern package instead.
- * This analyzer will be removed in a future release (4.1)
+ * @deprecated (4.0) use the pattern-based analysis in the analysis/pattern package instead.
  */
 @Deprecated
 public final class PatternAnalyzer extends Analyzer {
@@ -146,7 +145,7 @@ public final class PatternAnalyzer extends Analyzer {
   /**
    * Constructs a new instance with the given parameters.
    * 
-   * @param matchVersion If >= {@link Version#LUCENE_29}, StopFilter.enablePositionIncrement is set to true
+   * @param matchVersion currently does nothing
    * @param pattern
    *            a regular expression delimiting tokens
    * @param toLowerCase
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
index 86c98f7..7b6ab94 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter.java
@@ -189,48 +189,6 @@ public final class WordDelimiterFilter extends TokenFilter {
     this.protWords = protWords;
     this.iterator = new WordDelimiterIterator(charTypeTable, splitOnCaseChange != 0, splitOnNumerics != 0, stemEnglishPossessive != 0);
   }
-  
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             CharArraySet protWords) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, 1, null);
-  }
-
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, byte[], int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, 1, null);
-  }
 
   /**
    * @param in Token stream to be filtered.
@@ -259,76 +217,6 @@ public final class WordDelimiterFilter extends TokenFilter {
     this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, stemEnglishPossessive, protWords);
   }
   
-  /**
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal,
-                             int splitOnNumerics,
-                             CharArraySet protWords) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal, splitOnNumerics, 1, protWords);
-  }
-
-  /**   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll,
-                             int splitOnCaseChange,
-                             int preserveOriginal) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, splitOnCaseChange, preserveOriginal);
-  }
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             byte[] charTypeTable,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll) {
-    this(in, charTypeTable, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
-  }
-  /**
-   * Compatibility constructor
-   * 
-   * @deprecated Use
-   *             {@link #WordDelimiterFilter(TokenStream, int, int, int, int, int, int, int, int, int, CharArraySet)}
-   *             instead.
-   */
-  @Deprecated
-  public WordDelimiterFilter(TokenStream in,
-                             int generateWordParts,
-                             int generateNumberParts,
-                             int catenateWords,
-                             int catenateNumbers,
-                             int catenateAll) {
-    this(in, WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, generateWordParts, generateNumberParts, catenateWords, catenateNumbers, catenateAll, 1, 0, 1, null);
-  }
-  
   public boolean incrementToken() throws IOException {
     while (true) {
       if (!hasSavedState) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
index fc2f21b..1bce986 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchAnalyzer.java
@@ -68,12 +68,6 @@ import java.util.Map;
  * dependent settings as {@link StandardAnalyzer}.</p>
  */
 public final class DutchAnalyzer extends ReusableAnalyzerBase {
-  /**
-   * List of typical Dutch stopwords.
-   * @deprecated use {@link #getDefaultStopSet()} instead
-   */
-  @Deprecated
-  public final static String[] DUTCH_STOP_WORDS = getDefaultStopSet().toArray(new String[0]);
   
   /** File containing default Dutch stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "dutch_stop.txt";
@@ -139,84 +133,6 @@ public final class DutchAnalyzer extends ReusableAnalyzerBase {
   }
 
   /**
-   * Builds an analyzer with the given stop words.
-   *
-   * @param matchVersion
-   * @param stopwords
-   * @deprecated use {@link #DutchAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public DutchAnalyzer(Version matchVersion, String... stopwords) {
-    this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   *
-   * @param stopwords
-   * @deprecated use {@link #DutchAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public DutchAnalyzer(Version matchVersion, HashSet<?> stopwords) {
-    this(matchVersion, (Set<?>)stopwords);
-  }
-
-  /**
-   * Builds an analyzer with the given stop words.
-   *
-   * @param stopwords
-   * @deprecated use {@link #DutchAnalyzer(Version, Set)} instead
-   */
-  @Deprecated
-  public DutchAnalyzer(Version matchVersion, File stopwords) {
-    // this is completely broken!
-    try {
-      stoptable = org.apache.lucene.analysis.util.WordlistLoader.getWordSet(stopwords);
-    } catch (IOException e) {
-      // TODO: throw IOException
-      throw new RuntimeException(e);
-    }
-    this.matchVersion = matchVersion;
-  }
-
-  /**
-   * Builds an exclusionlist from an array of Strings.
-   *
-   * @param exclusionlist
-   * @deprecated use {@link #DutchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(String... exclusionlist) {
-    excltable = StopFilter.makeStopSet(matchVersion, exclusionlist);
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from a Hashtable.
-   * @deprecated use {@link #DutchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(HashSet<?> exclusionlist) {
-    excltable = exclusionlist;
-    setPreviousTokenStream(null); // force a new stemmer to be created
-  }
-
-  /**
-   * Builds an exclusionlist from the words contained in the given file.
-   * @deprecated use {@link #DutchAnalyzer(Version, Set, Set)} instead
-   */
-  @Deprecated
-  public void setStemExclusionTable(File exclusionlist) {
-    try {
-      excltable = org.apache.lucene.analysis.util.WordlistLoader.getWordSet(exclusionlist);
-      setPreviousTokenStream(null); // force a new stemmer to be created
-    } catch (IOException e) {
-      // TODO: throw IOException
-      throw new RuntimeException(e);
-    }
-  }
-
-  /**
    * Reads a stemdictionary file , that overrules the stemming algorithm
    * This is a textfile that contains per line
    * <tt>word<b>\t</b>stem</tt>, i.e: two tab seperated words
@@ -257,7 +173,7 @@ public final class DutchAnalyzer extends ReusableAnalyzerBase {
       return new TokenStreamComponents(source, result);
     } else {
       final Tokenizer source = new StandardTokenizer(matchVersion, aReader);
-      TokenStream result = new StandardFilter(source);
+      TokenStream result = new StandardFilter(matchVersion, source);
       result = new StopFilter(matchVersion, result, stoptable);
       if (!excltable.isEmpty())
         result = new KeywordMarkerFilter(result, excltable);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
index 1b9d0d0..252ce9e 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemFilter.java
@@ -19,9 +19,7 @@ package org.apache.lucene.analysis.nl;
 
 import java.io.IOException;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.Map;
-import java.util.Set;
 
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter; // for javadoc
 import org.apache.lucene.analysis.TokenFilter;
@@ -43,9 +41,9 @@ import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
  * the {@link KeywordAttribute} before this {@link TokenStream}.
  * </p>
  * @see KeywordMarkerFilter
- * @deprecated Use {@link SnowballFilter} with 
+ * @deprecated (3.1) Use {@link SnowballFilter} with 
  * {@link org.tartarus.snowball.ext.DutchStemmer} instead, which has the
- * same functionality. This filter will be removed in Lucene 4.0
+ * same functionality. This filter will be removed in Lucene 5.0
  */
 @Deprecated
 public final class DutchStemFilter extends TokenFilter {
@@ -53,7 +51,6 @@ public final class DutchStemFilter extends TokenFilter {
    * The actual token in the input stream.
    */
   private DutchStemmer stemmer = new DutchStemmer();
-  private Set<?> exclusions = null;
   
   private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
   private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
@@ -63,16 +60,6 @@ public final class DutchStemFilter extends TokenFilter {
   }
 
   /**
-   * Builds a DutchStemFilter that uses an exclusion table.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-   */
-  @Deprecated
-  public DutchStemFilter(TokenStream _in, Set<?> exclusiontable) {
-    this(_in);
-    exclusions = exclusiontable;
-  }
-  
-  /**
    * @param stemdictionary Dictionary of word stem pairs, that overrule the algorithm
    */
   public DutchStemFilter(TokenStream _in,  Map<?,?> stemdictionary) {
@@ -81,16 +68,6 @@ public final class DutchStemFilter extends TokenFilter {
   }
 
   /**
-   * @param stemdictionary Dictionary of word stem pairs, that overrule the algorithm
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-   */
-  @Deprecated
-  public DutchStemFilter(TokenStream _in, Set<?> exclusiontable, Map<?,?> stemdictionary) {
-    this(_in, exclusiontable);
-    stemmer.setStemDictionary(stemdictionary);
-  }
-
-  /**
    * Returns the next token in the stream, or null at EOS
    */
   @Override
@@ -99,7 +76,7 @@ public final class DutchStemFilter extends TokenFilter {
       final String term = termAtt.toString();
 
       // Check the exclusion table.
-      if (!keywordAttr.isKeyword() && (exclusions == null || !exclusions.contains(term))) {
+      if (!keywordAttr.isKeyword()) {
         final String s = stemmer.stem(term);
         // If not stemmed, don't waste the time adjusting the token.
         if ((s != null) && !s.equals(term))
@@ -121,15 +98,6 @@ public final class DutchStemFilter extends TokenFilter {
   }
 
   /**
-   * Set an alternative exclusion list for this filter.
-   * @deprecated use {@link KeywordAttribute} with {@link KeywordMarkerFilter} instead.
-   */
-  @Deprecated
-  public void setExclusionTable(HashSet<?> exclusiontable) {
-    exclusions = exclusiontable;
-  }
-
-  /**
    * Set dictionary for stemming, this dictionary overrules the algorithm,
    * so you can correct for a particular unwanted word-stem pair.
    */
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
index 2af381f..d146fe6 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/nl/DutchStemmer.java
@@ -26,8 +26,8 @@ import java.util.Map;
  * the <a href="http://snowball.tartarus.org/algorithms/dutch/stemmer.html">dutch stemming</a>
  * algorithm in Martin Porter's snowball project.
  * </p>
- * @deprecated Use {@link org.tartarus.snowball.ext.DutchStemmer} instead, 
- * which has the same functionality. This filter will be removed in Lucene 4.0
+ * @deprecated (3.1) Use {@link org.tartarus.snowball.ext.DutchStemmer} instead, 
+ * which has the same functionality. This filter will be removed in Lucene 5.0
  */
 @Deprecated
 public class DutchStemmer {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/payloads/IdentityEncoder.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/payloads/IdentityEncoder.java
index 0f30443..f143dda 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/payloads/IdentityEncoder.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/payloads/IdentityEncoder.java
@@ -28,23 +28,15 @@ import java.nio.charset.Charset;
  *
  **/
 public class IdentityEncoder extends AbstractEncoder implements PayloadEncoder{
-
   protected Charset charset = Charset.forName("UTF-8");
   
-  /** @deprecated This field is no longer used. Use {@link #charset} instead. */
-  @Deprecated
-  protected String charsetName = charset.name();
-
   public IdentityEncoder() {
   }
 
   public IdentityEncoder(Charset charset) {
     this.charset = charset;
-    // @deprecated, remove this in 4.0:
-    charsetName = charset.name();
   }
 
-
   public Payload encode(char[] buffer, int offset, int length) {
     final ByteBuffer bb = charset.encode(CharBuffer.wrap(buffer, offset, length));
     if (bb.hasArray()) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
index 7f67d0a..bcf7545 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/reverse/ReverseStringFilter.java
@@ -74,40 +74,6 @@ public final class ReverseStringFilter extends TokenFilter {
    * The reversed tokens will not be marked. 
    * </p>
    * 
-   * @param in {@link TokenStream} to filter
-   * @deprecated use {@link #ReverseStringFilter(Version, TokenStream)} 
-   *    instead. This constructor will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public ReverseStringFilter(TokenStream in) {
-    this(in, NOMARKER);
-  }
-  
-  /**
-   * Create a new ReverseStringFilter that reverses and marks all tokens in the
-   * supplied {@link TokenStream}.
-   * <p>
-   * The reversed tokens will be prepended (marked) by the <code>marker</code>
-   * character.
-   * </p>
-   * 
-   * @param in {@link TokenStream} to filter
-   * @param marker A character used to mark reversed tokens
-   * @deprecated use {@link #ReverseStringFilter(Version, TokenStream, char)} 
-   *    instead. This constructor will be removed in Lucene 4.0 
-   */
-  @Deprecated
-  public ReverseStringFilter(TokenStream in, char marker) {
-    this(Version.LUCENE_30, in, marker);
-  }
-  
-  /**
-   * Create a new ReverseStringFilter that reverses all tokens in the 
-   * supplied {@link TokenStream}.
-   * <p>
-   * The reversed tokens will not be marked. 
-   * </p>
-   * 
    * @param matchVersion See <a href="#version">above</a>
    * @param in {@link TokenStream} to filter
    */
@@ -153,19 +119,6 @@ public final class ReverseStringFilter extends TokenFilter {
   /**
    * Reverses the given input string
    * 
-   * @param input the string to reverse
-   * @return the given input string in reversed order
-   * @deprecated use {@link #reverse(Version, String)} instead. This method 
-   *    will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static String reverse( final String input ){
-    return reverse(Version.LUCENE_30, input);
-  }
-  
-  /**
-   * Reverses the given input string
-   * 
    * @param matchVersion See <a href="#version">above</a>
    * @param input the string to reverse
    * @return the given input string in reversed order
@@ -178,17 +131,6 @@ public final class ReverseStringFilter extends TokenFilter {
   
   /**
    * Reverses the given input buffer in-place
-   * @param buffer the input char array to reverse
-   * @deprecated use {@link #reverse(Version, char[])} instead. This 
-   *    method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static void reverse( final char[] buffer ){
-    reverse( buffer, 0, buffer.length );
-  }
-  
-  /**
-   * Reverses the given input buffer in-place
    * @param matchVersion See <a href="#version">above</a>
    * @param buffer the input char array to reverse
    */
@@ -199,20 +141,6 @@ public final class ReverseStringFilter extends TokenFilter {
   /**
    * Partially reverses the given input buffer in-place from offset 0
    * up to the given length.
-   * @param buffer the input char array to reverse
-   * @param len the length in the buffer up to where the
-   *        buffer should be reversed
-   * @deprecated use {@link #reverse(Version, char[], int)} instead. This 
-   *    method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static void reverse( final char[] buffer, final int len ){
-    reverse( buffer, 0, len );
-  }
-  
-  /**
-   * Partially reverses the given input buffer in-place from offset 0
-   * up to the given length.
    * @param matchVersion See <a href="#version">above</a>
    * @param buffer the input char array to reverse
    * @param len the length in the buffer up to where the
@@ -224,22 +152,7 @@ public final class ReverseStringFilter extends TokenFilter {
   }
   
   /**
-   * Partially reverses the given input buffer in-place from the given offset
-   * up to the given length.
-   * @param buffer the input char array to reverse
-   * @param start the offset from where to reverse the buffer
-   * @param len the length in the buffer up to where the
-   *        buffer should be reversed
-   * @deprecated use {@link #reverse(Version, char[], int, int)} instead. This 
-   *    method will be removed in Lucene 4.0
-   */
-  @Deprecated
-  public static void reverse(char[] buffer, int start, int len ) {
-    reverseUnicode3(buffer, start, len);
-  }
-  
-  /**
-   * @deprecated Remove this when support for 3.0 indexes is no longer needed.
+   * @deprecated (3.1) Remove this when support for 3.0 indexes is no longer needed.
    */
   @Deprecated
   private static void reverseUnicode3( char[] buffer, int start, int len ){
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
index cec8e36..64854a0 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianAnalyzer.java
@@ -20,7 +20,6 @@ package org.apache.lucene.analysis.ru;
 import java.io.IOException;
 import java.io.Reader;
 import java.util.Arrays;
-import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -56,7 +55,7 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase
 {
     /**
      * List of typical Russian stopwords. (for backwards compatibility)
-     * @deprecated Remove this for LUCENE 4.0
+     * @deprecated (3.1) Remove this for LUCENE 5.0
      */
     @Deprecated
     private static final String[] RUSSIAN_STOP_WORDS_30 = {
@@ -76,7 +75,7 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase
     public final static String DEFAULT_STOPWORD_FILE = "russian_stop.txt";
     
     private static class DefaultSetHolder {
-      /** @deprecated remove this for Lucene 4.0 */
+      /** @deprecated (3.1) remove this for Lucene 5.0 */
       @Deprecated
       static final Set<?> DEFAULT_STOP_SET_30 = CharArraySet
           .unmodifiableSet(new CharArraySet(Version.LUCENE_CURRENT, 
@@ -113,15 +112,6 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase
     }
   
     /**
-     * Builds an analyzer with the given stop words.
-     * @deprecated use {@link #RussianAnalyzer(Version, Set)} instead
-     */
-    @Deprecated
-    public RussianAnalyzer(Version matchVersion, String... stopwords) {
-      this(matchVersion, StopFilter.makeStopSet(matchVersion, stopwords));
-    }
-    
-    /**
      * Builds an analyzer with the given stop words
      * 
      * @param matchVersion
@@ -147,18 +137,6 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase
       this.stemExclusionSet = CharArraySet.unmodifiableSet(CharArraySet.copy(matchVersion, stemExclusionSet));
     }
    
-   
-    /**
-     * Builds an analyzer with the given stop words.
-     * TODO: create a Set version of this ctor
-     * @deprecated use {@link #RussianAnalyzer(Version, Set)} instead
-     */
-    @Deprecated
-    public RussianAnalyzer(Version matchVersion, Map<?,?> stopwords)
-    {
-      this(matchVersion, stopwords.keySet());
-    }
-
   /**
    * Creates
    * {@link org.apache.lucene.analysis.util.ReusableAnalyzerBase.TokenStreamComponents}
@@ -188,7 +166,8 @@ public final class RussianAnalyzer extends StopwordAnalyzerBase
         result = new StopFilter(matchVersion, result, stopwords);
         if (!stemExclusionSet.isEmpty()) result = new KeywordMarkerFilter(
           result, stemExclusionSet);
-        return new TokenStreamComponents(source, new RussianStemFilter(result));
+        result = new SnowballFilter(result, new org.tartarus.snowball.ext.RussianStemmer());
+        return new TokenStreamComponents(source, result);
       }
     }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizer.java
index 1a244e4..e5426d7 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLetterTokenizer.java
@@ -37,8 +37,8 @@ import org.apache.lucene.util.Version;
  * detect token characters. See {@link CharTokenizer#isTokenChar(int)} and
  * {@link CharTokenizer#normalize(int)} for details.</li>
  * </ul>
- * @deprecated Use {@link StandardTokenizer} instead, which has the same functionality.
- * This filter will be removed in Lucene 4.0 
+ * @deprecated (3.1) Use {@link StandardTokenizer} instead, which has the same functionality.
+ * This filter will be removed in Lucene 5.0 
  */
 @Deprecated
 public class RussianLetterTokenizer extends CharTokenizer
@@ -86,42 +86,7 @@ public class RussianLetterTokenizer extends CharTokenizer
       super(matchVersion, factory, in);
     }
     
-    /**
-     * Construct a new RussianLetterTokenizer.
-     * 
-     * @deprecated use {@link #RussianLetterTokenizer(Version, Reader)} instead. This will
-     *             be removed in Lucene 4.0.
-     */
-    @Deprecated
-    public RussianLetterTokenizer(Reader in) {
-      super(in);
-    }
-
-    /**
-     * Construct a new RussianLetterTokenizer using a given {@link AttributeSource}.
-     * 
-     * @deprecated use {@link #RussianLetterTokenizer(Version, AttributeSource, Reader)}
-     *             instead. This will be removed in Lucene 4.0.
-     */
-    @Deprecated
-    public RussianLetterTokenizer(AttributeSource source, Reader in) {
-      super(source, in);
-    }
-
-    /**
-     * Construct a new RussianLetterTokenizer using a given
-     * {@link org.apache.lucene.util.AttributeSource.AttributeFactory}.
-     * 
-     * @deprecated use {@link #RussianLetterTokenizer(Version, AttributeSource.AttributeFactory, Reader)}
-     *             instead. This will be removed in Lucene 4.0.
-     */
-    @Deprecated
-    public RussianLetterTokenizer(AttributeFactory factory, Reader in) {
-      super(factory, in);
-    }
-    
-    
-    /**
+     /**
      * Collects only characters which satisfy
      * {@link Character#isLetter(int)}.
      */
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java
deleted file mode 100644
index 86f3e2b..0000000
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianLowerCaseFilter.java
+++ /dev/null
@@ -1,57 +0,0 @@
-package org.apache.lucene.analysis.ru;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-
-/**
- * Normalizes token text to lower case.
- * @deprecated Use {@link LowerCaseFilter} instead, which has the same
- *  functionality. This filter will be removed in Lucene 4.0
- */
-@Deprecated
-public final class RussianLowerCaseFilter extends TokenFilter
-{
-    private CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-   
-    public RussianLowerCaseFilter(TokenStream in)
-    {
-        super(in);
-    }
-
-    @Override
-    public final boolean incrementToken() throws IOException
-    {
-      if (input.incrementToken()) {
-        char[] chArray = termAtt.buffer();
-        int chLen = termAtt.length();
-        for (int i = 0; i < chLen; i++)
-        {
-          chArray[i] = Character.toLowerCase(chArray[i]);
-        }
-        return true;
-      } else {
-        return false;
-      }
-    }
-}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
deleted file mode 100644
index 7e62e02..0000000
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemFilter.java
+++ /dev/null
@@ -1,93 +0,0 @@
-package org.apache.lucene.analysis.ru;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter; // for javadoc
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.ru.RussianStemmer;//javadoc @link
-import org.apache.lucene.analysis.snowball.SnowballFilter; // javadoc @link
-
-import java.io.IOException;
-
-/**
- * A {@link TokenFilter} that stems Russian words. 
- * <p>
- * The implementation was inspired by GermanStemFilter.
- * The input should be filtered by {@link LowerCaseFilter} before passing it to RussianStemFilter ,
- * because RussianStemFilter only works with lowercase characters.
- * </p>
- * <p>
- * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
- * the {@link KeywordAttribute} before this {@link TokenStream}.
- * </p>
- * @see KeywordMarkerFilter
- * @deprecated Use {@link SnowballFilter} with 
- * {@link org.tartarus.snowball.ext.RussianStemmer} instead, which has the
- * same functionality. This filter will be removed in Lucene 4.0
- */
-@Deprecated
-public final class RussianStemFilter extends TokenFilter
-{
-    /**
-     * The actual token in the input stream.
-     */
-    private RussianStemmer stemmer = new RussianStemmer();
-
-    private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-    private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
-
-    public RussianStemFilter(TokenStream in)
-    {
-        super(in);
-    }
-    /**
-     * Returns the next token in the stream, or null at EOS
-     */
-    @Override
-    public final boolean incrementToken() throws IOException
-    {
-      if (input.incrementToken()) {
-        if(!keywordAttr.isKeyword()) {
-          final String term = termAtt.toString();
-          final String s = stemmer.stem(term);
-          if (s != null && !s.equals(term))
-            termAtt.setEmpty().append(s);
-        }
-        return true;
-      } else {
-        return false;
-      }
-    }
-
-
-    /**
-     * Set a alternative/custom {@link RussianStemmer} for this filter.
-     */
-    public void setStemmer(RussianStemmer stemmer)
-    {
-        if (stemmer != null)
-        {
-            this.stemmer = stemmer;
-        }
-    }
-}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
deleted file mode 100644
index fea9e21..0000000
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ru/RussianStemmer.java
+++ /dev/null
@@ -1,600 +0,0 @@
-package org.apache.lucene.analysis.ru;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Russian stemming algorithm implementation (see http://snowball.sourceforge.net for detailed description).
- * @deprecated Use {@link org.tartarus.snowball.ext.RussianStemmer} instead, 
- * which has the same functionality. This filter will be removed in Lucene 4.0
- */
-@Deprecated
-class RussianStemmer
-{
-    // positions of RV, R1 and R2 respectively
-    private int RV, /*R1,*/ R2;
-
-    // letters (currently unused letters are commented out)
-    private final static char A = '\u0430';
-    //private final static char B = '\u0431';
-    private final static char V = '\u0432';
-    private final static char G = '\u0433';
-    //private final static char D = '\u0434';
-    private final static char E = '\u0435';
-    //private final static char ZH = '\u0436';
-    //private final static char Z = '\u0437';
-    private final static char I = '\u0438';
-    private final static char I_ = '\u0439';
-    //private final static char K = '\u043A';
-    private final static char L = '\u043B';
-    private final static char M = '\u043C';
-    private final static char N = '\u043D';
-    private final static char O = '\u043E';
-    //private final static char P = '\u043F';
-    //private final static char R = '\u0440';
-    private final static char S = '\u0441';
-    private final static char T = '\u0442';
-    private final static char U = '\u0443';
-    //private final static char F = '\u0444';
-    private final static char X = '\u0445';
-    //private final static char TS = '\u0446';
-    //private final static char CH = '\u0447';
-    private final static char SH = '\u0448';
-    private final static char SHCH = '\u0449';
-    //private final static char HARD = '\u044A';
-    private final static char Y = '\u044B';
-    private final static char SOFT = '\u044C';
-    private final static char AE = '\u044D';
-    private final static char IU = '\u044E';
-    private final static char IA = '\u044F';
-
-    // stem definitions
-    private static char[] vowels = { A, E, I, O, U, Y, AE, IU, IA };
-
-    private static char[][] perfectiveGerundEndings1 = {
-        { V },
-        { V, SH, I },
-        { V, SH, I, S, SOFT }
-    };
-
-    private static char[][] perfectiveGerund1Predessors = {
-        { A },
-        { IA }
-    };
-
-    private static char[][] perfectiveGerundEndings2 = { { I, V }, {
-        Y, V }, {
-            I, V, SH, I }, {
-                Y, V, SH, I }, {
-                    I, V, SH, I, S, SOFT }, {
-                        Y, V, SH, I, S, SOFT }
-    };
-
-    private static char[][] adjectiveEndings = {
-        { E, E },
-        { I, E },
-        { Y, E },
-        { O, E },
-        { E, I_ },
-        { I, I_ },
-        { Y, I_ },
-        { O, I_ },
-        { E, M },
-        { I, M },
-        { Y, M },
-        { O, M },
-        { I, X },
-        { Y, X },
-        { U, IU },
-        { IU, IU },
-        { A, IA },
-        { IA, IA },
-        { O, IU },
-        { E, IU },
-        { I, M, I },
-        { Y, M, I },
-        { E, G, O },
-        { O, G, O },
-        { E, M, U },
-        {O, M, U }
-    };
-
-    private static char[][] participleEndings1 = {
-        { SHCH },
-        { E, M },
-        { N, N },
-        { V, SH },
-        { IU, SHCH }
-    };
-
-    private static char[][] participleEndings2 = {
-        { I, V, SH },
-        { Y, V, SH },
-        { U, IU, SHCH }
-    };
-
-    private static char[][] participle1Predessors = {
-        { A },
-        { IA }
-    };
-
-    private static char[][] reflexiveEndings = {
-        { S, IA },
-        { S, SOFT }
-    };
-
-    private static char[][] verbEndings1 = {
-        { I_ },
-        { L },
-        { N },
-        { L, O },
-        { N, O },
-        { E, T },
-        { IU, T },
-        { L, A },
-        { N, A },
-        { L, I },
-        { E, M },
-        { N, Y },
-        { E, T, E },
-        { I_, T, E },
-        { T, SOFT },
-        { E, SH, SOFT },
-        { N, N, O }
-    };
-
-    private static char[][] verbEndings2 = {
-        { IU },
-        { U, IU },
-        { E, N },
-        { E, I_ },
-        { IA, T },
-        { U, I_ },
-        { I, L },
-        { Y, L },
-        { I, M },
-        { Y, M },
-        { I, T },
-        { Y, T },
-        { I, L, A },
-        { Y, L, A },
-        { E, N, A },
-        { I, T, E },
-        { I, L, I },
-        { Y, L, I },
-        { I, L, O },
-        { Y, L, O },
-        { E, N, O },
-        { U, E, T },
-        { U, IU, T },
-        { E, N, Y },
-        { I, T, SOFT },
-        { Y, T, SOFT },
-        { I, SH, SOFT },
-        { E, I_, T, E },
-        { U, I_, T, E }
-    };
-
-    private static char[][] verb1Predessors = {
-        { A },
-        { IA }
-    };
-
-    private static char[][] nounEndings = {
-        { A },
-        { U },
-        { I_ },
-        { O },
-        { U },
-        { E },
-        { Y },
-        { I },
-        { SOFT },
-        { IA },
-        { E, V },
-        { O, V },
-        { I, E },
-        { SOFT, E },
-        { IA, X },
-        { I, IU },
-        { E, I },
-        { I, I },
-        { E, I_ },
-        { O, I_ },
-        { E, M },
-        { A, M },
-        { O, M },
-        { A, X },
-        { SOFT, IU },
-        { I, IA },
-        { SOFT, IA },
-        { I, I_ },
-        { IA, M },
-        { IA, M, I },
-        { A, M, I },
-        { I, E, I_ },
-        { I, IA, M },
-        { I, E, M },
-        { I, IA, X },
-        { I, IA, M, I }
-    };
-
-    private static char[][] superlativeEndings = {
-        { E, I_, SH },
-        { E, I_, SH, E }
-    };
-
-    private static char[][] derivationalEndings = {
-        { O, S, T },
-        { O, S, T, SOFT }
-    };
-
-    /**
-     * RussianStemmer constructor comment.
-     */
-    public RussianStemmer()
-    {
-        super();
-    }
-
-    /**
-     * Adjectival ending is an adjective ending,
-     * optionally preceded by participle ending.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean adjectival(StringBuilder stemmingZone)
-    {
-        // look for adjective ending in a stemming zone
-        if (!findAndRemoveEnding(stemmingZone, adjectiveEndings))
-            return false;
-        // if adjective ending was found, try for participle ending.
-        if (!findAndRemoveEnding(stemmingZone, participleEndings1, participle1Predessors))
-            findAndRemoveEnding(stemmingZone, participleEndings2);
-        return true;
-    }
-
-    /**
-     * Derivational endings
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean derivational(StringBuilder stemmingZone)
-    {
-        int endingLength = findEnding(stemmingZone, derivationalEndings);
-        if (endingLength == 0)
-             // no derivational ending found
-            return false;
-        else
-        {
-            // Ensure that the ending locates in R2
-            if (R2 - RV <= stemmingZone.length() - endingLength)
-            {
-                stemmingZone.setLength(stemmingZone.length() - endingLength);
-                return true;
-            }
-            else
-            {
-                return false;
-            }
-        }
-    }
-
-    /**
-     * Finds ending among given ending class and returns the length of ending found(0, if not found).
-     * Creation date: (17/03/2002 8:18:34 PM)
-     */
-    private int findEnding(StringBuilder stemmingZone, int startIndex, char[][] theEndingClass)
-    {
-        boolean match = false;
-        for (int i = theEndingClass.length - 1; i >= 0; i--)
-        {
-            char[] theEnding = theEndingClass[i];
-            // check if the ending is bigger than stemming zone
-            if (startIndex < theEnding.length - 1)
-            {
-                match = false;
-                continue;
-            }
-            match = true;
-            int stemmingIndex = startIndex;
-            for (int j = theEnding.length - 1; j >= 0; j--)
-            {
-                if (stemmingZone.charAt(stemmingIndex--) != theEnding[j])
-                {
-                    match = false;
-                    break;
-                }
-            }
-            // check if ending was found
-            if (match)
-            {
-                return theEndingClass[i].length; // cut ending
-            }
-        }
-        return 0;
-    }
-
-    private int findEnding(StringBuilder stemmingZone, char[][] theEndingClass)
-    {
-        return findEnding(stemmingZone, stemmingZone.length() - 1, theEndingClass);
-    }
-
-    /**
-     * Finds the ending among the given class of endings and removes it from stemming zone.
-     * Creation date: (17/03/2002 8:18:34 PM)
-     */
-    private boolean findAndRemoveEnding(StringBuilder stemmingZone, char[][] theEndingClass)
-    {
-        int endingLength = findEnding(stemmingZone, theEndingClass);
-        if (endingLength == 0)
-            // not found
-            return false;
-        else {
-            stemmingZone.setLength(stemmingZone.length() - endingLength);
-            // cut the ending found
-            return true;
-        }
-    }
-
-    /**
-     * Finds the ending among the given class of endings, then checks if this ending was
-     * preceded by any of given predecessors, and if so, removes it from stemming zone.
-     * Creation date: (17/03/2002 8:18:34 PM)
-     */
-    private boolean findAndRemoveEnding(StringBuilder stemmingZone,
-        char[][] theEndingClass, char[][] thePredessors)
-    {
-        int endingLength = findEnding(stemmingZone, theEndingClass);
-        if (endingLength == 0)
-            // not found
-            return false;
-        else
-        {
-            int predessorLength =
-                findEnding(stemmingZone,
-                    stemmingZone.length() - endingLength - 1,
-                    thePredessors);
-            if (predessorLength == 0)
-                return false;
-            else {
-                stemmingZone.setLength(stemmingZone.length() - endingLength);
-                // cut the ending found
-                return true;
-            }
-        }
-
-    }
-
-    /**
-     * Marks positions of RV, R1 and R2 in a given word.
-     * Creation date: (16/03/2002 3:40:11 PM)
-     */
-    private void markPositions(String word)
-    {
-        RV = 0;
-//        R1 = 0;
-        R2 = 0;
-        int i = 0;
-        // find RV
-        while (word.length() > i && !isVowel(word.charAt(i)))
-        {
-            i++;
-        }
-        if (word.length() - 1 < ++i)
-            return; // RV zone is empty
-        RV = i;
-        // find R1
-        while (word.length() > i && isVowel(word.charAt(i)))
-        {
-            i++;
-        }
-        if (word.length() - 1 < ++i)
-            return; // R1 zone is empty
-//        R1 = i;
-        // find R2
-        while (word.length() > i && !isVowel(word.charAt(i)))
-        {
-            i++;
-        }
-        if (word.length() - 1 < ++i)
-            return; // R2 zone is empty
-        while (word.length() > i && isVowel(word.charAt(i)))
-        {
-            i++;
-        }
-        if (word.length() - 1 < ++i)
-            return; // R2 zone is empty
-        R2 = i;
-    }
-
-    /**
-     * Checks if character is a vowel..
-     * Creation date: (16/03/2002 10:47:03 PM)
-     * @return boolean
-     * @param letter char
-     */
-    private boolean isVowel(char letter)
-    {
-        for (int i = 0; i < vowels.length; i++)
-        {
-            if (letter == vowels[i])
-                return true;
-        }
-        return false;
-    }
-
-    /**
-     * Noun endings.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean noun(StringBuilder stemmingZone)
-    {
-        return findAndRemoveEnding(stemmingZone, nounEndings);
-    }
-
-    /**
-     * Perfective gerund endings.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean perfectiveGerund(StringBuilder stemmingZone)
-    {
-        return findAndRemoveEnding(
-            stemmingZone,
-            perfectiveGerundEndings1,
-            perfectiveGerund1Predessors)
-            || findAndRemoveEnding(stemmingZone, perfectiveGerundEndings2);
-    }
-
-    /**
-     * Reflexive endings.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean reflexive(StringBuilder stemmingZone)
-    {
-        return findAndRemoveEnding(stemmingZone, reflexiveEndings);
-    }
-
-    /**
-     * Insert the method's description here.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean removeI(StringBuilder stemmingZone)
-    {
-        if (stemmingZone.length() > 0
-            && stemmingZone.charAt(stemmingZone.length() - 1) == I)
-        {
-            stemmingZone.setLength(stemmingZone.length() - 1);
-            return true;
-        }
-        else
-        {
-            return false;
-        }
-    }
-
-    /**
-     * Insert the method's description here.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean removeSoft(StringBuilder stemmingZone)
-    {
-        if (stemmingZone.length() > 0
-            && stemmingZone.charAt(stemmingZone.length() - 1) == SOFT)
-        {
-            stemmingZone.setLength(stemmingZone.length() - 1);
-            return true;
-        }
-        else
-        {
-            return false;
-        }
-    }
-
-    /**
-     * Finds the stem for given Russian word.
-     * Creation date: (16/03/2002 3:36:48 PM)
-     * @return java.lang.String
-     * @param input java.lang.String
-     */
-    public String stem(String input)
-    {
-        markPositions(input);
-        if (RV == 0)
-            return input; //RV wasn't detected, nothing to stem
-        StringBuilder stemmingZone = new StringBuilder(input.substring(RV));
-        // stemming goes on in RV
-        // Step 1
-
-        if (!perfectiveGerund(stemmingZone))
-        {
-            reflexive(stemmingZone);
-            if (!adjectival(stemmingZone))
-              if (!verb(stemmingZone))
-                noun(stemmingZone);
-        }
-        // Step 2
-        removeI(stemmingZone);
-        // Step 3
-        derivational(stemmingZone);
-        // Step 4
-        superlative(stemmingZone);
-        undoubleN(stemmingZone);
-        removeSoft(stemmingZone);
-        // return result
-        return input.substring(0, RV) + stemmingZone.toString();
-    }
-
-    /**
-     * Superlative endings.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean superlative(StringBuilder stemmingZone)
-    {
-        return findAndRemoveEnding(stemmingZone, superlativeEndings);
-    }
-
-    /**
-     * Undoubles N.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean undoubleN(StringBuilder stemmingZone)
-    {
-        char[][] doubleN = {
-            { N, N }
-        };
-        if (findEnding(stemmingZone, doubleN) != 0)
-        {
-            stemmingZone.setLength(stemmingZone.length() - 1);
-            return true;
-        }
-        else
-        {
-            return false;
-        }
-    }
-
-    /**
-     * Verb endings.
-     * Creation date: (17/03/2002 12:14:58 AM)
-     * @param stemmingZone java.lang.StringBuilder
-     */
-    private boolean verb(StringBuilder stemmingZone)
-    {
-        return findAndRemoveEnding(
-            stemmingZone,
-            verbEndings1,
-            verb1Predessors)
-            || findAndRemoveEnding(stemmingZone, verbEndings2);
-    }
-   
-    /**
-     * Static method for stemming.
-     */
-    public static String stemWord(String theWord)
-    {
-        RussianStemmer stemmer = new RussianStemmer();
-        return stemmer.stem(theWord);
-    }
-}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
index 17b34ce..0bd7b09 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/snowball/SnowballAnalyzer.java
@@ -24,9 +24,9 @@ import org.apache.lucene.analysis.en.EnglishPossessiveFilter;
 import org.apache.lucene.analysis.standard.*;
 import org.apache.lucene.analysis.tr.TurkishLowerCaseFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
 import org.apache.lucene.util.Version;
 
-import java.io.IOException;
 import java.io.Reader;
 import java.util.Set;
 
@@ -43,11 +43,11 @@ import java.util.Set;
  *   <li> As of 3.1, uses {@link TurkishLowerCaseFilter} for Turkish language.
  * </ul>
  * </p>
- * @deprecated Use the language-specific analyzer in modules/analysis instead. 
- * This analyzer will be removed in Lucene 4.0
+ * @deprecated (3.1) Use the language-specific analyzer in modules/analysis instead. 
+ * This analyzer will be removed in Lucene 5.0
  */
 @Deprecated
-public final class SnowballAnalyzer extends Analyzer {
+public final class SnowballAnalyzer extends ReusableAnalyzerBase {
   private String name;
   private Set<?> stopSet;
   private final Version matchVersion;
@@ -58,16 +58,6 @@ public final class SnowballAnalyzer extends Analyzer {
     this.matchVersion = matchVersion;
   }
 
-  /** 
-   * Builds the named analyzer with the given stop words.
-   * @deprecated Use {@link #SnowballAnalyzer(Version, String, Set)} instead.  
-   */
-  @Deprecated
-  public SnowballAnalyzer(Version matchVersion, String name, String[] stopWords) {
-    this(matchVersion, name);
-    stopSet = StopFilter.makeStopSet(matchVersion, stopWords);
-  }
-  
   /** Builds the named analyzer with the given stop words. */
   public SnowballAnalyzer(Version matchVersion, String name, Set<?> stopWords) {
     this(matchVersion, name);
@@ -79,9 +69,9 @@ public final class SnowballAnalyzer extends Analyzer {
       StandardFilter}, a {@link LowerCaseFilter}, a {@link StopFilter},
       and a {@link SnowballFilter} */
   @Override
-  public TokenStream tokenStream(String fieldName, Reader reader) {
-    TokenStream result = new StandardTokenizer(matchVersion, reader);
-    result = new StandardFilter(matchVersion, result);
+  public TokenStreamComponents createComponents(String fieldName, Reader reader) {
+    Tokenizer tokenizer = new StandardTokenizer(matchVersion, reader);
+    TokenStream result = new StandardFilter(matchVersion, tokenizer);
     // remove the possessive 's for english stemmers
     if (matchVersion.onOrAfter(Version.LUCENE_31) && 
         (name.equals("English") || name.equals("Porter") || name.equals("Lovins")))
@@ -95,38 +85,6 @@ public final class SnowballAnalyzer extends Analyzer {
       result = new StopFilter(matchVersion,
                               result, stopSet);
     result = new SnowballFilter(result, name);
-    return result;
-  }
-  
-  private class SavedStreams {
-    Tokenizer source;
-    TokenStream result;
-  }
-  
-  /** Returns a (possibly reused) {@link StandardTokenizer} filtered by a 
-   * {@link StandardFilter}, a {@link LowerCaseFilter}, 
-   * a {@link StopFilter}, and a {@link SnowballFilter} */
-  @Override
-  public TokenStream reusableTokenStream(String fieldName, Reader reader)
-      throws IOException {
-    SavedStreams streams = (SavedStreams) getPreviousTokenStream();
-    if (streams == null) {
-      streams = new SavedStreams();
-      streams.source = new StandardTokenizer(matchVersion, reader);
-      streams.result = new StandardFilter(matchVersion, streams.source);
-      // Use a special lowercase filter for turkish, the stemmer expects it.
-      if (matchVersion.onOrAfter(Version.LUCENE_31) && name.equals("Turkish"))
-        streams.result = new TurkishLowerCaseFilter(streams.result);
-      else
-        streams.result = new LowerCaseFilter(matchVersion, streams.result);
-      if (stopSet != null)
-        streams.result = new StopFilter(matchVersion,
-                                        streams.result, stopSet);
-      streams.result = new SnowballFilter(streams.result, name);
-      setPreviousTokenStream(streams);
-    } else {
-      streams.source.reset(reader);
-    }
-    return streams.result;
+    return new TokenStreamComponents(tokenizer, result);
   }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
index bff61b7..c856b52 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
@@ -58,12 +58,6 @@ public final class ClassicAnalyzer extends StopwordAnalyzerBase {
 
   private int maxTokenLength = DEFAULT_MAX_TOKEN_LENGTH;
 
-  /**
-   * Specifies whether deprecated acronyms should be replaced with HOST type.
-   * See {@linkplain "https://issues.apache.org/jira/browse/LUCENE-1068"}
-   */
-  private final boolean replaceInvalidAcronym;
-
   /** An unmodifiable set containing some common English words that are usually not
   useful for searching. */
   public static final Set<?> STOP_WORDS_SET = StopAnalyzer.ENGLISH_STOP_WORDS_SET; 
@@ -74,7 +68,6 @@ public final class ClassicAnalyzer extends StopwordAnalyzerBase {
    * @param stopWords stop words */
   public ClassicAnalyzer(Version matchVersion, Set<?> stopWords) {
     super(matchVersion, stopWords);
-    replaceInvalidAcronym = matchVersion.onOrAfter(Version.LUCENE_24);
   }
 
   /** Builds an analyzer with the default stop words ({@link
@@ -125,7 +118,6 @@ public final class ClassicAnalyzer extends StopwordAnalyzerBase {
   protected TokenStreamComponents createComponents(final String fieldName, final Reader reader) {
     final ClassicTokenizer src = new ClassicTokenizer(matchVersion, reader);
     src.setMaxTokenLength(maxTokenLength);
-    src.setReplaceInvalidAcronym(replaceInvalidAcronym);
     TokenStream tok = new ClassicFilter(src);
     tok = new LowerCaseFilter(matchVersion, tok);
     tok = new StopFilter(matchVersion, tok, stopwords);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
index eb4c993..9c768cd 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizer.java
@@ -44,14 +44,6 @@ import org.apache.lucene.util.Version;
  * not suit your application, please consider copying this source code
  * directory to your project and maintaining your own grammar-based tokenizer.
  *
- * <a name="version"/>
- * <p>You must specify the required {@link Version}
- * compatibility when creating ClassicAnalyzer:
- * <ul>
- *   <li> As of 2.4, Tokens incorrectly identified as acronyms
- *        are corrected (see <a href="https://issues.apache.org/jira/browse/LUCENE-1068">LUCENE-1608</a>
- * </ul>
- * 
  * ClassicTokenizer was named StandardTokenizer in Lucene versions prior to 3.1.
  * As of 3.1, {@link StandardTokenizer} implements Unicode text segmentation,
  * as specified by UAX#29.
@@ -70,13 +62,8 @@ public final class ClassicTokenizer extends Tokenizer {
   public static final int NUM               = 6;
   public static final int CJ                = 7;
 
-  /**
-   * @deprecated this solves a bug where HOSTs that end with '.' are identified
-   *             as ACRONYMs.
-   */
-  @Deprecated
   public static final int ACRONYM_DEP       = 8;
-  
+
   /** String token types that correspond to token type int constants */
   public static final String [] TOKEN_TYPES = new String [] {
     "<ALPHANUM>",
@@ -90,8 +77,6 @@ public final class ClassicTokenizer extends Tokenizer {
     "<ACRONYM_DEP>"
   };
 
-  private boolean replaceInvalidAcronym;
-    
   private int maxTokenLength = StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH;
 
   /** Set the max allowed token length.  Any token longer
@@ -134,15 +119,9 @@ public final class ClassicTokenizer extends Tokenizer {
     init(input, matchVersion);
   }
 
-  private final void init(Reader input, Version matchVersion) {
+  private void init(Reader input, Version matchVersion) {
     this.scanner = new ClassicTokenizerImpl(input);
-
-    if (matchVersion.onOrAfter(Version.LUCENE_24)) {
-      replaceInvalidAcronym = true;
-    } else {
-      replaceInvalidAcronym = false;
-    }
-    this.input = input;    
+    this.input = input;
   }
 
   // this tokenizer generates three attributes:
@@ -174,16 +153,10 @@ public final class ClassicTokenizer extends Tokenizer {
         scanner.getText(termAtt);
         final int start = scanner.yychar();
         offsetAtt.setOffset(correctOffset(start), correctOffset(start+termAtt.length()));
-        // This 'if' should be removed in the next release. For now, it converts
-        // invalid acronyms to HOST. When removed, only the 'else' part should
-        // remain.
+
         if (tokenType == ClassicTokenizer.ACRONYM_DEP) {
-          if (replaceInvalidAcronym) {
-            typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[ClassicTokenizer.HOST]);
-            termAtt.setLength(termAtt.length() - 1); // remove extra '.'
-          } else {
-            typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[ClassicTokenizer.ACRONYM]);
-          }
+          typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[ClassicTokenizer.HOST]);
+          termAtt.setLength(termAtt.length() - 1); // remove extra '.'
         } else {
           typeAtt.setType(ClassicTokenizer.TOKEN_TYPES[tokenType]);
         }
@@ -207,28 +180,4 @@ public final class ClassicTokenizer extends Tokenizer {
     super.reset(reader);
     scanner.yyreset(reader);
   }
-
-  /**
-   * Prior to https://issues.apache.org/jira/browse/LUCENE-1068, ClassicTokenizer mischaracterized as acronyms tokens like www.abc.com
-   * when they should have been labeled as hosts instead.
-   * @return true if ClassicTokenizer now returns these tokens as Hosts, otherwise false
-   *
-   * @deprecated Remove in 3.X and make true the only valid value
-   */
-  @Deprecated
-  public boolean isReplaceInvalidAcronym() {
-    return replaceInvalidAcronym;
-  }
-
-  /**
-   *
-   * @param replaceInvalidAcronym Set to true to replace mischaracterized acronyms as HOST.
-   * @deprecated Remove in 3.X and make true the only valid value
-   *
-   * See https://issues.apache.org/jira/browse/LUCENE-1068
-   */
-  @Deprecated
-  public void setReplaceInvalidAcronym(boolean replaceInvalidAcronym) {
-    this.replaceInvalidAcronym = replaceInvalidAcronym;
-  }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java
index c1fa941..18d1b7b 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.java
@@ -355,11 +355,6 @@ public static final int EMAIL             = StandardTokenizer.EMAIL;
 public static final int HOST              = StandardTokenizer.HOST;
 public static final int NUM               = StandardTokenizer.NUM;
 public static final int CJ                = StandardTokenizer.CJ;
-/**
- * @deprecated this solves a bug where HOSTs that end with '.' are identified
- *             as ACRONYMs.
- */
-@Deprecated
 public static final int ACRONYM_DEP       = StandardTokenizer.ACRONYM_DEP;
 
 public static final String [] TOKEN_TYPES = StandardTokenizer.TOKEN_TYPES;
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex
index 037b71a..ce2bf05 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicTokenizerImpl.jflex
@@ -47,11 +47,6 @@ public static final int EMAIL             = StandardTokenizer.EMAIL;
 public static final int HOST              = StandardTokenizer.HOST;
 public static final int NUM               = StandardTokenizer.NUM;
 public static final int CJ                = StandardTokenizer.CJ;
-/**
- * @deprecated this solves a bug where HOSTs that end with '.' are identified
- *             as ACRONYMs.
- */
-@Deprecated
 public static final int ACRONYM_DEP       = StandardTokenizer.ACRONYM_DEP;
 
 public static final String [] TOKEN_TYPES = StandardTokenizer.TOKEN_TYPES;
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index 4a030fd..d028720 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -56,12 +56,6 @@ public final class StandardAnalyzer extends StopwordAnalyzerBase {
 
   private int maxTokenLength = DEFAULT_MAX_TOKEN_LENGTH;
 
-  /**
-   * Specifies whether deprecated acronyms should be replaced with HOST type.
-   * See {@linkplain "https://issues.apache.org/jira/browse/LUCENE-1068"}
-   */
-  private final boolean replaceInvalidAcronym;
-
   /** An unmodifiable set containing some common English words that are usually not
   useful for searching. */
   public static final Set<?> STOP_WORDS_SET = StopAnalyzer.ENGLISH_STOP_WORDS_SET; 
@@ -72,7 +66,6 @@ public final class StandardAnalyzer extends StopwordAnalyzerBase {
    * @param stopWords stop words */
   public StandardAnalyzer(Version matchVersion, Set<?> stopWords) {
     super(matchVersion, stopWords);
-    replaceInvalidAcronym = matchVersion.onOrAfter(Version.LUCENE_24);
   }
 
   /** Builds an analyzer with the default stop words ({@link
@@ -123,7 +116,6 @@ public final class StandardAnalyzer extends StopwordAnalyzerBase {
   protected TokenStreamComponents createComponents(final String fieldName, final Reader reader) {
     final StandardTokenizer src = new StandardTokenizer(matchVersion, reader);
     src.setMaxTokenLength(maxTokenLength);
-    src.setReplaceInvalidAcronym(replaceInvalidAcronym);
     TokenStream tok = new StandardFilter(matchVersion, src);
     tok = new LowerCaseFilter(matchVersion, tok);
     tok = new StopFilter(matchVersion, tok, stopwords);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
index 7eeb87c..8771466 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardFilter.java
@@ -31,12 +31,6 @@ import org.apache.lucene.util.Version;
 public class StandardFilter extends TokenFilter {
   private final Version matchVersion;
   
-  /** @deprecated Use {@link #StandardFilter(Version, TokenStream)} instead. */
-  @Deprecated
-  public StandardFilter(TokenStream in) {
-    this(Version.LUCENE_30, in);
-  }
-  
   public StandardFilter(Version matchVersion, TokenStream in) {
     super(in);
     this.matchVersion = matchVersion;
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
index d487b26..9370de7 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardTokenizer.java
@@ -17,6 +17,9 @@
 
 package org.apache.lucene.analysis.standard;
 
+import java.io.IOException;
+import java.io.Reader;
+
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
@@ -25,9 +28,6 @@ import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.Version;
 
-import java.io.IOException;
-import java.io.Reader;
-
 /** A grammar-based tokenizer constructed with JFlex.
  * <p>
  * As of Lucene version 3.1, this class implements the Word Break rules from the
@@ -61,28 +61,25 @@ public final class StandardTokenizer extends Tokenizer {
   private StandardTokenizerInterface scanner;
 
   public static final int ALPHANUM          = 0;
-  /** @deprecated */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int APOSTROPHE        = 1;
-  /** @deprecated */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int ACRONYM           = 2;
-  /** @deprecated */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int COMPANY           = 3;
   public static final int EMAIL             = 4;
-  /** @deprecated */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int HOST              = 5;
   public static final int NUM               = 6;
-  /** @deprecated */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int CJ                = 7;
 
-  /**
-   * @deprecated this solves a bug where HOSTs that end with '.' are identified
-   *             as ACRONYMs.
-   */
+  /** @deprecated (3.1) */
   @Deprecated
   public static final int ACRONYM_DEP       = 8;
 
@@ -108,8 +105,6 @@ public final class StandardTokenizer extends Tokenizer {
     "<HIRAGANA>"
   };
 
-  private boolean replaceInvalidAcronym;
-    
   private int maxTokenLength = StandardAnalyzer.DEFAULT_MAX_TOKEN_LENGTH;
 
   /** Set the max allowed token length.  Any token longer
@@ -155,12 +150,7 @@ public final class StandardTokenizer extends Tokenizer {
   private final void init(Reader input, Version matchVersion) {
     this.scanner = matchVersion.onOrAfter(Version.LUCENE_31) ?
       new StandardTokenizerImpl(input) : new ClassicTokenizerImpl(input);
-    if (matchVersion.onOrAfter(Version.LUCENE_24)) {
-      replaceInvalidAcronym = true;
-    } else {
-      replaceInvalidAcronym = false;
-    }
-    this.input = input;    
+    this.input = input;
   }
 
   // this tokenizer generates three attributes:
@@ -196,12 +186,8 @@ public final class StandardTokenizer extends Tokenizer {
         // invalid acronyms to HOST. When removed, only the 'else' part should
         // remain.
         if (tokenType == StandardTokenizer.ACRONYM_DEP) {
-          if (replaceInvalidAcronym) {
-            typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.HOST]);
-            termAtt.setLength(termAtt.length() - 1); // remove extra '.'
-          } else {
-            typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.ACRONYM]);
-          }
+          typeAtt.setType(StandardTokenizer.TOKEN_TYPES[StandardTokenizer.HOST]);
+          termAtt.setLength(termAtt.length() - 1); // remove extra '.'
         } else {
           typeAtt.setType(StandardTokenizer.TOKEN_TYPES[tokenType]);
         }
@@ -225,28 +211,4 @@ public final class StandardTokenizer extends Tokenizer {
     super.reset(reader);
     scanner.yyreset(reader);
   }
-
-  /**
-   * Prior to https://issues.apache.org/jira/browse/LUCENE-1068, StandardTokenizer mischaracterized as acronyms tokens like www.abc.com
-   * when they should have been labeled as hosts instead.
-   * @return true if StandardTokenizer now returns these tokens as Hosts, otherwise false
-   *
-   * @deprecated Remove in 3.X and make true the only valid value
-   */
-  @Deprecated
-  public boolean isReplaceInvalidAcronym() {
-    return replaceInvalidAcronym;
-  }
-
-  /**
-   *
-   * @param replaceInvalidAcronym Set to true to replace mischaracterized acronyms as HOST.
-   * @deprecated Remove in 3.X and make true the only valid value
-   *
-   * See https://issues.apache.org/jira/browse/LUCENE-1068
-   */
-  @Deprecated
-  public void setReplaceInvalidAcronym(boolean replaceInvalidAcronym) {
-    this.replaceInvalidAcronym = replaceInvalidAcronym;
-  }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
index 1defd70..ea8ba38 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/synonym/SynonymMap.java
@@ -53,9 +53,9 @@ public class SynonymMap {
     SynonymMap currMap = this;
     for (String str : singleMatch) {
       if (currMap.submap==null) {
-        // for now hardcode at 2.9, as its what the old code did.
+        // for now hardcode at 4.0, as its what the old code did.
         // would be nice to fix, but shouldn't store a version in each submap!!!
-        currMap.submap = new CharArrayMap<SynonymMap>(Version.LUCENE_29, 1, ignoreCase());
+        currMap.submap = new CharArrayMap<SynonymMap>(Version.LUCENE_40, 1, ignoreCase());
       }
 
       SynonymMap map = currMap.submap.get(str);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
index 2f6caf9..8f0935c 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiWordFilter.java
@@ -17,17 +17,17 @@ package org.apache.lucene.analysis.th;
  */
 
 import java.io.IOException;
-import java.util.Locale;
 import java.lang.Character.UnicodeBlock;
-import javax.swing.text.Segment;
 import java.text.BreakIterator;
+import java.util.Locale;
+import javax.swing.text.Segment;
 
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.Version;
 
@@ -69,14 +69,6 @@ public final class ThaiWordFilter extends TokenFilter {
   private OffsetAttribute clonedOffsetAtt = null;
   private boolean hasMoreTokensInClone = false;
 
-  /** Creates a new ThaiWordFilter that also lowercases non-thai text.
-   * @deprecated Use the ctor with {@code matchVersion} instead!
-   */
-  @Deprecated
-  public ThaiWordFilter(TokenStream input) {
-    this(Version.LUCENE_30, input);
-  }
-  
   /** Creates a new ThaiWordFilter with the specified match version. */
   public ThaiWordFilter(Version matchVersion, TokenStream input) {
     super(matchVersion.onOrAfter(Version.LUCENE_31) ?
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/util/CharArraySet.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/util/CharArraySet.java
index 9c0260d..25dd6b5 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/util/CharArraySet.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/util/CharArraySet.java
@@ -51,8 +51,7 @@ import org.apache.lucene.util.Version;
  * that has a string representation. The add methods will use
  * {@link Object#toString} and store the result using a {@code char[]}
  * buffer. The same behavior have the {@code contains()} methods.
- * The {@link #iterator()} returns an {@code Iterator<String>}.
- * For type safety also {@link #stringIterator()} is provided.
+ * The {@link #iterator()} returns an {@code Iterator<char[]>}.
  */
 public class CharArraySet extends AbstractSet<Object> {
   public static final CharArraySet EMPTY_SET = new CharArraySet(CharArrayMap.<Object>emptyMap());
@@ -93,37 +92,6 @@ public class CharArraySet extends AbstractSet<Object> {
     addAll(c);
   }
 
-  /**
-   * Creates a set with enough capacity to hold startSize terms
-   * 
-   * @param startSize
-   *          the initial capacity
-   * @param ignoreCase
-   *          <code>false</code> if and only if the set should be case sensitive
-   *          otherwise <code>true</code>.
-   * @deprecated use {@link #CharArraySet(Version, int, boolean)} instead
-   */
-  @Deprecated
-  public CharArraySet(int startSize, boolean ignoreCase) {
-    this(Version.LUCENE_30, startSize, ignoreCase);
-  }
-  
-  /**
-   * Creates a set from a Collection of objects. 
-   * 
-   * @param c
-   *          a collection whose elements to be placed into the set
-   * @param ignoreCase
-   *          <code>false</code> if and only if the set should be case sensitive
-   *          otherwise <code>true</code>.
-   * @deprecated use {@link #CharArraySet(Version, Collection, boolean)} instead         
-   */  
-  @Deprecated
-  public CharArraySet(Collection<?> c, boolean ignoreCase) {
-    this(Version.LUCENE_30, c.size(), ignoreCase);
-    addAll(c);
-  }
-  
   /** Create set from the specified map (internal only), used also by {@link CharArrayMap#keySet()} */
   CharArraySet(final CharArrayMap<Object> map){
     this.map = map;
@@ -202,24 +170,6 @@ public class CharArraySet extends AbstractSet<Object> {
   /**
    * Returns a copy of the given set as a {@link CharArraySet}. If the given set
    * is a {@link CharArraySet} the ignoreCase property will be preserved.
-   * 
-   * @param set
-   *          a set to copy
-   * @return a copy of the given set as a {@link CharArraySet}. If the given set
-   *         is a {@link CharArraySet} the ignoreCase and matchVersion property will be
-   *         preserved.
-   * @deprecated use {@link #copy(Version, Set)} instead.
-   */
-  @Deprecated
-  public static CharArraySet copy(final Set<?> set) {
-    if(set == EMPTY_SET)
-      return EMPTY_SET;
-    return copy(Version.LUCENE_30, set);
-  }
-  
-  /**
-   * Returns a copy of the given set as a {@link CharArraySet}. If the given set
-   * is a {@link CharArraySet} the ignoreCase property will be preserved.
    * <p>
    * <b>Note:</b> If you intend to create a copy of another {@link CharArraySet} where
    * the {@link Version} of the source set differs from its copy
@@ -248,68 +198,13 @@ public class CharArraySet extends AbstractSet<Object> {
     return new CharArraySet(matchVersion, set, false);
   }
   
-  /** The Iterator<String> for this set.  Strings are constructed on the fly, so
-   * use <code>nextCharArray</code> for more efficient access.
-   * @deprecated Use the standard iterator, which returns {@code char[]} instances.
-   */
-  @Deprecated
-  public class CharArraySetIterator implements Iterator<String> {
-    int pos=-1;
-    char[] next;
-    private CharArraySetIterator() {
-      goNext();
-    }
-
-    private void goNext() {
-      next = null;
-      pos++;
-      while (pos < map.keys.length && (next=map.keys[pos]) == null) pos++;
-    }
-
-    public boolean hasNext() {
-      return next != null;
-    }
-
-    /** do not modify the returned char[] */
-    public char[] nextCharArray() {
-      char[] ret = next;
-      goNext();
-      return ret;
-    }
-
-    /** Returns the next String, as a Set<String> would...
-     * use nextCharArray() for better efficiency. */
-    public String next() {
-      return new String(nextCharArray());
-    }
-
-    public void remove() {
-      throw new UnsupportedOperationException();
-    }
-  }
-
-  /** returns an iterator of new allocated Strings (an instance of {@link CharArraySetIterator}).
-   * @deprecated Use {@link #iterator}, which returns {@code char[]} instances.
-   */
-  @Deprecated
-  public Iterator<String> stringIterator() {
-    return new CharArraySetIterator();
-  }
-
-  /** Returns an {@link Iterator} depending on the version used:
-   * <ul>
-   * <li>if {@code matchVersion} &ge; 3.1, it returns {@code char[]} instances in this set.</li>
-   * <li>if {@code matchVersion} is 3.0 or older, it returns new
-   * allocated Strings, so this method violates the Set interface.
-   * It is kept this way for backwards compatibility, normally it should
-   * return {@code char[]} on {@code next()}</li>
-   * </ul>
+  /**
+   * Returns an {@link Iterator} for {@code char[]} instances in this set.
    */
   @Override @SuppressWarnings("unchecked")
   public Iterator<Object> iterator() {
     // use the AbstractSet#keySet()'s iterator (to not produce endless recursion)
-    return map.matchVersion.onOrAfter(Version.LUCENE_31) ?
-      map.originalKeySet().iterator() : (Iterator) stringIterator();
+    return map.originalKeySet().iterator();
   }
   
   @Override
diff --git a/modules/analysis/common/src/java/org/tartarus/snowball/SnowballProgram.java b/modules/analysis/common/src/java/org/tartarus/snowball/SnowballProgram.java
index 0aaa1de..bca16c6 100644
--- a/modules/analysis/common/src/java/org/tartarus/snowball/SnowballProgram.java
+++ b/modules/analysis/common/src/java/org/tartarus/snowball/SnowballProgram.java
@@ -239,13 +239,6 @@ public abstract class SnowballProgram {
 	return true;
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected boolean eq_s(int s_size, String s)
-    {
-	return eq_s(s_size, (CharSequence)s);
-    }
-
     protected boolean eq_s_b(int s_size, CharSequence s)
     {
 	if (cursor - limit_backward < s_size) return false;
@@ -257,35 +250,15 @@ public abstract class SnowballProgram {
 	return true;
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected boolean eq_s_b(int s_size, String s)
-    {
-	return eq_s_b(s_size, (CharSequence)s);
-    }
-
     protected boolean eq_v(CharSequence s)
     {
 	return eq_s(s.length(), s);
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected boolean eq_v(StringBuilder s)
-    {
-	return eq_s(s.length(), (CharSequence)s);
-    }
-
     protected boolean eq_v_b(CharSequence s)
     {   return eq_s_b(s.length(), s);
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected boolean eq_v_b(StringBuilder s)
-    {   return eq_s_b(s.length(), (CharSequence)s);
-    }
-
     protected int find_among(Among v[], int v_size)
     {
 	int i = 0;
@@ -456,12 +429,6 @@ public abstract class SnowballProgram {
 	return adjustment;
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected int replace_s(int c_bra, int c_ket, String s) {
-	return replace_s(c_bra, c_ket, (CharSequence)s);
-    }
-
     protected void slice_check()
     {
 	if (bra < 0 ||
@@ -484,20 +451,6 @@ public abstract class SnowballProgram {
 	replace_s(bra, ket, s);
     }
  
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected void slice_from(String s)
-    {
-	slice_from((CharSequence)s);
-    }
-
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected void slice_from(StringBuilder s)
-    {
-	slice_from((CharSequence)s);
-    }
-
     protected void slice_del()
     {
 	slice_from((CharSequence)"");
@@ -510,20 +463,6 @@ public abstract class SnowballProgram {
 	if (c_bra <= ket) ket += adjustment;
     }
 
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected void insert(int c_bra, int c_ket, String s)
-    {
-	insert(c_bra, c_ket, (CharSequence)s);
-    }
-
-    /** @deprecated for binary back compat. Will be removed in Lucene 4.0 */
-    @Deprecated
-    protected void insert(int c_bra, int c_ket, StringBuilder s)
-    {
-	insert(c_bra, c_ket, (CharSequence)s);
-    }
-
     /* Copy the slice into the supplied StringBuffer */
     protected StringBuilder slice_to(StringBuilder s)
     {
diff --git a/modules/analysis/common/src/resources/org/apache/lucene/analysis/cjk/stopwords.txt b/modules/analysis/common/src/resources/org/apache/lucene/analysis/cjk/stopwords.txt
new file mode 100644
index 0000000..fbf8017
--- /dev/null
+++ b/modules/analysis/common/src/resources/org/apache/lucene/analysis/cjk/stopwords.txt
@@ -0,0 +1,35 @@
+a
+and
+are
+as
+at
+be
+but
+by
+for
+if
+in
+into
+is
+it
+no
+not
+of
+on
+or
+s
+such
+t
+that
+the
+their
+then
+there
+these
+they
+this
+to
+was
+will
+with
+www
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
index 1bdebea..b21e35f 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/br/TestBrazilianStemmer.java
@@ -19,9 +19,10 @@ package org.apache.lucene.analysis.br;
 
 import java.io.IOException;
 import java.io.StringReader;
+import java.util.Collections;
 
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.core.LowerCaseTokenizer;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.util.CharArraySet;
@@ -135,19 +136,10 @@ public class TestBrazilianStemmer extends BaseTokenStreamTestCase {
   }
  
   public void testStemExclusionTable() throws Exception {
-    BrazilianAnalyzer a = new BrazilianAnalyzer(TEST_VERSION_CURRENT);
-    a.setStemExclusionTable(new String[] { "quintessncia" });
+    BrazilianAnalyzer a = new BrazilianAnalyzer(TEST_VERSION_CURRENT, Collections.emptySet(), asSet("quintessncia"));
     checkReuse(a, "quintessncia", "quintessncia"); // excluded words will be completely unchanged.
   }
   
-  public void testStemExclusionTableBWCompat() throws IOException {
-    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set.add("Braslia");
-    BrazilianStemFilter filter = new BrazilianStemFilter(
-        new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader("Braslia Brasilia")), set);
-    assertTokenStreamContents(filter, new String[] { "braslia", "brasil" });
-  }
-
   public void testWithKeywordAttribute() throws IOException {
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("Braslia");
@@ -157,28 +149,6 @@ public class TestBrazilianStemmer extends BaseTokenStreamTestCase {
     assertTokenStreamContents(filter, new String[] { "braslia", "brasil" });
   }
 
-  public void testWithKeywordAttributeAndExclusionTable() throws IOException {
-    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set.add("Braslia");
-    CharArraySet set1 = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set1.add("Brasilia");
-    BrazilianStemFilter filter = new BrazilianStemFilter(
-        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
-            "Braslia Brasilia")), set), set1);
-    assertTokenStreamContents(filter, new String[] { "braslia", "brasilia" });
-  }
-  
-  /* 
-   * Test that changes to the exclusion table are applied immediately
-   * when using reusable token streams.
-   */
-  public void testExclusionTableReuse() throws Exception {
-    BrazilianAnalyzer a = new BrazilianAnalyzer(TEST_VERSION_CURRENT);
-    checkReuse(a, "quintessncia", "quintessente");
-    a.setStemExclusionTable(new String[] { "quintessncia" });
-    checkReuse(a, "quintessncia", "quintessncia");
-  }
-  
   private void check(final String input, final String expected) throws Exception {
     checkOneTerm(new BrazilianAnalyzer(TEST_VERSION_CURRENT), input, expected);
   }
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
index 769db62..9a81436 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/commongrams/CommonGramsFilterTest.java
@@ -18,6 +18,7 @@ package org.apache.lucene.analysis.commongrams;
 
 import java.io.Reader;
 import java.io.StringReader;
+import java.util.Arrays;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
@@ -26,18 +27,20 @@ import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.util.CharArraySet;
 
 /**
  * Tests CommonGrams(Query)Filter
  */
 public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
-  private static final String[] commonWords = { "s", "a", "b", "c", "d", "the",
-      "of" };
+  private static final CharArraySet commonWords = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(
+      "s", "a", "b", "c", "d", "the", "of"
+  ), false);
   
   public void testReset() throws Exception {
     final String input = "How the s a brown s cow d like A B thing?";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     
     CharTermAttribute term = cgf.addAttribute(CharTermAttribute.class);
     assertTrue(cgf.incrementToken());
@@ -58,7 +61,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testQueryReset() throws Exception {
     final String input = "How the s a brown s cow d like A B thing?";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     CommonGramsQueryFilter nsf = new CommonGramsQueryFilter(cgf);
     
     CharTermAttribute term = wt.addAttribute(CharTermAttribute.class);
@@ -88,7 +91,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
     Analyzer a = new Analyzer() {    
       @Override
       public TokenStream tokenStream(String field, Reader in) {
-        return new CommonGramsQueryFilter(new CommonGramsFilter(
+        return new CommonGramsQueryFilter(new CommonGramsFilter(TEST_VERSION_CURRENT,
             new WhitespaceTokenizer(TEST_VERSION_CURRENT, in), commonWords));
       } 
     };
@@ -157,7 +160,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
     Analyzer a = new Analyzer() {    
       @Override
       public TokenStream tokenStream(String field, Reader in) {
-        return new CommonGramsFilter(
+        return new CommonGramsFilter(TEST_VERSION_CURRENT,
             new WhitespaceTokenizer(TEST_VERSION_CURRENT, in), commonWords);
       } 
     };
@@ -245,8 +248,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testCaseSensitive() throws Exception {
     final String input = "How The s a brown s cow d like A B thing?";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    Set common = CommonGramsFilter.makeCommonSet(commonWords);
-    TokenFilter cgf = new CommonGramsFilter(wt, common, false);
+    TokenFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     assertTokenStreamContents(cgf, new String[] {"How", "The", "The_s", "s",
         "s_a", "a", "a_brown", "brown", "brown_s", "s", "s_cow", "cow",
         "cow_d", "d", "d_like", "like", "A", "B", "thing?"});
@@ -258,7 +260,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testLastWordisStopWord() throws Exception {
     final String input = "dog the";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     TokenFilter nsf = new CommonGramsQueryFilter(cgf);
     assertTokenStreamContents(nsf, new String[] { "dog_the" });
   }
@@ -269,7 +271,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testFirstWordisStopWord() throws Exception {
     final String input = "the dog";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     TokenFilter nsf = new CommonGramsQueryFilter(cgf);
     assertTokenStreamContents(nsf, new String[] { "the_dog" });
   }
@@ -280,7 +282,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testOneWordQueryStopWord() throws Exception {
     final String input = "the";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     TokenFilter nsf = new CommonGramsQueryFilter(cgf);
     assertTokenStreamContents(nsf, new String[] { "the" });
   }
@@ -291,7 +293,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void testOneWordQuery() throws Exception {
     final String input = "monster";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     TokenFilter nsf = new CommonGramsQueryFilter(cgf);
     assertTokenStreamContents(nsf, new String[] { "monster" });
   }
@@ -302,7 +304,7 @@ public class CommonGramsFilterTest extends BaseTokenStreamTestCase {
   public void TestFirstAndLastStopWord() throws Exception {
     final String input = "the of";
     WhitespaceTokenizer wt = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    CommonGramsFilter cgf = new CommonGramsFilter(wt, commonWords);
+    CommonGramsFilter cgf = new CommonGramsFilter(TEST_VERSION_CURRENT, wt, commonWords);
     TokenFilter nsf = new CommonGramsQueryFilter(cgf);
     assertTokenStreamContents(nsf, new String[] { "the_of" });
   }
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestAnalyzers.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestAnalyzers.java
index 5976fbd..6f3b862 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestAnalyzers.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestAnalyzers.java
@@ -18,22 +18,16 @@ package org.apache.lucene.analysis.core;
  */
 
 import java.io.IOException;
-import java.io.StringReader;
 import java.io.Reader;
+import java.io.StringReader;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.core.LowerCaseTokenizer;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.core.SimpleAnalyzer;
-import org.apache.lucene.analysis.core.StopAnalyzer;
-import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.index.Payload;
 import org.apache.lucene.util.Version;
 
@@ -137,20 +131,6 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
   }
   
   /**
-   * @deprecated remove this when lucene 3.0 "broken unicode 4" support
-   * is no longer needed.
-   */
-  @Deprecated
-  private static class LowerCaseWhitespaceAnalyzerBWComp extends Analyzer {
-
-    @Override
-    public TokenStream tokenStream(String fieldName, Reader reader) {
-      return new LowerCaseFilter(new WhitespaceTokenizer(reader));
-    }
-    
-  }
-  
-  /**
    * Test that LowercaseFilter handles entire unicode range correctly
    */
   public void testLowerCaseFilter() throws IOException {
@@ -196,30 +176,6 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
     
   }
   
-  /**
-   * Test that LowercaseFilter only works on BMP for back compat,
-   * depending upon version
-   * @deprecated remove this test when lucene 3.0 "broken unicode 4" support
-   * is no longer needed.
-   */
-  @Deprecated
-  public void testLowerCaseFilterBWComp() throws IOException {
-    Analyzer a = new LowerCaseWhitespaceAnalyzerBWComp();
-    // BMP
-    assertAnalyzesTo(a, "AbaCaDabA", new String[] { "abacadaba" });
-    // supplementary, no-op
-    assertAnalyzesTo(a, "\ud801\udc16\ud801\udc16\ud801\udc16\ud801\udc16",
-        new String[] {"\ud801\udc16\ud801\udc16\ud801\udc16\ud801\udc16"});
-    assertAnalyzesTo(a, "AbaCa\ud801\udc16DabA",
-        new String[] { "abaca\ud801\udc16daba" });
-    // unpaired lead surrogate
-    assertAnalyzesTo(a, "AbaC\uD801AdaBa", 
-        new String [] { "abac\uD801adaba" });
-    // unpaired trail surrogate
-    assertAnalyzesTo(a, "AbaC\uDC16AdaBa", 
-        new String [] { "abac\uDC16adaba" });
-  }
-  
   public void testLowerCaseTokenizer() throws IOException {
     StringReader reader = new StringReader("Tokenizer \ud801\udc1ctest");
     LowerCaseTokenizer tokenizer = new LowerCaseTokenizer(TEST_VERSION_CURRENT,
@@ -228,6 +184,7 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
         "\ud801\udc44test" });
   }
 
+  /** @deprecated (3.1) */
   @Deprecated
   public void testLowerCaseTokenizerBWCompat() throws IOException {
     StringReader reader = new StringReader("Tokenizer \ud801\udc1ctest");
@@ -235,7 +192,7 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
         reader);
     assertTokenStreamContents(tokenizer, new String[] { "tokenizer", "test" });
   }
-  
+
   public void testWhitespaceTokenizer() throws IOException {
     StringReader reader = new StringReader("Tokenizer \ud801\udc1ctest");
     WhitespaceTokenizer tokenizer = new WhitespaceTokenizer(TEST_VERSION_CURRENT,
@@ -244,6 +201,7 @@ public class TestAnalyzers extends BaseTokenStreamTestCase {
         "\ud801\udc1ctest" });
   }
 
+  /** @deprecated (3.1) */
   @Deprecated
   public void testWhitespaceTokenizerBWCompat() throws IOException {
     StringReader reader = new StringReader("Tokenizer \ud801\udc1ctest");
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java
index 23d1128..4cd9f9f 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestClassicAnalyzer.java
@@ -129,12 +129,13 @@ public class TestClassicAnalyzer extends BaseTokenStreamTestCase {
     // the following should be recognized as HOST:
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
 
-    // 2.3 should show the bug
-    a2 = new ClassicAnalyzer(org.apache.lucene.util.Version.LUCENE_23);
-    assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "wwwnutchorg" }, new String[] { "<ACRONYM>" });
+    // 2.3 should show the bug. But, alas, it's obsolete, we don't support it.
+    // a2 = new ClassicAnalyzer(org.apache.lucene.util.Version.LUCENE_23);
+    // assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "wwwnutchorg" }, new String[] { "<ACRONYM>" });
 
-    // 2.4 should not show the bug
-    a2 = new ClassicAnalyzer(Version.LUCENE_24);
+    // 2.4 should not show the bug. But, alas, it's also obsolete,
+    // so we check latest released (Robert's gonna break this on 4.0 soon :) )
+    a2 = new ClassicAnalyzer(Version.LUCENE_31);
     assertAnalyzesTo(a2, "www.nutch.org.", new String[]{ "www.nutch.org" }, new String[] { "<HOST>" });
   }
 
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
index d602b17..aee74d1 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopAnalyzer.java
@@ -62,17 +62,15 @@ public class TestStopAnalyzer extends BaseTokenStreamTestCase {
     stopWordsSet.add("good");
     stopWordsSet.add("test");
     stopWordsSet.add("analyzer");
-    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_24, stopWordsSet);
+    StopAnalyzer newStop = new StopAnalyzer(Version.LUCENE_40, stopWordsSet);
     StringReader reader = new StringReader("This is a good test of the english stop analyzer");
     TokenStream stream = newStop.tokenStream("test", reader);
     assertNotNull(stream);
     CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
-    PositionIncrementAttribute posIncrAtt = stream.addAttribute(PositionIncrementAttribute.class);
     
     while (stream.incrementToken()) {
       String text = termAtt.toString();
       assertFalse(stopWordsSet.contains(text));
-      assertEquals(1,posIncrAtt.getPositionIncrement()); // in 2.4 stop tokenizer does not apply increments.
     }
   }
 
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
index c17843f..88957ff 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/core/TestStopFilter.java
@@ -16,22 +16,18 @@ package org.apache.lucene.analysis.core;
  * limitations under the License.
  */
 
+import java.io.IOException;
+import java.io.StringReader;
+import java.util.ArrayList;
+import java.util.Set;
+
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.util.English;
 import org.apache.lucene.util.Version;
 
-import java.io.IOException;
-import java.io.StringReader;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Set;
-import java.util.HashSet;
-
 
 public class TestStopFilter extends BaseTokenStreamTestCase {
   
@@ -39,7 +35,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
 
   public void testExactCase() throws IOException {
     StringReader reader = new StringReader("Now is The Time");
-    Set<String> stopWords = new HashSet<String>(Arrays.asList("is", "the", "Time"));
+    Set<String> stopWords = asSet("is", "the", "Time");
     TokenStream stream = new StopFilter(TEST_VERSION_CURRENT, new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader), stopWords, false);
     final CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
     assertTrue(stream.incrementToken());
@@ -51,7 +47,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
 
   public void testIgnoreCase() throws IOException {
     StringReader reader = new StringReader("Now is The Time");
-    Set<Object> stopWords = new HashSet<Object>(Arrays.asList( "is", "the", "Time" ));
+    Set<String> stopWords = asSet( "is", "the", "Time" );
     TokenStream stream = new StopFilter(TEST_VERSION_CURRENT, new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader), stopWords, true);
     final CharTermAttribute termAtt = stream.getAttribute(CharTermAttribute.class);
     assertTrue(stream.incrementToken());
@@ -89,7 +85,7 @@ public class TestStopFilter extends BaseTokenStreamTestCase {
     Set<Object> stopSet = StopFilter.makeStopSet(TEST_VERSION_CURRENT, stopWords);
     // with increments
     StringReader reader = new StringReader(sb.toString());
-    StopFilter stpf = new StopFilter(Version.LUCENE_24, new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader), stopSet);
+    StopFilter stpf = new StopFilter(Version.LUCENE_40, new WhitespaceTokenizer(TEST_VERSION_CURRENT, reader), stopSet);
     doTestStopPositons(stpf,true);
     // without increments
     reader = new StringReader(sb.toString());
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
index 388b27e..eb6beb0 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/cz/TestCzechAnalyzer.java
@@ -35,9 +35,8 @@ import org.apache.lucene.util.Version;
  *
  */
 public class TestCzechAnalyzer extends BaseTokenStreamTestCase {
-  
   /**
-   * @deprecated Remove this test when support for 3.0 indexes is no longer needed.
+   * @deprecated (3.1) Remove this test when support for 3.0 indexes is no longer needed.
    */
   @Deprecated
   public void testStopWordLegacy() throws Exception {
@@ -51,7 +50,7 @@ public class TestCzechAnalyzer extends BaseTokenStreamTestCase {
   }
   
   /**
-   * @deprecated Remove this test when support for 3.0 indexes is no longer needed.
+   * @deprecated (3.1) Remove this test when support for 3.0 indexes is no longer needed.
    */
   @Deprecated
   public void testReusableTokenStreamLegacy() throws Exception {
@@ -66,49 +65,6 @@ public class TestCzechAnalyzer extends BaseTokenStreamTestCase {
     assertAnalyzesToReuse(analyzer, "?esk Republika", new String[] { "?esk", "republik" });
   }
 
-  /**
-   * An input stream that always throws IOException for testing.
-   * @deprecated Remove this class when the loadStopWords method is removed.
-   */
-  @Deprecated
-  private class UnreliableInputStream extends InputStream {
-    @Override
-    public int read() throws IOException {
-      throw new IOException();
-    }
-  }
-  
-  /**
-   * The loadStopWords method does not throw IOException on error,
-   * instead previously it set the stoptable to null (versus empty)
-   * this would cause a NPE when it is time to create the StopFilter.
-   * @deprecated Remove this test when the loadStopWords method is removed.
-   */
-  @Deprecated
-  public void testInvalidStopWordFile() throws Exception {
-    CzechAnalyzer cz = new CzechAnalyzer(Version.LUCENE_30);
-    cz.loadStopWords(new UnreliableInputStream(), "UTF-8");
-    assertAnalyzesTo(cz, "Pokud mluvime o volnem",
-        new String[] { "pokud", "mluvime", "o", "volnem" });
-  }
-  
-  /** 
-   * Test that changes to the stop table via loadStopWords are applied immediately
-   * when using reusable token streams.
-   * @deprecated Remove this test when the loadStopWords method is removed.
-   */
-  @Deprecated
-  public void testStopWordFileReuse() throws Exception {
-    CzechAnalyzer cz = new CzechAnalyzer(Version.LUCENE_30);
-    assertAnalyzesToReuse(cz, "?esk Republika", 
-      new String[] { "?esk", "republika" });
-    
-    InputStream stopwords = getClass().getResourceAsStream("customStopWordFile.txt");
-    cz.loadStopWords(stopwords, "UTF-8");
-    
-    assertAnalyzesToReuse(cz, "?esk Republika", new String[] { "?esk" });
-  }
-  
   public void testWithStemExclusionSet() throws IOException{
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("hole");
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
index 288aa4f..b329298 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanAnalyzer.java
@@ -19,6 +19,7 @@ package org.apache.lucene.analysis.de;
 
 import java.io.IOException;
 import java.io.StringReader;
+import java.util.Collections;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
@@ -35,15 +36,6 @@ public class TestGermanAnalyzer extends BaseTokenStreamTestCase {
     checkOneTermReuse(a, "Tischen", "tisch");
   }
   
-  public void testExclusionTableBWCompat() throws IOException {
-    GermanStemFilter filter = new GermanStemFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, 
-        new StringReader("Fischen Trinken")));
-    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set.add("fischen");
-    filter.setExclusionSet(set);
-    assertTokenStreamContents(filter, new String[] { "fischen", "trink" });
-  }
-
   public void testWithKeywordAttribute() throws IOException {
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("fischen");
@@ -53,27 +45,8 @@ public class TestGermanAnalyzer extends BaseTokenStreamTestCase {
     assertTokenStreamContents(filter, new String[] { "fischen", "trink" });
   }
 
-  public void testWithKeywordAttributeAndExclusionTable() throws IOException {
-    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set.add("fischen");
-    CharArraySet set1 = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
-    set1.add("trinken");
-    set1.add("fischen");
-    GermanStemFilter filter = new GermanStemFilter(
-        new KeywordMarkerFilter(new LowerCaseTokenizer(TEST_VERSION_CURRENT, new StringReader(
-            "Fischen Trinken")), set));
-    filter.setExclusionSet(set1);
-    assertTokenStreamContents(filter, new String[] { "fischen", "trinken" });
-  }
-  
-  /* 
-   * Test that changes to the exclusion table are applied immediately
-   * when using reusable token streams.
-   */
-  public void testExclusionTableReuse() throws Exception {
-    GermanAnalyzer a = new GermanAnalyzer(TEST_VERSION_CURRENT);
-    checkOneTermReuse(a, "tischen", "tisch");
-    a.setStemExclusionTable(new String[] { "tischen" });
+  public void testStemExclusionTable() throws Exception {
+    GermanAnalyzer a = new GermanAnalyzer(TEST_VERSION_CURRENT, Collections.emptySet(), asSet("tischen"));
     checkOneTermReuse(a, "tischen", "tischen");
   }
   
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
index 3f57b62..d8a1f69 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/el/GreekAnalyzerTest.java
@@ -16,8 +16,8 @@ package org.apache.lucene.analysis.el;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.util.Version;
 
 /**
@@ -52,7 +52,7 @@ public class GreekAnalyzerTest extends BaseTokenStreamTestCase {
 	 * Test the analysis of various greek strings.
 	 *
 	 * @throws Exception in case an error occurs
-	 * @deprecated Remove this test when support for 3.0 is no longer needed
+	 * @deprecated (3.1) Remove this test when support for 3.0 is no longer needed
 	 */
   @Deprecated
 	public void testAnalyzerBWCompat() throws Exception {
@@ -87,15 +87,4 @@ public class GreekAnalyzerTest extends BaseTokenStreamTestCase {
     assertAnalyzesToReuse(a, "????????  ???,  ????   ",
         new String[] { "?????", "?", "??", "" });
   }
-	
-	/**
-	 * Greek Analyzer didn't call standardFilter, so no normalization of acronyms.
-	 * check that this is preserved.
-	 * @deprecated remove this test in Lucene 4.0
-	 */
-	@Deprecated
-	public void testAcronymBWCompat() throws Exception {
-	  Analyzer a = new GreekAnalyzer(Version.LUCENE_30);
-	  assertAnalyzesTo(a, "?.?..", new String[] { ".?.?." });
 	}
-}
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
index 452f356..d38d0f6 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/fa/TestPersianAnalyzer.java
@@ -17,8 +17,8 @@ package org.apache.lucene.analysis.fa;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 
 /**
  * Test the Persian Analyzer
@@ -215,9 +215,8 @@ public class TestPersianAnalyzer extends BaseTokenStreamTestCase {
    * Test that custom stopwords work, and are not case-sensitive.
    */
   public void testCustomStopwords() throws Exception {
-    PersianAnalyzer a = new PersianAnalyzer(TEST_VERSION_CURRENT, new String[] { "the", "and", "a" });
+    PersianAnalyzer a = new PersianAnalyzer(TEST_VERSION_CURRENT, asSet("the", "and", "a"));
     assertAnalyzesTo(a, "The quick brown fox.", new String[] { "quick",
         "brown", "fox" });
   }
-
 }
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
index 60901ee..8366462 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
@@ -116,7 +116,7 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 	}
 	
 	/**
-	 * @deprecated remove this test for Lucene 4.0
+	 * @deprecated (3.1) remove this test for Lucene 5.0
 	 */
 	@Deprecated
 	public void testAnalyzer30() throws Exception {
@@ -224,17 +224,6 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
               "captif" });
 	}
 
-	/* 
-	 * Test that changes to the exclusion table are applied immediately
-	 * when using reusable token streams.
-	 */
-	public void testExclusionTableReuse() throws Exception {
-	  FrenchAnalyzer fa = new FrenchAnalyzer(TEST_VERSION_CURRENT);
-	  assertAnalyzesToReuse(fa, "habitable", new String[] { "habit" });
-	  fa.setStemExclusionTable(new String[] { "habitable" });
-	  assertAnalyzesToReuse(fa, "habitable", new String[] { "habitable" });
-	}
-	
   public void testExclusionTableViaCtor() throws Exception {
     CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, 1, true);
     set.add("habitable");
@@ -256,7 +245,7 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
   /**
    * Prior to 3.1, this analyzer had no lowercase filter.
    * stopwords were case sensitive. Preserve this for back compat.
-   * @deprecated Remove this test in Lucene 4.0
+   * @deprecated (3.1) Remove this test in Lucene 5.0
    */
   @Deprecated
   public void testBuggyStopwordsCasing() throws IOException {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestISOLatin1AccentFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestISOLatin1AccentFilter.java
deleted file mode 100644
index 8092810..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestISOLatin1AccentFilter.java
+++ /dev/null
@@ -1,113 +0,0 @@
-package org.apache.lucene.analysis.miscellaneous;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import java.io.StringReader;
-
-public class TestISOLatin1AccentFilter extends BaseTokenStreamTestCase {
-  public void testU() throws Exception {
-    TokenStream stream = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader("Des mot cls ? LA CHA?NE ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  ?                         ? ?        ? ?"));
-    ISOLatin1AccentFilter filter = new ISOLatin1AccentFilter(stream);
-    CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);
-    assertTermEquals("Des", filter, termAtt);
-    assertTermEquals("mot", filter, termAtt);
-    assertTermEquals("cles", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("LA", filter, termAtt);
-    assertTermEquals("CHAINE", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("A", filter, termAtt);
-    assertTermEquals("AE", filter, termAtt);
-    assertTermEquals("C", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("E", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("I", filter, termAtt);
-    assertTermEquals("IJ", filter, termAtt);
-    assertTermEquals("D", filter, termAtt);
-    assertTermEquals("N", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("O", filter, termAtt);
-    assertTermEquals("OE", filter, termAtt);
-    assertTermEquals("TH", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("U", filter, termAtt);
-    assertTermEquals("Y", filter, termAtt);
-    assertTermEquals("Y", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("a", filter, termAtt);
-    assertTermEquals("ae", filter, termAtt);
-    assertTermEquals("c", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("e", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("i", filter, termAtt);
-    assertTermEquals("ij", filter, termAtt);
-    assertTermEquals("d", filter, termAtt);
-    assertTermEquals("n", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("o", filter, termAtt);
-    assertTermEquals("oe", filter, termAtt);
-    assertTermEquals("ss", filter, termAtt);
-    assertTermEquals("th", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("u", filter, termAtt);
-    assertTermEquals("y", filter, termAtt);
-    assertTermEquals("y", filter, termAtt);
-    assertTermEquals("fi", filter, termAtt);
-    assertTermEquals("fl", filter, termAtt);
-    assertFalse(filter.incrementToken());
-  }
-  
-  void assertTermEquals(String expected, TokenStream stream, CharTermAttribute termAtt) throws Exception {
-    assertTrue(stream.incrementToken());
-    assertEquals(expected, termAtt.toString());
-  }
-}
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java
index e1ebf7d..5039b4b 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestKeepWordFilter.java
@@ -24,6 +24,7 @@ import java.util.Set;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.analysis.util.CharArraySet;
 
 /** Test {@link KeepWordFilter} */
 public class TestKeepWordFilter extends BaseTokenStreamTestCase {
@@ -38,12 +39,12 @@ public class TestKeepWordFilter extends BaseTokenStreamTestCase {
     
     // Test Stopwords
     TokenStream stream = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    stream = new KeepWordFilter(stream, words, true);
+    stream = new KeepWordFilter(stream, new CharArraySet(TEST_VERSION_CURRENT, words, true));
     assertTokenStreamContents(stream, new String[] { "aaa", "BBB" });
        
     // Now force case
     stream = new WhitespaceTokenizer(TEST_VERSION_CURRENT, new StringReader(input));
-    stream = new KeepWordFilter(stream, words, false);
+    stream = new KeepWordFilter(stream, new CharArraySet(TEST_VERSION_CURRENT,words, false));
     assertTokenStreamContents(stream, new String[] { "aaa" });
   }
 }
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java
index 68c5d70..4e65f9b 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestTrimFilter.java
@@ -23,12 +23,7 @@ import java.util.Collection;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.analysis.tokenattributes.*;
 
 /**
  * @version $Id:$
@@ -70,7 +65,7 @@ public class TestTrimFilter extends BaseTokenStreamTestCase {
   }
   
   /**
-   * @deprecated does not support custom attributes
+   * @deprecated (3.0) does not support custom attributes
    */
   @Deprecated
   private static class IterTokenStream extends TokenStream {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
index df19528..c784130 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestWordDelimiterFilter.java
@@ -25,7 +25,6 @@ import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.core.KeywordTokenizer;
 import org.apache.lucene.analysis.core.StopFilter;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.miscellaneous.SingleTokenTokenStream;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
@@ -68,18 +67,14 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
 
     // test that subwords and catenated subwords have
     // the correct offsets.
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-            new SingleTokenTokenStream(new Token("foo-bar", 5, 12)),
-    1,1,0,0,1,1,0);
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("foo-bar", 5, 12)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
 
     assertTokenStreamContents(wdf, 
         new String[] { "foo", "bar", "foobar" },
         new int[] { 5, 9, 5 }, 
         new int[] { 8, 12, 12 });
 
-    wdf = new WordDelimiterFilter(
-            new SingleTokenTokenStream(new Token("foo-bar", 5, 6)),
-    1,1,0,0,1,1,0);
+    wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("foo-bar", 5, 6)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf,
         new String[] { "foo", "bar", "foobar" },
@@ -90,10 +85,7 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
   @Test
   public void testOffsetChange() throws Exception
   {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("belkeit)", 7, 16)),
-      1,1,0,0,1,1,0
-    );
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("belkeit)", 7, 16)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf,
         new String[] { "belkeit" },
@@ -104,10 +96,7 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
   @Test
   public void testOffsetChange2() throws Exception
   {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(belkeit", 7, 17)),
-      1,1,0,0,1,1,0
-    );
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("(belkeit", 7, 17)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf,
         new String[] { "belkeit" },
@@ -118,10 +107,7 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
   @Test
   public void testOffsetChange3() throws Exception
   {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(belkeit", 7, 16)),
-      1,1,0,0,1,1,0
-    );
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("(belkeit", 7, 16)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf,
         new String[] { "belkeit" },
@@ -132,10 +118,7 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
   @Test
   public void testOffsetChange4() throws Exception
   {
-    WordDelimiterFilter wdf = new WordDelimiterFilter(
-      new SingleTokenTokenStream(new Token("(foo,bar)", 7, 16)),
-      1,1,0,0,1,1,0
-    );
+    WordDelimiterFilter wdf = new WordDelimiterFilter(new SingleTokenTokenStream(new Token("(foo,bar)", 7, 16)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 1, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf,
         new String[] { "foo", "bar", "foobar"},
@@ -145,7 +128,7 @@ public class TestWordDelimiterFilter extends BaseTokenStreamTestCase {
 
   public void doSplit(final String input, String... output) throws Exception {
     WordDelimiterFilter wdf = new WordDelimiterFilter(new KeywordTokenizer(
-        new StringReader(input)), 1, 1, 0, 0, 0);
+                new StringReader(input)), WordDelimiterIterator.DEFAULT_WORD_DELIM_TABLE, 1, 1, 0, 0, 0, 1, 0, 1, 1, null);
     
     assertTokenStreamContents(wdf, output);
   }
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
index 141f23e..1c2f727 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/nl/TestDutchStemmer.java
@@ -114,7 +114,7 @@ public class TestDutchStemmer extends BaseTokenStreamTestCase {
   }
   
   /**
-   * @deprecated remove this test in Lucene 4.0
+   * @deprecated (3.1) remove this test in Lucene 5.0
    */
   @Deprecated
   public void testOldBuggyStemmer() throws Exception {
@@ -139,19 +139,6 @@ public class TestDutchStemmer extends BaseTokenStreamTestCase {
     checkOneTermReuse(a, "lichamelijkheden", "licham");
   }
   
-  /* 
-   * Test that changes to the exclusion table are applied immediately
-   * when using reusable token streams.
-   */
-  public void testExclusionTableReuse() throws Exception {
-    DutchAnalyzer a = new DutchAnalyzer(TEST_VERSION_CURRENT);
-    checkOneTermReuse(a, "lichamelijk", "licham");
-    a.setStemExclusionTable(new String[] { "lichamelijk" });
-    checkOneTermReuse(a, "lichamelijk", "lichamelijk");
-
-    
-  }
-  
   public void testExclusionTableViaCtor() throws IOException {
     CharArraySet set = new CharArraySet(Version.LUCENE_30, 1, true);
     set.add("lichamelijk");
@@ -178,7 +165,7 @@ public class TestDutchStemmer extends BaseTokenStreamTestCase {
   /**
    * Prior to 3.1, this analyzer had no lowercase filter.
    * stopwords were case sensitive. Preserve this for back compat.
-   * @deprecated Remove this test in Lucene 4.0
+   * @deprecated (3.1) Remove this test in Lucene 5.0
    */
   @Deprecated
   public void testBuggyStopwordsCasing() throws IOException {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
index 2e8ac60..830d19c 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
@@ -26,9 +26,9 @@ import java.util.regex.Pattern;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.charfilter.MappingCharFilter;
 import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
-import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 
 public class TestPatternTokenizer extends BaseTokenStreamTestCase 
@@ -96,9 +96,7 @@ public class TestPatternTokenizer extends BaseTokenStreamTestCase
   
   /** 
    * TODO: rewrite tests not to use string comparison.
-   * @deprecated only tests TermAttribute!
    */
-  @Deprecated
   private static String tsToString(TokenStream in) throws IOException {
     StringBuilder out = new StringBuilder();
     CharTermAttribute termAtt = in.addAttribute(CharTermAttribute.class);
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
index a6896e5..3c52876 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/reverse/TestReverseStringFilter.java
@@ -22,6 +22,7 @@ import java.io.StringReader;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.util.Version;
 
 public class TestReverseStringFilter extends BaseTokenStreamTestCase {
   public void testFilter() throws Exception {
@@ -53,9 +54,11 @@ public class TestReverseStringFilter extends BaseTokenStreamTestCase {
   
   /**
    * Test the broken 3.0 behavior, for back compat
+   * @deprecated (3.1) Remove in Lucene 5.0
    */
+  @Deprecated
   public void testBackCompat() throws Exception {
-    assertEquals("\uDF05\uD866\uDF05\uD866", ReverseStringFilter.reverse("??"));
+    assertEquals("\uDF05\uD866\uDF05\uD866", ReverseStringFilter.reverse(Version.LUCENE_30, "??"));
   }
   
   public void testReverseSupplementary() throws Exception {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
index 45d9789..b52ec1b 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianAnalyzer.java
@@ -18,12 +18,9 @@ package org.apache.lucene.analysis.ru;
  */
 
 import java.io.IOException;
-import java.io.InputStreamReader;
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.util.Version;
 
@@ -31,65 +28,16 @@ import org.apache.lucene.util.Version;
  * Test case for RussianAnalyzer.
  */
 
-public class TestRussianAnalyzer extends BaseTokenStreamTestCase
-{
-    private InputStreamReader inWords;
+public class TestRussianAnalyzer extends BaseTokenStreamTestCase {
 
-    private InputStreamReader sampleUnicode;
-
-    /**
-     * @deprecated remove this test and its datafiles in Lucene 4.0
-     * the Snowball version has its own data tests.
-     */
-    @Deprecated
-    public void testUnicode30() throws IOException
-    {
-        RussianAnalyzer ra = new RussianAnalyzer(Version.LUCENE_30);
-        inWords =
-            new InputStreamReader(
-                getClass().getResourceAsStream("testUTF8.txt"),
-                "UTF-8");
-
-        sampleUnicode =
-            new InputStreamReader(
-                getClass().getResourceAsStream("resUTF8.htm"),
-                "UTF-8");
-
-        TokenStream in = ra.tokenStream("all", inWords);
-
-        RussianLetterTokenizer sample =
-            new RussianLetterTokenizer(TEST_VERSION_CURRENT,
-                sampleUnicode);
-
-        CharTermAttribute text = in.getAttribute(CharTermAttribute.class);
-        CharTermAttribute sampleText = sample.getAttribute(CharTermAttribute.class);
-
-        for (;;)
-        {
-          if (in.incrementToken() == false)
-            break;
-
-            boolean nextSampleToken = sample.incrementToken();
-            assertEquals(
-                "Unicode",
-                text.toString(),
-                nextSampleToken == false
-                ? null
-                : sampleText.toString());
-        }
-
-        inWords.close();
-        sampleUnicode.close();
-    }
-    
-    /** Check that RussianAnalyzer doesnt discard any numbers */
+     /** Check that RussianAnalyzer doesnt discard any numbers */
     public void testDigitsInRussianCharset() throws IOException
     {
       RussianAnalyzer ra = new RussianAnalyzer(TEST_VERSION_CURRENT);
       assertAnalyzesTo(ra, "text 1000", new String[] { "text", "1000" });
     }
     
-    /** @deprecated remove this test in Lucene 4.0: stopwords changed */
+    /** @deprecated (3.1) remove this test in Lucene 5.0: stopwords changed */
     @Deprecated
     public void testReusableTokenStream30() throws Exception {
       Analyzer a = new RussianAnalyzer(Version.LUCENE_30);
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLetterTokenizer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLetterTokenizer.java
index ce3ff5d..2fedf78 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLetterTokenizer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianLetterTokenizer.java
@@ -25,7 +25,7 @@ import org.apache.lucene.util.Version;
 
 /**
  * Testcase for {@link RussianLetterTokenizer}
- * @deprecated Remove this test class in Lucene 4.0
+ * @deprecated (3.1) Remove this test class in Lucene 5.0
  */
 @Deprecated
 public class TestRussianLetterTokenizer extends BaseTokenStreamTestCase {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianStem.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianStem.java
deleted file mode 100644
index 0688f6d..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/TestRussianStem.java
+++ /dev/null
@@ -1,51 +0,0 @@
-package org.apache.lucene.analysis.ru;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-import org.apache.lucene.analysis.util.ReusableAnalyzerBase;
-import org.apache.lucene.util.LuceneTestCase;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.Reader;
-
-import static org.apache.lucene.analysis.util.VocabularyAssert.*;
-
-/**
- * @deprecated Remove this test class (and its datafiles!) in Lucene 4.0
- */
-@Deprecated
-public class TestRussianStem extends LuceneTestCase {
-  public void testStem() throws IOException {
-    Analyzer a = new ReusableAnalyzerBase() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName,
-          Reader reader) {
-        Tokenizer t = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(t, new RussianStemFilter(t));
-      }
-    };
-    InputStream voc = getClass().getResourceAsStream("wordsUTF8.txt");
-    InputStream out = getClass().getResourceAsStream("stemsUTF8.txt");
-    assertVocabulary(a, voc, out);
-    voc.close();
-    out.close();
-  }
-}
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/resUTF8.htm b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/resUTF8.htm
deleted file mode 100644
index 9bcf0aa..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/resUTF8.htm
+++ /dev/null
@@ -1 +0,0 @@
-???][?][????][??][][???][?][??][?][?][][??][?][?][??][???][??][?][?][?][?][][??][?][][????][?][][?][][?][][???][??][???][??][??][??][??][???][?][???][?][???][??]
\ No newline at end of file
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/stemsUTF8.txt b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/stemsUTF8.txt
deleted file mode 100644
index bdf9b35..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/stemsUTF8.txt
+++ /dev/null
@@ -1,49673 +0,0 @@
-?
-??
-?
-?
-?
-?
-??
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-
-?
-???
-????
-???
-???
-?
-?
-??
-??
-????
-????
-????
-??
-??
-
-?
-
-
-?
-?
-?
-?
-?
-?
-
-?
-?
-
-
-
-?
-?
-?
-??
-??
-??
-????
-????
-?????
-?
-
-??
-??
-??
-??
-??
-??
-?
-????
-?
-?
-
-??
-??
-?
-??
-??
-??
-
-
-?
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-???
-???
-???
-?
-?
-?
-?
-?
-???
-???
-??
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-???
-
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-
-
-
-
-
-?
-?
-?
-??
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-??
-??
-???
-
-
-
-
-
-
-?????
-?
-?
-?
-?????
-??
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-
-
-
-
-
-?
-?
-
-
-
-
-?
-?
-???
-?
-?
-?
-?
-
-
-
-
-
-?
-
-
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-???
-????
-???
-???
-???
-???
-???
-???
-???
-
-
-?
-?
-?
-
-?
-?
-?
-??
-?
-?
-
-
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-??
-??
-???
-
-
-?
-??
-???
-???
-???
-?
-?
-??
-???
-??
-?
-??
-
-???
-?
-??
-??
-??
-??
-?
-?
-???
-?
-?
-??
-?
-?
-?
-??
-????
-?
-??
-?
-?
-??
-??
-???
-?
-???
-?
-?
-?
-?
-?
-???
-????
-????
-????
-?????
-?????
-????
-???
-????
-???
-???
-???
-?
-???
-???????
-???????
-???????
-???????
-???????
-???????
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-??
-??
-????
-????
-??????
-??????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-?????
-?????
-?????
-??????
-??
-??
-??
-????
-?????
-??
-???
-???
-????
-??
-????
-?????
-???
-???
-???
-???
-???
-
-?
-??
-??
-??
-??
-??
-????
-????
-?
-?
-????
-?????
-?????
-
-???
-??
-??
-?
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??????
-??????
-????
-?
-?
-?
-?
-??
-???
-??
-?
-??
-??
-??
-??
-???
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-?
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-?
-
-?
-
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-??
-?
-
-
-
-?
-???
-?
-
-
-
-
-
-
-??
-??
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-???
-?
-?
-?
-??
-?
-?
-??
-??
-?
-?
-?
-
-??
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-
-?
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-??
-??
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-???
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-??
-?
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-??
-??
-?
-???
-???
-???
-???
-???
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-
-???
-???
-??
-????
-????
-????
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-?
-???
-??
-???
-????
-????
-????
-???
-?
-???
-???
-???
-???
-???
-
-
-?
-?
-?
-
-
-
-
-?
-
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-
-????
-????
-????
-????
-???
-???
-?
-
-
-
-
-??
-???
-???
-??
-??
-??
-??
-
-
-???
-?
-?
-
-
-
-
-
-
-
-???
-?
-
-
-??
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-??
-??
-??
-??
-???
-???
-?????
-?????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-????
-????
-????
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???????
-????
-???
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-??
-????
-????
-????
-????
-????
-????
-???
-??
-???
-??
-??
-??
-??
-???
-???
-???
-??????
-??????
-??????
-??????
-?????
-?????
-????
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-
-
-
-
-???
-???
-???
-???
-???
-
-
-??
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-????
-??
-?
-?
-???
-?
-
-
-
-
-
-
-?
-
-
-
-
-??
-??
-?
-
-
-
-
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-??
-??
-????
-????
-????
-?
-?
-?
-?
-??
-
-
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-????
-????
-??
-??
-???
-????
-????
-??
-??
-?
-????
-??
-??
-??
-??
-??
-??
-???
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-
-?
-
-?
-?
-??
-
-
-
-
-
-
-??
-???
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-?
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-???
-????
-
-
-
-
-
-
-?
-
-
-
-?
-?
-?
-??
-???
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-
-
-
-?
-
-
-
-
-?
-?
-?
-??
-??
-???
-
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-
-
-?
-
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-
-
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-??
-
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-??
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??
-??
-??
-???
-??
-???
-??
-???
-????
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?????
-?
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-???
-??????
-????
-???
-??
-??
-??
-????
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-????
-???
-?
-??
-??
-???
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-??
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-???
-???
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-?????
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-????
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-????
-????
-????
-??
-??
-??
-??
-????
-??
-????
-??
-??
-??
-??
-?
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-???
-???
-???
-????
-????
-??
-???
-???
-
-
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-?
-
-
-?
-?
-?
-?
-
-
-
-
-
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-???
-
-
-?
-?
-?
-
-
-
-
-
-?
-
-??
-??
-??
-??
-
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-????
-????
-?
-?
-??
-?
-?
-?
-??
-??
-?
-??
-???
-??
-??
-??
-???
-???
-???
-???
-??
-?
-???
-???
-??
-??
-??
-?
-??
-?
-?
-??
-??
-????
-????
-?
-?
-?
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-?
-??
-???
-??
-??
-??
-??
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-????
-
-
-
-?
-?
-
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-??
-????
-?
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-??
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-
-?
-?
-?
-
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-
-?
-??
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-
-?
-
-?
-?
-?
-
-
-??
-
-???
-?
-??
-??
-??
-?
-
-
-?
-?
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-??
-???
-??
-??
-??
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-?
-?
-???
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-
-??
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-??
-??
-??
-
-
-
-
-
-
-??
-?
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-
-
-?
-?
-?
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-?
-??
-??
-?
-???
-?
-?
-??
-??
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-?
-?
-
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-
-
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-??
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-
-
-?
-?
-?
-?
-
-?
-?
-?
-?
-??
-??
-?
-
-?
-?
-
-
-
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-??
-??
-??
-??
-??
-?
-??
-?
-?
-??
-????
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-??
-?
-?
-?
-
-
-
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-?
-?
-
-
-?
-??
-??
-?
-
-
-?
-?
-?
-?
-??
-?
-????
-????
-????
-???
-???
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-
-
-
-
-?
-?
-
-?
-??
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-?
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-?
-?
-?
-?
-?
-??
-?
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-??
-
-
-
-
-
-
-
-
-
-?
-??
-??
-??
-??
-
-
-
-
-
-?
-?
-?
-?
-
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-
-
-
-?
-?
-?
-
-
-
-?
-?
-?
-?
-??
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-??
-
-
-
-
-?
-?
-
-
-
-?
-???
-???
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-
-?
-?
-
-??
-
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-??
-?
-?
-
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-
-
-
-
-
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-??
-??
-
-?
-??
-?
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-
-
-
-
-
-??
-
-
-?
-?
-
-
-
-??
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-??
-??
-
-??
-??
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-
-
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-???
-
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-??
-??
-
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-?
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-??
-?
-???
-????
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-????
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-????
-??
-???
-?????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-????
-???
-?????
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-??
-?????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-??
-?????
-?????
-???
-??
-??
-??
-??
-??
-?
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-??
-?
-
-
-
-
-
-?
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-????
-????
-
-
-
-
-
-??
-?
-?
-
-
-?
-
-
-
-
-???
-
-??
-?
-???
-??
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-???
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-???
-???
-?
-??
-??
-??
-??
-??
-?
-???
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??????
-?
-??
-??
-?
-?
-??
-??
-??
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-????
-?????
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-?
-??
-?
-?
-??
-??
-?
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-????
-???
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-??
-????
-??
-?
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-????
-????
-???
-????
-???
-????
-??
-??
-????
-????
-????
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-??
-????
-??
-????
-???
-???
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-??????
-??????
-???????
-???????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-????
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-?????
-???
-?
-?
-?
-??
-??
-?
-?
-???
-?
-?
-??
-?
-?
-?
-?
-???
-???
-???
-????
-????
-???
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-?
-?
-???
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-?
-?
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?
-?
-??
-???
-??
-???
-???
-???
-???
-???
-????
-?????
-???
-???
-????
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?
-???
-???
-?
-????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-????
-????
-?????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-?????
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-??
-???
-???
-?????
-????
-????
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-????
-????
-?????
-????
-???
-???
-??
-????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-?????
-??
-???
-???
-???
-???
-??
-???
-??????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-???
-?
-?
-?
-?
-??
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-
-
-
-
-?
-??
-??
-??
-???
-???
-???
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-
-
-?
-?
-?
-?
-?
-?
-
-??
-
-
-?
-
-???
-???
-???
-???
-???
-????
-??
-
-???
-?
-?
-??
-
-
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?
-????
-????
-?
-???
-?
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-???
-?????
-?????
-?
-???
-?
-
-
-
-?
-?
-
-
-
-
-
-???
-
-??
-?
-??
-?
-?
-??
-??
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-
-
-
-??
-?
-????
-??
-??
-??
-??
-??
-?
-?
-?
-?
-???
-???
-???
-????
-????
-?
-?
-?
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-??
-???
-?
-?
-??
-????
-??
-??
-??
-?
-??
-
-
-?
-?
-?
-
-
-
-?
-?
-
-??
-??
-
-??
-?
-
-
-
-??
-??
-??
-
-??
-??
-??
-
-??
-??
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-???
-
-
-
-??
-
-
-
-
-
-
-
-
-?
-??
-
-?
-
-
-
-
-
-?
-?
-?
-???
-?
-?
-??
-
-
-
-
-?
-?
-?
-??
-??
-?
-??
-?
-?
-?
-?
-??
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-???
-
-
-
-?
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-
-
-?
-?
-??
-??
-?
-?
-
-?
-?
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-?
-
-
-?
-
-
-
-
-?
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-???
-?
-??
-?
-?
-?
-?
-?
-???
-???
-
-
-
-
-
-
-
-
-???
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-???
-???
-???
-???
-??
-??
-??
-??
-?
-?
-??
-??
-???
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-??
-??
-?
-???
-??
-??
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-???
-???
-???
-?
-?
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-????
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-???
-?
-?
-??
-???
-???
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-????
-????
-????
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-??
-???
-???
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-???
-???
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-????
-????
-????
-????
-??????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?????
-???
-?
-?
-?
-?
-?
-?
-?
-???
-??
-???
-??
-??
-???
-???
-????
-????
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-?
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-??
-
-
-??
-?
-?
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-
-??
-
-??
-???
-????
-????
-??
-?
-??
-
-
-??
-??
-??
-??
-??
-?
-??
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-??
-?
-?
-????
-????
-????
-????
-??
-???
-????
-????
-???
-????
-????
-
-??
-??
-?
-???
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-????
-
-?
-??
-????
-???
-??
-??
-??
-??
-?
-?????
-?
-?
-
-
-
-
-
-
-??
-??
-??
-
-???
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-????
-??
-??
-??
-??
-??
-??
-???
-?
-?
-???
-?
-?
-?
-??
-??
-
-?
-???
-??
-???
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-??
-??
-?
-
-
-
-
-
-
-
-?
-????
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-?
-??
-??
-??
-????
-????
-???
-????
-????
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-
-?
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-??
-??
-
-?
-?
-?
-?
-
-??
-?
-
-?
-
-?
-???
-?
-???
-???
-????
-??
-?
-?????
-???
-?
-?
-???
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-??
-
-
-
-
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-??
-??
-?
-??
-??
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-?
-?
-??
-?
-?
-????
-????
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-
-??
-??
-
-???
-?
-?
-
-
-
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-??
-?
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-
-?
-?
-??
-
-
-?
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-?
-
-?
-?
-?
-
-?
-
-?
-?
-
-??
-
-??
-?
-
-?
-?
-
-
-
-
-
-
-
-????
-????
-????
-????
-
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-?
-
-
-
-?
-
-
-
-
-?
-?
-?
-
-
-
-
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-?
-
-
-
-
-
-
-?
-?
-??
-
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-
-
-????
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-?
-??
-??
-?
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-???
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-?
-?
-?
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-????
-????
-??
-???
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-????
-??
-???
-??
-???
-??
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-??
-???
-??
-??
-?
-?
-?
-??
-???
-???
-??
-???
-???
-???
-????
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-??
-?
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-????
-???
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-?
-?
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-???
-??
-???
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?????
-????
-??
-???
-???
-???
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-???
-???
-?
-?
-?
-?
-?
-????
-?
-?
-?
-??
-?
-?
-??
-???
-???
-?
-?
-
-
-
-
-
-
-
-??
-?
-??
-??
-?
-?
-??
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-?
-?
-
-?
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-
-
-
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-???
-??
-??
-??
-?
-?
-??
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-???
-???
-??
-???
-?
-
-
-
-
-
-
-
-
-
-?
-
-???
-??
-
-
-
-
-
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-?
-?
-??
-????
-????
-????
-????
-????
-????
-????
-??????
-????
-????
-????
-????
-????
-????
-????
-??
-
-?
-?
-????
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-
-
-
-?
-?
-
-
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-
-
-??
-??
-??
-??
-
-?
-
-
-
-
-
-
-?
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-
-?
-??
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-
-?
-?
-?
-
-?
-?
-??
-??
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-??
-???
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-??
-??
-??
-??
-
-
-?
-?
-?
-?
-??
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-
-?
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-??
-
-
-
-
-
-??
-?
-?
-?
-?
-??
-
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?????
-?????
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-????
-????
-?
-?
-?
-?
-?
-?
-??
-
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-????
-???
-???
-???
-??
-????
-??
-???
-
-
-
-
-???
-
-?
-?
-?
-
-
-
-
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-?
-
-??
-?
-???
-
-
-?
-?
-?
-?
-?
-
-?
-?
-?
-
-?
-?
-????
-????
-????
-??
-??
-??
-?
-?
-?
-?
-
-
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?
-???
-?
-???
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-??
-??
-
-??
-??
-???
-?
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-??
-
-?
-
-
-
-
-
-??
-??
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-??
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-
-?
-
-
-
-
-
-
-
-
-
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-???
-??
-???
-??
-??
-??
-?
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-???
-?
-
-
-
-
-?
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-?
-?
-
-
-??
-
-
-?
-
-
-
-
-
-?
-
-
-
-
-??
-
-
-
-
-
-
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-
-
-
-
-??
-??
-???
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-?
-
-?
-?
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-
-?
-?
-?
-
-
-
-
-
-
-?
-?
-?
-
-
-??
-??
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-
-
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-
-?
-?
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-??
-??
-??
-??
-??
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-??
-??
-??
-??
-
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?????
-?????
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-??
-??
-??
-??
-?
-?
-
-
-
-
-
-
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-
-??
-?
-???
-?
-?
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-
-?
-??
-??
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-
-?
-?
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-???
-
-
-
-?
-??
-?
-??
-?
-
-
-??
-?
-?
-?
-?
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-??
-??
-
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-?
-?
-?
-?
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-?
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-?
-??
-???
-???
-?
-?
-???
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-?
-??
-??
-??
-?
-?
-???
-?
-?
-???
-???
-?
-?
-??
-??
-??
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-???
-???
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-???
-???
-??
-??
-??
-??
-??
-???
-??
-?
-???
-??
-??
-??
-???
-?
-??
-??
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-??
-????
-????
-????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-??
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-???
-???
-???
-???
-???
-???
-??
-??
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-?
-?
-?
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-??
-???
-???
-???
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-????
-???
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-????
-????
-????
-????
-???
-????
-????
-????
-????
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-????
-??
-???
-???
-???
-??
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-????
-????
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-????
-???
-???
-???
-??
-??
-??
-?????
-?
-?
-?
-?
-???
-??
-??
-?
-??
-??
-?
-??
-???
-???
-???
-????
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-?
-?
-??
-
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-?
-
-?
-
-
-?
-?
-?
-??
-
-
-
-?
-?
-
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-????
-????
-
-
-
-
-?
-?
-?
-
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-?
-?
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-?
-?
-
-
-?
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-?
-?
-?
-?
-?
-?
-
-?
-
-
-
-
-?
-??
-??
-
-?
-
-
-
-?
-?
-???
-?
-?
-??
-??
-??
-??
-????
-???
-???
-????
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-
-?
-?
-?
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-??
-??
-
-
-
-
-
-?
-?
-?
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-????
-????
-?
-?
-???
-???
-?
-?
-?
-?
-?
-
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-?
-?
-??
-??
-?
-?
-?
-??
-??
-
-
-?
-?
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-?
-
-
-
-
-??
-??
-??
-??
-
-
-
-
-
-???
-???
-???
-??
-??
-???
-???
-?
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-????
-???
-?
-
-
-
-
-
-
-??
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-???
-
-
-
-
-
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-??
-
-?
-??
-???
-???
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-
-??
-??
-??
-
-
-
-
-
-
-?
-
-?
-?
-??
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-?
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-??
-
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-??
-?
-?
-???
-????
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-?
-
-?
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-???
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-
-
-?
-?
-
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-??
-??
-???
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-?
-??
-??
-????
-???
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-???
-???
-????
-???
-??
-??
-??
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-
-???
-
-
-
-
-
-??
-
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-??
-??
-??
-??
-
-??
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-??
-?
-
-??
-??
-??
-??
-??
-
-
-??
-????
-????
-????
-
-?
-
-
-
-
-
-
-?
-?
-??
-?
-????
-
-
-
-?
-?????
-
-
-
-
-
-
-
-????
-???
-???
-???
-???
-????
-????
-????
-????
-
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-????
-???
-?
-?
-??
-??
-??
-??
-??
-
-
-????
-???
-
-
-
-
-
-
-??
-??
-??
-????
-??
-?
-?
-?
-?
-?
-??
-??
-?
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-????
-?
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-??
-??
-??
-?
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-???
-??
-??
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-?
-??
-?
-?
-??
-??
-??
-??
-??
-?
-?
-???
-?
-??
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-???
-????
-????
-????
-????
-????
-????
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-????
-???
-???
-????
-???
-???
-???
-???
-?
-?
-?
-?
-?
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-??
-??
-
-
-
-
-?
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-??
-??
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-???
-???
-???
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-???
-???
-
-
-
-??
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-?
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-??
-??
-
-
-
-
-
-
-?
-
-
-?
-??
-??
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-
-
-
-
-??
-?
-?
-?
-
-
-?
-?
-???
-?????
-?????
-?????
-???
-????
-????
-?
-
-
-?
-?
-??
-??
-??
-??
-?
-?
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-??
-
-
-
-?
-
-
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-??
-?
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-????
-????
-????
-????
-????
-?
-?
-?
-?????
-?????
-?????
-?????
-?????
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-???
-??
-??
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-??
-??
-?
-??
-
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-??
-?
-?
-??
-
-
-
-?
-???
-
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-???
-???
-
-
-
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-
-
-
-
-?
-
-??
-??
-??
-
-??
-??
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-??
-?
-?
-?
-
-
-
-
-
-
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-
-??
-
-
-
-
-
-?
-
-
-
-?
-?
-?
-?
-???
-???
-???
-?
-?
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-???
-
-
-?
-??
-??
-?
-
-
-
-?
-
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-???
-???
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-??
-??
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-
-
-?
-?
-?
-?
-??
-??
-???
-
-?
-?
-?
-?
-???
-???
-???
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-
-?
-???
-
-
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-???
-
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-???
-
-
-??
-?
-?
-?
-??
-?
-?
-?
-
-
-
-
-
-?
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-
-
-
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-?
-
-
-
-???
-???
-???
-
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-
-
-?
-
-
-
-
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-
-?
-??
-??
-??
-??
-??
-???
-
-??
-??
-??
-
-??
-??
-??
-??
-??
-???
-???
-???
-
-
-
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-
-
-?
-?
-?
-
-
-??
-??
-??
-??
-??
-??
-??
-
-
-
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-???
-
-???
-???
-???
-???
-??
-
-
-
-???
-
-???
-??
-???
-??
-???
-
-
-?
-?
-?
-
-?
-???
-???
-????
-??
-?
-?
-?
-???
-??
-???
-???
-???
-???
-???
-?????
-?????
-?????
-??
-??
-??
-??
-??
-???
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-?
-?
-?
-?
-????
-?????
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-??
-??
-??
-???
-
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-?
-?
-
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-???
-??
-???
-?????
-????
-????
-???
-??
-??
-???
-???
-?
-?????
-????
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-???
-????
-????
-????
-????
-???
-??
-??
-??
-???
-?
-???
-???
-?
-??
-?
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-????
-??
-???
-????
-?
-?
-??
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-??
-?
-?
-??
-??
-??
-?
-?
-?
-??
-????
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-???
-???
-???
-???
-??
-????
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-???
-????
-??
-????
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-?
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-??
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-???
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-??????
-???
-????
-???
-???
-????
-????
-????
-????
-???
-???
-?
-??
-????
-???
-?
-???
-???
-???
-???
-???
-?
-??
-??
-??
-???
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-???
-?
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?
-?
-??
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-??
-???
-???
-????
-????
-?????
-????
-??
-??
-????
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-?
-?
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-
-
-??
-??
-??
-
-
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-
-
-
-?
-??
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-?
-?
-
-?
-?
-
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-??
-???
-??
-???
-??
-??
-
-?
-?
-
-
-
-?
-
-
-
-?
-
-?
-??
-?
-??
-??
-
-
-
-
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-??????
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-
-
-
-
-
-
-?
-?
-
-?
-
-
-?
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-?
-??
-?
-?
-?
-
-?
-
-?
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-??
-??
-?
-?
-??
-?
-
-
-
-
-?
-
-
-??
-?
-?
-?
-?
-??
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-?
-????
-????
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-???
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-??
-??
-??
-
-
-??
-?
-?
-?
-?
-
-
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-?
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-?
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-
-??
-?
-?
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-?
-
-
-
-
-
-
-
-??
-
-
-??
-??
-??
-
-
-
-
-
-
-??
-??
-??
-??
-??
-?
-?
-
-
-
-
-?
-?
-?
-
-
-?
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-?
-??
-?
-??
-??
-?
-?
-?
-??
-??
-??
-??
-?
-????
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-????
-??
-??
-??
-????
-?
-?
-?
-?
-?
-??
-?
-???
-???
-?
-??
-??
-??
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-???
-
-???
-??
-??
-??
-?
-?
-?
-
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-??
-??
-??
-??
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-
-
-?
-?
-?
-
-
-
-???
-??
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-
-
-?
-
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-?
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-
-???
-?
-?
-?
-?
-?
-?
-???
-??
-??
-?
-?
-??
-??
-?
-?
-??
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-???
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-????
-??
-??
-???????
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-??
-?
-???
-?
-?
-?
-?
-?
-
-?
-?
-??
-??
-??
-?
-??
-
-
-??
-??
-??
-??
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-??
-??
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-
-?
-?
-???
-???
-???
-??
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-???
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-??
-
-
-
-
-?
-??
-??
-??
-??
-??
-????
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-????
-??
-??
-?
-?
-?
-?
-?
-???
-?
-???
-???
-?
-?
-??
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-???
-???
-?
-?
-?
-?
-??
-?
-??
-?
-??
-?
-??
-??
-?
-?
-?
-??
-?
-??
-??
-??
-?
-?
-???
-??
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-??
-?
-??
-
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-????
-????
-????
-
-
-?
-
-
-
-
-?
-?
-?
-???
-???
-?
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-???
-???
-??
-?
-
-
-
-
-
-?
-?
-??
-
-
-
-?
-?
-?
-?
-
-
-
-?
-?
-?????
-?????
-???
-???
-???
-???
-???
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-
-?
-
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-?
-??
-?
-??
-??
-?????
-????
-????
-????
-??
-??
-??
-????
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-
-?
-
-
-
-
-
-
-
-?
-?
-??
-??
-??
-
-
-
-
-
-
-?
-
-?
-???
-
-??
-??
-?
-???
-
-
-?
-?
-?
-
-??
-??
-??
-?
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-
-
-
-
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-????
-??
-
-
-
-
-??
-
-?
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-????
-????
-?????
-????
-
-?
-?
-?
-?
-?
-
-?
-?
-?
-??
-?
-??
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-??
-???
-???
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-????
-?
-
-
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-???
-????
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-????
-????
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-????
-??
-??
-??
-???
-???
-???
-???
-????
-??????
-???
-??
-???
-?????
-???
-???
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-????
-??
-???
-??
-??
-????
-????
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-???
-
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-
-
-?
-?
-?
-?
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-?
-
-
-
-?
-?
-?
-
-
-
-
-
-
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-?
-???
-???
-???
-???
-?
-?
-?
-????
-???
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-??
-??
-??
-??
-
-
-
-?
-?
-?
-
-?
-
-?
-??
-?
-?
-?
-
-??
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-???
-???
-
-
-
-?
-?
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-?
-?
-?
-
-?
-??
-????
-??
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-
-?
-?
-?
-?
-?
-
-?
-??
-??????
-??
-??
-??
-??
-?
-?
-?
-???
-?????
-?
-?
-?
-?
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-
-??
-
-
-?
-
-?
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-????
-?
-
-
-
-
-??
-
-
-
-
-
-??
-??
-
-???
-??
-
-??
-?
-?
-???
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-??
-??
-
-
-?
-?
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-?
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-
-?
-??
-??
-?
-???
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-
-
-
-?
-
-?
-???
-?
-
-
-?
-??
-?
-??
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-??
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-?
-??
-??
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-??
-
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-?
-??
-??
-?
-?
-?
-???
-
-
-
-?
-??
-?
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-??
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-???
-???
-??
-??
-????
-????
-??
-??
-
-?
-???
-???
-???
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-????
-?
-?
-?
-??
-??
-?
-?
-?
-????
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-????
-????
-????
-????
-????
-?
-?
-?
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-???
-?
-?
-??
-??
-??
-????
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-??????
-???
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-???
-??
-???
-??
-?
-??
-??
-???
-??
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-????
-????
-????
-??
-??
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-??
-??
-??
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-????
-?
-??
-??
-??
-??
-?
-?
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-
-???
-???
-??
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-
-?
-??
-???
-?
-?
-???
-?
-??
-
-?
-?
-?
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-??
-??
-
-??
-??
-??
-??
-??
-??
-??
-?
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-??
-
-
-?
-?
-?
-?
-?
-?
-
-
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-???
-
-
-
-
-
-
-??
-?
-?
-?
-?
-
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-??
-??
-???
-???
-?
-?
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-??
-
-
-?
-?
-?
-
-
-?
-
-
-
-??
-??
-
-?
-??
-?
-??
-?????
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-???
-???
-
-?
-?
-?
-?
-
-
-?
-
-?
-??
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-???
-???
-??
-???
-?
-?
-?
-??
-??
-
-????
-????
-????
-
-?
-
-
-
-
-
-
-?
-
-
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-
-
-
-
-
-??
-
-?
-
-
-
-
-
-
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-?
-?
-?
-
-
-
-
-?
-?
-??
-???
-???
-???
-
-?
-?
-?
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-
-
-?
-??
-???
-?
-
-
-
-
-
-???
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-????
-??
-??
-?
-?
-???
-?
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-
-
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-
-?
-???
-?
-?
-?
-?
-
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-
-
-??
-??
-??
-??
-??
-
-
-
-
-?
-
-
-
-
-
-
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-
-
-
-?
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-?????
-???
-???
-??
-??
-???
-???
-?
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-?
-?
-?
-
-
-
-
-??
-??
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-?
-?
-??
-??
-
-
-
-
-
-
-
-?
-???
-?
-
-
-?
-?
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-????
-????
-??
-??
-??
-?
-??
-?
-?
-????
-????
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-???
-???
-???
-???
-????
-???
-??
-??
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-?
-?
-??
-??
-??
-??
-??
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-???
-?
-???
-?
-???
-???
-????
-??
-??
-?
-???
-???
-?
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-????
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-????
-????
-????
-????
-????
-????
-?
-?
-????
-???
-?
-?
-????
-????
-????
-????
-????
-????
-?
-?
-?
-???
-???
-??
-??
-??
-??
-??
-???
-????
-????
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-???
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-????
-????
-?????
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-???
-???
-??????
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-?
-???
-???
-?????
-???
-???
-???
-???
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-????
-????
-?
-??
-?
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?????
-????
-????
-????
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-????
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-?
-??
-??
-????
-??
-???
-???
-???
-???
-????
-?????
-??????
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-???
-???
-???
-???
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-?
-???
-?
-?
-??
-??
-??
-?
-???
-????
-????
-????
-???
-??
-??
-??
-??
-??????
-???
-??
-??
-??
-????
-
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-?
-
-
-
-
-??
-??
-??
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-
-?
-
-??
-?
-?
-?
-??
-
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-?
-?
-
-?
-
-?
-?
-
-
-
-
-?
-?
-
-
-
-
-
-?
-
-
-
-
-
-??
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-?
-?
-??
-??
-?
-???
-?
-?
-?
-?
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-
-?
-??
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-
-?
-?
-?
-?
-
-
-?
-
-
-
-
-?
-?
-??
-??
-??
-??
-??
-??
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-
-
-?
-
-
-
-
-
-
-
-?
-?
-
-
-
-?
-?
-
-
-?
-?
-?
-
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-
-?
-
-
-?
-?
-?
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-
-?
-
-
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-???
-???
-?
-?
-?
-
-
-??
-
-
-
-
-
-
-?
-??
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-?
-
-
-
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-
-
-
-??
-
-?
-
-
-
-
-?
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-??
-??
-?
-?
-?
-?
-?
-??
-????
-????
-????
-?
-?
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-?
-?
-
-
-
-?
-?
-?
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-
-
-
-
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-?
-
-
-
-
-?
-?
-?
-??
-
-
-?
-?
-
-??
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-
-?
-??
-???
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-
-
-
-
-
-
-?
-?
-?
-
-
-??
-
-
-?
-?
-?
-???
-?
-?
-??
-??
-???
-?????
-?????
-?????
-???
-
-
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-??
-??
-??
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-????
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-?????
-?????
-???????
-???????
-???????
-???????
-???????
-???????
-???????
-???????
-???????
-???
-???
-???
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-
-?
-??
-??
-??
-??
-??
-??
-
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-
-?
-?
-?
-?
-?
-??
-?
-
-
-
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-
-
-?
-??
-??
-??
-??
-?
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-?
-??
-?
-?
-???
-??
-??
-??
-??
-???
-
-
-?
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-?
-
-
-
-
-
-
-
-
-???
-???
-???
-?
-?
-?
-?
-
-
-
-
-?
-
-
-
-
-
-
-?
-
-??
-??
-??
-
-
-??
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-??
-
-
-?
-?
-???
-?
-??
-
-
-
-
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-???
-???
-???
-??
-??
-??
-???
-??
-??
-??
-??
-
-??
-??
-?
-???
-???
-???
-
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-?
-??
-??
-??
-
-
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-????
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-
-
-?
-?
-
-
-
-?
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-?
-
-?
-?
-?
-
-
-
-
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-
-?
-?
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-???
-?????
-?????
-???
-
-??
-?
-?
-??
-??
-
-
-
-
-
-
-
-?
-?
-?
-
-?
-?
-???
-
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-
-?
-??
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-
-??
-??
-??
-?
-
-??
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-
-
-
-?
-??
-??
-??
-??
-???
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-?
-?
-??
-?
-??
-??
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-??
-?
-?
-??
-??
-??
-??
-???
-???
-????
-?????
-???????
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-????
-????
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-??
-??
-??
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-????
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?????
-?????
-?????
-?????
-??????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-???
-???
-????
-????
-???
-???
-???
-????
-????
-????
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-??
-??
-??
-??
-???
-???
-???
-????
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-????
-???
-???
-???
-?
-??
-?
-?
-??
-??
-??
-???
-???
-????
-????
-????
-?
-?
-?
-??
-???
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-???
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-????
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-??
-??
-??
-????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-???
-??
-??
-??
-???
-?
-???
-???
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-??
-???
-???
-???
-???
-????
-?????
-?????
-?????
-???
-???
-???
-??
-??
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-????
-???
-????
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-???
-?????
-???
-???
-????
-????
-????
-????
-?????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-??????
-??????
-??????
-??????
-????
-?????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-???
-????
-??
-???
-???
-???
-???
-???
-????
-????
-???
-????
-???
-???
-????
-??
-??
-??
-???
-??
-???
-???
-???
-????
-???
-???
-???
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-???
-???
-????
-????
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-??
-??
-?
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-???
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?????
-???
-???
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-?
-???
-???
-??
-??
-??
-?
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-
-
-
-
-?
-?
-
-
-
-
-?
-
-
-
-
-
-?
-??
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-
-?
-?
-?
-??
-??
-
-
-
-?
-?
-?
-?
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-????
-????
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-
-
-
-?
-
-
-?
-?
-?
-??
-??
-
-
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-??
-??
-???
-
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-??
-
-
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-???
-???
-??
-??
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-????
-????
-????
-????
-????
-????
-??
-??
-???
-???
-??
-??
-??
-????
-??
-??
-????
-????
-????
-????
-????
-????
-?
-?????
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-?
-?
-???
-
-??
-??
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-??
-
-?
-?
-?
-???
-???
-???
-???
-?
-
-
-
-
-
-
-??
-?
-?
-
-
-??
-??
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-??
-?
-?
-
-
-
-
-?
-?
-?
-
-??
-
-
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-???
-???
-??
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-????
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-???
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-????
-???
-????
-????
-????
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-??
-?
-??
-??
-??
-??
-??
-???
-?
-??
-??
-??
-??
-???
-?
-??
-??
-?
-?
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-??
-???
-??
-??
-?
-?
-?
-?
-????
-????
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-?
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-????
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-???
-??
-??
-??
-???
-???
-????
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-?????
-???
-?????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-????
-???
-???
-??
-???
-????
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-????
-?
-?
-?
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?????
-???
-???
-???
-????
-???
-?????
-???
-???
-????
-????
-????
-??
-??
-??
-??
-?
-?
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-??
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-?
-?
-
-??
-
-
-
-
-?
-?
-?
-??
-
-
-
-
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-?????
-??
-??
-??
-??
-?
-?
-??
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-
-?
-???
-
-
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-???
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-???
-???
-???
-???
-?
-???
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-??
-
-??
-??
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-??
-???
-???
-???
-????
-??
-??
-?
-?
-?
-?
-??
-?
-??
-?
-??
-?
-??
-???
-?
-??
-??
-??
-??
-??
-?
-???
-??
-??
-??
-??
-??
-???
-???
-???
-??
-????
-
-
-?
-
-
-
-
-
-??
-??
-
-
-
-
-
-
-?
-?
-
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-?
-??
-??
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-
-?
-?
-?
-
-
-
-
-??
-
-
-
-
-
-?
-?
-?
-
-
-?
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-
-????
-
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-
-??
-
-?
-
-??
-
-
-
-
-
-
-
-
-?
-??
-??
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-??
-???
-??
-???
-??
-????
-????
-??
-?
-???
-?
-??
-??
-??
-?
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-
-??
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-
-
-?
-??
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-????
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-
-
-
-
-?
-
-
-
-
-?
-
-??
-?
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-???
-???
-????
-???
-???
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-
-
-?
-?
-?
-?
-?
-
-
-??
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-
-?
-?
-?
-
-
-
-
-?
-
-??
-
-
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-?
-?
-?
-?
-?
-
-
-
-?
-?
-?
-?
-?
-?
-???
-?
-???
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-
-
-
-
-
-
-??
-?
-?
-
-
-
-
-
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-??
-
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-??
-
-
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-
-
-
-
-?
-?
-??
-??
-???
-???
-???
-???
-???
-?
-
-?
-
-
-
-
-
-
-
-
-
-?
-???
-
-
-
-
-?
-?
-
-
-
-
-??
-????
-?
-??
-??
-
-
-
-?
-?
-?
-
-
-
-?
-??
-???
-?
-?
-??
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-
-
-
-
-
-??
-??
-
-
-
-
-
-??
-?
-??
-??
-?
-?
-?
-?
-
-
-
-
-?
-?
-??
-?
-?
-??
-??
-?
-??
-?
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-??
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-?????
-??????
-?????
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-
-
-
-
-
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-?
-?
-
-
-
-?
-
-
-
-
-
-???
-??
-
-????
-??
-?
-?
-??
-?
-??
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-
-
-
-?
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-
-?
-??
-??
-??
-?
-?
-
-
-
-
-
-???
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-????
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-??
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-????
-?
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-????
-??
-?????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-????
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-?
-?
-?
-?
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-
-????
-???
-???
-???
-
-?
-?
-?
-?
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-???
-???
-
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-??
-?
-?
-??
-??
-??
-??
-??
-????
-??
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-?
-
-?
-?
-
-
-??
-
-
-??
-??
-??
-??
-??
-
-??
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-
-
-??
-
-?
-?
-?
-
-?
-?
-?
-?
-
-
-?
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-
-?
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-???
-?
-
-
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-
-
-
-?
-?
-
-?
-
-
-
-?
-?
-?
-?
-??
-
-
-?
-?
-?
-
-
-?
-?
-?
-?
-
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-??
-?
-
-?
-?
-?
-
-
-
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-
-?
-?
-??
-??
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-?
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-??
-
-
-
-
-
-
-
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-?
-?
-
-
-
-
-
-?
-???
-?
-?
-??
-???
-???
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-?
-?
-??
-???
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-???
-?
-
-?
-
-
-
-?
-?
-
-
-?
-?
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-?
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-?
-
-
-??
-
-
-
-
-
-?
-
-
-
-
-
-?
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-??
-
-
-
-
-?
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-??
-??
-??
-??
-??
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-???
-
-
-?
-??
-??
-????
-???
-?
-?
-?
-?
-??
-??
-
-??
-?????
-?
-??
-??
-?
-??
-????
-?
-?
-?
-???
-???
-?
-???
-??
-??
-?
-??
-??
-??
-???
-???
-???
-???
-?????
-?
-???
-???
-????
-???
-??
-?????
-??
-??
-??
-????
-??????
-??????
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-??
-??
-??
-?
-
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?????
-?
-??
-??
-
-?
-?
-?
-?
-
-
-?
-?
-??
-
-???
-??
-??
-??
-??
-
-
-
-?
-
-?
-??
-
-
-
-
-
-
-
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?????
-?????
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-??
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-
-
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-??
-???
-???
-??
-?
-
-?
-?
-?
-
-
-
-
-
-
-
-??
-?
-??
-
-?
-?
-?
-
-
-
-?
-?
-??
-??
-?
-?
-?
-???
-
-
-
-
-
-
-?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-
-
-
-
-
-
-
-??
-
-??
-???
-???
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-?
-?
-?
-?
-
-
-
-
-
-
-
-
-
-??
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-
-
-??
-???
-?
-?
-
-
-?
-???
-
-?
-
-
-
-
-?
-
-
-
-
-?
-?
-
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-?
-???
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-???
-?????
-????
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-????
-????
-????
-????
-???
-????
-?
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-????
-???
-???
-???
-???
-???
-???
-???
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-?
-???
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-???
-???
-???
-???
-???
-?
-?
-?
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-?
-??
-??
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-???
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-????
-??
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-??
-??
-??
-??
-??
-????
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-????
-??
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-????
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-????
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-?
-??
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-????
-?
-?
-?
-?
-?
-???
-?
-??
-??
-???
-???
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-?????
-???
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-?
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-????
-??
-???
-?????
-?????
-??????
-???????
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-?
-??
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-?
-?
-?
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-???
-????
-????
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-?
-?
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-?
-??
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-????
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-????
-??
-??
-???
-???
-???
-?
-?
-?
-?
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-??
-??
-??
-
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?????
-?????
-??
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-???
-?
-?
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???????
-???????
-???????
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?????
-?
-?
-????
-????
-????
-???
-???
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-??
-???
-???
-??
-???
-????
-???
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??
-???
-???
-??????
-???
-??
-??
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-?????
-???
-???
-????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-??
-???
-???
-???
-?????
-???
-???
-???
-???
-?????
-???????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??
-??
-??
-?
-?
-?
-?
-?
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-????
-???
-????
-?
-???
-?????
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-???
-??
-??
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-????
-????
-????
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-???
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-????
-????
-????
-?????
-????
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-?
-??
-??
-??
-??
-??
-??
-???
-????
-?
-??
-?
-?
-?
-???
-?
-???
-????
-?
-??
-??
-?
-?
-??
-?
-?
-???
-?
-??
-?
-?
-?
-??
-??
-?
-???
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-???
-???
-???
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?
-??
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-??
-??
-????
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-?
-?
-???
-???
-???
-?
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-???
-??
-????
-??
-???
-???
-???
-???
-??
-??
-??
-????
-????
-????
-????
-????
-????
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-????
-??
-??
-???
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-?
-??
-??
-????
-????
-????
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-???
-???
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-???
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-???
-???
-???
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-???
-??
-??
-??
-???
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-????
-????
-????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-????
-???
-???
-??????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-???
-???
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-???
-???
-???
-???
-???
-???
-????
-???
-????
-???
-???
-?????
-???
-??
-??
-??
-??
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-????
-????
-????
-????
-????
-???
-??
-???
-???
-????
-??
-??
-???
-???
-???
-???
-???
-????
-???
-???
-???
-?????
-???
-??
-??
-???
-???
-???
-????
-?????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-????
-????
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-??
-???
-??
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??????
-??????
-??????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-????
-????
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-?
-?
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-????
-????
-?????
-?????
-?????
-?????
-?????
-?
-??
-?
-??
-??
-??
-??
-?
-?
-??
-??
-?
-?
-???
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-?
-?
-?
-?
-?
-??
-???
-????
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-????
-???
-???
-?
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-?
-?
-??
-??
-?
-??
-???
-??
-?
-?
-?
-???
-???
-???
-????
-???
-????
-???
-???
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-?
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-???
-??
-??
-??
-??
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-???
-??
-???
-???
-??
-??
-??
-??
-???
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-?????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-???
-???
-???
-??
-??
-????
-????
-????
-????
-???
-???
-???
-??
-????
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-?????
-??????
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-????
-????
-????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-????
-????
-????
-????
-??????
-??????
-??????
-??????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-???
-????
-????
-????
-?????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-?
-??
-??
-??
-???
-???
-???
-???
-??
-??
-???
-???
-???
-????
-???
-????
-???
-???
-???
-????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-??
-???
-????
-???
-??
-???
-????
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-????
-?????
-?????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??
-?????
-?????
-?????
-?????
-??????
-?????
-??????
-??
-??
-??
-??
-??
-??
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-????
-??
-???
-???
-???
-???
-?????
-?????
-?????
-???
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-????
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-?????
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-??
-??
-?????
-???
-????
-????
-?????
-???
-???
-???
-??
-??
-??
-????
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-?????
-?
-?
-????
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-???
-???
-?
-???
-???
-????
-????
-????
-????
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-???
-???
-????
-????
-????
-????
-????
-???
-?????
-?????
-?????
-?????
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-????
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-????
-????
-??
-??
-??
-??
-???
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-?
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-???
-??
-?????
-??????
-??????
-???????
-?????
-???
-???
-????
-?????
-?????
-?????
-???
-????
-????
-??
-????
-??
-??
-??
-????
-?????
-????
-???
-??
-??
-??
-???
-???
-???
-???
-??
-??
-????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-?????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-??
-???
-???
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-??
-??
-???
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-???
-??
-??
-???
-???
-???
-???
-???
-?
-??
-?
-?
-?
-??
-?
-?
-???
-???
-??
-??
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-???
-????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-??
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-????
-???
-??
-????
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-?
-?
-?
-???
-???
-??
-???
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-???
-???
-???
-???
-?????
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-????
-????
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-???
-???
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-??????
-??????
-?????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-???
-???
-???
-???
-????
-??
-??
-??
-??
-???
-??
-??
-????
-????
-????
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-????
-???
-???
-???
-??
-???
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-?????
-?????
-?????
-???
-????
-????
-????
-??
-???
-???
-?????
-????
-????
-????
-?????
-???
-????
-????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-???
-???
-???
-???
-???
-?????
-???
-???
-????
-??
-???
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-???????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-??????
-???????
-???????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-???????
-???????
-???
-???
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-?????
-?????
-????
-????
-????
-???
-???
-????
-???
-???
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-??????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-??????
-????
-????
-????
-????
-?????
-??????
-?????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???????
-???????
-???????
-?????
-????
-????
-????
-????
-????
-????
-????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-??????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-?????
-?????
-????
-????
-????
-????
-????
-????
-?????
-??????
-?????
-????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-????
-?????
-?????
-?????
-?????
-???????
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-???
-????
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-??
-??
-???
-???
-????
-???
-??
-???
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?
-??
-??
-?
-??
-??
-??
-??
-??
-??
-?
-???
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-???
-????
-????
-????
-????
-????
-????
-?????
-???
-???
-?
-?
-???
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-??
-???
-???
-???
-???
-???
-?
-???
-???????
-???????
-??
-???
-????
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?????
-?????
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-?
-?
-??
-??
-?
-??
-???
-????
-?
-?
-?
-????
-????
-????
-????
-?
-???
-???
-???
-???
-???
-????
-????
-????
-????
-??
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-??
-??
-???
-??
-??
-????
-??
-???
-???
-??
-??
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-??
-??
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-????
-????
-????
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-???
-???
-???
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-????
-???
-???
-????
-????
-???
-???
-???
-????
-?????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-??????
-??????
-??????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-????
-????
-????
-????
-?????
-??
-???
-??
-???
-??
-???
-???
-???
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-??
-???
-???
-???
-???
-???
-????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-??
-???
-???
-???
-????
-???
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-????
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-??
-?
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-??
-????
-??????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-??
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??????
-??????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-????
-????
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-??
-???
-???
-???
-??
-??
-??
-???
-??
-??
-???
-???
-???
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-????
-????
-?
-?
-?
-?
-?
-??
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-????
-????
-????
-???
-???
-????????
-????????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-??
-?????
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-????
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-????
-??
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-??
-??
-???
-?
-?
-?
-?
-??
-??
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-????
-??
-??
-????
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-?
-???
-?
-??
-??
-??
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?
-?
-???
-???
-???
-?
-?
-?
-????
-???
-???
-???????
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-???
-???
-???
-?
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-???
-?
-??
-???
-???
-????
-?????
-?????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-??
-???
-??
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-?????
-???
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-????
-????
-?
-?
-??
-??
-????
-????
-????
-???
-???
-??
-?
-?
-?
-?
-???
-?
-?
-?
-????
-?
-?
-???
-?
-?
-?
-??
-??
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-???
-???
-???
-???
-????
-????
-????
-????
-?
-?
-?
-??
-??
-???
-??
-???
-???
-??
-??
-??
-???
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-??
-???
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-??
-???
-???
-?????
-?????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-?????
-??
-??
-???
-??
-??
-?
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-?
-?
-??
-???
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-????
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-????
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?????
-????
-??
-??
-???
-???
-???
-???
-???
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-???
-?
-?
-?
-?
-?
-??
-??
-?
-????
-?
-???
-???
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-????
-??
-???
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-??????
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-???
-?
-?
-??????
-?
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-???
-??
-??
-??
-??
-????
-????
-????
-??
-??
-???
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-?
-?
-?
-?
-??
-?
-?
-??
-???
-???
-???
-??
-??
-??
-?
-??
-???
-???
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-??
-?
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-??
-??
-???
-???
-??
-??
-??
-?
-?
-?
-?
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-????
-???
-??
-??
-???
-???
-???
-??
-???
-???
-???
-???
-?????
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-??
-??
-??
-???
-???
-??
-??
-??
-??
-????
-??
-??
-??
-??
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-?????
-??
-??
-??
-??
-??
-????
-????
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??????
-??????
-??????
-??????
-???
-???
-???
-?
-?
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-?
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-???
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-???
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??????
-????
-????
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?
-?
-??
-?
-??
-?
-??
-???
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-??
-??
-??
-?
-??
-??
-??
-????
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??????
-??????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-??????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-??
-??
-??
-??
-??
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-????
-??
-??
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-?
-?
-?
-???
-???
-???
-?????
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-?
-??
-??
-??
-?
-?
-???
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-??
-????
-????
-????
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-????
-?
-??
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-?????
-?????
-?????
-?????
-??
-??
-??
-???
-???
-??
-?
-?
-??
-???
-???
-???
-????
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-????
-???
-???
-?????
-?????
-?
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-???
-??
-??
-???
-???
-????
-????
-????
-????
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-????
-??
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-???
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-??
-??
-???
-??
-????
-??
-??
-???
-?????
-?????
-?????
-?????
-??
-???
-???
-???
-???
-??
-??
-??
-????
-??
-???
-???
-???
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-???
-??
-????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-???
-???
-???
-???
-??
-??
-??
-??
-???
-????
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-????
-??
-????
-????
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-?????
-????
-????
-????
-????
-??
-???
-???
-??
-???
-??
-??
-?
-??
-??
-????
-?
-???
-?
-?
-??
-??
-??
-????
-???
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-????
-????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-????
-?
-??
-??
-??
-???
-?????
-???
-?
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-?????
-??
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-???
-????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-??????
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-??
-????????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-????
-????
-????
-?????
-?????
-?????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-????
-????
-????
-????
-????
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??????
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-????
-????
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-????
-????
-????
-????
-????
-????
-???
-???
-??
-??
-??????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-??????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-??
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???????
-???????
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??????
-??????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-??????
-???
-?????
-?????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-?????
-???
-???
-???
-???
-???
-????
-???
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-????
-????
-?????
-?????
-?????
-?????
-??????
-???????
-???
-?????
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-??
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-????
-???
-???
-???
-????
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-???
-???
-??
-??
-??
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-??
-??
-??
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-??????
-??????
-??????
-??
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-????
-????
-?????
-???
-???????
-????
-???
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-???????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-??
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-????
-????
-???
-????
-????
-???
-???
-???
-?????
-???
-?????
-??
-??
-??
-???
-????
-????
-????
-?????
-?????
-?????
-???????
-??????
-??
-???
-??
-????
-??
-????
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-???
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-?????
-??
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-????
-????
-????
-?????
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-?
-?
-?
-??
-???
-???
-???
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?????
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-??
-?
-?
-??
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-??
-?
-???
-???
-?
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-??
-???
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-????
-????
-????
-????
-???
-????
-???
-????
-???
-???
-???
-???
-???
-???
-????
-??
-??
-???
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-???
-??
-????
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???????
-????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-????
-????
-????
-??
-??
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-??
-??
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-??
-?????
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??
-??
-??
-??
-???
-????
-????
-??
-???
-???
-???
-???
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-?????
-?????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-???
-???
-????
-???????
-??????
-???
-????
-??
-??
-????
-?????
-????
-???
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-??
-??
-??
-??
-???
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-????
-????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-????
-???
-???
-?????
-?????
-????
-??????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-?????
-??????
-???
-????
-???
-???
-???
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-??????
-???
-????
-?????
-??
-???
-???
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?????
-??
-???
-??
-??
-???
-??
-??
-??
-????
-???
-???
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-??
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-????
-?????
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-????
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??
-?
-?
-??
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-?
-???
-???
-???
-???
-???
-?
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-????
-????
-????
-???
-????
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-???
-??
-?
-??
-??
-??
-???
-???
-??
-??
-???
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-????
-????
-????
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-???
-???
-???
-???
-???
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-??
-??
-??
-??
-?
-?
-?
-???
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-??
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-????
-??
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-????
-????
-????
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-???
-???
-??
-????
-??
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-??
-?
-??
-??
-??
-?
-?
-?
-?
-???
-?
-?
-?
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-?
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-????
-??
-??
-?
-?
-??????
-??????
-??
-??
-?
-??
-???
-???
-???
-??
-??
-??
-????
-???
-???
-???
-???
-???
-?
-??
-??
-??
-?
-??
-??
-??
-???
-??
-?
-?
-???
-???
-???
-???
-?
-???
-???
-???
-??
-??
-??
-???
-??
-??
-??
-???
-????
-?????
-?????
-?????
-??????
-??????
-??????
-?????
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-???
-???
-???
-????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-?????
-?????
-?????
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-?????
-???
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-????
-?????
-????
-????
-????
-???
-???
-???
-???
-?????
-????
-???
-???
-??
-??
-???
-???
-????
-????
-??
-???
-??
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-???
-????
-??
-???
-???
-???
-???
-???
-????
-????
-???
-??
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-???
-???
-????
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-??
-??
-????
-????
-?????
-?????
-????
-??
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?????
-?????
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??
-??
-??
-?????
-?????
-?????
-????
-????
-????
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-??
-??
-??
-????
-????
-????
-????
-????
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-?????
-??????
-??????
-??????
-??????
-??????
-??????
-?????
-?????
-???
-????
-?????
-???
-????
-????
-?????
-????
-????
-????
-????
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-???
-???
-????
-?
-??
-???
-???
-???
-???
-??
-???
-????
-??
-???
-??
-???
-???
-???
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-?????
-???
-???
-???
-????
-????
-?????
-?????
-??????
-?????
-???????
-?????
-?????
-???
-??
-?
-??
-????
-??
-?
-????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-?
-?
-?
-?
-??
-????
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-????
-????
-???
-???
-???
-??
-??
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-????
-?????
-??
-???
-???
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-???
-???
-??
-???
-????
-????
-??
-??
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???????
-???
-???
-???
-???
-????
-????
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-????
-????
-????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-?
-?
-???
-???
-???
-???
-???
-???
-?
-?
-?
-??
-??
-?
-????
-???
-??
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-?????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-?
-??
-???
-????
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-????
-?
-????
-???
-????
-???
-???
-???
-???
-????
-??
-????
-????
-????
-????
-?
-?
-?
-?
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-?????
-???
-??
-????
-????
-?????
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-???
-???
-???
-??
-??
-???
-????
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-????
-????
-????
-?????
-?????
-????
-????
-????
-?????
-????
-??
-??
-??
-??
-????
-???
-???
-???
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-?????
-?????
-?????
-????
-??
-??
-??
-???
-???
-???
-???
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-??
-??
-????
-????
-?????
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??
-????
-?????
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-????
-????
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-?????
-???
-????
-???
-??
-???
-???
-???
-???
-???
-?
-????
-????
-??
-???
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-????
-????
-???
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-????
-????
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-????
-????
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??????
-??
-??
-??
-???
-???
-??
-??
-??
-???
-????
-??
-??
-??
-??
-????
-????
-????
-????
-????
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-??
-????
-????
-????
-??????
-?????
-???????
-???????
-???????
-??????
-???????
-???????
-?????
-????
-????
-??
-??
-??
-???
-???
-???
-????
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-????
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??????
-??????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-??????
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-????
-????
-????
-????
-????
-????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-??????
-????
-??????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-?????
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-????
-???
-????
-???
-???
-????
-????
-???
-???
-???
-????
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?????
-????
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-???
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-?
-??
-???
-???
-???
-????
-????
-???
-????
-????
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-????
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-???
-???
-?
-???
-???
-???
-???
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-???
-???
-???
-????
-???
-??????
-?????
-??????
-??????
-????
-???
-???
-???
-???
-???
-???
-?????
-??????
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-??
-??
-???
-?
-???
-???
-?
-?
-??
-?
-????
-?????
-??
-??
-?
-?
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-??
-??
-???
-???
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-??
-???
-??
-???
-????
-????
-????
-????
-????
-????
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-??????
-???
-???
-???
-????
-????
-????
-???
-???
-???
-??
-??
-??
-????
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-????
-???
-???
-????
-?
-?
-?
-?
-?
-?
-??
-????
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-??
-??
-????
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-?
-??
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-???
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-??????
-?
-?
-??
-??
-?
-??
-?
-?
-?
-?
-?
-????
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-?
-?
-?
-?
-??
-???
-???
-???
-??????
-??????
-???????
-???????
-???????
-???????
-??????
-?
-?????
-??????
-???
-???
-???
-??
-??
-??
-?
-???
-???
-?
-?????
-??
-??
-??
-????
-????
-????
-???
-??
-???
-???
-???
-????
-?
-???
-?
-?
-???
-???
-?
-????
-?
-?
-?
-?
-???
-???
-??
-?
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-??????
-??????
-??????
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-??
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??
-??
-????
-????
-????
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-????
-????
-??
-??
-?
-?
-?
-?
-???
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-????
-????
-????
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-?
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-???
-????
-???
-???
-???
-???
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-????
-????
-??
-??
-??
-??
-??
-??
-???
-????
-????
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/testUTF8.txt b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/testUTF8.txt
deleted file mode 100644
index 6f2fe32..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/testUTF8.txt
+++ /dev/null
@@ -1,2 +0,0 @@
-???? ? ?  ? ???? ??  ??? ?, ?, ??? ?? ??. ?  ?? ????  ?,  
-? ??? ?????. ??? ? ?, ??? ? ? ? ??,  ?  ????? ?  ?? . ?? ? ?, ?? ? ???? ????? ??? ??? ??? ?? ??  ?? ?????,  ? ??? ?  ?????  ?????? ?.
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/wordsUTF8.txt b/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/wordsUTF8.txt
deleted file mode 100644
index d439f17..0000000
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ru/wordsUTF8.txt
+++ /dev/null
@@ -1,49673 +0,0 @@
-?
-???
-?
-???
-????
-?????
-???
-???
-???
-???
-??
-??
-??
-???
-???
-???
-?
-?
-??
-??
-??
-??
-?
-???
-????
-????
-???
-?
-??
-??
-??
-????
-????
-?????
-??
-??
-
-?
-
-?
-??
-??
-??
-???
-???
-?
-
-?
-?
-
-
-
-?
-?
-?
-??
-??
-????
-?????
-??????
-?????
-??
-
-??
-??
-???
-??
-??
-???
-??
-????
-??
-?
-
-??
-??
-??
-??
-??
-??
-
-?
-?
-?
-
-
-?
-
-
-
-?
-?
-??
-???
-?
-?
-?
-?
-?
-???
-???
-???
-????
-
-???
-??
-?
-?
-?
-?
-??
-??
-??
-???
-?
-???
-???
-????
-?
-?
-?
-??
-??
-???
-???
-??
-?
-?
-?
-??
-???
-
-?
-?
-?
-??
-???
-
-??
-??
-???
-???
-??
-??
-??
-???
-???
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-
-
-
-?
-?
-?
-?
-?
-??
-?
-
-?
-?
-
-
-?
-?
-?
-
-
-?
-?
-
-
-?
-???
-???
-???
-???
-?
-?
-?
-?
-??
-?
-?????
-?
-?
-??
-?????
-??
-
-
-?
-?
-?
-?
-?
-??
-??
-?
-??
-?
-??
-?
-?
-??
-???
-?
-?
-
-
-
-?
-????
-
-?
-
-???
-?
-??
-???
-?
-??
-?
-??
-
-
-?
-
-
-?
-?
-?
-??
-??
-??
-
-??
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-?
-??
-??
-??
-???
-?
-??
-??
-???
-????
-???
-???
-???
-???
-???
-????
-????
-
-
-?
-??
-?
-
-??
-??
-??
-??
-???
-???
-
-
-
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-???
-???
-?
-??
-??
-????
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-?????
-??
-???
-???
-
-???
-??
-??
-??
-??
-??
-?
-??
-????
-??
-?
-???
-?
-?
-??
-??
-????
-?
-??
-?
-??
-??
-???
-???
-?
-???
-??
-??
-?
-??
-??
-???
-????
-????
-????
-??????
-?????
-?????
-?????
-??????
-?????
-??????
-????
-?
-???
-???????
-???????
-????????
-???????
-???????
-????????
-???
-???
-????
-??
-??
-?
-?
-?
-??
-??
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-????
-??
-??
-??
-???
-???
-??
-???
-??
-?????
-????
-????
-????
-?????
-??
-????
-????
-????
-??????
-??????
-????
-????
-????
-????
-?????
-????
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-?????
-?????
-??????
-??????
-??
-??
-??
-????
-?????
-??
-????
-????
-??????
-??
-????
-?????
-???
-???
-????
-????
-???
-??
-???
-??
-???
-??
-???
-???
-????
-?????
-??
-?
-?????
-?????
-?????
-?
-???
-??
-??
-?
-??
-??
-???
-???
-???
-????
-????
-?????
-??
-??
-??
-???
-??????
-??????
-????
-?
-?
-???
-???
-??
-???
-???
-?
-??
-??
-??
-??
-????
-??
-??
-??
-
-
-
-
-
-
-
-
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-
-?
-?
-??
-??
-??
-???
-???
-??
-?
-?
-??
-?
-
-?
-
-?
-?
-?
-
-?
-
-?
-?
-?
-??
-??
-
-
-
-?
-
-
-
-?
-
-??
-?
-?
-?
-?
-
-
-
-
-?
-
-
-
-??????
-
-??
-??
-?
-
-?
-??
-?
-?
-?
-???
-?
-????
-?
-
-
-
-?
-
-
-????
-??
-
-?
-?
-??
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-?
-???
-?
-?
-?
-?
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-????
-???
-??
-???
-???
-???
-?????
-????
-????
-?????
-????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-????
-????
-???
-?
-?
-?
-?
-?
-????
-?
-??
-???
-????
-???
-??
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-???
-???
-???
-?
-?
-?
-??
-??
-?
-??
-??
-?
-?
-??
-
-??
-?
-???
-
-
-??
-?
-?
-??
-
-
-
-
-??
-?
-?
-??
-???
-?
-
-?
-
-?
-?
-??
-
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-????
-
-
-
-
-
-?
-
-?
-?
-?
-???
-
-?
-??
-
-
-
-
-
-?
-??
-???
-????
-?
-??
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-
-
-?
-?
-?
-??
-??
-???
-???
-????
-?
-?
-??
-
-
-
-??
-
-?
-??
-
-?
-
-
-
-
-?
-?
-?
-?
-?
-???
-???
-???
-??
-??
-?
-?
-?
-???
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-?
-???
-????
-???
-??
-???
-???
-??
-??
-?
-
-
-
-
-?
-?
-
-
-?
-
-
-????
-??
-?
-??
-??
-???
-??
-??
-??
-?????
-??
-???
-?
-??
-?
-?
-????
-??
-??
-??
-?
-??
-?
-??
-???
-????
-???
-
-?
-??
-
-??
-??
-?
-???
-??
-?
-????
-??
-?
-??
-?
-
-
-
-?
-?
-?
-?
-??
-????
-??
-??
-??
-?????
-???
-?
-
-
-
-
-??
-???
-?
-
-??
-???
-??
-????
-???
-????
-????
-????
-
-
-
-?
-????
-??
-?
-?
-??
-??
-?
-??
-?
-??
-??
-?
-??
-????
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-???
-??
-???
-??
-???
-??
-??
-???
-???
-???
-?????
-????
-??
-???
-?
-???
-??????
-???
-????
-????
-?????
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-???
-?????
-?????
-??
-???
-???
-????
-??
-????
-?????
-????
-?????
-???
-??
-???
-???
-??????
-????
-????
-
-??
-?
-?
-??
-
-
-?
-
-?
-
-??
-?
-?
-?
-?
-??
-?
-
-
-?
-??
-?
-???
-????
-????
-????
-?????
-????
-????
-?
-?
-
-
-
-???
-????
-???
-???
-???
-???
-???
-
-?
-???
-??
-?
-?
-??
-?
-?
-?
-?
-??
-???
-??
-?
-?
-??
-??
-
-?
-?
-??
-?
-?
-?
-???
-??
-????
-?
-???
-?
-?
-???
-??
-?
-??
-??
-???
-?
-?
-??
-??
-??
-??
-???
-??
-?
-?
-??
-??
-????
-???
-?????
-???
-?
-??
-?
-?
-?
-??
-????
-???
-?????
-??
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-????
-?
-???
-????
-??
-???
-??
-??
-??
-??
-??
-???
-????
-?????
-???
-????
-???
-???
-???
-????
-?????
-?????
-???
-??
-????
-???
-????
-????
-?????
-?????
-????
-???
-??
-??
-??
-????
-?????
-???
-???
-??
-?
-??
-???
-???
-?
-?
-?
-?
-???
-?
-?
-???
-?
-??
-????
-???
-?????
-?????
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-????
-??
-????
-???
-??
-?
-?
-?
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-????
-?????
-???
-????
-???
-???
-???
-?????
-????
-?????
-??????
-???
-??
-??
-????
-???
-???
-???
-?????
-????
-???
-??
-?????
-????
-????
-????
-??????
-?????
-?????
-?????
-??????
-????
-???
-???????
-?????
-???
-????
-?????
-????
-??
-??
-??
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-??
-????
-??
-??
-????
-??????
-?????
-??????
-?????
-????
-????
-???????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-???
-????
-?????
-????
-????
-????
-?????
-????
-???
-????
-??
-???
-???
-????
-???
-???
-???
-??????
-???????
-??????
-??????
-??????
-?????
-????
-????
-????
-?????
-?????
-????
-???
-???
-????
-???
-????
-????
-???????
-???
-???
-???
-????
-?????
-????
-???
-????
-?????
-??
-???
-???
-????
-???
-????
-?????
-?????
-????
-?????
-?????
-?????
-??????
-????
-???
-???
-?????
-?????
-?????
-??????
-?????
-??????
-??????
-??????
-??????
-???
-??
-??
-?
-?
-?
-??
-???
-???
-???
-???
-??
-??
-?
-?
-?
-??
-?
-?
-?
-
-
-?
-?
-
-
-?
-?
-
-
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-
-??
-??
-?
-???
-???
-???
-?????
-????
-
-?
-???
-?
-?
-?
-??
-??
-??
-???
-?
-?
-??
-??
-?
-?
-??
-??
-??
-??
-????
-????
-????
-???
-?
-?
-????
-??
-
-
-
-
-?
-
-?
-
-?
-?
-
-???
-????
-?
-
-
-?
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-?
-?
-???
-????
-????
-?????
-??
-??
-?
-??
-?
-?
-?
-??
-??
-???
-????
-??????
-??????
-??
-?
-?
-??
-??
-
-?
-??
-?
-?
-??
-??
-????
-????
-???
-???
-????
-??????
-??
-???
-???
-???
-??
-????
-?
-?
-??
-?
-???
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?
-?
-??
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-???
-??
-???
-??
-????
-???
-???
-????
-???
-????
-?????
-??
-???
-???
-??????
-???????
-???
-???
-??
-????
-??
-???
-????
-???
-?????
-?????
-???
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-??
-????
-??
-????
-?????
-
-?
-??
-
-
-
-
-?
-?
-
-?
-
-?
-??
-??
-?
-
-
-
-
-
-???
-????
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-????
-??
-??
-???
-??
-????
-????
-????
-?????
-?????
-????
-????
-????
-?????
-??????
-??
-???
-???
-???
-???
-???
-??
-?
-?
-?
-?
-???
-
-
-
-
-
-???
-
-
-
-
-
-?
-
-
-
-
-
-??
-?
-
-??
-???
-?
-
-?
-
-?
-???
-???
-??
-??
-??
-???
-????
-?????
-??????
-????
-????
-????
-????
-
-
-
-?
-
-
-
-?
-?
-?
-???
-??
-??
-?
-?
-???
-??
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-???
-?????
-
-?
-
-
-?
-
-???
-?
-
-
-?
-?
-??
-??
-???
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-??
-???
-????
-?????
-???
-?
-?
-?
-?
-?
-??
-
-
-
-???
-
-?
-
-?
-?
-?
-??
-??
-???
-???
-?
-?
-??
-???
-?
-?
-?
-?
-???
-????
-?????
-???
-???
-?????
-??
-??
-???
-?
-
-
-?
-
-??
-??
-??
-???
-????
-??
-
-
-
-
-??
-???
-?
-?
-?
-?
-?
-??
-???
-???
-????
-
-?
-
-
-
-
-
-
-
-??
-???
-
-
-
-
-?
-
-?
-
-
-
-?
-
-
-
-
-??
-
-?
-
-
-?
-
-
-?
-?
-
-?
-
-
-
-
-
-???
-??
-?
-?
-?
-??
-
-?
-?
-??
-?
-??
-
-
-
-
-
-??
-??
-
-?
-??
-?
-?
-????
-?
-??
-??
-?
-?
-??
-????
-?
-?
-???
-?
-???
-???
-???
-??
-???
-?????
-????
-?
-?
-??
-??
-?
-?
-??
-??
-??
-???
-???
-?
-?
-??
-?
-?
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-???
-??
-??
-??
-??
-???
-???
-????
-??
-??
-
-??
-
-?
-??
-????
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-????
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-???
-?????
-??
-??
-??
-???
-??
-??
-???
-??
-??
-???
-???
-?????
-????
-??
-???
-?
-??
-?
-??
-??
-??
-??
-?
-???
-???
-?
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-????
-????
-?
-?
-??
-?
-??
-???
-???
-???
-???
-???
-????
-?????
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-???
-?
-?
-?
-?
-?
-???
-??
-??
-????
-???
-?????
-??
-??
-???
-????
-????
-???
-???
-???
-???
-????
-??
-??
-??
-???
-??
-???
-??
-???
-????
-???
-???
-???
-???
-????
-????
-???
-???
-???
-?????
-????
-????
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-?
-??
-???
-????
-??
-??
-??
-??
-???
-?
-??
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-???
-?
-?
-??
-??
-??
-???
-???
-??
-???
-??
-???
-??
-???
-?????
-?
-?
-??
-???
-??
-???
-???
-?
-?
-?
-??
-???
-???
-??
-??
-???
-???
-?????
-???
-???
-?
-???
-???
-???
-?????
-?????
-??
-??
-????
-????
-??
-????
-????
-???
-????
-??????
-??????
-??????
-???
-?????
-??
-?????
-??
-??
-????
-??
-????
-??
-????
-????
-??
-???
-?????
-????
-??????
-????
-???
-????
-????
-??????
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-???
-?????
-???
-????
-?????
-?????
-???
-??????
-????
-???
-??
-???
-??
-????
-???
-???
-???
-???
-????
-???
-??
-???
-??
-???
-???
-???
-???
-???
-??
-??
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-?????
-????
-?
-??
-??
-???
-??
-??
-???
-??
-?
-?
-??
-??
-??
-???
-?
-?
-?
-?
-?
-????
-??
-???
-?
-?
-?
-??
-??
-??
-???
-???
-????
-??
-???
-?
-????
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-??????
-?????
-??
-???
-??
-???
-??
-?
-??
-?
-?
-?
-?
-??
-??
-??
-???
-?????
-???
-???
-??
-?
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-???
-?
-??
-?
-?
-?
-??
-?
-??
-??
-??
-????
-????
-??
-???
-???
-???
-????
-??
-??
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-????
-?????
-???
-??
-???
-??
-??
-???
-??
-???
-?????
-??
-??
-??
-???
-????
-????
-????
-???
-???
-????
-??
-??
-???
-???
-???
-???
-???
-????
-????
-????
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-????
-???
-????
-?????
-?????
-???
-???
-???
-???
-????
-????
-????
-????
-???
-??
-???
-??
-????
-??????
-??
-??
-??
-?
-?
-?
-??
-??
-???
-?
-?
-?
-?
-?
-???
-??
-??
-???
-???
-??
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-????
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-??
-?????
-????
-????
-?????
-????
-????
-????
-?????
-?????
-??????
-??????
-?????
-?????
-?????
-??
-??
-??
-??
-??????
-???
-?????
-???
-???
-???
-????
-???
-??
-????
-?????
-????
-???
-?????
-??????
-?????
-??
-???
-???
-???
-???
-????
-????
-??
-???
-???
-
-
-?
-
-
-
-
-
-?
-?
-
-?
-?
-?
-
-
-
-
-
-?
-??
-???
-???
-????
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-
-??
-?
-???
-??
-?
-
-
-??
-???
-
-??
-??
-??
-??
-????
-???
-????
-???
-???
-???
-???
-???
-?????
-
-
-?
-???
-
-
-?
-??
-??
-
-
-?
-??
-?
-?
-?
-??
-??
-??
-???
-?
-??
-??
-???
-?
-?
-?
-?
-?
-?
-???
-??
-??
-???
-???
-???
-?
-??
-?
-???
-?
-??
-???
-??
-??
-??
-???
-???
-????
-??????
-??
-??
-??
-???
-?
-?
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-????
-???
-??
-???
-???
-??
-??
-??
-?
-??
-??
-?
-??
-??
-????
-?????
-??
-??
-??
-????
-????
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-?
-
-?
-
-
-
-
-
-
-???
-???
-??
-???
-??
-??
-??
-????
-??
-???
-???
-??
-?
-
-??
-?
-??
-???
-???
-??
-????
-???
-???
-?????
-????
-????
-??????
-?????
-????
-
-??
-
-
-?
-
-
-
-??
-????
-
-
-
-?
-?
-
-?
-?
-
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-???
-??
-??
-??
-????
-?
-??
-?????
-????
-?????
-??
-??
-????
-????
-?????
-
-
-?
-?
-??
-
-
-??
-?
-?
-?
-?
-
-?
-??
-
-?
-
-
-??
-????
-???
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-
-
-
-??
-???
-?
-?
-
-?
-??
-
-?
-?
-?
-???
-
-
-
-
-?
-
-
-
-??
-??
-
-?
-?
-?
-?
-??
-??
-?
-
-
-
-
-
-?
-
-??
-
-
-
-
-
-
-?
-?
-
-
-
-
-?
-
-??
-???
-???
-??
-???
-??
-??
-???
-???
-???
-????
-
-
-
-
-?
-
-?
-
-
-
-
-
-??
-?
-?
-??
-
-?
-
-??
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-???
-??
-??
-?
-???
-????
-???
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-??
-
-????
-?
-??
-???
-??
-??
-
-
-?
-?
-
-
-
-
-
-
-?
-?
-??
-???
-?
-???
-???
-???
-?????
-???
-?
-?
-?
-???
-??
-?
-??
-?
-?
-?
-??
-???
-??
-?
-??
-??
-???
-??
-?
-?
-?
-??
-??
-????
-???
-???
-?
-??
-?
-?
-?
-??
-????
-???
-?????
-?
-???
-????
-?
-?
-?
-?
-??
-???
-????
-?????
-??
-??
-?????
-????
-????
-????
-????
-?????
-????
-??????
-???
-??
-??
-??
-??
-???
-??
-?
-?
-?
-???
-?
-?
-???
-???
-??
-???
-???
-?????
-??????
-????
-???
-???
-????
-???
-?????
-????
-????
-??
-????
-??
-????
-????
-??
-????
-???
-?????
-??????
-????
-???
-???
-?????
-????
-??
-???
-???
-?????
-????
-??
-???
-????
-????
-????
-????
-???
-???
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-??
-????
-????
-??
-??
-????
-??
-???
-????
-?????
-????
-??
-???
-??
-??
-???
-???
-???
-????
-???
-??
-??
-??
-??
-???
-??
-??
-???
-?
-??
-?
-?
-??
-?
-?
-??
-?
-???
-?????
-?
-?
-?
-?
-???
-????
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-?
-?
-???
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-???
-???
-????
-???
-??
-??
-??
-??
-?
-?
-???
-??
-??
-??
-??
-?
-??
-?
-?
-?
-??
-??
-?
-??
-??
-???
-?????
-???
-???
-??
-???
-??
-???
-??
-??
-???
-??
-??
-???
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-?
-?
-?
-?
-??
-???
-????
-???
-??
-??
-??
-??
-???
-??
-?
-???
-?????
-?????
-?
-?
-?
-??
-?
-???
-?
-?
-??
-??
-?
-???
-????
-?
-?
-??
-??
-???
-??
-???
-?
-?
-??
-??
-
-
-
-
-
-
-??
-???
-????
-?
-?
-?
-??
-?
-
-??
-??
-??
-
-
-??
-????
-???
-??
-?????
-??
-???
-?????
-????
-??
-??
-?
-??????
-??????
-?
-?
-
-
-?
-?
-??
-?
-??
-???
-
-?
-?
-
-
-??
-??
-
-??
-
-
-??
-
-??
-
-
-?
-
-
-?
-??
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-???
-????
-???
-??
-???
-?
-??
-??
-??
-??
-??
-??
-????
-??
-???
-?
-?
-??
-??
-??
-???
-?
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-????
-?
-??
-??
-?
-?
-?
-???
-???
-???
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?
-???
-??
-??
-????
-?
-?
-?
-???
-????
-?????
-???
-??
-??
-????
-????
-????
-????
-???
-??
-???
-?
-???
-?
-??
-??
-
-???
-??
-?
-??
-??
-?
-?????
-?
-?????
-??
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-???
-???
-???
-????
-??
-??
-??
-??
-???
-????
-??
-?
-?
-???
-??
-???
-??
-??
-??
-???
-???
-????
-????
-????
-?????
-????
-????
-???
-???
-?
-??
-?
-?
-???
-?
-???
-?
-???
-???
-??
-??
-???
-???
-???
-???
-???
-????
-???
-?????
-
-
-
-?
-
-
-??
-
-??
-
-??
-????
-?
-
-?
-??
-
-
-
-??
-
-??
-?
-
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-??
-??
-????
-
-?
-
-
-
-
-?
-?
-??
-?
-?
-??
-?
-?
-???
-??
-????
-
-?
-??
-??
-??
-
-
-?
-?
-
-?
-??????
-
-?
-?
-?
-?
-?
-??
-????
-??
-?
-???
-
-
-
-?
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-???
-??
-???
-?
-?
-??
-
-
-??
-
-
-
-?
-?
-
-?
-?
-??
-
-
-
-
-
-?
-???
-??
-??
-?
-?
-
-?
-?
-??
-?
-?
-?
-??
-??
-??
-
-
-
-?
-?
-??
-?
-?
-??
-?
-
-?
-?
-?
-?
-??
-???
-??
-?
-?
-?
-?
-?
-???
-???
-???
-??
-?
-?
-?
-???
-?
-??
-?
-??
-?
-??
-?
-?
-??
-??
-?
-?????
-???
-???
-????
-??
-???
-?
-???
-?
-?
-??
-?????
-??
-??
-??
-??
-??
-???
-???
-?
-???
-???
-???
-?
-??
-??
-?
-??
-??
-??
-?
-??
-??
-??
-???
-???
-???
-?
-???
-?
-?
-?
-??
-??
-?????
-???
-???
-??
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-??
-???
-????
-
-?
-
-
-
-?
-?
-
-
-?
-???
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-????
-????
-??????
-???
-????
-
-?
-?
-?
-??
-????
-????
-??
-??
-??
-??
-????
-???
-???
-???
-??
-
-
-
-?
-?
-??
-
-??
-??
-
-
-
-???
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-???
-???
-??
-??
-
-??
-?
-?
-?
-?
-??
-??
-
-
-
-??
-??
-???
-???
-????
-?????
-?
-?
-?
-?
-?
-?
-???
-????
-??
-??
-??
-??
-??
-????
-?????
-????
-??????
-??????
-?????
-??
-??
-???
-???
-?
-
-?
-??
-?
-
-?
-
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-??
-?
-??
-?
-??
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-??
-???
-???
-
-?
-??
-
-??
-?
-?
-?
-???
-
-
-
-
-
-?
-?
-??
-??
-?
-??
-??
-???
-???
-??
-?
-?
-
-?
-??
-??
-???
-???
-??
-?
-?
-???
-???
-???
-???
-????
-???
-???
-???
-????
-???
-?????
-?????
-?????
-???
-????
-???
-??
-???
-??
-??
-????
-???
-???
-???
-???
-??
-??
-???
-????
-????
-?????
-?????
-????
-??
-??
-??
-???
-
-
-
-?
-??
-?
-??
-
-
-??
-???
-???
-???
-????
-???
-
-?
-
-
-
-??
-??
-?
-???
-??
-??
-
-
-
-?
-
-
-??
-
-
-
-?
-?
-??
-?
-?
-?
-??
-????
-????
-?
-?
-???
-??
-??
-
-
-
-
-?
-??
-?
-?
-?
-??
-?
-
-
-?
-
-
-
-
-
-?
-??
-?
-?
-?
-??
-???
-???
-??
-??
-?
-???
-?
-???
-??
-?
-??
-?
-?
-?
-??
-
-
-
-
-??
-?
-??
-??
-??????
-??
-????
-????
-???
-?????
-????
-??????
-????
-??
-???
-?????
-?????
-?????
-??????
-??
-????
-????
-????
-????
-????
-??????
-?????
-??????
-??????
-?????
-??
-??
-???
-????
-???
-??
-????
-????
-????
-????
-????
-????
-??????
-???
-?????
-???
-???
-?
-??
-?
-??
-??
-????
-
-?
-?
-?
-???
-??
-??
-??
-??
-???
-??
-???
-???
-????
-??
-??
-
-
-?
-??
-????
-
-
-??
-??
-??
-????
-????
-
-???
-
-?
-?
-???
-?
-?
-??
-??
-??
-
-?
-
-
-??
-???
-??
-?
-??
-???
-????
-????
-????
-????
-????
-???
-?????
-?????
-??
-??
-???
-???
-??
-?
-?
-???
-
-
-?
-??
-?
-??
-??
-??
-
-
-?
-
-
-??
-??
-
-
-?
-?
-?
-???
-????
-??
-?
-?
-??
-??
-??
-???
-
-
-
-??
-?
-?
-??
-?
-?
-???
-???
-???
-????
-????
-????
-???
-?????
-????
-???
-???
-????
-???
-???
-?
-??
-??
-??
-?
-?
-???
-?
-??
-??
-????
-????
-???
-?
-??
-??
-???
-?????
-??
-
-
-?
-?
-???
-
-
-?
-??
-
-?
-?
-??
-?
-
-
-
-
-
-
-
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-
-
-?
-??
-
-
-?
-
-
-
-?
-
-
-
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-??
-
-??
-
-??
-
-??
-??
-????
-
-?
-?
-?
-??
-??
-????
-????
-???
-?????
-???
-????
-????
-???
-?????
-???
-?????
-???????
-????
-?
-
-?
-??
-
-
-?
-?
-?
-?
-???
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-?
-??
-??
-???
-?
-?
-??
-???
-?
-?
-?
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-???
-?
-?
-
-
-?
-
-
-
-??
-??
-
-?
-??
-??
-???
-??
-???
-?
-?
-?
-???
-??
-???
-??
-?
-?
-?
-??
-??
-??
-???
-?
-?
-?
-?
-???
-???
-???
-??
-??
-????
-???
-?
-????
-??????
-?????
-??
-???
-???
-????
-??????
-
-
-??
-??
-
-
-
-
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-????
-????
-?????
-?????
-??
-??
-???
-???
-???
-????
-????
-?????
-????
-?
-?
-????
-???
-???
-????
-?
-???
-???
-?
-??
-???
-?
-?
-???
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-??
-?????
-?????
-??
-????
-????
-????
-????
-????
-?????
-?????
-????
-??????
-????
-??????
-??
-??
-??
-????
-???
-???
-?????
-??????
-??
-???
-?????
-??????
-??
-??
-????
-??
-????
-????
-????
-??????
-????
-?????
-???
-?????
-???
-???
-????
-??
-?????
-??
-??
-???
-???
-????
-???
-????
-???
-???
-??
-???
-????
-??
-?????
-????
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-?????
-???
-?????
-???
-???
-????
-????
-?????
-?????
-?????
-???
-???
-?????
-???
-???
-????
-????
-?????
-????
-?????
-????
-?????
-????
-???
-?
-?
-??
-?
-?
-??
-??
-???
-????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-???
-??????
-?????
-?????
-?????
-????
-????
-???
-????
-?????
-????
-????
-??????
-??????
-?
-?
-?
-?
-??
-??
-??
-???
-??
-???
-????
-???
-???
-????
-???
-??????
-????
-???
-?????
-?????
-???????
-??????
-???
-???
-???
-????
-???
-???
-????
-???
-???
-???
-?????
-???
-????
-?????
-?????
-?????
-???
-??
-??
-???
-???
-???
-???
-???????
-???
-???
-???
-????
-???
-???
-???
-??????
-???????
-????
-????
-????
-????
-?????
-???
-????
-????
-????
-???
-???
-????
-????
-????
-????
-??????
-?????
-???????
-???
-???
-????
-??
-???
-????
-??
-???
-???
-??
-?????
-???????
-???
-??
-??
-??
-???
-????
-?
-??
-???
-??
-????
-????
-??????
-????
-???
-??
-???
-??
-??
-???
-????
-?
-?
-?
-?
-??
-??
-????
-?
-?
-?
-?
-????
-?
-?
-?
-
-
-?
-??
-
-
-
-???
-?
-??
-??
-?
-?
-???
-?????
-??
-??
-??
-???
-???
-????
-????????
-??
-???
-??
-??
-??
-??
-??
-??
-?
-
-?
-?
-
-
-?
-???
-
-???
-??
-???
-???
-??
-?
-?
-??
-???
-?
-??
-????
-??
-???
-???
-??
-????
-?????
-?????
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-??
-???
-?
-??
-??
-???
-?
-??
-??
-???
-???
-???
-?
-??
-???
-???
-???
-??
-??
-???
-???
-???
-???
-?????
-????
-??
-?
-?
-?
-???
-?
-??
-?
-??
-??
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-?
-?
-??
-???
-???
-??
-??
-??
-??
-???
-???
-???
-?????
-???
-?????
-??????
-?????
-????
-?????
-????
-??
-??
-?
-?
-?
-??
-???
-???
-????
-?
-??
-??
-??
-????
-????
-?
-????
-??
-???
-?
-?
-???
-???
-?
-??
-?
-??
-???
-???
-??????
-???
-?????
-?????
-?
-?
-??
-????
-???
-??
-????
-??
-??
-?
-??
-??
-??
-??
-???
-??????
-???
-????
-????
-??????
-????
-?????
-??
-??
-??
-??
-?
-?
-???
-??
-???
-??
-??
-????
-????
-???
-????
-?
-??
-?
-?
-???
-??
-?
-?????
-??????
-???
-??
-??
-?????
-??
-??
-??
-???
-????
-???
-??
-???
-????
-???
-???
-???
-???
-???
-???
-????
-?????
-???
-???
-?????
-?????
-?????
-?????
-?????
-????
-?
-???
-???
-??????
-?????
-?????
-???????
-??????
-??????
-?????
-???????
-??????
-???
-???
-???
-???
-?????
-??
-????
-??
-??
-?????
-??
-????
-?
-??
-????
-???
-?
-??
-?
-?
-???
-?
-???
-??
-??
-?
-?
-?
-?
-???
-?
-???
-???
-???
-??
-??
-???
-???
-??
-???
-?
-?
-??
-??????
-???
-????
-????
-????
-???
-?????
-???
-?????
-??
-??
-????
-????
-?????
-???
-????
-???
-???
-?????
-????
-????
-????
-????
-????
-????
-??????
-???
-???
-????
-????
-??
-??
-???
-??
-??
-??
-????
-???
-??
-????
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-???
-???
-????
-???
-????
-???
-????
-????
-????
-???
-????
-???
-????
-???
-???
-?????
-????
-????
-????
-??????
-?????
-???
-?????
-?????
-????
-??????
-??????
-??????
-??????
-???????
-????
-???????
-?????
-???????
-????
-????
-????
-??????
-??????
-??????
-??????
-?????
-?????
-???????
-??????
-????????
-??????
-?????
-????????
-????
-????
-????????
-???????
-??????
-?????
-???????
-??????
-????
-????
-??????
-????
-??????
-??????
-??????
-??????
-????????
-?????
-?????
-???????
-??????
-????????
-???????
-????
-????
-??????
-????
-????
-????
-?????
-?????
-?????
-?????
-??????
-?????
-??????
-??????
-??????
-????????
-????????
-??????????
-????
-???
-????
-?????
-????
-???
-?????
-????
-???
-???
-?????
-???
-?????
-?????
-???
-????
-???
-???
-?????
-????
-????
-???
-???
-?????
-????
-??
-??
-????
-??
-???
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-????
-????
-?
-??
-??
-????
-??????
-???
-???
-??
-???
-?????
-???
-????
-??
-??
-??
-??
-??
-????
-??????
-????
-???
-???
-????
-??
-??
-?????
-???
-??
-????
-????
-???
-?????
-???
-???
-?
-???
-?
-????
-???
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-???
-??
-???
-???
-???
-???
-????
-?????
-??
-???
-???
-????
-??
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-?????
-??
-???
-??
-?
-?
-???
-???
-??
-??
-????
-?
-??
-?
-??
-?
-?
-?
-??
-???
-???
-???
-????
-???
-??
-???
-???
-??
-????
-??????
-???
-????
-???
-???
-??
-???
-?????
-??
-???
-??
-??
-??
-??
-????
-??
-??
-?????
-??????
-????
-??????
-????
-???
-???
-????
-????
-???
-?????
-????
-?????
-????
-??
-???
-??
-??
-???
-?
-??
-???
-??
-??
-??
-?
-?
-?
-?
-???
-???
-?????
-?????
-???????
-???
-??
-??
-??
-???
-?????
-??????
-??
-?
-?
-?
-?
-?
-???
-?
-?
-???
-??
-???
-???
-???
-???
-???
-??
-????
-??????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-?
-?
-??
-???
-????
-???
-??
-??
-??
-????
-????
-??????
-???
-??
-??
-??
-??
-????
-????
-????
-?
-?
-??
-?
-?
-?
-?
-?
-???
-??
-??
-???
-??
-????
-???
-??
-?
-???
-?
-???
-???
-??
-???
-???
-??
-??
-??
-?
-?
-???
-?
-?
-??
-???
-?????
-???
-???
-?????
-??????
-??
-?
-??
-?
-????
-???
-???
-??
-??
-??
-??
-????
-???
-??
-???
-????
-???
-???
-???
-????
-???
-???
-???
-????
-??
-??????
-??
-??
-???
-????
-??
-??
-??
-????
-??
-???
-????
-??
-??
-???
-??
-???
-???
-?????
-????
-?????
-??
-???
-?
-??
-?
-??
-???
-?
-??
-??
-?
-?
-???
-???
-??
-??
-??
-????
-?
-???
-???
-??
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-??
-???
-????
-???
-???
-???
-????
-??
-????
-??
-???
-???
-???
-?
-?
-??
-???
-??
-??
-????
-????
-?????
-????
-????
-???
-???
-??
-??
-????
-?
-?
-??
-??
-???
-?
-??
-???
-??
-??
-?
-?
-???
-??
-????
-????
-????
-??
-????
-??
-??
-??
-????
-??
-???
-?
-???
-???
-??
-??
-???????
-??
-??
-????
-??
-???
-???
-????
-????
-?????
-?
-?
-?
-???
-?
-?
-??
-??
-???
-??
-??
-??
-??
-????
-?????
-????
-???
-?
-????
-???
-?
-?
-?
-??
-???
-??
-???
-?
-???
-?
-?
-??
-????
-??
-?
-???
-???
-???
-?
-??
-??
-??
-??
-????
-???
-???
-????
-????
-????
-????
-????
-??????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-?
-???
-??
-???
-??
-??
-??
-????
-????
-???
-???
-???
-????
-???
-??
-??
-??
-??
-??
-??
-????
-???
-????
-????
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-????
-????
-??
-??
-?
-???
-?
-??
-??
-????
-???
-????
-??
-??
-?
-?
-?
-??
-??
-????
-????
-??
-???
-?????
-????
-??
-??
-??
-??
-??
-???
-???
-???
-?
-?
-?????
-??
-??
-?????
-???
-???
-??
-??
-????
-?????
-??
-???
-???
-????
-?????
-????
-????
-??????
-?????
-?????
-??????
-?????
-???????
-??
-?????
-???
-????
-???
-????
-?????
-????
-???
-????
-????
-????
-????
-?????
-??????
-??????
-???????
-??????
-???
-???
-???
-???
-????
-????
-????
-????
-???
-??????
-????
-?????
-??
-???
-????
-???
-????
-???
-?????
-?????
-?????
-????
-?????
-???????
-???????
-??????
-??????
-???
-???
-?????
-?????
-??
-??
-????
-??
-??
-????
-????
-????
-??????
-???
-??
-??
-??
-???
-???
-????
-??
-???
-???
-????
-??
-??
-????
-????
-??
-????
-????
-?????
-????
-????
-?????
-?????
-????
-??????
-????
-??????
-?????
-????
-??????
-?????
-????
-??????
-??
-??
-????
-??
-????
-????
-????
-??
-????
-??????
-?????
-???
-??
-??
-????
-??
-??
-???
-??
-??
-???
-???
-???
-???
-????
-?????
-????
-?????
-?????
-????
-?????
-????
-????
-????
-?????
-????
-??????
-??????
-?????
-???
-?????
-?????
-???????
-????
-????
-????
-??
-??
-????
-???
-????
-??
-??
-????
-??
-????
-???
-?????
-???
-?????
-??
-????
-????
-????
-????
-????
-??????
-????
-??????
-???
-?????
-???
-?????
-?????
-???????
-????
-??????
-???
-????
-????
-???
-???
-????
-?????
-???
-???
-??????
-??
-????
-???
-???
-???????
-????
-?????
-?????
-?????
-????
-????
-??????
-????
-????
-????
-??????
-?????
-??????
-?????
-??????
-?????
-??
-???
-????
-???
-??
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-????
-???
-???
-????
-????
-????
-???
-????
-???
-????
-????
-???
-????
-????
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-?????
-?????
-????
-???
-???
-???
-?????
-???
-????
-???
-????
-????
-???????
-????
-??????
-??????
-????
-????
-????
-????
-????
-??????
-??????
-?????
-?????
-????
-??????
-????
-??????
-??????
-?????
-?????
-?????
-????
-????
-????
-??????
-????
-????
-??????
-??????
-????
-?????
-????
-???
-???
-???
-????
-???
-????
-?????
-?????
-????
-???
-???
-???
-????
-?????
-????
-????
-????
-????
-???
-?????
-????
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-???
-???
-???
-?????
-????
-?????
-????
-????
-?????
-????
-??
-?????
-???
-???
-????
-?????
-???
-???????
-????
-?????
-????
-????
-????
-??????
-????
-???
-???
-???
-???
-???
-?????
-?????
-???????
-????
-????
-???
-???
-???
-???
-?????
-????
-??
-??
-??
-??
-????
-???
-????
-????
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-????
-????
-????
-????
-???
-??
-????
-?????
-??????
-????
-???
-???
-??
-??????
-??????
-???
-???
-????
-?????
-?????
-?????
-????
-?????
-????
-?????
-??
-???
-???
-???
-?????
-??
-????
-???????
-??
-???
-???
-???
-??
-????
-??
-??
-??
-??
-???
-??
-????
-?????
-?????
-????????
-????
-??
-??
-??
-??
-??
-??
-??
-?????
-?????
-??????
-??
-?????
-?
-?
-??
-???
-??
-?
-???
-???
-??
-??
-?
-?
-?
-??
-??
-??
-??
-???
-????
-
-
-
-
-?
-??
-??
-???
-???
-???
-????
-
-
-
-
-?
-??
-??
-?
-??
-
-
-
-
-
-??
-
-
-???
-???
-??
-
-
-
-?
-
-
-?
-?
-?
-??
-?
-??
-?
-???
-??
-?
-??
-??
-
-?
-
-??
-
-
-?
-?
-?
-??
-??
-???
-?
-???
-
-
-?
-?
-????
-???
-???
-???
-???
-????
-??
-
-???
-?
-?
-??
-
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-???
-??
-????
-????
-?
-???
-???
-?
-?
-?
-?
-??
-??
-??
-???
-????
-????
-???
-?????
-?????
-?
-????
-?
-
-
-
-??
-?
-?
-?
-
-
-
-???
-
-??
-?
-??
-?
-?
-??
-???
-?
-?
-??
-??
-???
-???
-?
-???
-??
-??
-??
-
-
-
-??
-??
-????
-???
-???
-??
-??
-???
-?
-?
-???
-??
-???
-???
-????
-????
-?????
-??
-?
-??
-??
-??
-????
-?
-??
-??
-?
-?
-??
-?
-??
-???
-??
-??
-??
-?????
-??
-??
-???
-?
-???
-
-?
-?
-?
-??
-??
-
-
-?
-??
-?
-??
-???
-
-??
-??
-
-
-
-??
-??
-??
-?
-??
-??
-???
-?
-??
-???
-??
-??
-??
-???
-??
-???
-
-
-
-?
-??
-?
-?
-?
-??
-
-
-
-
-?
-??
-?
-?
-?
-??
-
-?
-?
-
-
-??
-
-
-?
-??
-
-
-
-????
-
-??
-?
-??
-?
-
-
-
-
-?
-
-
-?
-???
-?
-?
-
-
-
-
-?
-?
-?
-?
-???
-?
-???
-??
-
-
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-?
-?
-??
-??
-?
-???
-?
-?
-?
-?
-?
-??
-??
-?
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-???
-???
-???
-???
-???
-???
-??
-????
-?
-?
-??
-?
-?
-??
-???
-??
-??
-??
-??
-?
-??
-???
-?
-?
-?
-?
-??
-???
-???
-???
-????
-????
-?????
-????
-?????
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-???
-???
-?
-?
-???
-?
-?
-?
-???
-?
-???
-??
-??
-????
-???
-??
-??
-????
-???
-???
-??
-????
-??
-??
-??
-??
-??
-???
-
-
-
-??
-
-
-???
-??
-????
-
-
-???
-?
-?
-
-?
-
-
-
-???
-
-?
-?
-??
-??
-?
-??
-?
-?
-??
-
-
-
-
-??
-?
-?
-??
-??
-??
-??
-??
-???
-?????
-???
-???
-???
-???
-????
-
-??
-?
-?
-?
-?
-??
-??
-???
-????
-?
-?
-?
-?
-???
-??
-?
-??
-??
-????
-???
-?????
-???
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-?
-?
-??
-??
-?
-?
-
-
-
-
-?
-
-
-
-?
-???
-??
-????
-
-?
-
-
-?
-?
-
-?
-?
-?
-????
-?
-??
-
-
-??
-??
-?
-
-
-
-
-?
-
-
-
-?
-
-
-
-
-?
-??
-?
-??
-
-??
-?
-?
-??
-?
-
-
-
-?
-
-
-
-
-?
-?
-?
-??
-?
-
-?
-?
-?
-?
-?
-?
-????
-?
-?
-?
-?
-??
-???
-??
-??
-???
-?
-???
-???
-?
-?
-?
-?
-??
-???
-???
-??
-??
-??
-??
-???
-??
-???
-????
-??
-?
-?
-?
-?
-?
-??
-?
-???
-
-?
-?
-???
-????
-
-
-
-
-
-
-
-
-
-?
-??
-?
-?
-??
-??
-????
-????
-?
-???
-??
-???
-
-?
-?
-?
-?
-?
-?
-??
-???
-?????
-?
-?
-??
-?
-???
-???
-???
-????
-?????
-?
-?
-?
-?
-??
-???
-????
-????
-?????
-??
-??
-??
-??
-??
-??
-???
-????
-?????
-???
-?
-?
-???
-??
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-???
-???
-???
-?????
-?????
-???
-??
-???
-????
-????
-?
-??
-??
-???
-??
-??
-???
-?????
-??
-?
-?
-?
-??
-?
-?
-???
-?
-??
-???
-?
-???
-???
-???
-???
-???
-??
-????
-?
-??
-??
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-?
-??
-??
-?
-?
-??
-??
-?
-?
-???
-??
-??
-??
-??
-????
-??
-???
-?
-??
-??
-??
-??
-????
-???
-??
-???
-??
-??
-??
-?????
-?????
-??
-???
-??
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-???
-??
-??
-??
-???
-????
-??
-??
-??
-???
-???
-???
-???
-???
-??
-???
-???
-?????
-????
-???
-???
-????
-??????
-????
-??????
-???
-???
-???
-?????
-?????
-???
-???
-?????
-??????
-????
-???????
-???
-???
-???
-????
-?????
-???
-??????
-?????
-???
-???
-???
-???
-???
-??
-????
-?????
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-??
-???
-?
-???
-??
-??
-??
-????
-???
-???????
-??????
-??????
-??
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-????
-??
-???
-??
-???
-???
-???
-???
-????
-????
-??
-??
-????
-????
-????
-???
-????
-???
-????
-???
-????
-???
-???
-???
-???
-????
-??????
-?????
-??????
-??????
-???????
-?????
-????
-????
-?
-?
-?
-??
-????
-????
-?
-?
-???
-?
-???
-???
-??
-????
-????
-???
-?????
-????
-????
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-????
-???
-?????
-?????
-?????
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-???
-???
-????
-?
-?
-??
-???
-???
-???
-????
-??
-?
-?
-??
-??
-???
-??
-??
-???
-??
-???
-??
-??
-?????
-???
-????
-???
-??
-?
-?
-??
-?
-??
-???
-??
-??
-??
-???
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-???
-???
-??
-??
-????
-????
-???
-???
-???
-?
-??
-??
-??
-?
-?
-?
-??
-?
-???
-???
-??
-????
-???
-???
-??
-?????
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-????
-??
-???
-????
-??
-??
-????
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-????
-????
-????
-??
-???
-??
-??
-??
-?
-?
-?
-??
-?
-??
-??
-?
-??
-?
-??
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-???
-??
-????
-???
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-?
-??
-???
-?
-??
-??
-????
-???
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-??
-???
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-?
-?
-?
-??
-????
-??
-??
-?????
-?????
-????
-???
-???
-??
-??
-??
-??
-???
-????
-??
-??
-??
-???
-??
-????
-???
-????
-???
-????
-??
-???
-???
-??
-??
-??
-??
-????
-?????
-?????
-??????
-???
-???
-???
-???
-???
-????
-??
-???
-??
-??
-???
-??
-???
-????
-??
-???
-???
-???
-????
-??
-??
-??
-???
-??
-??
-???
-????
-????
-????
-?????
-??????
-?????
-????
-????
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-??????
-?????
-??????
-?????
-??????
-???
-???
-???
-????
-???
-??
-??
-??
-??
-????
-????
-????
-????
-????
-????
-????
-?????
-???
-??
-??
-???
-??
-??
-??
-??
-????
-???
-????
-???
-???
-???
-???
-????
-???
-???
-????
-???
-???
-?????
-???
-???
-?
-?
-?
-?
-??
-????
-????
-????
-????
-??????
-?????
-??
-??
-???
-???
-???
-???
-???
-????
-???
-???
-?
-?
-??
-???
-????
-?????
-???
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-????
-???
-???
-?
-?
-?
-???
-??
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-????
-????
-???
-????
-????
-???
-?
-??
-?????
-???
-??
-?
-?
-?
-???
-??
-??
-???
-??
-???
-??
-??
-???
-???
-????
-????
-??
-??
-????
-????
-????
-???
-???
-?????
-????
-????
-????
-????
-???
-???
-??
-?
-
-
-
-
-?
-
-
-??
-
-??
-??
-?
-
-?
-?
-?
-?
-??
-?
-??
-???
-???
-?
-?
-
-
-?
-??
-
-
-
-
-?
-?
-?
-?
-?
-??
-???
-
-?
-??
-?
-??
-??
-
-?
-??
-?
-?
-???
-
-
-?
-
-
-??
-
-
-
-
-?
-
-
-
-?
-
-
-
-
-??
-?
-
-??
-
-??
-??
-?
-?
-?
-??
-??
-??
-??
-???
-???
-??
-???
-??
-?
-?
-??
-??
-??
-???
-??
-??
-
-
-
-
-?
-
-
-?
-?
-???
-??
-?
-?
-
-
-
-?
-??
-?
-
-?
-?
-?
-?
-?
-?
-?
-???
-?
-???
-?
-?
-?
-?
-??
-???
-?
-??
-??
-??
-???
-???
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-?
-??
-
-??
-???
-?????
-????
-???
-???
-????
-?
-
-??
-??
-??
-????
-???
-???
-????
-??
-?
-??
-?
-??
-??
-??
-???
-??
-??
-???
-??
-???
-?
-???
-
-??
-
-??
-??
-??
-??
-??
-??
-????
-??
-?
-???
-
-
-
-
-?
-?
-??
-?
-?
-??
-???
-?
-???
-????
-??
-?
-??
-????
-??
-????
-????
-?????
-???
-???
-?
-???
-???
-????
-???
-?????
-
-??
-
-
-?
-?
-
-
-?
-?
-??
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-????
-??
-??
-??
-??
-?
-??
-?
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-??
-???
-???
-????
-???
-??
-?
-??
-????
-??????
-??????
-??????
-??
-???
-?????
-????
-???
-????
-????
-
-??
-??
-?
-???
-
-
-??
-
-
-??
-????
-??
-
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-???
-
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-???
-?
-?
-??
-???
-????
-?
-???
-??
-?????
-?????
-??
-??
-???
-???
-???
-?????
-??
-?
-
-
-?
-
-
-?
-??
-??
-??
-?
-?????
-???
-??
-??
-??
-?????
-????
-????
-????
-??????
-???????
-????????
-?????
-?????
-?????
-??????
-???
-????
-??????
-??
-??
-????
-????
-?????
-?????
-????
-?
-??
-???
-??
-?
-??
-??
-??
-
-???
-???
-???
-????
-??
-??
-???
-
-
-
-?
-?
-???
-??
-
-?
-
-
-??
-
-??
-??
-?
-
-
-??
-??
-?
-?
-???
-??
-??
-?
-???
-
-?
-?
-?
-??
-??
-?
-???
-??
-??
-??
-
-??
-??
-?
-?
-?
-
-?
-???
-????
-
-
-??
-?
-?
-??
-
-??
-?
-?
-?
-??
-??
-??
-??
-???
-??
-?
-
-
-
-
-
-
-
-?
-????
-
-
-
-?
-?
-
-
-
-??
-
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-???
-???
-????
-???
-???
-???
-???
-????
-?
-??
-??
-?
-?
-???
-??
-?
-?
-?
-?
-???
-??
-??
-??
-???
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-?
-?
-??
-????
-??
-??
-???
-???
-???
-????
-???
-??
-??
-???
-????
-???
-???
-???
-???
-????
-?
-??
-?
-??
-?
-?
-???
-?
-???
-???
-??
-???
-?????
-?
-?
-???
-??
-??
-????
-???
-??
-?
-?
-?
-??
-?
-?
-?
-???
-?
-???
-???
-???
-????
-????
-?????
-?
-?
-??
-??
-??
-??
-??
-????
-?????
-???
-???
-??
-??
-??
-????
-?????
-???
-?????
-??????
-???
-???
-????
-???????
-??????
-???
-???
-???
-???
-???
-???
-?????
-????
-????
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-??
-??
-????
-??
-???
-?
-?
-???
-??
-??
-??
-????
-???
-?????
-??????
-???????
-????
-????
-????
-??
-??
-????
-???
-???
-
-?
-
-
-
-
-
-
-
-?
-?
-?
-
-??
-??
-??
-???
-????
-???
-?
-
-
-??
-?
-?
-?
-
-?
-???
-??
-?
-
-
-
-
-
-
-
-
-
-??
-???
-?
-?
-???
-??
-???
-??
-??
-?
-?
-?
-
-?
-???
-??
-???
-???
-?????
-??
-?
-?????
-???
-????
-??
-????
-?
-?
-????
-??
-??
-??
-??
-??
-??
-??
-?
-
-?
-
-??
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-??
-
-?
-???
-?
-????
-??
-??
-??
-???
-
-
-?
-
-
-
-
-
-
-?
-??
-
-
-
-?
-
-
-?
-?
-?
-?
-??
-
-
-
-
-????
-????
-
-??
-??
-????
-????
-??
-??
-????
-???
-???
-????
-????
-??
-??
-????
-?
-?
-???
-?????
-??
-?
-?
-?
-??
-?
-??
-???
-?
-??
-????
-?
-??
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?
-?
-??
-?
-??
-?????
-?????
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-??
-?
-?
-?
-???
-???
-??
-???
-???
-??
-?
-???
-???
-???
-????
-????
-???
-??
-??
-?
-??
-?
-?
-?
-?
-
-
-?
-
-
-
-???
-????
-?????
-?
-???
-???
-?????
-??
-??
-??
-??
-??
-??
-????
-?????
-??????
-???
-???
-??
-??
-?????
-???
-??
-????
-????
-????
-???
-???
-??
-
-
-?
-??
-??
-?
-
-?
-?
-??
-??
-??
-???
-???
-???
-?????
-???
-????
-???
-???
-???
-???
-??
-??
-????
-????
-
-
-?
-
-
-???
-???
-????
-????
-??
-??
-
-
-
-???
-?
-?
-???
-??
-?
-?
-???
-???
-???
-???
-??
-?
-???
-???
-??
-??
-??
-?
-?
-??
-?
-?
-
-???
-???
-????
-
-
-??
-?
-
-
-?
-???
-
-???
-??
-??
-????
-
-?
-?
-
-
-??
-???
-????
-
-
-?
-??
-??
-?
-?
-?
-?
-
-
-?
-
-??
-???
-
-???
-??
-????
-???
-????
-???
-
-
-??
-????
-
-
-??
-?
-????
-????
-???
-???
-?????
-??
-????
-
-?
-??
-?
-??
-?
-??
-?
-
-?
-?
-?
-
-
-
-
-
-
-????
-????
-????
-????
-??
-??
-??
-????
-?
-?
-???
-???
-
-??
-?
-
-
-?
-??
-
-?
-??
-?
-???
-??
-
-
-
-?
-?
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-???
-??
-????
-??
-???
-
-
-
-?
-
-
-
-
-
-?
-
-
-
-
-?
-???
-?
-
-???
-
-?
-
-?
-
-?
-
-
-?
-???
-?
-
-
-
-
-??
-??
-???
-?
-?
-
-
-
-
-?
-
-?
-?
-
-
-
-??
-??
-
-?
-?
-?
-??
-?
-?
-
-
-
-
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-???
-
-?
-
-
-
-
-?
-
-
-?
-?
-
-
-?
-??
-??
-?
-????
-???
-???
-?
-
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-??
-?
-
-????
-
-?
-?
-???
-???
-???
-????
-???
-??
-??
-?????
-??
-?
-?
-?
-??
-?
-??
-???
-???
-????
-??
-?
-
-?
-??
-?
-???
-??
-???
-????
-??
-??
-????
-????
-?????
-??
-??
-???
-??
-??
-????
-??????
-??????
-??
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-????
-????
-???
-???
-???
-???
-???
-????
-?????
-???
-?????
-??
-????
-?????
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-??
-?
-??
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-??
-???
-???
-??
-???
-???
-?
-?
-?
-?
-?
-?
-???
-?
-???
-?
-?
-??
-??
-??
-???
-???
-???
-???
-????
-?????
-???
-?
-??
-??
-??
-??
-??
-????
-????
-????
-??????
-??
-??
-???
-????
-????
-???
-???
-?????
-??????
-???????
-???
-?????
-??
-??
-??
-????
-??
-????
-????
-???
-?????
-????
-???
-????
-??????
-???
-???
-?????
-????
-????
-?????
-????
-????
-??????
-???????
-??
-????
-??
-??
-??
-????
-??
-??
-???
-????
-???
-???
-????
-?????
-??
-????
-??
-???
-??
-????
-????
-????
-????
-????
-????
-?????
-???
-??
-???
-??
-??
-??
-???
-???
-????
-????
-???
-?????
-?????
-???
-???
-???
-???
-????
-?????
-??????
-??
-???
-????
-??????
-?
-?
-???
-?????
-?????
-?????
-???
-???
-????
-???
-?????
-????
-???
-??
-??
-??
-???
-????
-?
-?
-?
-?
-?
-?
-??
-?
-??
-???
-??
-??
-???
-??
-?
-??
-??
-????
-????
-????
-???
-??
-??
-????
-???
-???
-?????
-?
-?
-?
-??
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-??
-??
-?????
-???
-???
-???
-????
-???
-?
-?
-??
-?
-?
-?
-?
-??
-??
-???
-???
-??
-???
-?
-?
-?
-?
-??
-?
-?
-???
-???
-?
-??
-??
-??
-???
-??
-??????
-??????
-??
-???
-?????
-??
-???
-??
-?
-?
-????
-?
-?
-?
-???
-?
-?
-?
-?
-??
-???
-?
-???
-??
-????
-???
-??
-???
-???
-???
-???
-?????
-??
-??
-??
-???
-??
-???
-???
-??
-???
-????
-?
-?
-???
-??
-?
-?
-?
-??
-???
-????
-??
-??
-??
-??
-?
-??
-??
-???
-??
-???
-????
-?
-?
-?
-?
-??
-??
-???
-???
-??
-???
-??
-??
-????
-?
-?
-??
-??
-???
-?
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-????
-?????
-????
-?????
-?????
-??
-????
-????
-???
-??
-??
-??
-??
-??
-??
-????
-???
-??
-????
-????
-????
-????
-?????
-???
-?????
-??????
-??
-???
-???
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-????
-???
-?????
-????
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-????
-?
-??
-?
-?
-?
-??
-??
-???
-?
-??
-?
-?
-?
-???
-?
-???
-??
-??
-???
-????
-??
-??
-??
-?
-?
-??
-??
-??
-??
-??
-??
-???
-????
-??
-???
-?
-??
-??
-??
-??
-???
-???
-???
-???
-????
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-??????
-?????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-????
-????
-???
-???
-???
-???
-???
-???
-???
-?????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-????
-????
-???
-????
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-???
-???
-????
-????
-?????
-?????
-??
-???
-????
-???
-??
-??
-?????
-?????
-?????
-?????
-???
-???
-????
-??
-??
-???
-??
-??
-??
-???
-???
-????
-??
-??
-???
-???
-??
-???
-???
-???
-?
-?
-?
-???
-???
-????
-?
-?
-?
-??
-??
-???
-?
-??
-???
-?????
-??
-??
-???
-??
-??
-???
-???
-???
-????
-????
-????
-????
-??
-???
-???
-??
-??
-??
-??
-??
-???
-????
-??
-???
-?????
-????
-??
-???
-??
-??
-??
-??
-???
-?????
-????
-??
-???
-???
-?
-?
-??
-??
-??
-????
-?
-?
-?
-??
-?
-?
-??
-???
-???
-??
-??
-
-
-
-?
-
-
-?
-??
-?
-??
-??
-??
-?
-??
-??
-??
-??
-???
-??
-?
-??
-??
-??
-????
-?
-?
-
-?
-??
-
-
-
-
-?
-?
-?
-??
-?
-???
-??
-?
-?
-???
-
-
-?
-?
-???
-??
-???
-??
-??
-??
-???
-???
-????
-???
-???
-???
-?
-?
-?
-
-
-
-?
-?
-??
-??
-???
-??
-
-
-?
-
-
-
-
-
-?
-?
-??
-
-???
-??
-???
-????
-??
-?
-???
-
-?
-
-
-
-?
-?
-??
-??
-
-?
-??
-
-
-?
-
-???
-???
-??
-???
-??
-
-
-
-
-
-
-
-?
-?
-?
-
-???
-??
-
-?
-?
-??
-?
-??
-
-
-?
-???
-?
-?
-??
-?
-?
-??
-???
-?
-?
-?
-??
-?
-??
-???
-???
-??
-??
-??
-?
-??
-??
-?????
-????
-????
-????
-????
-????
-?????
-???????
-??????
-?????
-??????
-?????
-?????
-?????
-??????
-???
-??
-?
-?
-????
-??
-??
-???
-?
-???
-?
-?
-?
-???
-??
-???
-?
-?
-
-
-?
-?
-?
-
-??
-???
-????
-?
-?
-?
-?
-??
-
-
-
-?
-
-?
-??
-??
-??
-????
-?
-??
-
-
-??
-
-
-
-??
-?
-??
-?
-
-??
-????
-
-?
-
-
-
-
-?
-
-
-
-
-
-
-
-??
-?
-
-?
-?
-?
-??
-??
-??
-
-?
-??
-????
-
-??
-???
-????
-??
-???
-????
-????
-???
-????
-?
-
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-????
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-??
-??
-
-
-
-
-??
-???
-??
-??
-??
-??
-??
-??
-???
-????
-
-
-
-
-??
-
-?
-?
-??
-
-?
-?
-??
-??
-????
-?
-
-
-
-??
-
-
-
-
-
-?
-?
-??
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-
-?
-?
-??
-??
-??
-?
-??
-?
-
-?
-
-???
-
-
-?
-??
-?
-?
-?
-?
-
-
-
-
-?
-??
-??
-???
-?
-??
-???
-??
-??
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-?
-??
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-
-
-
-
-?
-??
-
-
-??
-??
-???
-???
-??
-??
-??
-???
-???
-????
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-??
-????
-
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-???
-??
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-?
-???
-??
-????
-?
-??
-?
-??
-??
-??
-???
-????
-??
-???
-???
-????
-????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-?????
-????
-??
-???
-??
-??
-???
-??
-??
-??
-????
-?????
-??
-???
-???
-???
-???
-?
-??
-
-?
-
-
-?
-
-
-
-?
-?
-???
-??
-
-?
-??
-??
-
-
-
-
-
-??
-?
-?
-?
-???
-???
-??
-???
-??
-???
-????
-?
-?
-?
-??
-??
-???
-?????
-??????
-?
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-?
-??
-?
-?
-?
-?
-??
-?
-?
-
-?
-?
-?
-
-?
-?
-
-?
-
-
-
-??
-?
-?
-??
-
-?
-?
-??
-
-
-
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-
-?
-??
-?
-?
-
-?
-
-?
-?
-??
-??
-???
-??
-??
-???
-???
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-??
-??
-???
-??
-??
-??
-?
-?
-????
-????
-??
-??
-???
-?
-???
-??
-??
-??
-?
-??
-?
-?
-?
-??
-???
-???
-?
-?
-???
-?
-??
-??
-??
-??
-??
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-????
-??
-???
-???
-????
-????
-????
-????
-??
-?????
-??
-???
-
-
-
-??
-?????
-?
-??
-?
-????
-
-
-?
-?
-?
-??
-
-?
-?
-??
-?
-??
-
-
-??
-?
-??
-?
-?
-?
-
-??
-?
-?
-??
-????
-??
-???
-??
-??
-??
-????
-?
-???
-????
-?
-?
-??
-???
-??
-?
-?
-????
-??????
-?????
-????
-??
-??
-???
-????
-?
-?
-
-?
-?
-
-
-?
-????
-???
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-???
-???
-???
-???
-??
-????
-?????
-?????
-??
-?
-?
-?
-???
-????
-????
-?????
-???
-??
-??
-??
-??
-?
-??
-??
-??
-????
-????
-?
-?
-?
-???
-???
-???
-??
-???
-??
-?
-??
-??
-????
-???
-??
-?
-?
-???
-??
-????
-???
-??
-???
-??
-???
-??
-??
-?
-??
-??
-?
-??
-?
-?
-???
-?
-???
-???
-?????
-??
-???
-??
-??
-????
-???
-??
-??
-????
-?
-?
-???
-?
-???
-???
-???
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-????
-???
-???
-???
-?????
-????
-????
-?????
-??
-
-
-???
-??
-??
-
-????
-????
-???
-???
-
-
-
-
-?
-?
-??
-?
-???
-
-?
-
-??
-?
-????
-??
-?
-?
-
-??
-??
-??
-??
-????
-???
-????
-????
-????
-??????
-????
-????
-???????
-??????
-??
-???
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-???
-
-??
-
-?
-
-??
-???
-??
-?
-
-????
-?
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-?
-??
-???
-
-
-
-
-
-?
-
-
-?
-
-
-
-?
-???
-??
-?
-?
-?
-?
-??
-
-??
-
-
-
-
-?
-??
-??
-??
-???
-?
-??
-??
-??
-???
-??
-????
-????
-??
-???
-???
-????
-???
-???
-??
-?
-??
-??
-????
-??
-?
-???
-???
-???
-?
-??
-??
-??
-
-
-??
-
-
-
-
-?
-
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-
-
-
-?
-
-??
-???
-??
-?
-???
-??
-??
-???
-???
-????
-??
-???
-????
-??
-????
-???
-???
-???
-???
-??
-??
-????
-???
-??
-??
-??
-??
-??
-??
-????
-
-?
-??
-???
-?
-?
-?
-???
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-???
-?
-????
-??
-???
-??
-???
-???
-?????
-????
-?????
-????
-?????
-????
-???
-?
-???
-?
-???
-???
-??
-???
-??
-?
-?
-???
-?
-??
-?????
-?
-??
-?
-???
-???
-???
-????
-?
-?
-?
-?
-??
-???
-??
-???
-????
-????
-????
-?
-?
-??
-?
-?
-?
-
-
-
-??
-?
-
-?
-
-??
-?
-
-
-
-
-?
-??
-?
-?
-??
-?
-??
-?
-?
-??
-?
-??
-?
-??
-????
-
-?
-?
-?
-?
-??
-?
-??
-?
-?
-
-
-
-
-?
-?
-?
-?
-???
-?
-?
-???
-??
-?
-?
-??
-????
-??
-??
-??
-??
-???
-???
-
-
-
-?
-???
-
-
-
-?
-?
-????
-?
-??
-?
-?
-???
-??
-???
-?
-?
-?
-?
-?
-??
-?
-????
-??
-????
-?
-??
-?
-?
-???
-???
-???
-?
-?
-?
-?????
-????
-?????
-??
-???
-??
-??
-??
-??
-??
-????
-????
-?????
-??????
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-????
-????
-????
-??????
-??????
-?????
-????
-???
-??
-??
-??
-????
-?
-???
-????
-??????
-?????
-??????
-????
-????
-??????
-?????
-??????
-????????
-?????
-?
-??
-?
-?
-?
-
-
-
-
-?
-?
-?
-?
-???
-
-
-
-??
-??
-??
-
-??
-??
-
-??
-
-?
-??
-????
-
-?
-
-?
-
-
-??
-??
-?
-
-
-
-?
-?
-??
-?
-??
-???
-??
-?????
-??
-????
-???
-?
-?
-??
-
-
-??
-??
-??
-???
-???
-?
-??
-??
-??
-???
-?
-?
-?
-???
-???
-??
-???
-????
-????
-???
-???
-???
-???
-?
-???
-???
-???
-?????
-???
-????
-?????
-???
-?
-??
-??
-
-?
-?
-??
-
-?
-?
-?
-
-??
-?
-???
-??
-?
-???
-??
-????
-?
-?
-?
-?
-
-
-
-?
-??
-?
-?
-?
-???
-???
-
-?
-????
-???
-
-???
-?
-?
-?
-?
-????
-????
-???
-???
-???
-?
-?
-?
-??
-???
-?
-??
-????
-?
-
-
-?
-?
-?
-???
-??
-???
-
-
-
-
-?
-
-
-
-
-
-
-?
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-???
-???
-?
-???
-???
-?????
-??
-????
-????
-???
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-????
-???
-
-??
-?
-?
-???
-??
-
-
-
-
-
-
-
-?
-??
-???
-?
-??
-?
-?
-?
-??
-
-?
-??
-
-?
-?????
-????
-????
-????
-??????
-??
-???
-???
-???
-?
-
-??
-?
-??
-????
-????
-???
-????
-?
-?
-??
-?????
-????
-????
-???
-??
-??
-??
-???
-????
-???
-???
-????
-??
-????
-?
-???
-??
-???
-??
-????
-????
-???
-?????
-?????
-???????
-?????
-????
-??
-???
-????
-??
-??
-??
-????
-???
-?????
-??
-??
-????
-??
-????
-???
-???
-???
-????
-????
-????
-?????
-???
-????
-???
-?
-?
-?
-????
-????
-????
-??
-???
-????
-??
-??
-??
-????
-??
-??
-??
-??
-???
-???
-???
-?????
-??
-?????
-??
-????
-????
-???
-???
-??????
-
-
-?
-?
-?
-
-
-
-???
-??
-????
-
-
-
-??
-?
-
-??
-?
-?
-?
-???
-
-
-??
-??
-????
-????
-???
-???
-
-?
-??
-???
-
-??
-??
-??
-??
-?
-?
-??
-??
-??
-
-
-
-
-?
-
-
-
-
-?
-??
-?
-
-
-????
-?
-
-?
-????
-?
-???
-??
-????
-???
-????
-
-?
-?
-??
-??
-?
-?
-?????
-??
-?
-???
-??
-???
-?
-????
-????
-????
-??
-????
-?
-?
-
-
-??
-?
-?
-?
-
-??
-??
-??
-?
-?
-?
-??
-???
-?
-???
-??
-????
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-??
-??
-?
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-?
-?
-??
-??
-??
-?
-??
-???
-???
-??
-??
-??
-????
-???
-?
-?
-?
-?
-???
-?
-?
-??
-??
-??
-??
-????
-?????
-????
-???
-???
-???
-???
-????
-????
-???
-??
-???
-??
-?
-?
-??
-???
-??
-????
-????
-????
-???
-?
-??
-?????
-?????
-?
-???
-???
-
-??
-?
-?
-?
-???
-???
-???
-??
-
-
-
-?
-??
-????
-????
-???
-???
-??
-
-?
-
-
-
-
-??
-???
-?
-?
-?
-??
-???
-?
-??
-??
-???
-??
-??
-????
-???
-???
-?
-???
-?
-??
-?
-???
-?
-?
-???
-???
-????
-???
-??????
-??
-???
-??
-??
-????
-??
-????
-????
-???
-????
-??
-??
-???
-?
-??
-??
-????
-??
-??
-????
-??
-???
-???
-???
-?????
-?
-???
-?
-???
-?
-?
-?
-?
-?
-??
-?
-?
-??
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-???
-???
-????
-
-??
-???
-
-
-??
-
-??
-
-??
-???
-??
-????
-?
-???
-????
-?????
-
-
-?
-???
-??
-??
-?????
-???
-???
-??
-??
-?
-??
-??
-?
-?
-???
-???
-?
-???
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-???
-???
-???
-???
-?????
-
-?
-?
-??
-
-?
-??
-??
-???
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-?
-?
-???
-??
-?
-??
-?????
-?
-?
-
-?
-?
-????
-??
-??
-???
-???
-????
-
-
-
-?
-???
-?
-?
-???
-?????
-?
-???
-?
-???
-??
-??
-???
-??
-??
-????
-???
-????
-????
-??
-????
-?
-??
-
-????
-???
-
-??
-??
-??
-????
-???
-???
-?
-???
-???
-??
-???
-?????
-?
-???
-?
-??
-?
-??
-???
-?
-?
-??
-?
-?
-?
-??
-??
-?
-???
-?
-???
-???
-???
-????
-????
-???
-????
-???
-???
-??
-?
-?
-??
-
-
-
-
-
-?
-??
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-?
-??
-?
-??
-???
-??
-???
-?
-?
-?
-?
-???
-??
-????
-?
-??
-?
-??
-???
-???
-?
-???
-
-?
-??
-
-?
-?
-??
-
-??
-??
-
-??
-?
-
-
-
-?
-??
-?
-??
-
-
-?
-?
-?
-??
-??
-???
-?
-???
-???
-???
-?
-????
-??
-??
-??
-????
-???
-???
-??
-??
-???
-???
-??
-??
-????
-????????
-?????
-??
-?????
-???
-????
-??
-???
-??
-??
-??
-????
-???
-??
-????
-?
-?
-??
-???
-???
-??
-????
-???
-???
-?????
-???
-??????
-????
-??
-???
-???????
-????
-??????
-???
-??????
-????
-???
-???
-????
-??
-??
-?
-?
-?
-??
-???
-??
-??
-???
-???
-?????
-????
-???
-??
-????
-?????
-???
-???
-???
-??
-????
-????
-????
-??
-??
-?
-???
-???
-?????
-??
-?
-??
-??
-?
-?
-?
-???
-?
-??
-????
-???
-????
-??
-??
-???
-??
-?
-?????
-????
-???
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-??
-?
-???
-??
-??
-??
-??
-?
-???
-???
-???
-???
-???
-???
-?????
-?
-??
-???
-?
-???
-??
-???
-???
-???
-??
-????
-?????
-??
-???
-????
-????
-???
-???
-????
-??????
-???
-???
-??
-??
-??
-??
-???
-?
-?
-?
-??
-????
-??
-???
-??
-??
-??
-??
-????
-????
-??
-?????
-?????
-?????
-?????
-?????
-?????
-???????
-???
-?
-??
-?
-?
-?
-???
-?
-???
-????
-?
-???
-??
-??
-??
-??
-???
-???
-???
-???
-??
-?
-???
-???
-???
-????
-??
-??
-???
-??
-??
-??
-???
-??
-???
-?????
-???
-????
-???????
-????
-???
-?????
-?????
-????
-????
-????
-??????
-??????
-??
-??
-???
-??
-??
-??
-????
-??
-??
-??
-??
-????
-???
-???
-????
-?
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-???
-????
-??
-???
-?????
-????
-???
-???
-???
-????
-?????
-????
-??
-???
-???
-????
-??
-??
-??
-??
-???
-????
-???
-???
-????
-????
-??
-????
-???
-????
-????
-????
-???
-???
-???
-?????
-??????
-????
-??
-???
-??
-??
-?????
-??
-???
-?????
-??????
-??????
-???
-?????
-?????
-??????
-??????
-???????
-??????
-????
-?????
-???
-???????
-???
-???
-??????
-???????
-???
-????
-????
-????
-?????
-?????
-???
-???
-????
-?????
-?????
-?????
-???
-???
-????
-????
-?????
-?????
-?????
-???????
-???
-???
-???
-???
-???
-????
-????
-?????
-???
-??
-??
-???
-???
-????
-??
-???
-?????
-??
-?
-????
-????
-????
-?
-????
-??
-????
-??
-??
-??
-??
-??
-????
-????
-?????
-???
-????
-??????
-?????
-????
-????
-???
-?
-??
-???
-?
-?
-??
-?
-?
-?
-???
-????
-????
-???
-????
-??????
-???
-????
-????
-???????
-??
-????
-??
-??
-????
-??
-????
-??
-????
-??
-??
-??
-???
-???
-?????
-??
-?
-????
-????
-?
-?
-?
-?
-???
-?
-?
-???
-???
-???
-?????
-????
-????
-?????
-??
-???
-???
-????
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-?????
-???????
-??????
-??????
-??????
-???????
-????
-??????
-??????
-???????
-??
-????
-???
-???
-?????
-????
-????
-??
-??
-??
-???
-???
-??????
-???
-???
-?????
-????
-????
-????
-???
-???
-??
-????
-???
-???
-?????
-???????
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-???
-????
-????
-???
-??
-???
-??
-??
-??
-??
-???
-????
-????
-???
-?????
-???
-??
-??
-??
-????
-?????
-????
-????
-??
-????
-??
-???
-??
-??
-?
-?
-?
-?
-??
-???
-??
-???
-???
-??
-??
-??
-??
-??
-????
-????
-???
-????
-???
-???
-???
-????
-???
-?????
-????
-???
-??
-??
-?????
-??
-??
-?????
-?
-?????
-???
-??
-??
-??
-???
-?
-???
-???
-???
-?????
-??????
-??
-????
-?????
-??
-????
-????
-???
-??
-????
-???
-?????
-?
-??
-??
-????
-???
-?
-??
-???
-?
-?
-?
-?
-??
-????
-???
-????
-?
-?
-??
-??
-??
-???
-???
-????
-??????
-??
-???
-???
-????
-???
-??
-??
-????
-????
-?
-?
-???
-???
-?
-???
-????
-
-
-
-?
-
-
-?
-??
-??
-??
-
-
-
-
-?
-
-
-
-?
-?
-?
-?
-
-
-
-
-?
-
-?
-?
-??
-?
-??
-??
-?
-?
-?
-?
-?
-???
-??
-?
-???
-??
-??
-??
-???
-??
-??
-??
-
-
-
-
-?
-??
-
-
-
-
-
-
-
-
-
-
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-???
-??
-???
-???
-?
-???
-??
-
-??
-
-?
-??
-?
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-?
-?
-????
-???
-?????
-??
-?
-??
-??
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-?
-??
-?????
-?????
-????
-?????
-??
-??
-
-??
-?
-
-
-??
-?
-?
-?
-?
-???
-?
-??
-??
-
-?
-
-?
-?
-?
-???
-??
-
-?
-
-??
-??
-
-
-
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-??
-?
-
-
-
-????
-?????
-?
-
-?
-?
-?
-?
-??
-?
-??
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-???
-??
-??
-?
-??
-?
-?
-??
-?
-?
-?
-??
-???
-???
-???
-?
-?
-
-
-??
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-???
-
-
-??
-??
-?
-?
-??
-?????
-?
-
-?
-??
-?
-???
-???
-????
-????
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-??
-
-?
-?????
-?
-?
-??
-?
-?
-?
-?
-?
-
-???
-
-
-
-
-??
-??
-??
-?
-?
-
-
-
-??
-?
-???
-?
-??
-??
-????
-???
-????
-?????
-???
-???
-??????
-?
-??
-?
-?
-?
-?
-??
-???
-???
-??
-???
-
-
-?
-
-??
-??
-?
-???
-
-?
-?
-?????
-
-
-?
-?
-
-?
-?
-??
-
-?
-
-
-
-
-
-
-
-?
-????
-
-
-
-
-
-?
-??
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-??
-?
-
-
-
-?
-
-
-??
-??
-???
-???
-???
-????
-
-
-?
-??
-?
-???
-????
-??
-?
-
-
-?
-
-
-
-?
-?
-?
-??
-?
-?
-????
-??
-???
-?
-??
-????
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-????
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-?????
-???
-???
-??
-?
-??
-???
-???
-??
-??
-?
-??
-
-
-
-?
-
-?
-?
-?
-?
-
-
-
-?
-?
-??
-
-
-?
-??
-???
-
-
-
-
-
-?
-??
-?
-??
-????
-????
-????
-??
-????
-???
-?
-?
-??
-?
-?
-?
-????
-?
-????
-???????
-??
-??
-???
-????
-???
-??
-??
-??
-???
-?
-?
-?
-?
-????
-?
-??
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-?
-??
-??
-?
-??
-?
-?
-???
-????
-?????
-??
-??
-?
-??
-??
-??
-???
-?
-??
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-????
-???
-????
-????
-??
-???
-??
-???
-?
-?
-?
-????
-??
-
-
-?
-?
-
-
-
-
-
-?
-?
-??
-
-
-
-?
-?
-
-???
-?
-
-
-?
-??
-??
-??
-???
-
-
-
-?
-?
-???
-???
-???
-??
-???
-???
-???
-?
-
-
-?
-
-?
-?
-??
-??
-???
-?????
-?
-??
-?
-?
-?
-?
-??
-?
-???
-??
-??
-???
-???
-???
-????
-????
-??
-?
-??
-?
-???
-?
-???
-????
-???
-??
-?
-?
-??
-?????
-???
-??
-
-
-
-
-
-
-??
-
-
-?
-?
-??
-?
-??
-
-
-
-
-
-?
-??
-
-?
-?
-?
-??
-??
-?
-?
-
-
-
-?
-?
-???
-?
-
-
-
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-???
-????
-?
-??
-
-?
-??
-???
-???
-??
-
-
-
-
-??
-?
-??
-
-
-?
-???
-??
-?
-
-??
-??
-
-?
-?
-
-?
-
-
-
-??
-?
-?
-???
-??
-??
-???
-
-??
-?
-?
-???
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-?
-???
-??
-?
-??
-??
-??
-???
-
-
-
-?
-??
-??
-
-?
-?
-??
-????
-????
-???
-??
-?????
-??
-??
-??
-???
-???
-???
-??
-??
-????
-???
-??
-??
-??
-??
-??
-???
-????
-?????
-???
-????
-???
-???
-???
-???
-???
-????
-????
-?????
-?
-?
-?
-??
-
-???
-
-??
-
-?
-
-??
-
-??
-?
-??
-????
-???
-?????
-???
-??
-?????
-????
-?????
-??
-????
-
-
-
-?
-??
-
-??
-?
-?
-?
-?
-?
-?
-?
-??
-
-
-
-
-?
-?
-?
-??
-??
-????
-??????
-??????
-????
-??
-??
-
-
-?
-
-
-??
-??
-
-?
-??
-??
-????
-???
-???
-????
-??
-
-
-
-
-
-
-?
-?
-??
-?
-?
-???
-????
-??
-??
-???
-????
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-??
-????
-?
-
-?
-?
-
-??
-??
-?
-?
-???
-
-???
-???
-
-??
-??
-?
-?
-?
-??
-?
-???
-?
-??
-
-????
-
-?
-
-
-??
-?
-
-
-??
-??
-
-
-?
-??
-
-????
-???
-
-???
-??
-
-
-
-?
-
-???
-
-??
-
-??
-??
-??
-?
-???
-??
-????
-?
-?
-?
-???
-?
-??
-????
-?
-??
-????
-???
-???
-??
-?
-??
-???
-??
-??
-??
-???
-?
-?
-???
-??
-???
-??
-???
-???
-?????
-?????
-??
-????
-??
-????
-??
-????
-??????
-????
-?????
-??
-???
-??
-????
-???
-???
-?
-?
-?
-
-?
-
-
-?
-??
-?
-
-
-
-?
-??
-???
-??
-?
-??
-??
-???
-??
-???
-
-?
-???
-??
-?
-???
-???
-?
-?
-?
-??
-?
-???
-???
-???
-???
-??
-????
-??
-??
-???
-?????
-??
-??
-?
-?
-??
-?
-?
-???
-??????
-???
-?
-?
-??
-?
-?
-???
-??
-????
-????
-?
-???
-???
-???
-???
-???
-????
-????
-????
-????
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-????
-???
-??
-????
-???
-??
-??
-??
-??
-????
-???
-??
-??
-???
-???
-???
-?????
-?????
-?????
-???
-??
-????
-?
-??
-????
-??
-???
-??
-??
-??
-????
-???
-???
-???
-???
-????
-???
-????
-?
-
-???
-?
-?
-
-
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-
-???
-??
-?
-?
-??
-??
-???
-
-?
-?
-???
-??
-
-?
-
-
-
-??
-
-??
-
-
-
-
-
-
-
-
-
-
-?
-
-?
-?
-?
-?
-?
-
-??
-??
-?
-??
-??
-???
-??
-???
-?
-
-????
-????
-?????
-????
-?
-?
-?
-
-
-
-
-?
-?
-?
-???
-?
-????
-?
-
-
-??
-?????
-
-
-
-
-
-
-?
-????
-???
-???
-???
-????
-????
-????
-????
-?????
-?
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-?????
-?????
-?????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-???
-??
-????
-??
-??
-??
-???
-???
-????
-???
-???
-????
-????
-??????
-???
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-?????
-?????
-???????
-???
-?????
-?????
-???????
-???????
-???????
-????????
-???????
-????
-?
-???
-??
-??
-??
-????
-????
-?
-??
-????
-????
-?
-?
-?
-??
-
-
-??
-??
-???
-????
-???
-?
-?
-?
-??
-??
-??
-???
-?
-???
-???
-????
-?
-??
-?
-???
-??
-?
-?
-??
-??
-??
-?
-?
-???
-???
-?
-?
-??
-???
-?
-?
-?
-??
-????
-???
-????
-???
-???
-????
-????
-?????
-?????
-?????
-??????
-??
-????
-??
-?
-??
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-?????
-??????
-????
-??????
-?????
-?????
-??
-????
-??
-???
-???
-???
-??
-????
-??
-???
-???
-????
-???
-?????
-????
-????
-??
-???
-????
-????
-?????
-?????
-??????
-?????
-??????
-?????
-?????
-?????
-??????
-????
-???
-??
-??
-?
-????
-???
-???
-??
-????
-??
-?
-???
-???
-????
-????
-???
-???
-??
-????
-???
-??
-???
-???
-?
-?
-?
-???
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-???
-?
-??
-?
-?
-?
-???
-???
-????
-??
-??
-???
-???
-????
-???
-?????
-???
-??
-???
-??
-??
-????
-???
-????
-???
-??
-??
-???
-?????
-????
-?????
-?????
-???
-????
-????
-????
-????
-????
-???
-????
-????
-??
-???
-????
-?????
-??
-???
-??
-???
-????
-?????
-???
-??
-??
-?????
-?????
-??
-????
-??
-????
-????
-???
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-??????
-?????
-??
-??
-???
-????
-????
-???
-????
-????
-???
-????
-????
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-??????
-??????
-?????
-????
-????
-????
-??????
-?????
-???
-???
-????
-???
-????
-????
-????
-????
-?????
-????????
-??????
-??????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-???
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-????
-???
-???
-?????
-?????
-??????
-?????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-???
-???
-??
-???
-????
-??
-??
-????
-???
-???
-???
-???
-?????
-?????
-????
-????
-???
-???
-???
-???
-???
-?????
-???
-????
-???
-?????
-?????
-??????
-????
-????
-?????
-??????
-???
-?????
-?????
-?????
-????
-??????
-????
-???
-???
-?????
-???
-???
-????
-??
-??
-??
-????
-???
-????
-???
-????
-???????
-????
-??
-???
-??
-??
-??
-??
-????
-????
-??
-??
-??
-???
-???
-??
-????
-?????
-????
-??????
-???
-???
-?????
-??????
-?
-?
-?
-?
-??
-????
-????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-?
-?
-??
-??
-???
-?
-??
-??
-???
-???
-???
-??
-??
-?
-??
-??
-
-??
-
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-??
-??
-
-?
-???
-??
-
-
-
-
-??
-
-?
-??
-?
-
-
-
-
-?
-?
-?
-??
-?
-?
-?
-?
-???
-???
-????
-??
-???
-????
-??????
-????
-???
-
-
-??
-??
-??
-??
-??
-?
-??
-?
-??
-??
-????
-?
-??
-?
-?
-
-
-
-??
-?
-??
-?
-
-
-??
-?
-
-
-
-?
-?
-??
-?
-?
-?
-??
-??
-???
-???
-????
-??
-
-
-?
-
-
-
-?
-
-
-
-
-?
-?
-
-
-
-
-?
-?
-???
-???
-?
-??
-
-??
-?
-?
-?
-?
-??
-
-
-
-
-?
-??
-??
-?
-?
-
-?
-?
-?
-??
-??
-?
-??
-?
-
-
-?
-??
-???
-?
-
-
-
-?
-??
-?
-?
-??
-?
-??
-??
-?
-?
-?
-
-
-
-
-
-?
-?
-?
-??
-?
-?
-?
-??
-
-??
-??
-??
-??
-??
-
-
-
-
-?
-?
-
-
-?
-??
-??
-?
-?
-?
-??
-?
-?
-
-?
-?
-
-???
-?
-??
-??
-
-??
-?
-?
-???
-?????
-?????
-??????
-????
-????
-????
-?
-
-?
-?
-??
-??
-??
-???
-????
-?
-?
-????
-?
-?
-??
-??
-???
-??
-??
-??
-???
-???
-?
-?
-??
-
-
-
-?
-
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-????
-?
-??
-??
-?
-??
-??
-???
-???
-???
-????
-????
-?
-???
-????
-?
-?
-??
-??
-??
-??
-??
-???
-??
-??
-????
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-?
-??
-???
-?
-??
-???
-??
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-?
-????
-?
-?
-???
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-????
-??
-??
-???
-???
-????
-????
-????
-???
-???
-????
-???
-???
-???
-???
-??
-???
-???
-???
-????
-????
-?????
-????
-????
-???
-???
-???
-?????
-?????
-?????
-??????
-????
-?
-???
-?
-????
-????
-?????
-?????
-?????
-????
-????
-?
-?????
-?????
-?????
-?????
-??????
-?????
-?
-?
-??
-??
-??
-???
-???
-???
-???
-?
-?
-???
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-????
-???
-??
-??
-???
-?????
-???
-???
-???
-???
-??
-??
-??
-??
-??
-?
-?
-??
-??
-????
-?
-?
-?
-?
-???
-??
-?????
-??????
-??
-?
-???
-???
-???
-???
-????
-???
-??
-????
-????
-?
-?
-??
-?
-?
-?
-??
-???
-??
-??
-???
-???
-????
-???
-???
-???
-???
-??
-??
-???
-?????
-???
-???
-??
-??
-??
-???
-???
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-????
-???
-???
-????
-????
-?????
-?????
-???
-????
-????
-?
-?
-??
-??
-??
-?
-???
-?
-??
-
-??
-???
-?
-
-??
-?
-?
-?
-?
-?
-?
-???
-
-
-??
-????
-???
-
-
-
-?
-
-???
-???
-
-?
-?
-?
-?
-???
-???
-???
-??
-??
-???
-???
-?????
-?
-?
-??
-???
-???
-
-
-
-
-??
-?
-??
-???
-??
-??
-??
-????
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-????
-???
-?
-??
-??
-?
-??
-??
-??
-?
-?
-??
-??
-??
-??
-???
-????
-???
-??
-??
-??
-??
-?
-???
-??
-?
-?
-?
-??
-?
-?
-
-
-?
-?
-??
-??
-?
-?
-?
-?
-
-??
-
-?
-??
-?
-
-
-????
-????
-???
-???
-???
-?????
-?????
-????
-??
-??
-???
-??
-???
-??
-???
-?
-?
-?
-?
-??
-??
-??
-???
-
-???
-?
-
-
-?
-??
-?
-
-?
-?
-?
-?
-?
-??
-???
-???
-?????
-?
-??
-
-
-??
-
-
-
-?
-?
-???
-?
-?
-?
-???
-
-
-?
-??
-???
-??
-
-
-
-?
-
-?
-???
-
-??
-??
-
-???
-?
-???
-????
-
-
-
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-?
-?
-???
-???
-??
-????
-???
-?
-????
-??
-????
-??????
-??
-???
-??
-??
-??
-???
-
-
-
-
-
-?
-
-
-
-??
-???
-?
-
-??
-
-
-?
-
-
-
-?
-
-?
-?
-
-
-
-?
-??
-??
-??
-??
-??
-???
-???
-?
-??
-???
-??
-??
-?
-??
-??
-?
-??
-??
-???
-??
-??
-
-
-?
-?
-?
-??
-??
-??
-????
-
-?
-?
-???
-??
-???
-???
-????
-
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?????
-
-
-?
-?
-??
-??
-???
-?
-
-
-?
-
-
-?
-
-
-
-
-
-
-?
-
-??
-?
-
-
-?
-??
-??
-???
-?
-
-?
-
-?
-??
-?
-???
-???
-??
-????
-???
-???
-???
-???
-????
-
-
-??
-?
-??
-?
-??
-?
-?
-???
-???
-
-??
-
-?
-???
-????
-????
-?
-???
-
-
-
-
-
-?
-
-
-
-?
-
-
-??
-?
-
-??
-??
-?
-?
-?
-??
-?
-?
-?
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-
-???
-???
-???
-
-?
-?
-?
-?
-???
-??
-??
-
-?
-?
-
-
-?
-
-
-
-
-?
-??
-??
-??
-???
-??
-??
-??
-??
-???
-
-??
-??
-
-
-
-?
-??
-??
-??
-?
-???
-??
-??
-????
-???
-?????
-????
-??
-????
-?????
-
-
-
-
-
-?
-?
-?
-??
-???
-?
-??
-????
-??????
-?????
-?
-?
-??
-??
-??
-??
-???
-????
-?
-??
-??
-???
-?
-??
-??
-??
-??
-???
-???
-???
-????
-
-
-
-?
-?
-??
-?
-
-?
-?
-??
-?
-
-?
-?
-?
-?
-??
-
-
-??
-???
-???
-???
-??
-??
-????
-?
-
-?
-???
-????
-?
-?
-?
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-?
-??
-??
-
-
-
-?
-
-?
-
-
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-?
-???
-???
-???
-???
-??
-
-
-?
-???
-
-???
-??
-???
-??
-???
-
-
-?
-?
-??
-
-?
-???
-????
-????
-??
-??
-?
-??
-????
-??
-???
-???
-???
-????
-????
-?????
-?????
-?????
-??
-??
-???
-??
-??
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-???
-??
-???
-??
-??
-???
-???
-??
-???
-??
-????
-?????
-??????
-??
-???
-??????
-??????
-?
-?
-??
-?
-??????
-??????
-???
-???
-????
-???
-?
-?
-??
-??
-????
-???
-???
-???
-???
-????
-???
-??
-?????
-?
-?
-?
-?
-???
-?
-?
-?
-?
-?
-?
-???
-?
-???
-???
-???
-?
-??
-????
-???
-?????
-???
-??
-?
-?
-??
-??
-???
-???
-?
-??
-????
-??
-??
-???
-???
-?
-?
-??
-
-?
-
-
-
-
-
-?
-
-?
-?
-
-
-?
-??
-????
-?
-
-??
-???
-??
-??
-??
-??
-?
-??
-??
-??
-?
-??
-?
-?
-??
-?
-??
-??
-??
-???
-???
-??
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-???
-?
-???
-?
-??
-?
-??
-???
-?
-??
-??
-???
-?????
-?
-?
-?
-??
-??
-??
-??
-????
-?
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-??
-??
-?
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-???
-??????
-????
-?????
-????
-??
-???
-???
-????
-??
-???????
-?????
-???
-???
-???
-???
-??
-?
-?
-?
-?
-??
-????
-???
-??
-?
-???
-????
-?????
-????
-?????
-?????
-????
-????
-????
-??????
-?
-???
-????
-?
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-???
-???
-????
-??
-??
-??
-??
-???
-??
-???
-???
-????
-??
-????
-???
-?????
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-????
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-?
-???
-???
-????
-?
-?
-?
-?
-??
-???
-??
-?
-?
-?????
-???
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??????
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-???
-????
-?????
-???
-?
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-???
-???
-???
-????
-???
-??
-??
-??
-??
-???
-??
-????
-??
-??
-??
-??
-????
-???
-???
-???
-???
-????
-??
-??
-????
-????
-????
-????
-????
-???
-????
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-????
-??
-??
-???
-???
-???
-?????
-????
-???
-????
-???
-??
-???
-????
-????
-????
-????
-??
-??
-??
-??
-???
-????
-????
-?????
-????
-????
-???
-????
-???
-???
-???
-???
-???
-????
-????
-??
-??
-???
-???
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-??
-??
-???
-????
-????
-????
-???
-???
-???
-??
-??
-??
-???
-??
-???
-??
-??
-??
-???
-???
-???
-????
-??
-????
-???
-??
-???
-?
-??
-??
-???
-?
-???
-????
-????
-?
-?
-?
-?
-?
-?
-?
-???
-??
-?
-???
-???
-???
-???
-???
-????
-????
-?????
-????
-?????
-??
-??
-??
-????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-?????
-???
-????
-????
-??????
-?????
-????
-?????
-????
-???
-????
-????
-???
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-???????
-???????
-??????
-??????
-???
-???
-????
-??
-??
-??
-?
-???
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-?
-?
-?
-??
-???
-??
-??
-????
-?
-?
-??
-?
-????
-????
-??
-??
-??
-????
-??
-??
-??
-??
-???
-???
-????
-???
-??
-???
-???
-????
-???
-?
-??
-?????
-?
-?
-??
-???
-??
-??
-??
-???
-????
-???
-??
-?
-??
-?
-??
-??
-??
-??
-?
-??
-??
-?
-???
-????
-???
-???
-??
-???
-????
-?
-???
-??
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-?????
-?????
-??????
-???
-???
-????
-???
-?????
-????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-??
-????
-??
-????
-???
-???
-???
-???
-????
-??
-????
-????
-??
-???
-?????
-??????
-?????
-??
-??
-??
-???
-???
-????
-??
-???
-???
-???
-????
-??
-????
-????
-???
-?????
-????
-??????
-???
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-????
-??
-???
-????
-??????
-????
-?????
-?????
-???
-???
-???
-????
-????
-????
-??????
-???
-???
-???
-????
-???
-?????
-??
-??
-??
-???
-????
-???
-??
-????
-??
-??
-??
-???
-???
-????
-????
-????
-????
-?????
-????
-????
-?????
-??
-??
-???
-????
-?????
-???
-????
-????
-???
-????
-???
-???
-???
-???
-????
-????
-??
-??
-??
-???
-???
-????
-???
-???
-??????
-???
-????
-???
-???
-????
-?????
-?????
-?????
-???
-???
-?
-??
-??????
-???
-?
-????
-???
-????
-????
-?????
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??????
-?
-?
-???
-?
-??
-???
-??
-???
-?
-?
-??
-??
-?
-???
-???
-??
-???
-???
-??
-??
-?????
-??
-???
-????
-?
-?
-?
-?
-??
-???
-???
-?
-?
-?
-???
-??
-??
-?
-??
-?
-?
-??
-??
-??
-???
-??
-???
-???
-??
-???
-??
-????
-??
-????
-????
-??
-????
-????
-???
-????
-???
-???
-????
-???
-???
-???
-????
-???
-????
-??
-???
-???
-???
-???
-?????
-???
-????
-???
-???
-????
-????
-?????
-????
-????
-???
-???
-????
-????
-????
-?????
-?????
-???
-???
-????
-????
-??????
-?????
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-????
-???
-????
-?????
-???
-???
-????
-????
-???
-???
-????
-???
-???
-???
-????
-???
-??????
-??
-??
-??
-???
-???
-???
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-????
-????
-???
-????
-???
-????
-??
-??
-???
-?
-?
-
-
-
-
-
-?
-??
-
-
-?
-?
-?
-
-?
-
-
-
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-??
-??
-?
-??
-???
-?
-??
-?
-??
-?
-??
-
-
-?
-
-??
-
-
-?
-??
-?
-?
-??
-
-
-?
-???
-???
-??
-??
-??
-
-??
-??
-??
-???
-
-
-???
-
-
-
-
-
-?
-?
-??
-???
-??
-?
-?
-?
-??
-??
-
-
-
-
-
-
-?
-?
-
-?
-???
-??
-??
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-?
-?
-???
-?
-????
-??
-??
-???
-?????
-????
-???
-?????
-??
-????
-?
-?
-?
-??
-?
-?
-?
-????
-??
-??
-??
-??
-???
-?
-??
-???
-???
-?
-??
-?
-??
-?????
-????
-???
-??
-??
-?
-?
-???
-
-
-
-?
-
-
-
-??
-
-?
-??
-???
-??
-??
-
-
-?
-
-??
-??
-??
-???
-???
-?
-
-
-
-?
-??
-?
-?
-
-?
-
-
-??????
-
-?
-
-
-
-
-?
-
-??
-??
-
-
-
-
-??
-??
-??
-??
-??
-??
-????
-??
-??
-??
-???
-?
-?
-??
-
-
-
-
-?
-?
-
-?
-?
-?
-?
-??
-??
-
-
-?
-??
-
-?
-?
-?
-?
-?
-?
-??
-???
-
-
-
-
-
-
-?
-
-?
-?
-??
-?
-??
-?
-?
-?
-???
-
-?
-?
-??
-?
-
-
-
-?
-?
-?
-??
-??
-??
-??
-??
-?
-???
-???
-???
-????
-?????
-???
-?
-??
-?
-?
-??
-?
-?
-
-?
-
-
-
-
-?
-
-?
-
-
-
-
-
-?
-?
-?
-?
-??
-??
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-??
-?
-?
-?
-
-
-??
-?
-?
-?
-?
-??
-??
-??
-
-??
-????
-??
-??
-?
-?
-?
-??
-?
-????
-????
-??
-?
-??
-???
-?
-?
-?
-??
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-??
-??
-???
-????
-???
-????
-??
-?
-?
-??
-???
-?
-?
-?
-?
-?
-?
-???
-??
-???
-????
-?
-?
-?
-???
-?
-?
-??
-??
-???
-?
-?
-?
-?
-??
-?
-?
-??
-???
-???
-?
-?
-??
-??
-??
-????
-???
-???
-????
-??
-???
-??
-???
-??
-??
-?
-?
-???
-??
-???
-?????
-?????
-??
-?
-?
-?
-?
-?
-??
-
-
-
-?
-
-?
-?
-??
-??
-???
-???
-
-?
-??
-?
-?
-?
-??
-
-
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-?
-
-
-
-?
-
-??
-??
-??
-
-??
-
-
-??
-?
-
-
-?
-?
-??
-
-???
-
-
-
-?
-
-
-
-?
-?
-?
-??
-???
-
-
-
-
-
-?
-
-?
-?
-??
-??
-
-?
-?
-?
-????
-??
-???
-???
-??
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-?????
-??
-??
-?
-?
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-???????
-??????
-?????
-??????
-??????
-??
-??
-??
-?
-?
-?
-??
-??
-??
-???
-????
-???
-???
-???
-???
-??????
-?????
-????
-????
-?????
-?
-?
-?
-??
-?
-????
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-????
-?????
-???
-??
-??
-??
-???
-??
-?
-?
-??
-?
-?
-??
-??
-?
-????
-?
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-
-
-
-??
-?
-
-
-?
-??
-?
-
-
-???
-??
-?
-??
-??
-???
-?
-??
-
-
-
-
-??
-???
-??
-??
-??
-?
-??
-
-
-
-?
-?
-?
-??
-
-??
-???
-
-
-
-?
-?
-?
-?
-??
-
-??
-??
-??
-??
-??
-???
-???
-????
-
-
-?
-
-
-?
-?
-?
-??
-
-?
-?
-
-?
-?
-??
-?
-?
-?
-??
-??
-???
-
-?
-??
-???
-
-
-?
-
-??
-????
-?
-??
-????
-?
-?
-?
-??
-??
-??
-???
-
-
-?
-??
-
-??
-?
-??
-??
-
-
-
-
-
-
-??
-??
-?
-?
-?
-?
-??
-??
-?
-??
-?
-?
-?
-?
-??
-??
-???
-??
-?
-?
-???
-???
-???
-???
-???
-????
-?????
-???
-?????
-?????
-??
-??
-?
-??
-??
-???
-??
-?
-???
-??
-??
-???
-????
-????
-?????
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-???
-??
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-??
-?
-??
-???
-??
-?
-?
-?
-?
-??
-???
-???
-???
-??
-??
-??
-??
-???
-??
-???
-?
-????
-??
-?
-??
-?
-??
-?
-?
-?
-??
-??
-??
-??
-?
-??
-??
-???
-??
-??
-??
-??
-???
-???
-??
-??
-???
-???
-???
-?????
-?????
-??
-????
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-????
-???
-?
-???
-??
-??
-??
-???
-???
-???
-?
-?
-?
-??
-??
-?
-??
-?
-??
-??
-?
-??
-?
-??
-????
-??
-??
-?
-????
-???
-???
-????
-???
-???
-??
-???
-????
-???
-???
-???
-?
-?
-?
-?
-?
-?
-???
-??
-?
-?
-???
-????
-?????
-????
-??
-??
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-?
-???
-??
-???
-??
-??
-??
-???
-??
-??
-???
-???
-???
-???
-??
-?
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-??
-??
-???
-?
-??
-???
-??
-???
-?
-?
-?
-???
-????
-????
-???
-???
-???
-?????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-???????
-?????
-????
-?????
-??
-???
-???
-???
-???
-???
-???
-?????
-??????
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-???
-??
-???
-????
-??
-??
-???
-?
-????
-??
-??
-???
-????
-?
-?
-?
-????
-?????
-??
-??
-???
-???
-???
-??
-??
-???
-??
-?
-???
-?
-
-
-
-
-
-
-
-
-
-?
-???
-
-???
-??
-??
-??
-?
-?
-?
-
-??
-?
-??
-
-
-?
-?
-
-?
-???
-????
-?
-?
-??
-?
-
-
-
-?
-??
-??
-??
-??
-???
-??
-
-
-?
-?
-?
-??
-?
-?
-??
-
-??
-???
-?
-
-?
-?
-??
-??
-
-
-??
-??
-?
-?
-?
-??
-?
-??
-???
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-
-
-?
-
-
-?
-?
-?
-
-
-
-
-???
-????
-??
-??
-???
-??
-??
-
-
-?
-?
-??
-
-?
-?
-????
-???
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?????
-????
-???
-???
-???
-???
-???
-???
-???
-????
-??
-???
-??
-??
-??
-??
-??
-???
-
-
-??
-??
-?
-?
-?
-?
-??
-??
-
-?
-?
-?
-??
-
-?
-?
-?
-
-
-
-
-?
-?
-?
-??
-?
-?
-??
-??
-?
-??
-
-
-
-
-?
-?
-???
-?
-?
-??
-?
-?
-???
-???
-???
-??
-?
-??
-??
-???
-???
-?
-??
-??
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???????
-??
-??
-??
-???
-???
-???
-?
-??
-??
-?
-?
-??
-?
-??
-??
-???
-??
-?
-?
-??
-???
-?
-??
-???
-???
-????
-??
-???
-???
-???
-???
-??
-???
-????
-????
-????
-?????
-???
-?????
-????
-?????
-????
-????
-????
-???
-?
-??
-??
-??
-???
-?
-?
-?
-??
-??
-?
-??
-??
-??
-?
-??
-???
-????
-????
-?????
-????
-??????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-?????
-????
-????
-?????
-???
-??
-??
-???
-???
-???
-???
-????
-???
-????
-????????
-??
-??
-???
-?
-??
-???
-????
-???
-???
-????
-???
-??
-?
-???
-??
-???
-??
-??
-??
-?
-??
-????
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-?
-?
-?
-??
-?
-???
-??
-??
-??
-?
-??
-?
-?
-?
-??
-??
-??
-?????
-????
-
-
-??
-??
-??
-???
-
-?
-?
-?
-
-
-
-?
-?
-
-
-
-
-?
-?
-?
-
-
-?
-?
-???
-??
-??
-
-
-?
-?
-?
-??
-
-
-
-
-
-?
-?
-?
-??
-
-??
-
-
-?
-??
-??
-??
-??
-?
-
-
-
-
-?
-?
-?
-??
-
-
-
-?
-??
-??????
-?
-?
-
-
-
-
-??
-?
-?
-?
-??
-?
-??
-?
-?
-?
-??
-
-?
-?
-???
-??
-
-?
-?
-???
-???
-???
-???
-??
-?
-?
-?
-??
-
-
-?
-
-
-
-
-?
-
-
-
-
-??
-???
-?
-
-?
-
-?
-??
-?
-?
-?
-??
-???
-???
-??
-???
-??
-??
-???
-??
-?
-?
-???
-?
-?
-???
-???
-???
-??
-???
-???
-???
-??
-??
-??
-????
-?
-?
-??
-??
-??
-???
-??
-???
-???
-????
-??
-?
-
-
-
-??
-???
-??
-??
-??
-??
-????
-??
-??
-????
-?
-??
-????
-????
-???
-?
-???
-???
-??
-???
-????
-?
-?
-?
-?
-????
-????
-????
-????
-?????
-??????
-??????
-??
-???
-?
-?
-?
-???
-?
-????
-?
-???
-????
-?
-?
-??
-??
-???
-?
-?
-??
-??
-??
-?
-??
-??
-???
-??
-???
-???
-???
-???
-????
-????
-????
-???
-??
-??
-??
-??
-???
-????
-???
-???
-???
-????
-????
-??
-???
-??
-???
-???
-????
-????
-??
-??
-?????
-??????
-???
-???
-???
-??
-??
-??
-??
-???
-??
-???
-????
-??
-????
-?????
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-???
-????
-????
-?
-???
-?
-????
-???
-???
-?
-???
-?????
-??
-?
-??
-??
-????
-???
-???
-???
-?
-??
-?
-???
-?
-??
-????
-????
-?
-?
-???
-??
-??
-?
-?
-?
-?
-???
-??
-?
-??
-??
-???
-?
-?
-?
-?
-??
-????
-?
-?
-??
-?????
-???
-?????
-????
-??
-??
-??
-????
-??
-??
-??
-???
-???
-????
-???
-????
-????
-?????
-????
-???????
-???????
-??????
-????
-????
-???
-???
-??
-??
-???
-???
-????
-???
-?????
-??
-????
-???
-?
-??
-??
-????
-?
-??
-?
-?
-???
-?
-???
-?
-???
-?????
-??
-???
-?????
-???
-?????
-??
-????
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-??
-??
-
-
-
-?
-?
-
-
-??
-??
-??
-?
-
-?
-
-??
-?
-???
-
-??
-?
-??
-???
-?
-?
-
-?
-?
-
-
-
-?
-
-?
-?
-????
-?????
-?????
-
-
-?
-?
-
-??
-?
-??
-?
-?
-???
-???
-??
-
-
-
-?
-?
-?
-
-?
-?
-
-??
-
-
-
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-??
-???
-?????
-???
-???
-????
-???
-?
-??
-?
-?
-?
-?
-?
-?
-???
-
-
-
-?
-?
-???
-?
-?
-?
-?
-?
-?
-?????
-?????
-???
-???
-???
-???
-????
-
-
-
-??
-??
-
-??
-??
-
-?
-??
-??
-??
-???
-??
-?
-??
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-????
-???
-???
-???
-???
-??
-?
-???????
-?
-?
-?
-?
-?
-?
-?
-???
-???
-??
-????
-???
-?????
-?
-?
-?
-?
-??
-??
-???
-?
-??
-?
-?
-?
-??
-???
-???
-??
-?
-??
-???
-??
-??
-??
-?????
-??
-??
-???????
-????
-????
-????
-??
-??
-???
-????
-??
-??
-??
-???
-?
-?
-?
-??
-?
-??
-??
-??
-???
-???
-?
-?
-??
-??
-??
-??
-?
-?
-??
-??
-????
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-?
-??
-?
-???
-?
-?
-
-
-
-
-
-?
-?
-?
-?
-??
-?????
-???
-
-
-
-?
-
-
-??
-
-?
-????
-?
-??
-??
-??
-????
-
-?
-??
-????
-??
-?
-???
-????
-??
-??
-???
-???
-????
-??
-?
-??
-??
-???
-??
-???
-??
-???
-???
-????
-???
-?????
-??
-??
-??
-?
-
-
-?
-?
-
-
-?
-
-
-
-
-
-
-
-
-
-?
-?
-?
-??
-?
-??
-??
-??
-
-
-
-?
-??
-??
-??
-??
-??
-???
-??
-????
-??
-
-
-
-??
-??
-?
-??
-
-
-
-?
-?
-
-
-
-
-?
-?
-???
-?
-
-
-
-?
-?
-??
-
-
-
-
-
-?
-?
-
-
-
-??
-?
-
-
-??
-?
-?
-?
-??
-???
-???
-??
-??
-??
-??
-??
-???
-
-
-
-
-?
-
-?
-?
-
-
-
-
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-??
-?
-??
-??
-???
-??
-????
-????
-
-?
-???
-
-
-?
-?
-?
-
-
-?
-?
-
-?
-??
-?
-?
-?
-
-
-
-
-
-?
-??
-???
-?
-??
-?
-??
-??
-?
-?
-?
-?
-??
-
-
-
-
-
-
-??
-??
-???
-
-?
-?
-??
-??
-??
-??
-???
-?
-??
-?
-?
-?
-?
-??
-?
-?
-????
-???
-??
-??
-??
-?
-?
-?
-??
-??
-?
-??
-???
-?
-?
-??
-??
-???
-??
-?
-?
-?
-?
-?
-???
-?
-???
-??
-?
-?
-??
-????
-????
-?????
-?????
-?
-?
-?
-?
-??
-??
-
-?
-??
-?
-??
-??
-??
-
-?
-
-
-
-?
-?
-
-?
-?
-?
-?
-??
-??
-??
-???
-?????
-??
-??
-??
-???
-?
-?
-??
-??
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-??
-????
-??
-??
-????
-?????
-??
-????
-????
-??
-??
-???
-????
-??
-??
-???
-?????
-?????
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-????
-????
-??
-???
-???
-??
-???
-??
-???
-?
-??
-??
-?
-??
-??
-????
-???
-?
-?
-??
-??
-?
-?
-?
-??
-?
-?
-?
-?
-????
-???
-????
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-????
-????
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-????
-??
-???
-????
-????
-????
-????
-??
-?
-??
-???
-??
-??
-???
-???
-???
-???
-???
-????
-??
-????
-??
-??
-?????
-??????
-???
-?
-?
-?
-?
-?
-???
-???
-???
-???
-?????
-??????
-????
-????
-???
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-????
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-?
-??
-??
-???
-???
-????
-???
-???
-???
-????
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-????
-??
-??
-???
-????
-???
-???
-?????
-?????
-??????
-???
-??
-???
-???????
-???
-????
-?????
-????
-????
-????
-?????
-???
-????
-???
-?????
-????
-??
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-????
-????
-???
-???
-???
-?????
-?????
-????
-??????
-??
-????
-???
-????
-???
-???
-?????
-????
-???
-?????
-??
-??
-??
-?????
-???
-????
-???
-????
-?????
-??
-??
-????
-??
-????
-??
-????
-???
-???
-???
-???
-?????
-????
-?????
-??????
-????
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-?????
-??????
-????
-?????
-?????
-????
-??????
-????
-??????
-????
-??
-????
-?????
-???
-????
-??????
-?
-???
-???
-????
-?????
-??
-????
-?
-??
-?
-????
-???
-?????
-??
-?
-?
-?
-?
-???
-??
-??
-???
-??
-??
-???
-???
-????
-?????
-????
-????
-????
-????
-???
-???
-????
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-????
-???
-??
-??
-??
-??
-???
-???
-??
-???
-???
-????
-??
-???
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-???
-????
-?????
-?
-??
-??
-?????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-?????
-???
-???
-???
-????
-??
-???
-??
-
-
-
-?
-?
-?
-
-
-
-??
-???
-
-
-??
-?
-???
-??
-???
-????
-??
-???
-?
-??
-????
-???
-?
-?
-??
-?
-???
-??
-??
-??
-?
-??
-?
-?
-?
-???
-????
-???
-???
-???
-?????
-??
-?
-??
-??
-??
-??
-??
-
-?
-
-?
-??
-??????
-?
-???
-???
-?????
-???
-?????
-?
-??
-????
-???
-?????
-??
-????
-????
-????
-??????
-???
-?
-?
-
-
-
-??
-????
-???
-?
-????
-???
-???
-
-
-
-
-
-
-?
-?
-????
-??
-??
-???
-??
-?
-?
-?
-?
-??
-??
-????
-?
-??
-??
-?
-??
-??
-
-?
-?
-??
-
-
-
-?
-?
-??
-
-?
-?
-
-?
-?
-???
-???
-???
-?????
-?
-?
-?
-?????
-???
-?
-??
-?
-?
-???
-???
-??
-????
-????
-??????
-
-???
-??
-????
-???
-
-
-??
-???
-????
-??
-?
-?
-?
-?
-???
-?
-
-???
-??
-?
-????
-?
-?
-???
-???
-?????
-???
-?
-?
-???
-?????
-
-?
-?
-?
-?
-?
-?
-???
-?
-??
-??
-???
-??
-??
-?
-????
-?
-??
-???
-??
-????
-??
-???
-???
-
-
-?
-??
-??
-???
-???
-
-?
-??
-??
-??
-?
-??
-???
-
-?
-??
-
-
-??
-??
-?
-??
-???
-???
-
-
-
-?
-
-
-?
-?
-?
-?
-?
-???
-
-
-?
-
-
-??
-
-?
-?
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-???
-????
-???
-???
-???
-???
-?????
-???
-????
-???
-???
-?
-????
-?
-?
-
-?
-
-
-
-???
-?
-?
-
-
-??
-
-??
-??
-???
-?
-
-
-
-?
-
-??
-
-
-
-
-
-??
-???
-
-?
-?
-??
-??
-?
-??
-???
-?????
-??????
-???
-??????
-??????
-?????
-????
-?????
-?
-???
-??????
-?
-??
-?
-???
-??
-????
-???
-?
-?
-???
-????
-?
-??
-????
-?
-???
-??
-??
-???
-???
-??
-???
-??????
-
-
-??
-
-?
-??
-??
-
-
-
-??
-
-
-
-
-
-
-
-
-
-
-
-?
-??
-??
-?
-
-?
-??
-
-??????
-??
-?
-???
-?
-???
-???
-???
-??
-?
-?
-?
-??
-?
-??
-???
-??
-?
-??
-?
-?
-???
-??
-?
-?
-??
-
-??
-?
-???
-????
-?????
-?
-??
-?
-?
-???
-??
-??
-??
-??
-????
-???
-?
-?
-?
-???
-???
-?????
-??
-???
-??
-????
-????
-?????
-??
-
-
-?
-
-??
-?
-?
-?
-?
-??
-???
-???
-?
-????
-??
-?
-????
-???
-?
-????
-
-
-
-
-?
-?
-?
-???
-??
-
-?
-?
-??
-????
-?
-
-?
-??
-
-?
-?
-?
-?
-
-
-
-
-?
-?
-??
-
-??
-?
-?
-?
-?
-
-???
-??
-?
-?
-?
-?
-?
-???
-???
-??
-??
-????
-
-???
-??
-?
-??
-?
-???
-???
-
-?
-
-
-?
-
-
-???
-???
-
-
-??
-??
-???
-????
-??
-??
-???
-????
-?
-?
-
-???
-???
-??
-????
-
-?
-?
-???
-??
-???
-?
-?
-???
-??
-???
-??
-??
-???
-???
-?
-???
-???
-???
-?????
-???
-???
-??
-????
-????
-??
-??
-??
-????
-???
-????
-????
-??
-??
-??
-???
-?
-
-??
-
-?
-
-
-
-?
-
-
-
-?
-?
-??
-?
-?
-?
-??
-?
-???
-
-
-
-?
-
-
-????
-
-
-??
-??
-?
-???
-???
-
-
-
-?
-??
-?????
-??????
-??????
-
-??
-????
-????
-??
-??
-
-??
-
-
-?
-?
-?
-
-
-
-
-??
-??
-
-
-?
-
-
-?
-
-?
-???
-????
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-??
-?
-???
-?
-????
-
-
-???
-?
-?
-?
-??
-?
-??
-??
-?
-
-??
-??
-??
-
-?
-??
-??
-??
-?
-?
-?
-???
-??
-??
-???
-?
-??
-?
-???
-??
-?
-
-?
-
-
-
-?????
-???
-
-
-?
-?
-??
-?
-?
-
-??
-
-?
-?
-?
-?
-??
-???
-??
-??
-???
-??
-????
-??
-??
-??
-????
-???
-???
-??
-??
-?
-???
-???
-??
-?
-?
-?
-?
-??
-?
-?
-?
-???
-??
-?
-??
-???
-??
-??
-?
-?????
-????
-?
-??
-???
-?
-??
-??
-???
-??
-
-??
-???
-????
-?
-
-
-
-
-
-
-
-
-
-?
-
-??
-?
-
-?
-
-?
-?
-?
-??
-
-?
-
-??
-??
-?
-???
-??
-?
-??
-????
-?
-???
-?
-???
-???
-???
-???
-??
-?
-
-??
-??
-??
-?
-
-
-
-?
-??
-?
-??
-??
-?
-
-
-
-
-??
-
-?
-?
-??
-?
-?
-????
-?
-??
-?
-???
-???
-???
-?????
-?
-?
-?
-??
-??
-???
-?
-??
-?????
-????
-?????
-?
-?????
-??
-???
-??
-??
-???
-???
-????
-?????
-?????
-??????
-??
-??
-???
-??
-???
-??
-????
-???
-???
-?????
-??????
-???
-??
-??
-???
-???
-??
-??
-??
-??
-???
-???
-???
-?
-?
-???
-?
-??
-?
-???
-???
-???
-??
-???
-???
-???
-?????
-???
-????
-????
-????
-???
-????
-????
-?
-????
-???
-???
-???
-?????
-??
-??
-???
-????
-??
-???
-??
-????
-?????
-?
-?
-?
-??
-??
-?
-??
-?
-????
-?
-???
-??
-??
-?????
-??
-??
-???
-??
-??
-??
-??
-????
-?????
-??????
-????
-???
-???
-???
-?????
-???
-????
-???
-?????
-???
-???
-?????
-?????
-????
-???
-???
-????
-???
-???
-?????
-?????
-????
-????
-??????
-?????
-????
-??
-??
-???
-???
-??
-??
-??
-??
-????
-???
-??
-??
-??
-?????
-????
-??????
-?
-?
-?
-?????
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-???
-?
-??
-?????
-?
-?
-??
-???
-??
-??
-????
-????
-?????
-?????
-?????
-???
-?
-??
-??
-??
-??
-???
-???
-????
-????
-???
-????
-???
-???
-???
-?????
-????
-?????
-????
-?
-?
-?
-??
-?
-?
-??
-??
-?
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-?????
-??
-??
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-??
-????
-???
-???
-????
-????
-????
-?????
-???
-?
-??
-??
-??
-????
-??
-????
-??
-???
-???
-???
-???
-??
-???
-???
-??
-??
-????
-???
-??
-??
-??
-??
-???
-????
-????
-????
-????
-?????
-??????
-?????
-???
-???
-??????
-??
-??
-???
-?????
-???
-???
-???
-???
-?????
-??????
-???????
-????
-????
-????
-???
-???
-???
-????
-???
-?????
-???????
-?????
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-?????
-??????
-????
-??????
-???
-???
-???
-???
-????
-????
-???
-????
-???
-????
-?????
-????
-??????
-?????
-?????
-????
-???
-?????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-????
-???
-??
-??
-???
-??
-??
-??
-??
-???
-??
-????
-?
-?
-????
-????
-????
-????
-????
-???
-???
-??
-??
-????
-??
-???
-???
-????
-????
-??????
-??????
-?????
-???
-???
-????
-????
-?????
-????
-???
-????
-??
-???
-?????
-?????
-????
-?????
-?
-?
-?
-??
-?
-?
-?
-??
-???
-???
-??
-??
-??
-??
-????
-????
-???
-???
-????
-???
-????
-?????
-???
-??
-??
-?
-??
-??
-???
-???
-????
-????
-????
-???
-????
-?
-?????
-???
-???
-???
-????
-????
-????
-????
-???
-??????
-???
-???
-?????
-??????
-????
-?
-?
-???
-?
-???
-?
-???
-???
-??
-??
-????
-???
-?????
-???
-??
-????
-??
-????
-???
-?????
-???
-??
-???
-?
-?
-????
-???
-??
-??
-????
-??
-??
-??
-?
-?
-?
-???
-?
-?
-???
-?
-?
-???
-???
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-?????
-??
-??
-???
-???
-??
-???
-???
-???
-????
-?????
-?????
-???
-????
-?????
-??
-????
-??
-?
-??
-??
-????
-???
-?
-??
-?
-?
-???
-?
-???
-?
-???
-???
-?
-???
-??
-???
-????
-???
-???
-?????
-??
-??
-?
-?
-???
-?????
-?
-??
-??
-????
-???
-?
-??
-???
-?????
-??
-?
-?
-?
-?
-?
-?
-???
-?
-??
-????
-???
-???
-???
-?
-?
-?
-??
-?
-???
-?
-???
-?
-???
-??
-??
-??
-??
-??
-
-???
-???
-??
-
-
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-???
-?
-?
-?
-?
-???
-????
-?????
-??
-??
-???
-???
-??
-????
-??
-??
-???
-?
-???
-
-?
-??
-??
-
-??
-???
-??
-??
-??
-??
-??
-??
-???
-????
-
-?
-??
-??
-?
-?
-?
-?
-?
-???
-????
-?????
-??
-??
-??
-??
-???
-????
-???
-?
-??
-?
-?
-?
-??
-??
-??
-??
-???
-????
-???
-???
-
-
-
-
-?
-?
-
-
-
-?
-
-?
-
-
-?
-?
-?
-?
-??
-
-?
-??
-??
-
-?
-
-?
-
-
-
-??
-?
-?
-?
-?
-??
-??
-???
-???
-?????
-????
-????
-????
-?????
-??
-??
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-
-?
-???
-
-
-
-?
-?
-
-
-??
-?
-?
-
-
-?
-
-
-
-?
-??
-???
-????
-?
-?
-??
-??
-?
-?
-???
-???
-?
-??
-???
-??
-??
-??
-???
-???
-??
-
-
-
-?
-??
-??
-?
-?
-??
-???
-??
-??
-??
-??
-???
-???
-
-
-
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?????
-???
-?
-
-?
-?
-?
-??
-?
-??
-?
-?
-?
-???
-??
-??
-???
-??
-??
-???
-???
-???
-???
-??
-??
-??
-??
-???
-??
-??
-???
-????????
-?????
-????
-
-
-
-
-
-
-???
-?
-?
-??
-??
-
-?
-?
-
-?
-?
-
-
-
-?
-??
-?
-?
-??
-
-??
-???
-???
-???
-?
-?
-??
-????
-
-
-
-
-?
-
-?
-
-??
-??
-
-?
-?
-??
-?
-
-??
-
-
-?
-??
-?????
-??
-?
-??
-?
-?
-?
-??
-??
-?
-?
-??
-?
-??
-?????
-???
-??
-?
-??
-??
-??
-??
-????
-?????
-??????
-???
-???
-???
-
-?
-??
-??
-??
-??
-???
-???
-?
-?
-?
-???
-???
-?
-
-?
-
-?
-???
-?
-?
-?
-??
-???
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-???
-??????
-?????
-????
-??
-??
-???
-????
-?
-??
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??????
-???
-?
-??
-????
-???
-??
-????
-?
-?
-?
-??
-??
-
-????
-?????
-??????
-
-?
-
-
-?
-?
-
-
-?
-
-?
-?
-?
-??
-??
-
-?
-
-
-?
-?
-?
-
-
-
-
-
-??
-???
-????
-?
-??
-?
-?
-?
-?
-??
-?
-
-???
-??
-???
-?
-?
-???
-????
-???
-??
-???
-
-??
-?
-?
-?
-?
-?
-?
-???
-???
-????
-????
-??
-??
-???
-??
-???
-????
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-??
-???
-????
-?
-??
-??
-??
-?
-
-
-?
-?
-?
-
-?
-
-
-
-
-?
-???
-??
-?
-?
-?
-?
-?
-
-?
-??
-???
-???
-????
-?
-?
-??
-??
-??
-?
-?
-
-
-
-???
-?
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-??
-????
-?????
-???
-???
-???
-???
-????
-
-?
-?
-???
-??
-
-??
-?
-?
-?????
-??
-??
-???
-???
-?????
-
-?
-??
-??
-???
-????
-???
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-???
-???
-???
-?????
-???
-???
-??
-???
-
-
-?
-??
-????
-?
-
-?
-
-
-
-????
-?
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-????
-???
-???
-???
-???
-????
-?
-??
-??
-??
-???
-???
-?????
-??
-???
-?
-?
-???
-?
-?
-???
-??
-
-?
-??
-?
-
-??
-
-
-
-??
-
-
-
-??
-???
-?
-?
-
-??
-?
-
-
-
-
-
-??
-???
-????
-
-
-??
-?
-??
-??
-
-?
-
-
-
-
-
-?
-?
-
-
-???
-???
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-???
-??
-??
-?
-?
-??
-??
-
-
-
-?
-
-
-?
-
-?
-
-
-
-
-
-
-?
-?
-??
-??
-
-?
-?????
-??
-?
-?
-??
-?
-???
-??
-???
-???
-??
-?
-?
-?
-?
-??
-??
-?
-?
-??
-???
-??
-????
-???
-??
-
-
-
-??
-?
-?
-??
-?
-??
-?
-??
-??
-???
-??
-???
-?????
-??
-??
-??
-???
-???
-???
-???
-????
-??
-???
-??
-??
-
-??
-
-?
-????
-???
-???
-??
-???
-????
-???
-????
-??????
-?????
-????
-????
-???
-??
-?
-?
-?
-????
-???
-??
-??
-??
-??
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-?
-?
-?
-???
-????
-????
-?????
-??
-??
-??
-??
-???
-???
-????
-????
-????
-???
-???
-???
-???
-????
-?????
-????
-?
-??
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-????
-???
-???
-???
-??
-???
-?
-?
-???
-?
-?
-
-
-
-?
-???
-?
-??
-?
-?
-?
-?
-?
-??
-???
-?
-?
-?
-??
-?
-??
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-??
-???
-????
-???
-???
-????
-???
-???
-???
-???
-???
-?????
-??????
-????
-????
-????
-?????
-??????
-???
-????
-???
-???
-?????
-????
-???
-???
-??
-???
-????
-????
-???
-??
-??
-??
-??
-???
-???
-???
-????
-?????
-?????
-????
-????
-?????
-??
-??
-??
-??
-???
-???
-???
-?
-
-?
-?
-
-??
-??
-???
-?
-?
-?
-
-
-?
-
-
-
-
-
-??
-???
-????
-?
-?
-?
-?
-?
-?
-?
-??
-?
-
-?
-?
-???
-??
-
-?
-
-
-
-
-?
-???
-???
-?
-?
-?
-?
-??
-??
-
-???
-????
-???
-??
-???
-??
-??
-??
-???
-???
-???
-??
-???
-????
-??
-????
-????
-????
-????
-??
-??
-???
-?
-??
-?
-?
-????
-???????
-?
-??
-??
-??
-??
-??
-????
-?????
-???
-??
-??
-???
-?
-??
-???????
-??
-?
-?
-??
-?
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-??
-??
-??
-?????
-???
-??
-??
-??
-????
-???
-??
-??
-????
-????
-???
-?????
-?????
-?????
-?????
-???
-???
-????
-????
-???
-??
-???
-????
-?????
-?????
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-??????
-??????
-???????
-????
-????
-????
-????
-??
-??
-??
-????
-???
-???
-??
-???
-???
-????
-?
-??
-??
-????
-???
-???
-????
-?????
-?????
-???????
-??????
-???
-??
-???
-????
-??
-??
-??
-???
-?
-???
-??
-???
-???
-??????
-?????
-???
-?
-???
-????
-???
-????
-???
-????
-???
-????
-?????
-???
-????
-????
-????
-?????
-???
-???
-?????
-??
-????
-?
-?
-????
-???
-???
-???
-??
-?
-?
-?
-??
-??
-??
-??
-???
-?
-??
-?
-??
-????
-????
-????
-??????
-???????
-????????
-?????
-?
-???
-?????
-???
-?
-?????
-????
-?????
-??????
-?????
-?????
-??????
-?
-?
-???
-???
-????
-???
-??
-???
-???
-????
-????
-????
-?????
-??
-??
-????
-???
-?
-?
-?
-??
-?
-?
-??
-???
-??
-???
-??
-???
-???
-???
-????
-???
-????
-????
-???
-?
-??
-???
-?
-???
-????
-?
-???
-???
-????
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-???
-????
-??
-???
-???
-????
-????
-??
-??
-??
-????
-???
-???
-????
-????
-?????
-??
-????
-???
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???????
-??
-???
-???
-???
-?
-?
-?????
-???
-??
-???
-??
-??
-??
-?????
-??????
-????
-???
-???
-??
-???
-?????
-???
-???
-????
-???
-???
-???
-???
-????
-??
-???
-???
-??
-???
-?????
-????????
-???
-?????
-???
-??????
-??
-????
-????
-????
-????
-?????
-?????
-??????
-????
-????
-?????
-?????
-????
-?????
-????
-?????
-????
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-?????
-??????
-??????
-??????
-????
-????
-??
-?
-???
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-??
-??
-??
-???
-???
-??
-??
-??????
-?????
-??
-??
-??
-????
-??
-???
-?????
-????
-??
-?
-??
-?
-??
-????
-????
-??????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-???
-?
-?
-??
-???
-???
-???
-???
-????
-??????
-??????
-????
-????
-?????
-?
-??
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-????
-???
-???
-?
-?
-??
-?
-?
-??
-?
-?
-??
-???
-???
-??
-??
-????
-????
-?
-?
-?
-?
-??
-??
-???
-??
-???
-???
-????
-???
-???
-??
-??
-??
-????
-???
-???
-????
-?????
-???
-??????
-?????
-??????
-???
-????
-????
-???
-??
-???
-????
-???
-?????
-???
-???
-??
-???
-???
-????
-???
-???
-???
-?????
-???
-???
-??
-??
-????
-???
-???
-?
-????
-?
-??
-????
-???
-??
-???
-???
-????
-?????
-?????
-????
-???
-???
-??
-??
-??????
-???
-??
-??
-????
-?????
-?
-?????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-????
-
-??
-
-?
-
-
-??
-??
-???
-
-????
-
-
-
-
-?
-?
-
-?
-??
-??
-??
-
-
-
-?
-?
-
-?
-
-
-
-
-?
-
-
-
-
-
-??
-?
-
-??
-???
-?
-?
-?
-?
-
-?
-
-
-
-?
-
-
-
-?
-
-?
-?
-??
-?
-??
-??
-??
-
-?
-
-
-
-
-
-
-?
-
-
-?
-?
-??
-
-
-
-?
-??
-?
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-
-
-
-?
-
-?
-
-
-
-?
-?
-??
-?
-??
-??
-??
-???
-????
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-???
-??
-???
-?
-?
-??
-??
-?
-???
-?
-?
-??
-?
-??
-??
-????
-????
-???
-???
-???
-???
-??
-??
-?????
-???
-???
-???
-???
-???
-????
-????
-??
-??
-??
-??
-???
-???
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-??
-
-?
-
-?
-??
-
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-???
-
-?
-?
-?
-?
-
-
-?
-
-
-
-?
-??
-??
-??
-??
-???
-????
-???
-????
-?
-??
-??
-?
-?
-?
-?
-??
-?
-??
-
-
-
-
-?
-
-
-
-
-?
-?
-?
-?
-??
-?
-
-?
-
-
-
-
-
-
-
-?
-?
-
-
-
-?
-?
-
-?
-?
-?
-?
-
-?
-?
-?
-?
-?
-???
-??
-??
-??
-???
-????
-???
-???
-??
-??
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-???
-?
-???
-?
-???
-??
-???
-??
-????
-????
-???
-?????
-???
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-????
-???
-?????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-?
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-???
-??
-???
-???
-????
-???
-??
-???
-?
-?
-??
-????
-?
-?
-??
-??
-???
-???
-?
-?
-??
-?
-???
-???
-???
-???
-????
-????
-?????
-?
-?
-????
-????
-???
-???
-???
-???
-???
-?????
-??????
-????
-?????
-????
-????
-????
-?????
-??
-??
-?????
-?
-??
-??
-??
-?
-????
-???
-??
-????
-?????
-????
-?
-?
-??
-??
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-?
-?
-?
-??
-??
-??
-??
-???
-??
-??
-????
-??
-???
-????
-???
-??
-???
-???
-?
-?
-?
-??
-?
-????
-??
-????
-?????
-??
-??
-??
-??
-???
-??
-??
-
-?
-
-
-?
-???
-??
-??????
-?
-?
-??
-??
-??
-????
-???
-???
-???
-????
-????
-?
-
-
-??
-???
-
-
-
-???
-
-??
-
-
-
-?
-?
-
-
-
-
-???
-??
-??
-??
-???
-?
-?
-???
-??
-???
-??
-
-
-??
-??
-???
-????
-?
-?
-??
-
-
-??
-?
-??
-
-??
-??
-??
-???
-??
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-???
-???
-??
-???
-
-
-?
-
-
-
-?
-??
-
-
-
-
-??
-?
-?
-??
-?
-
-
-
-?
-
-
-?
-?
-
-
-?
-?
-
-?
-?
-???
-?
-?
-?
-?
-???
-?
-?
-
-
-?
-??
-?
-???
-??
-???
-?????
-????
-??
-?????
-??
-????
-????
-????
-????
-????
-??????
-???
-????
-??
-??
-???
-??
-????
-?
-??
-?
-?
-?
-???
-??
-?????
-??
-???
-??
-??
-?
-?
-?
-??
-??
-??
-????
-?
-?
-?
-?
-???
-???
-?
-?
-?
-??
-??
-???
-???
-???
-????
-??
-????
-
-??
-??
-???
-
-??
-???
-
-?
-
-??
-
-
-???
-
-
-??
-??
-??
-??
-????
-
-
-
-
-
-?
-?
-
-?
-????
-?
-??
-?
-????
-?
-?
-???
-???
-????
-???
-??
-??
-??
-????
-?
-??
-????
-
-?
-
-?
-?
-
-
-
-?
-?
-?
-??
-??
-?
-???
-???
-??
-?
-??
-??
-???
-??
-??
-??
-??
-?
-??
-????
-????
-??????
-??
-???
-?
-
-
-
-?
-
-
-
-
-?
-?
-???
-??
-??
-???
-?
-?
-??
-??
-??
-????
-?
-???
-????
-???
-?
-??
-
-??
-??
-
-?
-?
-?
-?
-
-??
-???
-?
-???
-?
-????
-
-
-??
-?
-?
-??
-??
-????
-??
-?
-??
-???
-???
-???
-???
-??
-??
-?
-???
-?
-?
-??
-??
-???
-??
-?
-
-
-
-?
-????
-???
-???
-?????
-????
-
-??
-
-
-
-
-
-?
-
-
-
-?
-??
-?
-??
-?
-?
-?
-??
-???
-?
-?
-?
-??
-?
-?
-?
-??
-
-??
-??
-?
-???
-
-
-?
-?
-
-??
-?
-?
-?
-??
-??
-???
-???
-?????
-?
-??
-?
-???
-??
-??
-???
-?
-?
-???
-??
-???
-????
-??
-
-
-
-???
-???
-?
-?
-???
-??
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-???
-??
-?
-????
-?
-??
-?
-??
-
-??
-??
-??
-??
-????
-???
-??
-??
-??
-????
-?????
-????
-??????
-???????
-?
-??
-?
-??
-
-
-??
-??
-?
-????
-?
-??
-?
-
-???
-??
-??
-
-?
-
-???
-?
-???
-?
-????
-?
-?
-???
-???
-
-?
-??
-???
-
-??
-?
-??
-????
-????
-?
-???
-?
-???
-???
-??
-????
-???
-?????
-??
-??????
-
-
-?
-
-
-?
-??
-?
-
-
-
-?
-
-?
-
-
-
-??
-??
-????
-???
-?????
-?
-?
-???
-???
-
-???
-?
-
-
-
-?
-
-?
-???
-??
-
-???
-????
-?
-
-?
-???
-?
-????
-?
-??
-??
-????
-????
-?????
-?????
-??????
-???
-
-
-????
-?????
-???
-????
-????
-???
-?????
-??
-?
-?
-???
-???
-??
-?
-??
-??
-??
-???
-??
-????
-?????
-?
-???
-?????
-??
-??
-?????
-?????
-??
-????
-????
-?????
-??????
-??
-??
-??
-???
-??
-?????
-???
-?
-?
-???
-???
-???
-????
-?
-???
-?
-??
-????
-?
-???
-???
-???
-??
-?
-??
-????
-?????
-??????
-?
-?
-?
-?
-?
-?
-?
-???
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-????
-??
-??
-??
-???
-?
-?
-??
-???
-????
-??????
-??
-???
-??
-???
-???
-?
-?
-?
-??
-?????
-??
-??
-????
-??
-????
-??
-????
-????
-??
-???
-?????
-????
-??????
-??
-?????
-????
-??????
-???
-?????
-???
-?????
-??
-????
-??
-????
-????
-????
-??????
-?????
-??????
-??????
-???
-?????
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-???
-???
-?????
-?????
-?
-?
-??
-?
-??
-??
-??
-???
-???
-???
-??????
-???
-???
-?
-?
-?
-?
-?
-??
-?
-???
-????
-??
-???
-??
-???
-??
-??
-??
-????
-??????
-???
-????
-???
-???
-?????
-??????
-???
-??????
-???
-?????
-?????
-??????
-??
-??
-?????
-????
-???
-???
-?????
-???
-??
-??
-??
-???
-??
-??
-??
-???
-??
-???
-????
-??
-????
-???
-???
-???
-??
-??
-??
-??
-??
-??
-???
-?????
-?????
-???????
-??????
-???????
-???????
-???????
-???????
-????????
-???????
-???????
-???????
-????????
-?????
-????
-?????
-?????
-???
-???
-?????
-??
-??
-???
-????
-????
-??
-????
-???
-??
-????
-????
-?????
-???
-??
-??
-???
-???
-???
-?
-??
-????
-??
-??
-??
-???
-??
-????
-??
-???
-???
-??
-??
-??
-??
-????
-?
-????
-?
-?
-???
-???
-??
-????
-?????
-?
-??
-?????
-?
-??
-???
-???
-?
-??
-??
-????
-???
-???
-??
-?
-???
-??
-?
-?
-?
-?
-??
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-???
-???
-????
-?????
-?
-?
-?
-??
-???
-??
-?
-???
-?
-????
-??
-??
-?
-????
-??
-??
-??
-??
-????
-????
-??
-???
-???
-?????
-????
-??
-??
-???
-????
-??????
-????
-???
-????
-?????
-????
-??
-???
-???
-???
-????
-????
-????
-?????
-???
-???
-???
-?????
-?????
-?????
-????
-?????
-????
-????
-??????
-?????
-???????
-???????
-????
-??????
-??????
-?????
-???????
-??????
-????
-??????
-????????
-?????
-?????
-???????
-???
-???
-???
-????
-?????
-????
-?????
-??????
-?????
-????
-??????
-?
-??
-???
-???
-?
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-???
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-??
-??
-????
-???
-???
-???
-????
-??
-???
-?????
-??
-?
-?
-?
-???
-???
-????
-?????
-?????
-??
-??
-??
-????
-???
-????
-????
-?????
-?????
-?????
-??????
-?????
-
-?
-??
-??
-?
-??
-??
-?
-
-
-?
-
-
-
-??
-?
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-???
-?
-
-?
-??
-?
-?
-?
-??
-???
-??
-??
-?
-????
-?
-?
-???
-???
-???
-?
-?
-???
-?????
-????
-??
-??
-????
-??
-????
-????
-??????
-???
-?????
-?????
-???
-????
-???
-????
-?????
-??
-????
-????
-????
-??????
-
-?
-?
-
-?
-?
-
-???
-???
-
-
-
-?
-?
-??
-
-?
-?
-?
-?
-??
-
-?
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-???
-?
-??
-??
-???
-???
-????
-????
-??
-??
-???
-???
-???
-???
-??
-????
-????
-?
-?
-???
-?
-?
-??
-?
-??
-?
-???
-?
-??
-??
-????
-??
-???
-????
-????
-????
-?????
-????
-?
-??
-?
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-????
-??????
-???
-???
-???
-????
-???
-?
-??
-
-???
-????
-??
-
-??
-
-??
-??
-????
-??
-?????
-???
-???
-
-
-
-
-?
-?
-
-?
-?
-
-??
-??
-???
-??
-?
-???
-??
-??
-?
-??
-???
-?
-?
-??
-?
-?
-??
-??
-??
-??
-??
-??
-????
-?
-?
-?
-?
-
-
-
-
-
-?
-?
-??
-??
-??
-??
-??
-???
-???
-
-
-
-
-
-
-
-?
-???
-???
-???
-??
-?
-?
-??
-
-?
-
-
-?
-
-
-
-?
-
-?
-?
-
-??
-???
-???
-
-
-??
-
-?
-?
-?
-??
-?
-?
-??
-???
-??
-??
-??
-???
-???
-???
-??
-?
-?
-?
-?
-???
-???
-??
-?
-?
-
-??
-
-
-
-
-??
-???
-
-
-?
-??
-?
-?
-????
-???
-?????
-???
-????
-???
-???
-????
-????
-??
-??
-??
-???
-?
-??
-??
-??
-???
-????
-???
-
-?
-??
-
-??
-
-
-
-
-
-????
-?
-?
-??
-???
-???
-???
-????
-????
-??
-??
-?
-?
-?
-???
-
-
-
-
-
-
-
-?
-??
-??
-????
-?
-
-
-??
-
-????
-?
-?
-?
-???
-??
-??
-?
-??
-?
-??
-??
-?
-?
-?
-???
-???
-?
-??
-????
-????
-?
-?
-?
-??
-?
-?
-?
-?
-??
-
-?
-????
-?
-?
-???
-???
-??
-????
-??
-??
-???
-?
-????
-
-??
-??
-??
-????
-?
-
-
-
-?
-??
-??
-??
-
-
-???
-??
-??
-??
-??
-
-??
-
-??
-??
-????
-?
-???
-?
-???
-???
-???
-?
-
-?
-???
-??
-???
-???
-??????
-?
-??
-?
-??
-??
-
-
-?
-??
-??
-?
-??
-?
-?
-
-
-?
-?
-
-?
-??
-?
-?
-???
-
-
-
-?
-
-
-
-?
-
-
-?
-?
-?
-??
-???
-
-?
-?
-
-?
-??
-?
-
-
-
-?
-?
-?
-??
-???
-???
-???
-???
-???
-????
-????
-????
-????
-?????
-?
-?
-?
-?
-??
-????
-???
-??
-?
-?
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-??
-??
-???
-??
-???
-???
-???
-???
-?????
-??????
-????
-?????
-?
-?
-?
-???
-?
-??
-??
-????
-????
-???
-?????
-???
-???
-??
-????
-????
-????
-?????
-????
-????
-????
-?????
-??????
-???
-??
-??
-???
-????
-??
-???
-?
-??
-????
-?????
-???????
-????
-??
-????
-??
-?????
-??
-????
-
-
-?
-
-
-
-
-?
-?
-?
-
-?
-?
-????
-
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-??
-???
-????
-????
-??
-??
-???
-????
-?
-??
-??
-??
-???
-??
-???
-
-
-
-
-
-
-
-??
-?
-
-?
-?
-??
-??
-
-
-??
-?
-??
-
-?
-?
-?
-?
-?????
-??
-???
-????
-?
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-?
-???
-???
-????
-????
-??
-??
-??
-???
-
-
-?
-?
-?
-?
-?
-??
-???
-?
-?
-???
-???
-?
-???
-??
-????
-??
-??
-???
-????
-??
-?
-????
-????
-?
-?
-?
-?
-?
-?
-??
-?
-?
-???
-?
-??
-????
-??
-
-?
-??
-??
-??
-???
-??
-???
-??????
-?
-?
-?
-
-
-
-??
-??
-???
-?????
-???
-??
-??
-??
-???
-????
-???
-?
-??
-??
-??
-??
-???
-??
-???
-??
-?
-?
-?
-??
-??
-????
-???
-??
-???
-???
-?????
-????
-????
-??
-????
-????
-????
-??????
-?????
-????
-???
-?
-?
-????
-?
-???
-???
-?????
-????
-??
-????
-??????
-???
-???
-??
-?
-??
-??
-?
-?
-?
-?
-?
-???
-???
-??
-??
-???
-?
-?????
-?
-???
-???
-???
-??
-??
-???
-??
-???
-???
-???
-??
-??????
-?????
-???
-??????
-?????
-??
-???
-???
-????
-?????
-???
-????
-??
-??
-????
-???
-???
-??????
-???
-?
-?
-??
-???
-???
-?????
-??????
-??
-??
-????
-??
-????
-??????
-????
-???
-?????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-?????
-?????
-?????
-????
-??????
-???????
-?????
-????????
-????
-????
-?????
-????
-???
-??
-???
-???
-??
-???
-???
-???
-???
-???
-???
-??
-??
-???
-??
-???
-??
-??
-????
-?????
-???
-???
-???
-???
-??
-???
-??
-???
-???
-????
-???
-?
-??
-?
-?
-???
-???
-????
-??
-???
-???
-????
-?????
-????????
-??
-?
-???
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-???
-??
-????
-?????
-???
-???
-????
-????
-????
-?
-?
-??
-??
-??
-??
-?
-???
-??
-?
-??
-???
-??
-??
-????
-?
-?
-???
-?
-?
-?
-??
-??
-???
-????
-????
-?
-?
-???
-???
-?????
-??
-???
-?
-???
-???
-?
-?
-??
-????
-???
-?????
-??
-????
-???
-???
-????
-???
-??
-??
-???
-??
-??
-??
-???
-?
-????
-???
-???
-?????
-??
-????
-???
-???
-?????
-??
-???
-??
-???
-???
-???
-???
-?
-?
-???
-?
-?
-?
-???
-?
-?
-?
-??
-??
-???
-???
-??
-????
-???
-?????
-????
-???
-???
-???
-????
-??
-?
-?
-?
-??
-??
-??
-??
-????
-?
-?
-??
-??
-????
-??
-????
-????
-????
-????
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-???
-???
-???
-???
-????
-??????
-???
-?????
-?????
-?????
-??????
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-???
-???
-????
-????
-?????
-?
-?
-??
-??
-??
-????
-??
-????
-??
-??
-??
-???
-??
-?????
-????
-????
-??????
-???
-?????
-?????
-?????
-???????
-????
-????
-??????
-????
-???
-???
-???
-????
-????
-?????
-?????
-????
-??
-????
-???
-???
-???
-???
-?????
-?????
-???
-?????
-????
-?????
-??????
-???
-?????
-?????
-?????
-?
-??
-??
-?
-???
-?
-?
-?
-?
-??
-???
-??
-?
-??
-?
-???
-???
-????
-???
-??
-??
-???
-??
-??
-???
-?????
-?
-??
-??
-?
-?
-?
-?
-?
-???
-???
-????
-??
-???
-??
-??
-??
-???
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-???
-?
-?
-???
-??
-????
-??
-??
-???
-??
-????
-?????
-????
-????
-????
-????
-??????
-?????
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-????
-???
-???
-????
-???
-????
-???
-????
-???
-???
-?????
-????
-?????
-????
-?????
-?????
-?????
-??????
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-?????
-????
-????
-?????
-????
-?????
-?????
-????
-??
-????
-????
-????
-????
-??????
-??????
-???????
-???
-?????
-????
-?????
-?????
-??????
-??
-??
-?????
-?????
-??
-??
-????
-??
-????
-????
-????
-????
-???
-???
-?????
-?????
-????
-??????
-????
-??
-???
-?????
-?????
-????
-??????
-?????
-??????
-?????
-??????
-???
-???
-???
-??????
-?????
-??????
-??????
-???
-???
-????
-??????
-?????
-?????
-????
-??
-???
-???
-???
-???
-???
-???
-?????
-??????
-??????
-???????
-????
-????
-????
-????
-????
-?????
-???
-???
-????
-???
-???
-????
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-???
-?????
-????
-????
-?????
-?????
-????
-????
-????
-?????
-?????
-????
-?????
-????
-????
-?????
-????
-????
-????
-?????
-?????
-??????
-???
-????
-??
-???
-????
-????
-???
-???
-??
-???
-??
-??
-???
-????
-?????
-?????
-????
-???????
-???????
-????????
-???????
-????????
-????
-????
-?????
-?????
-???
-?????
-??
-????
-??
-???
-????
-??
-???
-???
-?
-???
-??
-???
-??
-???
-??
-??
-??
-??
-???
-??????
-???
-???
-???
-????
-?
-?
-??
-??
-?
-??
-??
-?
-???
-?
-??
-???
-??
-??
-??
-?
-??
-?
-?
-?
-????
-?????
-???
-????
-????
-????
-????
-???
-?????
-??????
-??????
-?????
-?????
-?????
-???????
-??????
-????????
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-???
-??
-??
-??????
-???????
-???
-???
-???
-????
-???
-????
-??
-???
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-?
-?
-??
-???
-????
-???
-?
-?
-?
-?
-?
-??
-???
-??
-??
-???
-??
-?????
-???????
-????
-??????
-??
-??
-??
-???
-????
-???
-????
-???
-??
-??
-???
-??
-??
-????
-??
-????
-???
-???
-????
-???
-???
-?????
-????
-??????
-???
-??????
-????
-??????
-?????
-???
-????
-???
-?????
-?????
-????
-?????
-???????
-?????
-???????
-????
-???
-?????
-??????
-?????
-?????
-?????
-??????
-??????
-??????
-?????
-???
-???
-???
-????
-????
-??
-??
-??
-???
-??????
-??????
-??
-????
-????
-??????
-???
-??
-????
-??????
-??
-????
-??
-??
-??
-?
-??
-???
-??
-????
-??
-??????
-?????
-?
-?
-?
-???
-???
-?????
-???
-??
-??
-??
-????
-?
-??
-????
-?
-?
-???
-?
-?
-?
-?
-?
-???
-??
-??
-??
-???
-?
-???
-??
-?
-?
-??
-?
-???
-???
-?????
-???
-??
-???
-?????
-????
-???????
-?
-???
-?????
-????
-?
-?
-??
-??
-??
-?
-??
-?
-??
-?
-??
-?????
-??
-????
-??????
-????
-???
-??
-??
-??
-???
-????
-???
-??
-????
-????
-????
-????
-???
-???
-??
-???
-????
-??
-???
-????
-???
-???
-???
-???
-?????
-???
-???
-????
-????
-???
-???
-?????
-????
-????
-??????
-???????
-??????
-???
-?????
-???????
-???
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?????
-?????
-??
-?
-?
-??
-???
-????
-??
-??
-?????
-??????
-??????
-??
-??
-???
-???
-?????
-????
-???
-???
-??
-????
-????
-??
-????
-??
-????
-?
-????
-?
-?
-???
-?
-???
-???
-?
-???
-?????
-?
-???
-???
-?????
-??????
-?????
-??
-????
-??????
-?????
-????
-????
-??????
-??????
-??
-?????
-??
-??
-???
-??
-????
-???
-???
-?????
-????
-????
-????
-??????
-???
-????
-?
-????
-????
-?
-???
-??
-??
-??
-?
-???
-??
-??
-??
-???
-????
-???
-??
-??
-????
-?????
-?????
-??????
-???
-???
-???
-????
-???
-?????
-??
-????
-???
-????
-??????
-???
-????
-??????
-???
-???
-?????
-?????
-?????
-?????
-?????
-???????
-????
-???????
-???????
-????
-???
-???
-?????
-???
-?????
-?????
-????
-????
-?????
-????
-????
-????
-?????
-?????
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-?????
-??????
-?????
-???????
-??
-??
-??
-??
-??????
-???
-???
-?????
-?????
-???
-????
-?
-?
-???
-??
-??
-???
-?
-???
-?
-???
-????
-???
-????
-????
-???
-????
-??????
-??
-?????
-????
-???
-???
-??
-??
-??
-??
-????
-???
-???
-?
-??
-??
-??
-?
-?
-?
-?
-??
-???
-??
-??
-?
-?????
-?????
-???????
-???
-??????
-?????
-?????
-????
-??????
-?????
-??????
-?????
-?
-???
-?
-??
-??
-???
-???
-??
-??
-??
-???
-???
-????
-???
-???
-??
-???
-??
-????
-??
-???
-???
-??
-???
-??
-????
-??
-????
-???
-???
-??
-????
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-????
-????
-????
-?????
-?????
-?????
-??????
-??????
-??????
-??
-??
-??
-???
-????
-?????
-??
-???
-??
-??
-??
-????
-????
-?
-?
-??
-?
-???
-??
-??
-????
-????
-?
-???
-??
-????
-???
-???
-?????
-??
-????
-??
-??
-??
-????
-????
-????
-?
-???
-???
-???
-?????
-??
-?
-??
-??
-??
-???
-??
-??
-??
-?????
-?
-???
-?????
-?????
-??
-??
-????
-??????
-???
-??
-???
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-?
-??
-??
-??
-??
-???
-????
-???
-???
-?????
-?????
-?????
-?
-??
-?
-???
-??
-????
-????
-??
-???
-???
-?????
-????
-??
-??
-?????
-??
-??
-????
-??
-????
-????
-????
-????
-?????
-?????
-????
-??????
-????
-??????
-??
-??
-??
-??
-???
-????
-????
-???
-?????
-??????
-??????
-?????
-??????
-???
-???
-?????
-?????
-?????
-????
-??????
-???????
-?????
-??????
-??????
-????
-????
-????
-????
-?????
-???
-????
-???
-???
-?????
-???
-?????
-?????
-????
-????
-????
-?????
-??????
-??????
-???
-???
-??
-??
-??
-??
-????
-????
-?????
-?????
-????
-??????
-??
-??
-???
-???
-???
-?????
-???
-?????
-??
-??
-??
-????
-????
-??????
-?????
-??
-??
-???
-????
-????
-????
-?????
-??????
-????
-??
-??
-??
-???
-???
-????
-??
-????
-????
-?????
-??????
-?????
-???
-???????
-?????
-??????
-??
-?????
-????
-?????
-????
-????
-??????
-????
-??????
-???
-????
-??????
-???????
-???
-???
-????
-???
-????
-????
-??????
-?????
-??????
-????
-?????
-????
-???
-?????
-?????
-?????
-?????
-????
-??????
-???
-???
-?????
-????
-??????
-?????
-??????
-???
-???
-????
-???
-????
-???
-????
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-????
-???
-??????
-??????
-???
-???
-???
-????
-???
-???
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-???????
-????
-?????
-????
-????
-?????
-????
-?????
-?????
-????
-????
-????
-??????
-??????
-?????????
-??????
-????????
-??????
-?????
-????
-???????
-?????
-????
-????
-????
-????
-????
-??????
-????????
-?????
-???????
-????????
-??????
-??????
-???????
-??????????
-??????????
-????
-???????
-???
-?????
-???
-???
-???
-????
-??
-??
-??
-??
-????
-????
-????
-????
-???
-?????
-??
-??
-??
-????
-??????
-???
-???
-???
-?????
-??
-???
-????
-???
-???
-???
-?????
-?????????
-???
-????
-???
-???
-??????
-???
-????
-???
-????
-???
-????
-????
-????
-??????
-????
-???
-????
-??????
-????
-????
-????
-??
-??
-??
-???
-??
-????
-??
-??
-??
-???
-??
-????
-????
-??
-??
-???
-???
-????
-?????
-??
-???
-???
-????
-????
-??????
-????
-??????
-?????
-?????
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-????
-????
-?????
-????
-?????
-?????
-???????
-??
-??
-???
-??
-????
-????
-????
-???
-???
-???
-????
-???
-???
-????
-??
-???
-??
-??
-????
-?????
-????
-??????
-??????
-???
-??
-???
-???
-??
-??
-??
-??
-???
-????
-????
-???
-???
-???
-????
-???
-???
-???
-?????
-???
-?????
-?????
-?????
-???
-?????
-????
-????
-???
-???
-?????
-???????
-????
-??????
-?????
-???
-????
-?????
-??
-??
-??
-???
-???
-???
-???
-???
-?????
-?????
-????
-????
-???
-???
-???
-????
-????
-?????
-??????
-?
-??
-??
-?
-??
-???
-??
-??
-??
-??
-??
-??
-????
-????
-???
-???
-?????
-??
-???
-?
-???
-????
-???
-?
-?
-?
-??
-????
-??
-????
-?
-??
-??
-???
-??
-??
-??
-??
-?????
-??
-??
-???
-???
-???
-???
-????
-????
-???
-??
-?
-?
-?
-?
-???
-??
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-???
-???
-????
-???
-????
-?????
-????
-??????
-????
-??
-?
-?
-???
-????
-???
-??
-??
-?
-??
-??
-???
-??
-???
-????
-????
-???
-????
-?
-?
-??
-?
-???????
-?????
-???
-???
-????
-??
-??
-?
-??
-?
-????
-????
-?????
-????
-?????
-?????
-????
-????
-????
-????
-??????
-??
-??????
-??????
-?????
-?????
-?????
-?????
-???????
-??????
-?
-??
-??
-????
-????
-?????
-???
-???
-???
-?????
-????
-?????
-????
-?????
-?
-?
-?
-?
-??
-???
-???
-?
-??
-??
-??
-????
-???
-????
-??????
-?????
-????
-??
-??
-??
-????
-????
-????
-???
-?????
-???
-?????
-?????
-????
-??????
-???
-???
-?????
-????
-????
-???
-???
-???
-???
-????
-
-
-
-
-?
-?
-
-
-?
-?
-?
-
-
-
-?
-?
-??
-??
-??
-??
-?
-
-
-
-?
-??
-?
-??
-??
-??
-
-
-
-
-
-?
-?
-??
-?
-??
-???
-???
-????
-??
-?
-??
-?
-?
-??
-???
-
-??
-???
-
-?
-?
-??
-??
-??
-
-
-
-?
-?
-??
-??
-
-?
-??
-?
-
-
-
-
-?
-?
-
-
-
-?
-?
-?
-??
-??
-????
-????
-?
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-??
-???
-????
-
-?
-
-?
-
-
-?
-??
-??
-??
-??
-
-
-?
-??
-??
-?
-?
-?
-??
-?
-?
-??
-??
-??
-?
-??
-??
-????
-
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-???
-???
-????
-????
-?????
-???
-???
-
-?
-?
-??
-?
-?
-?
-?
-??
-?
-??
-?
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-???
-???
-???
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-??
-??
-?
-??
-???
-?
-??
-??
-???
-??
-???
-???
-??
-??
-???
-???
-??
-???
-????
-??
-??
-??
-?
-??
-?
-???
-???
-????
-???
-???
-???
-????
-????
-??
-??
-????
-????
-????
-????
-????
-?????
-???
-????
-???
-????
-??
-??
-???
-????
-????
-??
-?????
-????
-?????
-????
-?????
-??????
-?
-?????
-?
-??
-?
-?
-?
-?
-??
-??
-???
-???
-?
-??
-???
-???
-?
-??
-??
-??
-???
-??
-??
-??
-??
-?
-?
-?
-??
-???
-???
-?
-??
-??
-??
-??
-?
-?
-???
-??
-??
-??
-
-
-
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-??
-?
-??
-?
-?
-??
-??
-
-??
-
-?
-?
-?
-???
-????
-???
-?????
-??
-
-
-
-?
-
-
-??
-??
-?
-
-??
-??
-??????
-
-
-
-?
-
-?
-
-?
-
-
-
-
-
-
-
-
-???
-?
-
-
-?
-
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-?
-??
-???
-
-???
-
-
-?
-??
-???
-??
-??
-???
-??????
-????????
-??
-??
-?
-????
-????
-?
-?
-??
-?
-?
-??
-????
-???
-???
-?????
-????
-????
-?????
-??
-???
-??
-??
-??
-???
-???
-??
-?
-?
-???
-?
-??
-???
-??????
-????
-?????
-????
-??
-?
-?
-???
-???
-????
-??
-??
-?
-?
-?
-???
-?????
-??
-??
-????
-???
-???
-???
-?
-??
-??
-??
-??
-????
-???
-???????
-????
-???
-??
-??
-????
-?
-?????
-????
-???
-????
-?????
-????
-??
-?
-???
-?
-???
-?
-???
-?
-???
-?????
-???
-???
-???
-???
-?????
-?????
-?????
-???
-???????
-??????
-???????
-??
-???
-????
-????
-?
-?
-?
-???
-?
-?
-?
-??
-??
-???
-??
-?????
-?
-?
-???
-??????
-?????
-????
-???
-???
-???
-?????
-??
-??
-??
-????
-???
-????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-????
-???
-???
-???
-??
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-??
-??
-?
-?
-?
-?
-?
-???
-???
-??
-??
-??
-???
-?
-?
-???
-?
-??
-????
-???
-???
-????
-?
-?
-???
-?
-??
-??
-???
-?
-???
-??
-??
-???
-??
-??
-??
-????
-?????
-???
-?
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-?
-???
-??
-???
-??
-??
-??
-??
-????
-???
-?
-?
-???
-???
-??
-?
-??
-?
-???
-??
-?
-??
-????
-???
-???
-??
-???
-??
-????
-??
-??
-???
-??
-??
-????
-??
-??
-????
-???
-??
-??
-?????
-???
-????
-????
-????
-???????
-????
-??????
-??????
-??????
-?????
-????
-?????
-????
-?????
-?????
-????
-???????
-?????
-????
-??????
-????
-??
-???
-???
-???
-??
-????
-??
-???
-?????
-????
-????
-??????
-?????
-?
-?
-??
-?
-?
-?
-??
-????
-???
-????
-?
-?
-?
-?
-????
-????
-?
-?
-???
-?
-???
-???
-???
-??
-??
-???
-?????
-?
-??
-???
-???
-?????
-????
-???
-??
-????
-???
-????
-???
-?
-????
-??
-????
-??
-??
-???
-????
-??
-??
-????
-???
-?????
-????
-???
-????
-??
-??
-??
-???
-?????
-????
-???
-?????
-???
-??
-????
-?????
-?
-??
-?
-?
-?
-?
-??
-??
-????
-??
-???
-????
-?????
-???
-???
-??
-??
-??
-????
-??
-???
-?
-??
-?
-????
-??
-????
-????
-??????
-???
-??
-?????
-??????
-????
-????
-????
-???
-???
-???
-????
-?????
-?????
-????
-??????
-?????
-?????
-??
-???
-???
-??
-??????
-???
-???
-????
-????
-????
-????
-???
-??
-??
-????
-????
-????
-??????
-?????
-???
-??
-???
-??
-??
-???
-??
-????
-???
-???
-?????
-??
-????
-?????
-???
-??
-????
-?????
-????
-?????
-???
-???
-???
-?????
-????
-????
-??????
-???
-???
-???
-???
-???
-????
-???
-????
-????
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-?????
-????
-?????
-?????
-????
-?????
-??????
-????
-?????
-????
-??????
-??????
-?????
-????
-????
-????
-??????
-????
-??????
-????
-??????
-?????
-???
-?????
-?????
-???
-?????
-???
-???
-?????
-??
-??
-???
-??
-??
-??
-???
-??
-???
-?????
-?????
-??
-??
-??
-??
-??
-??
-???
-????
-???
-????
-????
-???
-???
-???
-???
-???
-????
-???
-?????
-???
-???
-??
-???
-????????
-??
-????
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-?
-???
-???
-???
-????
-?????
-????
-?
-????
-??
-?
-?
-???
-???
-???
-??
-??
-???
-???
-???
-????
-????
-???
-????
-???
-???
-????
-?????
-???
-????
-??
-???
-??
-???
-??
-???
-???
-????
-???
-???
-????
-???
-????
-???
-??
-???
-???
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-??
-?
-??
-?
-?
-?
-??
-??
-???
-??
-??
-??
-???
-?
-??
-????
-?????
-???
-????
-???
-????
-????
-?????
-????
-????
-????
-????
-?????
-??
-????
-???
-??
-?
-??
-????
-????
-????
-????
-??????
-?????
-?????
-?????
-??????
-?????
-?????
-?????
-???????
-??????
-?
-?
-?
-???
-??
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-??
-???
-????
-????
-????
-?????
-????
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-?????
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-????
-???
-??
-?
-???
-?????
-??
-??????
-??
-???
-????
-???
-????
-?
-?
-?
-?
-???
-???
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-
-
-
-
-
-
-?
-?
-
-??
-
-
-
-
-?
-??
-??
-???
-
-
-
-?
-?
-?
-??
-
-?
-?
-?
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-????
-??
-?
-?
-?
-?
-???
-?
-?
-?
-??
-???
-??
-???
-???
-??
-???
-???
-???
-???
-???
-??
-??
-??
-???
-????
-?????
-???
-???
-???
-???
-???
-?
-??
-?
-??
-???
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-??
-???
-????
-????
-????
-??
-???
-??
-?
-?
-???
-?
-?
-???
-?????
-??
-??
-????
-?
-?
-??
-??
-??
-?
-?
-??
-???
-??
-??
-???
-?
-?
-??
-??
-????
-???
-?
-??
-??
-???
-?????
-???
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-?
-
-?
-?
-??
-???
-?
-
-
-?
-?
-??
-???
-
-
-
-??
-
-?
-??
-?
-?
-?
-
-
-?
-
-
-?
-?
-?
-
-
-
-?
-
-?
-?
-??
-?
-??
-??
-
-?
-????
-?
-?
-??
-?????
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-???
-?
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-??
-????
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-????
-??
-???
-?
-?
-?
-??
-??
-?
-??
-??
-???
-??
-???
-???
-???
-????
-?????
-??
-???
-?
-?
-??
-?
-?
-
-
-?
-?
-
-
-
-??
-
-?
-?
-??
-
-??
-???
-?
-
-
-?
-?
-?
-???
-?
-???
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-?
-?
-?
-??
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-??
-?
-??
-
-
-??
-
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-?
-?
-??
-?
-??
-?
-??
-???
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-?
-??
-???
-????
-??
-????
-???
-????
-????
-???
-??
-?
-?
-?
-?
-???
-?
-??
-?
-??
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-??
-??
-???
-?????
-???
-??
-????
-
-
-?
-???
-??
-
-
-?
-??
-???
-
-
-
-
-
-
-?
-??
-??
-
-?
-
-??
-???
-?
-?
-
-
-
-
-?
-
-??
-???
-?
-
-?
-?
-?
-??
-?
-
-?
-??
-???
-???
-?????
-?
-???
-
-
-?????
-?
-?
-?
-???
-??
-
-??
-?
-?
-
-
-
-
-??
-
-
-
-
-?
-?
-?
-??
-
-??
-?
-
-??
-????
-
-???
-
-?
-
-???
-??
-???
-?
-????
-?
-???
-??
-???
-?
-????
-??
-?
-?
-?
-??
-??
-???
-?
-?
-?
-???
-??
-?
-????
-???
-??
-??
-
-????
-
-
-??
-
-??
-??
-???
-????
-?
-?????
-?
-?
-?
-?
-?
-??
-??
-
-
-?
-?
-?
-??
-?
-??
-
-?
-
-??
-
-
-
-
-
-?
-
-
-??
-??
-???
-
-??
-??
-???
-??
-?
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-?
-??
-???
-??
-?????
-?????
-??
-??
-????
-??
-????
-????
-??????
-????
-??
-??????
-???
-????
-??
-????
-?????
-?????
-??
-???
-??
-???
-??
-??
-???
-????
-??
-?
-??
-?
-?
-?
-?
-???
-?????
-????
-?
-????
-?
-???
-?????
-??
-??
-????
-????
-??
-??
-??
-??
-???
-???
-???
-????
-???
-??
-???
-??
-?
-?
-??
-???
-???
-??
-????
-
-??
-?
-??
-??
-??
-???
-?????
-????
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-????
-
-
-?
-??
-
-
-
-
-?
-?
-???
-?????
-????
-????
-???
-???
-?????
-??
-??
-??
-??
-??
-????
-????
-??
-??
-???
-?
-??
-???
-?????
-???
-?????
-??????
-????????
-???
-??
-???
-????
-??
-?????
-??
-??
-??
-??
-????
-??
-???
-?????
-????
-???
-????
-????
-???
-???
-?????
-?????
-?????
-?????
-???????
-????
-?????
-???????
-????
-????
-????
-??
-??
-????
-?
-??
-?
-?
-??
-?
-??
-?
-?
-?
-??
-?
-?
-??
-?
-?
-?
-??
-
-?
-?
-
-
-??
-??
-
-??
-??
-
-
-
-?
-?
-???
-?
-?
-?
-
-?
-??
-?????
-?
-??
-?
-???
-?
-?
-???
-?
-?
-?
-?
-?
-???
-?
-?
-??
-??
-???
-???
-??
-??
-??
-???
-??
-
-??
-????
-?
-???
-???
-?
-?
-?
-?
-??
-???
-???
-??
-???
-
-
-
-
-?
-
-?
-?
-?
-?
-
-?
-??
-?????
-?
-???
-???
-??????
-?????
-??????
-????
-?
-?
-??
-???
-???
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?????
-????
-????
-????
-?????
-?????
-??
-??
-???
-???
-??
-????
-????
-????
-????
-???
-?????
-??????
-????
-?????
-????
-????
-?
-?
-??
-???
-??
-???
-??
-???
-??
-????
-??
-
-
-
-
-
-??
-??
-?
-
-??
-
-?
-?
-?
-?
-???
-?????
-??
-
-?
-?
-?
-??
-??
-
-?
-??
-?
-??
-
-?
-
-
-??
-
-??
-??
-
-
-?
-
-?
-?
-??
-?
-?
-?
-?
-??
-???
-?
-?
-?
-?
-??
-??
-?
-??
-?
-?
-??
-?
-??
-??
-??
-?
-?
-??
-
-
-
-??
-??
-??
-?
-???
-??
-?????
-??
-??
-??
-?
-?
-?
-????
-????
-
-?
-?
-??
-??
-?
-??
-
-
-
-???
-????
-???
-???
-?????
-?????
-??????
-???
-??????
-????
-????
-??
-
-
-???
-??
-??
-??
-?
-?
-???
-
-
-
-
-
-?
-?
-?
-?
-???
-???
-???
-???
-?????
-??
-
-?
-
-?
-??
-?
-?
-???
-?
-??
-
-??
-??
-????
-?
-?
-????
-???
-?
-??
-?????
-?
-?
-?
-????
-???
-????
-?
-??
-??
-??
-
-???
-????
-
-
-
-??
-?
-?
-??
-
-
-??
-??
-????
-?
-
-
-????
-?
-?
-?
-??
-??
-???
-?
-???
-??
-?
-?
-???
-?
-???
-??
-??
-?
-??
-?
-???
-??
-??
-??
-??
-????
-????
-??
-???
-????
-
-??
-?
-????
-????
-???
-???
-????
-????
-?????
-?
-
-??
-
-
-??
-
-
-
-?
-??
-?
-??
-???
-?
-
-?
-??
-?
-?
-
-??
-???
-?
-??
-????
-?
-???
-??
-
-
-?
-?
-?
-??
-
-
-?
-???
-????
-?????
-?
-?
-????
-???
-???
-?
-
-
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-?
-
-
-
-???
-
-
-
-
-
-??
-???
-?
-?
-?
-??
-??
-??
-?
-??
-??
-?
-???
-?
-?
-??
-??
-??
-?
-?
-?
-??????
-??
-?
-??
-??
-?
-???
-?
-??
-??
-???
-?
-???
-
-
-
-??
-
-??
-??
-??
-??
-????
-?
-??
-?????
-?
-???
-
-?
-
-??
-???
-?
-?
-?
-?
-??
-???
-?
-?????
-??
-????
-????
-?
-?
-???
-?
-???
-???
-???
-??
-???
-???
-?????
-
-
-
-
-
-
-
-
-??
-?
-?
-?
-??
-??????
-??????
-?????
-?
-?
-?
-?
-???
-??
-??
-????
-???
-???
-?
-?
-
-
-
-??
-
-?
-??
-
-?
-?
-?
-
-??
-??
-?
-?
-?
-?
-???
-??
-???
-???
-??
-?
-?
-?
-?
-??
-??
-???
-??
-???
-???
-???
-???
-????
-????
-?????
-?
-??
-
-?
-?
-?
-
-?
-
-?
-
-?????
-?????
-
-??????
-??
-?
-?
-??
-?
-??
-?
-??
-??
-???
-??
-?
-?
-?
-?
-??
-?
-
-??
-?
-???
-??
-?
-????
-?
-?
-?
-?
-?
-???
-?
-?
-?
-??
-???
-??
-????
-????
-????
-????
-???
-??
-???
-??
-??
-???
-????
-??
-?
-
-
-
-?
-???
-??
-??
-????
-???
-???
-????
-?
-???
-?
-??
-???
-????
-?
-???
-???
-?????
-??
-???
-??
-?
-????
-?
-???
-???
-????
-?????
-????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?????
-??
-??
-??
-???
-???
-???
-????
-??
-??
-?????
-???
-?
-?
-?
-?
-?
-???
-??
-????
-???
-?
-??
-???
-???
-??
-?????
-???
-???
-????
-???
-????
-???
-???
-?????
-?????
-?????
-?????
-???
-???
-??
-???
-????
-????
-?????
-????
-????
-?????
-???????
-?????
-???
-??????
-????
-???
-????
-???
-????
-???
-??
-???
-???
-????
-???
-???
-?
-???
-??
-??
-???
-????
-???
-????
-??
-??
-??
-????
-????
-???
-??
-??
-???
-??
-??
-?????
-?
-??
-??
-?
-?
-?
-??
-??
-???
-?
-??
-?
-?
-?
-???
-???
-??
-???
-???
-??
-??
-??
-??????
-??
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-????
-????
-?????
-????
-????
-?
-??
-?
-?
-?
-?
-??
-??
-???
-?
-??
-???
-???
-???
-???
-??
-??
-???
-?
-??
-???
-?
-???
-???
-?????
-????
-??
-???
-?????
-?
-??
-???
-?
-?
-???
-??
-??
-?????
-????
-??
-???
-?
-???
-?
-???
-?????
-??
-????
-????
-???
-????
-???
-?
-????
-???
-???
-????
-
-?
-?
-?
-??
-
-?
-?
-??
-??
-
-
-
-
-
-
-?
-
-?
-
-?
-
-
-??
-???
-?
-?
-???
-?
-?
-?
-???
-??
-
-
-
-
-?
-??
-
-?
-
-
-
-
-
-
-??
-??
-????
-?
-???
-???
-??
-?
-?
-??
-?
-??
-??
-??
-?
-?
-??
-?
-??
-??
-
-?
-?
-
-
-
-??
-?
-??
-????
-??
-?
-??
-??
-??
-????
-????
-????
-????
-?
-??
-
-
-??
-?
-
-
-?
-?
-??
-?
-
-
-?
-?
-?
-?
-????
-??
-??
-
-?
-???
-????
-????
-?
-?
-???
-
-??
-??
-??
-????
-???
-??
-
-??????
-?????
-?
-
-
-
-?
-
-??
-
-?
-
-
-
-
-?
-?
-??
-???
-??
-??
-?
-??
-?
-??
-???
-?
-??
-???
-??
-???
-???
-
-
-???
-
-
-?
-?
-?
-
-
-??
-????
-???
-???
-?????
-?
-??
-?
-???
-?
-??
-??
-????
-???
-????
-??
-
-??
-
-??
-??
-
-
-?
-
-
-
-??
-??
-??
-????
-?
-???
-
-
-
-?
-??
-???
-?
-
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-
-???
-
-
-
-?
-?
-???
-?
-??
-?
-??
-?
-??
-??
-
-
-?
-?
-?
-??
-?
-??
-
-?
-??
-?
-
-
-
-
-
-?
-??
-??
-
-?
-?
-??
-
-?
-?
-??
-?
-
-?
-?
-???
-
-?
-?
-??
-????
-
-
-
-??
-
-??
-??
-??
-
-
-
-?
-?
-?
-??
-????
-??
-??
-????
-?
-???
-??
-?
-?
-???
-?
-?
-???
-???
-??
-???
-?????
-??
-??
-???
-??
-?????
-???
-???
-???
-????
-???
-??????
-???
-?
-??
-?
-?
-?
-??
-????
-????
-???
-??
-??
-
-?
-?
-
-
-
-??
-?
-?
-?
-??
-?
-?
-?
-??
-???
-?
-?????
-
-?
-
-
-
-
-
-?
-???
-??
-??
-??
-???
-????
-
-
-
-
-
-
-
-
-?
-???
-????
-???
-???
-???
-?????
-????
-????
-???
-???
-????
-
-
-
-
-???
-??
-??
-?
-???
-??
-????
-
-
-?
-
-
-
-
-
-
-?
-?
-??
-??
-
-
-
-
-?
-?
-??
-?
-?
-?
-?
-??
-????
-???
-??
-??
-
-
-?
-??
-?
-???
-???
-?
-??
-?
-??
-?
-?
-?
-??
-???
-?
-??
-???
-?????
-??
-?
-??
-??
-?
-?
-?
-???
-????
-????
-?????
-???
-??
-??
-??
-???
-?
-???
-??
-????
-?????
-????
-?????
-????
-???
-?
-???
-?
-????
-??
-????
-???
-?
-?
-??
-???
-???
-??
-??
-????
-??
-?????
-????
-???
-???
-??
-???
-?????
-?????
-?????
-?????
-???????
-??
-????
-??
-??????
-??
-???
-?????
-??
-??
-??
-??
-?????
-???
-??
-??
-????
-???
-???
-????
-????
-?????
-????
-????
-?
-??
-????
-?
-???
-??
-???
-?
-?
-?
-?
-??
-??
-??
-????
-????
-??????
-???
-?????
-????
-??
-??
-???
-????
-????
-
-
-?
-?
-???
-
-
-??
-?
-?
-????
-?
-?
-???
-?
-
-?
-?
-?
-?
-?
-??
-
-??
-??
-?
-
-
-
-??
-??
-?
-
-
-
-?
-
-
-?
-
-??
-
-
-
-?
-??
-?
-?
-?
-?
-
-
-
-
-??
-
-?
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-???
-?
-?
-???
-?
-?
-?
-??
-??
-
-?
-
-
-??
-?
-??
-??
-???
-?
-
-??
-??
-
-
-
-?
-???
-??
-?
-?
-??
-??
-???
-?
-?
-?
-?
-?
-??
-????
-???
-???
-???
-???
-???
-?????
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-
-
-
-?
-
-
-
-
-?
-??
-???
-?
-
-
-??
-?
-
-???
-
-?
-
-?
-?
-??
-
-
-
-
-
-??
-
-????
-?
-?
-??
-?
-??
-??
-??
-??
-?
-??
-?
-?
-?
-?
-?
-??
-
-?
-
-
-
-
-?
-??
-
-?
-??
-?
-
-?
-??
-?
-?
-
-
-
-?
-
-
-
-
-
-
-?
-?
-??
-
-
-?
-?
-?
-
-
-
-
-
-
-
-??
-?
-??
-??
-??
-??
-???
-???
-????
-???
-??
-????
-??
-?
-
-
-
-????
-?
-
-?
-?
-?
-??
-???
-?
-?
-?
-??
-??
-??
-?
-??
-??
-???
-??
-??
-??
-?
-?
-?
-??
-?
-??
-?
-??
-??
-??
-?????
-
-??
-?
-???
-??
-?????
-???
-?
-?
-??
-?
-??
-???
-?
-???
-??????
-?
-??
-???
-?
-???
-?????
-??
-?
-??
-????
-???
-??
-????
-??
-??
-?
-??
-??
-???
-???
-?????
-????
-????
-??????
-?
-???
-???
-???????
-?????
-?????
-??????
-??
-??
-??
-?????
-???????
-???????
-??
-????
-???
-??
-????
-???
-???
-?????
-????
-??
-??
-??
-????
-????
-????
-???
-???
-??
-??
-???
-??
-???
-???
-???
-???
-????
-??
-???
-??
-??
-??
-??
-??
-??
-???
-?????
-???
-???
-????
-????
-???
-???
-???
-????
-???
-???
-??
-??
-??
-?
-?
-?
-??
-?
-??
-???
-?
-????
-?
-???
-???
-?????
-?
-??
-?????
-??????
-??????
-?????
-??
-?
-??
-??
-??
-??
-???
-??
-?????
-????
-??
-??
-???
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-?????
-?????
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-??
-???
-??
-??
-???
-??
-
-
-?
-??
-?
-??
-??
-
-
-??
-?
-
-
-
-??
-???
-?????
-?
-??
-????
-???
-???
-???
-????
-????
-?
-?
-?
-?
-?
-??
-?
-??
-????
-???
-???
-???
-???
-??
-??
-????
-?????
-??
-????
-????
-??
-?????
-????
-???
-?
-???
-??
-??
-??
-?
-?
-???
-?
-?
-???
-?
-??
-?
-?
-???
-??
-??
-??
-?????
-?????
-??????
-???
-??
-???
-????
-???
-???
-?????
-?
-?
-??
-??
-?
-?
-?
-?
-??
-??
-???
-??
-?????
-??
-?
-??
-
-
-
-?
-
-
-
-??
-
-?
-
-
-?
-??
-???
-??
-???
-???
-??
-????
-?????
-
-
-
-
-??
-
-?
-?
-???
-??
-??
-?
-?
-??
-????
-??
-??
-????
-
-?
-??
-
-
-??
-?
-??
-?
-
-?
-
-
-
-?
-??
-?
-?
-??
-??
-??
-???
-????
-
-
-
-?
-?
-?
-?
-???
-?
-?
-???
-????
-????
-??
-?
-?
-??
-?
-??
-?
-?
-?
-??
-???
-??
-???
-?
-??
-????
-??
-??
-???
-????
-??
-??
-????
-???
-?????
-????
-???
-????
-????
-??
-???
-???
-????
-???
-??
-??
-?
-??
-??
-???
-????
-???
-???
-????
-???
-???
-?????
-??
-??
-??
-???
-????
-???
-????
-???
-???
-??????
-
-?
-?
-?
-
-?
-?
-?
-?
-??
-????
-?
-???
-?
-???
-?
-
-?
-
-??
-
-?
-??
-?
-
-?
-?
-??
-
-
-
-
-
-?
-?
-??
-?
-??
-???
-??
-??
-?
-?
-
-?
-?
-?
-??
-??
-?
-???
-???
-???
-???
-????
-?????
-?
-?
-?
-?
-??
-??
-?
-??
-???
-??
-???
-??
-????
-?
-???
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-???
-??
-??
-??
-??
-???
-???
-??
-???
-
-
-?
-
-
-??
-?
-????
-?
-??
-???
-????
-
-?
-???
-?
-?
-???
-
-??
-
-??
-??
-??
-????
-?
-?
-???
-??
-????
-
-
-??
-
-??
-
-??
-??
-
-???
-??
-?
-?
-??
-????
-???
-?
-???
-??
-???
-
-
-??
-???
-????
-??
-??
-??
-?
-???
-
-?
-
-
-
-
-?
-
-?
-
-?
-?
-?????
-?
-
-????
-????
-?
-?
-???
-???
-???
-?
-??
-???
-?????
-?
-?
-?
-??
-???
-?????
-??
-????
-???
-??
-??
-???
-???
-??
-???
-?
-?
-???
-??
-?
-????
-???
-??
-??
-??
-???
-?
-?
-???
-??
-???
-???
-??
-??
-??
-??
-??
-???
-???
-????
-??????
-????
-????
-????
-???
-???
-??????
-????
-???
-????
-????
-??????
-??
-???
-??
-????
-?
-?
-???
-????
-??
-?????
-????
-????
-???
-???
-?????
-??
-?
-?
-?
-?
-??
-?
-??
-???
-??
-??
-??
-??
-???
-???
-?
-?
-?
-?
-???
-???
-???
-?????
-????
-??
-?
-???
-??
-???
-????
-?
-???
-??
-??
-???
-????
-??
-???
-????
-?????
-????
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-???
-?
-?
-?
-??
-?
-??
-??
-??
-????
-????
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-??
-???
-???
-????
-??
-??
-???
-????
-??
-???
-???
-???
-??
-??
-???
-???
-???
-????
-????
-????
-?????
-????
-????
-??
-??
-????
-??
-???
-???
-???
-???
-????
-?????
-???
-???
-???
-????
-????
-????
-????
-???
-??????
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-????
-????
-?????
-???????
-????
-???
-???
-???
-????
-????
-???
-??
-???
-???
-???
-??
-??
-??
-??
-?????
-????
-????
-????
-??
-??
-???
-???
-??????
-??
-????
-????
-??????
-??????
-??
-??
-???
-????
-????
-?????
-??
-??
-??
-??
-??
-???
-??
-????
-???
-???
-???
-?????
-????
-????
-????
-?????
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-????
-??????
-?
-?????
-???
-?????
-??????
-???
-?????
-???
-???
-?
-??
-???
-???
-???
-???
-?????
-????
-?????
-??
-??
-??
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-???
-????
-????
-???
-??
-??
-????
-????
-????
-??
-??
-??
-???
-???
-??
-?
-?
-???
-?
-?
-??
-??
-???
-??
-??
-??
-????
-???
-???
-???
-???
-???
-???
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-???
-???
-?
-?
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-???
-???
-??
-??
-?
-?
-?
-???
-?????
-???
-???
-???
-????
-????
-????
-????
-????
-????
-???
-?
-???
-??
-??
-??
-??
-??
-??
-???
-????
-???
-????
-??????
-?????
-???
-????
-??????
-???
-???
-???
-?????
-?????
-???
-???
-????
-?????
-??????
-???
-???
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-?????
-??????
-??????
-?????
-???
-????
-???
-??
-????
-????
-?????
-?
-?
-???
-???
-?????
-????
-??????
-??
-???
-???
-???
-???
-?????
-?????
-???
-???
-????
-????
-?????
-????
-?????
-?
-??
-??
-?????
-??????
-??
-????
-????
-??????
-??????
-??????
-?
-???
-??
-????
-??
-?
-?
-?
-???
-???
-??
-?
-???
-???
-?????
-???
-??
-??
-??
-??
-????
-??
-??
-?????
-??????
-???
-???
-??
-?
-?????
-??
-??
-??
-??
-??
-????
-????
-?????
-?????
-?????
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-???
-??
-???
-???
-???
-???
-????
-????
-??????
-??????
-?????
-?????
-?????
-???????
-??????
-????
-???
-???
-???
-?????
-????
-??
-???
-???
-????
-???
-????
-???
-???
-??
-??
-??
-??????
-??
-????
-???
-????
-?????
-???
-???
-????
-??
-??
-??
-????
-??
-???
-???
-??
-???
-????
-??
-?????
-?????
-???
-???
-???
-???
-????
-???
-???
-???
-????
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-?????
-?????
-??????
-????
-?????
-??????
-???
-???
-???????
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-???
-???
-???
-????
-???
-???
-????
-?????
-?????
-?????
-???
-???
-?????
-????
-?????
-???
-???
-???
-???
-???
-????
-????
-?????
-???
-???
-???
-????
-???
-???
-???
-???
-????
-????
-???
-????
-?????
-????
-????
-??????
-????????
-?????
-?????
-?????
-?????
-??????
-???
-????
-???
-???
-????
-??
-??
-???
-???
-??
-???
-???
-???????
-?????
-??
-???
-?????
-????
-??
-??
-??
-????
-????
-????
-????
-??
-????
-????
-??
-?
-?
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-??
-????
-?
-?
-?
-???
-??
-????
-?
-?
-?
-?
-??
-??
-???
-??
-??
-???
-???
-????
-???
-???
-???
-????
-??????
-??????
-????
-??????
-?????
-???
-???
-?????
-???
-?????
-?????
-???
-???
-????
-???
-????
-???
-????
-?????
-??
-??
-?????
-?????
-????
-??
-??
-???
-??
-???
-???
-????
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-???
-????
-?
-?
-?
-?
-?
-????
-??
-??
-??
-???
-????
-?????
-????
-????
-??
-?????
-???
-???
-???
-????
-?????
-??????
-?????
-??????
-??
-??
-??
-????
-????
-???
-????
-??????
-?????
-????
-????
-??
-??
-???
-????
-?????
-???
-???
-???
-???
-?????
-??????
-????
-????
-?????
-?????
-??????
-??????
-?????
-????
-????
-?????
-????
-????
-??
-??
-??
-?????
-??
-??
-????
-???
-????
-??????
-???
-?????
-???
-???
-???
-???
-????
-????
-?????
-????
-????
-???
-???
-????
-????
-????
-?????
-??????
-?????
-???
-??
-???
-?????
-?????
-???
-?
-????
-?
-?
-???
-??
-?
-??
-????
-????
-???
-????
-????
-?????
-?????
-???????
-??????
-????????
-?????
-??
-?
-?
-?
-?
-?
-???
-?????
-?
-??
-???
-??
-??
-???
-??????
-?????
-???
-??
-????
-???
-????
-????
-???
-???
-??
-??
-???
-?
-?
-?
-?
-???
-?
-?
-?
-?
-??
-??
-??
-???
-?
-?
-??
-??
-?
-??
-??
-?
-?
-??
-???
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?????
-?
-?
-?
-?
-?
-??
-??
-???
-??
-???
-??
-??
-??
-??
-????
-???
-????
-???
-???
-????
-???
-??
-??
-????
-???
-????
-??
-??
-??
-??
-??
-?
-?
-?
-???
-??
-??
-??
-????
-???
-??
-??
-???
-???
-???
-???
-?
-???
-??
-?
-?
-??
-??
-?
-?
-??
-??
-???
-??
-????
-????
-????
-?????
-?????
-??
-????
-?????
-????
-????
-??
-??
-???
-????
-??
-??
-?
-?
-???
-???
-??
-?
-?
-?
-?
-???
-?
-?
-??
-??
-?????
-???
-????
-??
-??
-??
-???
-???
-????
-??
-???
-???
-?
-????
-??
-??
-???
-????
-???
-??
-??
-??
-???
-????
-???
-???
-???
-??
-??
-??
-???
-???
-???
-???
-??
-???
-?????
-????
-????
-????
-???????
-?????
-?????
-?????
-????
-?????
-??
-??
-??
-???
-???
-???
-????
-??
-???
-???
-????
-????
-????
-??????
-??????
-????
-????
-????
-?????
-???
-???
-??
-??
-?????
-?????
-??????
-??????
-?
-?????
-?
-?
-???
-???
-???
-???
-????
-???
-?????
-?
-??
-????
-?
-???
-????
-?
-??
-??
-??
-??
-???
-?
-??
-?
-?
-?
-?
-???
-????
-?????
-??
-??
-???
-??
-??
-??
-??
-?????
-??
-???
-???
-???
-???
-?
-??
-???
-??
-??
-????
-?
-?
-????
-?
-??
-??
-?
-??
-??
-??
-??
-???
-?????
-????
-????
-????
-????
-?????
-????
-????
-???
-???
-??
-???
-???
-?
-??
-????
-???
-???
-???
-????
-?????
-?
-?
-?
-??
-?????
-????
-????
-????
-??????
-???
-??
-??
-??
-??
-??
-????
-??
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-??
-?????
-???
-????
-???
-??
-?????????
-????????
-???
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-????
-???
-???
-??
-??
-???
-??
-??
-??
-??
-?
-?
-???
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-???
-???
-????
-?
-?
-?
-?
-???
-?
-??
-???
-????
-?????
-??
-??
-???
-??
-??
-??
-??
-????
-???
-????
-????
-?????
-????
-????
-????
-??????
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-??
-???
-???
-??
-?
-???
-??
-????
-???????
-???????
-????????
-????
-????
-???
-???
-????
-????
-?????
-?????
-???
-???
-?????
-?????
-??????
-???
-??????
-?????
-?????
-?????
-???????
-????
-????
-?????
-????
-??
-??
-???
-??
-???
-?
-?
-???
-?????
-?
-?
-?
-???
-?
-?
-?
-?
-??
-??
-???
-?
-???
-????
-?????
-???
-??
-??
-???
-????
-???
-??
-?????
-???
-?????
-????
-?????
-??????
-???
-????
-??
-??
-????
-?????
-?
-?
-?
-???
-?
-??
-???
-??
-????
-??
-??
-???
-?
-?
-?
-?
-??
-?
-??
-?
-?
-??
-????
-???
-?
-?
-?
-???
-??
-???
-??
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-??
-??
-???
-??
-????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-???
-??
-??
-?
-??
-??
-??
-???
-?????
-????
-?????
-????
-?????
-????
-????
-?????
-??????
-??????
-????
-????
-??
-???
-????
-???
-??
-????
-????
-?????
-??
-??
-????
-???
-?
-?
-???
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-???
-???
-????
-??
-?????
-????
-??
-???
-????
-???
-???
-????
-???
-?????
-????
-????
-????
-?????
-?????
-???????
-?????
-?????
-??????
-?????
-?????
-?????
-?????
-???????
-????????
-??
-???
-????
-????????
-????
-??
-???
-????
-????
-?????
-???
-???
-??????
-???
-???
-?????
-???
-?????
-???????
-??????
-?????
-???????
-???
-????
-????
-????
-????
-?????
-???????
-???????
-????
-????
-??????
-????
-??????
-??????
-??????
-??????
-????????
-???????
-?????
-????
-?????
-?????
-???
-????
-?????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-??????
-??
-??
-???
-????
-???
-???
-??
-????
-?????
-??
-???
-???
-???
-?????
-?????
-???
-????
-???
-?????
-???????????
-?????
-?????
-?????
-??????
-??????
-??????
-???????
-?????
-?????
-???????
-???????
-???????
-???????
-???????
-???????
-????????
-???????
-????
-?????
-??????
-?????
-?????
-????
-????
-????
-??????
-?
-??
-???
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-???
-???
-??
-???
-????
-???
-???
-??
-??
-??
-????
-???
-????
-????
-???
-???
-??
-??
-???
-???
-??
-??
-???
-????
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??
-??
-??
-?
-?
-???
-?????
-??
-??????
-???
-???
-???
-???
-????
-???
-???
-?????
-???
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-????
-????
-?????
-???
-?????
-???
-?????
-?????
-????
-?
-???
-????
-???
-???
-????
-????
-????
-????
-???
-????
-????????
-????
-?????
-?
-?????
-????????
-????
-?????
-?
-??
-??
-????
-???
-??
-??
-???
-?
-?
-??????
-????
-????
-??
-????
-?
-???
-??
-?
-?
-??
-????
-??
-???
-????
-?????
-?????
-??????
-??????
-??????
-?????
-????????
-??
-??
-??
-??
-????
-????
-??
-??
-????
-????
-???
-???
-?????
-?????
-????
-?????
-?????????
-????
-?????
-??????
-?????
-??
-????
-????
-?????
-??
-??
-??
-??
-???
-????
-????
-????
-?????
-??????
-??
-???
-????
-?????
-?????
-??????
-???
-?????
-??????
-??????
-????
-????
-????
-????
-?????
-?????
-??????
-??????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-?????
-?????
-????
-??????
-????
-??
-??
-???
-???
-???
-???
-???
-???
-?????
-?????
-????
-???
-???
-????
-????
-???
-????
-????
-???
-?????
-???
-???
-?????
-????
-????
-?????
-?????
-?????
-????
-??
-?
-?
-?
-?
-?
-?
-???
-?
-??
-???
-???
-?
-?
-?
-?
-?
-??
-?
-??
-???
-????
-??
-??
-????
-???
-????
-??????
-???
-??
-???
-?
-?
-???
-??
-??
-??
-?
-?
-?
-??
-??
-???
-????
-???
-?
-?
-??
-???
-??
-????
-??????
-???
-????
-????
-???
-???
-?????
-??
-??
-?
-???
-???
-???
-?
-??
-??
-??
-??
-???
-????
-???
-????
-???
-????
-??
-???
-???
-??
-??
-????
-????
-???
-????
-?
-??
-???
-?
-??
-??
-?
-??
-???
-?
-??
-??
-?
-?
-??
-???
-??
-???
-?
-?
-?
-?
-???
-????
-???
-??
-??
-???
-???
-????
-????
-??????
-??????
-??
-???
-?
-?
-??
-?
-??
-??
-???
-?
-??
-?
-???
-???
-???
-?
-???
-?
-?
-?
-??
-???
-???
-?
-?
-??
-???
-???
-???
-???
-???
-????
-???
-???
-????
-??
-???
-??
-??
-??
-???
-???
-????
-???
-?????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-???
-???
-?????
-????
-????
-????
-?????
-??????
-??
-????
-????
-??
-??
-????
-?????
-??????
-?????
-???
-??????
-??
-???
-??????
-?
-??
-??
-??
-??
-???
-???
-????
-??
-???
-???
-??
-??
-????
-??
-???
-????
-???
-????
-??
-??
-??
-??
-???
-????
-???
-???
-????
-?????
-?????
-?????
-???????
-????
-??????
-?????
-??
-??
-????
-????
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-????
-????
-?
-?????
-??
-??
-???
-??
-??????
-?????
-?????
-??
-????
-????
-???
-????
-??????
-??
-??
-??
-???
-????
-???
-???
-??
-???
-???
-?????
-?????
-???????
-??????
-??????
-????
-????
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-?
-??
-??
-??
-?
-??
-?
-?
-???
-??
-???
-???
-??
-??
-????
-??
-?
-??
-????
-??????
-???
-??
-????
-????
-??????
-?????
-???
-?????
-??
-??
-????
-???
-?
-?????
-??????
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-????
-????
-????
-???
-???
-????
-???
-?????
-??
-?
-??
-??
-???
-??
-???
-?
-?
-?
-?
-??
-??
-?
-??
-?
-??
-?
-?
-?
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-??
-?
-??
-??
-??
-???
-??
-??
-??
-????
-?
-????
-?
-?
-???
-?
-??
-???
-?
-??
-?
-????
-?
-???
-???
-??
-??
-????
-???
-???
-??
-????
-?
-?
-?
-?
-??
-???
-???
-?
-?
-???
-?
-?
-???
-???
-???
-?????
-??
-????
-??
-??
-????
-???
-????
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-?
-???
-?
-?
-??
-??
-???
-???
-???
-?????
-????
-???
-?????
-??
-????
-??
-???
-??
-??
-??
-???
-??
-??
-???
-???
-??
-???
-??
-??
-????
-????
-????
-???
-??
-??
-????
-??
-?
-??
-??
-???
-????
-????
-???
-??
-??
-??
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-???
-?
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-????
-????
-?
-????
-?????
-??????
-?????
-????
-??????
-??
-??
-???
-????
-???
-?????
-???
-???
-???
-??????
-????
-????
-??
-???
-?????
-?????
-?????
-???????
-???????
-???
-??
-?????
-???
-??????
-???
-?????
-??????
-???
-???
-???
-?????
-????
-????
-??????
-?????
-??????
-?????
-????
-???
-??
-?
-?????
-??
-???
-???
-??
-????
-????
-?
-??
-?
-?
-??
-????
-???
-???
-?????
-????
-???
-????
-???
-?
-?
-?
-?
-?
-?
-??
-?
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-????
-???
-???
-???
-????
-?
-??
-?
-?
-?
-?
-?
-?
-???
-??
-???
-???
-???
-???
-?????
-??
-???
-???
-?
-???
-?????
-?
-??
-???
-???
-????
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-???
-???
-???
-???
-????
-?????
-????
-??
-??
-??
-??
-????
-??
-??
-????
-????
-???
-??
-??
-???
-????
-???
-???
-????
-???
-???
-??
-??????
-????
-?????
-??
-????
-?
-??
-???
-?????
-?????
-??????
-?????
-??????
-??
-?
-???
-?
-?
-?
-??
-??
-??
-???
-?????
-???
-???
-?????
-???
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-???
-??
-??
-???
-???
-?????
-??
-???????
-??
-??
-??
-???
-???
-????
-??
-???
-???
-???
-????
-??
-???
-??
-??
-??
-???
-???
-????
-???
-???
-?
-??
-?
-???
-?
-?
-?
-??
-??
-??
-??
-????
-???
-?
-??
-?
-?
-???
-?
-???
-?
-???
-???
-?????
-??
-????
-???
-???
-??
-????
-??
-??
-????
-????
-???
-???
-????
-????
-??
-???
-??
-??
-??
-????
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-???
-??
-???
-??
-??
-????
-??
-????
-??
-????
-???
-????
-????
-???
-????
-????
-?????
-????
-??????
-??
-??
-????
-?????
-??????
-???
-???
-?????
-?????
-?????
-????
-?????
-????
-???
-????
-???
-???
-????
-???
-?????
-?????
-???
-????
-???
-?????
-?????
-?
-??
-??
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?
-??
-??
-??
-??
-???
-???
-??
-???
-??
-??
-????
-????
-????
-???
-?????
-?????
-????
-?????
-?????
-??
-????
-??
-?????
-??
-??
-????
-??
-????
-????
-????
-????
-??????
-?
-?
-?
-?
-???
-???
-?????
-??
-?
-?
-?
-?
-???
-???
-???
-??
-???
-???
-??
-????
-????
-????
-??????
-????
-???
-????
-????
-????
-?????
-????
-????
-????
-???
-????
-??
-??
-???
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-????
-???????
-??????
-?????
-????
-??
-???
-??
-????
-???
-??
-??
-?????
-???
-????
-??
-??
-??
-??
-???
-????
-????
-???
-??
-????
-????
-?????
-???
-???
-???
-???
-???
-?????
-????
-???????
-??????
-??????
-???????
-???????
-??????
-??????
-??????
-????????
-????????
-???????
-??????
-????
-???
-???
-???
-?????
-?????
-?????
-????
-????
-????
-????
-?????
-?????
-???
-??
-?????
-?????
-?????
-???
-???
-???
-???
-???
-???
-????
-?????
-???
-?????
-???
-????
-????
-????
-?????
-???
-???
-???
-????
-????
-????
-????
-???????
-?????
-?????
-?????
-????
-???
-????
-????
-?????
-??????
-?????
-????
-????
-??????
-????
-?????
-????
-????
-????
-??????
-?????
-???
-???
-??????
-??????
-??????
-???????
-???????
-????????
-??????
-??????
-??????
-???????
-????????
-??????
-??????
-??????
-????????
-????????
-?????????
-??????????
-????
-????
-???
-???
-?????
-???
-????
-????
-????
-????
-????
-?????
-???
-?????
-????
-????
-??????
-???
-????
-?????
-????
-?????
-???
-???
-???
-???
-?????
-???
-?????
-?????
-???????
-???
-????
-?????
-?????
-????
-???????
-????
-??????
-????????
-???????
-???
-???
-???
-????
-??
-??
-?????
-????
-?????
-?????
-????
-????
-???
-????
-????
-??????
-???
-????
-???
-???
-???
-???
-?????
-?????
-????
-??
-??
-??
-????
-???
-????
-??
-??
-????
-??
-??
-????
-???
-???
-?????
-????
-????
-??
-??
-???
-????
-?????
-???
-??
-???
-????
-???
-???
-???
-???
-????
-????
-?????
-????
-????
-??????
-???
-??????
-??????
-???
-??
-???
-?????
-???
-???
-????
-????
-????
-?????
-???
-???
-???
-???
-?????
-????
-???????
-??
-??
-??
-??
-??
-???
-???
-???
-?????
-???
-??????
-??????
-???
-???
-??????
-???????
-??????
-???
-????
-???
-???
-???
-????
-??
-????
-????
-???
-??
-????
-??
-??
-???
-??
-????
-???
-??
-????
-???
-????
-???
-?????
-????
-???????
-????
-??????
-??????
-?????
-???
-???
-???????
-???
-???
-???
-???
-????
-?????
-??????
-??????
-?????
-????
-????
-????
-????
-?????
-???
-???
-???
-????
-????
-???
-???
-???
-???
-???
-?????
-????
-?????
-????
-????
-????
-????
-?????
-?
-??????
-??????
-?????
-??
-?
-?
-???
-??
-?
-?
-?
-?
-??
-?
-????
-???
-???
-???
-????
-?
-?
-?
-?????
-????
-????
-??????
-?????
-???
-?????
-?
-??
-??
-?
-?
-?
-?
-?
-????
-??????
-??
-???
-???
-?????
-??
-??
-?????
-????
-????
-??
-???
-?????
-????
-????
-???
-???
-?????
-?????
-????
-??????
-??????
-???
-??
-???
-???
-???
-??
-????
-?
-????
-????
-???
-???
-???
-?????
-?????
-?
-????
-?????
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-??
-????
-???
-???
-?????
-???
-???
-????
-?
-?
-?
-??
-??
-??
-?
-??
-??
-???
-????
-??
-???
-?
-?
-?
-?
-?
-?
-?
-?
-???
-??
-??
-????
-???
-??
-??
-?
-??
-?
-?
-?
-???
-??
-???
-??
-?
-??
-??
-?
-??
-?????
-?
-??
-????
-???
-??
-??
-???
-??
-????
-???
-???
-????
-????
-????
-??
-????
-???
-??
-???
-???
-???
-?
-?
-?
-??
-???
-?
-?????
-??????
-???
-??
-??
-?????
-??
-??
-????
-????
-?????
-??????
-?????
-???
-?
-??
-??
-??
-??
-???
-????
-??
-??
-???
-????
-????
-????
-????
-?????
-??????
-??????
-???????
-????
-?????
-?????
-?????
-??
-???
-??
-??
-??
-?????
-???
-???????
-?
-??
-?
-?
-???
-?????
-??
-???
-?
-??
-???
-?
-??
-????
-???
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-???
-???
-???
-???
-?????
-?
-??
-?
-??
-?
-?
-??
-????
-????
-????
-?
-???
-?????
-????
-????
-???
-???
-????
-??
-??
-????
-?
-??
-?
-?
-???
-?
-???
-???
-???
-?????
-??
-???
-?????
-??
-?
-?
-?
-??
-??
-?
-?
-???
-???
-???
-????
-????
-????
-???
-???
-???
-??
-????
-???
-???
-????
-??
-??
-??
-????
-?
-??
-??
-??
-????
-??
-????
-??
-?
-??
-???
-?
-??
-??
-??
-????
-?
-?
-???
-?
-??
-??
-?
-??
-??
-?
-?
-???
-???
-?
-??
-??
-???
-??
-???
-?
-?
-?
-??
-??
-??
-????
-???
-???
-???
-???
-?
-?
-?
-?
-???
-???
-????
-?
-????
-??
-???
-??
-??
-????
-????
-???
-???
-????
-????
-??
-???
-????
-???
-??
-??
-??
-????
-????
-??
-????
-?
-?
-?
-?
-?
-?
-??
-?
-??
-?
-??
-?
-?
-?
-?
-???
-??
-?
-?
-???
-???
-??
-?????
-???
-???
-???
-?
-??
-??
-??
-???
-??
-???
-??
-???
-??
-???
-???
-????
-???
-????
-??
-??
-??
-??
-??
-??
-??????
-???
-???
-???
-???
-????
-?????
-?????
-?????
-???
-????
-????
-??????
-?????
-?????
-?????
-?????
-??????
-?
-??
-?
-??
-??
-????
-???
-?
-??
-??
-??
-??
-????
-???
-??
-????
-??
-?
-?
-?
-???
-??
-??
-????
-?????
-?????
-??????
-??
-?
-?
-?
-???
-??
-????
-?????
-???
-????
-???
-???
-???
-????
-????
-????
-???
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-?????
-????
-?????
-???
-????
-??????
-???
-??
-????
-????
-????
-???
-???
-??
-????
-?
-?
-?
-?
-?
-??
-?
-??
-???
-??
-???
-?
-???
-??
-???
-????
-???
-????
-??
-??
-???
-??
-?
-???
-???
-??
-?
-?
-???
-??
-???
-????
-?
-?
-??
-?
-???
-????
-??
-??
-??
-?????
-???
-???
-???
-?
-???
-????
-???
-?????
-???
-?????
-???
-???
-??
-??
-????
-???
-??
-??
-?
-??
-?
-?
-?
-???
-??
-??
-???
-?????
-???
-???
-???
-????
-???
-???
-???
-?????
-??????
-??????
-??
-??
-???
-?????
-??
-????
-??
-????
-????
-???
-?
-?
-???
-???
-??
-??
-??
-?
-?
-?
-?
-??
-????
-????
-?????
-?
-???
-?
-?
-???
-???
-?
-??
-??
-???
-???
-????
-????
-???
-????
-??
-????
-????
-??????
-?????
-????
-??
-????
-???
-????
-??????
-???
-?????
-?
-?
-????
-?
-??
-?
-?
-?
-?
-?
-???
-???
-???
-????
-??
-??
-???
-??
-???
-?
-?
-?
-?
-???
-???
-????
-?????
-????
-?????
-??
-??
-?
-???
-?
-?
-?
-??
-???
-?
-?
-??
-??
-?????
-??
-??
-??
-???
-?
-???
-???
-??
-?
-?
-???
-?????
-??
-??
-???
-?????
-?????
-????
-????
-????
-????
-????
-?????
-??????
-??????
-????
-???
-???
-???
-??
-????
-????
-??
-?????
-??????
-???
-????
-????
-??
-??
-??
-??
-??
-???
-????
-????
-?????
-????
-????
-?????
-?????
-????
-???
-????
-???
-?????
-???
-???
-?????
-????
-????
-????
-???
-???
-?????
-???
-????
-????
-???
-????
-?????
-???
-???
-????
-???
-??
-??
-??
-??
-??
-??
-????
-??
-??
-???
-??
-??
-????
-??
-????
-???
-??
-??
-??
-???
-???
-???
-???
-??????
-?????
-?????
-????
-????
-???
-????
-????
-???
-????
-????
-????
-??????
-????
-?????
-????
-???
-??
-??
-????
-????
-?????
-???
-???
-????
-????
-????
-??????
-????
-????
-??????
-????
-??????
-??????
-?????
-?????
-??????
-????
-?????
-???????
-??????
-??????
-??????
-?????
-?????
-?????
-?????
-???????
-??
-??
-??
-????
-???
-???
-???
-????
-????
-?????
-?????
-??????
-???
-???
-?????
-????
-???
-????
-????
-????
-???
-????
-????
-????
-?????
-?????
-?????
-???
-??????
-???
-???
-???
-?????
-?????
-???
-?????
-??????
-??????
-?????
-????
-????
-?????
-??????
-?????
-???????
-?????
-???
-????
-????
-???????
-?????
-?????
-?????
-???
-?????
-?????
-??????
-?????
-?????
-??????
-??????
-???
-???
-????
-?????
-????
-???
-???
-???
-?????
-?????
-????
-????
-????
-????
-????
-????
-??????
-?????
-?????
-?????
-????
-????
-????
-?????
-?????
-?????
-????
-????
-????
-??????
-?????
-??????
-??????
-??????
-??????
-????
-?????
-????
-??????
-??????
-???????
-???????
-??????
-????????
-?????
-??????
-???????
-????
-????
-??????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-??????
-????
-??????
-??????
-??????
-??????
-???????
-?????
-???
-?????
-?????
-?????
-???????
-??????
-???????
-???????
-????
-???
-???
-???
-???
-????
-???
-????
-????
-???
-?????
-????
-??????
-???
-???
-?????
-???
-??
-??
-????
-????
-???
-?????
-???
-?????
-?????
-?????
-?????
-????????
-???????
-???????
-????
-????
-????
-??????
-????
-?????
-??????
-?????
-??
-??
-??????
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??????
-???
-??
-??
-??
-?????
-????
-???
-???
-???
-??????
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-???
-??
-???
-?????
-??
-??
-???
-???
-???
-????
-???
-????
-???
-???
-?????
-????
-???
-???
-????
-????
-?????
-????
-????
-????
-????????
-???????
-????
-????
-??????
-??????
-?????
-?????
-??????
-?????
-??????
-???????
-??????
-??????
-??????
-????????
-??
-?????
-?????
-?????
-?????
-????????
-??????
-???????
-??
-???
-???
-?????
-????
-??????
-???
-????
-??
-???
-??
-??
-???
-???
-????
-??
-???
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-???
-???
-????
-????
-???
-??
-???
-???
-????
-?????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-?????
-??
-????
-???
-???
-???
-????
-???
-?????
-??????
-??????
-????
-????
-????
-????
-????
-?????
-????
-?????
-??
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-?????
-?????
-????
-???
-??
-??
-??
-??
-?????
-???
-???
-????
-????
-????
-?????
-???
-????
-????
-????
-???
-???
-????
-???
-???
-???
-???
-????
-?????
-??
-????
-???
-???
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-???
-????
-???
-???
-????
-?????
-????
-??????
-???
-????
-???
-?????
-?????
-??
-???
-??
-??
-????
-????
-????
-??
-??
-???
-???
-??????
-???
-?????
-????
-??????
-???
-?????
-??
-??
-??
-???
-??
-????
-???
-???
-????
-????
-????
-??
-???
-???
-???
-??????
-???
-?????
-?????
-?????
-???
-???
-??????
-?????
-?????
-?????
-??????
-??????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-??
-???
-?????
-??????
-??
-???
-???
-??
-??
-??
-??
-??
-???
-????
-????
-???
-???
-?????
-??
-??
-??
-??????
-??????
-????
-????
-??????
-????
-?????
-???
-???
-???
-??
-????
-????
-??
-??
-????
-?????
-?????
-??
-??
-???
-???
-????
-???
-???
-???
-????
-???
-??
-??
-????
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-???????
-???
-?????
-????
-??????
-?????
-?????
-???????
-???????
-?
-?
-????
-??
-??
-?????
-????
-????
-????
-????
-????
-????
-??????
-???
-???
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-??
-???
-????
-???
-???
-???
-??
-?
-?
-?
-?
-??
-???
-??
-??
-??
-????
-???
-???
-????
-??
-??
-????
-???
-?
-???
-????
-?
-?
-?
-?
-???
-???
-?????
-????
-???
-????
-???
-???
-????
-??
-?
-?
-?
-??
-???
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?????
-??
-??
-???
-????
-???
-????
-??
-???
-???
-????
-????
-?????
-?????
-??
-??
-??
-????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-???
-?
-????
-????
-???
-???
-????
-??
-???
-??
-??
-????
-??
-????
-????
-??????
-????
-???
-???
-????
-????
-?????
-???
-???
-???
-???
-?????
-???
-?????
-???
-?????
-???
-????
-????
-?????
-???????
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-????
-?????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-??????
-?????
-??????
-??
-??
-????
-???
-????
-??
-??????
-???
-??????
-???
-???
-?????
-??
-??
-??
-?????
-?????
-?????
-?????
-?????
-??????
-???????
-???????
-??
-??
-??
-???
-??
-???
-??
-??
-???
-???
-????
-??
-??
-??
-???
-??
-????
-???
-???
-??
-???
-??
-???
-??
-????
-?????
-?????
-??
-??
-??
-??
-???
-???
-?????
-???
-??
-??
-??
-??
-???
-???
-?
-?
-???
-??
-??
-???
-???
-???
-????
-?????
-?
-?
-?
-?
-??
-?
-?
-???
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-????
-???
-???
-???
-???
-???
-??
-????
-???
-?????
-??
-??
-??
-???
-??
-??
-????
-???
-??
-????
-???
-???
-??
-??
-??
-????
-???
-????
-????
-?
-???
-?
-??
-??
-???
-??
-???
-???
-??
-??
-???
-??
-???
-???
-???
-????
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-??
-??
-??
-???
-????
-????
-????
-??????
-??????
-?????
-????
-???
-???
-???
-???
-????
-?
-??
-???
-????
-??
-??
-??
-??
-??
-??
-???
-????
-???
-???
-??
-???
-??
-?????
-???????
-???????
-?????????
-???????
-???
-?????
-?????
-??????
-??????
-???????
-????
-????
-?????
-????
-????
-??
-??
-??
-????
-???????
-????
-?????
-??
-??
-???
-???
-???
-????
-????
-??
-??
-????
-????
-??
-??
-??
-??
-???
-???
-????
-???
-???
-??????
-?????
-????
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-????
-???
-???
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-????
-???
-???
-????
-??
-??
-??
-???
-??
-??
-???
-??
-???
-???
-??
-??
-??
-???
-????
-???
-??
-???
-???
-??
-?
-???
-???
-???
-?
-?
-??
-?
-??
-??
-???
-???
-???
-???
-???
-????
-????
-???
-????
-???
-???
-???
-????
-????
-?
-??
-???
-??
-??
-???
-?????
-??
-??
-????
-???
-???
-?
-?
-??
-?
-??
-???
-???
-??
-?
-?????
-???
-???
-?????
-???
-???
-???
-????
-???
-???
-???
-????
-????
-?????
-????
-?????
-????
-?????
-?????
-??????
-??
-???
-???
-???
-????
-???
-????
-?????
-?????
-??
-?
-?
-????
-?????
-?
-???
-????
-??
-???
-????
-??????
-?
-???
-?????
-???
-????
-?
-?
-???
-?
-???
-??
-??
-????
-????
-???
-??
-??
-??
-??
-??
-???
-????
-???
-???
-?????
-???
-??
-????
-?
-?
-?
-??
-?
-?
-?
-??
-???
-???
-???
-??
-??
-????
-??
-???
-???
-??
-???????
-??????
-????
-???
-?????
-????
-????
-?????
-???
-????
-??
-??
-??
-??
-??
-???
-????
-????
-????
-??????
-???
-???
-???
-???
-?
-??
-?
-?
-??
-????
-?
-?
-???
-?????
-????
-???
-????
-???
-???
-?????
-????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-????
-????
-?????
-???
-???
-??
-????
-??
-??
-????
-?
-???
-???
-???
-??
-?????
-????
-???
-???
-???
-????
-??
-??
-??
-??
-??
-???
-???
-??
-?????
-???
-???
-???
-????
-???
-???
-???
-???
-???
-??
-??
-??????
-???
-???
-???
-???
-???
-???
-?????
-???
-????
-????
-???????
-???
-????
-??????
-???
-??
-??
-????
-???
-????
-??
-??
-??
-??
-???
-???
-??
-??
-????
-???
-????
-?????
-?
-???
-?
-?
-?
-??
-??
-???
-???
-???
-????
-??
-??
-??
-??
-????
-??
-???
-????
-????
-????
-????
-???
-?????
-????
-??
-???
-???
-??
-??
-??
-????
-????
-???
-???
-???
-??
-??
-??
-??
-???
-??
-????
-??
-??
-???
-????
-???
-????
-??
-????
-?????
-????
-?????
-????
-???????
-??????
-??????
-??
-??
-????
-???
-?????
-?????
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-?
-??
-????
-?
-???
-???
-???
-???
-????
-?????
-?????
-???
-?????
-??
-??
-??
-????
-????
-???
-?
-?
-???
-???
-???
-????
-????
-?
-?????
-???
-??
-?
-?
-?
-??
-???
-??
-??
-???
-???
-??
-??
-????
-???
-??????
-????
-????
-??
-???
-????
-??
-??
-??
-???
-???
-???
-?????
-?????
-??
-????
-????
-????
-????
-??????
-????
-????
-?????
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-????
-???
-?????
-??
-????
-??
-???
-???
-?????
-????
-????
-????
-????
-???????
-??????
-?????
-?????
-?????
-?????
-????
-????
-??
-??
-??????
-???
-??
-????
-???
-??
-????
-??
-????
-???
-???
-???
-???????
-????
-???
-????
-????
-????
-????
-??
-?
-?
-????
-?
-??
-??
-?
-?
-??
-??
-??
-????
-????
-??
-??
-????
-????
-???
-???
-???
-?????
-??????
-?
-???
-???
-???
-??
-?????
-?
-???
-???
-???
-???
-???
-??
-??
-???
-???
-??
-??
-????
-???
-??
-??
-????
-???
-??
-???
-???
-???
-????
-??
-??
-?
-??
-?
-??
-??
-??
-???????
-???
-?????
-???????
-??
-???
-????
-????
-???
-???
-????
-????
-??
-??
-??
-?????
-??
-????
-??????
-???
-??????
-?????
-???
-?????
-?
-???
-???
-?????
-??
-????
-??
-????
-??
-??
-??
-??
-??
-??
-???
-???
-?????
-????
-???
-????
-??
-?
-???
-???
-???
-????
-?????
-????
-??????
-?????
-???
-?????
-??
-???
-?
-???
-?????
-??
-?????
-???
-???
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-??
-??
-???
-????
-????
-??
-?????
-????
-????
-?????
-????
-????
-???
-???
-???
-??????
-????
-????
-???
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-???
-????
-??????
-????
-????
-??
-???
-??
-???
-??
-????
-??
-???
-??
-????
-?
-???
-???
-????
-???
-?????
-?
-????
-??
-??
-??
-????
-??
-??
-??
-???
-???
-??
-????
-?????
-??
-???
-??
-??
-????
-????
-????
-?????
-???
-?????
-?????
-???
-????
-????
-?????
-???????
-????????
-??
-????
-????
-???
-????
-?????
-????
-????
-????
-???
-?????
-??????
-???
-??
-??????
-?????
-?????
-?????
-???????
-????
-???
-????
-???
-????
-???
-???
-???
-?????
-????
-??????
-?????
-???????
-?????
-????
-???
-?????
-?????
-?????
-??????
-????
-??????
-??????
-??????
-??????
-?????
-????
-????
-?????
-????
-????
-????
-?????
-??????
-???????
-??????
-????????
-???
-???
-???
-?????
-?????
-?????
-????
-???
-????
-???
-???
-??????
-???
-????
-????
-????
-?????
-??
-????
-??
-???
-???
-????
-?????
-??????
-??
-????
-??
-??
-???
-????
-???
-??????
-?????
-?????
-??
-??
-???
-?????
-????
-??
-??
-??
-???
-???
-???
-???
-????
-????
-??
-??
-??
-??
-???
-???
-??
-?????
-???
-??
-??
-???
-????
-???
-??????
-?????
-??????
-????
-????
-?????
-????
-????
-??????
-???????
-??????
-?????
-??????
-?????
-?????
-?????
-?????
-???????
-???????
-??????
-?????
-??????
-??????
-??????
-???
-???
-???
-?????
-???
-???
-?????
-????
-????
-???
-?
-??
-??
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-?
-??
-?
-??
-?
-???
-??
-?
-?
-?
-?
-???
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-???
-?
-??
-??
-??
-???
-???
-???
-?????
-??????
-????
-??????
-?????
-?????
-???
-???
-???
-???
-????
-???????
-?????
-???
-???
-???
-????
-???????
-??
-?????
-???
-???
-?????
-?????
-?????
-????
-?????
-?????
-?????
-?????
-???
-?????
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-??????
-????????
-???????
-??????
-??????
-???????
-????
-??????
-????????
-??????
-?????
-????
-????
-????
-??????
-??????
-??????
-??????
-??????
-??????
-????
-?????
-??????
-????
-????
-????
-???????
-????
-??????
-??????
-?????
-????
-????
-????
-?????
-???????
-??????
-????
-???
-????
-????
-?????
-???
-?????
-?????
-?????
-???
-???
-???
-????
-??????
-????????
-????
-???
-??????
-?????
-???????
-???????
-???????
-?????
-???
-????
-????
-??????
-???????
-??????
-?????
-???
-??
-????
-????
-?????
-????
-??
-????
-??????
-????
-?????
-????
-??
-??
-??
-??
-???
-???
-??
-???
-??????
-??????
-??????
-???????
-????????
-?????????
-???????
-????????
-????
-????????
-???????
-???????
-??????
-??????
-????
-????
-?????
-?????
-?????
-???????
-???
-???
-???????
-?????
-????
-?????
-???
-???
-??????
-????????
-????????
-?????????
-??????
-??????
-???????
-????????
-????????
-????????
-????????
-??????????
-?????????
-?????
-???
-???????
-????
-????
-??????
-??????
-?????
-????????
-?????
-?????
-?????
-???????
-???????
-?????
-?????
-?????
-???????
-?????
-?????
-??????
-???
-????
-?????
-?????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-?????
-???????
-???????
-??????
-????
-??????
-??????
-???????
-???????
-????????
-????????
-????
-?????
-?????
-?????
-??????
-????
-????
-????
-??????
-???????
-????????
-?????
-?????
-?????
-????
-??????
-????????
-????
-????
-?????
-???
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-???
-????
-????
-?????
-????
-?????
-??????
-????
-?????
-????
-????
-????
-??????
-?????
-??????
-???
-????
-????
-???
-?????
-???????
-?????
-?????
-?????
-???????
-??????
-??????
-????????
-?????
-?????
-?????
-??????
-???????
-???????
-??????
-??????
-?????
-????
-????
-????
-?????
-???????
-??????
-????????
-?????
-?????
-???????
-????????
-??????
-?????
-?????
-?????
-???????
-??????
-?????
-?????
-??????
-???????
-?????
-??????
-????????
-????
-????
-????
-????
-????
-??????
-??????
-???????
-??????
-??????
-??????
-??????
-??????
-????
-????
-????????
-????????
-?????
-???????
-?????
-??????
-??????
-????????
-?????
-?????
-??????
-???????
-?????
-?????
-?????
-?????
-???????
-??????
-??????
-?????
-??????
-??????
-?????
-?????
-???????
-?????????
-???????
-?????????
-???????
-???????
-???????
-???????
-????
-????
-????
-????
-??????
-?????
-?????
-??????
-???????
-??????
-???????
-??????
-????
-????
-????
-????
-????
-?????
-?????
-??????
-????
-??????
-?????
-??????
-?????
-????
-????
-?????
-?????
-?????
-?????
-??????
-?????
-?????
-??????
-???????
-??????
-???????
-???????
-??????
-??????
-??????
-????????
-???????
-???????
-???????
-????
-??????
-??????
-??????
-???????
-????
-?????
-????
-????
-??????
-????
-??????
-??????
-??????
-??????
-???
-????
-????
-?????????
-????????
-????????
-????????
-?????
-?????
-???????
-?????
-?????
-??????
-???????
-????
-???
-?????
-???
-???
-?????
-??????
-?????
-?????
-?????
-?????
-???????
-????
-?????
-?????
-?????
-?????
-??????
-?????
-????????
-???????
-????
-??????
-???????
-?????
-????
-??????
-????
-?????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-???????
-???????
-???????
-?????????
-?????
-?????
-?????
-??????
-?????
-???
-???
-?????
-?????
-??????
-????
-????
-??????
-???????
-???????
-???????
-???
-???
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-????
-????
-????
-?????
-?????
-????
-????
-?????
-?????
-????
-????????
-??????
-??????
-???
-?????
-???
-?????
-????
-??????
-????
-?????
-???????
-???????
-??????
-??????
-??????
-????
-???
-???
-???
-?????
-????
-???
-???
-???
-????
-???
-????
-??
-??
-?
-?
-???
-?
-?
-?
-??
-????
-????
-??????
-??
-???
-?????
-?
-??
-????
-???
-?????
-??
-??
-?
-???
-??
-?
-?
-??
-?
-?
-?
-??
-?
-??
-??
-??
-??
-???
-???
-????
-????
-????
-????
-?????
-????
-?????
-???
-?????
-?
-??
-???
-?
-??
-??
-??
-??
-?
-?
-?
-??
-?
-?
-???
-???
-????
-?????
-???
-???
-???
-???
-???
-?????
-????
-?
-????
-???????
-???????
-??
-?????
-????
-???
-??
-??
-???
-??
-???
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-???
-????
-??
-??
-???
-??
-?
-??
-??
-???
-??
-???
-?
-?
-??
-??
-????
-??
-??
-????
-?????
-?
-??
-??
-???
-???
-??
-?
-?
-?
-?
-??
-?
-?
-?
-????
-?
-??
-?
-??
-??
-?????
-??????
-?????
-?????
-??????
-??????
-??
-??
-??
-???
-??
-?
-?
-?
-??
-?
-?
-?
-??
-???
-???
-?
-???
-???
-?????
-???
-???
-??
-??
-???
-??
-?
-?
-?
-?
-???????
-???
-????
-????
-???
-????
-??
-??
-??
-??
-??
-???
-?
-?
-??
-??
-???
-??
-???
-????
-?
-?
-??
-????
-????
-????
-?????
-??
-???
-???
-????
-????
-????
-??????
-????
-????
-????
-??
-??????
-?????
-????
-????
-???
-???
-????
-?????
-?????
-???
-???
-???
-??
-???
-??
-??
-????
-??
-??
-??
-??
-???
-??
-???
-????
-???
-???
-?????
-??????
-??
-?????
-??
-??
-????
-????
-????
-?????
-????
-?????
-????
-?????
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-??
-????
-?????
-??????
-??????
-??????
-??
-??
-?????
-???
-?????
-?????
-??
-??
-????
-??
-????
-????
-??
-????
-?????
-??????
-???
-???
-???
-?????
-????
-????
-????
-????
-????
-??????
-??????
-?????
-?????
-?????
-????
-??????
-???
-?????
-???
-??
-?
-??
-??
-???
-?
-?
-?
-?
-?
-?
-??
-??
-????
-????
-?????
-??????
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-????
-????
-???
-????
-??
-???
-????
-?????
-???
-???
-???
-????
-??????
-????
-??
-??
-????
-???
-???
-???
-??
-????
-?
-?
-?
-?
-?
-???
-???
-??
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-????
-????
-?????
-??
-??
-?
-?
-???
-?
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-??
-?
-?
-???
-?
-?
-???
-???
-???
-???
-??
-?
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-??
-??
-???
-?????
-????
-????
-????
-???
-???
-????
-?????
-??
-?
-??
-?
-?
-?
-?
-?
-?
-???
-??
-??
-??
-???
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-???
-???
-???
-????
-????
-????
-?????
-???
-??
-??
-??
-??
-??
-??
-??
-????
-?????
-?
-????
-?????
-?
-?
-??
-????
-?
-?
-???
-???
-???
-?????
-?????
-??????
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-????
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-??
-?
-?
-??
-??
-???
-??
-?
-?
-?
-??
-??
-??
-???
-?
-?????
-??
-??
-????
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-?
-?
-?
-??
-?
-?
-?
-??
-?
-???
-???
-???
-???
-?
-??
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-?
-??
-???
-??
-????
-???
-??
-??
-??
-??
-????
-???
-??
-??
-???
-??
-??????
-???
-????
-???
-???
-???
-????
-????
-????
-?????
-????
-?????
-??
-??
-??
-???
-????
-???
-???
-????
-????
-????
-????
-?????
-???
-???
-???
-????
-?????
-???
-????
-???
-??
-????
-??
-???
-??
-??
-??
-???
-???
-?????
-??
-??
-???
-???
-????
-??????
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-?????
-?????
-???
-????
-???
-???
-???
-????
-???
-??
-??
-???
-??
-????
-??
-??
-??
-??
-??
-????
-???
-????
-???
-???
-?????
-??
-???
-??
-??
-???
-???
-???
-???
-???
-????
-?????
-????
-???
-?????
-??
-??
-????
-????
-???
-?????
-?????
-??????
-??????
-??????
-????
-??????
-????
-???
-?????
-???
-??
-??
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-????
-????
-????
-????
-??????
-????
-????????
-??
-???
-???
-???
-????
-???
-???
-?????
-???
-???
-???
-???
-????
-????
-???
-????
-??????
-???
-?????
-????
-????
-????
-????
-??
-???
-???
-???
-???
-????
-??????
-???
-???
-?????
-????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-?????
-??????
-????
-????
-????
-????
-?????
-???
-???
-?????
-????
-?????
-????
-??????
-????
-??????
-?????
-???
-??????
-??????
-??????
-???
-?????
-????
-???
-???
-???
-???
-????
-???
-????
-???
-???
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-??
-??
-??
-?????
-?????
-??
-???
-???
-???
-???
-??
-??
-??
-??
-????
-??
-??
-???
-???
-????
-????
-????
-????
-???
-???
-????
-??
-??
-?????
-??
-??
-????
-???
-??
-???
-??
-??
-??
-???
-????
-??????
-????
-????
-????
-?????
-???
-???
-????
-????
-????
-???
-??
-??
-??
-??
-??
-???
-???
-????
-???
-???
-??
-???
-??
-???
-???
-???
-???
-??
-??
-???
-??
-??
-???
-???
-????
-????
-???
-????
-???
-?
-?
-?
-??
-?
-?
-???
-??
-??
-??
-????
-???
-???
-????
-?
-?
-?
-?
-?
-??
-???
-???
-???
-????
-????
-???
-?????
-?
-?
-?
-?
-??
-?
-??
-???
-???
-??
-???
-?
-??
-????
-?????
-?????
-??
-?
-?
-???
-??
-???
-??
-?
-?
-??
-???
-????
-?
-??
-??
-????
-???
-?
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-???
-????
-???
-??
-???
-?
-?
-??
-?
-?
-??
-?
-??
-??
-??
-??
-??
-???
-?????
-??
-?
-???
-??
-???
-?
-?
-??
-???
-?
-??
-??
-??
-???
-??
-???
-???
-????
-??
-??
-???
-?
-???
-?
-??
-??
-???
-???
-????
-????
-????
-???
-?????
-???????
-??????
-??????
-??????
-????????
-?????????
-????
-????
-????
-????
-???
-????
-???
-?????
-??????
-???????
-???
-?????
-??
-???
-??
-??
-??
-??
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-??????
-????????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-????
-???
-????
-????
-?????
-????
-????
-?
-?
-???
-??
-???
-?
-?
-???
-???
-??
-?
-?
-???
-???
-???
-???
-???
-????
-??
-??
-????
-?????
-?
-???
-???
-???
-?????
-????
-????
-??
-????
-????
-?????
-????
-?
-???
-?
-?
-???
-????
-????
-??
-???
-???
-????
-???
-???
-???
-?
-??
-??
-?
-??
-???
-??
-??
-??
-????
-?????
-????
-??
-??
-???
-???
-???
-???
-?????
-????
-????
-????
-?????
-??????
-????
-???????
-?????
-??
-????
-???
-????
-??????
-?
-?
-??
-??
-??
-???
-???
-????
-?
-?
-???
-???
-??
-????
-???
-??
-???
-??
-????
-????
-????
-?????
-????
-????
-?
-?
-??
-??
-??
-??
-?
-????
-?
-?
-??
-?
-?
-?
-?
-??
-???
-????
-???
-????
-?????
-??
-?
-?
-?
-?
-??
-?
-??
-??
-???
-?
-?
-?????
-??
-???
-???
-??
-??
-??
-???
-????
-????
-????
-????
-???
-???
-????
-????
-???
-???
-???
-???
-????
-?????
-???
-?????
-???
-???
-?????
-?????
-????
-?????
-???
-?????
-????
-??????
-???
-????
-????????
-?????????
-???
-???
-?????
-????
-???
-???
-?????
-?????
-??????
-????
-???
-??
-???
-??
-??
-???
-????
-??
-??
-??
-??
-??
-??
-??
-????
-????
-??
-????
-???
-?????
-????
-??
-???
-??
-??
-??
-???
-???
-???
-????
-??
-?????
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-???
-????
-???
-??
-????
-??
-?????
-????
-???
-???
-????
-???
-???
-????
-???
-???
-??????
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-??
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-??
-???
-????
-????
-?????
-?????
-?????
-?????
-???????
-?????
-???????
-????????
-???????
-???
-???
-????
-??
-??
-??
-???
-???
-???
-????
-??
-?
-???
-???
-????
-???
-???
-??
-??
-??
-???
-???
-??
-???
-??
-?????
-???
-??????
-????
-???
-???
-???
-???
-????
-???
-????
-????
-???
-????
-??
-??
-???
-????
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-??
-???
-??
-??
-?
-??
-???
-??
-???
-?
-?
-?
-??
-??
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-????
-???
-???
-????
-???
-???
-?????
-????
-???
-???
-????
-?????
-???
-??
-??
-???
-???
-??
-????
-??
-??
-??
-????
-??
-??
-????
-????
-????
-??????
-??
-??
-??
-????
-???
-???
-???????
-???
-????
-???
-???
-????
-?????
-????
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-?????
-????
-?????
-?????
-????
-???
-???
-???
-????
-???
-?????
-????
-????
-?????
-?
-???
-???
-??
-????
-??
-???
-?
-???
-??
-??
-?
-???
-????
-??????
-?????
-????
-????
-????
-??????
-??????
-??
-??
-????
-??
-??
-???
-???
-???
-??
-??
-??
-????
-???
-????
-??
-??
-??????
-??
-??
-??
-??
-??????
-???????
-?????
-???????
-?
-?
-??
-????
-?
-?
-???
-??
-??
-??
-???
-??
-?????
-?
-?????
-??
-??
-????
-????
-????
-????
-????
-?????
-?
-?
-??
-??
-????
-???
-?
-??
-?
-?
-???
-?
-???
-???
-???
-?
-??
-?
-??
-?
-??
-???
-?????
-??
-???
-?????
-??
-??
-??
-??
-???
-??
-??
-??????
-???
-???
-???
-????
-????
-???
-??
-??
-??
-????
-????
-????
-??????
-???
-?????
-???
-???
-???
-????
-???
-??
-??????
-???
-???
-?
-?
-??
-????
-???
-????
-???????
-?
-??
-??
-??
-??
-???
-???
-??
-???
-?
-??
-???
-????
-???
-???
-?????
-??
-???
-???
-??
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-??
-??
-???
-???
-??
-??
-????
-??
-?
-?
-???
-?
-??
-???
-???
-????
-?????
-??????
-?????
-?????
-?????
-???
-???
-?????
-???
-????
-????
-???
-??
-???
-???
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-?
-?????
-?
-??
-??
-???
-???
-???????
-???
-???
-?
-???
-???
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-?
-?
-?
-?
-??
-?
-??
-??
-??
-??
-???
-?
-?
-?
-??
-??
-?
-??
-???
-???
-?
-????
-??????
-?
-?
-??
-??
-????
-????
-????
-???
-???
-????
-?
-?
-??
-??
-?????
-??
-??
-??
-????
-???
-???
-???
-??
-?
-?
-??
-??
-???
-????
-???
-???
-???
-?
-?
-??
-?
-???
-??
-???
-?
-?
-?
-?
-??
-??
-?
-???
-???
-???
-????
-????
-??????
-????
-?????
-?????
-??
-???
-???
-???
-??
-????
-???
-???
-????
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-???
-???
-????
-?????
-???
-?????
-????
-??????
-??????
-????
-??
-???
-???
-????
-???
-???
-????
-??????
-???
-???
-?????
-??????
-???
-???
-????
-????
-?????
-?????
-????
-????
-??????
-?????
-?????
-?????
-??????
-??
-??
-??
-??
-????
-???
-???
-???
-??
-???
-??
-???
-?????
-??
-??
-???
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-????
-???
-???
-????
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-????
-?????
-?????
-????
-??
-??
-??
-???
-??
-?????
-???
-????
-???
-??
-???
-??
-???
-??
-?
-????
-?
-?
-???
-???
-???
-????
-?????
-?
-???
-???
-??
-????
-???
-???
-???
-???
-???
-?
-???
-???
-?
-?
-???
-?
-???
-??
-???
-??
-?
-???
-????
-??
-??
-???
-??
-??
-??
-????
-??
-???
-???
-???
-?
-???
-??
-???
-??
-??
-?
-?
-?
-?
-???
-??
-???
-?
-?
-??
-??
-????
-???
-??
-???
-????
-???
-?
-?
-??
-??
-??
-??
-?
-??
-????
-?
-?
-?
-?
-??
-??
-?
-?
-???
-???
-????
-?
-??
-??
-???
-????
-??
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-????
-????
-?
-?
-?
-?
-?
-??
-???
-????
-?
-?
-???
-?
-?????
-????
-??
-??
-???
-????
-???
-????
-????
-???
-???
-?
-???
-?
-??
-??
-?
-?
-?
-?
-??
-??
-???
-??
-????
-????
-?
-?
-?
-?
-??
-???
-????
-??
-????
-??
-???
-????
-???
-???
-???
-?
-??
-??
-???
-??
-?
-???
-??
-??
-???
-??
-????
-??
-??
-???
-???
-????
-??
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-????
-???
-???
-??????
-???
-????
-????
-??
-????
-???
-???
-?????
-????
-?????
-???
-??
-??
-??
-???
-????
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??????
-????
-????
-????
-????
-????
-????
-?????
-??????
-???
-?
-??
-??
-???
-?
-??
-??
-???
-?
-?
-????
-?
-?
-?
-???
-???
-??
-??
-??
-?
-?
-?
-??
-??
-?
-??
-???
-?
-?
-?
-??
-?
-?
-??
-?
-??
-???
-??
-???
-??
-??
-??
-????
-??????
-?
-?
-??
-??
-???
-???
-??
-????
-?
-?
-??????
-?
-????
-???
-???
-?
-?
-??
-??
-??
-??
-????
-??
-??
-???
-?
-?
-?
-?
-??
-??
-??
-???
-???
-????
-?
-??
-?
-????
-??
-???
-????
-???
-??
-??
-????
-????
-?????
-??????
-????
-??
-???
-??
-??
-?
-??
-??
-???
-??
-???
-???
-??
-??
-??
-?????
-???
-???
-???
-????
-?
-??
-???
-?
-???
-??
-??
-???
-???
-???
-????
-??
-??
-????
-?
-??
-????
-???
-??
-????
-????
-????
-????
-????
-?????
-????
-??????
-??
-???
-?
-?
-?
-??
-?
-??
-?
-?
-?
-??
-?
-?
-?
-???
-????
-???
-?
-?
-?
-?
-??
-?
-?
-????
-????
-?
-?
-???
-?
-???
-???
-?
-????
-???
-????
-??
-??
-??
-???
-?????
-??
-????
-????
-?????
-????
-??????
-?????
-?????
-??
-??
-??
-?
-??
-??
-??
-??
-??
-???
-???
-??
-?
-?
-????
-??
-????
-??
-??
-???
-????
-??
-???
-??
-???
-???
-???
-???
-?????
-???
-????
-????
-????
-???
-??
-???
-?
-?
-??
-?
-??????
-???
-????
-????
-???????
-??????
-??????
-?????
-?????
-????
-??????
-????
-????
-????
-???
-???
-?
-??
-????
-??
-???
-???
-??
-??
-??
-????
-???
-???
-???
-??
-??
-???
-???
-????
-????
-???
-??
-??
-???
-???
-??
-??
-??
-???
-????
-??????
-???
-???
-???
-??
-??
-??
-??
-????
-???
-???
-????
-???
-????
-???
-????
-??
-???
-?????
-???
-??
-???
-???
-???
-???
-?????
-??
-????
-????
-????
-????
-??
-??
-??
-???
-??
-???
-??
-???
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-????
-????
-????
-????
-??
-??
-???
-?????
-??
-???
-??
-??
-????
-???
-????
-???
-???
-????
-????
-???
-????
-???
-?????
-????
-????
-???????
-?????
-???
-?????
-???
-?????
-?????
-???????
-????
-???????
-????
-??????
-???
-???
-?????
-???
-?????
-?????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-??????
-?????
-???????
-???????
-??????
-???
-??
-??
-??
-????
-???
-???
-???
-??
-??
-??
-??
-???
-???
-????
-??????
-??
-??
-???
-??
-??
-????
-?????
-???
-???
-????
-????
-?????
-???
-???
-???
-?????
-????
-?????
-??????
-????
-???
-???
-????
-???
-????
-???
-????
-???
-???
-???
-???
-???
-?????
-????
-????
-????
-???
-???
-?
-?
-??
-?
-??
-?
-???
-??
-???
-??
-?
-?
-?
-?
-?
-???
-??
-???
-????
-????
-????
-??
-??
-??
-??
-??
-??
-???
-?
-?
-??
-???
-??
-???
-?
-?
-??
-??
-??
-??
-???
-?
-??
-??
-???
-???
-???
-??
-????
-???
-???
-??
-?
-?
-?
-??
-?
-?
-?
-??
-?
-???
-???
-???
-?????
-??????
-??????
-??????
-???????
-????
-???
-?????
-?
-??
-????
-????
-???
-??
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-????
-???
-????
-????
-????
-????
-????
-?????
-??????
-???
-??
-??
-???
-???
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-????
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-???
-????
-????
-???
-??
-???
-??
-??
-??
-????
-???
-?
-?????
-???
-???
-???
-?
-??
-?
-?
-??
-????
-???
-???
-?????
-????
-???
-?????
-????
-??
-??
-?
-?
-?
-?
-??
-??
-?
-???
-??
-??
-??
-??
-??
-?
-?
-?
-???
-????
-???
-??
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-?
-???
-??
-??
-??
-?
-????
-?
-???
-?
-???
-???
-??
-?
-???
-?????
-?
-?
-?
-??
-???
-????
-????
-?
-???
-?
-???
-?
-???
-???
-?
-?
-??
-??
-?
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-??
-???
-??
-????
-???
-???
-?????
-???
-??
-??
-??
-????
-??
-???
-???
-????
-????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-??????
-???
-???
-????
-???
-???
-???
-???
-????
-?????
-?????
-??????
-???????
-??????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-????
-???????
-????
-????
-?????
-??????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-??????
-???????
-?????
-????
-????
-????
-????
-????
-??????
-?????
-???
-?????
-????
-???
-???
-?????
-???
-?????
-????
-????
-?????
-??????
-?????
-?????
-?????
-????
-??????
-?????
-?????
-????
-???
-??
-??
-???
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-?????
-?????
-?????
-????
-???
-????
-????
-????
-??????
-?????
-???
-???
-????
-????
-??????
-?????
-???
-???
-???
-???
-????
-????
-????
-????
-????
-?????
-???
-????
-??
-?
-??
-???
-?
-??
-?
-????
-?????
-???
-???
-???
-??
-??
-????
-????
-???
-?????
-??
-?
-???
-?
-???
-??
-????
-?
-??
-?
-?
-??
-?
-?
-?
-?
-?
-????
-?????
-???
-??
-??
-??
-??
-??
-?
-?
-?
-???
-???
-???
-????
-???
-??
-????
-??
-????
-????
-????
-????
-??????
-???
-????
-?????
-??????
-????
-???
-????
-?????
-??????
-??????
-???
-????
-????
-???
-???
-???
-?????
-????
-????
-???????
-????
-?????
-???
-???
-???
-????
-??
-???
-??
-???
-??
-???
-???
-???
-???
-??
-??
-??
-??
-???
-?????
-??
-??
-????
-????
-???
-???
-???
-??
-??
-????
-?????
-??
-???
-????
-??
-???
-??
-????
-???
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-??
-??
-????
-???
-?????
-?????
-?????
-?????
-?????
-??
-????
-????
-????
-????
-????
-??????
-??
-??
-??
-??
-???
-??
-???
-??
-???
-?????
-?????
-??????
-??
-???
-???
-???
-????
-???
-?????
-?????
-???????
-?
-?
-?
-??
-??
-?
-??
-?
-??
-???
-?
-??
-?
-?
-?
-??
-?
-?
-??
-???
-??
-??
-?????
-????
-??
-??
-????
-???
-???
-???
-??
-????
-??
-???
-????
-??????
-??????
-???
-????
-????
-????
-??????
-???
-???
-???
-???
-????
-?????
-???
-???
-????
-????
-?????
-??????
-?????
-????
-????
-?????
-??
-????
-???
-??
-??
-???
-????
-??
-???
-????
-??
-??
-???
-???
-???
-???
-????
-???
-??????
-???
-?????
-?????
-?????
-???
-???
-???
-???
-????
-????
-????
-?????
-??????
-????
-????
-??????
-?????
-???
-???
-???
-?????
-?????
-?????
-???????
-????
-??????
-??????
-???
-???
-???
-???
-???
-????
-????
-???
-????
-????
-????
-?????
-????
-????
-???
-??
-???
-???
-???
-???
-????
-?????
-???
-????
-????
-????
-?????
-????
-????
-???
-???
-???
-?????
-?????
-????
-????
-??????
-?????
-?????
-??
-???
-???
-????
-????
-????
-???
-????
-????
-?
-??
-???
-?
-?
-???
-?????
-??
-??
-?
-?
-?
-?
-??
-?
-??
-???
-?
-??
-??
-???
-??
-?
-?
-?
-??
-??
-?
-?
-?
-??
-???
-??
-??
-???
-??
-??
-????
-??
-???
-??
-???
-??
-??
-??
-???
-???
-???
-???
-??
-??
-???
-?
-???
-?
-???
-??
-???
-??
-??
-????
-??
-????
-?????
-??????
-?????
-?????
-?????
-?????
-?????????
-??????
-???????
-??????
-???
-???
-????
-????
-?????
-?
-?
-?
-???
-?
-???
-?
-?
-??
-??
-??
-????
-??
-???
-???
-???
-??
-??
-???
-??
-???
-????
-???
-????
-?????
-??
-?????
-??
-??
-??
-???
-???
-???
-?????
-????
-?
-?
-?
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-???
-???
-????
-???
-?????
-???
-?????
-??????
-??
-??
-??
-??
-????
-???
-?????
-?????
-????
-??????
-??
-????
-??
-????
-????
-?????
-????
-????
-??????
-?????
-??????
-?????
-??
-???
-????
-???
-???
-????
-?????
-????
-????
-?????
-???
-???
-??
-???
-????
-???
-??
-???
-???
-????
-?
-?
-???
-??
-??
-??
-???
-??
-??
-?????
-?????
-?????
-??????
-??
-????
-??
-????
-????
-??
-??
-??
-???
-???
-???
-???
-????
-??????
-????
-???
-???
-???
-???
-???
-????
-??????
-??????
-??????
-?????
-????
-????
-????
-????
-?????
-???
-???
-???
-????
-????
-????
-?????
-???
-????
-??????
-????
-?
-?
-?????
-???
-????
-??????
-???
-???
-?????
-?????
-?????
-???????
-???????
-????
-????
-????
-????
-???
-???
-???
-?????
-???
-????
-????
-????
-????
-????
-?????
-???
-?????
-?????
-???????
-??????
-???
-???
-?????
-????
-?????
-???
-?????
-??????
-???
-???
-????
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-????
-????
-????
-??????
-??
-???
-????
-????
-?????
-???
-????
-??
-??????
-??
-?
-???
-???
-??????
-??
-?????
-??
-???
-?
-?
-?
-?
-??
-??
-????
-????
-??
-??
-??
-???
-???
-????
-??
-?????
-?
-??
-??
-??
-??
-????
-????
-????
-????
-?????
-?????
-??????
-??????
-???
-??
-???
-??
-???
-???
-??????
-?????
-?????
-????
-????
-????
-??????
-?????
-??
-??
-?????
-???
-???
-????
-??
-?????
-????
-??????
-????
-???
-???
-??????
-???
-?????
-???
-??
-??
-??
-??
-???
-????
-????
-???
-?
-??
-????
-????
-??
-???
-?????
-?????
-???????
-??
-???
-??
-?
-???
-???
-???
-???
-?????
-?
-?
-?
-??
-??
-???
-???
-??
-??
-?
-?
-?
-??
-??
-?
-??
-?????
-???
-??
-?
-??
-??
-???
-?
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-???
-??
-??
-?
-??
-??
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-?
-?
-?
-???
-???
-?????
-??
-??
-????
-????
-???
-????
-?
-?
-???
-?
-?
-?
-??
-??
-??
-??
-???
-????
-???
-???
-????
-????
-?????
-???
-?????
-??
-????
-?????
-???
-??
-???
-???
-??
-??
-??
-??
-????
-??
-???
-??
-????
-???
-??
-????
-?????
-????
-??
-????
-?
-?
-?
-?
-??
-?
-??
-?????
-?????
-???
-????
-????
-???
-???
-????
-???
-???
-???
-????
-????????
-????
-?????
-?
-???
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-??
-??
-??
-??
-???
-??
-?
-?
-??
-?
-?
-??
-?????
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-???
-???
-?
-??
-??
-???
-??
-??
-???
-???
-?
-?
-?
-??
-?
-??
-??
-?
-?
-??
-??
-???
-???
-???
-??????
-?
-??
-?
-?????
-????
-????
-?????
-????
-???
-?????
-????
-?
-?
-?
-??
-??
-??
-??
-????
-???
-???
-?
-?
-?
-???
-??
-??
-??
-??
-??
-??
-??
-???
-?
-?
-???
-??
-?
-??
-??
-?
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-???
-??
-???
-??
-??
-????
-???
-????
-???
-??
-??
-???
-???
-????
-??
-?????
-??
-??
-???
-???
-????
-????
-??
-???
-???
-????
-???
-?????
-??
-????
-????
-???
-???
-???
-??
-????
-??
-??
-??
-??
-????
-??
-???
-????
-?????
-????
-???
-?????
-?????
-???????
-????????
-??
-??
-??
-????
-?????
-???
-??
-??
-??
-?????
-???
-???
-??????
-?????
-???
-????
-??????
-???
-??
-???
-???
-?????
-??
-????
-????
-????
-??????
-????
-??
-???
-???
-??????
-??????
-????????
-????
-???
-?????
-?????????
-???
-??
-????
-???
-??
-??
-????
-??
-????
-????
-??
-???
-???
-????
-???
-?????
-????
-??
-??
-??
-???
-???
-????
-???
-??
-??
-???
-??
-????
-??
-??
-???
-????
-???
-???
-??
-??
-??
-??
-??
-??
-??
-???
-????
-????
-????
-?????
-???
-???
-??
-???
-??
-???
-???
-?????
-??????
-??????
-???????
-????????
-??????
-???
-????
-????
-?????
-?????
-??
-??
-??
-???
-???
-???
-?????
-???
-?????
-?????
-?????
-???????
-????????
-??????
-??????
-??????
-???????
-???????
-??????
-?????????
-???????
-???????
-????????
-???????
-?????????
-???
-???
-???
-???
-???
-????
-??????
-?????
-?????
-???
-????
-????
-??????
-????
-??????
-?????
-??????
-???????
-???
-???????
-???????
-??????
-??????
-??????
-????????
-???
-????
-????
-??????
-?????
-????
-???????
-????
-????
-??????
-????
-??????
-??????
-????
-????
-????
-????
-?????
-?????
-??????
-??????
-????
-????
-????
-?????
-??????
-?????
-?????
-??????
-???
-???
-?????
-????
-?????
-??????
-????
-????
-??????
-??
-???
-???
-????
-??????
-??
-???
-???
-???????
-???????
-??????
-??????
-???
-???
-???
-???
-????
-??
-??
-??
-????
-??
-???
-???
-????
-???
-???
-???
-????
-????
-????
-???
-????
-???
-????
-??????
-??????
-????
-???????
-???
-?????
-?????
-?????
-?????
-?????
-???????
-?????
-?????
-???????
-????
-????
-??????
-?????
-???
-????
-????
-???
-?????
-????
-????
-?????
-????
-?????
-?????
-??
-??
-??
-??
-???
-????
-????
-???
-???
-???
-????
-????
-????
-???
-?????
-????
-?????
-??
-??
-???
-??
-????
-????
-????
-?????
-?????
-??????
-??????
-?????
-???????
-???????
-????????
-???????
-??????
-??
-????
-??
-????
-?????
-??
-????
-??
-????
-??????
-????
-????
-??????
-?????
-??
-??
-???
-????
-??
-??
-??
-?
-?
-?
-???
-?
-?
-???
-??
-??
-??
-??
-???
-???
-??
-???
-??
-??
-???
-??
-????
-??
-????
-??
-??
-??
-??
-???
-???
-????
-???
-???
-????
-???
-??
-??
-???
-?????
-??????
-????
-????
-????
-?????
-????
-???
-?????
-???
-???
-???
-????
-?
-???
-???
-????
-?
-???
-?
-?
-??
-??
-????
-????
-????
-???
-???
-?????
-????
-??
-???
-????
-??
-??
-??
-??
-???
-???
-????
-????
-???
-?
-?
-?
-?
-?
-?
-?
-??
-?
-?
-?
-??
-??
-??
-?????
-????
-????
-????
-????
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-????
-???
-??
-???
-??
-??
-??
-??
-???
-?
-?
-???
-???
-??
-????
-???
-??
-??
-??
-???
-??????
-?
-???
-???
-??
-???
-?????
-???
-?
-??
-??
-?
-??
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-???
-????
-????
-???
-?
-??
-??
-??
-?
-??
-??
-???
-??
-??
-??
-??
-???
-?????
-????
-????
-????
-??
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-?????
-??????
-?????
-?????
-??????
-???
-???
-???
-???
-????
-??
-????
-????
-????
-??????
-??????
-???
-??????
-?????
-?????
-?????
-??????
-??????
-?????
-??
-??
-??
-???
-??
-??
-??
-??
-??
-????
-?????
-??????
-???
-?????
-????
-??????
-??????
-??
-??????
-?????
-?????
-???????
-????
-??
-????
-??????
-????
-????
-????
-?????
-???
-????
-???
-???
-???
-?????
-????
-?????
-????
-??
-????
-???
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-?????
-?????
-?????
-????
-?????
-????
-??????
-????
-????
-????
-????
-??????
-????
-??????
-??????
-????
-?????
-????
-?????
-??????
-????????
-???????
-???????
-??????
-???
-???
-???
-?????
-???
-?????
-???????
-????
-???
-???
-?????
-?????
-???????
-????
-????
-??????
-???????
-????
-????
-??????
-??????
-????
-??????
-????????
-?????
-???
-???
-?????
-???
-???
-???
-????
-????
-????
-???
-????
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-??
-??
-??
-???
-????
-??
-????
-??????
-???
-?????
-????
-???
-???
-??
-??
-??
-??
-?????
-????
-??????
-???
-?????
-??????
-??????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-????
-??
-????
-????
-????
-?????
-????
-????
-????
-?????
-???
-???
-???
-??
-??
-??
-????
-??
-??
-??
-???
-??
-??
-??
-???
-?????
-????
-?????
-?????
-????
-??????
-????
-??
-???
-???
-???
-???
-???
-?????
-?????
-?????
-?????
-??????
-???????
-????
-???????
-?????
-?????
-?????
-??????
-???
-???
-???
-???
-???
-????
-?????
-???
-??
-??
-??
-??
-??
-????
-??
-???
-???
-????
-??
-???
-??
-??
-???
-????
-???
-????
-???
-????
-??????
-??
-??
-????????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-?????
-??
-??
-??
-??
-??????
-??????
-???????
-?????
-??
-????
-???
-????
-???
-????
-????
-?????
-????
-??
-??
-??
-??
-??
-???
-???
-?????
-????
-???
-??
-?????
-????
-????
-????
-????
-????
-?????
-?????
-????
-??????
-??????
-?????
-???
-?????
-??????
-??
-???
-????
-???
-???
-????
-????
-???
-????
-???
-???
-??????
-??????
-?????
-?????
-?????
-???
-????
-????
-????
-???????
-??????
-???????
-????
-??????
-???
-???
-?????
-????
-????
-?????
-?????
-???
-???
-???
-???
-???
-???
-????
-?????
-???
-???
-????
-???
-???
-???
-????
-?????
-????
-????
-????
-????
-????
-????
-??????
-????
-????
-????
-????
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-??????
-??????
-?????
-??????
-??????
-???????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-?????
-?????
-??????
-?????
-?????
-????
-????
-?????
-?????
-?????
-??????
-?????
-????
-????
-??????
-?????
-????
-????
-????
-?????
-????
-????
-????
-????
-????
-?????
-???
-???
-???
-???
-????
-???
-???
-?????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-????
-??????
-?????
-?????
-??????
-????
-???
-???
-????
-?????
-???
-???
-??
-??
-????
-???
-???
-???
-?????
-??
-??
-???
-??
-??
-??
-???
-????
-?????
-????
-????
-????
-??????
-?????
-??????
-??????
-??
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-????
-??
-???
-???
-??
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-????
-???
-????
-???
-????
-???
-????
-???
-???
-???
-???
-?????
-????
-????
-??????
-?????
-?????
-?????
-???
-????
-??????
-???
-????
-???
-???
-???
-????
-???
-?????
-?????
-?????
-?????
-???????
-????
-??????
-??????
-??????
-?????
-???????
-??
-??
-??????
-???
-???
-????
-???
-?????
-?????
-????
-???
-???
-????
-????
-????
-???
-???
-????
-???
-????
-???
-???
-???
-???
-?????
-????
-????
-???
-???
-?????
-??????
-??????
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?????
-????
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-???
-??
-??
-???
-??
-??
-??
-??
-???
-???
-????
-????
-????
-??
-??????
-?????
-?????
-?????
-????
-??
-???
-??
-????
-???
-????
-??
-??
-??????
-????
-????
-???
-???
-???
-???
-???
-????
-???
-????
-????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-???
-??
-????
-?????
-???
-?????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-?????
-??????
-???
-???
-???
-????
-????
-????
-?????
-???????
-?????????
-???
-???
-???
-?????
-????
-????
-?????
-????
-?????
-??????
-???
-???
-???
-???
-????
-?????
-?????
-????
-????
-????
-?????
-???
-????
-???
-???
-???
-???
-???
-????
-??????
-??????
-???
-???
-???
-???
-????
-????
-?????
-????
-????
-?????
-?????
-?????
-?????
-????
-?????
-?????
-????
-???
-???
-???
-???
-????
-???
-???
-????
-???
-???
-????
-????
-????
-????
-?????
-?????
-????
-???
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-?????
-??????
-????
-?????
-????
-????
-????
-????
-????
-?????
-???
-?????
-?????
-???????
-????
-?????
-?????
-??????
-??????
-??????
-?????
-?????
-?????
-?????
-?????
-??????
-???????
-??????
-??????
-??????
-??????
-???????
-??????
-???????
-??????
-??????
-?????
-??????
-????
-????
-????
-????
-????
-????
-????
-?????
-??????
-????
-????????
-????
-?????
-????
-????
-????
-????
-????
-????
-????
-?????
-??????
-?????
-?????
-?????
-?????
-??????
-????
-????
-???
-????
-?????
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-?????
-????
-?????
-????
-??????
-??????
-???
-?????
-????
-?????
-?????
-??????
-???????
-???
-???
-???
-????
-????
-????
-?????
-???????
-????
-?????
-????
-?????
-???
-????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-??????
-??????
-???????
-????
-?????
-???
-?????
-???
-???
-???
-?????
-?????
-???????
-???
-???
-???
-????
-????
-???
-???
-????
-????
-???
-???
-????
-???
-????
-?????
-??????
-????
-????
-?????
-????
-?????
-???????
-?????
-????
-??????
-???????
-????????
-?????
-????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-??????
-?????
-?????
-?????
-??????
-?????
-?????
-?????
-??????
-????????
-???????
-?????
-??????
-????????
-???
-?????
-???
-????
-????
-????
-????
-????
-?????
-?????
-?????
-??????
-?????
-?????
-????
-???
-???
-???
-????
-???
-???
-????
-???
-???
-???
-????
-??????
-??????
-????
-???????
-????
-???????
-????
-????
-????
-??????
-?????
-???
-????
-???
-???
-???
-???
-????
-?????
-?????
-?????
-??????
-????
-???
-????
-???
-?????
-???
-???
-????
-????
-?????
-????
-????
-????
-????
-???
-???
-???
-????
-?????
-???
-????
-????
-??????
-????
-??????
-????
-??????
-????
-??????
-??????
-?????
-???????
-??????
-????????
-????
-??????
-?????
-???????
-??????
-???????
-??????
-?????????
-???
-???
-???
-?????
-?????
-?????
-??????
-??????
-???????
-???
-???
-????
-???
-???
-???
-???
-???
-?????
-??????
-????
-???
-???
-???
-????
-????
-??????
-???????
-?????????
-????
-??????
-???
-????
-???
-???
-????
-?????
-???
-????
-?????
-??????
-??
-???
-???
-????
-????
-????
-????
-???
-????
-???
-????
-??
-??
-??
-?????
-????
-??
-??
-??
-???
-???
-???
-???
-???
-???
-??
-??
-???
-????
-????
-???
-??
-??
-?????
-?????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-???
-?????
-???
-???
-???
-????
-???
-????
-????
-????
-???
-???
-????
-???
-???
-????
-???
-???
-????
-???
-???
-???
-?????
-?????
-?????
-??????
-???
-???
-?????
-?????
-????
-????
-??????
-????
-??????
-??
-??
-??
-???
-???
-???
-???
-??
-???
-???
-???
-????
-????
-????
-??
-??
-??
-??
-??
-???
-????
-????
-?????
-???
-????
-????
-????
-??????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-???????
-??????
-??????
-???????
-???????
-??????
-????????
-????
-????
-????
-????
-???
-????
-??
-??
-??
-????
-???
-???
-????
-??
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-????
-????
-?????
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-???
-?????
-??
-??
-??
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-??????
-???????
-??????
-???
-?????
-?????
-?????
-???
-??????
-???
-???
-????
-???
-???
-???
-???
-???
-?????
-??????
-????
-?????
-????
-????
-????
-???
-?????
-???
-???
-???
-???
-????
-?????
-??????
-??????
-????
-???????
-?????
-???
-????
-????
-????
-????
-?????
-?????
-?????
-????
-???
-???
-????
-???
-???
-???
-???
-?????
-?????
-???
-??????
-????
-?????
-????
-???
-?????
-?????
-????
-????
-???
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-??????
-?????
-?????
-?????
-?????
-??????
-???????
-???????
-?????
-??????
-??????
-???????
-???????
-???????
-????????
-????????
-?????????
-??????????
-?????
-??????
-???
-???
-????
-???
-???
-????
-????
-????
-???
-???
-???
-??????
-???
-???
-?????
-???
-?????
-????
-?????
-???????
-????
-?????
-???????
-??????
-?????
-?????
-???
-????
-??
-????
-??????
-???
-??
-??
-??
-??
-??
-????
-??
-???
-???
-?????
-????
-??????
-????
-??
-???
-??
-????
-???
-??
-????
-????
-????
-????
-???
-???
-?????
-????
-??????
-??
-??
-???
-????
-????
-???
-???
-???
-?????
-??
-??
-??
-??
-???
-???
-?????
-????
-??
-????
-????
-????
-?????
-?????
-????
-????
-?????
-????
-????
-?????
-?????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-?????
-?????
-??????
-??????
-??
-?????
-???
-???
-???
-????
-???
-???
-???
-????
-????
-???
-?????
-????
-????
-??????
-?????
-???
-????
-???
-???
-???
-?????
-?????
-?????
-???????
-????
-?????
-????
-???
-??
-??
-???
-???
-???
-????
-???
-??
-???
-???
-?????
-?????
-??
-??
-??
-???
-????
-??
-???
-??
-???
-??
-???
-????
-??????
-???
-???
-??
-??
-??
-????
-????
-????
-?????
-??????
-?????
-???
-???
-?????
-????
-????
-????
-???
-???
-???
-???
-???
-?????
-????
-?????
-??
-??
-??
-??
-??
-??
-??
-???
-????
-??
-???
-???
-??
-??
-????
-?????
-???????
-??
-???
-????
-???
-???
-???
-???
-???
-?????
-??????
-???????
-????
-?????
-????
-????
-???
-???
-?????
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-????
-???
-????
-?????
-???
-???
-???
-?????
-????
-?????
-??
-??
-??
-???
-????
-????
-?????
-?????
-?????
-?????
-???????
-??????
-??
-???
-???
-????
-???
-????
-???
-??
-??
-?
-?
-?
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-???
-???
-?????
-???
-??
-?
-?
-????
-?
-?
-???
-???
-?
-?
-???
-???
-???
-???
-????
-??????
-????
-????
-????
-????
-?????
-???
-????
-?
-?
-?
-?
-??
-?
-??
-?
-?
-?
-?
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-???
-???
-??
-??
-?
-?
-?
-?
-??
-??
-????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-??
-??
-???
-??
-?
-?
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-????
-????
-????
-?????
-????
-???
-??
-??
-??
-???
-??
-???
-????
-????
-????
-?????
-?????
-?????
-???
-???
-???
-???
-????
-???
-??????
-???
-??
-??
-???
-??
-??
-??
-???
-??
-???
-???
-??
-???
-??????
-????
-????
-???
-????
-???
-?????
-????
-????
-????
-???
-????
-????
-??
-??
-??
-??
-??
-??
-???
-????
-??????
-???
-????
-???
-???
-??
-??
-??
-???
-????
-?????
-??
-???
-????
-??
-???
-????
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-??
-??
-????
-?????
-??????
-???
-????
-???
-???
-????
-???
-??
-???
-?
-?
-?
-?
-??
-??
-?
-?
-?
-??
-?
-????
-???
-??
-????
-??
-???
-?????
-????
-??
-???
-????
-????
-????
-?????
-??????
-?????
-????
-??
-??
-?
-???
-???
-???
-?
-??
-?
-?
-?
-???
-???
-???
-???
-????
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-????
-??????
-??????
-?????
-????
-????
-?????
-??
-?
-?
-??
-??
-?
-???
-??
-??
-?
-?
-??
-???
-???
-???
-???
-????
-????
-?
-?
-?
-?
-??
-?
-??
-?
-??
-???
-????
-?
-?
-?
-??
-???
-???
-???
-?
-???
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-??
-???
-?????
-??
-??
-??
-?
-?
-???
-???
-???
-????
-?????
-??
-??
-???
-???
-???
-?????
-??
-??
-??
-??
-???
-???
-???
-????
-?
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-?????
-???
-???
-?
-??
-?
-?
-???
-???
-????
-??
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-??
-???
-?????
-??
-??
-???
-????
-???
-??
-????
-???
-?????
-????
-??
-??
-????
-??
-??
-????
-??
-??
-????
-???
-???
-???
-????
-??
-??
-???
-??
-?????
-??
-??
-??
-???
-????
-??
-???
-???
-?????
-???
-????
-????
-?????
-????
-????
-?????
-?????
-????
-????
-??????
-?????
-???
-???
-?????
-???
-???
-?????
-?????
-????
-??????
-?????
-??????
-????
-??
-???
-??
-??
-??????
-??
-????
-????
-???
-?????
-??
-??
-???
-????
-???
-???
-????
-?????
-????
-????
-???
-???
-???
-???
-????
-????
-??
-???
-???
-???
-??
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-????
-????
-???
-??
-??
-??
-???
-??
-???
-???
-???
-???
-???
-?????
-??
-???
-?????
-???
-??
-??
-???
-??
-??
-?
-??
-?
-???
-????
-??
-???
-???
-??
-??
-???
-????
-???
-??
-??
-???
-??????
-??????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-???
-???
-????
-??
-??
-??
-??
-??
-??
-???
-???
-???
-???
-?
-?
-?
-??
-???
-??
-??
-?
-??
-????
-?
-?
-??
-??
-??
-???
-???
-???
-???
-???
-???
-???
-?????
-???
-????
-???
-??
-??
-???
-???
-?
-??
-??
-???
-??
-????
-?
-?
-?
-???
-?
-?
-??
-?
-?
-?
-??
-?
-???
-?????
-??
-?????
-??
-?
-?
-?
-??
-??
-????
-????
-?
-?
-?
-??
-???
-?
-??
-??
-???
-??
-???
-???
-????
-???
-???
-???
-???
-????
-???
-?
-?
-?
-????
-?????
-???
-???
-???
-???
-????
-?
-??
-??
-??
-???
-???
-????
-????
-?????
-????
-?????
-???
-?????
-???
-?????
-????
-?????
-????
-????
-????
-????
-????
-??
-???
-???
-??
-??
-??
-??
-??
-??
-?
-?
-??
-?
-?
-?
-?
-???
-?
-?
-???
-?
-??
-????
-????
-????
-????
-???
-?????
-???
-?
-?
-??
-??
-??
-??
-???
-????
-?
-?
-?
-?
-??
-???
-??
-??
-??
-??
-?
-??
-????
-???
-?????
-??????
-?
-?
-?
-???
-??
-??
-??
-??
-??
-???
-????
-??
-??
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-????
-?????
-???
-??
-?
-?
-??
-??
-??
-???
-????
-???
-???
-???
-??
-??
-?
-???
-?
-?
-??
-???
-?
-??
-??
-??
-?
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-??
-??
-???????
-??
-???
-??
-????
-????
-???
-????
-???
-???
-???
-??
-??
-??
-??
-????
-??????
-??
-???
-??
-??
-??
-??
-??
-???
-????
-???
-????
-???
-?????
-????
-????
-????
-????
-????
-????
-????
-????
-???????
-??????
-?????
-?????
-?????
-????
-????
-????
-????
-??????
-??????
-???????
-???????
-????????
-??????
-???
-??
-??
-????
-????
-????
-???
-?????
-?????
-????
-??????
-??
-??
-??
-?????
-??????
-???
-???
-???
-?????
-?????
-????
-??????
-???
-???
-???
-????
-????
-????
-???
-???
-????
-????
-???
-??
-???
-????
-??
-??
-??
-??
-??
-???
-???
-??
-??
-????
-??
-???
-???
-???
-????
-?????
-????
-?????
-?????
-?????
-????
-??
-????
-??
-??
-??
-???
-????
-??
-??
-??
-??
-??
-???
-??
-???
-????
-??
-??
-??
-??
-????
-?????
-??????
-???
-???
-????
-???
-??
-??
-????
-???
-??
-??
-????
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-??
-??
-???
-??
-??
-????
-????
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-?????
-????
-????
-?????
-??
-??
-?????
-???
-???
-???
-?????
-????
-????
-??????
-?????
-????
-?????
-???????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-?????
-?????
-?????
-????
-???
-????
-??
-??
-??
-??
-??
-??
-???
-???
-????
-???
-????
-????
-??????
-?????
-???
-????
-????
-????
-?????
-?????
-?????
-????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-??
-????
-???
-??
-??
-????
-??
-??
-????
-???
-?????
-????
-??????
-????
-???
-??
-??
-??
-??
-??
-???
-???
-????
-?????
-???
-?????
-????
-???
-????
-??
-??
-??
-??
-????
-???
-???
-???
-?????
-?????
-????
-???
-?????
-???
-??
-??
-???
-????
-???
-???
-?????
-????
-?????
-???
-???
-???
-????
-????
-???
-???
-???
-????
-???
-????
-???
-????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-???????
-??
-??
-???
-???
-???
-????
-??????
-???
-???
-????
-???
-???
-????
-?????
-?????
-???
-???
-???
-????
-????
-????
-??????
-???????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-?????
-?????
-???
-????
-????
-??????
-??????
-???????
-?????
-?????
-??????
-??????
-??????
-???
-?????
-???
-???
-???
-????
-?????
-???
-???
-????
-????
-??
-???
-???
-???
-???
-????
-????
-????
-???????
-????????
-?????
-??????
-???
-??
-????
-?????
-????
-?????
-????
-????
-????
-???
-?????
-????
-??
-???
-??
-??
-??
-????
-????
-????
-?????
-?????
-????
-??????
-???
-?????
-??
-??
-????
-????
-????
-?????
-???
-??
-??
-???
-???
-????
-??
-??
-??
-???
-???
-?????
-????
-???
-?????
-????
-?????
-?????
-?????
-???????
-???
-????
-??
-??
-??
-??
-??
-???
-??
-???
-???
-??????
-?????
-??????
-??????
-???????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-???
-???
-????
-????
-????
-?????
-?????
-?????
-???????
-???
-???
-????
-???
-????
-???
-???
-???
-???
-????
-????
-????
-????
-??????
-????
-????
-????
-???
-???
-???
-???
-????
-???
-???
-?????
-?????
-?????
-??????
-???????
-????
-???
-???
-???
-???
-???
-?????
-??????
-?????
-????
-????
-????
-?????
-???
-????
-???
-???
-?????
-????
-?????
-?????
-????
-?????
-???
-????
-????
-??????
-???????
-?????
-??????
-???
-????
-???
-????
-????
-????
-????
-??????
-?????
-????
-????
-????
-????
-?????
-??????
-???
-?????
-???
-???
-???
-????
-???
-????
-????
-???????
-????
-??????
-??????
-??????
-????????
-?????
-???????
-?????
-??
-???
-???
-??
-???
-???
-?????
-????
-??
-??
-??
-???
-????
-??
-???
-???
-???
-????
-??
-??
-????
-???
-???
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-??
-????
-????
-??
-??
-??
-????
-???
-???
-???
-???
-????
-??
-??
-???
-????
-??
-???
-?????
-???
-???
-???
-??
-????
-??
-??
-??
-?????
-????
-???
-????
-???
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-?????
-????
-???
-???
-???
-????
-????
-????
-????
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-????
-?????
-????
-???
-????
-????
-????
-??
-????
-????
-???
-???
-???
-????
-????
-???
-???
-????
-??
-??
-????
-??
-?????
-?????
-?????
-??????
-?????
-?????
-??????
-??????
-??????
-?????
-??????
-??????
-???????
-?????
-????
-?????
-??
-??
-??
-???
-???
-????
-??
-??
-??
-??
-???
-????
-????
-????
-????
-????
-????
-?????
-?????
-????
-????
-??
-??
-?????
-????
-????
-??????
-?????
-?????
-?????
-???
-?????
-?????
-????
-?????
-???????
-?????
-???
-??
-???
-???
-??
-??
-???
-??
-??
-???
-???
-??
-???
-??
-??
-??
-??
-????
-???
-???
-???
-???
-???
-????
-????
-?????
-??
-??
-??
-???
-??
-??
-???
-?????
-???
-?????
-?????
-???
-?????
-??????
-?????
-??
-?
-?
-??
-?
-???
-???
-??
-????
-??
-?
-???
-???
-??
-??
-???
-???
-?
-?????
-???
-???????
-?????
-????
-???
-?????
-?????
-?
-?
-?
-???
-????
-??
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-?
-?
-??
-??
-??
-????
-??
-??
-?
-??
-????
-???
-????
-????
-???
-???
-?
-?
-??
-??
-????
-?
-???
-?
-??
-???
-???
-????
-??
-???
-???
-???
-???
-???
-????
-??
-??
-??
-???
-???
-?
-?
-?
-???
-??
-????
-?????
-??
-??
-??
-????
-???
-????
-???
-??
-??
-???
-??
-??
-??
-???
-????
-???
-???
-???
-???
-???
-??
-?
-??
-??
-??
-??
-??
-??
-????
-????
-??
-??
-????
-??
-????
-??
-???
-??
-???
-???
-????
-????
-????
-????
-??
-???
-???
-???
-????
-???
-??
-???
-???
-????
-??????
-???
-??
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-???
-??
-???
-???
-?
-?
-?
-??
-????
-?
-??
-?
-?
-???
-?
-?
-??
-??
-?
-?
-??
-?
-?
-??
-??
-??
-????
-?
-?
-?????
-????
-??????
-????
-????
-????
-????
-??
-????
-??
-??
-??
-??
-??
-??
-????
-?????
-??????
-???
-???
-???
-???
-????
-??
-????
-???
-????
-????
-????
-??
-??
-????
-???
-???
-???
-??????
-????
-?????
-????
-????
-???
-???
-???
-?????
-????
-?????
-????
-???
-????
-?????
-?????
-???
-??????
-???
-????
-???
-???
-?
-??
-?
-?
-?
-???
-?
-?
-?
-?
-???
-?
-???
-??
-??
-???
-?????
-??
-???
-??
-????
-??
-?
-?
-?
-???
-???
-????
-?????
-???
-??????
-????
-???
-?
-?
-???
-????
-??
-??
-??
-??
-???
-???
-???
-???
-???
-?????
-?
-??
-?
-?
-??
-???
-???
-??
-??
-????
-????
-???
-???
-???
-??
-??????
-???
-????
-??
-??
-?
-??
-??
-?
-?
-?
-?
-??
-?
-??
-???
-???
-???
-????
-??
-??
-????
-???
-???
-??
-??
-??
-????
-??
-??
-??
-???
-????
-???
-?
-?
-??
-?
-?
-??
-????
-???
-???
-?
-?
-??
-????
-????
-?????
-??????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-????
-??????
-??
-???
-???
-???
-?
-?
-??
-?
-?
-?
-?
-?
-??
-?
-???
-?
-??
-??
-??
-??
-???
-???
-???
-????
-?????
-???
-??
-????
-??
-??
-???
-???
-???
-??
-????
-?????
-????
-??????
-??
-??
-??
-???
-???
-???
-?????
-???
-????
-???
-???
-???
-???
-???
-???
-????
-??????
-?????
-????
-????
-????
-?????
-????
-???
-???
-?????
-????
-???
-?????
-????
-???
-?
-?
-???
-???
-???
-?????
-???
-???
-????
-?????
-?????
-?????
-??????
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-??
-???
-?????
-????
-??????
-??
-??
-???
-???
-???
-???
-????
-??????
-?????
-??
-??
-??
-?
-??
-??
-????
-?
-???
-???
-???
-?
-??
-??
-????
-??
-????
-????
-?????
-????
-??????
-???
-?????
-???
-??
-??
-??
-????
-???
-?????
-????
-???
-???
-???
-???
-????
-????
-?
-???
-?
-???
-?
-???
-????
-???
-???
-???
-???
-????
-????
-????
-????
-???
-?
-?
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-??
-???
-??
-?????
-?????
-??????
-??
-????
-????
-????
-????
-??????
-?????
-?????
-????
-?????
-?
-??
-???
-?
-?
-?
-?
-???
-?????
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-???
-?????
-?????
-?????
-?????
-??????
-??????
-??????
-??????
-?????
-?????
-???????
-????
-????
-????
-?????
-??????
-??????
-?????
-?????
-???????
-????????
-????
-???
-???
-?????
-??
-??
-???
-??
-?????
-?????
-????
-???
-????
-????
-?????
-???
-?
-??
-??
-???
-?
-?
-??
-?
-?
-?
-?
-?
-???
-?????
-??
-???
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-??
-?
-??
-??
-???
-?
-??
-?
-?
-?
-???
-??
-???
-??
-??
-??
-??
-????
-?
-?
-?
-??
-??
-??
-????
-????
-??
-??
-????
-?????
-??
-??
-???
-??
-??
-????
-???
-???
-???
-??
-??
-??
-??
-??
-?????
-?????
-?????
-????
-???
-???
-???
-????
-??
-??
-???
-???
-?
-?
-??
-????
-???
-?
-?
-?
-??
-??
-??
-?
-?
-???
-??
-?
-??
-?
-?
-?
-???
-?
-?
-?
-???
-??
-????
-??
-?
-?
-?
-?
-??
-???
-?
-?
-?
-?
-??
-?
-?
-?
-?
-???
-??
-??
-?
-??
-??
-???
-?
-??
-?
-?
-?
-???
-??
-???
-??
-??
-??
-??
-???
-???
-???
-??
-??
-???
-????
-???
-????
-??
-?
-??
-??
-??
-???
-?
-??
-??
-???
-??
-????
-??
-??
-??
-??
-??
-?
-?
-?
-?
-?
-?
-?
-??
-??
-?
-???
-????
-???
-?
-???
-??
-??
-??
-????
-????
-???
-???
-?
-?
-?
-?
-?
-??
-??
-?
-???
-??
-????
-????
-??????
-???
-????
-?????
-????
-???
-?????
-????
-????
-?????
-?????
-??
-??
-??
-????
-??
-??
-???
-??
-??
-????
-???
-???
-???
-?????
-????
-?????
-???
-???
-??
-??
-??
-?????
-?????
-????
-?????
-???
-???
-???
-????
-???
-?????
-????
-?????
-???????
-???
-????
-???????
-???
-???????
-????
-????
-?????
-???
-???
-?
-???
-????
-???
-??
-?
-???
-???
-???
-????
-???
-???
-??
-?????
-???
-??
-????
-??
-???
-????
-??
-??
-????
-?
-?
-?
-?
-?
-???
-??
-??
-??
-??
-???
-??
-???
-???
-????
-???
-???
-??
-??
-??
-???
-???
-????
-???
-???
-???
-?
-?
-?
-??
-???
-?
-?
-??
-?
-?
-?
-???
-??
-?????
-????
-????
-?????
-??????
-?????
-?????
-?????
-????
-????
-????
-????
-??????
-?????
-??????
-??????
-??????
-??????
-???????
-?????
-??
-??
-??
-??
-??
-??
-???
-???
-?????
-?????
-??????
-??????
-?????
-?????
-?????
-?????
-???????
-??
-???
-?
-?
-?
-??
-???
-????
-????
-??
-????
-?
-??
-?
-??
-??
-???
-?
-?
-?
-?
-?????
-?
-??
-??
-???
-????
-?????
-???
-??
-???
-????
-??????
-????
-???
-???
-???
-????
-??
-??
-??
-???
-?????
-????
-???
-???
-???
-???
-???
-???
-?????
-???
-?????
-??
-???
-??
-?
-?
-?
-??
-????
-???
-??
-??
-??
-????
-???
-????
-????
-????
-????
-?????
-???
-???
-?
-??
-?
-?
-??
-??
-??
-?
-?
-?
-??
-??
-??
-???
-????
-????
-?
-?
-?
-??
-??
-??
-??
-??
-???
-?
-??
-?????
-?????
-??????
-???
-?
-?
-??
-?
-???
-????
-??
-?
-??
-??
-??
-??
-????
-???
-??
-???
-???
-??
-??
-????
-???
-????
-????
-????
-???
-?
-??????
-??????
-??
-????
-????
-??
-???
-???
-????
-??
-???
-???
-????
-???
-???
-????
-????
-?????
-??
-????
-??
-???
-??
-???
-?????
-????
-???
-??????
-????
-????
-???
-???
-???
-???
-??????
-???
-???
-????
-??
-???
-??
-???
-???
-??
-????
-???
-????
-?????
-?????
-?????
-??????
-??????
-???????
-??????
-??????
-????
-?
-????
-?
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-?
-?
-?
-???
-???
-???
-???
-???
-?????
-??????
-???
-????
-???
-???
-???
-???
-????
-??????
-?????
-???????
-??
-??
-????
-???
-??????
-????
-?????
-???
-??
-???
-??
-??
-??
-???
-??
-??
-??
-???
-??
-????
-??
-??
-??
-?
-?
-??
-??
-?
-?
-??
-?
-??
-???
-?
-?
-?
-?
-??
-????
-??
-????
-????
-????
-???
-???
-????
-???
-??
-????
-????
-??????
-???
-?????
-??
-????
-?????
-??
-??
-??
-????
-???
-???
-???
-????
-??
-?
-???
-??
-?
-?
-???
-?
-?
-??
-??
-??
-????
-??
-?
-?
-???
-??
-???
-??
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-??
-???
-??
-??
-??
-???
-????
-???
-???
-????
-????
-???
-???
-????
-?????
-???
-???
-????
-????
-???????
-????
-??????
-??????
-?????
-??
-????
-????
-?????
-??????
-??
-??
-???
-?????
-????
-???
-?????
-?????
-??????
-?????
-?????
-??????
-????
-???
-???
-??
-???
-???
-???
-????
-?????
-?????
-????
-??
-??
-??
-??
-??
-????
-???
-??
-??
-????
-???
-???
-?????
-??
-??
-???
-?????
-???
-????
-?????
-?????
-?????
-????
-???
-??????
-??????
-????
-???
-???
-?????
-?????
-??????
-????
-??????
-????
-???
-???
-?????
-????
-???
-???
-????
-????
-???
-?????
-??
-??
-???
-????
-????
-??
-??
-????
-?????
-??
-???
-??????
-??
-??
-???
-??
-??
-??
-??
-??
-????
-???
-???
-??
-??
-??
-??
-??
-???
-???
-????
-???
-????
-??
-??
-??
-??
-??
-???
-???
-???
-????
-????
-???
-??
-????
-????
-????
-??????
-???
-?????
-??
-????
-????
-???
-???
-????
-??
-????
-????
-????
-????
-???
-????
-????
-????
-???
-????
-????
-??
-??
-????
-???
-????
-??
-???
-??
-??
-??
-???
-???
-?????
-????
-????
-????
-?????
-?????
-??
-??
-??
-??????
-???
-???
-????
-???
-????
-????
-???
-????
-????
-????
-??????
-????
-????
-?????
-??
-??
-???
-???
-????
-??
-????
-??
-??
-????
-??????
-???
-????
-??
-???
-???
-???
-???
-????
-????
-???
-????
-????
-????
-????
-??????
-????
-????
-????
-????
-?????
-?????
-??????
-?????
-????
-?????
-?????
-??????
-?????
-??????
-??????
-??????
-???????
-??????
-??????
-??????
-???
-???
-???
-???
-??????
-??????
-???
-????
-???
-???
-???
-???
-????
-?????
-??
-???
-??????
-????
-???
-????
-??
-??
-???
-??
-???
-???
-?????
-??
-???
-???
-????
-??
-??
-??
-??
-???
-????
-???
-???
-???
-???
-???
-???
-???
-????
-???
-????
-??
-????
-??
-???
-???
-??
-??
-??
-??
-????
-????
-??
-??
-????
-??
-????
-????
-????
-??
-???
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-????
-??????
-??
-????
-?????
-???
-?????
-??????
-???
-???
-???
-???
-???
-???
-?????
-????
-??????
-???
-???
-?????
-?????
-?????
-????
-??????
-?????
-???
-????
-????
-????
-????
-??????
-???
-???
-????
-???
-???
-???
-???
-???
-?????
-??????
-???????
-?????
-????
-????
-????
-?????
-????
-?????
-???
-???
-?????
-?????
-????
-????
-??????
-?????
-???
-???
-???
-????
-?????
-??????
-?????
-?????
-????
-?????
-???
-???
-????
-????
-?????
-??????
-?????
-???????
-??????
-????????
-?????
-??????
-??????
-???????
-??????
-????????
-????
-????
-????
-??????
-????
-????
-????
-?????
-?????
-?????
-?????
-????????
-???????
-???????
-?????
-????
-????
-?????
-?????
-??????
-????
-?????
-????
-??????
-????
-??????
-????
-?????
-???????
-??????
-????????
-??????
-??????
-??????
-??????
-???????
-?????
-????????
-?????
-????
-????
-?????
-??????
-?????
-????
-????
-????
-??????
-????
-?????
-???????
-??????
-??????
-???
-???
-????
-????
-?????
-????
-??????
-??????
-??????
-??
-????
-???
-?????
-?????
-?????
-?????
-???
-?????
-????
-?????
-????
-???
-??
-???
-???
-???
-???
-?????
-????
-????
-???
-???
-?????
-?????
-??????
-?????
-???
-???
-????
-????
-????
-????
-????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-?????
-??????
-????
-???
-???
-?????
-????
-???
-???
-?????
-???
-???
-???
-????
-??
-???
-???
-??
-????
-????
-??
-????
-???
-?????
-??
-??
-??
-??
-???
-???
-??
-??
-??
-???
-???
-???
-??
-???
-?????
-????
-?????
-???
-?????
-????
-???
-???
-????
-?????
-?????
-??????
-????
-???
-??
-??
-????
-????
-???
-??
-????
-?????
-????
-??????
-???
-???
-???
-????
-???
-????
-???
-???
-???
-????
-????
-????
-?????
-????
-????
-?????
-????
-????
-????
-???
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-???
-???
-????
-?????
-?????
-???????
-????
-??
-??
-??
-???
-???
-??
-??
-???
-???
-?????
-????
-??????
-?????
-???????
-????
-??
-??
-??????
-??????
-????????
-???????
-????
-??
-??
-???
-???????
-???????
-???
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-????
-??
-???
-????
-????
-????
-???
-??
-???
-???
-???
-??
-??
-??
-????
-????
-??????
-?????
-??
-????
-????
-??????
-??????
-????
-????
-????
-????
-????
-?????
-????
-????
-?????
-?????
-????
-?????
-??????
-???
-?????
-????
-?????
-??
-???
-???
-??
-??
-??
-??
-???
-????
-??
-??
-??
-????
-????
-???
-???
-???
-????
-???
-????
-????
-?????
-??
-???
-?????
-??
-??
-????
-??
-????
-????
-????
-????
-???
-???
-???
-????
-??????
-??????
-????
-?????
-?????
-????
-??????
-????
-??????
-???
-?????
-???
-?????
-???
-?????
-??
-??
-???
-???
-??
-??
-??
-??
-??
-?????
-??
-??
-??
-??
-??
-??
-??
-??
-????
-???
-???
-???
-???
-??
-???
-???
-???
-????
-????
-??
-??
-???
-??
-??
-?????
-???
-???
-?????
-?
-??
-??
-???
-??
-???
-????
-????
-?????
-?
-??
-???
-?
-?
-??
-??
-??
-??
-???
-??
-????
-????
-??????
-??
-??
-???
-?????
-?????
-?????
-????
-????
-?????
-??
-???
-???
-????
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-?????
-?
-??
-??
-??
-???
-???
-????
-????
-????
-??????
-???????
-???????
-??
-??
-??
-???
-??
-??
-??
-???
-???
-???
-????
-????
-?????
-??????
-??????
-??????
-??????
-???????
-????????
-?????
-?????????
-???
-????
-?????
-????
-????
-????
-?????
-????
-?????
-??????
-?????
-??
-??
-??
-???
-???
-???
-???
-?????
-????
-????
-??
-??
-???
-???
-???
-????
-????
-??
-???
-???
-???
-??
-??
-??
-??
-???
-????
-??
-??
-??
-??
-??
-??
-???
-???
-????
-?
-???
-???
-???
-???
-????
-???
-???
-????
-???
-???
-??
-???
-???
-????
-??
-??
-?
-?
-???
-???
-???
-???
-???
-???
-???
-????
-????
-???
-??
-??
-?
-?
-?
-??
-??
-???
-???
-???
-???
-???
-???
-?????
-?
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-?????
-????
-????
-???
-?????
-?????
-?????
-???????
-??????
-???????
-???????
-??????
-????????
-????
-??
-?
-???
-????
-??
-?
-?????
-??
-???
-???
-???
-??
-???
-???
-???
-???
-????
-?????
-?
-?
-?
-?
-??
-????
-??
-??
-??
-??
-?
-??
-??
-??
-??
-??
-????
-????
-???
-????
-????
-???
-??
-???
-????
-?
-?
-??
-??
-??
-??
-??
-???
-?
-??
-??
-??
-??
-??
-??
-???
-???
-?
-?
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-????
-???
-?????
-??
-??
-???
-??
-??
-??
-??
-??
-?????
-???????
-???????
-??
-???
-????
-???????
-???
-????
-???
-?????
-?????
-????
-????
-?????
-????
-?????
-????
-?????
-?????
-????
-??
-??
-??
-??
-???
-??
-???
-???
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-????
-???
-???
-???
-????
-???
-????
-????
-????
-????
-????
-????
-????
-?????
-????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-?????
-??????
-?????
-???
-???
-??
-???
-?????
-?????
-??
-??
-???
-???
-???
-?????
-???
-????
-???
-???
-???
-????
-????
-????
-?????
-?????
-??????
-?????
-?????
-??????
-?????
-?????
-???????
-???
-????
-????
-?????
-????
-????
-??
-??
-?
-?
-?
-??
-??
-???
-??
-??
-?
-??
-??
-???
-????
-??
-??
-??
-??
-??
-??
-????
-????
-????
-??????
-??????
-???????
-?????
-????
-???????
-?????
-?????
-????
-?????
-?????
-??
-??
-???
-??
-??
-???
-???
-???
-????
-????
-???
-???
-???
-????
-???
-??
-?
-???
-?
-???
-??
-??
-????
-???
-??
-??
-???
-?????
-???????
-?????
-?????
-????
-??????
-???
-???
-?????
-??
-??
-????
-???
-??????
-????
-???
-?????
-??
-??
-????
-??
-???
-?????
-??????
-???
-???
-??
-???
-???
-???
-????
-???
-?
-?
-???
-???
-????
-???
-???
-????
-?
-?
-?
-??
-???
-??
-????
-???
-??
-???
-????
-???
-???
-????
-????
-????
-?????
-???
-?????
-?????
-???
-???
-???
-?????
-??????
-??????
-???????
-??????
-????
-????
-????
-?????
-???
-??
-??
-??
-???
-????
-???
-??
-???
-??
-???
-?
-?
-?
-?
-??
-??
-??
-??
-??
-?
-??
-???
-?
-?
-?
-?
-?
-?
-??
-????
-??
-?
-??
-???
-????
-???
-??
-?
-?
-??
-?
-??
-???
-???
-??
-???
-??
-???
-??
-??
-??
-??
-??
-????
-???
-??
-??
-???
-???
-???
-??
-???
-???
-??
-???
-????
-???
-????
-???
-??????
-???
-???
-???
-???
-????
-???
-????
-????
-????
-????
-?
-?
-?
-??
-??
-??
-??
-??
-?????
-?????
-??????
-??????
-???????
-????
-???????
-??????
-????
-????
-?????
-??????
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-??
-?
-??
-??
-???
-???
-??
-??
-???
-??
-???
-???
-???
-??
-?
-?
-?
-??
-??
-?
-??
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-???
-??
-???
-????
-???
-?????
-????
-???
-???
-???
-???
-???
-???
-?????
-????
-????
-?????
-????
-????
-?????
-?????
-??????
-????
-????
-?????
-????
-??
-???
-?
-?
-?
-?
-??
-?
-?
-??
-?
-?
-?
-??
-?
-?
-???
-??
-?
-?
-??
-?
-?
-?
-?
-?
-?
-???
-????
-??
-???
-??
-??
-??
-???
-?
-?
-??
-??
-?
-???
-????
-?????
-???
-????
-????
-????
-???
-????
-??
-??
-???
-??
-??
-??
-??
-????
-??
-???
-????
-????
-???
-???
-????
-???
-???
-???
-???
-?????
-????
-????
-????
-????
-????
-????
-?????
-??????
-???
-???
-???
-???
-????
-???
-?????
-???
-???
-????
-?????
-??
-??
-??
-??
-????
-???
-????
-??
-???
-???
-???
-????
-??
-??
-????
-???
-???
-???
-???
-???
-?????
-???
-???
-???
-????
-?????
-?????
-???
-?????
-????
-???
-???
-????
-????
-??????
-???
-?????
-??
-??
-??
-??
-????
-??
-????
-???
-?????
-????
-???
-???
-??
-???
-????
-????
-???
-???
-????
-??
-??
-???
-??
-???
-????
-???
-??
-???
-???
-????
-????
-????
-????
-?????
-?????
-????
-??????
-????
-?????
-?????
-??
-???
-??
-??
-?????
-???
-???
-???
-?????
-?????
-?????
-??????
-???????
-??????
-??????
-??????
-???????
-???????
-???????
-?????
-?????
-??????
-????
-??
-??
-???
-????
-???
-???
-????
-??
-??
-?????
-????
-????
-????
-????
-???????
-?????
-????
-??
-??
-??
-??
-??
-?????
-???
-????
-????
-???
-???
-??
-??
-???
-????
-????
-?????
-?
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-????
-???
-???
-????
-?????
-????
-????
-????
-????
-????
-????
-??????
-???????
-???
-????
-??????
-???
-???
-?
-?
-?
-?
-??
-??
-??
-??
-???
-??
-????
-???
-????
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-???
-????
-??
-??
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-?
-??
-??
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-???
-?
-???
-?????
-?
-?
-?
-?
-??
-???
-???
-???
-??????
-????
-???
-???
-???
-?????
-????
-??
-??
-???
-?????
-????
-???
-????
-??????
-????????
-???
-??
-??
-??
-??
-??
-???
-??
-???
-??
-???
-???
-??
-??
-?
-?
-?
-?
-?
-??
-??
-???
-???
-??
-??
-???
-???
-???
-??
-??
-??
-??
-???
-?
-??
-?
-?
-????
-?
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-?????
-??????
-??
-??????
-???
-??
-??
-??
-???
-???
-????
-??
-?
-???
-???
-??
-??
-??
-????
-?
-?
-?
-?
-?
-???
-???
-??
-???
-???
-??????
-???
-????
-???
-??????
-???
-????
-????
-????
-???
-???
-????
-????
-??
-???
-??
-??
-????
-???
-????
-???
-???
-??
-??
-??
-????
-????
-????
-?????
-???
-????
-???
-?
-?
-?
-?
-?
-???
-??
-?
-?
-?
-??
-?
-?
-?
-?
-??
-??
-?
-?
-?
-???
-?
-?
-?
-?
-??
-?
-?
-??
-????
-???
-??
-???
-????
-???
-??
-??
-??
-??
-???
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-????
-???
-????
-???
-???
-???
-????
-?????
-?????
-????
-????
-?????
-???
-????
-????
-????
-????
-?????
-????
-?????
-???
-???
-???
-????
-?????
-???
-???
-???
-???
-????
-?????
-????
-????
-????
-?????
-??????
-?????
-??
-??
-??
-????
-??
-??
-??
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-?
-??
-??
-???
-???
-????
-????
-?????
-?????
-?????
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-?
-?
-?
-??
-??
-????
-???
-???
-???
-???
-????
-???
-???
-???
-????
-?????
-????
-????
-?????
-??
-????
-?????
-???
-?
-?
-?
-?
-?
-?
-??
-??
-??
-???
-???
-????
-????
-??
-??
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-??
-??
-???
-???
-??
-??
-??
-????
-??
-??
-????
-???
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-??????
-??
-???
-??
-???
-?????
-???
-????
-????
-???
-????
-??
-??
-??
-???
-????
-????
-????
-?????
-?????
-??
-???
-????
-??
-??
-??
-???
-??
-??
-???
-???
-????
-???
-???
-????
-???
-????
-???
-???
-???
-???
-????
-???
-??
-????
-?????
-????
-?????
-?????
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-???
-???
-???
-???
-????
-?????
-????
-???
-???
-????
-????
-????
-?????
-????
-????
-????
-????
-??
-????
-????
-??
-?????
-???
-???
-???
-????
-???
-????
-???
-?????
-????
-????
-???
-???
-???
-???
-?????
-??????
-?????
-????
-????
-????
-????
-????
-?????
-????
-?????
-????
-?????
-??
-??
-???
-???
-????
-???
-????
-?????
-????
-????
-????
-????
-????
-????
-??????
-?????
-?????
-??????
-?????
-????
-??
-????
-????
-????
-??????
-?????
-???????
-???????
-????????
-??????
-???????
-?????????
-???????
-????
-?????
-??
-??
-??
-????
-???
-?????
-??????
-????
-?
-?
-?
-?
-?
-?
-?
-??
-?
-??
-???
-?
-?
-?
-??
-??
-??
-???
-?
-?
-?
-?
-?
-?
-?
-??
-??
-???
-???
-????
-???
-???
-?
-?
-??
-???
-?
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-?????
-???
-???
-????
-????
-????
-????
-????
-????
-???
-????
-?????
-?????
-???
-???
-???
-???
-???
-???
-????
-????
-????
-??????
-??????
-????
-????
-????
-?????
-?????
-????
-?????
-????
-????
-????
-????
-????
-?????
-????
-?????
-??
-??
-???
-???
-????
-??
-???
-??
-??
-????
-??
-????
-???
-???
-????
-???
-????
-????
-????
-????
-???
-????
-???
-??
-???
-???
-????
-???
-?????
-??
-???
-???
-????
-???
-?
-?
-?
-??
-?
-??
-??
-?????
-????
-??
-??
-???
-???
-???
-??????
-???
-??
-?????
-????
-????
-????
-????
-????
-?????
-?????
-?????
-???
-????
-??
-??
-??
-??
-??
-???
-???
-???
-????
-??
-??
-???
-??
-???
-??
-???
-???
-??
-????
-????
-????
-????
-?????
-????
-??????
-??????
-??????
-??????
-??????
-??????
-???????
-???????
-???????
-????
-????
-????
-????
-??????
-????
-?????
-?????
-??????
-??????
-????????
-???????
-??????
-???????
-???????
-??????
-???
-???
-???
-???
-???
-???
-????
-????
-??
-??
-??
-??
-??
-??
-?????
-???
-??
-??
-???
-???
-???
-????
-???
-????
-???
-???
-???
-????
-????
-????
-?????
-?????
-???
-????
-???
-??
-??
-??
-???
-???
-???
-??
-???
-???
-???
-???
-???
-????
-???
-???
-?????
-????
-????
-??
-???
-???
-???
-????
-???
-??
-??
-?????
-????
-??
-??
-???
-???
-???
-??
-??
-??
-???
-??
-??
-??
-??
-???
-????
-??
-??
-???
-??
-??
-???
-??
-??
-??
-???
-?????
-??
-???
-???
-???
-???
-???
-???
-???
-???
-??????
-????
-????
-????
-???
-???
-????
-?????
-???
-???
-????
-????
-???
-?????
-??
-??
-??
-??
-??
-??
-???
-???
-??
-?
-?
-??
-?
-?
-?
-?
-??
-??
-???
-????
-??
-?
-?
-?
-??
-??
-????
-?
-?
-??
-??
-?
-??
-??
-?
-?
-??
-???
-?
-????
-??
-???
-??
-????
-??
-??
-???
-??
-???
-?
-??
-??
-??
-??
-??
-??
-???
-??
-???
-?
-?
-?
-??
-??
-??
-??
-??
-???
-??
-??
-????
-???
-???
-?????
-????
-????
-?????
-??
-??
-??
-???
-???
-???
-???
-????
-???
-??
-??
-????
-??
-???
-???
-???
-???
-?????
-??????
-????
-????
-????
-????
-??????
-??????
-???????
-?????
-???
-??
-??
-???
-???
-????
-?
-??
-???
-???
-????
-????
-????
-????
-?????
-????
-?????
-?
-?
-?
-???
-???
-???
-???
-??
-???
-?????
-?????
-???
-??????
-?????
-?????
-?????
-???????
-??
-????
-?
-?
-?
-?
-???
-???
-?
-???
-????
-????
-?????
-?
-?
-?
-????
-?
-?
-??
-??
-??
-??
-???
-?
-?
-?
-?
-??????
-??
-??
-???
-??
-???
-??
-??
-??
-??
-???
-??
-???
-??
-??
-????
-????
-??
-????
-??
-??
-???
-????
-??????
-????
-?????
-?????
-?????
-?????
-?????
-???????
-???
-????
-???
-????
-???
-??????
-?????
-??????
-??????
-??????
-???
-???
-???
-???
-????
-????
-???????
-??????
-??
-??
-?
-??
-?
-??
-??
-????
-?
-???
-??
-?
-??
-???
-?
-??
-??
-?
-?
-??
-?????
-??
-??
-???
-???
-???
-?????
-??
-??
-??
-???
-???
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-??
-??????
-???
-????
-???
-??????
-??
-????
-???
-???
-???
-???
-????
-??
-??
-??
-?
-??
-?
-?
-??
-???
-???
-????
-??
-??
-???
-??
-??
-???
-???
-???
-?
-??
-?
-??
-??
-??
-??
-???
-?
-???
-???
-?
-?
-??
-?
-????
-?????
-??
-???
-?
-?
-??
-???
-??????
-????
-????
-??
-???
-??
-??
-??
-??
-???
-??
-??
-???
-???
-???
-??????
-??
-??
-????
-???
-???
-????
-????
-?????
-????
-??
-??
-??
-??
-???
-???
-???
-???
-????
-????
-???
-???
-?
-?
-?
-?
-??
-??
-???
-???
-???
-??
-??
-????
-???
-??
-???
-???
-???
-????
-????
-????
-????
-?????
-????
-????
-????
-??
-????
-??
-???
-????
-????
-????
-????
-????
-?????
-????
-???
-???
-???
-????
-????
-???
-???
-????
-????
-????
-????
-???
-???
-??????
-???
-???
-????
-????
-????
-?????
-???
-???
-???
-??
-??
-??
-????
-??
-??
-??
-???
-???
-???
-???
-???
-??
-??
-??
-??
-??
-????
-??
-??
-???
-???
-??
-??
-??
-??
-??
-???
-????
-??
-???
-????
-?????
-???
-????
-?????
-???
-???
-???
-???
-???
-???
-????
-????
-?????
-?????
-???
-???
-???
-???
-???
-????
-???
-???
-????
-????
-????
-????
-????
-????
-?????
-????
-?????
-???
-???
-????
-?
-?
-??
-??
-??
-?
-??
-????
-??
-??
-????
-???
-???
-???
-????
-???
-???
-???
-??
-????
-??
-??
-?????
-???
-?
-?
-?
-?
-??
-?
-?
-??
-??
-??
-????
-??
-??
-?????
-??
-?
-?
-??
-??
-???
-???
-???
-??
-????
-??
-??
-??
-??
-???
-??
-??
-???
-????
-???
-?
-?
-?
-?
-????
-????
-??
-?????
-???
-??
-??
-??
-???
-??
-??
-??
-?
-?
-?
-?
-??
-??
-??
-??
-??
-??
-????
-????
-?????
-?
-?
-?
-?
-?
-???
-?
-?
-?
-?
-???
-???
-???
-???
-??????
-?
-??
-??
-??
-?
-??
-?
-?
-??
-?
-???
-????
-???
-????
-????
-????
-?
-?
-?
-?
-??
-?
-?
-?
-?
-?
-?
-?
-????
-???
-???
-????
-???
-??
-??
-?
-?
-??
-??
-?????
-??????
-????
-???????
-??????
-????????
-???????
-????????
-???????
-??????
-?
-???????
-??????
-????
-???
-????
-??
-??
-???
-???
-???
-????
-?
-??????
-??
-??
-??
-????
-????
-????
-???
-???
-???
-???
-???
-????
-?
-???
-??
-?
-???
-???
-?
-????
-?
-?
-?
-?
-????
-???
-???
-?
-??
-??
-??
-??
-???
-???
-??
-???
-???
-???
-???
-??
-???
-?????
-????
-????
-????
-????
-???????
-??????
-??????
-????
-????
-?????
-?????
-??
-??
-??
-???
-??
-???
-????
-???
-???
-????
-??
-??
-???
-??
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-????
-??
-??
-??
-???
-??
-??
-??
-??
-???
-???
-???
-???
-???
-???
-????
-???
-???
-???
-???
-???
-????
-????
-??
-??
-????
-????
-?????
-??
-?
-?
-?
-?
-?
-?
-??
-??
-????
-???
-?
-?
-?
-?
-?
-??
-???
-?
-???
-??
-??
-??
-?
-?
-???
-????
-?????
-??
-??
-??
-??
-???
-???
-????
-?????
-????
-??
-???
-???
-??
-??
-???
-???
-????
-????
-????
-????
-????
-????
-????
-????
-?????
-??????
-????
-????
-?????
-???
-???
-???
-??
-???
-???
-????
-???
-???
-???
-??
-???
-?
-?
-?
-?
-?
-?
-??
-?
-??
-????
-????
-???
-???
-???
-???
-???
-????
-????
-?????
-?
-?
-??
-?
-?
-?
-??
-??
-???
-??
-????
-?????
-????
-????
-????
-????
-????
-??????
-??????
-???????
-?????
-??
-?
-?
-??
-??
-??
-???
-???
-??
-?????
-?
-??
-?
-?
-???
-??
-??
-??
-??
-???
-???
-???
-????
-?
-??
-??
-??
-?
-?
-??
-?
-?
-?
-??
-???
-???
-???
-??????
-????
-??
-??
-??
-??
-??
-??
-??
-???
-??
-??
-???
-????
-???
-??
-??
-???
-??
-?
-??
-?
-??
-??
-???
-???
-??
-??
-??
-?
-?
-??
-?
-?
-??
-?
-??
-??
-??
-??
-??
-??
-??
-???
-???
-????
-???
-????
-??
-???
-??
-??
-??
-??
-???
-??
-??
-??
-??
-?????
-??????
-????
-???
-????
-???
-???
-???
-????
-??
-??
-??
-????
-?????
-????
-????
-????
-?????
-??????
-???
-???
-??
-???
-??
-??
-???
-??
-???
-??
-??
-??
-??
-??
-????
-?????
-????
-???
-???
-???
-???
-????
-???
-????
-????
-??
-????
-??
-???
-???
-????
-??
-??
-??
-??
-??
-???
-??
-??
-??
-??
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
index b12c862..f129f7e 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/sinks/TestTeeSinkTokenFilter.java
@@ -16,18 +16,17 @@ package org.apache.lucene.analysis.sinks;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CachingTokenFilter;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
+import java.io.IOException;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.*;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
 import org.apache.lucene.analysis.core.WhitespaceTokenizer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
@@ -37,8 +36,6 @@ import org.apache.lucene.index.TermVectorOffsetInfo;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.English;
-import java.io.IOException;
-import java.io.StringReader;
 
 
 /**
@@ -168,10 +165,10 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
         buffer.append(English.intToEnglish(i).toUpperCase()).append(' ');
       }
       //make sure we produce the same tokens
-      TeeSinkTokenFilter teeStream = new TeeSinkTokenFilter(new StandardFilter(new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))));
+      TeeSinkTokenFilter teeStream = new TeeSinkTokenFilter(new StandardFilter(TEST_VERSION_CURRENT, new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))));
       TokenStream sink = teeStream.newSinkTokenStream(new ModuloSinkFilter(100));
       teeStream.consumeAllTokens();
-      TokenStream stream = new ModuloTokenFilter(new StandardFilter(new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))), 100);
+      TokenStream stream = new ModuloTokenFilter(new StandardFilter(TEST_VERSION_CURRENT, new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))), 100);
       CharTermAttribute tfTok = stream.addAttribute(CharTermAttribute.class);
       CharTermAttribute sinkTok = sink.addAttribute(CharTermAttribute.class);
       for (int i=0; stream.incrementToken(); i++) {
@@ -184,12 +181,12 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
         int tfPos = 0;
         long start = System.currentTimeMillis();
         for (int i = 0; i < 20; i++) {
-          stream = new StandardFilter(new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString())));
+          stream = new StandardFilter(TEST_VERSION_CURRENT, new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString())));
           PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);
           while (stream.incrementToken()) {
             tfPos += posIncrAtt.getPositionIncrement();
           }
-          stream = new ModuloTokenFilter(new StandardFilter(new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))), modCounts[j]);
+          stream = new ModuloTokenFilter(new StandardFilter(TEST_VERSION_CURRENT, new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))), modCounts[j]);
           posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class);
           while (stream.incrementToken()) {
             tfPos += posIncrAtt.getPositionIncrement();
@@ -201,7 +198,7 @@ public class TestTeeSinkTokenFilter extends BaseTokenStreamTestCase {
         //simulate one field with one sink
         start = System.currentTimeMillis();
         for (int i = 0; i < 20; i++) {
-          teeStream = new TeeSinkTokenFilter(new StandardFilter(new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))));
+          teeStream = new TeeSinkTokenFilter(new StandardFilter(TEST_VERSION_CURRENT, new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(buffer.toString()))));
           sink = teeStream.newSinkTokenStream(new ModuloSinkFilter(modCounts[j]));
           PositionIncrementAttribute posIncrAtt = teeStream.getAttribute(PositionIncrementAttribute.class);
           while (teeStream.incrementToken()) {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
index e5771c3..6b5ae18 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/snowball/TestSnowball.java
@@ -71,7 +71,7 @@ public class TestSnowball extends BaseTokenStreamTestCase {
   
   /**
    * Test turkish lowercasing (old buggy behavior)
-   * @deprecated Remove this when support for 3.0 indexes is no longer required
+   * @deprecated (3.1) Remove this when support for 3.0 indexes is no longer required (5.0)
    */
   @Deprecated
   public void testTurkishBWComp() throws Exception {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilter.java
index 311e413..2c68e04 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilter.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/synonym/TestSynonymFilter.java
@@ -17,18 +17,6 @@
 
 package org.apache.lucene.analysis.synonym;
 
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Token;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
-
 import java.io.IOException;
 import java.io.StringReader;
 import java.util.ArrayList;
@@ -36,6 +24,13 @@ import java.util.Arrays;
 import java.util.Collection;
 import java.util.List;
 
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Token;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.WhitespaceTokenizer;
+import org.apache.lucene.analysis.tokenattributes.*;
+
 /**
  * @version $Id$
  */
@@ -332,7 +327,7 @@ public class TestSynonymFilter extends BaseTokenStreamTestCase {
    * a/b   => tokens a and b share the same spot (b.positionIncrement=0)
    * a,3/b/c => a,b,c all share same position (a.positionIncrement=3, b.positionIncrement=0, c.positionIncrement=0)
    * a,1,10,11  => "a" with positionIncrement=1, startOffset=10, endOffset=11
-   * @deprecated does not support attributes api
+   * @deprecated (3.0) does not support attributes api
    */
   @Deprecated
   private List<Token> tokens(String str) {
@@ -378,7 +373,7 @@ public class TestSynonymFilter extends BaseTokenStreamTestCase {
   }
   
   /**
-   * @deprecated does not support custom attributes
+   * @deprecated (3.0) does not support custom attributes
    */
   @Deprecated
   private static class IterTokenStream extends TokenStream {
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
index f9a95cf..af45f0d 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
@@ -52,7 +52,7 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
 
 	/**
 	 * Thai numeric tokens were typed as <ALPHANUM> instead of <NUM>.
-	 * @deprecated testing backwards behavior
+	 * @deprecated (3.1) testing backwards behavior
  	 */
 	@Deprecated
 	public void testBuggyTokenType30() throws Exception {
@@ -64,7 +64,7 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
                                         "<ALPHANUM>", "<ALPHANUM>", "<ALPHANUM>" });
 	}
 	
-	/** @deprecated testing backwards behavior */
+	/** @deprecated (3.1) testing backwards behavior */
 	@Deprecated
     public void testAnalyzer30() throws Exception {
 	  assumeTrue("JRE does not support Thai dictionary-based BreakIterator", ThaiWordFilter.DBBI_AVAILABLE);
@@ -126,7 +126,7 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
           new String[] { "??", "??", "xy", "z", "??", "??", "xyz@demo.com" });
 	}
 	
-	/** @deprecated, for version back compat */
+	/** @deprecated (3.1) for version back compat */
 	@Deprecated
 	public void testReusableTokenStream30() throws Exception {
 	    assumeTrue("JRE does not support Thai dictionary-based BreakIterator", ThaiWordFilter.DBBI_AVAILABLE);
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArraySet.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArraySet.java
index 643cda8..8983ead 100755
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArraySet.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/util/TestCharArraySet.java
@@ -17,15 +17,8 @@ package org.apache.lucene.analysis.util;
  * limitations under the License.
  */
 
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.Iterator;
+import java.util.*;
 
-import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.Version;
 
@@ -167,7 +160,7 @@ public class TestCharArraySet extends LuceneTestCase {
     }
     
     try{
-      set.addAll(Arrays.asList(new String[]{NOT_IN_SET}));  
+      set.addAll(Arrays.asList(NOT_IN_SET));
       fail("Modified unmodifiable set");
     }catch (UnsupportedOperationException e) {
       // expected
@@ -258,7 +251,7 @@ public class TestCharArraySet extends LuceneTestCase {
   }
   
   /**
-   * @deprecated remove this test when lucene 3.0 "broken unicode 4" support is
+   * @deprecated (3.1) remove this test when lucene 3.0 "broken unicode 4" support is
    *             no longer needed.
    */
   @Deprecated
@@ -290,7 +283,7 @@ public class TestCharArraySet extends LuceneTestCase {
   }
 
   /**
-   * @deprecated remove this test when lucene 3.0 "broken unicode 4" support is
+   * @deprecated (3.1) remove this test when lucene 3.0 "broken unicode 4" support is
    *             no longer needed.
    */
   @Deprecated
@@ -343,9 +336,8 @@ public class TestCharArraySet extends LuceneTestCase {
     setCaseSensitive.addAll(Arrays.asList(TEST_STOP_WORDS));
     setCaseSensitive.add(Integer.valueOf(1));
 
-    // This should use the deprecated methods, because it checks a bw compatibility.
-    CharArraySet copy = CharArraySet.copy(setIngoreCase);
-    CharArraySet copyCaseSens = CharArraySet.copy(setCaseSensitive);
+    CharArraySet copy = CharArraySet.copy(TEST_VERSION_CURRENT, setIngoreCase);
+    CharArraySet copyCaseSens = CharArraySet.copy(TEST_VERSION_CURRENT, setCaseSensitive);
 
     assertEquals(setIngoreCase.size(), copy.size());
     assertEquals(setCaseSensitive.size(), copy.size());
@@ -502,32 +494,6 @@ public class TestCharArraySet extends LuceneTestCase {
     } catch (NullPointerException e) {}
   }
   
-  @Deprecated @SuppressWarnings("unchecked")
-  public void testIterator() {
-    HashSet<String> hset = new HashSet<String>();
-    hset.addAll(Arrays.asList(TEST_STOP_WORDS));
-
-    assertTrue("in 3.0 version, iterator should be CharArraySetIterator",
-      ((Iterator) CharArraySet.copy(Version.LUCENE_30, hset).iterator()) instanceof CharArraySet.CharArraySetIterator);
-
-    CharArraySet set = CharArraySet.copy(TEST_VERSION_CURRENT, hset);
-    assertFalse("in current version, iterator should not be CharArraySetIterator",
-      ((Iterator) set.iterator()) instanceof CharArraySet.CharArraySetIterator);
-    
-    Iterator<String> it = set.stringIterator();
-    assertTrue(it instanceof CharArraySet.CharArraySetIterator);
-    while (it.hasNext()) {
-      // as the set returns String instances, this must work:
-      assertTrue(hset.contains(it.next()));
-      try {
-        it.remove();
-        fail("remove() should not work on CharArraySetIterator");
-      } catch (UnsupportedOperationException uoe) {
-        // pass
-      }
-    }
-  }
-  
   public void testToString() {
     CharArraySet set = CharArraySet.copy(TEST_VERSION_CURRENT, Collections.singleton("test"));
     assertEquals("[test]", set.toString());
diff --git a/solr/src/java/org/apache/solr/analysis/DutchStemFilterFactory.java b/solr/src/java/org/apache/solr/analysis/DutchStemFilterFactory.java
deleted file mode 100644
index 77b74c1..0000000
--- a/solr/src/java/org/apache/solr/analysis/DutchStemFilterFactory.java
+++ /dev/null
@@ -1,36 +0,0 @@
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.snowball.SnowballFilter;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * @deprecated Use {@link SnowballPorterFilterFactory} with "Dutch" instead,
- * which has the same functionality.
- */
-@Deprecated
-public class DutchStemFilterFactory extends BaseTokenFilterFactory {
-  public TokenFilter create(TokenStream _in) {
-    return new SnowballFilter(_in, new org.tartarus.snowball.ext.DutchStemmer());
-  }
-}
-
diff --git a/solr/src/java/org/apache/solr/analysis/FrenchStemFilterFactory.java b/solr/src/java/org/apache/solr/analysis/FrenchStemFilterFactory.java
deleted file mode 100644
index cef735f..0000000
--- a/solr/src/java/org/apache/solr/analysis/FrenchStemFilterFactory.java
+++ /dev/null
@@ -1,36 +0,0 @@
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.snowball.SnowballFilter;
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-
-/** 
- * @deprecated Use {@link SnowballPorterFilterFactory} with "French" instead,
- * which has the same functionality.
- */
-@Deprecated
-public class FrenchStemFilterFactory extends BaseTokenFilterFactory {
-  public TokenFilter create(TokenStream in) {
-    return new SnowballFilter(in, new org.tartarus.snowball.ext.FrenchStemmer());
-  }
-}
-
diff --git a/solr/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java b/solr/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java
index c9dd410..4e87773 100644
--- a/solr/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java
+++ b/solr/src/java/org/apache/solr/analysis/GreekLowerCaseFilterFactory.java
@@ -41,7 +41,7 @@ public class GreekLowerCaseFilterFactory extends BaseTokenFilterFactory
   }
 
   public GreekLowerCaseFilter create(TokenStream in) {
-    return new GreekLowerCaseFilter(in);
+    return new GreekLowerCaseFilter(luceneMatchVersion, in);
   }
 }
 
diff --git a/solr/src/java/org/apache/solr/analysis/ISOLatin1AccentFilterFactory.java b/solr/src/java/org/apache/solr/analysis/ISOLatin1AccentFilterFactory.java
deleted file mode 100644
index 3dd10302..0000000
--- a/solr/src/java/org/apache/solr/analysis/ISOLatin1AccentFilterFactory.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
- 
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.miscellaneous.ISOLatin1AccentFilter;
-import org.apache.lucene.analysis.TokenStream;
-
-/** Factory for ISOLatin1AccentFilter
- * @deprecated Use {@link ASCIIFoldingFilterFactory} instead.
- *  $Id$ 
- */
-@Deprecated
-public class ISOLatin1AccentFilterFactory extends BaseTokenFilterFactory {
-  public ISOLatin1AccentFilter create(TokenStream input) {
-    return new ISOLatin1AccentFilter(input);
-  }
-}
diff --git a/solr/src/java/org/apache/solr/analysis/RussianLowerCaseFilterFactory.java b/solr/src/java/org/apache/solr/analysis/RussianLowerCaseFilterFactory.java
deleted file mode 100644
index de6cda7..0000000
--- a/solr/src/java/org/apache/solr/analysis/RussianLowerCaseFilterFactory.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.analysis;
-
-import java.util.Map;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.util.Version;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-
-/** @deprecated Use {@link LowerCaseFilterFactory} instead which has the
- *  same functionality.
- */
-@Deprecated
-public class RussianLowerCaseFilterFactory extends BaseTokenFilterFactory {
-
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    if (args.containsKey("charset"))
-      throw new SolrException(ErrorCode.SERVER_ERROR,
-          "The charset parameter is no longer supported.  "
-          + "Please process your documents as Unicode instead.");
-  }
-
-  public TokenFilter create(TokenStream in) {
-    // hardcode the version to give exactly the old behavior
-    return new LowerCaseFilter(Version.LUCENE_29, in);
-  }
-}
-
diff --git a/solr/src/java/org/apache/solr/analysis/RussianStemFilterFactory.java b/solr/src/java/org/apache/solr/analysis/RussianStemFilterFactory.java
deleted file mode 100644
index be84233..0000000
--- a/solr/src/java/org/apache/solr/analysis/RussianStemFilterFactory.java
+++ /dev/null
@@ -1,37 +0,0 @@
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.solr.analysis;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.snowball.SnowballFilter;
-
-/**
- * @deprecated Use {@link SnowballPorterFilterFactory} with "Russian" instead,
- * which has the same functionality.
- */
-@Deprecated
-public class RussianStemFilterFactory extends BaseTokenFilterFactory {
-
-  public TokenFilter create(TokenStream in) {
-    return new SnowballFilter(in, new org.tartarus.snowball.ext.RussianStemmer());
-  }
-}
-
diff --git a/solr/src/java/org/apache/solr/core/SolrConfig.java b/solr/src/java/org/apache/solr/core/SolrConfig.java
index 07f75a8..0d5e974 100644
--- a/solr/src/java/org/apache/solr/core/SolrConfig.java
+++ b/solr/src/java/org/apache/solr/core/SolrConfig.java
@@ -138,7 +138,7 @@ public class SolrConfig extends Config {
     reopenReaders = getBool("mainIndex/reopenReaders", true);
     
     booleanQueryMaxClauseCount = getInt("query/maxBooleanClauses", BooleanQuery.getMaxClauseCount());
-    luceneMatchVersion = getLuceneVersion("luceneMatchVersion", Version.LUCENE_24);
+    luceneMatchVersion = getLuceneVersion("luceneMatchVersion", Version.LUCENE_30);
     log.info("Using Lucene MatchVersion: " + luceneMatchVersion);
 
     filtOptEnabled = getBool("query/boolTofilterOptimizer/@enabled", false);
diff --git a/solr/src/java/org/apache/solr/core/SolrDeletionPolicy.java b/solr/src/java/org/apache/solr/core/SolrDeletionPolicy.java
index 7e375d7..e165484 100644
--- a/solr/src/java/org/apache/solr/core/SolrDeletionPolicy.java
+++ b/solr/src/java/org/apache/solr/core/SolrDeletionPolicy.java
@@ -81,7 +81,7 @@ public class SolrDeletionPolicy implements IndexDeletionPolicy, NamedListInitial
 
       if (dir instanceof FSDirectory) {
         FSDirectory fsd = (FSDirectory) dir;
-        sb.append("dir=").append(fsd.getFile());
+        sb.append("dir=").append(fsd.getDirectory());
       } else {
         sb.append("dir=").append(dir);
       }
@@ -183,7 +183,7 @@ public class SolrDeletionPolicy implements IndexDeletionPolicy, NamedListInitial
     // be the same, regardless of the Directory instance.
     if (dir instanceof FSDirectory) {
       FSDirectory fsd = (FSDirectory) dir;
-      File fdir = fsd.getFile();
+      File fdir = fsd.getDirectory();
       sb.append(fdir.getPath());
     } else {
       sb.append(dir);
diff --git a/solr/src/java/org/apache/solr/handler/component/SpellCheckComponent.java b/solr/src/java/org/apache/solr/handler/component/SpellCheckComponent.java
index 36019c2..669cd93 100644
--- a/solr/src/java/org/apache/solr/handler/component/SpellCheckComponent.java
+++ b/solr/src/java/org/apache/solr/handler/component/SpellCheckComponent.java
@@ -640,7 +640,7 @@ public class SpellCheckComponent extends SearchComponent implements SolrCoreAwar
         IndexSchema schema = core.getSchema();
         String fieldTypeName = (String) initParams.get("queryAnalyzerFieldType");
         FieldType fieldType = schema.getFieldTypes().get(fieldTypeName);
-        Analyzer analyzer = fieldType == null ? new WhitespaceAnalyzer()
+        Analyzer analyzer = fieldType == null ? new WhitespaceAnalyzer(core.getSolrConfig().luceneMatchVersion)
                 : fieldType.getQueryAnalyzer();
         //TODO: There's got to be a better way!  Where's Spring when you need it?
         queryConverter.setAnalyzer(analyzer);
diff --git a/solr/src/java/org/apache/solr/schema/BinaryField.java b/solr/src/java/org/apache/solr/schema/BinaryField.java
index aa87230..5cc4cc1 100644
--- a/solr/src/java/org/apache/solr/schema/BinaryField.java
+++ b/solr/src/java/org/apache/solr/schema/BinaryField.java
@@ -79,8 +79,7 @@ public class BinaryField extends FieldType  {
       len = buf.length;
     }
 
-    Field f = new Field(field.getName(), buf, offset, len,
-            getFieldStore(field, null));
+    Field f = new Field(field.getName(), buf, offset, len);
     f.setBoost(boost);
     return f;
   }
diff --git a/solr/src/java/org/apache/solr/schema/TrieDateField.java b/solr/src/java/org/apache/solr/schema/TrieDateField.java
index 24dcdc7..4f48c98 100755
--- a/solr/src/java/org/apache/solr/schema/TrieDateField.java
+++ b/solr/src/java/org/apache/solr/schema/TrieDateField.java
@@ -193,7 +193,7 @@ public class TrieDateField extends DateField {
 
     Field f;
     if (stored) {
-      f = new Field(field.getName(), arr, Field.Store.YES);
+      f = new Field(field.getName(), arr);
       if (indexed) f.setTokenStream(ts);
     } else {
       f = new Field(field.getName(), ts);
diff --git a/solr/src/java/org/apache/solr/schema/TrieField.java b/solr/src/java/org/apache/solr/schema/TrieField.java
index 4d88e70..3e7f4c1 100644
--- a/solr/src/java/org/apache/solr/schema/TrieField.java
+++ b/solr/src/java/org/apache/solr/schema/TrieField.java
@@ -552,7 +552,7 @@ public class TrieField extends FieldType {
 
     Field f;
     if (stored) {
-      f = new Field(field.getName(), arr, Field.Store.YES);
+      f = new Field(field.getName(), arr);
       if (indexed) f.setTokenStream(ts);
     } else {
       f = new Field(field.getName(), ts);
diff --git a/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java b/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java
index 88f5e40..0b2c79e 100644
--- a/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java
+++ b/solr/src/java/org/apache/solr/search/SolrIndexSearcher.java
@@ -149,7 +149,7 @@ public class SolrIndexSearcher extends IndexSearcher implements SolrInfoMBean {
 
     if (r.directory() instanceof FSDirectory) {
       FSDirectory fsDirectory = (FSDirectory) r.directory();
-      indexDir = fsDirectory.getFile().getAbsolutePath();
+      indexDir = fsDirectory.getDirectory().getAbsolutePath();
     }
 
     this.closeReader = closeReader;
diff --git a/solr/src/java/org/apache/solr/search/SolrQueryParser.java b/solr/src/java/org/apache/solr/search/SolrQueryParser.java
index a88a9f4..63097fb 100644
--- a/solr/src/java/org/apache/solr/search/SolrQueryParser.java
+++ b/solr/src/java/org/apache/solr/search/SolrQueryParser.java
@@ -78,7 +78,7 @@ public class SolrQueryParser extends QueryParser {
    * @see IndexSchema#getDefaultSearchFieldName()
    */
   public SolrQueryParser(IndexSchema schema, String defaultField) {
-    super(schema.getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_24), defaultField == null ? schema.getDefaultSearchFieldName() : defaultField, schema.getQueryAnalyzer());
+    super(schema.getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_30), defaultField == null ? schema.getDefaultSearchFieldName() : defaultField, schema.getQueryAnalyzer());
     this.schema = schema;
     this.parser  = null;
     this.defaultField = defaultField;
@@ -92,7 +92,7 @@ public class SolrQueryParser extends QueryParser {
   }
 
   public SolrQueryParser(QParser parser, String defaultField, Analyzer analyzer) {
-    super(parser.getReq().getSchema().getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_24), defaultField, analyzer);
+    super(parser.getReq().getSchema().getSolrConfig().getLuceneVersion("luceneMatchVersion", Version.LUCENE_30), defaultField, analyzer);
     this.schema = parser.getReq().getSchema();
     this.parser = parser;
     this.defaultField = defaultField;
diff --git a/solr/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java b/solr/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java
index 306a466..1dcfcb2 100644
--- a/solr/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java
+++ b/solr/src/java/org/apache/solr/spelling/AbstractLuceneSpellChecker.java
@@ -149,7 +149,7 @@ public abstract class AbstractLuceneSpellChecker extends SolrSpellChecker {
     }
     if (analyzer == null)   {
       log.info("Using WhitespaceAnalzyer for dictionary: " + name);
-      analyzer = new WhitespaceAnalyzer();
+      analyzer = new WhitespaceAnalyzer(core.getSolrConfig().luceneMatchVersion);
     }
     return name;
   }
diff --git a/solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker.java b/solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker.java
index 8ea3e26..c2d53c7 100644
--- a/solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker.java
+++ b/solr/src/java/org/apache/solr/spelling/FileBasedSpellChecker.java
@@ -19,20 +19,18 @@ package org.apache.solr.spelling;
 import java.io.IOException;
 import java.io.InputStreamReader;
 import java.util.List;
+
+import org.apache.lucene.index.*;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.search.spell.PlainTextDictionary;
 import org.apache.lucene.store.RAMDirectory;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrCore;
-import org.apache.solr.core.SolrResourceLoader;
 import org.apache.solr.schema.FieldType;
-import org.apache.solr.schema.IndexSchema;
 import org.apache.solr.util.HighFrequencyDictionary;
 import org.apache.solr.search.SolrIndexSearcher;
 
@@ -60,7 +58,7 @@ public class FileBasedSpellChecker extends AbstractLuceneSpellChecker {
 
   public void build(SolrCore core, SolrIndexSearcher searcher) {
     try {
-      loadExternalFileDictionary(core.getSchema(), core.getResourceLoader());
+      loadExternalFileDictionary(core);
       spellChecker.clearIndex();
       spellChecker.indexDictionary(dictionary);
     } catch (IOException e) {
@@ -77,22 +75,28 @@ public class FileBasedSpellChecker extends AbstractLuceneSpellChecker {
   }
 
   @SuppressWarnings("unchecked")
-  private void loadExternalFileDictionary(IndexSchema schema, SolrResourceLoader loader) {
+  private void loadExternalFileDictionary(SolrCore core) {
     try {
 
       // Get the field's analyzer
-      if (fieldTypeName != null
-              && schema.getFieldTypeNoEx(fieldTypeName) != null) {
-        FieldType fieldType = schema.getFieldTypes()
-                .get(fieldTypeName);
+      if (fieldTypeName != null && core.getSchema().getFieldTypeNoEx(fieldTypeName) != null) {
+        FieldType fieldType = core.getSchema().getFieldTypes().get(fieldTypeName);
         // Do index-time analysis using the given fieldType's analyzer
         RAMDirectory ramDir = new RAMDirectory();
-        IndexWriter writer = new IndexWriter(ramDir, fieldType.getAnalyzer(),
-                true, IndexWriter.MaxFieldLength.UNLIMITED);
-        writer.setMergeFactor(300);
-        writer.setMaxBufferedDocs(150);
 
-        List<String> lines = loader.getLines(sourceLocation, characterEncoding);
+        LogMergePolicy mp = new LogByteSizeMergePolicy();
+        mp.setMergeFactor(300);
+
+        IndexWriter writer = new IndexWriter(
+            ramDir,
+            new IndexWriterConfig(core.getSolrConfig().luceneMatchVersion, fieldType.getAnalyzer()).
+                setMaxBufferedDocs(150).
+                setMergePolicy(mp).
+                setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH).
+                setOpenMode(IndexWriterConfig.OpenMode.CREATE)
+        );
+
+        List<String> lines = core.getResourceLoader().getLines(sourceLocation, characterEncoding);
 
         for (String s : lines) {
           Document d = new Document();
@@ -107,9 +111,9 @@ public class FileBasedSpellChecker extends AbstractLuceneSpellChecker {
       } else {
         // check if character encoding is defined
         if (characterEncoding == null) {
-          dictionary = new PlainTextDictionary(loader.openResource(sourceLocation));
+          dictionary = new PlainTextDictionary(core.getResourceLoader().openResource(sourceLocation));
         } else {
-          dictionary = new PlainTextDictionary(new InputStreamReader(loader.openResource(sourceLocation), characterEncoding));
+          dictionary = new PlainTextDictionary(new InputStreamReader(core.getResourceLoader().openResource(sourceLocation), characterEncoding));
         }
       }
 
diff --git a/solr/src/java/org/apache/solr/update/SolrIndexConfig.java b/solr/src/java/org/apache/solr/update/SolrIndexConfig.java
index e6a6cb5..85d0f74 100644
--- a/solr/src/java/org/apache/solr/update/SolrIndexConfig.java
+++ b/solr/src/java/org/apache/solr/update/SolrIndexConfig.java
@@ -17,11 +17,12 @@
 
 package org.apache.solr.update;
 
+import org.apache.lucene.index.*;
+import org.apache.lucene.util.Version;
 import org.apache.solr.core.SolrConfig;
 import org.apache.solr.core.PluginInfo;
-import org.apache.lucene.index.LogByteSizeMergePolicy;
-import org.apache.lucene.index.ConcurrentMergeScheduler;
-import org.apache.lucene.index.IndexWriter;
+import org.apache.solr.schema.IndexSchema;
+import org.apache.solr.util.SolrPluginUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -45,8 +46,8 @@ public class SolrIndexConfig {
   public static final String DEFAULT_MERGE_SCHEDULER_CLASSNAME = ConcurrentMergeScheduler.class.getName();
   static final SolrIndexConfig defaultDefaults = new SolrIndexConfig();
 
-
   private SolrIndexConfig() {
+    luceneVersion = Version.LUCENE_40;
     useCompoundFile = true;
     maxBufferedDocs = -1;
     maxMergeDocs = -1;
@@ -56,10 +57,12 @@ public class SolrIndexConfig {
     writeLockTimeout = -1;
     commitLockTimeout = -1;
     lockType = null;
-    termIndexInterval = IndexWriter.DEFAULT_TERM_INDEX_INTERVAL;
+    termIndexInterval = IndexWriterConfig.DEFAULT_TERM_INDEX_INTERVAL;
     mergePolicyInfo = null;
     mergeSchedulerInfo = null;
   }
+
+  public final Version luceneVersion;
   
   public final boolean useCompoundFile;
   public final int maxBufferedDocs;
@@ -83,6 +86,9 @@ public class SolrIndexConfig {
       prefix = defaultsName;
     if (def == null)
       def = defaultDefaults;
+
+    luceneVersion = solrConfig.luceneMatchVersion;
+
     useCompoundFile=solrConfig.getBool(prefix+"/useCompoundFile", def.useCompoundFile);
     maxBufferedDocs=solrConfig.getInt(prefix+"/maxBufferedDocs",def.maxBufferedDocs);
     maxMergeDocs=solrConfig.getInt(prefix+"/maxMergeDocs",def.maxMergeDocs);
@@ -129,11 +135,74 @@ public class SolrIndexConfig {
       infoStreamFile= solrConfig.get(prefix + "/infoStream/@file", null);
       log.info("IndexWriter infoStream debug log is enabled: " + infoStreamFile);
     }
-
   }
 
   private PluginInfo getPluginInfo(String path, SolrConfig solrConfig, PluginInfo def)  {
     List<PluginInfo> l = solrConfig.readPluginInfos(path, false, true);
     return l.isEmpty() ? def : l.get(0);
   }
+
+  public IndexWriterConfig toIndexWriterConfig(IndexSchema schema) {
+    IndexWriterConfig iwc = new IndexWriterConfig(luceneVersion, schema.getAnalyzer());
+    if (maxBufferedDocs != -1)
+      iwc.setMaxBufferedDocs(maxBufferedDocs);
+
+    if (ramBufferSizeMB != -1)
+      iwc.setRAMBufferSizeMB(ramBufferSizeMB);
+
+    if (termIndexInterval != -1)
+      iwc.setTermIndexInterval(termIndexInterval);
+
+    if (maxFieldLength != -1)
+      iwc.setMaxFieldLength(maxFieldLength);
+
+    if (writeLockTimeout != -1)
+      iwc.setWriteLockTimeout(writeLockTimeout);
+
+    iwc.setSimilarity(schema.getSimilarity());
+    iwc.setMergePolicy(buildMergePolicy(schema));
+    iwc.setMergeScheduler(buildMergeScheduler(schema));
+
+    return iwc;
+  }
+
+  private MergePolicy buildMergePolicy(IndexSchema schema) {
+    MergePolicy policy;
+    String mpClassName = mergePolicyInfo == null ? SolrIndexConfig.DEFAULT_MERGE_POLICY_CLASSNAME : mergePolicyInfo.className;
+
+    try {
+      policy = (MergePolicy) schema.getResourceLoader().newInstance(mpClassName, null, new Class[]{IndexWriter.class}, new Object[]{this});
+    } catch (Exception e) {
+      policy = (MergePolicy) schema.getResourceLoader().newInstance(mpClassName);
+    }
+
+    if (mergePolicyInfo != null)
+      SolrPluginUtils.invokeSetters(policy, mergePolicyInfo.initArgs);
+
+    if (policy instanceof LogMergePolicy) {
+      LogMergePolicy logMergePolicy = (LogMergePolicy) policy;
+
+      if (maxMergeDocs != -1)
+        logMergePolicy.setMaxMergeDocs(maxMergeDocs);
+
+      logMergePolicy.setUseCompoundFile(useCompoundFile);
+
+      if (mergeFactor != -1)
+        logMergePolicy.setMergeFactor(mergeFactor);
+    } else {
+      log.warn("Use of compound file format or mergefactor cannot be configured if merge policy is not an instance of LogMergePolicy. The configured policy's defaults will be used.");
+    }
+
+    return policy;
+  }
+
+  private MergeScheduler buildMergeScheduler(IndexSchema schema) {
+    String msClassName = mergeSchedulerInfo == null ? SolrIndexConfig.DEFAULT_MERGE_SCHEDULER_CLASSNAME : mergeSchedulerInfo.className;
+    MergeScheduler scheduler = (MergeScheduler) schema.getResourceLoader().newInstance(msClassName);
+
+    if (mergeSchedulerInfo != null)
+      SolrPluginUtils.invokeSetters(scheduler, mergeSchedulerInfo.initArgs);
+
+    return scheduler;
+  }
 }
diff --git a/solr/src/java/org/apache/solr/update/SolrIndexWriter.java b/solr/src/java/org/apache/solr/update/SolrIndexWriter.java
index 1457a18..6073a6a 100644
--- a/solr/src/java/org/apache/solr/update/SolrIndexWriter.java
+++ b/solr/src/java/org/apache/solr/update/SolrIndexWriter.java
@@ -20,11 +20,8 @@ package org.apache.solr.update;
 import org.apache.lucene.index.*;
 import org.apache.lucene.store.*;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.DirectoryFactory;
-import org.apache.solr.core.StandardDirectoryFactory;
 import org.apache.solr.schema.IndexSchema;
-import org.apache.solr.util.SolrPluginUtils;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -45,73 +42,12 @@ import java.util.Locale;
 * @since solr 0.9
 */
 
-
 public class SolrIndexWriter extends IndexWriter {
   private static Logger log = LoggerFactory.getLogger(SolrIndexWriter.class);
 
   String name;
-  IndexSchema schema;
-
   private PrintStream infoStream;
 
-  private void init(String name, IndexSchema schema, SolrIndexConfig config) throws IOException {
-    log.debug("Opened Writer " + name);
-    this.name = name;
-    this.schema = schema;
-    setSimilarity(schema.getSimilarity());
-    // setUseCompoundFile(false);
-
-    if (config != null) {
-      //only set maxBufferedDocs
-      if (config.maxBufferedDocs != -1) {
-        setMaxBufferedDocs(config.maxBufferedDocs);
-      }
-      if (config.ramBufferSizeMB != -1) {
-        setRAMBufferSizeMB(config.ramBufferSizeMB);
-      }
-      if (config.termIndexInterval != -1) {
-        setTermIndexInterval(config.termIndexInterval);
-        
-      }
-      if (config.maxMergeDocs != -1) setMaxMergeDocs(config.maxMergeDocs);
-      if (config.maxFieldLength != -1) setMaxFieldLength(config.maxFieldLength);
-      String className = config.mergePolicyInfo == null ? SolrIndexConfig.DEFAULT_MERGE_POLICY_CLASSNAME: config.mergePolicyInfo.className;
-      MergePolicy  policy = null;
-      try {
-        policy = (MergePolicy) schema.getResourceLoader().newInstance(className, null, new Class[]{IndexWriter.class}, new Object[] { this });
-      } catch (Exception e) {
-        policy = (MergePolicy) schema.getResourceLoader().newInstance(className);
-      }
-      if(config.mergePolicyInfo != null) SolrPluginUtils.invokeSetters(policy,config.mergePolicyInfo.initArgs);
-      setMergePolicy(policy);
-
-      if (getMergePolicy() instanceof LogMergePolicy) {
-        setUseCompoundFile(config.useCompoundFile);
-        if (config.mergeFactor != -1) { setMergeFactor(config.mergeFactor); }
-      } else  {
-        log.warn("Use of compound file format or mergefactor cannot be configured if merge policy is not an instance " +
-                "of LogMergePolicy. The configured policy's defaults will be used.");
-      }
-
-      className = config.mergeSchedulerInfo == null ? SolrIndexConfig.DEFAULT_MERGE_SCHEDULER_CLASSNAME: config.mergeSchedulerInfo.className;
-      MergeScheduler scheduler = (MergeScheduler) schema.getResourceLoader().newInstance(className);
-      if(config.mergeSchedulerInfo != null) SolrPluginUtils.invokeSetters(scheduler,config.mergeSchedulerInfo.initArgs);
-      setMergeScheduler(scheduler);
-
-      String infoStreamFile = config.infoStreamFile;
-      if (infoStreamFile != null) {
-        File f = new File(infoStreamFile);
-        File parent = f.getParentFile();
-        if (parent != null) parent.mkdirs();
-        FileOutputStream fos = new FileOutputStream(f, true);
-        infoStream = new TimeLoggingPrintStream(fos, true);
-        setInfoStream(infoStream);
-      }
-      //if (config.commitLockTimeout != -1) setWriteLockTimeout(config.commitLockTimeout);
-    }
-
-  }
-
   public static Directory getDirectory(String path, DirectoryFactory directoryFactory, SolrIndexConfig config) throws IOException {
     
     Directory d = directoryFactory.open(path);
@@ -135,7 +71,7 @@ public class SolrIndexWriter extends IndexWriter {
     } else if ("none".equals(lockType)) {
       // Recipe for disaster
       log.error("CONFIGURATION WARNING: locks are disabled on " + path);      
-      d.setLockFactory(new NoLockFactory());
+      d.setLockFactory(NoLockFactory.getNoLockFactory());
     } else {
       throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,
               "Unrecognized lockType: " + rawLockType);
@@ -143,58 +79,25 @@ public class SolrIndexWriter extends IndexWriter {
     return d;
   }
   
-  /** @deprecated remove when getDirectory(String,SolrIndexConfig) is gone */
-  @Deprecated
-  private static DirectoryFactory LEGACY_DIR_FACTORY 
-    = new StandardDirectoryFactory();
-  static {
-    LEGACY_DIR_FACTORY.init(new NamedList());
-  }
-
-  /**
-   * @deprecated use getDirectory(String path, DirectoryFactory directoryFactory, SolrIndexConfig config)
-   */
-  @Deprecated
-  public static Directory getDirectory(String path, SolrIndexConfig config) throws IOException {
-    log.warn("SolrIndexWriter is using LEGACY_DIR_FACTORY which means deprecated code is likely in use and SolrIndexWriter is ignoring any custom DirectoryFactory.");
-    return getDirectory(path, LEGACY_DIR_FACTORY, config);
-  }
-  
-  /**
-   *
-   */
-  public SolrIndexWriter(String name, String path, DirectoryFactory dirFactory, boolean create, IndexSchema schema) throws IOException {
-    super(getDirectory(path, dirFactory, null), schema.getAnalyzer(), create, MaxFieldLength.LIMITED);
-    init(name, schema, null);
-  }
-
-  @Deprecated
-  public SolrIndexWriter(String name, String path, DirectoryFactory dirFactory, boolean create, IndexSchema schema, SolrIndexConfig config) throws IOException {
-    super(getDirectory(path, dirFactory, null), schema.getAnalyzer(), create, MaxFieldLength.LIMITED);
-    init(name, schema, config);
-  }
-  
-  /**
-   * @deprecated
-   */
-  @Deprecated
-  public SolrIndexWriter(String name, String path, boolean create, IndexSchema schema) throws IOException {
-    super(getDirectory(path, null), schema.getAnalyzer(), create, MaxFieldLength.LIMITED);
-    init(name, schema, null);
-  }
-
-  /**
-   * @deprecated
-   */
-  @Deprecated
-  public SolrIndexWriter(String name, String path, boolean create, IndexSchema schema, SolrIndexConfig config) throws IOException {
-    super(getDirectory(path, config), schema.getAnalyzer(), create, MaxFieldLength.LIMITED);
-    init(name, schema, config);
-  }
-
   public SolrIndexWriter(String name, String path, DirectoryFactory dirFactory, boolean create, IndexSchema schema, SolrIndexConfig config, IndexDeletionPolicy delPolicy) throws IOException {
-    super(getDirectory(path, dirFactory, config), schema.getAnalyzer(), create, delPolicy, new MaxFieldLength(IndexWriter.DEFAULT_MAX_FIELD_LENGTH));
-    init(name, schema, config);
+    super(
+        getDirectory(path, dirFactory, config),
+        config.toIndexWriterConfig(schema).
+            setOpenMode(create ? IndexWriterConfig.OpenMode.CREATE : IndexWriterConfig.OpenMode.APPEND).
+            setIndexDeletionPolicy(delPolicy)
+    );
+    log.debug("Opened Writer " + name);
+    this.name = name;
+
+    String infoStreamFile = config.infoStreamFile;
+    if (infoStreamFile != null) {
+      File f = new File(infoStreamFile);
+      File parent = f.getParentFile();
+      if (parent != null) parent.mkdirs();
+      FileOutputStream fos = new FileOutputStream(f, true);
+      infoStream = new TimeLoggingPrintStream(fos, true);
+      setInfoStream(infoStream);
+    }
   }
 
 
@@ -280,5 +183,4 @@ public class SolrIndexWriter extends IndexWriter {
       super.println(x);
     }
   }
-
 }
diff --git a/solr/src/test/org/apache/solr/BasicFunctionalityTest.java b/solr/src/test/org/apache/solr/BasicFunctionalityTest.java
index ab5b758..1e76575 100644
--- a/solr/src/test/org/apache/solr/BasicFunctionalityTest.java
+++ b/solr/src/test/org/apache/solr/BasicFunctionalityTest.java
@@ -31,6 +31,7 @@ import javax.xml.parsers.DocumentBuilder;
 import javax.xml.parsers.DocumentBuilderFactory;
 
 import org.apache.lucene.document.Field;
+import org.apache.lucene.index.LogMergePolicy;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
 import org.apache.solr.common.params.AppendedSolrParams;
@@ -121,7 +122,7 @@ public class BasicFunctionalityTest extends SolrTestCaseJ4 {
     SolrCore core = h.getCore();
 
     SolrIndexWriter writer = new SolrIndexWriter("testWriter",core.getNewIndexDir(), core.getDirectoryFactory(), false, core.getSchema(), core.getSolrConfig().mainIndexConfig, core.getDeletionPolicy());
-    assertEquals("Mergefactor was not picked up", writer.getMergeFactor(), 8);
+    assertEquals("Mergefactor was not picked up", ((LogMergePolicy) writer.getConfig().getMergePolicy()).getMergeFactor(), 8);
     writer.close();
 
     lrf.args.put("version","2.0");
diff --git a/solr/src/test/org/apache/solr/analysis/TestDutchStemFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestDutchStemFilterFactory.java
deleted file mode 100644
index 6e3be4d..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestDutchStemFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-
-/**
- * Simple tests to ensure the Dutch stem filter factory is working.
- */
-public class TestDutchStemFilterFactory extends BaseTokenTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("lichamelijkheden");
-    Tokenizer tokenizer = new WhitespaceTokenizer(DEFAULT_VERSION, reader);
-    DutchStemFilterFactory factory = new DutchStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "licham" });
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestFrenchStemFilterFactory.java b/solr/src/test/org/apache/solr/analysis/TestFrenchStemFilterFactory.java
deleted file mode 100644
index d950df1..0000000
--- a/solr/src/test/org/apache/solr/analysis/TestFrenchStemFilterFactory.java
+++ /dev/null
@@ -1,41 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.WhitespaceTokenizer;
-
-/**
- * Simple tests to ensure the French stem filter factory is working.
- */
-public class TestFrenchStemFilterFactory extends BaseTokenTestCase {
-  /**
-   * Ensure the filter actually stems text.
-   */
-  public void testStemming() throws Exception {
-    Reader reader = new StringReader("habitable");
-    Tokenizer tokenizer = new WhitespaceTokenizer(DEFAULT_VERSION, reader);
-    FrenchStemFilterFactory factory = new FrenchStemFilterFactory();
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "habit" });
-  }
-}
diff --git a/solr/src/test/org/apache/solr/analysis/TestLuceneMatchVersion.java b/solr/src/test/org/apache/solr/analysis/TestLuceneMatchVersion.java
index 493997c..89a8b9d 100644
--- a/solr/src/test/org/apache/solr/analysis/TestLuceneMatchVersion.java
+++ b/solr/src/test/org/apache/solr/analysis/TestLuceneMatchVersion.java
@@ -16,15 +16,12 @@
  */
 package org.apache.solr.analysis;
 
-import java.io.StringReader;
 import java.lang.reflect.Field;
 
-import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.core.Config;
 import org.apache.solr.schema.IndexSchema;
 import org.apache.solr.schema.FieldType;
-import org.apache.solr.util.AbstractSolrTestCase;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.util.Version;
@@ -53,17 +50,11 @@ public class TestLuceneMatchVersion extends SolrTestCaseJ4 {
     TokenizerChain ana = (TokenizerChain) type.getAnalyzer();
     assertEquals(DEFAULT_VERSION, ((BaseTokenizerFactory) ana.getTokenizerFactory()).luceneMatchVersion);
     assertEquals(DEFAULT_VERSION, ((BaseTokenFilterFactory) ana.getTokenFilterFactories()[2]).luceneMatchVersion);
-    TokenizerChain.TokenStreamInfo tsi = ana.getStream("textDefault",new StringReader(""));
-    StandardTokenizer tok = (StandardTokenizer) tsi.getTokenizer();
-    assertTrue(tok.isReplaceInvalidAcronym());
-    
-    type = schema.getFieldType("text20");
+
+    type = schema.getFieldType("text30");
     ana = (TokenizerChain) type.getAnalyzer();
-    assertEquals(Version.LUCENE_20, ((BaseTokenizerFactory) ana.getTokenizerFactory()).luceneMatchVersion);
-    assertEquals(Version.LUCENE_24, ((BaseTokenFilterFactory) ana.getTokenFilterFactories()[2]).luceneMatchVersion);
-    tsi = ana.getStream("text20",new StringReader(""));
-    tok = (StandardTokenizer) tsi.getTokenizer();
-    assertFalse(tok.isReplaceInvalidAcronym());
+    assertEquals(Version.LUCENE_30, ((BaseTokenizerFactory) ana.getTokenizerFactory()).luceneMatchVersion);
+    assertEquals(Version.LUCENE_31, ((BaseTokenFilterFactory) ana.getTokenFilterFactories()[2]).luceneMatchVersion);
 
     // this is a hack to get the private matchVersion field in StandardAnalyzer's superclass, may break in later lucene versions - we have no getter :(
     final Field matchVersionField = StandardAnalyzer.class.getSuperclass().getDeclaredField("matchVersion");
@@ -74,9 +65,9 @@ public class TestLuceneMatchVersion extends SolrTestCaseJ4 {
     assertTrue(ana1 instanceof StandardAnalyzer);
     assertEquals(DEFAULT_VERSION, matchVersionField.get(ana1));
 
-    type = schema.getFieldType("textStandardAnalyzer20");
+    type = schema.getFieldType("textStandardAnalyzer30");
     ana1 = type.getAnalyzer();
     assertTrue(ana1 instanceof StandardAnalyzer);
-    assertEquals(Version.LUCENE_20, matchVersionField.get(ana1));
+    assertEquals(Version.LUCENE_30, matchVersionField.get(ana1));
   }
 }
diff --git a/solr/src/test/org/apache/solr/analysis/TestRussianFilters.java b/solr/src/test/org/apache/solr/analysis/TestRussianFilters.java
index 973900d..c2e6a6a 100644
--- a/solr/src/test/org/apache/solr/analysis/TestRussianFilters.java
+++ b/solr/src/test/org/apache/solr/analysis/TestRussianFilters.java
@@ -38,37 +38,4 @@ public class TestRussianFilters extends BaseTokenTestCase {
     assertTokenStreamContents(stream, new String[] {"???", "?", "?", "",
         "?", "????", "100"});
   }
-  
-  /**
-   * Test RussianLowerCaseFilterFactory
-   */
-  public void testLowerCase() throws Exception {
-    Reader reader = new StringReader("??? ? ?  ? ???? 100");
-    RussianLetterTokenizerFactory factory = new RussianLetterTokenizerFactory();
-    factory.init(DEFAULT_VERSION_PARAM);
-    RussianLowerCaseFilterFactory filterFactory = new RussianLowerCaseFilterFactory();
-    filterFactory.init(DEFAULT_VERSION_PARAM);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = filterFactory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] {"??", "?", "?", "",
-        "?", "????", "100"});
-  }
-  
-  /**
-   * Test RussianStemFilterFactory
-   */
-  public void testStemmer() throws Exception {
-    Reader reader = new StringReader("??? ? ?  ? ???? 100");
-    RussianLetterTokenizerFactory factory = new RussianLetterTokenizerFactory();
-    factory.init(DEFAULT_VERSION_PARAM);
-    RussianLowerCaseFilterFactory caseFactory = new RussianLowerCaseFilterFactory();
-    caseFactory.init(DEFAULT_VERSION_PARAM);
-    RussianStemFilterFactory stemFactory = new RussianStemFilterFactory();
-    stemFactory.init(DEFAULT_VERSION_PARAM);
-    Tokenizer tokenizer = factory.create(reader);
-    TokenStream stream = caseFactory.create(tokenizer);
-    stream = stemFactory.create(stream);
-    assertTokenStreamContents(stream, new String[] {"??", "?", "?", "",
-        "?", "????", "100"});
-  }
 }
diff --git a/solr/src/test/org/apache/solr/analysis/TestStandardFactories.java b/solr/src/test/org/apache/solr/analysis/TestStandardFactories.java
index 4d4563a..ef2bd99 100644
--- a/solr/src/test/org/apache/solr/analysis/TestStandardFactories.java
+++ b/solr/src/test/org/apache/solr/analysis/TestStandardFactories.java
@@ -126,17 +126,4 @@ public class TestStandardFactories extends BaseTokenTestCase {
     TokenStream stream = factory.create(tokenizer);
     assertTokenStreamContents(stream, new String[] { "Ceska" });
   }
-  
-  /**
-   * Ensure the ISOLatin1AccentFilterFactory works 
-   * (sometimes, at least not uppercase hacek)
-   */
-  public void testISOLatin1Folding() throws Exception {
-    Reader reader = new StringReader("?esk");
-    Tokenizer tokenizer = new WhitespaceTokenizer(DEFAULT_VERSION, reader);
-    ISOLatin1AccentFilterFactory factory = new ISOLatin1AccentFilterFactory();
-    factory.init(DEFAULT_VERSION_PARAM);
-    TokenStream stream = factory.create(tokenizer);
-    assertTokenStreamContents(stream, new String[] { "?eska" });
-  }
 }
diff --git a/solr/src/test/org/apache/solr/core/TestArbitraryIndexDir.java b/solr/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
index b4610a4..2c2555a 100644
--- a/solr/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
+++ b/solr/src/test/org/apache/solr/core/TestArbitraryIndexDir.java
@@ -27,11 +27,8 @@ import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.index.IndexWriter.MaxFieldLength;
+import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.queryParser.ParseException;
-import org.apache.lucene.queryParser.QueryParser;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Query;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.util.Version;
@@ -101,7 +98,11 @@ public class TestArbitraryIndexDir extends AbstractSolrTestCase{
 
     //add a doc in the new index dir
     Directory dir = FSDirectory.open(newDir);
-    IndexWriter iw = new IndexWriter(dir, new StandardAnalyzer(Version.LUCENE_24), new MaxFieldLength(1000));
+    IndexWriter iw = new IndexWriter(
+        dir,
+        new IndexWriterConfig(Version.LUCENE_40, new StandardAnalyzer(Version.LUCENE_40)).
+            setMaxFieldLength(1000)
+    );
     Document doc = new Document();
     doc.add(new Field("id", "2", Field.Store.YES, Field.Index.ANALYZED));
     doc.add(new Field("name", "name2", Field.Store.YES, Field.Index.ANALYZED));
diff --git a/solr/src/test/org/apache/solr/core/TestConfig.java b/solr/src/test/org/apache/solr/core/TestConfig.java
index 5781de0..4d78b6b 100644
--- a/solr/src/test/org/apache/solr/core/TestConfig.java
+++ b/solr/src/test/org/apache/solr/core/TestConfig.java
@@ -133,7 +133,7 @@ public class TestConfig extends SolrTestCaseJ4 {
 
     ExposeWriterHandler duh = new ExposeWriterHandler();
     IndexWriter writer = duh.getWriter();
-    int interval = writer.getTermIndexInterval();
+    int interval = writer.getConfig().getTermIndexInterval();
     assertEquals(256, interval);
     duh.close();
   }
diff --git a/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java b/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
index 59447c8..f0bd861 100644
--- a/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
+++ b/solr/src/test/org/apache/solr/core/TestLegacyMergeSchedulerPolicyConfig.java
@@ -20,8 +20,8 @@ public class TestLegacyMergeSchedulerPolicyConfig extends SolrTestCaseJ4 {
   public void testLegacy() throws Exception {
     ExposeWriterHandler duh = new ExposeWriterHandler();
     IndexWriter writer = duh.getWriter();
-    assertTrue(writer.getMergePolicy().getClass().getName().equals(LogDocMergePolicy.class.getName()));
-    assertTrue(writer.getMergeScheduler().getClass().getName().equals(SerialMergeScheduler.class.getName()));
+    assertTrue(writer.getConfig().getMergePolicy().getClass().getName().equals(LogDocMergePolicy.class.getName()));
+    assertTrue(writer.getConfig().getMergeScheduler().getClass().getName().equals(SerialMergeScheduler.class.getName()));
     duh.close();
   }
   
diff --git a/solr/src/test/org/apache/solr/core/TestPropInject.java b/solr/src/test/org/apache/solr/core/TestPropInject.java
index 6a80462..dbe7ab0 100644
--- a/solr/src/test/org/apache/solr/core/TestPropInject.java
+++ b/solr/src/test/org/apache/solr/core/TestPropInject.java
@@ -31,7 +31,7 @@ public class TestPropInject extends AbstractSolrTestCase {
   public void testMergePolicy() throws Exception {
     ExposeWriterHandler uh = new ExposeWriterHandler();
     IndexWriter writer = uh.getWriter();
-    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
+    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getConfig().getMergePolicy();
     assertEquals(64.0, mp.getMaxMergeMB());
     uh.close();
   }
@@ -39,7 +39,7 @@ public class TestPropInject extends AbstractSolrTestCase {
   public void testProps() throws Exception {
     ExposeWriterHandler uh = new ExposeWriterHandler();
     IndexWriter writer = uh.getWriter();
-    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
+    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getConfig().getMergeScheduler();
     assertEquals(2, cms.getMaxThreadCount());
     uh.close();
   }
diff --git a/solr/src/test/org/apache/solr/core/TestPropInjectDefaults.java b/solr/src/test/org/apache/solr/core/TestPropInjectDefaults.java
index 632ae1a..28848ea 100644
--- a/solr/src/test/org/apache/solr/core/TestPropInjectDefaults.java
+++ b/solr/src/test/org/apache/solr/core/TestPropInjectDefaults.java
@@ -48,7 +48,7 @@ public class TestPropInjectDefaults extends SolrTestCaseJ4 {
   public void testMergePolicyDefaults() throws Exception {
     ExposeWriterHandler uh = new ExposeWriterHandler();
     IndexWriter writer = uh.getWriter();
-    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getMergePolicy();
+    LogByteSizeMergePolicy mp = (LogByteSizeMergePolicy)writer.getConfig().getMergePolicy();
     assertEquals(32.0, mp.getMaxMergeMB());
     uh.close();
   }
@@ -57,7 +57,7 @@ public class TestPropInjectDefaults extends SolrTestCaseJ4 {
   public void testPropsDefaults() throws Exception {
     ExposeWriterHandler uh = new ExposeWriterHandler();
     IndexWriter writer = uh.getWriter();
-    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getMergeScheduler();
+    ConcurrentMergeScheduler cms = (ConcurrentMergeScheduler)writer.getConfig().getMergeScheduler();
     assertEquals(4, cms.getMaxThreadCount());
     uh.close();
   }
diff --git a/solr/src/test/org/apache/solr/highlight/HighlighterTest.java b/solr/src/test/org/apache/solr/highlight/HighlighterTest.java
index 3f9d1b6..e641dac 100755
--- a/solr/src/test/org/apache/solr/highlight/HighlighterTest.java
+++ b/solr/src/test/org/apache/solr/highlight/HighlighterTest.java
@@ -158,12 +158,12 @@ public class HighlighterTest extends SolrTestCaseJ4 {
   @Test
   public void testTermOffsetsTokenStream() throws Exception {
     String[] multivalued = { "a b c d", "e f g", "h", "i j k l m n" };
-    Analyzer a1 = new WhitespaceAnalyzer();
+    Analyzer a1 = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);
     TermOffsetsTokenStream tots = new TermOffsetsTokenStream(
         a1.tokenStream( "", new StringReader( "a b c d e f g h i j k l m n" ) ) );
     for( String v : multivalued ){
       TokenStream ts1 = tots.getMultiValuedTokenStream( v.length() );
-      Analyzer a2 = new WhitespaceAnalyzer();
+      Analyzer a2 = new WhitespaceAnalyzer(TEST_VERSION_CURRENT);
       TokenStream ts2 = a2.tokenStream( "", new StringReader( v ) );
       while (ts1.incrementToken()) {
         assertTrue(ts2.incrementToken());
diff --git a/solr/src/test/org/apache/solr/search/TestSort.java b/solr/src/test/org/apache/solr/search/TestSort.java
index f666d3f..cb32ce5 100755
--- a/solr/src/test/org/apache/solr/search/TestSort.java
+++ b/solr/src/test/org/apache/solr/search/TestSort.java
@@ -22,6 +22,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.search.*;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.RAMDirectory;
@@ -59,7 +60,12 @@ public class TestSort extends AbstractSolrTestCase {
     Field f2 = new Field("f2","0", Field.Store.NO, Field.Index.NOT_ANALYZED_NO_NORMS);
 
     for (int iterCnt = 0; iterCnt<iter; iterCnt++) {
-      IndexWriter iw = new IndexWriter(dir, new SimpleAnalyzer(), true, IndexWriter.MaxFieldLength.UNLIMITED);
+      IndexWriter iw = new IndexWriter(
+          dir,
+          new IndexWriterConfig(TEST_VERSION_CURRENT, new SimpleAnalyzer(TEST_VERSION_CURRENT)).
+              setOpenMode(IndexWriterConfig.OpenMode.CREATE).
+              setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)
+      );
       final MyDoc[] mydocs = new MyDoc[ndocs];
 
       int v1EmptyPercent = 50;
diff --git a/solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java b/solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
index 4a30c53..4e2041a 100644
--- a/solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
+++ b/solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest.java
@@ -24,6 +24,7 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.search.spell.JaroWinklerDistance;
 import org.apache.lucene.search.spell.SpellChecker;
 import org.apache.lucene.search.spell.StringDistance;
@@ -283,7 +284,11 @@ public class IndexBasedSpellCheckerTest extends SolrTestCaseJ4 {
     File indexDir = new File(TEMP_DIR, "spellingIdx" + new Date().getTime());
     //create a standalone index
     File altIndexDir = new File(TEMP_DIR, "alternateIdx" + new Date().getTime());
-    IndexWriter iw = new IndexWriter(FSDirectory.open(altIndexDir), new WhitespaceAnalyzer(), IndexWriter.MaxFieldLength.LIMITED);
+    IndexWriter iw = new IndexWriter(
+        FSDirectory.open(altIndexDir),
+        new IndexWriterConfig(TEST_VERSION_CURRENT, new WhitespaceAnalyzer(TEST_VERSION_CURRENT)).
+            setMaxFieldLength(IndexWriterConfig.UNLIMITED_FIELD_LENGTH)
+    );
     for (int i = 0; i < ALT_DOCS.length; i++) {
       Document doc = new Document();
       doc.add(new Field("title", ALT_DOCS[i], Field.Store.YES, Field.Index.ANALYZED));
diff --git a/solr/src/test/org/apache/solr/spelling/SimpleQueryConverter.java b/solr/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
index 56b7e39..0dcfee4 100644
--- a/solr/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
+++ b/solr/src/test/org/apache/solr/spelling/SimpleQueryConverter.java
@@ -25,6 +25,7 @@ import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
 import org.apache.lucene.analysis.tokenattributes.PayloadAttribute;
 import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
 import org.apache.lucene.analysis.tokenattributes.TypeAttribute;
+import org.apache.lucene.util.Version;
 
 import java.util.Collection;
 import java.util.HashSet;
@@ -40,7 +41,7 @@ class SimpleQueryConverter extends SpellingQueryConverter{
   @Override
   public Collection<Token> convert(String origQuery) {
     Collection<Token> result = new HashSet<Token>();
-    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer();
+    WhitespaceAnalyzer analyzer = new WhitespaceAnalyzer(Version.LUCENE_40);
     TokenStream ts = analyzer.tokenStream("", new StringReader(origQuery));
     // TODO: support custom attributes
     CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
diff --git a/solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest.java b/solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest.java
index d349774..b6efa9f 100644
--- a/solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest.java
+++ b/solr/src/test/org/apache/solr/spelling/SpellingQueryConverterTest.java
@@ -21,13 +21,9 @@ import org.apache.lucene.analysis.Token;
 import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.solr.common.util.NamedList;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.assertEquals;
 import org.junit.Test;
-import org.junit.Assert;
 
 import java.util.Collection;
-import java.util.ArrayList;
 
 
 /**
@@ -42,7 +38,7 @@ public class SpellingQueryConverterTest extends LuceneTestCase {
   public void test() throws Exception {
     SpellingQueryConverter converter = new SpellingQueryConverter();
     converter.init(new NamedList());
-    converter.setAnalyzer(new WhitespaceAnalyzer());
+    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));
     Collection<Token> tokens = converter.convert("field:foo");
     assertTrue("tokens is null and it shouldn't be", tokens != null);
     assertTrue("tokens Size: " + tokens.size() + " is not: " + 1, tokens.size() == 1);
@@ -52,7 +48,7 @@ public class SpellingQueryConverterTest extends LuceneTestCase {
   public void testSpecialChars()  {
     SpellingQueryConverter converter = new SpellingQueryConverter();
     converter.init(new NamedList());
-    converter.setAnalyzer(new WhitespaceAnalyzer());
+    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));
     String original = "field_with_underscore:value_with_underscore";
     Collection<Token> tokens = converter.convert(original);
     assertTrue("tokens is null and it shouldn't be", tokens != null);
@@ -98,7 +94,7 @@ public class SpellingQueryConverterTest extends LuceneTestCase {
   public void testUnicode() {
     SpellingQueryConverter converter = new SpellingQueryConverter();
     converter.init(new NamedList());
-    converter.setAnalyzer(new WhitespaceAnalyzer());
+    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));
     
     // chinese text value
     Collection<Token> tokens = converter.convert("text_field:????????????");
@@ -118,7 +114,7 @@ public class SpellingQueryConverterTest extends LuceneTestCase {
   public void testMultipleClauses() {
     SpellingQueryConverter converter = new SpellingQueryConverter();
     converter.init(new NamedList());
-    converter.setAnalyzer(new WhitespaceAnalyzer());
+    converter.setAnalyzer(new WhitespaceAnalyzer(TEST_VERSION_CURRENT));
 
     // two field:value pairs should give two tokens
     Collection<Token> tokens = converter.convert("?ext_field:???????????? field2:bar");
diff --git a/solr/src/test/test-files/solr/conf/schema-luceneMatchVersion.xml b/solr/src/test/test-files/solr/conf/schema-luceneMatchVersion.xml
index d523aa6..af94ce8 100644
--- a/solr/src/test/test-files/solr/conf/schema-luceneMatchVersion.xml
+++ b/solr/src/test/test-files/solr/conf/schema-luceneMatchVersion.xml
@@ -18,12 +18,12 @@
 <schema name="luceneMatchVersionTest" version="1.1">
  <types>
   <fieldtype name="string" class="solr.StrField"/>
-  <fieldtype name="text20" class="solr.TextField">
+  <fieldtype name="text30" class="solr.TextField">
     <analyzer>
-      <tokenizer class="solr.StandardTokenizerFactory" luceneMatchVersion="LUCENE_20"/>
+      <tokenizer class="solr.StandardTokenizerFactory" luceneMatchVersion="LUCENE_30"/>
       <filter class="solr.StandardFilterFactory"/>
       <filter class="solr.LowerCaseFilterFactory"/>
-      <filter class="solr.StopFilterFactory" luceneMatchVersion="2.4"/>
+      <filter class="solr.StopFilterFactory" luceneMatchVersion="3.1"/>
       <filter class="solr.PorterStemFilterFactory"/>
     </analyzer>
   </fieldtype>
@@ -36,8 +36,8 @@
       <filter class="solr.PorterStemFilterFactory"/>
     </analyzer>
   </fieldtype>
-  <fieldtype name="textStandardAnalyzer20" class="solr.TextField">
-    <analyzer class="org.apache.lucene.analysis.standard.StandardAnalyzer" luceneMatchVersion="LUCENE_20"/>
+  <fieldtype name="textStandardAnalyzer30" class="solr.TextField">
+    <analyzer class="org.apache.lucene.analysis.standard.StandardAnalyzer" luceneMatchVersion="LUCENE_30"/>
   </fieldtype>
   <fieldtype name="textStandardAnalyzerDefault" class="solr.TextField">
     <analyzer class="org.apache.lucene.analysis.standard.StandardAnalyzer"/>
@@ -45,9 +45,9 @@
  </types>
  <fields>
    <field name="signatureField" type="string" indexed="true" stored="false"/>
-   <field name="text20" type="text20" indexed="true" stored="false" />
+   <field name="text30" type="text30" indexed="true" stored="false" />
    <field name="textDefault" type="textDefault" indexed="true" stored="false" />
-   <field name="textStandardAnalyzer20" type="textStandardAnalyzer20" indexed="true" stored="false" />
+   <field name="textStandardAnalyzer30" type="textStandardAnalyzer30" indexed="true" stored="false" />
    <field name="textStandardAnalyzerDefault" type="textStandardAnalyzerDefault" indexed="true" stored="false" />
    <dynamicField name="*_sS" type="string"  indexed="false" stored="true"/>
  </fields>

