GitDiffStart: f5770479e39e9d67ccfa9cf78801d0b444e037fd | Mon Mar 26 10:31:48 2012 +0000
diff --git a/modules/analysis/kuromoji/build.xml b/modules/analysis/kuromoji/build.xml
index ea8442a..d29607f 100644
--- a/modules/analysis/kuromoji/build.xml
+++ b/modules/analysis/kuromoji/build.xml
@@ -78,10 +78,10 @@
   <target name="build-dict" depends="compile-tools, download-dict">
     <sequential>
       <delete verbose="true">
-        <fileset dir="src/resources/org/apache/lucene/analysis/kuromoji/dict" includes="**/*"/>
+        <fileset dir="src/resources/org/apache/lucene/analysis/ja/dict" includes="**/*"/>
       </delete>
       <!-- TODO: optimize the dictionary construction a bit so that you don't need 1G -->
-      <java fork="true" failonerror="true" maxmemory="1g" classname="org.apache.lucene.analysis.kuromoji.util.DictionaryBuilder">
+      <java fork="true" failonerror="true" maxmemory="1g" classname="org.apache.lucene.analysis.ja.util.DictionaryBuilder">
         <classpath>
           <path refid="tools.classpath"/>
           <pathelement path="${build.dir}/classes/tools"/>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/GraphvizFormatter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/GraphvizFormatter.java
new file mode 100644
index 0000000..7dcb493
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/GraphvizFormatter.java
@@ -0,0 +1,181 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Position;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.WrappedPositionArray;
+import org.apache.lucene.analysis.ja.dict.ConnectionCosts;
+import org.apache.lucene.analysis.ja.dict.Dictionary;
+
+
+// TODO: would be nice to show 2nd best path in a diff't
+// color...
+
+/**
+ * Outputs the dot (graphviz) string for the viterbi lattice.
+ */
+public class GraphvizFormatter {
+  
+  private final static String BOS_LABEL = "BOS";
+  
+  private final static String EOS_LABEL = "EOS";
+  
+  private final static String FONT_NAME = "Helvetica";
+  
+  private final ConnectionCosts costs;
+  
+  private final Map<String, String> bestPathMap;
+  
+  private final StringBuilder sb = new StringBuilder();
+  
+  public GraphvizFormatter(ConnectionCosts costs) {
+    this.costs = costs;
+    this.bestPathMap = new HashMap<String, String>();
+    sb.append(formatHeader());
+    sb.append("  init [style=invis]\n");
+    sb.append("  init -> 0.0 [label=\"" + BOS_LABEL + "\"]\n");
+  }
+
+  public String finish() {
+    sb.append(formatTrailer());
+    return sb.toString();
+  }
+
+  // Backtraces another incremental fragment:
+  void onBacktrace(JapaneseTokenizer tok, WrappedPositionArray positions, int lastBackTracePos, Position endPosData, int fromIDX, char[] fragment, boolean isEnd) {
+    setBestPathMap(positions, lastBackTracePos, endPosData, fromIDX);
+    sb.append(formatNodes(tok, positions, lastBackTracePos, endPosData, fragment));
+    if (isEnd) {
+      sb.append("  fini [style=invis]\n");
+      sb.append("  ");
+      sb.append(getNodeID(endPosData.pos, fromIDX));
+      sb.append(" -> fini [label=\"" + EOS_LABEL + "\"]");
+    }
+  }
+
+  // Records which arcs make up the best bath:
+  private void setBestPathMap(WrappedPositionArray positions, int startPos, Position endPosData, int fromIDX) {
+    bestPathMap.clear();
+
+    int pos = endPosData.pos;
+    int bestIDX = fromIDX;
+    while (pos > startPos) {
+      final Position posData = positions.get(pos);
+
+      final int backPos = posData.backPos[bestIDX];
+      final int backIDX = posData.backIndex[bestIDX];
+
+      final String toNodeID = getNodeID(pos, bestIDX);
+      final String fromNodeID = getNodeID(backPos, backIDX);
+      
+      assert !bestPathMap.containsKey(fromNodeID);
+      assert !bestPathMap.containsValue(toNodeID);
+      bestPathMap.put(fromNodeID, toNodeID);
+      pos = backPos;
+      bestIDX = backIDX;
+    }
+  }
+  
+  private String formatNodes(JapaneseTokenizer tok, WrappedPositionArray positions, int startPos, Position endPosData, char[] fragment) {
+
+    StringBuilder sb = new StringBuilder();
+    // Output nodes
+    for (int pos = startPos+1; pos <= endPosData.pos; pos++) {
+      final Position posData = positions.get(pos);
+      for(int idx=0;idx<posData.count;idx++) {
+        sb.append("  ");
+        sb.append(getNodeID(pos, idx));
+        sb.append(" [label=\"");
+        sb.append(pos);
+        sb.append(": ");
+        sb.append(posData.lastRightID[idx]);
+        sb.append("\"]\n");
+      }
+    }
+
+    // Output arcs
+    for (int pos = endPosData.pos; pos > startPos; pos--) {
+      final Position posData = positions.get(pos);
+      for(int idx=0;idx<posData.count;idx++) {
+        final Position backPosData = positions.get(posData.backPos[idx]);
+        final String toNodeID = getNodeID(pos, idx);
+        final String fromNodeID = getNodeID(posData.backPos[idx], posData.backIndex[idx]);
+
+        sb.append("  ");
+        sb.append(fromNodeID);
+        sb.append(" -> ");
+        sb.append(toNodeID);
+
+        final String attrs;
+        if (toNodeID.equals(bestPathMap.get(fromNodeID))) {
+          // This arc is on best path
+          attrs = " color=\"#40e050\" fontcolor=\"#40a050\" penwidth=3 fontsize=20";
+        } else {
+          attrs = "";
+        }
+
+        final Dictionary dict = tok.getDict(posData.backType[idx]);
+        final int wordCost = dict.getWordCost(posData.backID[idx]);
+        final int bgCost = costs.get(backPosData.lastRightID[posData.backIndex[idx]],
+                                     dict.getLeftId(posData.backID[idx]));
+
+        final String surfaceForm = new String(fragment,
+                                              posData.backPos[idx] - startPos,
+                                              pos - posData.backPos[idx]);
+        
+        sb.append(" [label=\"");
+        sb.append(surfaceForm);
+        sb.append(' ');
+        sb.append(wordCost);
+        if (bgCost >= 0) {
+          sb.append('+');
+        }
+        sb.append(bgCost);
+        sb.append("\"");
+        sb.append(attrs);
+        sb.append("]\n");
+      }
+    }
+    return sb.toString();
+  }
+  
+  private String formatHeader() {
+    StringBuilder sb = new StringBuilder();
+    sb.append("digraph viterbi {\n");
+    sb.append("  graph [ fontsize=30 labelloc=\"t\" label=\"\" splines=true overlap=false rankdir = \"LR\"];\n");
+    //sb.append("  // A2 paper size\n");
+    //sb.append("  size = \"34.4,16.5\";\n");
+    //sb.append("  // try to fill paper\n");
+    //sb.append("  ratio = fill;\n");
+    sb.append("  edge [ fontname=\"" + FONT_NAME + "\" fontcolor=\"red\" color=\"#606060\" ]\n");
+    sb.append("  node [ style=\"filled\" fillcolor=\"#e8e8f0\" shape=\"Mrecord\" fontname=\"" + FONT_NAME + "\" ]\n");
+    
+    return sb.toString();
+  }
+  
+  private String formatTrailer() {
+    return "}";
+  }
+  
+  private String getNodeID(int pos, int idx) {
+    return pos + "." + idx;
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseAnalyzer.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseAnalyzer.java
new file mode 100644
index 0000000..88ab98b
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseAnalyzer.java
@@ -0,0 +1,99 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.cjk.CJKWidthFilter;
+import org.apache.lucene.analysis.core.LowerCaseFilter;
+import org.apache.lucene.analysis.core.StopFilter;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.analysis.ja.dict.UserDictionary;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
+import org.apache.lucene.util.Version;
+
+/**
+ * Analyzer for Japanese that uses morphological analysis.
+ * @see JapaneseTokenizer
+ */
+public class JapaneseAnalyzer extends StopwordAnalyzerBase {
+  private final Mode mode;
+  private final Set<String> stoptags;
+  private final UserDictionary userDict;
+  
+  public JapaneseAnalyzer(Version matchVersion) {
+    this(matchVersion, null, JapaneseTokenizer.DEFAULT_MODE, DefaultSetHolder.DEFAULT_STOP_SET, DefaultSetHolder.DEFAULT_STOP_TAGS);
+  }
+  
+  public JapaneseAnalyzer(Version matchVersion, UserDictionary userDict, Mode mode, CharArraySet stopwords, Set<String> stoptags) {
+    super(matchVersion, stopwords);
+    this.userDict = userDict;
+    this.mode = mode;
+    this.stoptags = stoptags;
+  }
+  
+  public static CharArraySet getDefaultStopSet(){
+    return DefaultSetHolder.DEFAULT_STOP_SET;
+  }
+  
+  public static Set<String> getDefaultStopTags(){
+    return DefaultSetHolder.DEFAULT_STOP_TAGS;
+  }
+  
+  /**
+   * Atomically loads DEFAULT_STOP_SET, DEFAULT_STOP_TAGS in a lazy fashion once the 
+   * outer class accesses the static final set the first time.
+   */
+  private static class DefaultSetHolder {
+    static final CharArraySet DEFAULT_STOP_SET;
+    static final Set<String> DEFAULT_STOP_TAGS;
+
+    static {
+      try {
+        DEFAULT_STOP_SET = loadStopwordSet(true, JapaneseAnalyzer.class, "stopwords.txt", "#");  // ignore case
+        final CharArraySet tagset = loadStopwordSet(false, JapaneseAnalyzer.class, "stoptags.txt", "#");
+        DEFAULT_STOP_TAGS = new HashSet<String>();
+        for (Object element : tagset) {
+          char chars[] = (char[]) element;
+          DEFAULT_STOP_TAGS.add(new String(chars));
+        }
+      } catch (IOException ex) {
+        // default set should always be present as it is part of the distribution (JAR)
+        throw new RuntimeException("Unable to load default stopword or stoptag set");
+      }
+    }
+  }
+  
+  @Override
+  protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+    Tokenizer tokenizer = new JapaneseTokenizer(reader, userDict, true, mode);
+    TokenStream stream = new JapaneseBaseFormFilter(tokenizer);
+    stream = new JapanesePartOfSpeechStopFilter(true, stream, stoptags);
+    stream = new CJKWidthFilter(stream);
+    stream = new StopFilter(matchVersion, stream, stopwords);
+    stream = new JapaneseKatakanaStemFilter(stream);
+    stream = new LowerCaseFilter(matchVersion, stream);
+    return new TokenStreamComponents(tokenizer, stream);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilter.java
new file mode 100644
index 0000000..87f77d4
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseBaseFormFilter.java
@@ -0,0 +1,62 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.tokenattributes.BaseFormAttribute;
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
+
+/**
+ * Replaces term text with the {@link BaseFormAttribute}.
+ * <p>
+ * This acts as a lemmatizer for verbs and adjectives.
+ * <p>
+ * To prevent terms from being stemmed use an instance of
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
+ * the {@link KeywordAttribute} before this {@link TokenStream}.
+ * </p>
+ */
+public final class JapaneseBaseFormFilter extends TokenFilter {
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final BaseFormAttribute basicFormAtt = addAttribute(BaseFormAttribute.class);
+  private final KeywordAttribute keywordAtt = addAttribute(KeywordAttribute.class);
+
+  public JapaneseBaseFormFilter(TokenStream input) {
+    super(input);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      if (!keywordAtt.isKeyword()) {
+        String baseForm = basicFormAtt.getBaseForm();
+        if (baseForm != null) {
+          termAtt.setEmpty().append(baseForm);
+        }
+      }
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilter.java
new file mode 100644
index 0000000..1f3d1d6
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseKatakanaStemFilter.java
@@ -0,0 +1,98 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
+
+import java.io.IOException;
+
+/**
+ * A {@link TokenFilter} that normalizes common katakana spelling variations
+ * ending in a long sound character by removing this character (U+30FC).  Only
+ * katakana words longer than a minimum length are stemmed (default is four).
+ * <p>
+ * Note that only full-width katakana characters are supported.  Please use a
+ * {@link org.apache.lucene.analysis.cjk.CJKWidthFilter} to convert half-width
+ * katakana to full-width before using this filter.
+ * </p>
+ * <p>
+ * In order to prevent terms from being stemmed, use an instance of
+ * {@link org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter}
+ * or a custom {@link TokenFilter} that sets the {@link KeywordAttribute}
+ * before this {@link TokenStream}.
+ * </p>
+ */
+
+public final class JapaneseKatakanaStemFilter extends TokenFilter {
+  public final static int DEFAULT_MINIMUM_LENGTH = 4;
+  private final static char HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK = '\u30fc';
+
+  private final CharTermAttribute termAttr = addAttribute(CharTermAttribute.class);
+  private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
+  private final int minimumKatakanaLength;
+
+  public JapaneseKatakanaStemFilter(TokenStream input, int minimumLength) {
+    super(input);
+    this.minimumKatakanaLength = minimumLength;
+  }
+
+  public JapaneseKatakanaStemFilter(TokenStream input) {
+    this(input, DEFAULT_MINIMUM_LENGTH);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      if (!keywordAttr.isKeyword()) {
+        termAttr.setLength(stem(termAttr.buffer(), termAttr.length()));
+      }
+      return true;
+    } else {
+      return false;
+    }
+  }
+
+  private int stem(char[] term, int length) {
+    if (length < minimumKatakanaLength) {
+      return length;
+    }
+
+    if (! isKatakana(term, length)) {
+      return length;
+    }
+
+    if (term[length - 1] == HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK) {
+      return length - 1;
+    }
+
+    return length;
+  }
+
+  private boolean isKatakana(char[] term, int length) {
+    for (int i = 0; i < length; i++) {
+      // NOTE: Test only identifies full-width characters -- half-widths are supported
+      if (Character.UnicodeBlock.of(term[i]) != Character.UnicodeBlock.KATAKANA) {
+        return false;
+      }
+    }
+    return true;
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilter.java
new file mode 100644
index 0000000..a448c15
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapanesePartOfSpeechStopFilter.java
@@ -0,0 +1,44 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.analysis.ja.tokenattributes.PartOfSpeechAttribute;
+import org.apache.lucene.analysis.util.FilteringTokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Removes tokens that match a set of part-of-speech tags.
+ */
+public final class JapanesePartOfSpeechStopFilter extends FilteringTokenFilter {
+  private final Set<String> stopTags;
+  private final PartOfSpeechAttribute posAtt = addAttribute(PartOfSpeechAttribute.class);
+
+  public JapanesePartOfSpeechStopFilter(boolean enablePositionIncrements, TokenStream input, Set<String> stopTags) {
+    super(enablePositionIncrements, input);
+    this.stopTags = stopTags;
+  }
+
+  @Override
+  protected boolean accept() throws IOException {
+    final String pos = posAtt.getPartOfSpeech();
+    return pos == null || !stopTags.contains(pos);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilter.java
new file mode 100644
index 0000000..9cd7d40
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseReadingFormFilter.java
@@ -0,0 +1,65 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.ja.tokenattributes.ReadingAttribute;
+import org.apache.lucene.analysis.ja.util.ToStringUtil;
+
+import java.io.IOException;
+
+/**
+ * A {@link org.apache.lucene.analysis.TokenFilter} that replaces the term
+ * attribute with the reading of a token in either katakana or romaji form.
+ * The default reading form is katakana.
+ */
+
+public final class JapaneseReadingFormFilter extends TokenFilter {
+  private final CharTermAttribute termAttr = addAttribute(CharTermAttribute.class);
+  private final ReadingAttribute readingAttr = addAttribute(ReadingAttribute.class);
+
+  private boolean useRomaji;
+
+  public JapaneseReadingFormFilter(TokenStream input, boolean useRomaji) {
+    super(input);
+    this.useRomaji = useRomaji;
+  }
+
+  public JapaneseReadingFormFilter(TokenStream input) {
+    this(input, false);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      String reading = readingAttr.getReading();
+      if (reading != null) {
+        if (useRomaji) {
+          ToStringUtil.getRomanization(termAttr.setEmpty(), reading);
+        } else {
+          termAttr.setEmpty().append(reading);
+        }
+      }
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
new file mode 100644
index 0000000..360a036
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseTokenizer.java
@@ -0,0 +1,1239 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.EnumMap;
+import java.util.List;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.dict.CharacterDefinition;
+import org.apache.lucene.analysis.ja.dict.ConnectionCosts;
+import org.apache.lucene.analysis.ja.dict.Dictionary;
+import org.apache.lucene.analysis.ja.dict.TokenInfoDictionary;
+import org.apache.lucene.analysis.ja.dict.TokenInfoFST;
+import org.apache.lucene.analysis.ja.dict.UnknownDictionary;
+import org.apache.lucene.analysis.ja.dict.UserDictionary;
+import org.apache.lucene.analysis.ja.tokenattributes.*;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
+import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.RamUsageEstimator;
+import org.apache.lucene.util.RollingCharBuffer;
+import org.apache.lucene.util.fst.FST;
+
+// TODO: somehow factor out a reusable viterbi search here,
+// so other decompounders/tokenizers can reuse...
+
+/**
+ * Tokenizer for Japanese that uses morphological analysis.
+ * <p>
+ * This tokenizer sets a number of additional attributes:
+ * <ul>
+ *   <li>{@link BaseFormAttribute} containing base form for inflected
+ *       adjectives and verbs.
+ *   <li>{@link PartOfSpeechAttribute} containing part-of-speech.
+ *   <li>{@link ReadingAttribute} containing reading and pronunciation.
+ *   <li>{@link InflectionAttribute} containing additional part-of-speech
+ *       information for inflected forms.
+ * </ul>
+ * <p>
+ * This tokenizer uses a rolling Viterbi search to find the 
+ * least cost segmentation (path) of the incoming characters.  
+ * For tokens that appear to be compound (> length 2 for all
+ * Kanji, or > length 7 for non-Kanji), we see if there is a
+ * 2nd best segmentation of that token after applying
+ * penalties to the long tokens.  If so, and the Mode is
+ * {@link Mode#SEARCH}, we output the alternate segmentation 
+ * as well.
+ */
+public final class JapaneseTokenizer extends Tokenizer {
+
+  /**
+   * Tokenization mode: this determines how the tokenizer handles
+   * compound and unknown words.
+   */
+  public static enum Mode {
+    /**
+     * Ordinary segmentation: no decomposition for compounds,
+     */
+    NORMAL, 
+
+    /**
+     * Segmentation geared towards search: this includes a 
+     * decompounding process for long nouns, also including
+     * the full compound token as a synonym.
+     */
+    SEARCH, 
+
+    /**
+     * Extended mode outputs unigrams for unknown words.
+     * @lucene.experimental
+     */
+    EXTENDED
+  }
+
+  /**
+   * Default tokenization mode. Currently this is {@link Mode#SEARCH}.
+   */
+  public static final Mode DEFAULT_MODE = Mode.SEARCH;
+
+  enum Type {
+    KNOWN,
+    UNKNOWN,
+    USER
+  }
+
+  private static final boolean VERBOSE = false;
+
+  private static final int SEARCH_MODE_KANJI_LENGTH = 2;
+
+  private static final int SEARCH_MODE_OTHER_LENGTH = 7; // Must be >= SEARCH_MODE_KANJI_LENGTH
+
+  private static final int SEARCH_MODE_KANJI_PENALTY = 3000;
+
+  private static final int SEARCH_MODE_OTHER_PENALTY = 1700;
+
+  // For safety:
+  private static final int MAX_UNKNOWN_WORD_LENGTH = 1024;
+  private static final int MAX_BACKTRACE_GAP = 1024;
+
+  private final EnumMap<Type, Dictionary> dictionaryMap = new EnumMap<Type, Dictionary>(Type.class);
+
+  private final TokenInfoFST fst;
+  private final TokenInfoDictionary dictionary;
+  private final UnknownDictionary unkDictionary;
+  private final ConnectionCosts costs;
+  private final UserDictionary userDictionary;
+  private final CharacterDefinition characterDefinition;
+
+  private final FST.Arc<Long> arc = new FST.Arc<Long>();
+  private final FST.BytesReader fstReader;
+  private final IntsRef wordIdRef = new IntsRef();
+
+  private final FST.BytesReader userFSTReader;
+  private final TokenInfoFST userFST;
+
+  private final RollingCharBuffer buffer = new RollingCharBuffer();
+
+  private final WrappedPositionArray positions = new WrappedPositionArray();
+
+  private final boolean discardPunctuation;
+  private final boolean searchMode;
+  private final boolean extendedMode;
+  private final boolean outputCompounds;
+
+  // Index of the last character of unknown word:
+  private int unknownWordEndIndex = -1;
+
+  // True once we've hit the EOF from the input reader:
+  private boolean end;
+
+  // Last absolute position we backtraced from:
+  private int lastBackTracePos;
+
+  // Position of last token we returned; we use this to
+  // figure out whether to set posIncr to 0 or 1:
+  private int lastTokenPos;
+
+  // Next absolute position to process:
+  private int pos;
+
+  // Already parsed, but not yet passed to caller, tokens:
+  private final List<Token> pending = new ArrayList<Token>();
+
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
+  private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
+  private final PositionLengthAttribute posLengthAtt = addAttribute(PositionLengthAttribute.class);
+  private final BaseFormAttribute basicFormAtt = addAttribute(BaseFormAttribute.class);
+  private final PartOfSpeechAttribute posAtt = addAttribute(PartOfSpeechAttribute.class);
+  private final ReadingAttribute readingAtt = addAttribute(ReadingAttribute.class);
+  private final InflectionAttribute inflectionAtt = addAttribute(InflectionAttribute.class);
+
+  /**
+   * Create a new JapaneseTokenizer.
+   * 
+   * @param input Reader containing text
+   * @param userDictionary Optional: if non-null, user dictionary.
+   * @param discardPunctuation true if punctuation tokens should be dropped from the output.
+   * @param mode tokenization mode.
+   */
+  public JapaneseTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {
+    super(input);
+    dictionary = TokenInfoDictionary.getInstance();
+    fst = dictionary.getFST();
+    unkDictionary = UnknownDictionary.getInstance();
+    characterDefinition = unkDictionary.getCharacterDefinition();
+    this.userDictionary = userDictionary;
+    costs = ConnectionCosts.getInstance();
+    fstReader = fst.getBytesReader(0);
+    if (userDictionary != null) {
+      userFST = userDictionary.getFST();
+      userFSTReader = userFST.getBytesReader(0);
+    } else {
+      userFST = null;
+      userFSTReader = null;
+    }
+    this.discardPunctuation = discardPunctuation;
+    switch(mode){
+      case SEARCH:
+        searchMode = true;
+        extendedMode = false;
+        outputCompounds = true;
+        break;
+      case EXTENDED:
+        searchMode = true;
+        extendedMode = true;
+        outputCompounds = false;
+        break;
+      default:
+        searchMode = false;
+        extendedMode = false;
+        outputCompounds = false;
+        break;
+    }
+    buffer.reset(input);
+
+    resetState();
+
+    dictionaryMap.put(Type.KNOWN, dictionary);
+    dictionaryMap.put(Type.UNKNOWN, unkDictionary);
+    dictionaryMap.put(Type.USER, userDictionary);
+  }
+
+  private GraphvizFormatter dotOut;
+
+  /** Expert: set this to produce graphviz (dot) output of
+   *  the Viterbi lattice */
+  public void setGraphvizFormatter(GraphvizFormatter dotOut) {
+    this.dotOut = dotOut;
+  }
+
+  @Override
+  public void reset(Reader input) throws IOException {
+    super.reset(input);
+    buffer.reset(input);
+  }
+
+  @Override
+  public void reset() throws IOException {
+    super.reset();
+    resetState();
+  }
+
+  private void resetState() {
+    positions.reset();
+    unknownWordEndIndex = -1;
+    pos = 0;
+    end = false;
+    lastBackTracePos = 0;
+    lastTokenPos = -1;
+    pending.clear();
+
+    // Add BOS:
+    positions.get(0).add(0, 0, -1, -1, -1, Type.KNOWN);
+  }
+
+  @Override
+  public void end() {
+    // Set final offset
+    offsetAtt.setOffset(correctOffset(pos), correctOffset(pos));
+  }
+
+  // Returns the added cost that a 2nd best segmentation is
+  // allowed to have.  Ie, if we see path with cost X,
+  // ending in a compound word, and this method returns
+  // threshold > 0, then we will also find the 2nd best
+  // segmentation and if its path score is within this
+  // threshold of X, we'll include it in the output:
+  private int computeSecondBestThreshold(int pos, int length) throws IOException {
+    // TODO: maybe we do something else here, instead of just
+    // using the penalty...?  EG we can be more aggressive on
+    // when to also test for 2nd best path
+    return computePenalty(pos, length);
+  }
+
+  private int computePenalty(int pos, int length) throws IOException {
+    if (length > SEARCH_MODE_KANJI_LENGTH) {
+      boolean allKanji = true;
+      // check if node consists of only kanji
+      final int endPos = pos + length;
+      for (int pos2 = pos; pos2 < endPos; pos2++) {
+        if (!characterDefinition.isKanji((char) buffer.get(pos2))) {
+          allKanji = false;
+          break;
+        }				
+      }
+      if (allKanji) {	// Process only Kanji keywords
+        return (length - SEARCH_MODE_KANJI_LENGTH) * SEARCH_MODE_KANJI_PENALTY;
+      } else if (length > SEARCH_MODE_OTHER_LENGTH) {
+        return (length - SEARCH_MODE_OTHER_LENGTH) * SEARCH_MODE_OTHER_PENALTY;								
+      }
+    }
+    return 0;
+  }
+
+  // Holds all back pointers arriving to this position:
+  final static class Position {
+
+    int pos;
+
+    int count;
+
+    // maybe single int array * 5?
+    int[] costs = new int[8];
+    int[] lastRightID = new int[8];
+    int[] backPos = new int[8];
+    int[] backIndex = new int[8];
+    int[] backID = new int[8];
+    Type[] backType = new Type[8];
+
+    // Only used when finding 2nd best segmentation under a
+    // too-long token:
+    int forwardCount;
+    int[] forwardPos = new int[8];
+    int[] forwardID = new int[8];
+    int[] forwardIndex = new int[8];
+    Type[] forwardType = new Type[8];
+
+    public void grow() {
+      costs = ArrayUtil.grow(costs, 1+count);
+      lastRightID = ArrayUtil.grow(lastRightID, 1+count);
+      backPos = ArrayUtil.grow(backPos, 1+count);
+      backIndex = ArrayUtil.grow(backIndex, 1+count);
+      backID = ArrayUtil.grow(backID, 1+count);
+
+      // NOTE: sneaky: grow separately because
+      // ArrayUtil.grow will otherwise pick a different
+      // length than the int[]s we just grew:
+      final Type[] newBackType = new Type[backID.length];
+      System.arraycopy(backType, 0, newBackType, 0, backType.length);
+      backType = newBackType;
+    }
+
+    public void growForward() {
+      forwardPos = ArrayUtil.grow(forwardPos, 1+forwardCount);
+      forwardID = ArrayUtil.grow(forwardID, 1+forwardCount);
+      forwardIndex = ArrayUtil.grow(forwardIndex, 1+forwardCount);
+
+      // NOTE: sneaky: grow separately because
+      // ArrayUtil.grow will otherwise pick a different
+      // length than the int[]s we just grew:
+      final Type[] newForwardType = new Type[forwardPos.length];
+      System.arraycopy(forwardType, 0, newForwardType, 0, forwardType.length);
+      forwardType = newForwardType;
+    }
+
+    public void add(int cost, int lastRightID, int backPos, int backIndex, int backID, Type backType) {
+      // NOTE: this isn't quite a true Viterbit search,
+      // becase we should check if lastRightID is
+      // already present here, and only update if the new
+      // cost is less than the current cost, instead of
+      // simply appending.  However, that will likely hurt
+      // performance (usually we add a lastRightID only once),
+      // and it means we actually create the full graph
+      // intersection instead of a "normal" Viterbi lattice:
+      if (count == costs.length) {
+        grow();
+      }
+      this.costs[count] = cost;
+      this.lastRightID[count] = lastRightID;
+      this.backPos[count] = backPos;
+      this.backIndex[count] = backIndex;
+      this.backID[count] = backID;
+      this.backType[count] = backType;
+      count++;
+    }
+
+    public void addForward(int forwardPos, int forwardIndex, int forwardID, Type forwardType) {
+      if (forwardCount == this.forwardID.length) {
+        growForward();
+      }
+      this.forwardPos[forwardCount] = forwardPos;
+      this.forwardIndex[forwardCount] = forwardIndex;
+      this.forwardID[forwardCount] = forwardID;
+      this.forwardType[forwardCount] = forwardType;
+      forwardCount++;
+    }
+
+    public void reset() {
+      count = 0;
+      // forwardCount naturally resets after it runs:
+      assert forwardCount == 0: "pos=" + pos + " forwardCount=" + forwardCount;
+    }
+  }
+
+  private void add(Dictionary dict, Position fromPosData, int endPos, int wordID, Type type, boolean addPenalty) throws IOException {
+    final int wordCost = dict.getWordCost(wordID);
+    final int leftID = dict.getLeftId(wordID);
+    int leastCost = Integer.MAX_VALUE;
+    int leastIDX = -1;
+    assert fromPosData.count > 0;
+    for(int idx=0;idx<fromPosData.count;idx++) {
+      // Cost is path cost so far, plus word cost (added at
+      // end of loop), plus bigram cost:
+      final int cost = fromPosData.costs[idx] + costs.get(fromPosData.lastRightID[idx], leftID);
+      if (VERBOSE) {
+        System.out.println("      fromIDX=" + idx + ": cost=" + cost + " (prevCost=" + fromPosData.costs[idx] + " wordCost=" + wordCost + " bgCost=" + costs.get(fromPosData.lastRightID[idx], leftID) + " leftID=" + leftID);
+      }
+      if (cost < leastCost) {
+        leastCost = cost;
+        leastIDX = idx;
+        if (VERBOSE) {
+          System.out.println("        **");
+        }
+      }
+    }
+
+    leastCost += wordCost;
+
+    if (VERBOSE) {
+      System.out.println("      + cost=" + leastCost + " wordID=" + wordID + " leftID=" + leftID + " leastIDX=" + leastIDX + " toPos=" + endPos + " toPos.idx=" + positions.get(endPos).count);
+    }
+
+    if ((addPenalty || (!outputCompounds && searchMode)) && type != Type.USER) {
+      final int penalty = computePenalty(fromPosData.pos, endPos - fromPosData.pos);
+      if (VERBOSE) {
+        if (penalty > 0) {
+          System.out.println("        + penalty=" + penalty + " cost=" + (leastCost+penalty));
+        }
+      }
+      leastCost += penalty;
+    }
+
+    //positions.get(endPos).add(leastCost, dict.getRightId(wordID), fromPosData.pos, leastIDX, wordID, type);
+    assert leftID == dict.getRightId(wordID);
+    positions.get(endPos).add(leastCost, leftID, fromPosData.pos, leastIDX, wordID, type);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+
+    // parse() is able to return w/o producing any new
+    // tokens, when the tokens it had produced were entirely
+    // punctuation.  So we loop here until we get a real
+    // token or we end:
+    while (pending.size() == 0) {
+      if (end) {
+        return false;
+      }
+
+      // Push Viterbi forward some more:
+      parse();
+    }
+
+    final Token token = pending.remove(pending.size()-1);
+
+    int position = token.getPosition();
+    int length = token.getLength();
+    clearAttributes();
+    assert length > 0;
+    //System.out.println("off=" + token.getOffset() + " len=" + length + " vs " + token.getSurfaceForm().length);
+    termAtt.copyBuffer(token.getSurfaceForm(), token.getOffset(), length);
+    offsetAtt.setOffset(correctOffset(position), correctOffset(position+length));
+    basicFormAtt.setToken(token);
+    posAtt.setToken(token);
+    readingAtt.setToken(token);
+    inflectionAtt.setToken(token);
+    if (token.getPosition() == lastTokenPos) {
+      posIncAtt.setPositionIncrement(0);
+      posLengthAtt.setPositionLength(token.getPositionLength());
+    } else {
+      assert token.getPosition() > lastTokenPos;
+      posIncAtt.setPositionIncrement(1);
+      posLengthAtt.setPositionLength(1);
+    }
+    if (VERBOSE) {
+      System.out.println(Thread.currentThread().getName() + ":    incToken: return token=" + token);
+    }
+    lastTokenPos = token.getPosition();
+    return true;
+  }
+
+  // TODO: make generic'd version of this "circular array"?
+  // It's a bit tricky because we do things to the Position
+  // (eg, set .pos = N on reuse)...
+  static final class WrappedPositionArray {
+    private Position[] positions = new Position[8];
+
+    public WrappedPositionArray() {
+      for(int i=0;i<positions.length;i++) {
+        positions[i] = new Position();
+      }
+    }
+
+    // Next array index to write to in positions:
+    private int nextWrite;
+
+    // Next position to write:
+    private int nextPos;
+    
+    // How many valid Position instances are held in the
+    // positions array:
+    private int count;
+
+    public void reset() {
+      nextWrite--;
+      while(count > 0) {
+        if (nextWrite == -1) {
+          nextWrite = positions.length - 1;
+        }
+        positions[nextWrite--].reset();
+        count--;
+      }
+      nextWrite = 0;
+      nextPos = 0;
+      count = 0;
+    }
+
+    /** Get Position instance for this absolute position;
+     *  this is allowed to be arbitrarily far "in the
+     *  future" but cannot be before the last freeBefore. */
+    public Position get(int pos) {
+      while(pos >= nextPos) {
+        //System.out.println("count=" + count + " vs len=" + positions.length);
+        if (count == positions.length) {
+          Position[] newPositions = new Position[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
+          //System.out.println("grow positions " + newPositions.length);
+          System.arraycopy(positions, nextWrite, newPositions, 0, positions.length-nextWrite);
+          System.arraycopy(positions, 0, newPositions, positions.length-nextWrite, nextWrite);
+          for(int i=positions.length;i<newPositions.length;i++) {
+            newPositions[i] = new Position();
+          }
+          nextWrite = positions.length;
+          positions = newPositions;
+        }
+        if (nextWrite == positions.length) {
+          nextWrite = 0;
+        }
+        // Should have already been reset:
+        assert positions[nextWrite].count == 0;
+        positions[nextWrite++].pos = nextPos++;
+        count++;
+      }
+      assert inBounds(pos);
+      final int index = getIndex(pos);
+      assert positions[index].pos == pos;
+      return positions[index];
+    }
+
+    public int getNextPos() {
+      return nextPos;
+    }
+
+    // For assert:
+    private boolean inBounds(int pos) {
+      return pos < nextPos && pos >= nextPos - count;
+    }
+
+    private int getIndex(int pos) {
+      int index = nextWrite - (nextPos - pos);
+      if (index < 0) {
+        index += positions.length;
+      }
+      return index;
+    }
+
+    public void freeBefore(int pos) {
+      final int toFree = count - (nextPos - pos);
+      assert toFree >= 0;
+      assert toFree <= count;
+      int index = nextWrite - count;
+      if (index < 0) {
+        index += positions.length;
+      }
+      for(int i=0;i<toFree;i++) {
+        if (index == positions.length) {
+          index = 0;
+        }
+        //System.out.println("  fb idx=" + index);
+        positions[index].reset();
+        index++;
+      }
+      count -= toFree;
+    }
+  }
+
+  /* Incrementally parse some more characters.  This runs
+   * the viterbi search forwards "enough" so that we
+   * generate some more tokens.  How much forward depends on
+   * the chars coming in, since some chars could cause
+   * longer-lasting ambiguity in the parsing.  Once the
+   * ambiguity is resolved, then we back trace, produce
+   * the pending tokens, and return. */
+  private void parse() throws IOException {
+    if (VERBOSE) {
+      System.out.println("\nPARSE");
+    }
+
+    // Advances over each position (character):
+    while (true) {
+
+      if (buffer.get(pos) == -1) {
+        // End
+        break;
+      }
+
+      final Position posData = positions.get(pos);
+      final boolean isFrontier = positions.getNextPos() == pos+1;
+
+      if (posData.count == 0) {
+        // No arcs arrive here; move to next position:
+        pos++;
+        if (VERBOSE) {
+          System.out.println("    no arcs in; skip");
+        }
+        continue;
+      }
+
+      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {
+        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {
+        // We are at a "frontier", and only one node is
+        // alive, so whatever the eventual best path is must
+        // come through this node.  So we can safely commit
+        // to the prefix of the best path at this point:
+        backtrace(posData, 0);
+
+        // Re-base cost so we don't risk int overflow:
+        posData.costs[0] = 0;
+
+        if (pending.size() != 0) {
+          return;
+        } else {
+          // This means the backtrace only produced
+          // punctuation tokens, so we must keep parsing.
+        }
+      }
+
+      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {
+        // Safety: if we've buffered too much, force a
+        // backtrace now.  We find the least-cost partial
+        // path, across all paths, backtrace from it, and
+        // then prune all others.  Note that this, in
+        // general, can produce the wrong result, if the
+        // total bast path did not in fact back trace
+        // through this partial best path.  But it's the
+        // best we can do... (short of not having a
+        // safety!).
+
+        // First pass: find least cost parital path so far,
+        // including ending at future positions:
+        int leastIDX = -1;
+        int leastCost = Integer.MAX_VALUE;
+        Position leastPosData = null;
+        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {
+          final Position posData2 = positions.get(pos2);
+          for(int idx=0;idx<posData2.count;idx++) {
+            //System.out.println("    idx=" + idx + " cost=" + cost);
+            final int cost = posData2.costs[idx];
+            if (cost < leastCost) {
+              leastCost = cost;
+              leastIDX = idx;
+              leastPosData = posData2;
+            }
+          }
+        }
+
+        // We will always have at least one live path:
+        assert leastIDX != -1;
+
+        // Second pass: prune all but the best path:
+        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {
+          final Position posData2 = positions.get(pos2);
+          if (posData2 != leastPosData) {
+            posData2.reset();
+          } else {
+            if (leastIDX != 0) {
+              posData2.costs[0] = posData2.costs[leastIDX];
+              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];
+              posData2.backPos[0] = posData2.backPos[leastIDX];
+              posData2.backIndex[0] = posData2.backIndex[leastIDX];
+              posData2.backID[0] = posData2.backID[leastIDX];
+              posData2.backType[0] = posData2.backType[leastIDX];
+            }
+            posData2.count = 1;
+          }
+        }
+
+        backtrace(leastPosData, 0);
+
+        // Re-base cost so we don't risk int overflow:
+        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);
+
+        if (pos != leastPosData.pos) {
+          // We jumped into a future position:
+          assert pos < leastPosData.pos;
+          pos = leastPosData.pos;
+        }
+
+        if (pending.size() != 0) {
+          return;
+        } else {
+          // This means the backtrace only produced
+          // punctuation tokens, so we must keep parsing.
+          continue;
+        }
+      }
+
+      if (VERBOSE) {
+        System.out.println("\n  extend @ pos=" + pos + " char=" + (char) buffer.get(pos));
+      }
+
+      if (VERBOSE) {
+        System.out.println("    " + posData.count + " arcs in");
+      }
+
+      boolean anyMatches = false;
+
+      // First try user dict:
+      if (userFST != null) {
+        userFST.getFirstArc(arc);
+        int output = 0;
+        for(int posAhead=posData.pos;;posAhead++) {
+          final int ch = buffer.get(posAhead);
+          if (ch == -1) {
+            break;
+          }
+          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {
+            break;
+          }
+          output += arc.output.intValue();
+          if (arc.isFinal()) {
+            if (VERBOSE) {
+              System.out.println("    USER word " + new String(buffer.get(pos, posAhead - pos + 1)) + " toPos=" + (posAhead + 1));
+            }
+            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);
+            anyMatches = true;
+          }
+        }
+      }
+
+      // TODO: we can be more aggressive about user
+      // matches?  if we are "under" a user match then don't
+      // extend KNOWN/UNKNOWN paths?
+
+      if (!anyMatches) {
+        // Next, try known dictionary matches
+        fst.getFirstArc(arc);
+        int output = 0;
+
+        for(int posAhead=posData.pos;;posAhead++) {
+          final int ch = buffer.get(posAhead);
+          if (ch == -1) {
+            break;
+          }
+          //System.out.println("    match " + (char) ch + " posAhead=" + posAhead);
+          
+          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {
+            break;
+          }
+
+          output += arc.output.intValue();
+
+          // Optimization: for known words that are too-long
+          // (compound), we should pre-compute the 2nd
+          // best segmentation and store it in the
+          // dictionary instead of recomputing it each time a
+          // match is found.
+
+          if (arc.isFinal()) {
+            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);
+            if (VERBOSE) {
+              System.out.println("    KNOWN word " + new String(buffer.get(pos, posAhead - pos + 1)) + " toPos=" + (posAhead + 1) + " " + wordIdRef.length + " wordIDs");
+            }
+            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {
+              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);
+              anyMatches = true;
+            }
+          }
+        }
+      }
+
+      // In the case of normal mode, it doesn't process unknown word greedily.
+
+      if (!searchMode && unknownWordEndIndex > posData.pos) {
+        pos++;
+        continue;
+      }
+
+      final char firstCharacter = (char) buffer.get(pos);
+      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {
+
+        // Find unknown match:
+        final int characterId = characterDefinition.getCharacterClass(firstCharacter);
+
+        // NOTE: copied from UnknownDictionary.lookup:
+        int unknownWordLength;
+        if (!characterDefinition.isGroup(firstCharacter)) {
+          unknownWordLength = 1;
+        } else {
+          // Extract unknown word. Characters with the same character class are considered to be part of unknown word
+          unknownWordLength = 1;
+          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {
+            final int ch = buffer.get(posAhead);
+            if (ch == -1) {
+              break;
+            }
+            if (characterId == characterDefinition.getCharacterClass((char) ch)) {
+              unknownWordLength++;    			
+            } else {
+              break;
+            }
+          }
+        }
+
+        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same
+        if (VERBOSE) {
+          System.out.println("    UNKNOWN word len=" + unknownWordLength + " " + wordIdRef.length + " wordIDs");
+        }
+        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {
+          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);
+        }
+
+        unknownWordEndIndex = posData.pos + unknownWordLength;
+      }
+
+      pos++;
+    }
+
+    end = true;
+
+    if (pos > 0) {
+
+      final Position endPosData = positions.get(pos);
+      int leastCost = Integer.MAX_VALUE;
+      int leastIDX = -1;
+      if (VERBOSE) {
+        System.out.println("  end: " + endPosData.count + " nodes");
+      }
+      for(int idx=0;idx<endPosData.count;idx++) {
+        // Add EOS cost:
+        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);
+        //System.out.println("    idx=" + idx + " cost=" + cost + " (pathCost=" + endPosData.costs[idx] + " bgCost=" + costs.get(endPosData.lastRightID[idx], 0) + ") backPos=" + endPosData.backPos[idx]);
+        if (cost < leastCost) {
+          leastCost = cost;
+          leastIDX = idx;
+        }
+      }
+
+      backtrace(endPosData, leastIDX);
+    } else {
+      // No characters in the input string; return no tokens!
+    }
+  }
+
+  // Eliminates arcs from the lattice that are compound
+  // tokens (have a penalty) or are not congruent with the
+  // compound token we've matched (ie, span across the
+  // startPos).  This should be fairly efficient, because we
+  // just keep the already intersected structure of the
+  // graph, eg we don't have to consult the FSTs again:
+
+  private void pruneAndRescore(int startPos, int endPos, int bestStartIDX) throws IOException {
+    if (VERBOSE) {
+      System.out.println("  pruneAndRescore startPos=" + startPos + " endPos=" + endPos + " bestStartIDX=" + bestStartIDX);
+    }
+
+    // First pass: walk backwards, building up the forward
+    // arcs and pruning inadmissible arcs:
+    for(int pos=endPos; pos > startPos; pos--) {
+      final Position posData = positions.get(pos);
+      if (VERBOSE) {
+        System.out.println("    back pos=" + pos);
+      }
+      for(int arcIDX=0;arcIDX<posData.count;arcIDX++) {
+        final int backPos = posData.backPos[arcIDX];
+        if (backPos >= startPos) {
+          // Keep this arc:
+          //System.out.println("      keep backPos=" + backPos);
+          positions.get(backPos).addForward(pos,
+                                            arcIDX,
+                                            posData.backID[arcIDX],
+                                            posData.backType[arcIDX]);
+        } else {
+          if (VERBOSE) {
+            System.out.println("      prune");
+          }
+        }
+      }
+      if (pos != startPos) {
+        posData.count = 0;
+      }
+    }
+
+    // Second pass: walk forward, re-scoring:
+    for(int pos=startPos; pos < endPos; pos++) {
+      final Position posData = positions.get(pos);
+      if (VERBOSE) {
+        System.out.println("    forward pos=" + pos + " count=" + posData.forwardCount);
+      }
+      if (posData.count == 0) {
+        // No arcs arrive here...
+        if (VERBOSE) {
+          System.out.println("      skip");
+        }
+        posData.forwardCount = 0;
+        continue;
+      }
+
+      if (pos == startPos) {
+        // On the initial position, only consider the best
+        // path so we "force congruence":  the
+        // sub-segmentation is "in context" of what the best
+        // path (compound token) had matched:
+        final int rightID;
+        if (startPos == 0) {
+          rightID = 0;
+        } else {
+          rightID = getDict(posData.backType[bestStartIDX]).getRightId(posData.backID[bestStartIDX]);
+        }
+        final int pathCost = posData.costs[bestStartIDX];
+        for(int forwardArcIDX=0;forwardArcIDX<posData.forwardCount;forwardArcIDX++) {
+          final Type forwardType = posData.forwardType[forwardArcIDX];
+          final Dictionary dict2 = getDict(forwardType);
+          final int wordID = posData.forwardID[forwardArcIDX];
+          final int toPos = posData.forwardPos[forwardArcIDX];
+          final int newCost = pathCost + dict2.getWordCost(wordID) + 
+            costs.get(rightID, dict2.getLeftId(wordID)) +
+            computePenalty(pos, toPos-pos);
+          if (VERBOSE) {
+            System.out.println("      + " + forwardType + " word " + new String(buffer.get(pos, toPos-pos)) + " toPos=" + toPos + " cost=" + newCost + " penalty=" + computePenalty(pos, toPos-pos) + " toPos.idx=" + positions.get(toPos).count);
+          }
+          positions.get(toPos).add(newCost,
+                                   dict2.getRightId(wordID),
+                                   pos,
+                                   bestStartIDX,
+                                   wordID,
+                                   forwardType);
+        }
+      } else {
+        // On non-initial positions, we maximize score
+        // across all arriving lastRightIDs:
+        for(int forwardArcIDX=0;forwardArcIDX<posData.forwardCount;forwardArcIDX++) {
+          final Type forwardType = posData.forwardType[forwardArcIDX];
+          final int toPos = posData.forwardPos[forwardArcIDX];
+          if (VERBOSE) {
+            System.out.println("      + " + forwardType + " word " + new String(buffer.get(pos, toPos-pos)) + " toPos=" + toPos);
+          }
+          add(getDict(forwardType),
+              posData,
+              toPos,
+              posData.forwardID[forwardArcIDX],
+              forwardType,
+              true);
+        }
+      }
+      posData.forwardCount = 0;
+    }
+  }
+
+  // Backtrace from the provided position, back to the last
+  // time we back-traced, accumulating the resulting tokens to
+  // the pending list.  The pending list is then in-reverse
+  // (last token should be returned first).
+  private void backtrace(final Position endPosData, final int fromIDX) throws IOException {
+    final int endPos = endPosData.pos;
+
+    if (VERBOSE) {
+      System.out.println("\n  backtrace: endPos=" + endPos + " pos=" + pos + "; " + (pos - lastBackTracePos) + " characters; last=" + lastBackTracePos + " cost=" + endPosData.costs[fromIDX]);
+    }
+
+    final char[] fragment = buffer.get(lastBackTracePos, endPos-lastBackTracePos);
+
+    if (dotOut != null) {
+      dotOut.onBacktrace(this, positions, lastBackTracePos, endPosData, fromIDX, fragment, end);
+    }
+
+    int pos = endPos;
+    int bestIDX = fromIDX;
+    Token altToken = null;
+
+    // We trace backwards, so this will be the leftWordID of
+    // the token after the one we are now on:
+    int lastLeftWordID = -1;
+
+    int backCount = 0;
+
+    // TODO: sort of silly to make Token instances here; the
+    // back trace has all info needed to generate the
+    // token.  So, we could just directly set the attrs,
+    // from the backtrace, in incrementToken w/o ever
+    // creating Token; we'd have to defer calling freeBefore
+    // until after the bactrace was fully "consumed" by
+    // incrementToken.
+
+    while (pos > lastBackTracePos) {
+      //System.out.println("BT: back pos=" + pos + " bestIDX=" + bestIDX);
+      final Position posData = positions.get(pos);
+      assert bestIDX < posData.count;
+
+      int backPos = posData.backPos[bestIDX];
+      assert backPos >= lastBackTracePos: "backPos=" + backPos + " vs lastBackTracePos=" + lastBackTracePos;
+      int length = pos - backPos;
+      Type backType = posData.backType[bestIDX];
+      int backID = posData.backID[bestIDX];
+      int nextBestIDX = posData.backIndex[bestIDX];
+
+      if (outputCompounds && searchMode && altToken == null && backType != Type.USER) {
+        
+        // In searchMode, if best path had picked a too-long
+        // token, we use the "penalty" to compute the allowed
+        // max cost of an alternate back-trace.  If we find an
+        // alternate back trace with cost below that
+        // threshold, we pursue it instead (but also output
+        // the long token).
+        //System.out.println("    2nd best backPos=" + backPos + " pos=" + pos);
+
+        final int penalty = computeSecondBestThreshold(backPos, pos-backPos);
+        
+        if (penalty > 0) {
+          if (VERBOSE) {
+            System.out.println("  compound=" + new String(buffer.get(backPos, pos-backPos)) + " backPos=" + backPos + " pos=" + pos + " penalty=" + penalty + " cost=" + posData.costs[bestIDX] + " bestIDX=" + bestIDX + " lastLeftID=" + lastLeftWordID);
+          }
+
+          // Use the penalty to set maxCost on the 2nd best
+          // segmentation:
+          int maxCost = posData.costs[bestIDX] + penalty;
+          if (lastLeftWordID != -1) {
+            maxCost += costs.get(getDict(backType).getRightId(backID), lastLeftWordID);
+          }
+
+          // Now, prune all too-long tokens from the graph:
+          pruneAndRescore(backPos, pos,
+                          posData.backIndex[bestIDX]);
+
+          // Finally, find 2nd best back-trace and resume
+          // backtrace there:
+          int leastCost = Integer.MAX_VALUE;
+          int leastIDX = -1;
+          for(int idx=0;idx<posData.count;idx++) {
+            int cost = posData.costs[idx];
+            //System.out.println("    idx=" + idx + " prevCost=" + cost);
+            
+            if (lastLeftWordID != -1) {
+              cost += costs.get(getDict(posData.backType[idx]).getRightId(posData.backID[idx]),
+                                lastLeftWordID);
+              //System.out.println("      += bgCost=" + costs.get(getDict(posData.backType[idx]).getRightId(posData.backID[idx]),
+              //lastLeftWordID) + " -> " + cost);
+            }
+            //System.out.println("penalty " + posData.backPos[idx] + " to " + pos);
+            //cost += computePenalty(posData.backPos[idx], pos - posData.backPos[idx]);
+            if (cost < leastCost) {
+              //System.out.println("      ** ");
+              leastCost = cost;
+              leastIDX = idx;
+            }
+          }
+          //System.out.println("  leastIDX=" + leastIDX);
+
+          if (VERBOSE) {
+            System.out.println("  afterPrune: " + posData.count + " arcs arriving; leastCost=" + leastCost + " vs threshold=" + maxCost + " lastLeftWordID=" + lastLeftWordID);
+          }
+
+          if (leastIDX != -1 && leastCost <= maxCost && posData.backPos[leastIDX] != backPos) {
+            // We should have pruned the altToken from the graph:
+            assert posData.backPos[leastIDX] != backPos;
+
+            // Save the current compound token, to output when
+            // this alternate path joins back:
+            altToken = new Token(backID,
+                                 fragment,
+                                 backPos - lastBackTracePos,
+                                 length,
+                                 backType,
+                                 backPos,
+                                 getDict(backType));
+
+            // Redirect our backtrace to 2nd best:
+            bestIDX = leastIDX;
+            nextBestIDX = posData.backIndex[bestIDX];
+
+            backPos = posData.backPos[bestIDX];
+            length = pos - backPos;
+            backType = posData.backType[bestIDX];
+            backID = posData.backID[bestIDX];
+            backCount = 0;
+            //System.out.println("  do alt token!");
+            
+          } else {
+            // I think in theory it's possible there is no
+            // 2nd best path, which is fine; in this case we
+            // only output the compound token:
+            //System.out.println("  no alt token! bestIDX=" + bestIDX);
+          }
+        }
+      }
+
+      final int offset = backPos - lastBackTracePos;
+      assert offset >= 0;
+
+      if (altToken != null && altToken.getPosition() >= backPos) {
+
+        // We've backtraced to the position where the
+        // compound token starts; add it now:
+
+        // The pruning we did when we created the altToken
+        // ensures that the back trace will align back with
+        // the start of the altToken:
+        // cannot assert...
+        //assert altToken.getPosition() == backPos: altToken.getPosition() + " vs " + backPos;
+
+        if (VERBOSE) {
+          System.out.println("    add altToken=" + altToken);
+        }
+        if (backCount > 0) {
+          backCount++;
+          altToken.setPositionLength(backCount);
+          pending.add(altToken);
+        } else {
+          // This means alt token was all punct tokens:
+          assert discardPunctuation;
+        }
+        altToken = null;
+      }
+
+      final Dictionary dict = getDict(backType);
+
+      if (backType == Type.USER) {
+
+        // Expand the phraseID we recorded into the actual
+        // segmentation:
+        final int[] wordIDAndLength = userDictionary.lookupSegmentation(backID);
+        int wordID = wordIDAndLength[0];
+        int current = 0;
+        for(int j=1; j < wordIDAndLength.length; j++) {
+          final int len = wordIDAndLength[j];
+          //System.out.println("    add user: len=" + len);
+          pending.add(new Token(wordID+j-1,
+                                fragment,
+                                current + offset,
+                                len,
+                                Type.USER,
+                                current + backPos,
+                                dict));
+          if (VERBOSE) {
+            System.out.println("    add USER token=" + pending.get(pending.size()-1));
+          }
+          current += len;
+        }
+
+        // Reverse the tokens we just added, because when we
+        // serve them up from incrementToken we serve in
+        // reverse:
+        Collections.reverse(pending.subList(pending.size() - (wordIDAndLength.length - 1),
+                                            pending.size()));
+
+        backCount += wordIDAndLength.length-1;
+      } else {
+
+        if (extendedMode && backType == Type.UNKNOWN) {
+          // In EXTENDED mode we convert unknown word into
+          // unigrams:
+          int unigramTokenCount = 0;
+          for(int i=length-1;i>=0;i--) {
+            int charLen = 1;
+            if (i > 0 && Character.isLowSurrogate(fragment[offset+i])) {
+              i--;
+              charLen = 2;
+            }
+            //System.out.println("    extended tok offset="
+            //+ (offset + i));
+            if (!discardPunctuation || !isPunctuation(fragment[offset+i])) {
+              pending.add(new Token(CharacterDefinition.NGRAM,
+                                    fragment,
+                                    offset + i,
+                                    charLen,
+                                    Type.UNKNOWN,
+                                    backPos + i,
+                                    unkDictionary));
+              unigramTokenCount++;
+            }
+          }
+          backCount += unigramTokenCount;
+          
+        } else if (!discardPunctuation || length == 0 || !isPunctuation(fragment[offset])) {
+          pending.add(new Token(backID,
+                                fragment,
+                                offset,
+                                length,
+                                backType,
+                                backPos,
+                                dict));
+          if (VERBOSE) {
+            System.out.println("    add token=" + pending.get(pending.size()-1));
+          }
+          backCount++;
+        } else {
+          if (VERBOSE) {
+            System.out.println("    skip punctuation token=" + new String(fragment, offset, length));
+          }
+        }
+      }
+
+      lastLeftWordID = dict.getLeftId(backID);
+      pos = backPos;
+      bestIDX = nextBestIDX;
+    }
+
+    lastBackTracePos = endPos;
+
+    if (VERBOSE) {
+      System.out.println("  freeBefore pos=" + endPos);
+    }
+    // Notify the circular buffers that we are done with
+    // these positions:
+    buffer.freeBefore(endPos);
+    positions.freeBefore(endPos);
+  }
+
+  Dictionary getDict(Type type) {
+    return dictionaryMap.get(type);
+  }
+
+  private static boolean isPunctuation(char ch) {
+    switch(Character.getType(ch)) {
+      case Character.SPACE_SEPARATOR:
+      case Character.LINE_SEPARATOR:
+      case Character.PARAGRAPH_SEPARATOR:
+      case Character.CONTROL:
+      case Character.FORMAT:
+      case Character.DASH_PUNCTUATION:
+      case Character.START_PUNCTUATION:
+      case Character.END_PUNCTUATION:
+      case Character.CONNECTOR_PUNCTUATION:
+      case Character.OTHER_PUNCTUATION:
+      case Character.MATH_SYMBOL:
+      case Character.CURRENCY_SYMBOL:
+      case Character.MODIFIER_SYMBOL:
+      case Character.OTHER_SYMBOL:
+      case Character.INITIAL_QUOTE_PUNCTUATION:
+      case Character.FINAL_QUOTE_PUNCTUATION:
+        return true;
+      default:
+        return false;
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
new file mode 100644
index 0000000..8b536b5
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/Token.java
@@ -0,0 +1,174 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Type;
+import org.apache.lucene.analysis.ja.dict.Dictionary;
+
+/**
+ * Analyzed token with morphological data from its dictionary.
+ */
+public class Token {
+  private final Dictionary dictionary;
+  
+  private final int wordId;
+  
+  private final char[] surfaceForm;
+  private final int offset;
+  private final int length;
+  
+  private final int position;
+  private int positionLength;
+  
+  private final Type type;
+  
+  public Token(int wordId, char[] surfaceForm, int offset, int length, Type type, int position, Dictionary dictionary) {
+    this.wordId = wordId;
+    this.surfaceForm = surfaceForm;
+    this.offset = offset;
+    this.length = length;
+    this.type = type;
+    this.position = position;
+    this.positionLength = positionLength;
+    this.dictionary = dictionary;
+  }
+
+  @Override
+  public String toString() {
+    return "Token(\"" + new String(surfaceForm, offset, length) + "\" pos=" + position + " type=" + type + " wordId=" + wordId + " leftID=" + dictionary.getLeftId(wordId) + ")";
+  }
+  
+  /**
+   * @return surfaceForm
+   */
+  public char[] getSurfaceForm() {
+    return surfaceForm;
+  }
+  
+  /**
+   * @return offset into surfaceForm
+   */
+  public int getOffset() {
+    return offset;
+  }
+  
+  /**
+   * @return length of surfaceForm
+   */
+  public int getLength() {
+    return length;
+  }
+  
+  /**
+   * @return surfaceForm as a String
+   */
+  public String getSurfaceFormString() {
+    return new String(surfaceForm, offset, length);
+  }
+  
+  /**
+   * @return reading. null if token doesn't have reading.
+   */
+  public String getReading() {
+    return dictionary.getReading(wordId, surfaceForm, offset, length);
+  }
+  
+  /**
+   * @return pronunciation. null if token doesn't have pronunciation.
+   */
+  public String getPronunciation() {
+    return dictionary.getPronunciation(wordId, surfaceForm, offset, length);
+  }
+  
+  /**
+   * @return part of speech.
+   */
+  public String getPartOfSpeech() {
+    return dictionary.getPartOfSpeech(wordId);
+  }
+  
+  /**
+   * @return inflection type or null
+   */
+  public String getInflectionType() {
+    return dictionary.getInflectionType(wordId);
+  }
+  
+  /**
+   * @return inflection form or null
+   */
+  public String getInflectionForm() {
+    return dictionary.getInflectionForm(wordId);
+  }
+  
+  /**
+   * @return base form or null if token is not inflected
+   */
+  public String getBaseForm() {
+    return dictionary.getBaseForm(wordId, surfaceForm, offset, length);
+  }
+  
+  /**
+   * Returns true if this token is known word
+   * @return true if this token is in standard dictionary. false if not.
+   */
+  public boolean isKnown() {
+    return type == Type.KNOWN;
+  }
+  
+  /**
+   * Returns true if this token is unknown word
+   * @return true if this token is unknown word. false if not.
+   */
+  public boolean isUnknown() {
+    return type == Type.UNKNOWN;
+  }
+  
+  /**
+   * Returns true if this token is defined in user dictionary
+   * @return true if this token is in user dictionary. false if not.
+   */
+  public boolean isUser() {
+    return type == Type.USER;
+  }
+  
+  /**
+   * Get index of this token in input text
+   * @return position of token
+   */
+  public int getPosition() {
+    return position;
+  }
+
+  /**
+   * Set the position length (in tokens) of this token.  For normal
+   * tokens this is 1; for compound tokens it's > 1.
+   */
+  public void setPositionLength(int positionLength) {
+    this.positionLength = positionLength;
+  }
+  
+  /**
+   * Get the length (in tokens) of this token.  For normal
+   * tokens this is 1; for compound tokens it's > 1.
+   * @return position length of token
+   */
+  public int getPositionLength() {
+    return positionLength;
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/BinaryDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/BinaryDictionary.java
new file mode 100644
index 0000000..8b1437d
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/BinaryDictionary.java
@@ -0,0 +1,295 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedInputStream;
+import java.io.EOFException;
+import java.io.IOException;
+import java.io.FileNotFoundException;
+import java.io.InputStream;
+import java.nio.ByteBuffer;
+import java.nio.channels.Channels;
+import java.nio.channels.ReadableByteChannel;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.InputStreamDataInput;
+import org.apache.lucene.util.CodecUtil;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * Base class for a binary-encoded in-memory dictionary.
+ */
+public abstract class BinaryDictionary implements Dictionary {
+  
+  public static final String DICT_FILENAME_SUFFIX = "$buffer.dat";
+  public static final String TARGETMAP_FILENAME_SUFFIX = "$targetMap.dat";
+  public static final String POSDICT_FILENAME_SUFFIX = "$posDict.dat";
+  
+  public static final String DICT_HEADER = "kuromoji_dict";
+  public static final String TARGETMAP_HEADER = "kuromoji_dict_map";
+  public static final String POSDICT_HEADER = "kuromoji_dict_pos";
+  public static final int VERSION = 1;
+  
+  private final ByteBuffer buffer;
+  private final int[] targetMapOffsets, targetMap;
+  private final String[] posDict;
+  private final String[] inflTypeDict;
+  private final String[] inflFormDict;
+  
+  protected BinaryDictionary() throws IOException {
+    InputStream mapIS = null, dictIS = null, posIS = null;
+    IOException priorE = null;
+    int[] targetMapOffsets = null, targetMap = null;
+    String[] posDict = null;
+    String[] inflFormDict = null;
+    String[] inflTypeDict = null;
+    ByteBuffer buffer = null;
+    try {
+      mapIS = getResource(TARGETMAP_FILENAME_SUFFIX);
+      mapIS = new BufferedInputStream(mapIS);
+      DataInput in = new InputStreamDataInput(mapIS);
+      CodecUtil.checkHeader(in, TARGETMAP_HEADER, VERSION, VERSION);
+      targetMap = new int[in.readVInt()];
+      targetMapOffsets = new int[in.readVInt()];
+      int accum = 0, sourceId = 0;
+      for (int ofs = 0; ofs < targetMap.length; ofs++) {
+        final int val = in.readVInt();
+        if ((val & 0x01) != 0) {
+          targetMapOffsets[sourceId] = ofs;
+          sourceId++;
+        }
+        accum += val >>> 1;
+        targetMap[ofs] = accum;
+      }
+      if (sourceId + 1 != targetMapOffsets.length)
+        throw new IOException("targetMap file format broken");
+      targetMapOffsets[sourceId] = targetMap.length;
+      mapIS.close(); mapIS = null;
+      
+      posIS = getResource(POSDICT_FILENAME_SUFFIX);
+      posIS = new BufferedInputStream(posIS);
+      in = new InputStreamDataInput(posIS);
+      CodecUtil.checkHeader(in, POSDICT_HEADER, VERSION, VERSION);
+      int posSize = in.readVInt();
+      posDict = new String[posSize];
+      inflTypeDict = new String[posSize];
+      inflFormDict = new String[posSize];
+      for (int j = 0; j < posSize; j++) {
+        posDict[j] = in.readString();
+        inflTypeDict[j] = in.readString();
+        inflFormDict[j] = in.readString();
+        // this is how we encode null inflections
+        if (inflTypeDict[j].length() == 0) {
+          inflTypeDict[j] = null;
+        }
+        if (inflFormDict[j].length() == 0) {
+          inflFormDict[j] = null;
+        }
+      }
+      posIS.close(); posIS = null;
+      
+      dictIS = getResource(DICT_FILENAME_SUFFIX);
+      // no buffering here, as we load in one large buffer
+      in = new InputStreamDataInput(dictIS);
+      CodecUtil.checkHeader(in, DICT_HEADER, VERSION, VERSION);
+      final int size = in.readVInt();
+      final ByteBuffer tmpBuffer = ByteBuffer.allocateDirect(size);
+      final ReadableByteChannel channel = Channels.newChannel(dictIS);
+      final int read = channel.read(tmpBuffer);
+      if (read != size) {
+        throw new EOFException("Cannot read whole dictionary");
+      }
+      dictIS.close(); dictIS = null;
+      buffer = tmpBuffer.asReadOnlyBuffer();
+    } catch (IOException ioe) {
+      priorE = ioe;
+    } finally {
+      IOUtils.closeWhileHandlingException(priorE, mapIS, posIS, dictIS);
+    }
+    
+    this.targetMap = targetMap;
+    this.targetMapOffsets = targetMapOffsets;
+    this.posDict = posDict;
+    this.inflTypeDict = inflTypeDict;
+    this.inflFormDict = inflFormDict;
+    this.buffer = buffer;
+  }
+  
+  protected final InputStream getResource(String suffix) throws IOException {
+    return getClassResource(getClass(), suffix);
+  }
+  
+  // util, reused by ConnectionCosts and CharacterDefinition
+  public static final InputStream getClassResource(Class<?> clazz, String suffix) throws IOException {
+    final InputStream is = clazz.getResourceAsStream(clazz.getSimpleName() + suffix);
+    if (is == null)
+      throw new FileNotFoundException("Not in classpath: " + clazz.getName().replace('.','/') + suffix);
+    return is;
+  }
+  
+  public void lookupWordIds(int sourceId, IntsRef ref) {
+    ref.ints = targetMap;
+    ref.offset = targetMapOffsets[sourceId];
+    // targetMapOffsets always has one more entry pointing behind last:
+    ref.length = targetMapOffsets[sourceId + 1] - ref.offset;
+  }
+  
+  @Override	
+  public int getLeftId(int wordId) {
+    return buffer.getShort(wordId) >>> 3;
+  }
+  
+  @Override
+  public int getRightId(int wordId) {
+    return buffer.getShort(wordId) >>> 3;
+  }
+  
+  @Override
+  public int getWordCost(int wordId) {
+    return buffer.getShort(wordId + 2);	// Skip id
+  }
+
+  @Override
+  public String getBaseForm(int wordId, char surfaceForm[], int off, int len) {
+    if (hasBaseFormData(wordId)) {
+      int offset = baseFormOffset(wordId);
+      int data = buffer.get(offset++) & 0xff;
+      int prefix = data >>> 4;
+      int suffix = data & 0xF;
+      char text[] = new char[prefix+suffix];
+      System.arraycopy(surfaceForm, off, text, 0, prefix);
+      for (int i = 0; i < suffix; i++) {
+        text[prefix+i] = buffer.getChar(offset + (i << 1));
+      }
+      return new String(text);
+    } else {
+      return null;
+    }
+  }
+  
+  @Override
+  public String getReading(int wordId, char surface[], int off, int len) {
+    if (hasReadingData(wordId)) {
+      int offset = readingOffset(wordId);
+      int readingData = buffer.get(offset++) & 0xff;
+      return readString(offset, readingData >>> 1, (readingData & 1) == 1);
+    } else {
+      // the reading is the surface form, with hiragana shifted to katakana
+      char text[] = new char[len];
+      for (int i = 0; i < len; i++) {
+        char ch = surface[off+i];
+        if (ch > 0x3040 && ch < 0x3097) {
+          text[i] = (char)(ch + 0x60);
+        } else {
+          text[i] = ch;
+        }
+      }
+      return new String(text);
+    }
+  }
+  
+  @Override
+  public String getPartOfSpeech(int wordId) {
+    return posDict[getLeftId(wordId)];
+  }
+  
+  @Override
+  public String getPronunciation(int wordId, char surface[], int off, int len) {
+    if (hasPronunciationData(wordId)) {
+      int offset = pronunciationOffset(wordId);
+      int pronunciationData = buffer.get(offset++) & 0xff;
+      return readString(offset, pronunciationData >>> 1, (pronunciationData & 1) == 1);
+    } else {
+      return getReading(wordId, surface, off, len); // same as the reading
+    }
+  }
+  
+  @Override
+  public String getInflectionType(int wordId) {
+    return inflTypeDict[getLeftId(wordId)];
+  }
+
+  @Override
+  public String getInflectionForm(int wordId) {
+    return inflFormDict[getLeftId(wordId)];
+  }
+  
+  private static int baseFormOffset(int wordId) {
+    return wordId + 4;
+  }
+  
+  private int readingOffset(int wordId) {
+    int offset = baseFormOffset(wordId);
+    if (hasBaseFormData(wordId)) {
+      int baseFormLength = buffer.get(offset++) & 0xf;
+      return offset + (baseFormLength << 1);
+    } else {
+      return offset;
+    }
+  }
+  
+  private int pronunciationOffset(int wordId) {
+    if (hasReadingData(wordId)) {
+      int offset = readingOffset(wordId);
+      int readingData = buffer.get(offset++) & 0xff;
+      final int readingLength;
+      if ((readingData & 1) == 0) {
+        readingLength = readingData & 0xfe; // UTF-16: mask off kana bit
+      } else {
+        readingLength = readingData >>> 1;
+      }
+      return offset + readingLength;
+    } else {
+      return readingOffset(wordId);
+    }
+  }
+  
+  private boolean hasBaseFormData(int wordId) {
+    return (buffer.getShort(wordId) & HAS_BASEFORM) != 0;
+  }
+  
+  private boolean hasReadingData(int wordId) {
+    return (buffer.getShort(wordId) & HAS_READING) != 0;
+  }
+  
+  private boolean hasPronunciationData(int wordId) {
+    return (buffer.getShort(wordId) & HAS_PRONUNCIATION) != 0;
+  }
+  
+  private String readString(int offset, int length, boolean kana) {
+    char text[] = new char[length];
+    if (kana) {
+      for (int i = 0; i < length; i++) {
+        text[i] = (char) (0x30A0 + (buffer.get(offset + i) & 0xff));
+      }
+    } else {
+      for (int i = 0; i < length; i++) {
+        text[i] = buffer.getChar(offset + (i << 1));
+      }
+    }
+    return new String(text);
+  }
+  
+  /** flag that the entry has baseform data. otherwise its not inflected (same as surface form) */
+  public static final int HAS_BASEFORM = 1;
+  /** flag that the entry has reading data. otherwise reading is surface form converted to katakana */
+  public static final int HAS_READING = 2;
+  /** flag that the entry has pronunciation data. otherwise pronunciation is the reading */
+  public static final int HAS_PRONUNCIATION = 4;
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/CharacterDefinition.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/CharacterDefinition.java
new file mode 100644
index 0000000..1a61e7a
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/CharacterDefinition.java
@@ -0,0 +1,120 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.InputStreamDataInput;
+import org.apache.lucene.util.CodecUtil;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * Character category data.
+ */
+public final class CharacterDefinition {
+
+  public static final String FILENAME_SUFFIX = ".dat";
+  public static final String HEADER = "kuromoji_cd";
+  public static final int VERSION = 1;
+
+  public static final int CLASS_COUNT = CharacterClass.values().length;
+  
+  // only used internally for lookup:
+  private static enum CharacterClass {
+    NGRAM, DEFAULT, SPACE, SYMBOL, NUMERIC, ALPHA, CYRILLIC, GREEK, HIRAGANA, KATAKANA, KANJI, KANJINUMERIC;
+  }
+      
+  private final byte[] characterCategoryMap = new byte[0x10000];
+  
+  private final boolean[] invokeMap = new boolean[CLASS_COUNT];
+  private final boolean[] groupMap = new boolean[CLASS_COUNT];
+  
+  // the classes:
+  public static final byte NGRAM = (byte) CharacterClass.NGRAM.ordinal();
+  public static final byte DEFAULT = (byte) CharacterClass.DEFAULT.ordinal();
+  public static final byte SPACE = (byte) CharacterClass.SPACE.ordinal();
+  public static final byte SYMBOL = (byte) CharacterClass.SYMBOL.ordinal();
+  public static final byte NUMERIC = (byte) CharacterClass.NUMERIC.ordinal();
+  public static final byte ALPHA = (byte) CharacterClass.ALPHA.ordinal();
+  public static final byte CYRILLIC = (byte) CharacterClass.CYRILLIC.ordinal();
+  public static final byte GREEK = (byte) CharacterClass.GREEK.ordinal();
+  public static final byte HIRAGANA = (byte) CharacterClass.HIRAGANA.ordinal();
+  public static final byte KATAKANA = (byte) CharacterClass.KATAKANA.ordinal();
+  public static final byte KANJI = (byte) CharacterClass.KANJI.ordinal();
+  public static final byte KANJINUMERIC = (byte) CharacterClass.KANJINUMERIC.ordinal();
+  
+  private CharacterDefinition() throws IOException {
+    IOException priorE = null;
+    InputStream is = null;
+    try {
+      is = BinaryDictionary.getClassResource(getClass(), FILENAME_SUFFIX);
+      is = new BufferedInputStream(is);
+      final DataInput in = new InputStreamDataInput(is);
+      CodecUtil.checkHeader(in, HEADER, VERSION, VERSION);
+      in.readBytes(characterCategoryMap, 0, characterCategoryMap.length);
+      for (int i = 0; i < CLASS_COUNT; i++) {
+        final byte b = in.readByte();
+        invokeMap[i] = (b & 0x01) != 0;
+        groupMap[i] = (b & 0x02) != 0;
+      }
+    } catch (IOException ioe) {
+      priorE = ioe;
+    } finally {
+      IOUtils.closeWhileHandlingException(priorE, is);
+    }
+  }
+  
+  public byte getCharacterClass(char c) {
+    return characterCategoryMap[c];
+  }
+  
+  public boolean isInvoke(char c) {
+    return invokeMap[characterCategoryMap[c]];
+  }
+  
+  public boolean isGroup(char c) {
+    return groupMap[characterCategoryMap[c]];
+  }
+  
+  public boolean isKanji(char c) {
+    final byte characterClass = characterCategoryMap[c];
+    return characterClass == KANJI || characterClass == KANJINUMERIC;
+  }
+  
+  public static byte lookupCharacterClass(String characterClassName) {
+    return (byte) CharacterClass.valueOf(characterClassName).ordinal();
+  }
+
+  public static CharacterDefinition getInstance() {
+    return SingletonHolder.INSTANCE;
+  }
+  
+  private static class SingletonHolder {
+    static final CharacterDefinition INSTANCE;
+    static {
+      try {
+        INSTANCE = new CharacterDefinition();
+      } catch (IOException ioe) {
+        throw new RuntimeException("Cannot load CharacterDefinition.", ioe);
+      }
+    }
+   }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/ConnectionCosts.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/ConnectionCosts.java
new file mode 100644
index 0000000..42151ed
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/ConnectionCosts.java
@@ -0,0 +1,89 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.apache.lucene.store.DataInput;
+import org.apache.lucene.store.InputStreamDataInput;
+import org.apache.lucene.util.CodecUtil;
+import org.apache.lucene.util.IOUtils;
+
+/**
+ * n-gram connection cost data
+ */
+public final class ConnectionCosts {
+  
+  public static final String FILENAME_SUFFIX = ".dat";
+  public static final String HEADER = "kuromoji_cc";
+  public static final int VERSION = 1;
+  
+  private final short[][] costs; // array is backward IDs first since get is called using the same backward ID consecutively. maybe doesn't matter.
+  
+  private ConnectionCosts() throws IOException {
+    IOException priorE = null;
+    InputStream is = null;
+    short[][] costs = null;
+    try {
+      is = BinaryDictionary.getClassResource(getClass(), FILENAME_SUFFIX);
+      is = new BufferedInputStream(is);
+      final DataInput in = new InputStreamDataInput(is);
+      CodecUtil.checkHeader(in, HEADER, VERSION, VERSION);
+      int forwardSize = in.readVInt();
+      int backwardSize = in.readVInt();
+      costs = new short[backwardSize][forwardSize];
+      int accum = 0;
+      for (int j = 0; j < costs.length; j++) {
+        final short[] a = costs[j];
+        for (int i = 0; i < a.length; i++) {
+          int raw = in.readVInt();
+          accum += (raw >>> 1) ^ -(raw & 1);
+          a[i] = (short)accum;
+        }
+      }
+    } catch (IOException ioe) {
+      priorE = ioe;
+    } finally {
+      IOUtils.closeWhileHandlingException(priorE, is);
+    }
+    
+    this.costs = costs;
+  }
+  
+  public int get(int forwardId, int backwardId) {
+    return costs[backwardId][forwardId];
+  }
+  
+  public static ConnectionCosts getInstance() {
+    return SingletonHolder.INSTANCE;
+  }
+  
+  private static class SingletonHolder {
+    static final ConnectionCosts INSTANCE;
+    static {
+      try {
+        INSTANCE = new ConnectionCosts();
+      } catch (IOException ioe) {
+        throw new RuntimeException("Cannot load ConnectionCosts.", ioe);
+      }
+    }
+   }
+  
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/Dictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/Dictionary.java
new file mode 100644
index 0000000..9a47436
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/Dictionary.java
@@ -0,0 +1,92 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Dictionary interface for retrieving morphological data
+ * by id.
+ */
+public interface Dictionary {
+  
+  public static final String INTERNAL_SEPARATOR = "\u0000";
+  
+  /**
+   * Get left id of specified word
+   * @param wordId
+   * @return	left id
+   */
+  public int getLeftId(int wordId);
+  
+  /**
+   * Get right id of specified word
+   * @param wordId
+   * @return	left id
+   */
+  public int getRightId(int wordId);
+  
+  /**
+   * Get word cost of specified word
+   * @param wordId
+   * @return	left id
+   */
+  public int getWordCost(int wordId);
+  
+  /**
+   * Get Part-Of-Speech of tokens
+   * @param wordId word ID of token
+   * @return Part-Of-Speech of the token
+   */
+  public String getPartOfSpeech(int wordId);
+  
+  /**
+   * Get reading of tokens
+   * @param wordId word ID of token
+   * @return Reading of the token
+   */
+  public String getReading(int wordId, char surface[], int off, int len);
+  
+  /**
+   * Get base form of word
+   * @param wordId word ID of token
+   * @return Base form (only different for inflected words, otherwise null)
+   */
+  public String getBaseForm(int wordId, char surface[], int off, int len);
+  
+  /**
+   * Get pronunciation of tokens
+   * @param wordId word ID of token
+   * @return Pronunciation of the token
+   */
+  public String getPronunciation(int wordId, char surface[], int off, int len);
+  
+  /**
+   * Get inflection type of tokens
+   * @param wordId word ID of token
+   * @return inflection type, or null
+   */
+  public String getInflectionType(int wordId);
+  
+  /**
+   * Get inflection form of tokens
+   * @param wordId word ID of token
+   * @return inflection form, or null
+   */
+  public String getInflectionForm(int wordId);
+  // TODO: maybe we should have a optimal method, a non-typesafe
+  // 'getAdditionalData' if other dictionaries like unidic have additional data
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary.java
new file mode 100644
index 0000000..08e43d4
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary.java
@@ -0,0 +1,76 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedInputStream;
+import java.io.InputStream;
+import java.io.IOException;
+
+import org.apache.lucene.store.InputStreamDataInput;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
+
+/**
+ * Binary dictionary implementation for a known-word dictionary model:
+ * Words are encoded into an FST mapping to a list of wordIDs.
+ */
+public final class TokenInfoDictionary extends BinaryDictionary {
+
+  public static final String FST_FILENAME_SUFFIX = "$fst.dat";
+
+  private final TokenInfoFST fst;
+  
+  private TokenInfoDictionary() throws IOException {
+    super();
+    IOException priorE = null;
+    InputStream is = null;
+    FST<Long> fst = null;
+    try {
+      is = getResource(FST_FILENAME_SUFFIX);
+      is = new BufferedInputStream(is);
+      fst = new FST<Long>(new InputStreamDataInput(is), PositiveIntOutputs.getSingleton(true));
+    } catch (IOException ioe) {
+      priorE = ioe;
+    } finally {
+      IOUtils.closeWhileHandlingException(priorE, is);
+    }
+    // TODO: some way to configure?
+    this.fst = new TokenInfoFST(fst, true);
+  }
+  
+  public TokenInfoFST getFST() {
+    return fst;
+  }
+   
+  public static TokenInfoDictionary getInstance() {
+    return SingletonHolder.INSTANCE;
+  }
+  
+  private static class SingletonHolder {
+    static final TokenInfoDictionary INSTANCE;
+    static {
+      try {
+        INSTANCE = new TokenInfoDictionary();
+      } catch (IOException ioe) {
+        throw new RuntimeException("Cannot load TokenInfoDictionary.", ioe);
+      }
+    }
+   }
+  
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoFST.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoFST.java
new file mode 100644
index 0000000..c87788d
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/TokenInfoFST.java
@@ -0,0 +1,94 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.FST.Arc;
+
+/**
+ * Thin wrapper around an FST with root-arc caching for Japanese.
+ * <p>
+ * Depending upon fasterButMoreRam, either just kana (191 arcs),
+ * or kana and han (28,607 arcs) are cached. The latter offers
+ * additional performance at the cost of more RAM.
+ */
+public final class TokenInfoFST {
+  private final FST<Long> fst;
+
+  // depending upon fasterButMoreRam, we cache root arcs for either 
+  // kana (0x3040-0x30FF) or kana + han (0x3040-0x9FFF)
+  // false: 191 arcs
+  // true:  28,607 arcs (costs ~1.5MB)
+  private final int cacheCeiling;
+  private final FST.Arc<Long> rootCache[];
+  
+  public final Long NO_OUTPUT;
+
+  public TokenInfoFST(FST<Long> fst, boolean fasterButMoreRam) throws IOException {
+    this.fst = fst;
+    this.cacheCeiling = fasterButMoreRam ? 0x9FFF : 0x30FF;
+    NO_OUTPUT = fst.outputs.getNoOutput();
+    rootCache = cacheRootArcs();
+  }
+  
+  @SuppressWarnings("unchecked")
+  private FST.Arc<Long>[] cacheRootArcs() throws IOException {
+    FST.Arc<Long> rootCache[] = new FST.Arc[1+(cacheCeiling-0x3040)];
+    FST.Arc<Long> firstArc = new FST.Arc<Long>();
+    fst.getFirstArc(firstArc);
+    FST.Arc<Long> arc = new FST.Arc<Long>();
+    final FST.BytesReader fstReader = fst.getBytesReader(0);
+    // TODO: jump to 3040, readNextRealArc to ceiling? (just be careful we don't add bugs)
+    for (int i = 0; i < rootCache.length; i++) {
+      if (fst.findTargetArc(0x3040 + i, firstArc, arc, fstReader) != null) {
+        rootCache[i] = new FST.Arc<Long>().copyFrom(arc);
+      }
+    }
+    return rootCache;
+  }
+  
+  public FST.Arc<Long> findTargetArc(int ch, FST.Arc<Long> follow, FST.Arc<Long> arc, boolean useCache, FST.BytesReader fstReader) throws IOException {
+    if (useCache && ch >= 0x3040 && ch <= cacheCeiling) {
+      assert ch != FST.END_LABEL;
+      final Arc<Long> result = rootCache[ch - 0x3040];
+      if (result == null) {
+        return null;
+      } else {
+        arc.copyFrom(result);
+        return arc;
+      }
+    } else {
+      return fst.findTargetArc(ch, follow, arc, fstReader);
+    }
+  }
+  
+  public Arc<Long> getFirstArc(FST.Arc<Long> arc) {
+    return fst.getFirstArc(arc);
+  }
+
+  public FST.BytesReader getBytesReader(int pos) {
+    return fst.getBytesReader(pos);
+  }
+  
+  /** @lucene.internal for testing only */
+  FST<Long> getInternalFST() {
+    return fst;
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UnknownDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UnknownDictionary.java
new file mode 100644
index 0000000..feedb27
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UnknownDictionary.java
@@ -0,0 +1,86 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+/**
+ * Dictionary for unknown-word handling.
+ */
+public final class UnknownDictionary extends BinaryDictionary {
+
+  private final CharacterDefinition characterDefinition = CharacterDefinition.getInstance();
+  
+  private UnknownDictionary() throws IOException {
+    super();
+  }
+  
+  public int lookup(char[] text, int offset, int len) {
+    if(!characterDefinition.isGroup(text[offset])) {
+      return 1;
+    }
+    
+    // Extract unknown word. Characters with the same character class are considered to be part of unknown word
+    byte characterIdOfFirstCharacter = characterDefinition.getCharacterClass(text[offset]);
+    int length = 1;
+    for (int i = 1; i < len; i++) {
+      if (characterIdOfFirstCharacter == characterDefinition.getCharacterClass(text[offset+i])){
+        length++;    			
+      } else {
+        break;
+      }
+    }
+    
+    return length;
+  }
+  
+  public CharacterDefinition getCharacterDefinition() {
+    return characterDefinition;
+  }
+  
+  @Override
+  public String getReading(int wordId, char surface[], int off, int len) {
+    return null;
+  }
+
+  @Override
+  public String getInflectionType(int wordId) {
+    return null;
+  }
+
+  @Override
+  public String getInflectionForm(int wordId) {
+    return null;
+  }
+
+  public static UnknownDictionary getInstance() {
+    return SingletonHolder.INSTANCE;
+  }
+  
+  private static class SingletonHolder {
+    static final UnknownDictionary INSTANCE;
+    static {
+      try {
+        INSTANCE = new UnknownDictionary();
+      } catch (IOException ioe) {
+        throw new RuntimeException("Cannot load UnknownDictionary.", ioe);
+      }
+    }
+   }
+  
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java
new file mode 100644
index 0000000..75181ae
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/UserDictionary.java
@@ -0,0 +1,272 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.Reader;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+import java.util.Map;
+import java.util.TreeMap;
+
+import org.apache.lucene.analysis.ja.util.CSVUtil;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
+
+/**
+ * Class for building a User Dictionary.
+ * This class allows for custom segmentation of phrases.
+ */
+public final class UserDictionary implements Dictionary {
+  
+  // phrase text -> phrase ID
+  private final TokenInfoFST fst;
+  
+  // holds wordid, length, length... indexed by phrase ID
+  private final int segmentations[][];
+  
+  // holds readings and POS, indexed by wordid
+  private final String data[];
+  
+  private static final int CUSTOM_DICTIONARY_WORD_ID_OFFSET = 100000000;
+  
+  public static final int WORD_COST = -100000;
+  
+  public static final int LEFT_ID = 5;
+  
+  public static final int RIGHT_ID = 5;
+  
+  public UserDictionary(Reader reader) throws IOException {
+    BufferedReader br = new BufferedReader(reader);
+    String line = null;
+    int wordId = CUSTOM_DICTIONARY_WORD_ID_OFFSET;
+    List<String[]> featureEntries = new ArrayList<String[]>();
+ 
+    // text, segmentation, readings, POS
+    while ((line = br.readLine()) != null) {
+      // Remove comments
+      line = line.replaceAll("#.*$", "");
+      
+      // Skip empty lines or comment lines
+      if (line.trim().length() == 0) {
+        continue;
+      }
+      String[] values = CSVUtil.parse(line);
+      featureEntries.add(values);
+    }
+    
+    // TODO: should we allow multiple segmentations per input 'phrase'?
+    // the old treemap didn't support this either, and i'm not sure if its needed/useful?
+
+    Collections.sort(featureEntries, new Comparator<String[]>() {
+      @Override
+      public int compare(String[] left, String[] right) {
+        return left[0].compareTo(right[0]);
+     }
+    });
+    
+    List<String> data = new ArrayList<String>(featureEntries.size());
+    List<int[]> segmentations = new ArrayList<int[]>(featureEntries.size());
+    
+    PositiveIntOutputs fstOutput = PositiveIntOutputs.getSingleton(true);
+    Builder<Long> fstBuilder = new Builder<Long>(FST.INPUT_TYPE.BYTE2, fstOutput);
+    IntsRef scratch = new IntsRef();
+    long ord = 0;
+    
+    for (String[] values : featureEntries) {
+      String[] segmentation = values[1].replaceAll("  *", " ").split(" ");
+      String[] readings = values[2].replaceAll("  *", " ").split(" ");
+      String pos = values[3];
+      
+      if (segmentation.length != readings.length) {
+        // FIXME: Should probably deal with this differently.  Exception?
+        System.out.println("This entry is not properly formatted : " + line);
+      }
+      
+      int[] wordIdAndLength = new int[segmentation.length + 1]; // wordId offset, length, length....
+      wordIdAndLength[0] = wordId;
+      for (int i = 0; i < segmentation.length; i++) {
+        wordIdAndLength[i + 1] = segmentation[i].length();
+        data.add(readings[i] + INTERNAL_SEPARATOR + pos);
+        wordId++;
+      }
+      // add mapping to FST
+      String token = values[0];
+      scratch.grow(token.length());
+      scratch.length = token.length();
+      for (int i = 0; i < token.length(); i++) {
+        scratch.ints[i] = (int) token.charAt(i);
+      }
+      fstBuilder.add(scratch, ord);
+      segmentations.add(wordIdAndLength);
+      ord++;
+    }
+    this.fst = new TokenInfoFST(fstBuilder.finish(), false);
+    this.data = data.toArray(new String[data.size()]);
+    this.segmentations = segmentations.toArray(new int[segmentations.size()][]);
+  }
+  
+  /**
+   * Lookup words in text
+   * @param chars text
+   * @param off offset into text
+   * @param len length of text
+   * @return array of {wordId, position, length}
+   */
+  public int[][] lookup(char[] chars, int off, int len) throws IOException {
+    // TODO: can we avoid this treemap/toIndexArray?
+    TreeMap<Integer, int[]> result = new TreeMap<Integer, int[]>(); // index, [length, length...]
+    boolean found = false; // true if we found any results
+
+    final FST.BytesReader fstReader = fst.getBytesReader(0);
+
+    FST.Arc<Long> arc = new FST.Arc<Long>();
+    int end = off + len;
+    for (int startOffset = off; startOffset < end; startOffset++) {
+      arc = fst.getFirstArc(arc);
+      int output = 0;
+      int remaining = end - startOffset;
+      for (int i = 0; i < remaining; i++) {
+        int ch = chars[startOffset+i];
+        if (fst.findTargetArc(ch, arc, arc, i == 0, fstReader) == null) {
+          break; // continue to next position
+        }
+        output += arc.output.intValue();
+        if (arc.isFinal()) {
+          final int finalOutput = output + arc.nextFinalOutput.intValue();
+          result.put(startOffset-off, segmentations[finalOutput]);
+          found = true;
+        }
+      }
+    }
+    
+    return found ? toIndexArray(result) : EMPTY_RESULT;
+  }
+  
+  public TokenInfoFST getFST() {
+    return fst;
+  }
+
+  private static final int[][] EMPTY_RESULT = new int[0][];
+  
+  /**
+   * Convert Map of index and wordIdAndLength to array of {wordId, index, length}
+   * @param input
+   * @return array of {wordId, index, length}
+   */
+  private int[][] toIndexArray(Map<Integer, int[]> input) {
+    ArrayList<int[]> result = new ArrayList<int[]>();
+    for (int i : input.keySet()) {
+      int[] wordIdAndLength = input.get(i);
+      int wordId = wordIdAndLength[0];
+      // convert length to index
+      int current = i;
+      for (int j = 1; j < wordIdAndLength.length; j++) { // first entry is wordId offset
+        int[] token = { wordId + j - 1, current, wordIdAndLength[j] };
+        result.add(token);
+        current += wordIdAndLength[j];
+      }
+    }
+    return result.toArray(new int[result.size()][]);
+  }
+
+  public int[] lookupSegmentation(int phraseID) {
+    return segmentations[phraseID];
+  }
+  
+  @Override
+  public int getLeftId(int wordId) {
+    return LEFT_ID;
+  }
+  
+  @Override
+  public int getRightId(int wordId) {
+    return RIGHT_ID;
+  }
+  
+  @Override
+  public int getWordCost(int wordId) {
+    return WORD_COST;
+  }
+  
+  @Override
+  public String getReading(int wordId, char surface[], int off, int len) {
+    return getFeature(wordId, 0);
+  }
+  
+  @Override
+  public String getPartOfSpeech(int wordId) {
+    return getFeature(wordId, 1);
+  }
+  
+  @Override
+  public String getBaseForm(int wordId, char surface[], int off, int len) {
+    return null; // TODO: add support?
+  }
+  
+  @Override
+  public String getPronunciation(int wordId, char surface[], int off, int len) {
+    return null; // TODO: add support?
+  }
+  
+  @Override
+  public String getInflectionType(int wordId) {
+    return null; // TODO: add support?
+  }
+
+  @Override
+  public String getInflectionForm(int wordId) {
+    return null; // TODO: add support?
+  }
+  
+  private String[] getAllFeaturesArray(int wordId) {
+    String allFeatures = data[wordId-CUSTOM_DICTIONARY_WORD_ID_OFFSET];
+    if(allFeatures == null) {
+      return null;
+    }
+    
+    return allFeatures.split(INTERNAL_SEPARATOR);		
+  }
+  
+  
+  private String getFeature(int wordId, int... fields) {
+    String[] allFeatures = getAllFeaturesArray(wordId);
+    if (allFeatures == null) {
+      return null;
+    }
+    StringBuilder sb = new StringBuilder();
+    if (fields.length == 0) { // All features
+      for (String feature : allFeatures) {
+        sb.append(CSVUtil.quoteEscape(feature)).append(",");
+      }
+    } else if (fields.length == 1) { // One feature doesn't need to escape value
+      sb.append(allFeatures[fields[0]]).append(",");			
+    } else {
+      for (int field : fields){
+        sb.append(CSVUtil.quoteEscape(allFeatures[field])).append(",");
+      }
+    }
+    return sb.deleteCharAt(sb.length() - 1).toString();
+  }
+  
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/package.html
new file mode 100644
index 0000000..10b3f38
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/dict/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Kuromoji dictionary implementation.
+</body>
+</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/package.html
new file mode 100644
index 0000000..116bdca
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Analyzer for Japanese.
+</body>
+</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttribute.java
new file mode 100644
index 0000000..318fa25
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttribute.java
@@ -0,0 +1,32 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.util.Attribute;
+
+/**
+ * Attribute for {@link Token#getBaseForm()}.
+ * <p>
+ * Note: depending on part of speech, this value may not be applicable,
+ * and will be null.
+ */
+public interface BaseFormAttribute extends Attribute {
+  public String getBaseForm();
+  public void setToken(Token token);
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttributeImpl.java
new file mode 100644
index 0000000..24fbdd6
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/BaseFormAttributeImpl.java
@@ -0,0 +1,53 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+
+/**
+ * Attribute for {@link Token#getBaseForm()}.
+ */
+public class BaseFormAttributeImpl extends AttributeImpl implements BaseFormAttribute, Cloneable {
+  private Token token;
+  
+  public String getBaseForm() {
+    return token == null ? null : token.getBaseForm();
+  }
+  
+  public void setToken(Token token) {
+    this.token = token;
+  }
+
+  @Override
+  public void clear() {
+    token = null;
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    BaseFormAttribute t = (BaseFormAttribute) target;
+    t.setToken(token);
+  }
+  
+  @Override
+  public void reflectWith(AttributeReflector reflector) {
+    reflector.reflect(BaseFormAttribute.class, "baseForm", getBaseForm());
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttribute.java
new file mode 100644
index 0000000..255070e
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttribute.java
@@ -0,0 +1,33 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.util.Attribute;
+
+/**
+ * Attribute for Kuromoji inflection data.
+ * <p>
+ * Note: in some cases this value may not be applicable,
+ * and will be null.
+ */
+public interface InflectionAttribute extends Attribute {
+  public String getInflectionType();
+  public String getInflectionForm();
+  public void setToken(Token token);
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttributeImpl.java
new file mode 100644
index 0000000..da653f3
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/InflectionAttributeImpl.java
@@ -0,0 +1,65 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.analysis.ja.util.ToStringUtil;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+
+/**
+ * Attribute for Kuromoji inflection data.
+ */
+public class InflectionAttributeImpl extends AttributeImpl implements InflectionAttribute, Cloneable {
+  private Token token;
+  
+  public String getInflectionType() {
+    return token == null ? null : token.getInflectionType();
+  }
+  
+  public String getInflectionForm() {
+    return token == null ? null : token.getInflectionForm();
+  }
+  
+  public void setToken(Token token) {
+    this.token = token;
+  }
+
+  @Override
+  public void clear() {
+    token = null;
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    InflectionAttribute t = (InflectionAttribute) target;
+    t.setToken(token);
+  }
+  
+  @Override
+  public void reflectWith(AttributeReflector reflector) {
+    String type = getInflectionType();
+    String typeEN = type == null ? null : ToStringUtil.getInflectionTypeTranslation(type);
+    reflector.reflect(InflectionAttribute.class, "inflectionType", type);
+    reflector.reflect(InflectionAttribute.class, "inflectionType (en)", typeEN);
+    String form = getInflectionForm();
+    String formEN = form == null ? null : ToStringUtil.getInflectedFormTranslation(form);
+    reflector.reflect(InflectionAttribute.class, "inflectionForm", form);
+    reflector.reflect(InflectionAttribute.class, "inflectionForm (en)", formEN);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttribute.java
new file mode 100644
index 0000000..a181755
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttribute.java
@@ -0,0 +1,29 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.util.Attribute;
+
+/**
+ * Attribute for {@link Token#getPartOfSpeech()}.
+ */
+public interface PartOfSpeechAttribute extends Attribute {
+  public String getPartOfSpeech();
+  public void setToken(Token token);
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttributeImpl.java
new file mode 100644
index 0000000..0c3c77c
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/PartOfSpeechAttributeImpl.java
@@ -0,0 +1,57 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.analysis.ja.util.ToStringUtil;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+
+/**
+ * Attribute for {@link Token#getPartOfSpeech()}.
+ */
+public class PartOfSpeechAttributeImpl extends AttributeImpl implements PartOfSpeechAttribute, Cloneable {
+  private Token token;
+  
+  public String getPartOfSpeech() {
+    return token == null ? null : token.getPartOfSpeech();
+  }
+  
+  public void setToken(Token token) {
+    this.token = token;
+  }
+
+  @Override
+  public void clear() {
+    token = null;
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    PartOfSpeechAttribute t = (PartOfSpeechAttribute) target;
+    t.setToken(token);
+  }
+  
+  @Override
+  public void reflectWith(AttributeReflector reflector) {
+    String partOfSpeech = getPartOfSpeech();
+    String partOfSpeechEN = partOfSpeech == null ? null : ToStringUtil.getPOSTranslation(partOfSpeech);
+    reflector.reflect(PartOfSpeechAttribute.class, "partOfSpeech", partOfSpeech);
+    reflector.reflect(PartOfSpeechAttribute.class, "partOfSpeech (en)", partOfSpeechEN);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttribute.java
new file mode 100644
index 0000000..c0209a8
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttribute.java
@@ -0,0 +1,33 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.util.Attribute;
+
+/**
+ * Attribute for Kuromoji reading data
+ * <p>
+ * Note: in some cases this value may not be applicable,
+ * and will be null.
+ */
+public interface ReadingAttribute extends Attribute {
+  public String getReading();
+  public String getPronunciation();
+  public void setToken(Token token);
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttributeImpl.java
new file mode 100644
index 0000000..3716ea4
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/ReadingAttributeImpl.java
@@ -0,0 +1,65 @@
+package org.apache.lucene.analysis.ja.tokenattributes;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.Token;
+import org.apache.lucene.analysis.ja.util.ToStringUtil;
+import org.apache.lucene.util.AttributeImpl;
+import org.apache.lucene.util.AttributeReflector;
+
+/**
+ * Attribute for Kuromoji reading data
+ */
+public class ReadingAttributeImpl extends AttributeImpl implements ReadingAttribute, Cloneable {
+  private Token token;
+  
+  public String getReading() {
+    return token == null ? null : token.getReading();
+  }
+  
+  public String getPronunciation() {
+    return token == null ? null : token.getPronunciation();
+  }
+  
+  public void setToken(Token token) {
+    this.token = token;
+  }
+
+  @Override
+  public void clear() {
+    token = null;
+  }
+
+  @Override
+  public void copyTo(AttributeImpl target) {
+    ReadingAttribute t = (ReadingAttribute) target;
+    t.setToken(token);
+  }
+  
+  @Override
+  public void reflectWith(AttributeReflector reflector) {
+    String reading = getReading();
+    String readingEN = reading == null ? null : ToStringUtil.getRomanization(reading);
+    String pronunciation = getPronunciation();
+    String pronunciationEN = pronunciation == null ? null : ToStringUtil.getRomanization(pronunciation);
+    reflector.reflect(ReadingAttribute.class, "reading", reading);
+    reflector.reflect(ReadingAttribute.class, "reading (en)", readingEN);
+    reflector.reflect(ReadingAttribute.class, "pronunciation", pronunciation);
+    reflector.reflect(ReadingAttribute.class, "pronunciation (en)", pronunciationEN);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/package.html
new file mode 100644
index 0000000..ddabc85
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/tokenattributes/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Additional Kuromoji-specific Attributes for text analysis.
+</body>
+</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/CSVUtil.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/CSVUtil.java
new file mode 100644
index 0000000..ff91420
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/CSVUtil.java
@@ -0,0 +1,113 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.ArrayList;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Utility class for parsing CSV text
+ */
+public final class CSVUtil {
+  private static final char QUOTE = '"';
+  
+  private static final char COMMA = ',';
+  
+  private static final Pattern QUOTE_REPLACE_PATTERN = Pattern.compile("^\"([^\"]+)\"$");
+  
+  private static final String ESCAPED_QUOTE = "\"\"";
+  
+  private CSVUtil() {} // no instance!!!
+  
+  /**
+   * Parse CSV line
+   * @param line
+   * @return Array of values
+   */
+  public static String[] parse(String line) {
+    boolean insideQuote = false;
+    ArrayList<String> result = new ArrayList<String>();		
+    int quoteCount = 0;
+    StringBuilder sb = new StringBuilder();
+    for(int i = 0; i < line.length(); i++) {
+      char c = line.charAt(i);
+      
+      if(c == QUOTE) {
+        insideQuote = !insideQuote;
+        quoteCount++;
+      }
+      
+      if(c == COMMA && !insideQuote) {
+        String value = sb.toString();
+        value = unQuoteUnEscape(value);
+        result.add(value);
+        sb.setLength(0);
+        continue;
+      }
+      
+      sb.append(c);
+    }
+    
+    result.add(sb.toString());
+    
+    // Validate
+    if(quoteCount % 2 != 0) {
+      return new String[0];
+    }
+    
+    return result.toArray(new String[result.size()]);
+  }
+  
+  private static String unQuoteUnEscape(String original) {
+    String result = original;
+    
+    // Unquote
+    if (result.indexOf('\"') >= 0) {
+      Matcher m = QUOTE_REPLACE_PATTERN.matcher(original);
+      if(m.matches()) {
+        result = m.group(1);
+      }
+    
+      // Unescape
+      if (result.indexOf(ESCAPED_QUOTE) >= 0) {
+        result = result.replace(ESCAPED_QUOTE, "\"");
+      }
+    }
+    
+    return result;
+    
+  }
+  
+  /**
+   * Quote and escape input value for CSV
+   * @param original
+   */
+  public static String quoteEscape(String original) {
+    String result = original;
+    
+    if (result.indexOf('\"') >= 0) {
+      result.replace("\"", ESCAPED_QUOTE);
+    }
+    if(result.indexOf(COMMA) >= 0) {
+      result = "\"" + result + "\"";
+    }
+    return result;
+  }
+  
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/ToStringUtil.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/ToStringUtil.java
new file mode 100644
index 0000000..c83de19
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/ToStringUtil.java
@@ -0,0 +1,1039 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashMap;
+
+/**
+ * Utility class for english translations of morphological data,
+ * used only for debugging.
+ */
+public class ToStringUtil {
+  // a translation map for parts of speech, only used for reflectWith
+  private static final HashMap<String,String> posTranslations = new HashMap<String,String>();
+  static {
+    posTranslations.put("???", "noun");
+    posTranslations.put("???-???", "noun-common");
+    posTranslations.put("???-?????", "noun-proper");
+    posTranslations.put("???-?????-???", "noun-proper-misc");
+    posTranslations.put("???-?????-?", "noun-proper-person");
+    posTranslations.put("???-?????-?-???", "noun-proper-person-misc");
+    posTranslations.put("???-?????-?-?", "noun-proper-person-surname");
+    posTranslations.put("???-?????-?-??", "noun-proper-person-given_name");
+    posTranslations.put("???-?????-??", "noun-proper-organization");
+    posTranslations.put("???-?????-??", "noun-proper-place");
+    posTranslations.put("???-?????-??-???", "noun-proper-place-misc");
+    posTranslations.put("???-?????-??-??", "noun-proper-place-country");
+    posTranslations.put("???-??", "noun-pronoun");
+    posTranslations.put("???-??-???", "noun-pronoun-misc");
+    posTranslations.put("???-??-??", "noun-pronoun-contraction");
+    posTranslations.put("???-??????", "noun-adverbial");
+    posTranslations.put("???-????", "noun-verbal");
+    posTranslations.put("???-?????", "noun-adjective-base");
+    posTranslations.put("???-??", "noun-numeric");
+    posTranslations.put("???-????", "noun-affix");
+    posTranslations.put("???-????-???", "noun-affix-misc");
+    posTranslations.put("???-????-??????", "noun-affix-adverbial");
+    posTranslations.put("???-????-?????", "noun-affix-aux");
+    posTranslations.put("???-????-?????", "noun-affix-adjective-base");
+    posTranslations.put("???-??", "noun-special");
+    posTranslations.put("???-??-?????", "noun-special-aux");
+    posTranslations.put("???-?", "noun-suffix");
+    posTranslations.put("???-?-???", "noun-suffix-misc");
+    posTranslations.put("???-?-?", "noun-suffix-person");
+    posTranslations.put("???-?-??", "noun-suffix-place");
+    posTranslations.put("???-?-????", "noun-suffix-verbal");
+    posTranslations.put("???-?-?????", "noun-suffix-aux");
+    posTranslations.put("???-?-?????", "noun-suffix-adjective-base");
+    posTranslations.put("???-?-??????", "noun-suffix-adverbial");
+    posTranslations.put("???-?-???", "noun-suffix-classifier");
+    posTranslations.put("???-?-??", "noun-suffix-special");
+    posTranslations.put("???-????", "noun-suffix-conjunctive");
+    posTranslations.put("???-????????", "noun-verbal_aux");
+    posTranslations.put("???-???????", "noun-quotation");
+    posTranslations.put("???-???????", "noun-nai_adjective");
+    posTranslations.put("???", "prefix");
+    posTranslations.put("???-?????", "prefix-nominal");
+    posTranslations.put("???-?????", "prefix-verbal");
+    posTranslations.put("???-????", "prefix-adjectival");
+    posTranslations.put("???-???", "prefix-numerical");
+    posTranslations.put("???", "verb");
+    posTranslations.put("???-???", "verb-main");
+    posTranslations.put("???-????", "verb-auxiliary");
+    posTranslations.put("???-?", "verb-suffix");
+    posTranslations.put("??", "adjective");
+    posTranslations.put("??-???", "adjective-main");
+    posTranslations.put("??-????", "adjective-auxiliary");
+    posTranslations.put("??-?", "adjective-suffix");
+    posTranslations.put("???", "adverb");
+    posTranslations.put("???-???", "adverb-misc");
+    posTranslations.put("???-?????", "adverb-particle_conjunction");
+    posTranslations.put("???", "adnominal");
+    posTranslations.put("???", "conjunction");
+    posTranslations.put("??", "particle");
+    posTranslations.put("??-???", "particle-case");
+    posTranslations.put("??-???-???", "particle-case-misc");
+    posTranslations.put("??-???-??", "particle-case-quote");
+    posTranslations.put("??-???-??", "particle-case-compound");
+    posTranslations.put("??-????", "particle-conjunctive");
+    posTranslations.put("??-???", "particle-dependency");
+    posTranslations.put("??-????", "particle-adverbial");
+    posTranslations.put("??-?????", "particle-interjective");
+    posTranslations.put("??-????", "particle-coordinate");
+    posTranslations.put("??-???", "particle-final");
+    posTranslations.put("??-?????????????", "particle-adverbial/conjunctive/final");
+    posTranslations.put("??-????", "particle-adnominalizer");
+    posTranslations.put("??-?????", "particle-adnominalizer");
+    posTranslations.put("??-??", "particle-special");
+    posTranslations.put("???", "auxiliary-verb");
+    posTranslations.put("????", "interjection");
+    posTranslations.put("??", "symbol");
+    posTranslations.put("??-???", "symbol-misc");
+    posTranslations.put("??-??", "symbol-period");
+    posTranslations.put("??-??", "symbol-comma");
+    posTranslations.put("??-?", "symbol-space");
+    posTranslations.put("??-????", "symbol-open_bracket");
+    posTranslations.put("??-????", "symbol-close_bracket");
+    posTranslations.put("??-???????????", "symbol-alphabetic");
+    posTranslations.put("????", "other");
+    posTranslations.put("????-???", "other-interjection");
+    posTranslations.put("?????", "filler");
+    posTranslations.put("?????", "non-verbal");
+    posTranslations.put("????", "fragment");
+    posTranslations.put("????", "unknown");
+  }
+  
+  /**
+   * Get the english form of a POS tag
+   */
+  public static String getPOSTranslation(String s) {
+    return posTranslations.get(s);
+  }
+  
+  // a translation map for inflection types, only used for reflectWith
+  private static final HashMap<String,String> inflTypeTranslations = new HashMap<String,String>();
+  static {
+    inflTypeTranslations.put("*", "*");
+    inflTypeTranslations.put("?????????", "adj-group-a-o-u");
+    inflTypeTranslations.put("?????", "adj-group-i");
+    inflTypeTranslations.put("?????",  "adj-group-ii");
+    inflTypeTranslations.put("?????", "non-inflectional");
+    inflTypeTranslations.put("????", "special-da");
+    inflTypeTranslations.put("????", "special-ta");
+    inflTypeTranslations.put("????????", "classical-gotoshi");
+    inflTypeTranslations.put("??????", "special-ja");
+    inflTypeTranslations.put("??????", "special-nai");
+    inflTypeTranslations.put("???????", "5-row-cons-r-special");
+    inflTypeTranslations.put("????", "special-nu");
+    inflTypeTranslations.put("?????", "classical-ki");
+    inflTypeTranslations.put("??????", "special-tai");
+    inflTypeTranslations.put("???????", "classical-beshi");
+    inflTypeTranslations.put("????", "special-ya");
+    inflTypeTranslations.put("???????", "classical-maji");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-t");
+    inflTypeTranslations.put("??????", "special-desu");
+    inflTypeTranslations.put("??????", "special-masu");
+    inflTypeTranslations.put("????????", "5-row-aru");
+    inflTypeTranslations.put("???????", "classical-nari");
+    inflTypeTranslations.put("?????", "classical-ri");
+    inflTypeTranslations.put("???????", "classical-keri");
+    inflTypeTranslations.put("?????", "classical-ru");
+    inflTypeTranslations.put("???????", "5-row-cons-k-i-onbin");
+    inflTypeTranslations.put("?????", "5-row-cons-s");
+    inflTypeTranslations.put("??", "1-row");
+    inflTypeTranslations.put("???????", "5-row-cons-w-cons-onbin");
+    inflTypeTranslations.put("?????", "5-row-cons-m");
+    inflTypeTranslations.put("?????", "5-row-cons-t");
+    inflTypeTranslations.put("?????", "5-row-cons-r");
+    inflTypeTranslations.put("??????", "irregular-suffix-suru");
+    inflTypeTranslations.put("?????", "5-row-cons-g");
+    inflTypeTranslations.put("??????", "irregular-suffix-zuru");
+    inflTypeTranslations.put("?????", "5-row-cons-b");
+    inflTypeTranslations.put("???????", "5-row-cons-w-u-onbin");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-d");
+    inflTypeTranslations.put("??????????", "5-row-cons-k-cons-onbin-yuku");
+    inflTypeTranslations.put("?????", "2-row-upper-cons-d");
+    inflTypeTranslations.put("???????", "5-row-cons-k-cons-onbin");
+    inflTypeTranslations.put("????", "1-row-eru");
+    inflTypeTranslations.put("??????", "4-row-cons-t");
+    inflTypeTranslations.put("?????", "5-row-cons-n");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-h");
+    inflTypeTranslations.put("??????", "4-row-cons-h");
+    inflTypeTranslations.put("??????", "4-row-cons-b");
+    inflTypeTranslations.put("??????", "irregular-suru");
+    inflTypeTranslations.put("?????", "2-row-upper-cons-h");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-m");
+    inflTypeTranslations.put("??????", "4-row-cons-s");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-g");
+    inflTypeTranslations.put("???????", "kuru-kanji");
+    inflTypeTranslations.put("???????", "1-row-kureru");
+    inflTypeTranslations.put("????", "2-row-lower-u");
+    inflTypeTranslations.put("???????", "kuru-kana");
+    inflTypeTranslations.put("??", "irregular-cons-r");
+    inflTypeTranslations.put("?????", "2-row-lower-cons-k");
+  }
+  
+  /**
+   * Get the english form of inflection type
+   */
+  public static String getInflectionTypeTranslation(String s) {
+    return inflTypeTranslations.get(s);
+  }
+
+  // a translation map for inflection forms, only used for reflectWith
+  private static final HashMap<String,String> inflFormTranslations = new HashMap<String,String>();
+  static {
+    inflFormTranslations.put("*", "*");
+    inflFormTranslations.put("???", "base");
+    inflFormTranslations.put("??????", "classical-base");
+    inflFormTranslations.put("???????", "imperfective-nu-connection");
+    inflFormTranslations.put("???????", "imperfective-u-connection");
+    inflFormTranslations.put("?????", "conjunctive-ta-connection");
+    inflFormTranslations.put("??????", "conjunctive-te-connection");
+    inflFormTranslations.put("???????", "conjunctive-gozai-connection");
+    inflFormTranslations.put("????", "uninflected-connection");
+    inflFormTranslations.put("???", "subjunctive");
+    inflFormTranslations.put("??", "imperative-e");
+    inflFormTranslations.put("?????", "conditional-contracted-1");
+    inflFormTranslations.put("?????", "conditional-contracted-2");
+    inflFormTranslations.put("?????", "garu-connection");
+    inflFormTranslations.put("????", "imperfective");
+    inflFormTranslations.put("???", "conjunctive");
+    inflFormTranslations.put("????", "onbin-base");
+    inflFormTranslations.put("??????", "conjunctive-de-connection");
+    inflFormTranslations.put("?????", "imperfective-special");
+    inflFormTranslations.put("??", "imperative-i");
+    inflFormTranslations.put("??????", "conjunctive-ni-connection");
+    inflFormTranslations.put("???", "imperative-yo");
+    inflFormTranslations.put("??????", "adnominal-special");
+    inflFormTranslations.put("???", "imperative-ro");
+    inflFormTranslations.put("???????", "uninflected-special-connection-2");
+    inflFormTranslations.put("????????", "imperfective-reru-connection");
+    inflFormTranslations.put("????", "modern-base");
+    inflFormTranslations.put("???-???", "base-onbin"); // not sure about this
+  }
+  
+  /**
+   * Get the english form of inflected form
+   */
+  public static String getInflectedFormTranslation(String s) {
+    return inflFormTranslations.get(s);
+  }
+  
+  /**
+   * Romanize katakana with modified hepburn
+   */
+  public static String getRomanization(String s) {
+    StringBuilder out = new StringBuilder();
+    try {
+      getRomanization(out, s);
+    } catch (IOException bogus) {
+      throw new RuntimeException(bogus);
+    }
+    return out.toString();
+  }
+  
+  /**
+   * Romanize katakana with modified hepburn
+   */
+  public static void getRomanization(Appendable builder, CharSequence s) throws IOException {
+    final int len = s.length();
+    for (int i = 0; i < len; i++) {
+      // maximum lookahead: 3
+      char ch = s.charAt(i);
+      char ch2 = (i < len - 1) ? s.charAt(i + 1) : 0;
+      char ch3 = (i < len - 2) ? s.charAt(i + 2) : 0;
+      
+      main: switch (ch) {
+        case '??':
+          switch (ch2) {
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append('k');
+              break main;
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append('s');
+              break main;
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append('t');
+              break main;
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append('p');
+              break main;
+          }
+          break;
+        case '??':
+          builder.append('a');
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("yi");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("ye");
+            i++;
+          } else {
+            builder.append('i');
+          }
+          break;
+        case '??':
+          switch(ch2) {
+            case '??':
+              builder.append("wa");
+              i++;
+              break;
+            case '??':
+              builder.append("wi");
+              i++;
+              break;
+            case '??':
+              builder.append("wu");
+              i++;
+              break;
+            case '??':
+              builder.append("we");
+              i++;
+              break;
+            case '??':
+              builder.append("wo");
+              i++;
+              break;
+            case '??':
+              builder.append("wyu");
+              i++;
+              break;
+            default:
+              builder.append('u');
+              break;
+          }
+          break;
+        case '??':
+          builder.append('e');
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append('?');
+            i++;
+          } else {
+            builder.append('o');
+          }
+          break;
+        case '??':
+          builder.append("ka");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("ky?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("ky");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("kya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("kyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("kyu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("kye");
+            i++;
+          } else {
+            builder.append("ki");
+          }
+          break;
+        case '??':
+          switch(ch2) {
+            case '??':
+              builder.append("kwa");
+              i++;
+              break;
+            case '??':
+              builder.append("kwi");
+              i++;
+              break;
+            case '??':
+              builder.append("kwe");
+              i++;
+              break;
+            case '??':
+              builder.append("kwo");
+              i++;
+              break;
+            case '??':
+              builder.append("kwa");
+              i++;
+              break;
+            default:
+              builder.append("ku");
+              break;
+          }
+          break;
+        case '??':
+          builder.append("ke");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("k?");
+            i++;
+          } else {
+            builder.append("ko");
+          }
+          break;
+        case '??':
+          builder.append("sa");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("sh?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("sh");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("sha");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("sho");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("shu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("she");
+            i++;
+          } else {
+            builder.append("shi");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("si");
+            i++;
+          } else {
+            builder.append("su");
+          }
+          break;
+        case '??':
+          builder.append("se");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("s?");
+            i++;
+          } else {
+            builder.append("so");
+          }
+          break;
+        case '??':
+          builder.append("ta");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("ch?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("ch");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("cha");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("cho");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("chu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("che");
+            i++;
+          } else {
+            builder.append("chi");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("tsa");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tsi");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tse");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tso");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tsyu");
+            i++;
+          } else {
+            builder.append("tsu");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("ti");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("tyu");
+            i++;
+          } else {
+            builder.append("te");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("t?");
+            i++;
+          } else {
+            builder.append("to");
+          }
+          break;
+        case '??':
+          builder.append("na");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("ny?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("ny");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("nya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("nyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("nyu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("nye");
+            i++;
+          } else {
+            builder.append("ni");
+          }
+          break;
+        case '??':
+          builder.append("nu");
+          break;
+        case '??':
+          builder.append("ne");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("n?");
+            i++;
+          } else {
+            builder.append("no");
+          }
+          break;
+        case '??':
+          builder.append("ha");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("hy?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("hy");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("hya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("hyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("hyu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("hye");
+            i++;
+          } else {
+            builder.append("hi");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("fya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("fyu");
+            i++;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("fye");
+            i+=2;
+          } else if (ch2 == '??') {
+            builder.append("fyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("fa");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("fi");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("fe");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("fo");
+            i++;
+          } else {
+            builder.append("fu");
+          }
+          break;
+        case '??':
+          builder.append("he");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("h?");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("hu");
+            i++;
+          } else {
+            builder.append("ho");
+          }
+          break;
+        case '??':
+          builder.append("ma");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("my?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("my");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("mya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("myo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("myu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("mye");
+            i++;
+          } else {
+            builder.append("mi");
+          }
+          break;
+        case '??':
+          builder.append("mu");
+          break;
+        case '??':
+          builder.append("mi");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("m?");
+            i++;
+          } else {
+            builder.append("mo");
+          }
+          break;
+        case '??':
+          builder.append("ya");
+          break;
+        case '??':
+          builder.append("yu");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("y?");
+            i++;
+          } else {
+            builder.append("yo");
+          }
+          break;
+        case '??':
+          builder.append("ra");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("ry?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("ry");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("rya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("ryo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("ryu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("rye");
+            i++;
+          } else {
+            builder.append("ri");
+          }
+          break;
+        case '??':
+          builder.append("ru");
+          break;
+        case '??':
+          builder.append("re");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("r?");
+            i++;
+          } else {
+            builder.append("ro");
+          }
+          break;
+        case '??':
+          builder.append("wa");
+          break;
+        case '??':
+          builder.append("i");
+          break;
+        case '??':
+          builder.append("e");
+          break;
+        case '??':
+          builder.append("o");
+          break;
+        case '??':
+          switch (ch2) {
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append('m');
+              break main;
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+            case '??':
+              builder.append("n'");
+              break main;
+            default:
+              builder.append("n");
+              break main;
+          }
+        case '??':
+          builder.append("ga");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("gy?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("gy");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("gya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("gyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("gyu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("gye");
+            i++;
+          } else {
+            builder.append("gi");
+          }
+          break;
+        case '??':
+          switch(ch2) {
+            case '??':
+              builder.append("gwa");
+              i++;
+              break;
+            case '??':
+              builder.append("gwi");
+              i++;
+              break;
+            case '??':
+              builder.append("gwe");
+              i++;
+              break;
+            case '??':
+              builder.append("gwo");
+              i++;
+              break;
+            case '??':
+              builder.append("gwa");
+              i++;
+              break;
+            default:
+              builder.append("gu");
+              break;
+          }
+          break;
+        case '??':
+          builder.append("ge");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("g?");
+            i++;
+          } else {
+            builder.append("go");
+          }
+          break;
+        case '??':
+          builder.append("za");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("j?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("j");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("ja");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("jo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("ju");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("je");
+            i++;
+          } else {
+            builder.append("ji");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("zi");
+            i++;
+          } else {
+            builder.append("zu");
+          }
+          break;
+        case '??':
+          builder.append("ze");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("z?");
+            i++;
+          } else {
+            builder.append("zo");
+          }
+          break;
+        case '??':
+          builder.append("da");
+          break;
+        case '??':
+          builder.append("ji");
+          break;
+        case '??':
+          builder.append("zu");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("di");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("dyu");
+            i++;
+          } else {
+            builder.append("de");
+          }
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("d?");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("du");
+            i++;
+          } else {
+            builder.append("do");
+          }
+          break;
+        case '??':
+          builder.append("ba");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("by?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("by");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("bya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("byo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("byu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("bye");
+            i++;
+          } else {
+            builder.append("bi");
+          }
+          break;
+        case '??':
+          builder.append("bu");
+          break;
+        case '??':
+          builder.append("be");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("b?");
+            i++;
+          } else {
+            builder.append("bo");
+          }
+          break;
+        case '??':
+          builder.append("pa");
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("py?");
+            i += 2;
+          } else if (ch2 == '??' && ch3 == '??') {
+            builder.append("py");
+            i += 2;
+          } else if (ch2 == '??') {
+            builder.append("pya");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("pyo");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("pyu");
+            i++;
+          } else if (ch2 == '??') {
+            builder.append("pye");
+            i++;
+          } else {
+            builder.append("pi");
+          }
+          break;
+        case '??':
+          builder.append("pu");
+          break;
+        case '??':
+          builder.append("pe");
+          break;
+        case '??':
+          if (ch2 == '??') {
+            builder.append("p?");
+            i++;
+          } else {
+            builder.append("po");
+          }
+          break;
+        case '??':
+          if (ch2 == '??' && ch3 == '??') {
+            builder.append("vye");
+            i+= 2;
+          } else {
+            builder.append('v');
+          }
+          break;
+        case '??':
+          builder.append('a');
+          break;
+        case '??':
+          builder.append('i');
+          break;
+        case '??':
+          builder.append('u');
+          break;
+        case '??':
+          builder.append('e');
+          break;
+        case '??':
+          builder.append('o');
+          break;
+        case '??':
+          builder.append("wa");
+          break;
+        case '??':
+          builder.append("ya");
+          break;
+        case '??':
+          builder.append("yu");
+          break;
+        case '??':
+          builder.append("yo");
+          break;
+        case '??':
+          break;
+        default:
+          builder.append(ch);
+      }
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/package.html
new file mode 100644
index 0000000..34d4632
--- /dev/null
+++ b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/util/package.html
@@ -0,0 +1,22 @@
+<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
+<!--
+ Licensed to the Apache Software Foundation (ASF) under one or more
+ contributor license agreements.  See the NOTICE file distributed with
+ this work for additional information regarding copyright ownership.
+ The ASF licenses this file to You under the Apache License, Version 2.0
+ (the "License"); you may not use this file except in compliance with
+ the License.  You may obtain a copy of the License at
+
+     http://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing, software
+ distributed under the License is distributed on an "AS IS" BASIS,
+ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ See the License for the specific language governing permissions and
+ limitations under the License.
+-->
+<html><head></head>
+<body>
+Kuromoji utility classes.
+</body>
+</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/GraphvizFormatter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/GraphvizFormatter.java
deleted file mode 100644
index 51e3f11..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/GraphvizFormatter.java
+++ /dev/null
@@ -1,183 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Position;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Type;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.WrappedPositionArray;
-import org.apache.lucene.analysis.kuromoji.dict.ConnectionCosts;
-import org.apache.lucene.analysis.kuromoji.dict.Dictionary;
-
-
-// TODO: would be nice to show 2nd best path in a diff't
-// color...
-
-/**
- * Outputs the dot (graphviz) string for the viterbi lattice.
- */
-public class GraphvizFormatter {
-  
-  private final static String BOS_LABEL = "BOS";
-  
-  private final static String EOS_LABEL = "EOS";
-  
-  private final static String FONT_NAME = "Helvetica";
-  
-  private final ConnectionCosts costs;
-  
-  private final Map<String, String> bestPathMap;
-  
-  private final StringBuilder sb = new StringBuilder();
-  
-  public GraphvizFormatter(ConnectionCosts costs) {
-    this.costs = costs;
-    this.bestPathMap = new HashMap<String, String>();
-    sb.append(formatHeader());
-    sb.append("  init [style=invis]\n");
-    sb.append("  init -> 0.0 [label=\"" + BOS_LABEL + "\"]\n");
-  }
-
-  public String finish() {
-    sb.append(formatTrailer());
-    return sb.toString();
-  }
-
-  // Backtraces another incremental fragment:
-  void onBacktrace(KuromojiTokenizer tok, WrappedPositionArray positions, int lastBackTracePos, Position endPosData, int fromIDX, char[] fragment, boolean isEnd) {
-    setBestPathMap(positions, lastBackTracePos, endPosData, fromIDX);
-    sb.append(formatNodes(tok, positions, lastBackTracePos, endPosData, fragment));
-    if (isEnd) {
-      sb.append("  fini [style=invis]\n");
-      sb.append("  ");
-      sb.append(getNodeID(endPosData.pos, fromIDX));
-      sb.append(" -> fini [label=\"" + EOS_LABEL + "\"]");
-    }
-  }
-
-  // Records which arcs make up the best bath:
-  private void setBestPathMap(WrappedPositionArray positions, int startPos, Position endPosData, int fromIDX) {
-    bestPathMap.clear();
-
-    int pos = endPosData.pos;
-    int bestIDX = fromIDX;
-    while (pos > startPos) {
-      final Position posData = positions.get(pos);
-
-      final int backPos = posData.backPos[bestIDX];
-      final int backIDX = posData.backIndex[bestIDX];
-
-      final String toNodeID = getNodeID(pos, bestIDX);
-      final String fromNodeID = getNodeID(backPos, backIDX);
-      
-      assert !bestPathMap.containsKey(fromNodeID);
-      assert !bestPathMap.containsValue(toNodeID);
-      bestPathMap.put(fromNodeID, toNodeID);
-      pos = backPos;
-      bestIDX = backIDX;
-    }
-  }
-  
-  private String formatNodes(KuromojiTokenizer tok, WrappedPositionArray positions, int startPos, Position endPosData, char[] fragment) {
-
-    StringBuilder sb = new StringBuilder();
-    // Output nodes
-    for (int pos = startPos+1; pos <= endPosData.pos; pos++) {
-      final Position posData = positions.get(pos);
-      for(int idx=0;idx<posData.count;idx++) {
-        sb.append("  ");
-        sb.append(getNodeID(pos, idx));
-        sb.append(" [label=\"");
-        sb.append(pos);
-        sb.append(": ");
-        sb.append(posData.lastRightID[idx]);
-        sb.append("\"]\n");
-      }
-    }
-
-    // Output arcs
-    for (int pos = endPosData.pos; pos > startPos; pos--) {
-      final Position posData = positions.get(pos);
-      for(int idx=0;idx<posData.count;idx++) {
-        final Position backPosData = positions.get(posData.backPos[idx]);
-        final String toNodeID = getNodeID(pos, idx);
-        final String fromNodeID = getNodeID(posData.backPos[idx], posData.backIndex[idx]);
-
-        sb.append("  ");
-        sb.append(fromNodeID);
-        sb.append(" -> ");
-        sb.append(toNodeID);
-
-        final String attrs;
-        if (toNodeID.equals(bestPathMap.get(fromNodeID))) {
-          // This arc is on best path
-          attrs = " color=\"#40e050\" fontcolor=\"#40a050\" penwidth=3 fontsize=20";
-        } else {
-          attrs = "";
-        }
-
-        final Dictionary dict = tok.getDict(posData.backType[idx]);
-        final int wordCost = dict.getWordCost(posData.backID[idx]);
-        final int bgCost = costs.get(backPosData.lastRightID[posData.backIndex[idx]],
-                                     dict.getLeftId(posData.backID[idx]));
-
-        final String surfaceForm = new String(fragment,
-                                              posData.backPos[idx] - startPos,
-                                              pos - posData.backPos[idx]);
-        
-        sb.append(" [label=\"");
-        sb.append(surfaceForm);
-        sb.append(' ');
-        sb.append(wordCost);
-        if (bgCost >= 0) {
-          sb.append('+');
-        }
-        sb.append(bgCost);
-        sb.append("\"");
-        sb.append(attrs);
-        sb.append("]\n");
-      }
-    }
-    return sb.toString();
-  }
-  
-  private String formatHeader() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("digraph viterbi {\n");
-    sb.append("  graph [ fontsize=30 labelloc=\"t\" label=\"\" splines=true overlap=false rankdir = \"LR\"];\n");
-    //sb.append("  // A2 paper size\n");
-    //sb.append("  size = \"34.4,16.5\";\n");
-    //sb.append("  // try to fill paper\n");
-    //sb.append("  ratio = fill;\n");
-    sb.append("  edge [ fontname=\"" + FONT_NAME + "\" fontcolor=\"red\" color=\"#606060\" ]\n");
-    sb.append("  node [ style=\"filled\" fillcolor=\"#e8e8f0\" shape=\"Mrecord\" fontname=\"" + FONT_NAME + "\" ]\n");
-    
-    return sb.toString();
-  }
-  
-  private String formatTrailer() {
-    return "}";
-  }
-  
-  private String getNodeID(int pos, int idx) {
-    return pos + "." + idx;
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiAnalyzer.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiAnalyzer.java
deleted file mode 100644
index 3d758f8..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiAnalyzer.java
+++ /dev/null
@@ -1,99 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.cjk.CJKWidthFilter;
-import org.apache.lucene.analysis.core.LowerCaseFilter;
-import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-import org.apache.lucene.analysis.kuromoji.dict.UserDictionary;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
-import org.apache.lucene.util.Version;
-
-/**
- * Analyzer for Japanese that uses morphological analysis.
- * @see KuromojiTokenizer
- */
-public class KuromojiAnalyzer extends StopwordAnalyzerBase {
-  private final Mode mode;
-  private final Set<String> stoptags;
-  private final UserDictionary userDict;
-  
-  public KuromojiAnalyzer(Version matchVersion) {
-    this(matchVersion, null, KuromojiTokenizer.DEFAULT_MODE, DefaultSetHolder.DEFAULT_STOP_SET, DefaultSetHolder.DEFAULT_STOP_TAGS);
-  }
-  
-  public KuromojiAnalyzer(Version matchVersion, UserDictionary userDict, Mode mode, CharArraySet stopwords, Set<String> stoptags) {
-    super(matchVersion, stopwords);
-    this.userDict = userDict;
-    this.mode = mode;
-    this.stoptags = stoptags;
-  }
-  
-  public static CharArraySet getDefaultStopSet(){
-    return DefaultSetHolder.DEFAULT_STOP_SET;
-  }
-  
-  public static Set<String> getDefaultStopTags(){
-    return DefaultSetHolder.DEFAULT_STOP_TAGS;
-  }
-  
-  /**
-   * Atomically loads DEFAULT_STOP_SET, DEFAULT_STOP_TAGS in a lazy fashion once the 
-   * outer class accesses the static final set the first time.
-   */
-  private static class DefaultSetHolder {
-    static final CharArraySet DEFAULT_STOP_SET;
-    static final Set<String> DEFAULT_STOP_TAGS;
-
-    static {
-      try {
-        DEFAULT_STOP_SET = loadStopwordSet(true, KuromojiAnalyzer.class, "stopwords.txt", "#");  // ignore case
-        final CharArraySet tagset = loadStopwordSet(false, KuromojiAnalyzer.class, "stoptags.txt", "#");
-        DEFAULT_STOP_TAGS = new HashSet<String>();
-        for (Object element : tagset) {
-          char chars[] = (char[]) element;
-          DEFAULT_STOP_TAGS.add(new String(chars));
-        }
-      } catch (IOException ex) {
-        // default set should always be present as it is part of the distribution (JAR)
-        throw new RuntimeException("Unable to load default stopword or stoptag set");
-      }
-    }
-  }
-  
-  @Override
-  protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-    Tokenizer tokenizer = new KuromojiTokenizer(reader, userDict, true, mode);
-    TokenStream stream = new KuromojiBaseFormFilter(tokenizer);
-    stream = new KuromojiPartOfSpeechStopFilter(true, stream, stoptags);
-    stream = new CJKWidthFilter(stream);
-    stream = new StopFilter(matchVersion, stream, stopwords);
-    stream = new KuromojiKatakanaStemFilter(stream);
-    stream = new LowerCaseFilter(matchVersion, stream);
-    return new TokenStreamComponents(tokenizer, stream);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiBaseFormFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiBaseFormFilter.java
deleted file mode 100644
index 6dfb8be..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiBaseFormFilter.java
+++ /dev/null
@@ -1,62 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.kuromoji.tokenattributes.BaseFormAttribute;
-import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
-
-/**
- * Replaces term text with the {@link BaseFormAttribute}.
- * <p>
- * This acts as a lemmatizer for verbs and adjectives.
- * <p>
- * To prevent terms from being stemmed use an instance of
- * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
- * the {@link KeywordAttribute} before this {@link TokenStream}.
- * </p>
- */
-public final class KuromojiBaseFormFilter extends TokenFilter {
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final BaseFormAttribute basicFormAtt = addAttribute(BaseFormAttribute.class);
-  private final KeywordAttribute keywordAtt = addAttribute(KeywordAttribute.class);
-
-  public KuromojiBaseFormFilter(TokenStream input) {
-    super(input);
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (input.incrementToken()) {
-      if (!keywordAtt.isKeyword()) {
-        String baseForm = basicFormAtt.getBaseForm();
-        if (baseForm != null) {
-          termAtt.setEmpty().append(baseForm);
-        }
-      }
-      return true;
-    } else {
-      return false;
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiKatakanaStemFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiKatakanaStemFilter.java
deleted file mode 100644
index 37a60d7..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiKatakanaStemFilter.java
+++ /dev/null
@@ -1,98 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
-
-import java.io.IOException;
-
-/**
- * A {@link TokenFilter} that normalizes common katakana spelling variations
- * ending in a long sound character by removing this character (U+30FC).  Only
- * katakana words longer than a minimum length are stemmed (default is four).
- * <p>
- * Note that only full-width katakana characters are supported.  Please use a
- * {@link org.apache.lucene.analysis.cjk.CJKWidthFilter} to convert half-width
- * katakana to full-width before using this filter.
- * </p>
- * <p>
- * In order to prevent terms from being stemmed, use an instance of
- * {@link org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter}
- * or a custom {@link TokenFilter} that sets the {@link KeywordAttribute}
- * before this {@link TokenStream}.
- * </p>
- */
-
-public final class KuromojiKatakanaStemFilter extends TokenFilter {
-  public final static int DEFAULT_MINIMUM_LENGTH = 4;
-  private final static char HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK = '\u30fc';
-
-  private final CharTermAttribute termAttr = addAttribute(CharTermAttribute.class);
-  private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
-  private final int minimumKatakanaLength;
-
-  public KuromojiKatakanaStemFilter(TokenStream input, int minimumLength) {
-    super(input);
-    this.minimumKatakanaLength = minimumLength;
-  }
-
-  public KuromojiKatakanaStemFilter(TokenStream input) {
-    this(input, DEFAULT_MINIMUM_LENGTH);
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (input.incrementToken()) {
-      if (!keywordAttr.isKeyword()) {
-        termAttr.setLength(stem(termAttr.buffer(), termAttr.length()));
-      }
-      return true;
-    } else {
-      return false;
-    }
-  }
-
-  private int stem(char[] term, int length) {
-    if (length < minimumKatakanaLength) {
-      return length;
-    }
-
-    if (! isKatakana(term, length)) {
-      return length;
-    }
-
-    if (term[length - 1] == HIRAGANA_KATAKANA_PROLONGED_SOUND_MARK) {
-      return length - 1;
-    }
-
-    return length;
-  }
-
-  private boolean isKatakana(char[] term, int length) {
-    for (int i = 0; i < length; i++) {
-      // NOTE: Test only identifies full-width characters -- half-widths are supported
-      if (Character.UnicodeBlock.of(term[i]) != Character.UnicodeBlock.KATAKANA) {
-        return false;
-      }
-    }
-    return true;
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiPartOfSpeechStopFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiPartOfSpeechStopFilter.java
deleted file mode 100644
index fdd8c16..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiPartOfSpeechStopFilter.java
+++ /dev/null
@@ -1,44 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.analysis.kuromoji.tokenattributes.PartOfSpeechAttribute;
-import org.apache.lucene.analysis.util.FilteringTokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-
-/**
- * Removes tokens that match a set of part-of-speech tags.
- */
-public final class KuromojiPartOfSpeechStopFilter extends FilteringTokenFilter {
-  private final Set<String> stopTags;
-  private final PartOfSpeechAttribute posAtt = addAttribute(PartOfSpeechAttribute.class);
-
-  public KuromojiPartOfSpeechStopFilter(boolean enablePositionIncrements, TokenStream input, Set<String> stopTags) {
-    super(enablePositionIncrements, input);
-    this.stopTags = stopTags;
-  }
-
-  @Override
-  protected boolean accept() throws IOException {
-    final String pos = posAtt.getPartOfSpeech();
-    return pos == null || !stopTags.contains(pos);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiReadingFormFilter.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiReadingFormFilter.java
deleted file mode 100644
index 352fdd4..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiReadingFormFilter.java
+++ /dev/null
@@ -1,65 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenFilter;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.kuromoji.tokenattributes.ReadingAttribute;
-import org.apache.lucene.analysis.kuromoji.util.ToStringUtil;
-
-import java.io.IOException;
-
-/**
- * A {@link org.apache.lucene.analysis.TokenFilter} that replaces the term
- * attribute with the reading of a token in either katakana or romaji form.
- * The default reading form is katakana.
- */
-
-public final class KuromojiReadingFormFilter extends TokenFilter {
-  private final CharTermAttribute termAttr = addAttribute(CharTermAttribute.class);
-  private final ReadingAttribute readingAttr = addAttribute(ReadingAttribute.class);
-
-  private boolean useRomaji;
-
-  public KuromojiReadingFormFilter(TokenStream input, boolean useRomaji) {
-    super(input);
-    this.useRomaji = useRomaji;
-  }
-
-  public KuromojiReadingFormFilter(TokenStream input) {
-    this(input, false);
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-    if (input.incrementToken()) {
-      String reading = readingAttr.getReading();
-      if (reading != null) {
-        if (useRomaji) {
-          ToStringUtil.getRomanization(termAttr.setEmpty(), reading);
-        } else {
-          termAttr.setEmpty().append(reading);
-        }
-      }
-      return true;
-    } else {
-      return false;
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiTokenizer.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiTokenizer.java
deleted file mode 100644
index 85fe911..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/KuromojiTokenizer.java
+++ /dev/null
@@ -1,1239 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.EnumMap;
-import java.util.List;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.kuromoji.dict.CharacterDefinition;
-import org.apache.lucene.analysis.kuromoji.dict.ConnectionCosts;
-import org.apache.lucene.analysis.kuromoji.dict.Dictionary;
-import org.apache.lucene.analysis.kuromoji.dict.TokenInfoDictionary;
-import org.apache.lucene.analysis.kuromoji.dict.TokenInfoFST;
-import org.apache.lucene.analysis.kuromoji.dict.UnknownDictionary;
-import org.apache.lucene.analysis.kuromoji.dict.UserDictionary;
-import org.apache.lucene.analysis.kuromoji.tokenattributes.*;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionLengthAttribute;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.RamUsageEstimator;
-import org.apache.lucene.util.RollingCharBuffer;
-import org.apache.lucene.util.fst.FST;
-
-// TODO: somehow factor out a reusable viterbi search here,
-// so other decompounders/tokenizers can reuse...
-
-/**
- * Tokenizer for Japanese that uses morphological analysis.
- * <p>
- * This tokenizer sets a number of additional attributes:
- * <ul>
- *   <li>{@link BaseFormAttribute} containing base form for inflected
- *       adjectives and verbs.
- *   <li>{@link PartOfSpeechAttribute} containing part-of-speech.
- *   <li>{@link ReadingAttribute} containing reading and pronunciation.
- *   <li>{@link InflectionAttribute} containing additional part-of-speech
- *       information for inflected forms.
- * </ul>
- * <p>
- * This tokenizer uses a rolling Viterbi search to find the 
- * least cost segmentation (path) of the incoming characters.  
- * For tokens that appear to be compound (> length 2 for all
- * Kanji, or > length 7 for non-Kanji), we see if there is a
- * 2nd best segmentation of that token after applying
- * penalties to the long tokens.  If so, and the Mode is
- * {@link Mode#SEARCH}, we output the alternate segmentation 
- * as well.
- */
-public final class KuromojiTokenizer extends Tokenizer {
-
-  /**
-   * Tokenization mode: this determines how the tokenizer handles
-   * compound and unknown words.
-   */
-  public static enum Mode {
-    /**
-     * Ordinary segmentation: no decomposition for compounds,
-     */
-    NORMAL, 
-
-    /**
-     * Segmentation geared towards search: this includes a 
-     * decompounding process for long nouns, also including
-     * the full compound token as a synonym.
-     */
-    SEARCH, 
-
-    /**
-     * Extended mode outputs unigrams for unknown words.
-     * @lucene.experimental
-     */
-    EXTENDED
-  }
-
-  /**
-   * Default tokenization mode. Currently this is {@link Mode#SEARCH}.
-   */
-  public static final Mode DEFAULT_MODE = Mode.SEARCH;
-
-  enum Type {
-    KNOWN,
-    UNKNOWN,
-    USER
-  }
-
-  private static final boolean VERBOSE = false;
-
-  private static final int SEARCH_MODE_KANJI_LENGTH = 2;
-
-  private static final int SEARCH_MODE_OTHER_LENGTH = 7; // Must be >= SEARCH_MODE_KANJI_LENGTH
-
-  private static final int SEARCH_MODE_KANJI_PENALTY = 3000;
-
-  private static final int SEARCH_MODE_OTHER_PENALTY = 1700;
-
-  // For safety:
-  private static final int MAX_UNKNOWN_WORD_LENGTH = 1024;
-  private static final int MAX_BACKTRACE_GAP = 1024;
-
-  private final EnumMap<Type, Dictionary> dictionaryMap = new EnumMap<Type, Dictionary>(Type.class);
-
-  private final TokenInfoFST fst;
-  private final TokenInfoDictionary dictionary;
-  private final UnknownDictionary unkDictionary;
-  private final ConnectionCosts costs;
-  private final UserDictionary userDictionary;
-  private final CharacterDefinition characterDefinition;
-
-  private final FST.Arc<Long> arc = new FST.Arc<Long>();
-  private final FST.BytesReader fstReader;
-  private final IntsRef wordIdRef = new IntsRef();
-
-  private final FST.BytesReader userFSTReader;
-  private final TokenInfoFST userFST;
-
-  private final RollingCharBuffer buffer = new RollingCharBuffer();
-
-  private final WrappedPositionArray positions = new WrappedPositionArray();
-
-  private final boolean discardPunctuation;
-  private final boolean searchMode;
-  private final boolean extendedMode;
-  private final boolean outputCompounds;
-
-  // Index of the last character of unknown word:
-  private int unknownWordEndIndex = -1;
-
-  // True once we've hit the EOF from the input reader:
-  private boolean end;
-
-  // Last absolute position we backtraced from:
-  private int lastBackTracePos;
-
-  // Position of last token we returned; we use this to
-  // figure out whether to set posIncr to 0 or 1:
-  private int lastTokenPos;
-
-  // Next absolute position to process:
-  private int pos;
-
-  // Already parsed, but not yet passed to caller, tokens:
-  private final List<Token> pending = new ArrayList<Token>();
-
-  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
-  private final OffsetAttribute offsetAtt = addAttribute(OffsetAttribute.class);
-  private final PositionIncrementAttribute posIncAtt = addAttribute(PositionIncrementAttribute.class);
-  private final PositionLengthAttribute posLengthAtt = addAttribute(PositionLengthAttribute.class);
-  private final BaseFormAttribute basicFormAtt = addAttribute(BaseFormAttribute.class);
-  private final PartOfSpeechAttribute posAtt = addAttribute(PartOfSpeechAttribute.class);
-  private final ReadingAttribute readingAtt = addAttribute(ReadingAttribute.class);
-  private final InflectionAttribute inflectionAtt = addAttribute(InflectionAttribute.class);
-
-  /**
-   * Create a new KuromojiTokenizer.
-   * 
-   * @param input Reader containing text
-   * @param userDictionary Optional: if non-null, user dictionary.
-   * @param discardPunctuation true if punctuation tokens should be dropped from the output.
-   * @param mode tokenization mode.
-   */
-  public KuromojiTokenizer(Reader input, UserDictionary userDictionary, boolean discardPunctuation, Mode mode) {
-    super(input);
-    dictionary = TokenInfoDictionary.getInstance();
-    fst = dictionary.getFST();
-    unkDictionary = UnknownDictionary.getInstance();
-    characterDefinition = unkDictionary.getCharacterDefinition();
-    this.userDictionary = userDictionary;
-    costs = ConnectionCosts.getInstance();
-    fstReader = fst.getBytesReader(0);
-    if (userDictionary != null) {
-      userFST = userDictionary.getFST();
-      userFSTReader = userFST.getBytesReader(0);
-    } else {
-      userFST = null;
-      userFSTReader = null;
-    }
-    this.discardPunctuation = discardPunctuation;
-    switch(mode){
-      case SEARCH:
-        searchMode = true;
-        extendedMode = false;
-        outputCompounds = true;
-        break;
-      case EXTENDED:
-        searchMode = true;
-        extendedMode = true;
-        outputCompounds = false;
-        break;
-      default:
-        searchMode = false;
-        extendedMode = false;
-        outputCompounds = false;
-        break;
-    }
-    buffer.reset(input);
-
-    resetState();
-
-    dictionaryMap.put(Type.KNOWN, dictionary);
-    dictionaryMap.put(Type.UNKNOWN, unkDictionary);
-    dictionaryMap.put(Type.USER, userDictionary);
-  }
-
-  private GraphvizFormatter dotOut;
-
-  /** Expert: set this to produce graphviz (dot) output of
-   *  the Viterbi lattice */
-  public void setGraphvizFormatter(GraphvizFormatter dotOut) {
-    this.dotOut = dotOut;
-  }
-
-  @Override
-  public void reset(Reader input) throws IOException {
-    super.reset(input);
-    buffer.reset(input);
-  }
-
-  @Override
-  public void reset() throws IOException {
-    super.reset();
-    resetState();
-  }
-
-  private void resetState() {
-    positions.reset();
-    unknownWordEndIndex = -1;
-    pos = 0;
-    end = false;
-    lastBackTracePos = 0;
-    lastTokenPos = -1;
-    pending.clear();
-
-    // Add BOS:
-    positions.get(0).add(0, 0, -1, -1, -1, Type.KNOWN);
-  }
-
-  @Override
-  public void end() {
-    // Set final offset
-    offsetAtt.setOffset(correctOffset(pos), correctOffset(pos));
-  }
-
-  // Returns the added cost that a 2nd best segmentation is
-  // allowed to have.  Ie, if we see path with cost X,
-  // ending in a compound word, and this method returns
-  // threshold > 0, then we will also find the 2nd best
-  // segmentation and if its path score is within this
-  // threshold of X, we'll include it in the output:
-  private int computeSecondBestThreshold(int pos, int length) throws IOException {
-    // TODO: maybe we do something else here, instead of just
-    // using the penalty...?  EG we can be more aggressive on
-    // when to also test for 2nd best path
-    return computePenalty(pos, length);
-  }
-
-  private int computePenalty(int pos, int length) throws IOException {
-    if (length > SEARCH_MODE_KANJI_LENGTH) {
-      boolean allKanji = true;
-      // check if node consists of only kanji
-      final int endPos = pos + length;
-      for (int pos2 = pos; pos2 < endPos; pos2++) {
-        if (!characterDefinition.isKanji((char) buffer.get(pos2))) {
-          allKanji = false;
-          break;
-        }				
-      }
-      if (allKanji) {	// Process only Kanji keywords
-        return (length - SEARCH_MODE_KANJI_LENGTH) * SEARCH_MODE_KANJI_PENALTY;
-      } else if (length > SEARCH_MODE_OTHER_LENGTH) {
-        return (length - SEARCH_MODE_OTHER_LENGTH) * SEARCH_MODE_OTHER_PENALTY;								
-      }
-    }
-    return 0;
-  }
-
-  // Holds all back pointers arriving to this position:
-  final static class Position {
-
-    int pos;
-
-    int count;
-
-    // maybe single int array * 5?
-    int[] costs = new int[8];
-    int[] lastRightID = new int[8];
-    int[] backPos = new int[8];
-    int[] backIndex = new int[8];
-    int[] backID = new int[8];
-    Type[] backType = new Type[8];
-
-    // Only used when finding 2nd best segmentation under a
-    // too-long token:
-    int forwardCount;
-    int[] forwardPos = new int[8];
-    int[] forwardID = new int[8];
-    int[] forwardIndex = new int[8];
-    Type[] forwardType = new Type[8];
-
-    public void grow() {
-      costs = ArrayUtil.grow(costs, 1+count);
-      lastRightID = ArrayUtil.grow(lastRightID, 1+count);
-      backPos = ArrayUtil.grow(backPos, 1+count);
-      backIndex = ArrayUtil.grow(backIndex, 1+count);
-      backID = ArrayUtil.grow(backID, 1+count);
-
-      // NOTE: sneaky: grow separately because
-      // ArrayUtil.grow will otherwise pick a different
-      // length than the int[]s we just grew:
-      final Type[] newBackType = new Type[backID.length];
-      System.arraycopy(backType, 0, newBackType, 0, backType.length);
-      backType = newBackType;
-    }
-
-    public void growForward() {
-      forwardPos = ArrayUtil.grow(forwardPos, 1+forwardCount);
-      forwardID = ArrayUtil.grow(forwardID, 1+forwardCount);
-      forwardIndex = ArrayUtil.grow(forwardIndex, 1+forwardCount);
-
-      // NOTE: sneaky: grow separately because
-      // ArrayUtil.grow will otherwise pick a different
-      // length than the int[]s we just grew:
-      final Type[] newForwardType = new Type[forwardPos.length];
-      System.arraycopy(forwardType, 0, newForwardType, 0, forwardType.length);
-      forwardType = newForwardType;
-    }
-
-    public void add(int cost, int lastRightID, int backPos, int backIndex, int backID, Type backType) {
-      // NOTE: this isn't quite a true Viterbit search,
-      // becase we should check if lastRightID is
-      // already present here, and only update if the new
-      // cost is less than the current cost, instead of
-      // simply appending.  However, that will likely hurt
-      // performance (usually we add a lastRightID only once),
-      // and it means we actually create the full graph
-      // intersection instead of a "normal" Viterbi lattice:
-      if (count == costs.length) {
-        grow();
-      }
-      this.costs[count] = cost;
-      this.lastRightID[count] = lastRightID;
-      this.backPos[count] = backPos;
-      this.backIndex[count] = backIndex;
-      this.backID[count] = backID;
-      this.backType[count] = backType;
-      count++;
-    }
-
-    public void addForward(int forwardPos, int forwardIndex, int forwardID, Type forwardType) {
-      if (forwardCount == this.forwardID.length) {
-        growForward();
-      }
-      this.forwardPos[forwardCount] = forwardPos;
-      this.forwardIndex[forwardCount] = forwardIndex;
-      this.forwardID[forwardCount] = forwardID;
-      this.forwardType[forwardCount] = forwardType;
-      forwardCount++;
-    }
-
-    public void reset() {
-      count = 0;
-      // forwardCount naturally resets after it runs:
-      assert forwardCount == 0: "pos=" + pos + " forwardCount=" + forwardCount;
-    }
-  }
-
-  private void add(Dictionary dict, Position fromPosData, int endPos, int wordID, Type type, boolean addPenalty) throws IOException {
-    final int wordCost = dict.getWordCost(wordID);
-    final int leftID = dict.getLeftId(wordID);
-    int leastCost = Integer.MAX_VALUE;
-    int leastIDX = -1;
-    assert fromPosData.count > 0;
-    for(int idx=0;idx<fromPosData.count;idx++) {
-      // Cost is path cost so far, plus word cost (added at
-      // end of loop), plus bigram cost:
-      final int cost = fromPosData.costs[idx] + costs.get(fromPosData.lastRightID[idx], leftID);
-      if (VERBOSE) {
-        System.out.println("      fromIDX=" + idx + ": cost=" + cost + " (prevCost=" + fromPosData.costs[idx] + " wordCost=" + wordCost + " bgCost=" + costs.get(fromPosData.lastRightID[idx], leftID) + " leftID=" + leftID);
-      }
-      if (cost < leastCost) {
-        leastCost = cost;
-        leastIDX = idx;
-        if (VERBOSE) {
-          System.out.println("        **");
-        }
-      }
-    }
-
-    leastCost += wordCost;
-
-    if (VERBOSE) {
-      System.out.println("      + cost=" + leastCost + " wordID=" + wordID + " leftID=" + leftID + " leastIDX=" + leastIDX + " toPos=" + endPos + " toPos.idx=" + positions.get(endPos).count);
-    }
-
-    if ((addPenalty || (!outputCompounds && searchMode)) && type != Type.USER) {
-      final int penalty = computePenalty(fromPosData.pos, endPos - fromPosData.pos);
-      if (VERBOSE) {
-        if (penalty > 0) {
-          System.out.println("        + penalty=" + penalty + " cost=" + (leastCost+penalty));
-        }
-      }
-      leastCost += penalty;
-    }
-
-    //positions.get(endPos).add(leastCost, dict.getRightId(wordID), fromPosData.pos, leastIDX, wordID, type);
-    assert leftID == dict.getRightId(wordID);
-    positions.get(endPos).add(leastCost, leftID, fromPosData.pos, leastIDX, wordID, type);
-  }
-
-  @Override
-  public boolean incrementToken() throws IOException {
-
-    // parse() is able to return w/o producing any new
-    // tokens, when the tokens it had produced were entirely
-    // punctuation.  So we loop here until we get a real
-    // token or we end:
-    while (pending.size() == 0) {
-      if (end) {
-        return false;
-      }
-
-      // Push Viterbi forward some more:
-      parse();
-    }
-
-    final Token token = pending.remove(pending.size()-1);
-
-    int position = token.getPosition();
-    int length = token.getLength();
-    clearAttributes();
-    assert length > 0;
-    //System.out.println("off=" + token.getOffset() + " len=" + length + " vs " + token.getSurfaceForm().length);
-    termAtt.copyBuffer(token.getSurfaceForm(), token.getOffset(), length);
-    offsetAtt.setOffset(correctOffset(position), correctOffset(position+length));
-    basicFormAtt.setToken(token);
-    posAtt.setToken(token);
-    readingAtt.setToken(token);
-    inflectionAtt.setToken(token);
-    if (token.getPosition() == lastTokenPos) {
-      posIncAtt.setPositionIncrement(0);
-      posLengthAtt.setPositionLength(token.getPositionLength());
-    } else {
-      assert token.getPosition() > lastTokenPos;
-      posIncAtt.setPositionIncrement(1);
-      posLengthAtt.setPositionLength(1);
-    }
-    if (VERBOSE) {
-      System.out.println(Thread.currentThread().getName() + ":    incToken: return token=" + token);
-    }
-    lastTokenPos = token.getPosition();
-    return true;
-  }
-
-  // TODO: make generic'd version of this "circular array"?
-  // It's a bit tricky because we do things to the Position
-  // (eg, set .pos = N on reuse)...
-  static final class WrappedPositionArray {
-    private Position[] positions = new Position[8];
-
-    public WrappedPositionArray() {
-      for(int i=0;i<positions.length;i++) {
-        positions[i] = new Position();
-      }
-    }
-
-    // Next array index to write to in positions:
-    private int nextWrite;
-
-    // Next position to write:
-    private int nextPos;
-    
-    // How many valid Position instances are held in the
-    // positions array:
-    private int count;
-
-    public void reset() {
-      nextWrite--;
-      while(count > 0) {
-        if (nextWrite == -1) {
-          nextWrite = positions.length - 1;
-        }
-        positions[nextWrite--].reset();
-        count--;
-      }
-      nextWrite = 0;
-      nextPos = 0;
-      count = 0;
-    }
-
-    /** Get Position instance for this absolute position;
-     *  this is allowed to be arbitrarily far "in the
-     *  future" but cannot be before the last freeBefore. */
-    public Position get(int pos) {
-      while(pos >= nextPos) {
-        //System.out.println("count=" + count + " vs len=" + positions.length);
-        if (count == positions.length) {
-          Position[] newPositions = new Position[ArrayUtil.oversize(1+count, RamUsageEstimator.NUM_BYTES_OBJECT_REF)];
-          //System.out.println("grow positions " + newPositions.length);
-          System.arraycopy(positions, nextWrite, newPositions, 0, positions.length-nextWrite);
-          System.arraycopy(positions, 0, newPositions, positions.length-nextWrite, nextWrite);
-          for(int i=positions.length;i<newPositions.length;i++) {
-            newPositions[i] = new Position();
-          }
-          nextWrite = positions.length;
-          positions = newPositions;
-        }
-        if (nextWrite == positions.length) {
-          nextWrite = 0;
-        }
-        // Should have already been reset:
-        assert positions[nextWrite].count == 0;
-        positions[nextWrite++].pos = nextPos++;
-        count++;
-      }
-      assert inBounds(pos);
-      final int index = getIndex(pos);
-      assert positions[index].pos == pos;
-      return positions[index];
-    }
-
-    public int getNextPos() {
-      return nextPos;
-    }
-
-    // For assert:
-    private boolean inBounds(int pos) {
-      return pos < nextPos && pos >= nextPos - count;
-    }
-
-    private int getIndex(int pos) {
-      int index = nextWrite - (nextPos - pos);
-      if (index < 0) {
-        index += positions.length;
-      }
-      return index;
-    }
-
-    public void freeBefore(int pos) {
-      final int toFree = count - (nextPos - pos);
-      assert toFree >= 0;
-      assert toFree <= count;
-      int index = nextWrite - count;
-      if (index < 0) {
-        index += positions.length;
-      }
-      for(int i=0;i<toFree;i++) {
-        if (index == positions.length) {
-          index = 0;
-        }
-        //System.out.println("  fb idx=" + index);
-        positions[index].reset();
-        index++;
-      }
-      count -= toFree;
-    }
-  }
-
-  /* Incrementally parse some more characters.  This runs
-   * the viterbi search forwards "enough" so that we
-   * generate some more tokens.  How much forward depends on
-   * the chars coming in, since some chars could cause
-   * longer-lasting ambiguity in the parsing.  Once the
-   * ambiguity is resolved, then we back trace, produce
-   * the pending tokens, and return. */
-  private void parse() throws IOException {
-    if (VERBOSE) {
-      System.out.println("\nPARSE");
-    }
-
-    // Advances over each position (character):
-    while (true) {
-
-      if (buffer.get(pos) == -1) {
-        // End
-        break;
-      }
-
-      final Position posData = positions.get(pos);
-      final boolean isFrontier = positions.getNextPos() == pos+1;
-
-      if (posData.count == 0) {
-        // No arcs arrive here; move to next position:
-        pos++;
-        if (VERBOSE) {
-          System.out.println("    no arcs in; skip");
-        }
-        continue;
-      }
-
-      if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {
-        //  if (pos > lastBackTracePos && posData.count == 1 && isFrontier) {
-        // We are at a "frontier", and only one node is
-        // alive, so whatever the eventual best path is must
-        // come through this node.  So we can safely commit
-        // to the prefix of the best path at this point:
-        backtrace(posData, 0);
-
-        // Re-base cost so we don't risk int overflow:
-        posData.costs[0] = 0;
-
-        if (pending.size() != 0) {
-          return;
-        } else {
-          // This means the backtrace only produced
-          // punctuation tokens, so we must keep parsing.
-        }
-      }
-
-      if (pos - lastBackTracePos >= MAX_BACKTRACE_GAP) {
-        // Safety: if we've buffered too much, force a
-        // backtrace now.  We find the least-cost partial
-        // path, across all paths, backtrace from it, and
-        // then prune all others.  Note that this, in
-        // general, can produce the wrong result, if the
-        // total bast path did not in fact back trace
-        // through this partial best path.  But it's the
-        // best we can do... (short of not having a
-        // safety!).
-
-        // First pass: find least cost parital path so far,
-        // including ending at future positions:
-        int leastIDX = -1;
-        int leastCost = Integer.MAX_VALUE;
-        Position leastPosData = null;
-        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {
-          final Position posData2 = positions.get(pos2);
-          for(int idx=0;idx<posData2.count;idx++) {
-            //System.out.println("    idx=" + idx + " cost=" + cost);
-            final int cost = posData2.costs[idx];
-            if (cost < leastCost) {
-              leastCost = cost;
-              leastIDX = idx;
-              leastPosData = posData2;
-            }
-          }
-        }
-
-        // We will always have at least one live path:
-        assert leastIDX != -1;
-
-        // Second pass: prune all but the best path:
-        for(int pos2=pos;pos2<positions.getNextPos();pos2++) {
-          final Position posData2 = positions.get(pos2);
-          if (posData2 != leastPosData) {
-            posData2.reset();
-          } else {
-            if (leastIDX != 0) {
-              posData2.costs[0] = posData2.costs[leastIDX];
-              posData2.lastRightID[0] = posData2.lastRightID[leastIDX];
-              posData2.backPos[0] = posData2.backPos[leastIDX];
-              posData2.backIndex[0] = posData2.backIndex[leastIDX];
-              posData2.backID[0] = posData2.backID[leastIDX];
-              posData2.backType[0] = posData2.backType[leastIDX];
-            }
-            posData2.count = 1;
-          }
-        }
-
-        backtrace(leastPosData, 0);
-
-        // Re-base cost so we don't risk int overflow:
-        Arrays.fill(leastPosData.costs, 0, leastPosData.count, 0);
-
-        if (pos != leastPosData.pos) {
-          // We jumped into a future position:
-          assert pos < leastPosData.pos;
-          pos = leastPosData.pos;
-        }
-
-        if (pending.size() != 0) {
-          return;
-        } else {
-          // This means the backtrace only produced
-          // punctuation tokens, so we must keep parsing.
-          continue;
-        }
-      }
-
-      if (VERBOSE) {
-        System.out.println("\n  extend @ pos=" + pos + " char=" + (char) buffer.get(pos));
-      }
-
-      if (VERBOSE) {
-        System.out.println("    " + posData.count + " arcs in");
-      }
-
-      boolean anyMatches = false;
-
-      // First try user dict:
-      if (userFST != null) {
-        userFST.getFirstArc(arc);
-        int output = 0;
-        for(int posAhead=posData.pos;;posAhead++) {
-          final int ch = buffer.get(posAhead);
-          if (ch == -1) {
-            break;
-          }
-          if (userFST.findTargetArc(ch, arc, arc, posAhead == posData.pos, userFSTReader) == null) {
-            break;
-          }
-          output += arc.output.intValue();
-          if (arc.isFinal()) {
-            if (VERBOSE) {
-              System.out.println("    USER word " + new String(buffer.get(pos, posAhead - pos + 1)) + " toPos=" + (posAhead + 1));
-            }
-            add(userDictionary, posData, posAhead+1, output + arc.nextFinalOutput.intValue(), Type.USER, false);
-            anyMatches = true;
-          }
-        }
-      }
-
-      // TODO: we can be more aggressive about user
-      // matches?  if we are "under" a user match then don't
-      // extend KNOWN/UNKNOWN paths?
-
-      if (!anyMatches) {
-        // Next, try known dictionary matches
-        fst.getFirstArc(arc);
-        int output = 0;
-
-        for(int posAhead=posData.pos;;posAhead++) {
-          final int ch = buffer.get(posAhead);
-          if (ch == -1) {
-            break;
-          }
-          //System.out.println("    match " + (char) ch + " posAhead=" + posAhead);
-          
-          if (fst.findTargetArc(ch, arc, arc, posAhead == posData.pos, fstReader) == null) {
-            break;
-          }
-
-          output += arc.output.intValue();
-
-          // Optimization: for known words that are too-long
-          // (compound), we should pre-compute the 2nd
-          // best segmentation and store it in the
-          // dictionary instead of recomputing it each time a
-          // match is found.
-
-          if (arc.isFinal()) {
-            dictionary.lookupWordIds(output + arc.nextFinalOutput.intValue(), wordIdRef);
-            if (VERBOSE) {
-              System.out.println("    KNOWN word " + new String(buffer.get(pos, posAhead - pos + 1)) + " toPos=" + (posAhead + 1) + " " + wordIdRef.length + " wordIDs");
-            }
-            for (int ofs = 0; ofs < wordIdRef.length; ofs++) {
-              add(dictionary, posData, posAhead+1, wordIdRef.ints[wordIdRef.offset + ofs], Type.KNOWN, false);
-              anyMatches = true;
-            }
-          }
-        }
-      }
-
-      // In the case of normal mode, it doesn't process unknown word greedily.
-
-      if (!searchMode && unknownWordEndIndex > posData.pos) {
-        pos++;
-        continue;
-      }
-
-      final char firstCharacter = (char) buffer.get(pos);
-      if (!anyMatches || characterDefinition.isInvoke(firstCharacter)) {
-
-        // Find unknown match:
-        final int characterId = characterDefinition.getCharacterClass(firstCharacter);
-
-        // NOTE: copied from UnknownDictionary.lookup:
-        int unknownWordLength;
-        if (!characterDefinition.isGroup(firstCharacter)) {
-          unknownWordLength = 1;
-        } else {
-          // Extract unknown word. Characters with the same character class are considered to be part of unknown word
-          unknownWordLength = 1;
-          for (int posAhead=pos+1;unknownWordLength<MAX_UNKNOWN_WORD_LENGTH;posAhead++) {
-            final int ch = buffer.get(posAhead);
-            if (ch == -1) {
-              break;
-            }
-            if (characterId == characterDefinition.getCharacterClass((char) ch)) {
-              unknownWordLength++;    			
-            } else {
-              break;
-            }
-          }
-        }
-
-        unkDictionary.lookupWordIds(characterId, wordIdRef); // characters in input text are supposed to be the same
-        if (VERBOSE) {
-          System.out.println("    UNKNOWN word len=" + unknownWordLength + " " + wordIdRef.length + " wordIDs");
-        }
-        for (int ofs = 0; ofs < wordIdRef.length; ofs++) {
-          add(unkDictionary, posData, posData.pos + unknownWordLength, wordIdRef.ints[wordIdRef.offset + ofs], Type.UNKNOWN, false);
-        }
-
-        unknownWordEndIndex = posData.pos + unknownWordLength;
-      }
-
-      pos++;
-    }
-
-    end = true;
-
-    if (pos > 0) {
-
-      final Position endPosData = positions.get(pos);
-      int leastCost = Integer.MAX_VALUE;
-      int leastIDX = -1;
-      if (VERBOSE) {
-        System.out.println("  end: " + endPosData.count + " nodes");
-      }
-      for(int idx=0;idx<endPosData.count;idx++) {
-        // Add EOS cost:
-        final int cost = endPosData.costs[idx] + costs.get(endPosData.lastRightID[idx], 0);
-        //System.out.println("    idx=" + idx + " cost=" + cost + " (pathCost=" + endPosData.costs[idx] + " bgCost=" + costs.get(endPosData.lastRightID[idx], 0) + ") backPos=" + endPosData.backPos[idx]);
-        if (cost < leastCost) {
-          leastCost = cost;
-          leastIDX = idx;
-        }
-      }
-
-      backtrace(endPosData, leastIDX);
-    } else {
-      // No characters in the input string; return no tokens!
-    }
-  }
-
-  // Eliminates arcs from the lattice that are compound
-  // tokens (have a penalty) or are not congruent with the
-  // compound token we've matched (ie, span across the
-  // startPos).  This should be fairly efficient, because we
-  // just keep the already intersected structure of the
-  // graph, eg we don't have to consult the FSTs again:
-
-  private void pruneAndRescore(int startPos, int endPos, int bestStartIDX) throws IOException {
-    if (VERBOSE) {
-      System.out.println("  pruneAndRescore startPos=" + startPos + " endPos=" + endPos + " bestStartIDX=" + bestStartIDX);
-    }
-
-    // First pass: walk backwards, building up the forward
-    // arcs and pruning inadmissible arcs:
-    for(int pos=endPos; pos > startPos; pos--) {
-      final Position posData = positions.get(pos);
-      if (VERBOSE) {
-        System.out.println("    back pos=" + pos);
-      }
-      for(int arcIDX=0;arcIDX<posData.count;arcIDX++) {
-        final int backPos = posData.backPos[arcIDX];
-        if (backPos >= startPos) {
-          // Keep this arc:
-          //System.out.println("      keep backPos=" + backPos);
-          positions.get(backPos).addForward(pos,
-                                            arcIDX,
-                                            posData.backID[arcIDX],
-                                            posData.backType[arcIDX]);
-        } else {
-          if (VERBOSE) {
-            System.out.println("      prune");
-          }
-        }
-      }
-      if (pos != startPos) {
-        posData.count = 0;
-      }
-    }
-
-    // Second pass: walk forward, re-scoring:
-    for(int pos=startPos; pos < endPos; pos++) {
-      final Position posData = positions.get(pos);
-      if (VERBOSE) {
-        System.out.println("    forward pos=" + pos + " count=" + posData.forwardCount);
-      }
-      if (posData.count == 0) {
-        // No arcs arrive here...
-        if (VERBOSE) {
-          System.out.println("      skip");
-        }
-        posData.forwardCount = 0;
-        continue;
-      }
-
-      if (pos == startPos) {
-        // On the initial position, only consider the best
-        // path so we "force congruence":  the
-        // sub-segmentation is "in context" of what the best
-        // path (compound token) had matched:
-        final int rightID;
-        if (startPos == 0) {
-          rightID = 0;
-        } else {
-          rightID = getDict(posData.backType[bestStartIDX]).getRightId(posData.backID[bestStartIDX]);
-        }
-        final int pathCost = posData.costs[bestStartIDX];
-        for(int forwardArcIDX=0;forwardArcIDX<posData.forwardCount;forwardArcIDX++) {
-          final Type forwardType = posData.forwardType[forwardArcIDX];
-          final Dictionary dict2 = getDict(forwardType);
-          final int wordID = posData.forwardID[forwardArcIDX];
-          final int toPos = posData.forwardPos[forwardArcIDX];
-          final int newCost = pathCost + dict2.getWordCost(wordID) + 
-            costs.get(rightID, dict2.getLeftId(wordID)) +
-            computePenalty(pos, toPos-pos);
-          if (VERBOSE) {
-            System.out.println("      + " + forwardType + " word " + new String(buffer.get(pos, toPos-pos)) + " toPos=" + toPos + " cost=" + newCost + " penalty=" + computePenalty(pos, toPos-pos) + " toPos.idx=" + positions.get(toPos).count);
-          }
-          positions.get(toPos).add(newCost,
-                                   dict2.getRightId(wordID),
-                                   pos,
-                                   bestStartIDX,
-                                   wordID,
-                                   forwardType);
-        }
-      } else {
-        // On non-initial positions, we maximize score
-        // across all arriving lastRightIDs:
-        for(int forwardArcIDX=0;forwardArcIDX<posData.forwardCount;forwardArcIDX++) {
-          final Type forwardType = posData.forwardType[forwardArcIDX];
-          final int toPos = posData.forwardPos[forwardArcIDX];
-          if (VERBOSE) {
-            System.out.println("      + " + forwardType + " word " + new String(buffer.get(pos, toPos-pos)) + " toPos=" + toPos);
-          }
-          add(getDict(forwardType),
-              posData,
-              toPos,
-              posData.forwardID[forwardArcIDX],
-              forwardType,
-              true);
-        }
-      }
-      posData.forwardCount = 0;
-    }
-  }
-
-  // Backtrace from the provided position, back to the last
-  // time we back-traced, accumulating the resulting tokens to
-  // the pending list.  The pending list is then in-reverse
-  // (last token should be returned first).
-  private void backtrace(final Position endPosData, final int fromIDX) throws IOException {
-    final int endPos = endPosData.pos;
-
-    if (VERBOSE) {
-      System.out.println("\n  backtrace: endPos=" + endPos + " pos=" + pos + "; " + (pos - lastBackTracePos) + " characters; last=" + lastBackTracePos + " cost=" + endPosData.costs[fromIDX]);
-    }
-
-    final char[] fragment = buffer.get(lastBackTracePos, endPos-lastBackTracePos);
-
-    if (dotOut != null) {
-      dotOut.onBacktrace(this, positions, lastBackTracePos, endPosData, fromIDX, fragment, end);
-    }
-
-    int pos = endPos;
-    int bestIDX = fromIDX;
-    Token altToken = null;
-
-    // We trace backwards, so this will be the leftWordID of
-    // the token after the one we are now on:
-    int lastLeftWordID = -1;
-
-    int backCount = 0;
-
-    // TODO: sort of silly to make Token instances here; the
-    // back trace has all info needed to generate the
-    // token.  So, we could just directly set the attrs,
-    // from the backtrace, in incrementToken w/o ever
-    // creating Token; we'd have to defer calling freeBefore
-    // until after the bactrace was fully "consumed" by
-    // incrementToken.
-
-    while (pos > lastBackTracePos) {
-      //System.out.println("BT: back pos=" + pos + " bestIDX=" + bestIDX);
-      final Position posData = positions.get(pos);
-      assert bestIDX < posData.count;
-
-      int backPos = posData.backPos[bestIDX];
-      assert backPos >= lastBackTracePos: "backPos=" + backPos + " vs lastBackTracePos=" + lastBackTracePos;
-      int length = pos - backPos;
-      Type backType = posData.backType[bestIDX];
-      int backID = posData.backID[bestIDX];
-      int nextBestIDX = posData.backIndex[bestIDX];
-
-      if (outputCompounds && searchMode && altToken == null && backType != Type.USER) {
-        
-        // In searchMode, if best path had picked a too-long
-        // token, we use the "penalty" to compute the allowed
-        // max cost of an alternate back-trace.  If we find an
-        // alternate back trace with cost below that
-        // threshold, we pursue it instead (but also output
-        // the long token).
-        //System.out.println("    2nd best backPos=" + backPos + " pos=" + pos);
-
-        final int penalty = computeSecondBestThreshold(backPos, pos-backPos);
-        
-        if (penalty > 0) {
-          if (VERBOSE) {
-            System.out.println("  compound=" + new String(buffer.get(backPos, pos-backPos)) + " backPos=" + backPos + " pos=" + pos + " penalty=" + penalty + " cost=" + posData.costs[bestIDX] + " bestIDX=" + bestIDX + " lastLeftID=" + lastLeftWordID);
-          }
-
-          // Use the penalty to set maxCost on the 2nd best
-          // segmentation:
-          int maxCost = posData.costs[bestIDX] + penalty;
-          if (lastLeftWordID != -1) {
-            maxCost += costs.get(getDict(backType).getRightId(backID), lastLeftWordID);
-          }
-
-          // Now, prune all too-long tokens from the graph:
-          pruneAndRescore(backPos, pos,
-                          posData.backIndex[bestIDX]);
-
-          // Finally, find 2nd best back-trace and resume
-          // backtrace there:
-          int leastCost = Integer.MAX_VALUE;
-          int leastIDX = -1;
-          for(int idx=0;idx<posData.count;idx++) {
-            int cost = posData.costs[idx];
-            //System.out.println("    idx=" + idx + " prevCost=" + cost);
-            
-            if (lastLeftWordID != -1) {
-              cost += costs.get(getDict(posData.backType[idx]).getRightId(posData.backID[idx]),
-                                lastLeftWordID);
-              //System.out.println("      += bgCost=" + costs.get(getDict(posData.backType[idx]).getRightId(posData.backID[idx]),
-              //lastLeftWordID) + " -> " + cost);
-            }
-            //System.out.println("penalty " + posData.backPos[idx] + " to " + pos);
-            //cost += computePenalty(posData.backPos[idx], pos - posData.backPos[idx]);
-            if (cost < leastCost) {
-              //System.out.println("      ** ");
-              leastCost = cost;
-              leastIDX = idx;
-            }
-          }
-          //System.out.println("  leastIDX=" + leastIDX);
-
-          if (VERBOSE) {
-            System.out.println("  afterPrune: " + posData.count + " arcs arriving; leastCost=" + leastCost + " vs threshold=" + maxCost + " lastLeftWordID=" + lastLeftWordID);
-          }
-
-          if (leastIDX != -1 && leastCost <= maxCost && posData.backPos[leastIDX] != backPos) {
-            // We should have pruned the altToken from the graph:
-            assert posData.backPos[leastIDX] != backPos;
-
-            // Save the current compound token, to output when
-            // this alternate path joins back:
-            altToken = new Token(backID,
-                                 fragment,
-                                 backPos - lastBackTracePos,
-                                 length,
-                                 backType,
-                                 backPos,
-                                 getDict(backType));
-
-            // Redirect our backtrace to 2nd best:
-            bestIDX = leastIDX;
-            nextBestIDX = posData.backIndex[bestIDX];
-
-            backPos = posData.backPos[bestIDX];
-            length = pos - backPos;
-            backType = posData.backType[bestIDX];
-            backID = posData.backID[bestIDX];
-            backCount = 0;
-            //System.out.println("  do alt token!");
-            
-          } else {
-            // I think in theory it's possible there is no
-            // 2nd best path, which is fine; in this case we
-            // only output the compound token:
-            //System.out.println("  no alt token! bestIDX=" + bestIDX);
-          }
-        }
-      }
-
-      final int offset = backPos - lastBackTracePos;
-      assert offset >= 0;
-
-      if (altToken != null && altToken.getPosition() >= backPos) {
-
-        // We've backtraced to the position where the
-        // compound token starts; add it now:
-
-        // The pruning we did when we created the altToken
-        // ensures that the back trace will align back with
-        // the start of the altToken:
-        // cannot assert...
-        //assert altToken.getPosition() == backPos: altToken.getPosition() + " vs " + backPos;
-
-        if (VERBOSE) {
-          System.out.println("    add altToken=" + altToken);
-        }
-        if (backCount > 0) {
-          backCount++;
-          altToken.setPositionLength(backCount);
-          pending.add(altToken);
-        } else {
-          // This means alt token was all punct tokens:
-          assert discardPunctuation;
-        }
-        altToken = null;
-      }
-
-      final Dictionary dict = getDict(backType);
-
-      if (backType == Type.USER) {
-
-        // Expand the phraseID we recorded into the actual
-        // segmentation:
-        final int[] wordIDAndLength = userDictionary.lookupSegmentation(backID);
-        int wordID = wordIDAndLength[0];
-        int current = 0;
-        for(int j=1; j < wordIDAndLength.length; j++) {
-          final int len = wordIDAndLength[j];
-          //System.out.println("    add user: len=" + len);
-          pending.add(new Token(wordID+j-1,
-                                fragment,
-                                current + offset,
-                                len,
-                                Type.USER,
-                                current + backPos,
-                                dict));
-          if (VERBOSE) {
-            System.out.println("    add USER token=" + pending.get(pending.size()-1));
-          }
-          current += len;
-        }
-
-        // Reverse the tokens we just added, because when we
-        // serve them up from incrementToken we serve in
-        // reverse:
-        Collections.reverse(pending.subList(pending.size() - (wordIDAndLength.length - 1),
-                                            pending.size()));
-
-        backCount += wordIDAndLength.length-1;
-      } else {
-
-        if (extendedMode && backType == Type.UNKNOWN) {
-          // In EXTENDED mode we convert unknown word into
-          // unigrams:
-          int unigramTokenCount = 0;
-          for(int i=length-1;i>=0;i--) {
-            int charLen = 1;
-            if (i > 0 && Character.isLowSurrogate(fragment[offset+i])) {
-              i--;
-              charLen = 2;
-            }
-            //System.out.println("    extended tok offset="
-            //+ (offset + i));
-            if (!discardPunctuation || !isPunctuation(fragment[offset+i])) {
-              pending.add(new Token(CharacterDefinition.NGRAM,
-                                    fragment,
-                                    offset + i,
-                                    charLen,
-                                    Type.UNKNOWN,
-                                    backPos + i,
-                                    unkDictionary));
-              unigramTokenCount++;
-            }
-          }
-          backCount += unigramTokenCount;
-          
-        } else if (!discardPunctuation || length == 0 || !isPunctuation(fragment[offset])) {
-          pending.add(new Token(backID,
-                                fragment,
-                                offset,
-                                length,
-                                backType,
-                                backPos,
-                                dict));
-          if (VERBOSE) {
-            System.out.println("    add token=" + pending.get(pending.size()-1));
-          }
-          backCount++;
-        } else {
-          if (VERBOSE) {
-            System.out.println("    skip punctuation token=" + new String(fragment, offset, length));
-          }
-        }
-      }
-
-      lastLeftWordID = dict.getLeftId(backID);
-      pos = backPos;
-      bestIDX = nextBestIDX;
-    }
-
-    lastBackTracePos = endPos;
-
-    if (VERBOSE) {
-      System.out.println("  freeBefore pos=" + endPos);
-    }
-    // Notify the circular buffers that we are done with
-    // these positions:
-    buffer.freeBefore(endPos);
-    positions.freeBefore(endPos);
-  }
-
-  Dictionary getDict(Type type) {
-    return dictionaryMap.get(type);
-  }
-
-  private static boolean isPunctuation(char ch) {
-    switch(Character.getType(ch)) {
-      case Character.SPACE_SEPARATOR:
-      case Character.LINE_SEPARATOR:
-      case Character.PARAGRAPH_SEPARATOR:
-      case Character.CONTROL:
-      case Character.FORMAT:
-      case Character.DASH_PUNCTUATION:
-      case Character.START_PUNCTUATION:
-      case Character.END_PUNCTUATION:
-      case Character.CONNECTOR_PUNCTUATION:
-      case Character.OTHER_PUNCTUATION:
-      case Character.MATH_SYMBOL:
-      case Character.CURRENCY_SYMBOL:
-      case Character.MODIFIER_SYMBOL:
-      case Character.OTHER_SYMBOL:
-      case Character.INITIAL_QUOTE_PUNCTUATION:
-      case Character.FINAL_QUOTE_PUNCTUATION:
-        return true;
-      default:
-        return false;
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/Token.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/Token.java
deleted file mode 100644
index 6a1aef7..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/Token.java
+++ /dev/null
@@ -1,174 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Type;
-import org.apache.lucene.analysis.kuromoji.dict.Dictionary;
-
-/**
- * Analyzed token with morphological data from its dictionary.
- */
-public class Token {
-  private final Dictionary dictionary;
-  
-  private final int wordId;
-  
-  private final char[] surfaceForm;
-  private final int offset;
-  private final int length;
-  
-  private final int position;
-  private int positionLength;
-  
-  private final Type type;
-  
-  public Token(int wordId, char[] surfaceForm, int offset, int length, Type type, int position, Dictionary dictionary) {
-    this.wordId = wordId;
-    this.surfaceForm = surfaceForm;
-    this.offset = offset;
-    this.length = length;
-    this.type = type;
-    this.position = position;
-    this.positionLength = positionLength;
-    this.dictionary = dictionary;
-  }
-
-  @Override
-  public String toString() {
-    return "Token(\"" + new String(surfaceForm, offset, length) + "\" pos=" + position + " type=" + type + " wordId=" + wordId + " leftID=" + dictionary.getLeftId(wordId) + ")";
-  }
-  
-  /**
-   * @return surfaceForm
-   */
-  public char[] getSurfaceForm() {
-    return surfaceForm;
-  }
-  
-  /**
-   * @return offset into surfaceForm
-   */
-  public int getOffset() {
-    return offset;
-  }
-  
-  /**
-   * @return length of surfaceForm
-   */
-  public int getLength() {
-    return length;
-  }
-  
-  /**
-   * @return surfaceForm as a String
-   */
-  public String getSurfaceFormString() {
-    return new String(surfaceForm, offset, length);
-  }
-  
-  /**
-   * @return reading. null if token doesn't have reading.
-   */
-  public String getReading() {
-    return dictionary.getReading(wordId, surfaceForm, offset, length);
-  }
-  
-  /**
-   * @return pronunciation. null if token doesn't have pronunciation.
-   */
-  public String getPronunciation() {
-    return dictionary.getPronunciation(wordId, surfaceForm, offset, length);
-  }
-  
-  /**
-   * @return part of speech.
-   */
-  public String getPartOfSpeech() {
-    return dictionary.getPartOfSpeech(wordId);
-  }
-  
-  /**
-   * @return inflection type or null
-   */
-  public String getInflectionType() {
-    return dictionary.getInflectionType(wordId);
-  }
-  
-  /**
-   * @return inflection form or null
-   */
-  public String getInflectionForm() {
-    return dictionary.getInflectionForm(wordId);
-  }
-  
-  /**
-   * @return base form or null if token is not inflected
-   */
-  public String getBaseForm() {
-    return dictionary.getBaseForm(wordId, surfaceForm, offset, length);
-  }
-  
-  /**
-   * Returns true if this token is known word
-   * @return true if this token is in standard dictionary. false if not.
-   */
-  public boolean isKnown() {
-    return type == Type.KNOWN;
-  }
-  
-  /**
-   * Returns true if this token is unknown word
-   * @return true if this token is unknown word. false if not.
-   */
-  public boolean isUnknown() {
-    return type == Type.UNKNOWN;
-  }
-  
-  /**
-   * Returns true if this token is defined in user dictionary
-   * @return true if this token is in user dictionary. false if not.
-   */
-  public boolean isUser() {
-    return type == Type.USER;
-  }
-  
-  /**
-   * Get index of this token in input text
-   * @return position of token
-   */
-  public int getPosition() {
-    return position;
-  }
-
-  /**
-   * Set the position length (in tokens) of this token.  For normal
-   * tokens this is 1; for compound tokens it's > 1.
-   */
-  public void setPositionLength(int positionLength) {
-    this.positionLength = positionLength;
-  }
-  
-  /**
-   * Get the length (in tokens) of this token.  For normal
-   * tokens this is 1; for compound tokens it's > 1.
-   * @return position length of token
-   */
-  public int getPositionLength() {
-    return positionLength;
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/BinaryDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/BinaryDictionary.java
deleted file mode 100644
index 7f383c3..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/BinaryDictionary.java
+++ /dev/null
@@ -1,295 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedInputStream;
-import java.io.EOFException;
-import java.io.IOException;
-import java.io.FileNotFoundException;
-import java.io.InputStream;
-import java.nio.ByteBuffer;
-import java.nio.channels.Channels;
-import java.nio.channels.ReadableByteChannel;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.InputStreamDataInput;
-import org.apache.lucene.util.CodecUtil;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.IOUtils;
-
-/**
- * Base class for a binary-encoded in-memory dictionary.
- */
-public abstract class BinaryDictionary implements Dictionary {
-  
-  public static final String DICT_FILENAME_SUFFIX = "$buffer.dat";
-  public static final String TARGETMAP_FILENAME_SUFFIX = "$targetMap.dat";
-  public static final String POSDICT_FILENAME_SUFFIX = "$posDict.dat";
-  
-  public static final String DICT_HEADER = "kuromoji_dict";
-  public static final String TARGETMAP_HEADER = "kuromoji_dict_map";
-  public static final String POSDICT_HEADER = "kuromoji_dict_pos";
-  public static final int VERSION = 1;
-  
-  private final ByteBuffer buffer;
-  private final int[] targetMapOffsets, targetMap;
-  private final String[] posDict;
-  private final String[] inflTypeDict;
-  private final String[] inflFormDict;
-  
-  protected BinaryDictionary() throws IOException {
-    InputStream mapIS = null, dictIS = null, posIS = null;
-    IOException priorE = null;
-    int[] targetMapOffsets = null, targetMap = null;
-    String[] posDict = null;
-    String[] inflFormDict = null;
-    String[] inflTypeDict = null;
-    ByteBuffer buffer = null;
-    try {
-      mapIS = getResource(TARGETMAP_FILENAME_SUFFIX);
-      mapIS = new BufferedInputStream(mapIS);
-      DataInput in = new InputStreamDataInput(mapIS);
-      CodecUtil.checkHeader(in, TARGETMAP_HEADER, VERSION, VERSION);
-      targetMap = new int[in.readVInt()];
-      targetMapOffsets = new int[in.readVInt()];
-      int accum = 0, sourceId = 0;
-      for (int ofs = 0; ofs < targetMap.length; ofs++) {
-        final int val = in.readVInt();
-        if ((val & 0x01) != 0) {
-          targetMapOffsets[sourceId] = ofs;
-          sourceId++;
-        }
-        accum += val >>> 1;
-        targetMap[ofs] = accum;
-      }
-      if (sourceId + 1 != targetMapOffsets.length)
-        throw new IOException("targetMap file format broken");
-      targetMapOffsets[sourceId] = targetMap.length;
-      mapIS.close(); mapIS = null;
-      
-      posIS = getResource(POSDICT_FILENAME_SUFFIX);
-      posIS = new BufferedInputStream(posIS);
-      in = new InputStreamDataInput(posIS);
-      CodecUtil.checkHeader(in, POSDICT_HEADER, VERSION, VERSION);
-      int posSize = in.readVInt();
-      posDict = new String[posSize];
-      inflTypeDict = new String[posSize];
-      inflFormDict = new String[posSize];
-      for (int j = 0; j < posSize; j++) {
-        posDict[j] = in.readString();
-        inflTypeDict[j] = in.readString();
-        inflFormDict[j] = in.readString();
-        // this is how we encode null inflections
-        if (inflTypeDict[j].length() == 0) {
-          inflTypeDict[j] = null;
-        }
-        if (inflFormDict[j].length() == 0) {
-          inflFormDict[j] = null;
-        }
-      }
-      posIS.close(); posIS = null;
-      
-      dictIS = getResource(DICT_FILENAME_SUFFIX);
-      // no buffering here, as we load in one large buffer
-      in = new InputStreamDataInput(dictIS);
-      CodecUtil.checkHeader(in, DICT_HEADER, VERSION, VERSION);
-      final int size = in.readVInt();
-      final ByteBuffer tmpBuffer = ByteBuffer.allocateDirect(size);
-      final ReadableByteChannel channel = Channels.newChannel(dictIS);
-      final int read = channel.read(tmpBuffer);
-      if (read != size) {
-        throw new EOFException("Cannot read whole dictionary");
-      }
-      dictIS.close(); dictIS = null;
-      buffer = tmpBuffer.asReadOnlyBuffer();
-    } catch (IOException ioe) {
-      priorE = ioe;
-    } finally {
-      IOUtils.closeWhileHandlingException(priorE, mapIS, posIS, dictIS);
-    }
-    
-    this.targetMap = targetMap;
-    this.targetMapOffsets = targetMapOffsets;
-    this.posDict = posDict;
-    this.inflTypeDict = inflTypeDict;
-    this.inflFormDict = inflFormDict;
-    this.buffer = buffer;
-  }
-  
-  protected final InputStream getResource(String suffix) throws IOException {
-    return getClassResource(getClass(), suffix);
-  }
-  
-  // util, reused by ConnectionCosts and CharacterDefinition
-  public static final InputStream getClassResource(Class<?> clazz, String suffix) throws IOException {
-    final InputStream is = clazz.getResourceAsStream(clazz.getSimpleName() + suffix);
-    if (is == null)
-      throw new FileNotFoundException("Not in classpath: " + clazz.getName().replace('.','/') + suffix);
-    return is;
-  }
-  
-  public void lookupWordIds(int sourceId, IntsRef ref) {
-    ref.ints = targetMap;
-    ref.offset = targetMapOffsets[sourceId];
-    // targetMapOffsets always has one more entry pointing behind last:
-    ref.length = targetMapOffsets[sourceId + 1] - ref.offset;
-  }
-  
-  @Override	
-  public int getLeftId(int wordId) {
-    return buffer.getShort(wordId) >>> 3;
-  }
-  
-  @Override
-  public int getRightId(int wordId) {
-    return buffer.getShort(wordId) >>> 3;
-  }
-  
-  @Override
-  public int getWordCost(int wordId) {
-    return buffer.getShort(wordId + 2);	// Skip id
-  }
-
-  @Override
-  public String getBaseForm(int wordId, char surfaceForm[], int off, int len) {
-    if (hasBaseFormData(wordId)) {
-      int offset = baseFormOffset(wordId);
-      int data = buffer.get(offset++) & 0xff;
-      int prefix = data >>> 4;
-      int suffix = data & 0xF;
-      char text[] = new char[prefix+suffix];
-      System.arraycopy(surfaceForm, off, text, 0, prefix);
-      for (int i = 0; i < suffix; i++) {
-        text[prefix+i] = buffer.getChar(offset + (i << 1));
-      }
-      return new String(text);
-    } else {
-      return null;
-    }
-  }
-  
-  @Override
-  public String getReading(int wordId, char surface[], int off, int len) {
-    if (hasReadingData(wordId)) {
-      int offset = readingOffset(wordId);
-      int readingData = buffer.get(offset++) & 0xff;
-      return readString(offset, readingData >>> 1, (readingData & 1) == 1);
-    } else {
-      // the reading is the surface form, with hiragana shifted to katakana
-      char text[] = new char[len];
-      for (int i = 0; i < len; i++) {
-        char ch = surface[off+i];
-        if (ch > 0x3040 && ch < 0x3097) {
-          text[i] = (char)(ch + 0x60);
-        } else {
-          text[i] = ch;
-        }
-      }
-      return new String(text);
-    }
-  }
-  
-  @Override
-  public String getPartOfSpeech(int wordId) {
-    return posDict[getLeftId(wordId)];
-  }
-  
-  @Override
-  public String getPronunciation(int wordId, char surface[], int off, int len) {
-    if (hasPronunciationData(wordId)) {
-      int offset = pronunciationOffset(wordId);
-      int pronunciationData = buffer.get(offset++) & 0xff;
-      return readString(offset, pronunciationData >>> 1, (pronunciationData & 1) == 1);
-    } else {
-      return getReading(wordId, surface, off, len); // same as the reading
-    }
-  }
-  
-  @Override
-  public String getInflectionType(int wordId) {
-    return inflTypeDict[getLeftId(wordId)];
-  }
-
-  @Override
-  public String getInflectionForm(int wordId) {
-    return inflFormDict[getLeftId(wordId)];
-  }
-  
-  private static int baseFormOffset(int wordId) {
-    return wordId + 4;
-  }
-  
-  private int readingOffset(int wordId) {
-    int offset = baseFormOffset(wordId);
-    if (hasBaseFormData(wordId)) {
-      int baseFormLength = buffer.get(offset++) & 0xf;
-      return offset + (baseFormLength << 1);
-    } else {
-      return offset;
-    }
-  }
-  
-  private int pronunciationOffset(int wordId) {
-    if (hasReadingData(wordId)) {
-      int offset = readingOffset(wordId);
-      int readingData = buffer.get(offset++) & 0xff;
-      final int readingLength;
-      if ((readingData & 1) == 0) {
-        readingLength = readingData & 0xfe; // UTF-16: mask off kana bit
-      } else {
-        readingLength = readingData >>> 1;
-      }
-      return offset + readingLength;
-    } else {
-      return readingOffset(wordId);
-    }
-  }
-  
-  private boolean hasBaseFormData(int wordId) {
-    return (buffer.getShort(wordId) & HAS_BASEFORM) != 0;
-  }
-  
-  private boolean hasReadingData(int wordId) {
-    return (buffer.getShort(wordId) & HAS_READING) != 0;
-  }
-  
-  private boolean hasPronunciationData(int wordId) {
-    return (buffer.getShort(wordId) & HAS_PRONUNCIATION) != 0;
-  }
-  
-  private String readString(int offset, int length, boolean kana) {
-    char text[] = new char[length];
-    if (kana) {
-      for (int i = 0; i < length; i++) {
-        text[i] = (char) (0x30A0 + (buffer.get(offset + i) & 0xff));
-      }
-    } else {
-      for (int i = 0; i < length; i++) {
-        text[i] = buffer.getChar(offset + (i << 1));
-      }
-    }
-    return new String(text);
-  }
-  
-  /** flag that the entry has baseform data. otherwise its not inflected (same as surface form) */
-  public static final int HAS_BASEFORM = 1;
-  /** flag that the entry has reading data. otherwise reading is surface form converted to katakana */
-  public static final int HAS_READING = 2;
-  /** flag that the entry has pronunciation data. otherwise pronunciation is the reading */
-  public static final int HAS_PRONUNCIATION = 4;
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.java
deleted file mode 100644
index 123d640..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.java
+++ /dev/null
@@ -1,120 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.InputStreamDataInput;
-import org.apache.lucene.util.CodecUtil;
-import org.apache.lucene.util.IOUtils;
-
-/**
- * Character category data.
- */
-public final class CharacterDefinition {
-
-  public static final String FILENAME_SUFFIX = ".dat";
-  public static final String HEADER = "kuromoji_cd";
-  public static final int VERSION = 1;
-
-  public static final int CLASS_COUNT = CharacterClass.values().length;
-  
-  // only used internally for lookup:
-  private static enum CharacterClass {
-    NGRAM, DEFAULT, SPACE, SYMBOL, NUMERIC, ALPHA, CYRILLIC, GREEK, HIRAGANA, KATAKANA, KANJI, KANJINUMERIC;
-  }
-      
-  private final byte[] characterCategoryMap = new byte[0x10000];
-  
-  private final boolean[] invokeMap = new boolean[CLASS_COUNT];
-  private final boolean[] groupMap = new boolean[CLASS_COUNT];
-  
-  // the classes:
-  public static final byte NGRAM = (byte) CharacterClass.NGRAM.ordinal();
-  public static final byte DEFAULT = (byte) CharacterClass.DEFAULT.ordinal();
-  public static final byte SPACE = (byte) CharacterClass.SPACE.ordinal();
-  public static final byte SYMBOL = (byte) CharacterClass.SYMBOL.ordinal();
-  public static final byte NUMERIC = (byte) CharacterClass.NUMERIC.ordinal();
-  public static final byte ALPHA = (byte) CharacterClass.ALPHA.ordinal();
-  public static final byte CYRILLIC = (byte) CharacterClass.CYRILLIC.ordinal();
-  public static final byte GREEK = (byte) CharacterClass.GREEK.ordinal();
-  public static final byte HIRAGANA = (byte) CharacterClass.HIRAGANA.ordinal();
-  public static final byte KATAKANA = (byte) CharacterClass.KATAKANA.ordinal();
-  public static final byte KANJI = (byte) CharacterClass.KANJI.ordinal();
-  public static final byte KANJINUMERIC = (byte) CharacterClass.KANJINUMERIC.ordinal();
-  
-  private CharacterDefinition() throws IOException {
-    IOException priorE = null;
-    InputStream is = null;
-    try {
-      is = BinaryDictionary.getClassResource(getClass(), FILENAME_SUFFIX);
-      is = new BufferedInputStream(is);
-      final DataInput in = new InputStreamDataInput(is);
-      CodecUtil.checkHeader(in, HEADER, VERSION, VERSION);
-      in.readBytes(characterCategoryMap, 0, characterCategoryMap.length);
-      for (int i = 0; i < CLASS_COUNT; i++) {
-        final byte b = in.readByte();
-        invokeMap[i] = (b & 0x01) != 0;
-        groupMap[i] = (b & 0x02) != 0;
-      }
-    } catch (IOException ioe) {
-      priorE = ioe;
-    } finally {
-      IOUtils.closeWhileHandlingException(priorE, is);
-    }
-  }
-  
-  public byte getCharacterClass(char c) {
-    return characterCategoryMap[c];
-  }
-  
-  public boolean isInvoke(char c) {
-    return invokeMap[characterCategoryMap[c]];
-  }
-  
-  public boolean isGroup(char c) {
-    return groupMap[characterCategoryMap[c]];
-  }
-  
-  public boolean isKanji(char c) {
-    final byte characterClass = characterCategoryMap[c];
-    return characterClass == KANJI || characterClass == KANJINUMERIC;
-  }
-  
-  public static byte lookupCharacterClass(String characterClassName) {
-    return (byte) CharacterClass.valueOf(characterClassName).ordinal();
-  }
-
-  public static CharacterDefinition getInstance() {
-    return SingletonHolder.INSTANCE;
-  }
-  
-  private static class SingletonHolder {
-    static final CharacterDefinition INSTANCE;
-    static {
-      try {
-        INSTANCE = new CharacterDefinition();
-      } catch (IOException ioe) {
-        throw new RuntimeException("Cannot load CharacterDefinition.", ioe);
-      }
-    }
-   }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.java
deleted file mode 100644
index f26b927..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.java
+++ /dev/null
@@ -1,89 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-
-import org.apache.lucene.store.DataInput;
-import org.apache.lucene.store.InputStreamDataInput;
-import org.apache.lucene.util.CodecUtil;
-import org.apache.lucene.util.IOUtils;
-
-/**
- * n-gram connection cost data
- */
-public final class ConnectionCosts {
-  
-  public static final String FILENAME_SUFFIX = ".dat";
-  public static final String HEADER = "kuromoji_cc";
-  public static final int VERSION = 1;
-  
-  private final short[][] costs; // array is backward IDs first since get is called using the same backward ID consecutively. maybe doesn't matter.
-  
-  private ConnectionCosts() throws IOException {
-    IOException priorE = null;
-    InputStream is = null;
-    short[][] costs = null;
-    try {
-      is = BinaryDictionary.getClassResource(getClass(), FILENAME_SUFFIX);
-      is = new BufferedInputStream(is);
-      final DataInput in = new InputStreamDataInput(is);
-      CodecUtil.checkHeader(in, HEADER, VERSION, VERSION);
-      int forwardSize = in.readVInt();
-      int backwardSize = in.readVInt();
-      costs = new short[backwardSize][forwardSize];
-      int accum = 0;
-      for (int j = 0; j < costs.length; j++) {
-        final short[] a = costs[j];
-        for (int i = 0; i < a.length; i++) {
-          int raw = in.readVInt();
-          accum += (raw >>> 1) ^ -(raw & 1);
-          a[i] = (short)accum;
-        }
-      }
-    } catch (IOException ioe) {
-      priorE = ioe;
-    } finally {
-      IOUtils.closeWhileHandlingException(priorE, is);
-    }
-    
-    this.costs = costs;
-  }
-  
-  public int get(int forwardId, int backwardId) {
-    return costs[backwardId][forwardId];
-  }
-  
-  public static ConnectionCosts getInstance() {
-    return SingletonHolder.INSTANCE;
-  }
-  
-  private static class SingletonHolder {
-    static final ConnectionCosts INSTANCE;
-    static {
-      try {
-        INSTANCE = new ConnectionCosts();
-      } catch (IOException ioe) {
-        throw new RuntimeException("Cannot load ConnectionCosts.", ioe);
-      }
-    }
-   }
-  
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/Dictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/Dictionary.java
deleted file mode 100644
index 7f21cb4..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/Dictionary.java
+++ /dev/null
@@ -1,92 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Dictionary interface for retrieving morphological data
- * by id.
- */
-public interface Dictionary {
-  
-  public static final String INTERNAL_SEPARATOR = "\u0000";
-  
-  /**
-   * Get left id of specified word
-   * @param wordId
-   * @return	left id
-   */
-  public int getLeftId(int wordId);
-  
-  /**
-   * Get right id of specified word
-   * @param wordId
-   * @return	left id
-   */
-  public int getRightId(int wordId);
-  
-  /**
-   * Get word cost of specified word
-   * @param wordId
-   * @return	left id
-   */
-  public int getWordCost(int wordId);
-  
-  /**
-   * Get Part-Of-Speech of tokens
-   * @param wordId word ID of token
-   * @return Part-Of-Speech of the token
-   */
-  public String getPartOfSpeech(int wordId);
-  
-  /**
-   * Get reading of tokens
-   * @param wordId word ID of token
-   * @return Reading of the token
-   */
-  public String getReading(int wordId, char surface[], int off, int len);
-  
-  /**
-   * Get base form of word
-   * @param wordId word ID of token
-   * @return Base form (only different for inflected words, otherwise null)
-   */
-  public String getBaseForm(int wordId, char surface[], int off, int len);
-  
-  /**
-   * Get pronunciation of tokens
-   * @param wordId word ID of token
-   * @return Pronunciation of the token
-   */
-  public String getPronunciation(int wordId, char surface[], int off, int len);
-  
-  /**
-   * Get inflection type of tokens
-   * @param wordId word ID of token
-   * @return inflection type, or null
-   */
-  public String getInflectionType(int wordId);
-  
-  /**
-   * Get inflection form of tokens
-   * @param wordId word ID of token
-   * @return inflection form, or null
-   */
-  public String getInflectionForm(int wordId);
-  // TODO: maybe we should have a optimal method, a non-typesafe
-  // 'getAdditionalData' if other dictionaries like unidic have additional data
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary.java
deleted file mode 100644
index 3fddf25..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary.java
+++ /dev/null
@@ -1,76 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedInputStream;
-import java.io.InputStream;
-import java.io.IOException;
-
-import org.apache.lucene.store.InputStreamDataInput;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.fst.FST;
-import org.apache.lucene.util.fst.PositiveIntOutputs;
-
-/**
- * Binary dictionary implementation for a known-word dictionary model:
- * Words are encoded into an FST mapping to a list of wordIDs.
- */
-public final class TokenInfoDictionary extends BinaryDictionary {
-
-  public static final String FST_FILENAME_SUFFIX = "$fst.dat";
-
-  private final TokenInfoFST fst;
-  
-  private TokenInfoDictionary() throws IOException {
-    super();
-    IOException priorE = null;
-    InputStream is = null;
-    FST<Long> fst = null;
-    try {
-      is = getResource(FST_FILENAME_SUFFIX);
-      is = new BufferedInputStream(is);
-      fst = new FST<Long>(new InputStreamDataInput(is), PositiveIntOutputs.getSingleton(true));
-    } catch (IOException ioe) {
-      priorE = ioe;
-    } finally {
-      IOUtils.closeWhileHandlingException(priorE, is);
-    }
-    // TODO: some way to configure?
-    this.fst = new TokenInfoFST(fst, true);
-  }
-  
-  public TokenInfoFST getFST() {
-    return fst;
-  }
-   
-  public static TokenInfoDictionary getInstance() {
-    return SingletonHolder.INSTANCE;
-  }
-  
-  private static class SingletonHolder {
-    static final TokenInfoDictionary INSTANCE;
-    static {
-      try {
-        INSTANCE = new TokenInfoDictionary();
-      } catch (IOException ioe) {
-        throw new RuntimeException("Cannot load TokenInfoDictionary.", ioe);
-      }
-    }
-   }
-  
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoFST.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoFST.java
deleted file mode 100644
index 46def27..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/TokenInfoFST.java
+++ /dev/null
@@ -1,94 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.util.fst.FST;
-import org.apache.lucene.util.fst.FST.Arc;
-
-/**
- * Thin wrapper around an FST with root-arc caching for Japanese.
- * <p>
- * Depending upon fasterButMoreRam, either just kana (191 arcs),
- * or kana and han (28,607 arcs) are cached. The latter offers
- * additional performance at the cost of more RAM.
- */
-public final class TokenInfoFST {
-  private final FST<Long> fst;
-
-  // depending upon fasterButMoreRam, we cache root arcs for either 
-  // kana (0x3040-0x30FF) or kana + han (0x3040-0x9FFF)
-  // false: 191 arcs
-  // true:  28,607 arcs (costs ~1.5MB)
-  private final int cacheCeiling;
-  private final FST.Arc<Long> rootCache[];
-  
-  public final Long NO_OUTPUT;
-
-  public TokenInfoFST(FST<Long> fst, boolean fasterButMoreRam) throws IOException {
-    this.fst = fst;
-    this.cacheCeiling = fasterButMoreRam ? 0x9FFF : 0x30FF;
-    NO_OUTPUT = fst.outputs.getNoOutput();
-    rootCache = cacheRootArcs();
-  }
-  
-  @SuppressWarnings("unchecked")
-  private FST.Arc<Long>[] cacheRootArcs() throws IOException {
-    FST.Arc<Long> rootCache[] = new FST.Arc[1+(cacheCeiling-0x3040)];
-    FST.Arc<Long> firstArc = new FST.Arc<Long>();
-    fst.getFirstArc(firstArc);
-    FST.Arc<Long> arc = new FST.Arc<Long>();
-    final FST.BytesReader fstReader = fst.getBytesReader(0);
-    // TODO: jump to 3040, readNextRealArc to ceiling? (just be careful we don't add bugs)
-    for (int i = 0; i < rootCache.length; i++) {
-      if (fst.findTargetArc(0x3040 + i, firstArc, arc, fstReader) != null) {
-        rootCache[i] = new FST.Arc<Long>().copyFrom(arc);
-      }
-    }
-    return rootCache;
-  }
-  
-  public FST.Arc<Long> findTargetArc(int ch, FST.Arc<Long> follow, FST.Arc<Long> arc, boolean useCache, FST.BytesReader fstReader) throws IOException {
-    if (useCache && ch >= 0x3040 && ch <= cacheCeiling) {
-      assert ch != FST.END_LABEL;
-      final Arc<Long> result = rootCache[ch - 0x3040];
-      if (result == null) {
-        return null;
-      } else {
-        arc.copyFrom(result);
-        return arc;
-      }
-    } else {
-      return fst.findTargetArc(ch, follow, arc, fstReader);
-    }
-  }
-  
-  public Arc<Long> getFirstArc(FST.Arc<Long> arc) {
-    return fst.getFirstArc(arc);
-  }
-
-  public FST.BytesReader getBytesReader(int pos) {
-    return fst.getBytesReader(pos);
-  }
-  
-  /** @lucene.internal for testing only */
-  FST<Long> getInternalFST() {
-    return fst;
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary.java
deleted file mode 100644
index 8f800b0..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary.java
+++ /dev/null
@@ -1,86 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-/**
- * Dictionary for unknown-word handling.
- */
-public final class UnknownDictionary extends BinaryDictionary {
-
-  private final CharacterDefinition characterDefinition = CharacterDefinition.getInstance();
-  
-  private UnknownDictionary() throws IOException {
-    super();
-  }
-  
-  public int lookup(char[] text, int offset, int len) {
-    if(!characterDefinition.isGroup(text[offset])) {
-      return 1;
-    }
-    
-    // Extract unknown word. Characters with the same character class are considered to be part of unknown word
-    byte characterIdOfFirstCharacter = characterDefinition.getCharacterClass(text[offset]);
-    int length = 1;
-    for (int i = 1; i < len; i++) {
-      if (characterIdOfFirstCharacter == characterDefinition.getCharacterClass(text[offset+i])){
-        length++;    			
-      } else {
-        break;
-      }
-    }
-    
-    return length;
-  }
-  
-  public CharacterDefinition getCharacterDefinition() {
-    return characterDefinition;
-  }
-  
-  @Override
-  public String getReading(int wordId, char surface[], int off, int len) {
-    return null;
-  }
-
-  @Override
-  public String getInflectionType(int wordId) {
-    return null;
-  }
-
-  @Override
-  public String getInflectionForm(int wordId) {
-    return null;
-  }
-
-  public static UnknownDictionary getInstance() {
-    return SingletonHolder.INSTANCE;
-  }
-  
-  private static class SingletonHolder {
-    static final UnknownDictionary INSTANCE;
-    static {
-      try {
-        INSTANCE = new UnknownDictionary();
-      } catch (IOException ioe) {
-        throw new RuntimeException("Cannot load UnknownDictionary.", ioe);
-      }
-    }
-   }
-  
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UserDictionary.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UserDictionary.java
deleted file mode 100644
index 7190d76..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/UserDictionary.java
+++ /dev/null
@@ -1,273 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedReader;
-import java.io.IOException;
-import java.io.Reader;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.List;
-import java.util.Map;
-import java.util.TreeMap;
-
-import org.apache.lucene.analysis.kuromoji.dict.Dictionary;
-import org.apache.lucene.analysis.kuromoji.util.CSVUtil;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.fst.Builder;
-import org.apache.lucene.util.fst.FST;
-import org.apache.lucene.util.fst.PositiveIntOutputs;
-
-/**
- * Class for building a User Dictionary.
- * This class allows for custom segmentation of phrases.
- */
-public final class UserDictionary implements Dictionary {
-  
-  // phrase text -> phrase ID
-  private final TokenInfoFST fst;
-  
-  // holds wordid, length, length... indexed by phrase ID
-  private final int segmentations[][];
-  
-  // holds readings and POS, indexed by wordid
-  private final String data[];
-  
-  private static final int CUSTOM_DICTIONARY_WORD_ID_OFFSET = 100000000;
-  
-  public static final int WORD_COST = -100000;
-  
-  public static final int LEFT_ID = 5;
-  
-  public static final int RIGHT_ID = 5;
-  
-  public UserDictionary(Reader reader) throws IOException {
-    BufferedReader br = new BufferedReader(reader);
-    String line = null;
-    int wordId = CUSTOM_DICTIONARY_WORD_ID_OFFSET;
-    List<String[]> featureEntries = new ArrayList<String[]>();
- 
-    // text, segmentation, readings, POS
-    while ((line = br.readLine()) != null) {
-      // Remove comments
-      line = line.replaceAll("#.*$", "");
-      
-      // Skip empty lines or comment lines
-      if (line.trim().length() == 0) {
-        continue;
-      }
-      String[] values = CSVUtil.parse(line);
-      featureEntries.add(values);
-    }
-    
-    // TODO: should we allow multiple segmentations per input 'phrase'?
-    // the old treemap didn't support this either, and i'm not sure if its needed/useful?
-
-    Collections.sort(featureEntries, new Comparator<String[]>() {
-      @Override
-      public int compare(String[] left, String[] right) {
-        return left[0].compareTo(right[0]);
-     }
-    });
-    
-    List<String> data = new ArrayList<String>(featureEntries.size());
-    List<int[]> segmentations = new ArrayList<int[]>(featureEntries.size());
-    
-    PositiveIntOutputs fstOutput = PositiveIntOutputs.getSingleton(true);
-    Builder<Long> fstBuilder = new Builder<Long>(FST.INPUT_TYPE.BYTE2, fstOutput);
-    IntsRef scratch = new IntsRef();
-    long ord = 0;
-    
-    for (String[] values : featureEntries) {
-      String[] segmentation = values[1].replaceAll("  *", " ").split(" ");
-      String[] readings = values[2].replaceAll("  *", " ").split(" ");
-      String pos = values[3];
-      
-      if (segmentation.length != readings.length) {
-        // FIXME: Should probably deal with this differently.  Exception?
-        System.out.println("This entry is not properly formatted : " + line);
-      }
-      
-      int[] wordIdAndLength = new int[segmentation.length + 1]; // wordId offset, length, length....
-      wordIdAndLength[0] = wordId;
-      for (int i = 0; i < segmentation.length; i++) {
-        wordIdAndLength[i + 1] = segmentation[i].length();
-        data.add(readings[i] + INTERNAL_SEPARATOR + pos);
-        wordId++;
-      }
-      // add mapping to FST
-      String token = values[0];
-      scratch.grow(token.length());
-      scratch.length = token.length();
-      for (int i = 0; i < token.length(); i++) {
-        scratch.ints[i] = (int) token.charAt(i);
-      }
-      fstBuilder.add(scratch, ord);
-      segmentations.add(wordIdAndLength);
-      ord++;
-    }
-    this.fst = new TokenInfoFST(fstBuilder.finish(), false);
-    this.data = data.toArray(new String[data.size()]);
-    this.segmentations = segmentations.toArray(new int[segmentations.size()][]);
-  }
-  
-  /**
-   * Lookup words in text
-   * @param chars text
-   * @param off offset into text
-   * @param len length of text
-   * @return array of {wordId, position, length}
-   */
-  public int[][] lookup(char[] chars, int off, int len) throws IOException {
-    // TODO: can we avoid this treemap/toIndexArray?
-    TreeMap<Integer, int[]> result = new TreeMap<Integer, int[]>(); // index, [length, length...]
-    boolean found = false; // true if we found any results
-
-    final FST.BytesReader fstReader = fst.getBytesReader(0);
-
-    FST.Arc<Long> arc = new FST.Arc<Long>();
-    int end = off + len;
-    for (int startOffset = off; startOffset < end; startOffset++) {
-      arc = fst.getFirstArc(arc);
-      int output = 0;
-      int remaining = end - startOffset;
-      for (int i = 0; i < remaining; i++) {
-        int ch = chars[startOffset+i];
-        if (fst.findTargetArc(ch, arc, arc, i == 0, fstReader) == null) {
-          break; // continue to next position
-        }
-        output += arc.output.intValue();
-        if (arc.isFinal()) {
-          final int finalOutput = output + arc.nextFinalOutput.intValue();
-          result.put(startOffset-off, segmentations[finalOutput]);
-          found = true;
-        }
-      }
-    }
-    
-    return found ? toIndexArray(result) : EMPTY_RESULT;
-  }
-  
-  public TokenInfoFST getFST() {
-    return fst;
-  }
-
-  private static final int[][] EMPTY_RESULT = new int[0][];
-  
-  /**
-   * Convert Map of index and wordIdAndLength to array of {wordId, index, length}
-   * @param input
-   * @return array of {wordId, index, length}
-   */
-  private int[][] toIndexArray(Map<Integer, int[]> input) {
-    ArrayList<int[]> result = new ArrayList<int[]>();
-    for (int i : input.keySet()) {
-      int[] wordIdAndLength = input.get(i);
-      int wordId = wordIdAndLength[0];
-      // convert length to index
-      int current = i;
-      for (int j = 1; j < wordIdAndLength.length; j++) { // first entry is wordId offset
-        int[] token = { wordId + j - 1, current, wordIdAndLength[j] };
-        result.add(token);
-        current += wordIdAndLength[j];
-      }
-    }
-    return result.toArray(new int[result.size()][]);
-  }
-
-  public int[] lookupSegmentation(int phraseID) {
-    return segmentations[phraseID];
-  }
-  
-  @Override
-  public int getLeftId(int wordId) {
-    return LEFT_ID;
-  }
-  
-  @Override
-  public int getRightId(int wordId) {
-    return RIGHT_ID;
-  }
-  
-  @Override
-  public int getWordCost(int wordId) {
-    return WORD_COST;
-  }
-  
-  @Override
-  public String getReading(int wordId, char surface[], int off, int len) {
-    return getFeature(wordId, 0);
-  }
-  
-  @Override
-  public String getPartOfSpeech(int wordId) {
-    return getFeature(wordId, 1);
-  }
-  
-  @Override
-  public String getBaseForm(int wordId, char surface[], int off, int len) {
-    return null; // TODO: add support?
-  }
-  
-  @Override
-  public String getPronunciation(int wordId, char surface[], int off, int len) {
-    return null; // TODO: add support?
-  }
-  
-  @Override
-  public String getInflectionType(int wordId) {
-    return null; // TODO: add support?
-  }
-
-  @Override
-  public String getInflectionForm(int wordId) {
-    return null; // TODO: add support?
-  }
-  
-  private String[] getAllFeaturesArray(int wordId) {
-    String allFeatures = data[wordId-CUSTOM_DICTIONARY_WORD_ID_OFFSET];
-    if(allFeatures == null) {
-      return null;
-    }
-    
-    return allFeatures.split(INTERNAL_SEPARATOR);		
-  }
-  
-  
-  private String getFeature(int wordId, int... fields) {
-    String[] allFeatures = getAllFeaturesArray(wordId);
-    if (allFeatures == null) {
-      return null;
-    }
-    StringBuilder sb = new StringBuilder();
-    if (fields.length == 0) { // All features
-      for (String feature : allFeatures) {
-        sb.append(CSVUtil.quoteEscape(feature)).append(",");
-      }
-    } else if (fields.length == 1) { // One feature doesn't need to escape value
-      sb.append(allFeatures[fields[0]]).append(",");			
-    } else {
-      for (int field : fields){
-        sb.append(CSVUtil.quoteEscape(allFeatures[field])).append(",");
-      }
-    }
-    return sb.deleteCharAt(sb.length() - 1).toString();
-  }
-  
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/package.html
deleted file mode 100644
index 10b3f38..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/dict/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Kuromoji dictionary implementation.
-</body>
-</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/package.html
deleted file mode 100644
index 116bdca..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Analyzer for Japanese.
-</body>
-</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttribute.java
deleted file mode 100644
index ee24459..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttribute.java
+++ /dev/null
@@ -1,32 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.util.Attribute;
-
-/**
- * Attribute for {@link Token#getBaseForm()}.
- * <p>
- * Note: depending on part of speech, this value may not be applicable,
- * and will be null.
- */
-public interface BaseFormAttribute extends Attribute {
-  public String getBaseForm();
-  public void setToken(Token token);
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttributeImpl.java
deleted file mode 100644
index 5f4ffdc..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/BaseFormAttributeImpl.java
+++ /dev/null
@@ -1,53 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.AttributeReflector;
-
-/**
- * Attribute for {@link Token#getBaseForm()}.
- */
-public class BaseFormAttributeImpl extends AttributeImpl implements BaseFormAttribute, Cloneable {
-  private Token token;
-  
-  public String getBaseForm() {
-    return token == null ? null : token.getBaseForm();
-  }
-  
-  public void setToken(Token token) {
-    this.token = token;
-  }
-
-  @Override
-  public void clear() {
-    token = null;
-  }
-
-  @Override
-  public void copyTo(AttributeImpl target) {
-    BaseFormAttribute t = (BaseFormAttribute) target;
-    t.setToken(token);
-  }
-  
-  @Override
-  public void reflectWith(AttributeReflector reflector) {
-    reflector.reflect(BaseFormAttribute.class, "baseForm", getBaseForm());
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttribute.java
deleted file mode 100644
index 3205db0..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttribute.java
+++ /dev/null
@@ -1,33 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.util.Attribute;
-
-/**
- * Attribute for Kuromoji inflection data.
- * <p>
- * Note: in some cases this value may not be applicable,
- * and will be null.
- */
-public interface InflectionAttribute extends Attribute {
-  public String getInflectionType();
-  public String getInflectionForm();
-  public void setToken(Token token);
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttributeImpl.java
deleted file mode 100644
index c1af59c..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/InflectionAttributeImpl.java
+++ /dev/null
@@ -1,65 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.analysis.kuromoji.util.ToStringUtil;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.AttributeReflector;
-
-/**
- * Attribute for Kuromoji inflection data.
- */
-public class InflectionAttributeImpl extends AttributeImpl implements InflectionAttribute, Cloneable {
-  private Token token;
-  
-  public String getInflectionType() {
-    return token == null ? null : token.getInflectionType();
-  }
-  
-  public String getInflectionForm() {
-    return token == null ? null : token.getInflectionForm();
-  }
-  
-  public void setToken(Token token) {
-    this.token = token;
-  }
-
-  @Override
-  public void clear() {
-    token = null;
-  }
-
-  @Override
-  public void copyTo(AttributeImpl target) {
-    InflectionAttribute t = (InflectionAttribute) target;
-    t.setToken(token);
-  }
-  
-  @Override
-  public void reflectWith(AttributeReflector reflector) {
-    String type = getInflectionType();
-    String typeEN = type == null ? null : ToStringUtil.getInflectionTypeTranslation(type);
-    reflector.reflect(InflectionAttribute.class, "inflectionType", type);
-    reflector.reflect(InflectionAttribute.class, "inflectionType (en)", typeEN);
-    String form = getInflectionForm();
-    String formEN = form == null ? null : ToStringUtil.getInflectedFormTranslation(form);
-    reflector.reflect(InflectionAttribute.class, "inflectionForm", form);
-    reflector.reflect(InflectionAttribute.class, "inflectionForm (en)", formEN);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttribute.java
deleted file mode 100644
index 3f040d0..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttribute.java
+++ /dev/null
@@ -1,29 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.util.Attribute;
-
-/**
- * Attribute for {@link Token#getPartOfSpeech()}.
- */
-public interface PartOfSpeechAttribute extends Attribute {
-  public String getPartOfSpeech();
-  public void setToken(Token token);
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttributeImpl.java
deleted file mode 100644
index 257b17f..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/PartOfSpeechAttributeImpl.java
+++ /dev/null
@@ -1,57 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.analysis.kuromoji.util.ToStringUtil;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.AttributeReflector;
-
-/**
- * Attribute for {@link Token#getPartOfSpeech()}.
- */
-public class PartOfSpeechAttributeImpl extends AttributeImpl implements PartOfSpeechAttribute, Cloneable {
-  private Token token;
-  
-  public String getPartOfSpeech() {
-    return token == null ? null : token.getPartOfSpeech();
-  }
-  
-  public void setToken(Token token) {
-    this.token = token;
-  }
-
-  @Override
-  public void clear() {
-    token = null;
-  }
-
-  @Override
-  public void copyTo(AttributeImpl target) {
-    PartOfSpeechAttribute t = (PartOfSpeechAttribute) target;
-    t.setToken(token);
-  }
-  
-  @Override
-  public void reflectWith(AttributeReflector reflector) {
-    String partOfSpeech = getPartOfSpeech();
-    String partOfSpeechEN = partOfSpeech == null ? null : ToStringUtil.getPOSTranslation(partOfSpeech);
-    reflector.reflect(PartOfSpeechAttribute.class, "partOfSpeech", partOfSpeech);
-    reflector.reflect(PartOfSpeechAttribute.class, "partOfSpeech (en)", partOfSpeechEN);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttribute.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttribute.java
deleted file mode 100644
index 8bda4f1..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttribute.java
+++ /dev/null
@@ -1,33 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.util.Attribute;
-
-/**
- * Attribute for Kuromoji reading data
- * <p>
- * Note: in some cases this value may not be applicable,
- * and will be null.
- */
-public interface ReadingAttribute extends Attribute {
-  public String getReading();
-  public String getPronunciation();
-  public void setToken(Token token);
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttributeImpl.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttributeImpl.java
deleted file mode 100644
index 41d10b9..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/ReadingAttributeImpl.java
+++ /dev/null
@@ -1,65 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.tokenattributes;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.Token;
-import org.apache.lucene.analysis.kuromoji.util.ToStringUtil;
-import org.apache.lucene.util.AttributeImpl;
-import org.apache.lucene.util.AttributeReflector;
-
-/**
- * Attribute for Kuromoji reading data
- */
-public class ReadingAttributeImpl extends AttributeImpl implements ReadingAttribute, Cloneable {
-  private Token token;
-  
-  public String getReading() {
-    return token == null ? null : token.getReading();
-  }
-  
-  public String getPronunciation() {
-    return token == null ? null : token.getPronunciation();
-  }
-  
-  public void setToken(Token token) {
-    this.token = token;
-  }
-
-  @Override
-  public void clear() {
-    token = null;
-  }
-
-  @Override
-  public void copyTo(AttributeImpl target) {
-    ReadingAttribute t = (ReadingAttribute) target;
-    t.setToken(token);
-  }
-  
-  @Override
-  public void reflectWith(AttributeReflector reflector) {
-    String reading = getReading();
-    String readingEN = reading == null ? null : ToStringUtil.getRomanization(reading);
-    String pronunciation = getPronunciation();
-    String pronunciationEN = pronunciation == null ? null : ToStringUtil.getRomanization(pronunciation);
-    reflector.reflect(ReadingAttribute.class, "reading", reading);
-    reflector.reflect(ReadingAttribute.class, "reading (en)", readingEN);
-    reflector.reflect(ReadingAttribute.class, "pronunciation", pronunciation);
-    reflector.reflect(ReadingAttribute.class, "pronunciation (en)", pronunciationEN);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/package.html
deleted file mode 100644
index ddabc85..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/tokenattributes/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Additional Kuromoji-specific Attributes for text analysis.
-</body>
-</html>
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/CSVUtil.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/CSVUtil.java
deleted file mode 100644
index 1a87352..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/CSVUtil.java
+++ /dev/null
@@ -1,113 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.ArrayList;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-/**
- * Utility class for parsing CSV text
- */
-public final class CSVUtil {
-  private static final char QUOTE = '"';
-  
-  private static final char COMMA = ',';
-  
-  private static final Pattern QUOTE_REPLACE_PATTERN = Pattern.compile("^\"([^\"]+)\"$");
-  
-  private static final String ESCAPED_QUOTE = "\"\"";
-  
-  private CSVUtil() {} // no instance!!!
-  
-  /**
-   * Parse CSV line
-   * @param line
-   * @return Array of values
-   */
-  public static String[] parse(String line) {
-    boolean insideQuote = false;
-    ArrayList<String> result = new ArrayList<String>();		
-    int quoteCount = 0;
-    StringBuilder sb = new StringBuilder();
-    for(int i = 0; i < line.length(); i++) {
-      char c = line.charAt(i);
-      
-      if(c == QUOTE) {
-        insideQuote = !insideQuote;
-        quoteCount++;
-      }
-      
-      if(c == COMMA && !insideQuote) {
-        String value = sb.toString();
-        value = unQuoteUnEscape(value);
-        result.add(value);
-        sb.setLength(0);
-        continue;
-      }
-      
-      sb.append(c);
-    }
-    
-    result.add(sb.toString());
-    
-    // Validate
-    if(quoteCount % 2 != 0) {
-      return new String[0];
-    }
-    
-    return result.toArray(new String[result.size()]);
-  }
-  
-  private static String unQuoteUnEscape(String original) {
-    String result = original;
-    
-    // Unquote
-    if (result.indexOf('\"') >= 0) {
-      Matcher m = QUOTE_REPLACE_PATTERN.matcher(original);
-      if(m.matches()) {
-        result = m.group(1);
-      }
-    
-      // Unescape
-      if (result.indexOf(ESCAPED_QUOTE) >= 0) {
-        result = result.replace(ESCAPED_QUOTE, "\"");
-      }
-    }
-    
-    return result;
-    
-  }
-  
-  /**
-   * Quote and escape input value for CSV
-   * @param original
-   */
-  public static String quoteEscape(String original) {
-    String result = original;
-    
-    if (result.indexOf('\"') >= 0) {
-      result.replace("\"", ESCAPED_QUOTE);
-    }
-    if(result.indexOf(COMMA) >= 0) {
-      result = "\"" + result + "\"";
-    }
-    return result;
-  }
-  
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/ToStringUtil.java b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/ToStringUtil.java
deleted file mode 100644
index 2db22fd..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/ToStringUtil.java
+++ /dev/null
@@ -1,1039 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashMap;
-
-/**
- * Utility class for english translations of morphological data,
- * used only for debugging.
- */
-public class ToStringUtil {
-  // a translation map for parts of speech, only used for reflectWith
-  private static final HashMap<String,String> posTranslations = new HashMap<String,String>();
-  static {
-    posTranslations.put("???", "noun");
-    posTranslations.put("???-???", "noun-common");
-    posTranslations.put("???-?????", "noun-proper");
-    posTranslations.put("???-?????-???", "noun-proper-misc");
-    posTranslations.put("???-?????-?", "noun-proper-person");
-    posTranslations.put("???-?????-?-???", "noun-proper-person-misc");
-    posTranslations.put("???-?????-?-?", "noun-proper-person-surname");
-    posTranslations.put("???-?????-?-??", "noun-proper-person-given_name");
-    posTranslations.put("???-?????-??", "noun-proper-organization");
-    posTranslations.put("???-?????-??", "noun-proper-place");
-    posTranslations.put("???-?????-??-???", "noun-proper-place-misc");
-    posTranslations.put("???-?????-??-??", "noun-proper-place-country");
-    posTranslations.put("???-??", "noun-pronoun");
-    posTranslations.put("???-??-???", "noun-pronoun-misc");
-    posTranslations.put("???-??-??", "noun-pronoun-contraction");
-    posTranslations.put("???-??????", "noun-adverbial");
-    posTranslations.put("???-????", "noun-verbal");
-    posTranslations.put("???-?????", "noun-adjective-base");
-    posTranslations.put("???-??", "noun-numeric");
-    posTranslations.put("???-????", "noun-affix");
-    posTranslations.put("???-????-???", "noun-affix-misc");
-    posTranslations.put("???-????-??????", "noun-affix-adverbial");
-    posTranslations.put("???-????-?????", "noun-affix-aux");
-    posTranslations.put("???-????-?????", "noun-affix-adjective-base");
-    posTranslations.put("???-??", "noun-special");
-    posTranslations.put("???-??-?????", "noun-special-aux");
-    posTranslations.put("???-?", "noun-suffix");
-    posTranslations.put("???-?-???", "noun-suffix-misc");
-    posTranslations.put("???-?-?", "noun-suffix-person");
-    posTranslations.put("???-?-??", "noun-suffix-place");
-    posTranslations.put("???-?-????", "noun-suffix-verbal");
-    posTranslations.put("???-?-?????", "noun-suffix-aux");
-    posTranslations.put("???-?-?????", "noun-suffix-adjective-base");
-    posTranslations.put("???-?-??????", "noun-suffix-adverbial");
-    posTranslations.put("???-?-???", "noun-suffix-classifier");
-    posTranslations.put("???-?-??", "noun-suffix-special");
-    posTranslations.put("???-????", "noun-suffix-conjunctive");
-    posTranslations.put("???-????????", "noun-verbal_aux");
-    posTranslations.put("???-???????", "noun-quotation");
-    posTranslations.put("???-???????", "noun-nai_adjective");
-    posTranslations.put("???", "prefix");
-    posTranslations.put("???-?????", "prefix-nominal");
-    posTranslations.put("???-?????", "prefix-verbal");
-    posTranslations.put("???-????", "prefix-adjectival");
-    posTranslations.put("???-???", "prefix-numerical");
-    posTranslations.put("???", "verb");
-    posTranslations.put("???-???", "verb-main");
-    posTranslations.put("???-????", "verb-auxiliary");
-    posTranslations.put("???-?", "verb-suffix");
-    posTranslations.put("??", "adjective");
-    posTranslations.put("??-???", "adjective-main");
-    posTranslations.put("??-????", "adjective-auxiliary");
-    posTranslations.put("??-?", "adjective-suffix");
-    posTranslations.put("???", "adverb");
-    posTranslations.put("???-???", "adverb-misc");
-    posTranslations.put("???-?????", "adverb-particle_conjunction");
-    posTranslations.put("???", "adnominal");
-    posTranslations.put("???", "conjunction");
-    posTranslations.put("??", "particle");
-    posTranslations.put("??-???", "particle-case");
-    posTranslations.put("??-???-???", "particle-case-misc");
-    posTranslations.put("??-???-??", "particle-case-quote");
-    posTranslations.put("??-???-??", "particle-case-compound");
-    posTranslations.put("??-????", "particle-conjunctive");
-    posTranslations.put("??-???", "particle-dependency");
-    posTranslations.put("??-????", "particle-adverbial");
-    posTranslations.put("??-?????", "particle-interjective");
-    posTranslations.put("??-????", "particle-coordinate");
-    posTranslations.put("??-???", "particle-final");
-    posTranslations.put("??-?????????????", "particle-adverbial/conjunctive/final");
-    posTranslations.put("??-????", "particle-adnominalizer");
-    posTranslations.put("??-?????", "particle-adnominalizer");
-    posTranslations.put("??-??", "particle-special");
-    posTranslations.put("???", "auxiliary-verb");
-    posTranslations.put("????", "interjection");
-    posTranslations.put("??", "symbol");
-    posTranslations.put("??-???", "symbol-misc");
-    posTranslations.put("??-??", "symbol-period");
-    posTranslations.put("??-??", "symbol-comma");
-    posTranslations.put("??-?", "symbol-space");
-    posTranslations.put("??-????", "symbol-open_bracket");
-    posTranslations.put("??-????", "symbol-close_bracket");
-    posTranslations.put("??-???????????", "symbol-alphabetic");
-    posTranslations.put("????", "other");
-    posTranslations.put("????-???", "other-interjection");
-    posTranslations.put("?????", "filler");
-    posTranslations.put("?????", "non-verbal");
-    posTranslations.put("????", "fragment");
-    posTranslations.put("????", "unknown");
-  }
-  
-  /**
-   * Get the english form of a POS tag
-   */
-  public static String getPOSTranslation(String s) {
-    return posTranslations.get(s);
-  }
-  
-  // a translation map for inflection types, only used for reflectWith
-  private static final HashMap<String,String> inflTypeTranslations = new HashMap<String,String>();
-  static {
-    inflTypeTranslations.put("*", "*");
-    inflTypeTranslations.put("?????????", "adj-group-a-o-u");
-    inflTypeTranslations.put("?????", "adj-group-i");
-    inflTypeTranslations.put("?????",  "adj-group-ii");
-    inflTypeTranslations.put("?????", "non-inflectional");
-    inflTypeTranslations.put("????", "special-da");
-    inflTypeTranslations.put("????", "special-ta");
-    inflTypeTranslations.put("????????", "classical-gotoshi");
-    inflTypeTranslations.put("??????", "special-ja");
-    inflTypeTranslations.put("??????", "special-nai");
-    inflTypeTranslations.put("???????", "5-row-cons-r-special");
-    inflTypeTranslations.put("????", "special-nu");
-    inflTypeTranslations.put("?????", "classical-ki");
-    inflTypeTranslations.put("??????", "special-tai");
-    inflTypeTranslations.put("???????", "classical-beshi");
-    inflTypeTranslations.put("????", "special-ya");
-    inflTypeTranslations.put("???????", "classical-maji");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-t");
-    inflTypeTranslations.put("??????", "special-desu");
-    inflTypeTranslations.put("??????", "special-masu");
-    inflTypeTranslations.put("????????", "5-row-aru");
-    inflTypeTranslations.put("???????", "classical-nari");
-    inflTypeTranslations.put("?????", "classical-ri");
-    inflTypeTranslations.put("???????", "classical-keri");
-    inflTypeTranslations.put("?????", "classical-ru");
-    inflTypeTranslations.put("???????", "5-row-cons-k-i-onbin");
-    inflTypeTranslations.put("?????", "5-row-cons-s");
-    inflTypeTranslations.put("??", "1-row");
-    inflTypeTranslations.put("???????", "5-row-cons-w-cons-onbin");
-    inflTypeTranslations.put("?????", "5-row-cons-m");
-    inflTypeTranslations.put("?????", "5-row-cons-t");
-    inflTypeTranslations.put("?????", "5-row-cons-r");
-    inflTypeTranslations.put("??????", "irregular-suffix-suru");
-    inflTypeTranslations.put("?????", "5-row-cons-g");
-    inflTypeTranslations.put("??????", "irregular-suffix-zuru");
-    inflTypeTranslations.put("?????", "5-row-cons-b");
-    inflTypeTranslations.put("???????", "5-row-cons-w-u-onbin");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-d");
-    inflTypeTranslations.put("??????????", "5-row-cons-k-cons-onbin-yuku");
-    inflTypeTranslations.put("?????", "2-row-upper-cons-d");
-    inflTypeTranslations.put("???????", "5-row-cons-k-cons-onbin");
-    inflTypeTranslations.put("????", "1-row-eru");
-    inflTypeTranslations.put("??????", "4-row-cons-t");
-    inflTypeTranslations.put("?????", "5-row-cons-n");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-h");
-    inflTypeTranslations.put("??????", "4-row-cons-h");
-    inflTypeTranslations.put("??????", "4-row-cons-b");
-    inflTypeTranslations.put("??????", "irregular-suru");
-    inflTypeTranslations.put("?????", "2-row-upper-cons-h");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-m");
-    inflTypeTranslations.put("??????", "4-row-cons-s");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-g");
-    inflTypeTranslations.put("???????", "kuru-kanji");
-    inflTypeTranslations.put("???????", "1-row-kureru");
-    inflTypeTranslations.put("????", "2-row-lower-u");
-    inflTypeTranslations.put("???????", "kuru-kana");
-    inflTypeTranslations.put("??", "irregular-cons-r");
-    inflTypeTranslations.put("?????", "2-row-lower-cons-k");
-  }
-  
-  /**
-   * Get the english form of inflection type
-   */
-  public static String getInflectionTypeTranslation(String s) {
-    return inflTypeTranslations.get(s);
-  }
-
-  // a translation map for inflection forms, only used for reflectWith
-  private static final HashMap<String,String> inflFormTranslations = new HashMap<String,String>();
-  static {
-    inflFormTranslations.put("*", "*");
-    inflFormTranslations.put("???", "base");
-    inflFormTranslations.put("??????", "classical-base");
-    inflFormTranslations.put("???????", "imperfective-nu-connection");
-    inflFormTranslations.put("???????", "imperfective-u-connection");
-    inflFormTranslations.put("?????", "conjunctive-ta-connection");
-    inflFormTranslations.put("??????", "conjunctive-te-connection");
-    inflFormTranslations.put("???????", "conjunctive-gozai-connection");
-    inflFormTranslations.put("????", "uninflected-connection");
-    inflFormTranslations.put("???", "subjunctive");
-    inflFormTranslations.put("??", "imperative-e");
-    inflFormTranslations.put("?????", "conditional-contracted-1");
-    inflFormTranslations.put("?????", "conditional-contracted-2");
-    inflFormTranslations.put("?????", "garu-connection");
-    inflFormTranslations.put("????", "imperfective");
-    inflFormTranslations.put("???", "conjunctive");
-    inflFormTranslations.put("????", "onbin-base");
-    inflFormTranslations.put("??????", "conjunctive-de-connection");
-    inflFormTranslations.put("?????", "imperfective-special");
-    inflFormTranslations.put("??", "imperative-i");
-    inflFormTranslations.put("??????", "conjunctive-ni-connection");
-    inflFormTranslations.put("???", "imperative-yo");
-    inflFormTranslations.put("??????", "adnominal-special");
-    inflFormTranslations.put("???", "imperative-ro");
-    inflFormTranslations.put("???????", "uninflected-special-connection-2");
-    inflFormTranslations.put("????????", "imperfective-reru-connection");
-    inflFormTranslations.put("????", "modern-base");
-    inflFormTranslations.put("???-???", "base-onbin"); // not sure about this
-  }
-  
-  /**
-   * Get the english form of inflected form
-   */
-  public static String getInflectedFormTranslation(String s) {
-    return inflFormTranslations.get(s);
-  }
-  
-  /**
-   * Romanize katakana with modified hepburn
-   */
-  public static String getRomanization(String s) {
-    StringBuilder out = new StringBuilder();
-    try {
-      getRomanization(out, s);
-    } catch (IOException bogus) {
-      throw new RuntimeException(bogus);
-    }
-    return out.toString();
-  }
-  
-  /**
-   * Romanize katakana with modified hepburn
-   */
-  public static void getRomanization(Appendable builder, CharSequence s) throws IOException {
-    final int len = s.length();
-    for (int i = 0; i < len; i++) {
-      // maximum lookahead: 3
-      char ch = s.charAt(i);
-      char ch2 = (i < len - 1) ? s.charAt(i + 1) : 0;
-      char ch3 = (i < len - 2) ? s.charAt(i + 2) : 0;
-      
-      main: switch (ch) {
-        case '??':
-          switch (ch2) {
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append('k');
-              break main;
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append('s');
-              break main;
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append('t');
-              break main;
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append('p');
-              break main;
-          }
-          break;
-        case '??':
-          builder.append('a');
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("yi");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("ye");
-            i++;
-          } else {
-            builder.append('i');
-          }
-          break;
-        case '??':
-          switch(ch2) {
-            case '??':
-              builder.append("wa");
-              i++;
-              break;
-            case '??':
-              builder.append("wi");
-              i++;
-              break;
-            case '??':
-              builder.append("wu");
-              i++;
-              break;
-            case '??':
-              builder.append("we");
-              i++;
-              break;
-            case '??':
-              builder.append("wo");
-              i++;
-              break;
-            case '??':
-              builder.append("wyu");
-              i++;
-              break;
-            default:
-              builder.append('u');
-              break;
-          }
-          break;
-        case '??':
-          builder.append('e');
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append('?');
-            i++;
-          } else {
-            builder.append('o');
-          }
-          break;
-        case '??':
-          builder.append("ka");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("ky?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("ky");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("kya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("kyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("kyu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("kye");
-            i++;
-          } else {
-            builder.append("ki");
-          }
-          break;
-        case '??':
-          switch(ch2) {
-            case '??':
-              builder.append("kwa");
-              i++;
-              break;
-            case '??':
-              builder.append("kwi");
-              i++;
-              break;
-            case '??':
-              builder.append("kwe");
-              i++;
-              break;
-            case '??':
-              builder.append("kwo");
-              i++;
-              break;
-            case '??':
-              builder.append("kwa");
-              i++;
-              break;
-            default:
-              builder.append("ku");
-              break;
-          }
-          break;
-        case '??':
-          builder.append("ke");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("k?");
-            i++;
-          } else {
-            builder.append("ko");
-          }
-          break;
-        case '??':
-          builder.append("sa");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("sh?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("sh");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("sha");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("sho");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("shu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("she");
-            i++;
-          } else {
-            builder.append("shi");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("si");
-            i++;
-          } else {
-            builder.append("su");
-          }
-          break;
-        case '??':
-          builder.append("se");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("s?");
-            i++;
-          } else {
-            builder.append("so");
-          }
-          break;
-        case '??':
-          builder.append("ta");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("ch?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("ch");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("cha");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("cho");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("chu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("che");
-            i++;
-          } else {
-            builder.append("chi");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("tsa");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tsi");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tse");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tso");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tsyu");
-            i++;
-          } else {
-            builder.append("tsu");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("ti");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("tyu");
-            i++;
-          } else {
-            builder.append("te");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("t?");
-            i++;
-          } else {
-            builder.append("to");
-          }
-          break;
-        case '??':
-          builder.append("na");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("ny?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("ny");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("nya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("nyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("nyu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("nye");
-            i++;
-          } else {
-            builder.append("ni");
-          }
-          break;
-        case '??':
-          builder.append("nu");
-          break;
-        case '??':
-          builder.append("ne");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("n?");
-            i++;
-          } else {
-            builder.append("no");
-          }
-          break;
-        case '??':
-          builder.append("ha");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("hy?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("hy");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("hya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("hyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("hyu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("hye");
-            i++;
-          } else {
-            builder.append("hi");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("fya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("fyu");
-            i++;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("fye");
-            i+=2;
-          } else if (ch2 == '??') {
-            builder.append("fyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("fa");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("fi");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("fe");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("fo");
-            i++;
-          } else {
-            builder.append("fu");
-          }
-          break;
-        case '??':
-          builder.append("he");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("h?");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("hu");
-            i++;
-          } else {
-            builder.append("ho");
-          }
-          break;
-        case '??':
-          builder.append("ma");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("my?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("my");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("mya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("myo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("myu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("mye");
-            i++;
-          } else {
-            builder.append("mi");
-          }
-          break;
-        case '??':
-          builder.append("mu");
-          break;
-        case '??':
-          builder.append("mi");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("m?");
-            i++;
-          } else {
-            builder.append("mo");
-          }
-          break;
-        case '??':
-          builder.append("ya");
-          break;
-        case '??':
-          builder.append("yu");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("y?");
-            i++;
-          } else {
-            builder.append("yo");
-          }
-          break;
-        case '??':
-          builder.append("ra");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("ry?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("ry");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("rya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("ryo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("ryu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("rye");
-            i++;
-          } else {
-            builder.append("ri");
-          }
-          break;
-        case '??':
-          builder.append("ru");
-          break;
-        case '??':
-          builder.append("re");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("r?");
-            i++;
-          } else {
-            builder.append("ro");
-          }
-          break;
-        case '??':
-          builder.append("wa");
-          break;
-        case '??':
-          builder.append("i");
-          break;
-        case '??':
-          builder.append("e");
-          break;
-        case '??':
-          builder.append("o");
-          break;
-        case '??':
-          switch (ch2) {
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append('m');
-              break main;
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-            case '??':
-              builder.append("n'");
-              break main;
-            default:
-              builder.append("n");
-              break main;
-          }
-        case '??':
-          builder.append("ga");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("gy?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("gy");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("gya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("gyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("gyu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("gye");
-            i++;
-          } else {
-            builder.append("gi");
-          }
-          break;
-        case '??':
-          switch(ch2) {
-            case '??':
-              builder.append("gwa");
-              i++;
-              break;
-            case '??':
-              builder.append("gwi");
-              i++;
-              break;
-            case '??':
-              builder.append("gwe");
-              i++;
-              break;
-            case '??':
-              builder.append("gwo");
-              i++;
-              break;
-            case '??':
-              builder.append("gwa");
-              i++;
-              break;
-            default:
-              builder.append("gu");
-              break;
-          }
-          break;
-        case '??':
-          builder.append("ge");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("g?");
-            i++;
-          } else {
-            builder.append("go");
-          }
-          break;
-        case '??':
-          builder.append("za");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("j?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("j");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("ja");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("jo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("ju");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("je");
-            i++;
-          } else {
-            builder.append("ji");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("zi");
-            i++;
-          } else {
-            builder.append("zu");
-          }
-          break;
-        case '??':
-          builder.append("ze");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("z?");
-            i++;
-          } else {
-            builder.append("zo");
-          }
-          break;
-        case '??':
-          builder.append("da");
-          break;
-        case '??':
-          builder.append("ji");
-          break;
-        case '??':
-          builder.append("zu");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("di");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("dyu");
-            i++;
-          } else {
-            builder.append("de");
-          }
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("d?");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("du");
-            i++;
-          } else {
-            builder.append("do");
-          }
-          break;
-        case '??':
-          builder.append("ba");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("by?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("by");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("bya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("byo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("byu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("bye");
-            i++;
-          } else {
-            builder.append("bi");
-          }
-          break;
-        case '??':
-          builder.append("bu");
-          break;
-        case '??':
-          builder.append("be");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("b?");
-            i++;
-          } else {
-            builder.append("bo");
-          }
-          break;
-        case '??':
-          builder.append("pa");
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("py?");
-            i += 2;
-          } else if (ch2 == '??' && ch3 == '??') {
-            builder.append("py");
-            i += 2;
-          } else if (ch2 == '??') {
-            builder.append("pya");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("pyo");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("pyu");
-            i++;
-          } else if (ch2 == '??') {
-            builder.append("pye");
-            i++;
-          } else {
-            builder.append("pi");
-          }
-          break;
-        case '??':
-          builder.append("pu");
-          break;
-        case '??':
-          builder.append("pe");
-          break;
-        case '??':
-          if (ch2 == '??') {
-            builder.append("p?");
-            i++;
-          } else {
-            builder.append("po");
-          }
-          break;
-        case '??':
-          if (ch2 == '??' && ch3 == '??') {
-            builder.append("vye");
-            i+= 2;
-          } else {
-            builder.append('v');
-          }
-          break;
-        case '??':
-          builder.append('a');
-          break;
-        case '??':
-          builder.append('i');
-          break;
-        case '??':
-          builder.append('u');
-          break;
-        case '??':
-          builder.append('e');
-          break;
-        case '??':
-          builder.append('o');
-          break;
-        case '??':
-          builder.append("wa");
-          break;
-        case '??':
-          builder.append("ya");
-          break;
-        case '??':
-          builder.append("yu");
-          break;
-        case '??':
-          builder.append("yo");
-          break;
-        case '??':
-          break;
-        default:
-          builder.append(ch);
-      }
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/package.html b/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/package.html
deleted file mode 100644
index 34d4632..0000000
--- a/modules/analysis/kuromoji/src/java/org/apache/lucene/analysis/kuromoji/util/package.html
+++ /dev/null
@@ -1,22 +0,0 @@
-<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-     http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-<html><head></head>
-<body>
-Kuromoji utility classes.
-</body>
-</html>
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/CharacterDefinition.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/CharacterDefinition.dat
new file mode 100644
index 0000000..4b8bd4b
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/CharacterDefinition.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/ConnectionCosts.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/ConnectionCosts.dat
new file mode 100644
index 0000000..7679f14
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/ConnectionCosts.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$buffer.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$buffer.dat
new file mode 100644
index 0000000..dcf430a
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$buffer.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$fst.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$fst.dat
new file mode 100644
index 0000000..8fd2138
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$fst.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$posDict.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$posDict.dat
new file mode 100644
index 0000000..e727d90
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$posDict.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$targetMap.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$targetMap.dat
new file mode 100644
index 0000000..0e27345
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/TokenInfoDictionary$targetMap.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$buffer.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$buffer.dat
new file mode 100644
index 0000000..16f0a82
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$buffer.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$posDict.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$posDict.dat
new file mode 100644
index 0000000..e709dcc
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$posDict.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$targetMap.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$targetMap.dat
new file mode 100644
index 0000000..e8db0b3
Binary files /dev/null and b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/dict/UnknownDictionary$targetMap.dat differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stoptags.txt b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stoptags.txt
new file mode 100644
index 0000000..6f5cb8c
--- /dev/null
+++ b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stoptags.txt
@@ -0,0 +1,420 @@
+#
+# This file defines a Japanese stoptag set for KuromojiPartOfSpeechStopFilter.
+#
+# Any token with a part-of-speech tag that exactly matches those defined in this
+# file are removed from the token stream.
+#
+# Set your own stoptags by uncommenting the lines below.  Note that comments are
+# not allowed on the same line as a stoptag.  See LUCENE-3745 for frequency lists,
+# etc. that can be useful for building you own stoptag set.
+#
+# The entire possible tagset is provided below for convenience.
+#
+#####
+#  noun: unclassified nouns
+#???
+#
+#  noun-common: Common nouns or nouns where the sub-classification is undefined
+#???-???
+#
+#  noun-proper: Proper nouns where the sub-classification is undefined 
+#???-?????
+#
+#  noun-proper-misc: miscellaneous proper nouns
+#???-?????-???
+#
+#  noun-proper-person: Personal names where the sub-classification is undefined
+#???-?????-?
+#
+#  noun-proper-person-misc: names that cannot be divided into surname and 
+#  given name; foreign names; names where the surname or given name is unknown.
+#  e.g. ??????
+#???-?????-?-???
+#
+#  noun-proper-person-surname: Mainly Japanese surnames.
+#  e.g. ?
+#???-?????-?-?
+#
+#  noun-proper-person-given_name: Mainly Japanese given names.
+#  e.g. ??
+#???-?????-?-??
+#
+#  noun-proper-organization: Names representing organizations.
+#  e.g. ?????, NHK
+#???-?????-??
+#
+#  noun-proper-place: Place names where the sub-classification is undefined
+#???-?????-??
+#
+#  noun-proper-place-misc: Place names excluding countries.
+#  e.g. ?????, ???????, ??
+#???-?????-??-???
+#
+#  noun-proper-place-country: Country names. 
+#  e.g. ??, ?????????
+#???-?????-??-??
+#
+#  noun-pronoun: Pronouns where the sub-classification is undefined
+#???-??
+#
+#  noun-pronoun-misc: miscellaneous pronouns: 
+#  e.g. ???, ???, ?????, ?????, ??????, ?????, ????, ???, ?????, ????, ??????, ??????
+#???-??-???
+#
+#  noun-pronoun-contraction: Spoken language contraction made by combining a 
+#  pronoun and the particle 'wa'.
+#  e.g. ?????, ?????, ??????, ?????, ?????? 
+#???-??-??
+#
+#  noun-adverbial: Temporal nouns such as names of days or months that behave 
+#  like adverbs. Nouns that represent amount or ratios and can be used adverbially,
+#  e.g. ???, ???, ???, ??
+#???-??????
+#
+#  noun-verbal: Nouns that take arguments with case and can appear followed by 
+#  'suru' and related verbs (???, ????, ?????, ??????)
+#  e.g. ???????, ???, ???, ??????, ???, ????
+#???-????
+#
+#  noun-adjective-base: The base form of adjectives, words that appear before ?? ("na")
+#  e.g. ?, ??, ??, ???
+#???-?????
+#
+#  noun-numeric: Arabic numbers, Chinese numerals, and counters like ? (??), ??.
+#  e.g. 0, 1, 2, ?, ??, ?
+#???-??
+#
+#  noun-affix: noun affixes where the sub-classification is undefined
+#???-????
+#
+#  noun-affix-misc: Of adnominalizers, the case-marker ?? ("no"), and words that 
+#  attach to the base form of inflectional words, words that cannot be classified 
+#  into any of the other categories below. This category includes indefinite nouns.
+#  e.g. ?????, ??, ???, ??, ?, ?????, ??, ???, ??, ???, ?, ???, ?, ?????, ?, 
+#       ??, ???, ????, ????, ??, ????, ????, ??, ????, ??, ???, ?, ?????, ?, 
+#       ???, ??, ??, ???, ??, ??, ??, ???, ??, ??, ???, ??, ?????, ???, ???, ?,
+#       ???, ??, ??, ??-??/, ???-??/
+#???-????-???
+#
+#  noun-affix-adverbial: noun affixes that that can behave as adverbs.
+#  e.g. ?????, ??, ?????, ?????, ???, ?, ??, ?, ?, ?, ?, ?, ???, ???, 
+#       ?, ???, ??, ???, ???, ?????, ???, ???, ????, ??, ???, ??, ???, ??, ???, ?????, 
+#       ???, ?????, ???, ???, ?, ???, ??, ??, ?, ????, ???, ??, ??, ????, ??, 
+#       ????, ???, ???, ?, ???, ?, ????, ??, ??, ??, ??, ??, ?, ??, ??, ??, 
+#       ??, ?, ????, ??
+#???-????-??????
+#
+#  noun-affix-aux: noun affixes treated as ??? ("auxiliary verb") in school grammars 
+#  with the stem ???(??) ("you(da)").
+#  e.g.  ???, ???, ? (???)
+#???-????-?????
+#  
+#  noun-affix-adjective-base: noun affixes that can connect to the indeclinable
+#  connection form ?? (aux "da").
+#  e.g. ????, ??
+#???-????-?????
+#
+#  noun-special: special nouns where the sub-classification is undefined.
+#???-??
+#
+#  noun-special-aux: The ????? ("souda") stem form that is used for reporting news, is 
+#  treated as ??? ("auxiliary verb") in school grammars, and attach to the base 
+#  form of inflectional words.
+#  e.g. ???
+#???-??-?????
+#
+#  noun-suffix: noun suffixes where the sub-classification is undefined.
+#???-?
+#
+#  noun-suffix-misc: Of the nouns or stem forms of other parts of speech that connect 
+#  to ??? or ?? and can combine into compound nouns, words that cannot be classified into
+#  any of the other categories below. In general, this category is more inclusive than 
+#  ?? ("suffix") and is usually the last element in a compound noun.
+#  e.g. ???, ???, ??, ?? (???), ?????, ???, ??, ?????, (????) ??, ?, ? (??) ??,
+#       ???, (??)??, ??, ?, ??, ?, ?, ??, ??
+#???-?-???
+#
+#  noun-suffix-person: Suffixes that form nouns and attach to person names more often
+#  than other nouns.
+#  e.g. ??, ?, ??
+#???-?-?
+#
+#  noun-suffix-place: Suffixes that form nouns and attach to place names more often 
+#  than other nouns.
+#  e.g. ??, ?, ??
+#???-?-??
+#
+#  noun-suffix-verbal: Of the suffixes that attach to nouns and form nouns, those that 
+#  can appear before ?? ("suru").
+#  e.g. ??, ?, ???, ??, ??, ?
+#???-?-????
+#
+#  noun-suffix-aux: The stem form of ????? (??) that is used to indicate conditions, 
+#  is treated as ??? ("auxiliary verb") in school grammars, and attach to the 
+#  conjunctive form of inflectional words.
+#  e.g. ???
+#???-?-?????
+#
+#  noun-suffix-adjective-base: Suffixes that attach to other nouns or the conjunctive 
+#  form of inflectional words and appear before the copula ?? ("da").
+#  e.g. ??, ??, ???
+#???-?-?????
+#
+#  noun-suffix-adverbial: Suffixes that attach to other nouns and can behave as adverbs.
+#  e.g. ? (??), ?, ?, ?, ???, ?, ??, ?, ?? (??)
+#???-?-??????
+#
+#  noun-suffix-classifier: Suffixes that attach to numbers and form nouns. This category 
+#  is more inclusive than ??? ("classifier") and includes common nouns that attach 
+#  to numbers.
+#  e.g. ??, ??, ??, ??, ???????, cm, kg, ???, ???, ??, ???, ???
+#???-?-???
+#
+#  noun-suffix-special: Special suffixes that mainly attach to inflecting words.
+#  e.g. (?) ??, (???) ??
+#???-?-??
+#
+#  noun-suffix-conjunctive: Nouns that behave like conjunctions and join two words 
+#  together.
+#  e.g. (??) ? (??????), ? (??????), (3) ? (5), (?) ?? ()
+#???-????
+#
+#  noun-verbal_aux: Nouns that attach to the conjunctive particle ?? ("te") and are 
+#  semantically verb-like.
+#  e.g. ?????, ??, , ???
+#???-????????
+#
+#  noun-quotation: text that cannot be segmented into words, proverbs, Chinese poetry, 
+#  dialects, English, etc. Currently, the only entry for ??? ??????? ("noun quotation") 
+#  is ????? ("iwaku").
+#???-???????
+#
+#  noun-nai_adjective: Words that appear before the auxiliary verb ??? ("nai") and
+#  behave like an adjective.
+#  e.g. ???, ??, ????, ???
+#???-???????
+#
+#####
+#  prefix: unclassified prefixes
+#???
+#
+#  prefix-nominal: Prefixes that attach to nouns (including adjective stem forms) 
+#  excluding numerical expressions.
+#  e.g. ?? (?), ?? (?), ?? (?), ?? (??), ? (??), ?? (??), ?? (?)
+#???-?????
+#
+#  prefix-verbal: Prefixes that attach to the imperative form of a verb or a verb
+#  in conjunctive form followed by ???/?????/??????.
+#  e.g. ?? (???????), ?? (?)
+#???-?????
+#
+#  prefix-adjectival: Prefixes that attach to adjectives.
+#  e.g. ?? (???????), ??? (????)
+#???-????
+#
+#  prefix-numerical: Prefixes that attach to numerical expressions.
+#  e.g. ?, ?????, ??
+#???-???
+#
+#####
+#  verb: unclassified verbs
+#???
+#
+#  verb-main:
+#???-???
+#
+#  verb-auxiliary:
+#???-????
+#
+#  verb-suffix:
+#???-?
+#
+#####
+#  adjective: unclassified adjectives
+#??
+#
+#  adjective-main:
+#??-???
+#
+#  adjective-auxiliary:
+#??-????
+#
+#  adjective-suffix:
+#??-?
+#
+#####
+#  adverb: unclassified adverbs
+#???
+#
+#  adverb-misc: Words that can be segmented into one unit and where adnominal 
+#  modification is not possible.
+#  e.g. ?????????, ??
+#???-???
+#
+#  adverb-particle_conjunction: Adverbs that can be followed by ??, ??, ??, 
+#  ??, ???, ??, etc.
+#  e.g. ??????, ??????, ??????, ?????, ?????
+#???-?????
+#
+#####
+#  adnominal: Words that only have noun-modifying forms.
+#  e.g. ???, ???, ???, ??, ??????, ????????, ?????, ??????, ??????, ??????, ??????, 
+#       ?????, ?????, ?????, ?????, ????, ???, ????, ??????, ????, ??????, 
+#       ??(, ??) ??? (????????)??, ??????, ???????, ?????, ??????, ??????????, ?
+#???
+#
+#####
+#  conjunction: Conjunctions that can occur independently.
+#  e.g. ??, ?????, ?????, ?????, ????????
+???
+#
+#####
+#  particle: unclassified particles.
+??
+#
+#  particle-case: case particles where the subclassification is undefined.
+??-???
+#
+#  particle-case-misc: Case particles.
+#  e.g. ???, ??, ??, ??, ??, ??, ???, ??, ??, ???
+??-???-???
+#
+#  particle-case-quote: the "to" that appears after nouns, a person?? speech, 
+#  quotation marks, expressions of decisions from a meeting, reasons, judgements,
+#  conjectures, etc.
+#  e.g. ( ??) ?? (???.), ( ????) ?? (???????...)
+??-???-??
+#
+#  particle-case-compound: Compounds of particles and verbs that mainly behave 
+#  like case particles.
+#  e.g. ????, ????, ?????, ????, ?????, ????, ????, ????????, ????????, ?????,
+#       ??????, ??????, ?????, ??????, ??????, ??????, ??????,?????, ??????, ??????, 
+#       ?????, ??????, ??????, ?????, ????????, ??????, ????????, ??????, ?????, 
+#       ??????, ????????, ?????, ?????, ????????, ?????, ??????, ?????, ????????, 
+#       ??????, ????????, ??????, ??????, ?????, ?????, ??????, ?????, ??????, ?????,
+#       ?????, ???????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, 
+#       ????????, ??????, ?????, ????, ?????, ???????, ???????, ????????, ??????, ??????,
+#       ??-??/, ????-??????????/, (?) ????? (?)-??/, ?????-??/, ????, ?????
+??-???-??
+#
+#  particle-conjunctive:
+#  e.g. ???, ??????, ??, ?????, ?????, ???, ??, ??, ??, ??, ??, ?????, ?????, ??, ??, 
+#       ?????, ???, ???, ???, ??, ?????, ?? ( ???), ??????, (?????) ???(??????)-??/, 
+#       (??) ??(??????)-??/, (???) ????? (?????????)-??/, (????????)???? (?)-??/
+??-????
+#
+#  particle-dependency:
+#  e.g. ???, ???, ???, ???, ??, ??, ??
+??-???
+#
+#  particle-adverbial:
+#  e.g. ?????, ???, ?????, ?, ?????, ???, (??) ???(?????????????)-??/, 
+#       (???)????? (??????)-??/, ???, (?) ???, ???, (?) ??? (??), (???) ????? (???)-??/,
+#       (?) ?????, (???) ????? (???)-??/, ???, ???, (?) ?????-??/, ???, 
+#       (?)????-??/, (???) ?? (?????), ? (??), (??) ??, ????, ????-??/, ?????-??/,
+#       ??, ?, ??, ?, (?) ?? (??)([??-??? ????? [??-??? ???????????????)
+??-????
+#
+#  particle-interjective: particles with interjective grammatical roles.
+#  e.g. (?) ??
+??-?????
+#
+#  particle-coordinate:
+#  e.g. ??, ???, ???, ???, ??, ???, ??, ???
+??-????
+#
+#  particle-final:
+#  e.g. ???, ?????, ??, ??, (??)??-??/, (??????) ??-??/, ??, ??, ???-??/, ??, ??, ??, 
+#       ???-??/, ???-??/, ???-??/, ??, ???-??/, ??, ??, ??, ???-??/, ??, ???-??/
+??-???
+#
+#  particle-adverbial/conjunctive/final: The particle "ka" when unknown whether it is 
+#  adverbial, conjunctive, or sentence final. For example:
+#       (a) ?? ?? B ????. Ex:??(????????) ??,(???????) ?? (.)??
+#       (b) Inside an adverb phrase. Ex:??(?????) ?? (, ???????????.)??
+#           ??(???????????) ?? (, ?????????.)??
+#       (c) ???????????. Ex:??(???????) ?? (??????????????.)??
+#  e.g. ??
+??-?????????????
+#
+#  particle-adnominalizer: The "no" that attaches to nouns and modifies 
+#  non-inflectional words.
+??-????
+#
+#  particle-adnominalizer: The "ni" and "to" that appear following nouns and adverbs 
+#  that are giongo, giseigo, or gitaigo.
+#  e.g. ??, ??
+??-?????
+#
+#  particle-special: A particle that does not fit into one of the above classifications. 
+#  This includes particles that are used in Tanka, Haiku, and other poetry.
+#  e.g. ???, ???, ( ????????) ??, (?????) ???(??????), (?) ?? (?)
+??-??
+#
+#####
+#  auxiliary-verb:
+???
+#
+#####
+#  interjection: Greetings and other exclamations.
+#  e.g. ??????, ??????????????, ????????, ???????, ????????, ??????????, ??????????????, 
+#       ????????, ?????????, ??????, ????????, ???, ?????, ?????, ?????????
+#????
+#
+#####
+#  symbol: unclassified Symbols.
+??
+#
+#  symbol-misc: A general symbol not in one of the categories below.
+#  e.g. [???@$???+]
+??-???
+#
+#  symbol-comma: Commas
+#  e.g. [,??
+??-??
+#
+#  symbol-period: Periods and full stops.
+#  e.g. [.???
+??-??
+#
+#  symbol-space: Full-width whitespace.
+??-?
+#
+#  symbol-open_bracket:
+#  e.g. [({????????
+??-????
+#
+#  symbol-close_bracket:
+#  e.g. [)}??????????
+??-????
+#
+#  symbol-alphabetic:
+#??-???????????
+#
+#####
+#  other: unclassified other
+#????
+#
+#  other-interjection: Words that are hard to classify as noun-suffixes or 
+#  sentence-final particles.
+#  e.g. (??)??
+????-???
+#
+#####
+#  filler: Aizuchi that occurs during a conversation or sounds inserted as filler.
+#  e.g. ???, ?????, ???
+?????
+#
+#####
+#  non-verbal: non-verbal sound.
+?????
+#
+#####
+#  fragment:
+#????
+#
+#####
+#  unknown: unknown part of speech.
+#????
+#
+##### End of file
\ No newline at end of file
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stopwords.txt b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stopwords.txt
new file mode 100644
index 0000000..9a93e69
--- /dev/null
+++ b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/ja/stopwords.txt
@@ -0,0 +1,127 @@
+#
+# This file defines a stopword set for Japanese.
+#
+# This set is made up of hand-picked frequent terms from segmented Japanese Wikipedia.
+# Punctuation characters and frequent kanji have mostly been left out.  See LUCENE-3745
+# for frequency lists, etc. that can be useful for making your own set (if desired)
+#
+# Note that there is an overlap between these stopwords and the terms stopped when used
+# in combination with the KuromojiPartOfSpeechStopFilter.  When editing this file, note
+# that comments are not allowed on the same line as stopwords.
+#
+# Also note that stopping is done in a case-insensitive manner.  Change your StopFilter
+# configuration if you need case-sensitive stopping.  Lastly, note that stopping is done
+# using the same character width as the entries in this file.  Since this StopFilter is
+# normally done after a CJKWidthFilter in your chain, you would usually want your romaji
+# entries to be in half-width and your kana entries to be in full-width.
+#
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+???
+???
+??
+???
+???
+??
+???
+????
+??
+??
+???
+???
+???
+???
+???
+???
+???
+???
+???
+??
+???
+????
+???
+??
+???
+???
+??
+??
+??
+???
+?????
+?????
+???
+???
+?????
+??
+???
+?????
+??????
+??
+?????
+???
+?????
+??????
+??
+???
+????
+????
+???
+??
+???
+???
+???
+??
+??
+??
+??????
+?????
+???
+?????
+??
+??
+???
+????
+??????
+???
+??
+??
+???
+??????
+??
+???
+???
+?????
+??
+??
+???
+??
+?????
+???
+?????
+?????
+?????
+?????
+??????
+????
+??
+??
+?????
+??????
+?????
+????
+????
+??
+??
+????
+???
+##### End of file
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.dat
deleted file mode 100644
index 4b8bd4b..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/CharacterDefinition.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.dat
deleted file mode 100644
index 7679f14..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/ConnectionCosts.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$buffer.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$buffer.dat
deleted file mode 100644
index dcf430a..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$buffer.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$fst.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$fst.dat
deleted file mode 100644
index 8fd2138..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$fst.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$posDict.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$posDict.dat
deleted file mode 100644
index e727d90..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$posDict.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$targetMap.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$targetMap.dat
deleted file mode 100644
index 0e27345..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/TokenInfoDictionary$targetMap.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$buffer.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$buffer.dat
deleted file mode 100644
index 16f0a82..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$buffer.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$posDict.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$posDict.dat
deleted file mode 100644
index e709dcc..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$posDict.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$targetMap.dat b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$targetMap.dat
deleted file mode 100644
index e8db0b3..0000000
Binary files a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionary$targetMap.dat and /dev/null differ
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stoptags.txt b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stoptags.txt
deleted file mode 100644
index 6f5cb8c..0000000
--- a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stoptags.txt
+++ /dev/null
@@ -1,420 +0,0 @@
-#
-# This file defines a Japanese stoptag set for KuromojiPartOfSpeechStopFilter.
-#
-# Any token with a part-of-speech tag that exactly matches those defined in this
-# file are removed from the token stream.
-#
-# Set your own stoptags by uncommenting the lines below.  Note that comments are
-# not allowed on the same line as a stoptag.  See LUCENE-3745 for frequency lists,
-# etc. that can be useful for building you own stoptag set.
-#
-# The entire possible tagset is provided below for convenience.
-#
-#####
-#  noun: unclassified nouns
-#???
-#
-#  noun-common: Common nouns or nouns where the sub-classification is undefined
-#???-???
-#
-#  noun-proper: Proper nouns where the sub-classification is undefined 
-#???-?????
-#
-#  noun-proper-misc: miscellaneous proper nouns
-#???-?????-???
-#
-#  noun-proper-person: Personal names where the sub-classification is undefined
-#???-?????-?
-#
-#  noun-proper-person-misc: names that cannot be divided into surname and 
-#  given name; foreign names; names where the surname or given name is unknown.
-#  e.g. ??????
-#???-?????-?-???
-#
-#  noun-proper-person-surname: Mainly Japanese surnames.
-#  e.g. ?
-#???-?????-?-?
-#
-#  noun-proper-person-given_name: Mainly Japanese given names.
-#  e.g. ??
-#???-?????-?-??
-#
-#  noun-proper-organization: Names representing organizations.
-#  e.g. ?????, NHK
-#???-?????-??
-#
-#  noun-proper-place: Place names where the sub-classification is undefined
-#???-?????-??
-#
-#  noun-proper-place-misc: Place names excluding countries.
-#  e.g. ?????, ???????, ??
-#???-?????-??-???
-#
-#  noun-proper-place-country: Country names. 
-#  e.g. ??, ?????????
-#???-?????-??-??
-#
-#  noun-pronoun: Pronouns where the sub-classification is undefined
-#???-??
-#
-#  noun-pronoun-misc: miscellaneous pronouns: 
-#  e.g. ???, ???, ?????, ?????, ??????, ?????, ????, ???, ?????, ????, ??????, ??????
-#???-??-???
-#
-#  noun-pronoun-contraction: Spoken language contraction made by combining a 
-#  pronoun and the particle 'wa'.
-#  e.g. ?????, ?????, ??????, ?????, ?????? 
-#???-??-??
-#
-#  noun-adverbial: Temporal nouns such as names of days or months that behave 
-#  like adverbs. Nouns that represent amount or ratios and can be used adverbially,
-#  e.g. ???, ???, ???, ??
-#???-??????
-#
-#  noun-verbal: Nouns that take arguments with case and can appear followed by 
-#  'suru' and related verbs (???, ????, ?????, ??????)
-#  e.g. ???????, ???, ???, ??????, ???, ????
-#???-????
-#
-#  noun-adjective-base: The base form of adjectives, words that appear before ?? ("na")
-#  e.g. ?, ??, ??, ???
-#???-?????
-#
-#  noun-numeric: Arabic numbers, Chinese numerals, and counters like ? (??), ??.
-#  e.g. 0, 1, 2, ?, ??, ?
-#???-??
-#
-#  noun-affix: noun affixes where the sub-classification is undefined
-#???-????
-#
-#  noun-affix-misc: Of adnominalizers, the case-marker ?? ("no"), and words that 
-#  attach to the base form of inflectional words, words that cannot be classified 
-#  into any of the other categories below. This category includes indefinite nouns.
-#  e.g. ?????, ??, ???, ??, ?, ?????, ??, ???, ??, ???, ?, ???, ?, ?????, ?, 
-#       ??, ???, ????, ????, ??, ????, ????, ??, ????, ??, ???, ?, ?????, ?, 
-#       ???, ??, ??, ???, ??, ??, ??, ???, ??, ??, ???, ??, ?????, ???, ???, ?,
-#       ???, ??, ??, ??-??/, ???-??/
-#???-????-???
-#
-#  noun-affix-adverbial: noun affixes that that can behave as adverbs.
-#  e.g. ?????, ??, ?????, ?????, ???, ?, ??, ?, ?, ?, ?, ?, ???, ???, 
-#       ?, ???, ??, ???, ???, ?????, ???, ???, ????, ??, ???, ??, ???, ??, ???, ?????, 
-#       ???, ?????, ???, ???, ?, ???, ??, ??, ?, ????, ???, ??, ??, ????, ??, 
-#       ????, ???, ???, ?, ???, ?, ????, ??, ??, ??, ??, ??, ?, ??, ??, ??, 
-#       ??, ?, ????, ??
-#???-????-??????
-#
-#  noun-affix-aux: noun affixes treated as ??? ("auxiliary verb") in school grammars 
-#  with the stem ???(??) ("you(da)").
-#  e.g.  ???, ???, ? (???)
-#???-????-?????
-#  
-#  noun-affix-adjective-base: noun affixes that can connect to the indeclinable
-#  connection form ?? (aux "da").
-#  e.g. ????, ??
-#???-????-?????
-#
-#  noun-special: special nouns where the sub-classification is undefined.
-#???-??
-#
-#  noun-special-aux: The ????? ("souda") stem form that is used for reporting news, is 
-#  treated as ??? ("auxiliary verb") in school grammars, and attach to the base 
-#  form of inflectional words.
-#  e.g. ???
-#???-??-?????
-#
-#  noun-suffix: noun suffixes where the sub-classification is undefined.
-#???-?
-#
-#  noun-suffix-misc: Of the nouns or stem forms of other parts of speech that connect 
-#  to ??? or ?? and can combine into compound nouns, words that cannot be classified into
-#  any of the other categories below. In general, this category is more inclusive than 
-#  ?? ("suffix") and is usually the last element in a compound noun.
-#  e.g. ???, ???, ??, ?? (???), ?????, ???, ??, ?????, (????) ??, ?, ? (??) ??,
-#       ???, (??)??, ??, ?, ??, ?, ?, ??, ??
-#???-?-???
-#
-#  noun-suffix-person: Suffixes that form nouns and attach to person names more often
-#  than other nouns.
-#  e.g. ??, ?, ??
-#???-?-?
-#
-#  noun-suffix-place: Suffixes that form nouns and attach to place names more often 
-#  than other nouns.
-#  e.g. ??, ?, ??
-#???-?-??
-#
-#  noun-suffix-verbal: Of the suffixes that attach to nouns and form nouns, those that 
-#  can appear before ?? ("suru").
-#  e.g. ??, ?, ???, ??, ??, ?
-#???-?-????
-#
-#  noun-suffix-aux: The stem form of ????? (??) that is used to indicate conditions, 
-#  is treated as ??? ("auxiliary verb") in school grammars, and attach to the 
-#  conjunctive form of inflectional words.
-#  e.g. ???
-#???-?-?????
-#
-#  noun-suffix-adjective-base: Suffixes that attach to other nouns or the conjunctive 
-#  form of inflectional words and appear before the copula ?? ("da").
-#  e.g. ??, ??, ???
-#???-?-?????
-#
-#  noun-suffix-adverbial: Suffixes that attach to other nouns and can behave as adverbs.
-#  e.g. ? (??), ?, ?, ?, ???, ?, ??, ?, ?? (??)
-#???-?-??????
-#
-#  noun-suffix-classifier: Suffixes that attach to numbers and form nouns. This category 
-#  is more inclusive than ??? ("classifier") and includes common nouns that attach 
-#  to numbers.
-#  e.g. ??, ??, ??, ??, ???????, cm, kg, ???, ???, ??, ???, ???
-#???-?-???
-#
-#  noun-suffix-special: Special suffixes that mainly attach to inflecting words.
-#  e.g. (?) ??, (???) ??
-#???-?-??
-#
-#  noun-suffix-conjunctive: Nouns that behave like conjunctions and join two words 
-#  together.
-#  e.g. (??) ? (??????), ? (??????), (3) ? (5), (?) ?? ()
-#???-????
-#
-#  noun-verbal_aux: Nouns that attach to the conjunctive particle ?? ("te") and are 
-#  semantically verb-like.
-#  e.g. ?????, ??, , ???
-#???-????????
-#
-#  noun-quotation: text that cannot be segmented into words, proverbs, Chinese poetry, 
-#  dialects, English, etc. Currently, the only entry for ??? ??????? ("noun quotation") 
-#  is ????? ("iwaku").
-#???-???????
-#
-#  noun-nai_adjective: Words that appear before the auxiliary verb ??? ("nai") and
-#  behave like an adjective.
-#  e.g. ???, ??, ????, ???
-#???-???????
-#
-#####
-#  prefix: unclassified prefixes
-#???
-#
-#  prefix-nominal: Prefixes that attach to nouns (including adjective stem forms) 
-#  excluding numerical expressions.
-#  e.g. ?? (?), ?? (?), ?? (?), ?? (??), ? (??), ?? (??), ?? (?)
-#???-?????
-#
-#  prefix-verbal: Prefixes that attach to the imperative form of a verb or a verb
-#  in conjunctive form followed by ???/?????/??????.
-#  e.g. ?? (???????), ?? (?)
-#???-?????
-#
-#  prefix-adjectival: Prefixes that attach to adjectives.
-#  e.g. ?? (???????), ??? (????)
-#???-????
-#
-#  prefix-numerical: Prefixes that attach to numerical expressions.
-#  e.g. ?, ?????, ??
-#???-???
-#
-#####
-#  verb: unclassified verbs
-#???
-#
-#  verb-main:
-#???-???
-#
-#  verb-auxiliary:
-#???-????
-#
-#  verb-suffix:
-#???-?
-#
-#####
-#  adjective: unclassified adjectives
-#??
-#
-#  adjective-main:
-#??-???
-#
-#  adjective-auxiliary:
-#??-????
-#
-#  adjective-suffix:
-#??-?
-#
-#####
-#  adverb: unclassified adverbs
-#???
-#
-#  adverb-misc: Words that can be segmented into one unit and where adnominal 
-#  modification is not possible.
-#  e.g. ?????????, ??
-#???-???
-#
-#  adverb-particle_conjunction: Adverbs that can be followed by ??, ??, ??, 
-#  ??, ???, ??, etc.
-#  e.g. ??????, ??????, ??????, ?????, ?????
-#???-?????
-#
-#####
-#  adnominal: Words that only have noun-modifying forms.
-#  e.g. ???, ???, ???, ??, ??????, ????????, ?????, ??????, ??????, ??????, ??????, 
-#       ?????, ?????, ?????, ?????, ????, ???, ????, ??????, ????, ??????, 
-#       ??(, ??) ??? (????????)??, ??????, ???????, ?????, ??????, ??????????, ?
-#???
-#
-#####
-#  conjunction: Conjunctions that can occur independently.
-#  e.g. ??, ?????, ?????, ?????, ????????
-???
-#
-#####
-#  particle: unclassified particles.
-??
-#
-#  particle-case: case particles where the subclassification is undefined.
-??-???
-#
-#  particle-case-misc: Case particles.
-#  e.g. ???, ??, ??, ??, ??, ??, ???, ??, ??, ???
-??-???-???
-#
-#  particle-case-quote: the "to" that appears after nouns, a person?? speech, 
-#  quotation marks, expressions of decisions from a meeting, reasons, judgements,
-#  conjectures, etc.
-#  e.g. ( ??) ?? (???.), ( ????) ?? (???????...)
-??-???-??
-#
-#  particle-case-compound: Compounds of particles and verbs that mainly behave 
-#  like case particles.
-#  e.g. ????, ????, ?????, ????, ?????, ????, ????, ????????, ????????, ?????,
-#       ??????, ??????, ?????, ??????, ??????, ??????, ??????,?????, ??????, ??????, 
-#       ?????, ??????, ??????, ?????, ????????, ??????, ????????, ??????, ?????, 
-#       ??????, ????????, ?????, ?????, ????????, ?????, ??????, ?????, ????????, 
-#       ??????, ????????, ??????, ??????, ?????, ?????, ??????, ?????, ??????, ?????,
-#       ?????, ???????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, ?????, 
-#       ????????, ??????, ?????, ????, ?????, ???????, ???????, ????????, ??????, ??????,
-#       ??-??/, ????-??????????/, (?) ????? (?)-??/, ?????-??/, ????, ?????
-??-???-??
-#
-#  particle-conjunctive:
-#  e.g. ???, ??????, ??, ?????, ?????, ???, ??, ??, ??, ??, ??, ?????, ?????, ??, ??, 
-#       ?????, ???, ???, ???, ??, ?????, ?? ( ???), ??????, (?????) ???(??????)-??/, 
-#       (??) ??(??????)-??/, (???) ????? (?????????)-??/, (????????)???? (?)-??/
-??-????
-#
-#  particle-dependency:
-#  e.g. ???, ???, ???, ???, ??, ??, ??
-??-???
-#
-#  particle-adverbial:
-#  e.g. ?????, ???, ?????, ?, ?????, ???, (??) ???(?????????????)-??/, 
-#       (???)????? (??????)-??/, ???, (?) ???, ???, (?) ??? (??), (???) ????? (???)-??/,
-#       (?) ?????, (???) ????? (???)-??/, ???, ???, (?) ?????-??/, ???, 
-#       (?)????-??/, (???) ?? (?????), ? (??), (??) ??, ????, ????-??/, ?????-??/,
-#       ??, ?, ??, ?, (?) ?? (??)([??-??? ????? [??-??? ???????????????)
-??-????
-#
-#  particle-interjective: particles with interjective grammatical roles.
-#  e.g. (?) ??
-??-?????
-#
-#  particle-coordinate:
-#  e.g. ??, ???, ???, ???, ??, ???, ??, ???
-??-????
-#
-#  particle-final:
-#  e.g. ???, ?????, ??, ??, (??)??-??/, (??????) ??-??/, ??, ??, ???-??/, ??, ??, ??, 
-#       ???-??/, ???-??/, ???-??/, ??, ???-??/, ??, ??, ??, ???-??/, ??, ???-??/
-??-???
-#
-#  particle-adverbial/conjunctive/final: The particle "ka" when unknown whether it is 
-#  adverbial, conjunctive, or sentence final. For example:
-#       (a) ?? ?? B ????. Ex:??(????????) ??,(???????) ?? (.)??
-#       (b) Inside an adverb phrase. Ex:??(?????) ?? (, ???????????.)??
-#           ??(???????????) ?? (, ?????????.)??
-#       (c) ???????????. Ex:??(???????) ?? (??????????????.)??
-#  e.g. ??
-??-?????????????
-#
-#  particle-adnominalizer: The "no" that attaches to nouns and modifies 
-#  non-inflectional words.
-??-????
-#
-#  particle-adnominalizer: The "ni" and "to" that appear following nouns and adverbs 
-#  that are giongo, giseigo, or gitaigo.
-#  e.g. ??, ??
-??-?????
-#
-#  particle-special: A particle that does not fit into one of the above classifications. 
-#  This includes particles that are used in Tanka, Haiku, and other poetry.
-#  e.g. ???, ???, ( ????????) ??, (?????) ???(??????), (?) ?? (?)
-??-??
-#
-#####
-#  auxiliary-verb:
-???
-#
-#####
-#  interjection: Greetings and other exclamations.
-#  e.g. ??????, ??????????????, ????????, ???????, ????????, ??????????, ??????????????, 
-#       ????????, ?????????, ??????, ????????, ???, ?????, ?????, ?????????
-#????
-#
-#####
-#  symbol: unclassified Symbols.
-??
-#
-#  symbol-misc: A general symbol not in one of the categories below.
-#  e.g. [???@$???+]
-??-???
-#
-#  symbol-comma: Commas
-#  e.g. [,??
-??-??
-#
-#  symbol-period: Periods and full stops.
-#  e.g. [.???
-??-??
-#
-#  symbol-space: Full-width whitespace.
-??-?
-#
-#  symbol-open_bracket:
-#  e.g. [({????????
-??-????
-#
-#  symbol-close_bracket:
-#  e.g. [)}??????????
-??-????
-#
-#  symbol-alphabetic:
-#??-???????????
-#
-#####
-#  other: unclassified other
-#????
-#
-#  other-interjection: Words that are hard to classify as noun-suffixes or 
-#  sentence-final particles.
-#  e.g. (??)??
-????-???
-#
-#####
-#  filler: Aizuchi that occurs during a conversation or sounds inserted as filler.
-#  e.g. ???, ?????, ???
-?????
-#
-#####
-#  non-verbal: non-verbal sound.
-?????
-#
-#####
-#  fragment:
-#????
-#
-#####
-#  unknown: unknown part of speech.
-#????
-#
-##### End of file
\ No newline at end of file
diff --git a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stopwords.txt b/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stopwords.txt
deleted file mode 100644
index 9a93e69..0000000
--- a/modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis/kuromoji/stopwords.txt
+++ /dev/null
@@ -1,127 +0,0 @@
-#
-# This file defines a stopword set for Japanese.
-#
-# This set is made up of hand-picked frequent terms from segmented Japanese Wikipedia.
-# Punctuation characters and frequent kanji have mostly been left out.  See LUCENE-3745
-# for frequency lists, etc. that can be useful for making your own set (if desired)
-#
-# Note that there is an overlap between these stopwords and the terms stopped when used
-# in combination with the KuromojiPartOfSpeechStopFilter.  When editing this file, note
-# that comments are not allowed on the same line as stopwords.
-#
-# Also note that stopping is done in a case-insensitive manner.  Change your StopFilter
-# configuration if you need case-sensitive stopping.  Lastly, note that stopping is done
-# using the same character width as the entries in this file.  Since this StopFilter is
-# normally done after a CJKWidthFilter in your chain, you would usually want your romaji
-# entries to be in half-width and your kana entries to be in full-width.
-#
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-??
-???
-???
-??
-???
-???
-??
-???
-????
-??
-??
-???
-???
-???
-???
-???
-???
-???
-???
-???
-??
-???
-????
-???
-??
-???
-???
-??
-??
-??
-???
-?????
-?????
-???
-???
-?????
-??
-???
-?????
-??????
-??
-?????
-???
-?????
-??????
-??
-???
-????
-????
-???
-??
-???
-???
-???
-??
-??
-??
-??????
-?????
-???
-?????
-??
-??
-???
-????
-??????
-???
-??
-??
-???
-??????
-??
-???
-???
-?????
-??
-??
-???
-??
-?????
-???
-?????
-?????
-?????
-?????
-??????
-????
-??
-??
-?????
-??????
-?????
-????
-????
-??
-??
-????
-???
-##### End of file
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java
new file mode 100644
index 0000000..3b02fc6
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestExtendedMode.java
@@ -0,0 +1,72 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.lucene.util._TestUtil;
+
+public class TestExtendedMode extends BaseTokenStreamTestCase {
+  private final Analyzer analyzer = new Analyzer() {
+    
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, null, true, Mode.EXTENDED);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+  
+  /** simple test for supplementary characters */
+  public void testSurrogates() throws IOException {
+    assertAnalyzesTo(analyzer, "???????",
+      new String[] { "?", "??", "??", "??", "??", "??" });
+  }
+  
+  /** random test ensuring we don't ever split supplementaries */
+  public void testSurrogates2() throws IOException {
+    int numIterations = atLeast(10000);
+    for (int i = 0; i < numIterations; i++) {
+      String s = _TestUtil.randomUnicodeString(random, 100);
+      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
+      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
+      ts.reset();
+      while (ts.incrementToken()) {
+        assertTrue(UnicodeUtil.validUTF16String(termAtt));
+      }
+    }
+  }
+  
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
+  }
+  
+  /** blast some random large strings through the analyzer */
+  public void testRandomHugeStrings() throws Exception {
+    checkRandomData(random, analyzer, 200*RANDOM_MULTIPLIER, 8192);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer.java
new file mode 100644
index 0000000..1eb059a
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseAnalyzer.java
@@ -0,0 +1,186 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+
+/**
+ * Test Kuromoji Japanese morphological analyzer
+ */
+public class TestJapaneseAnalyzer extends BaseTokenStreamTestCase {
+  /** This test fails with NPE when the 
+   * stopwords file is missing in classpath */
+  public void testResourcesAvailable() {
+    new JapaneseAnalyzer(TEST_VERSION_CURRENT);
+  }
+  
+  /**
+   * An example sentence, test removal of particles, etc by POS,
+   * lemmatization with the basic form, and that position increments
+   * and offsets are correct.
+   */
+  public void testBasics() throws IOException {
+    assertAnalyzesTo(new JapaneseAnalyzer(TEST_VERSION_CURRENT), "?????????????????",
+        new String[] { "??", "??", "??", "????" },
+        new int[] { 0, 3, 6,  9 },
+        new int[] { 2, 5, 8, 11 },
+        new int[] { 1, 2, 2,  2 }
+      );
+  }
+
+  /**
+   * Test that search mode is enabled and working by default
+   */
+  public void testDecomposition() throws IOException {
+
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+
+    // Senior software engineer:
+    assertAnalyzesToPositions(a, "???????????????????",
+                              new String[] { "????",
+                                             "???????????????????", // zero pos inc
+                                             "???????",
+                                             "??????" },
+                              new int[] { 1, 0, 1, 1},
+                              new int[] { 1, 3, 1, 1}
+                              );
+
+    // Senior project manager: also tests katakana spelling variation stemming
+    assertAnalyzesToPositions(a, "????????????????????",
+                              new String[] { "????",
+                                              "??????????????????", // trailing ?? removed by stemming, zero pos inc
+                                              "????????",
+                                              "???????"}, // trailing ?? removed by stemming
+                              new int[]{1, 0, 1, 1},
+                              new int[]{1, 3, 1, 1}
+                              );
+
+    // Kansai International Airport:
+    assertAnalyzesToPositions(a, "???",
+                              new String[] { "?",
+                                             "???", // zero pos inc
+                                             "??",
+                                             "" },
+                              new int[] {1, 0, 1, 1},
+                              new int[] {1, 3, 1, 1}
+                              );
+
+    // Konika Minolta Holdings; not quite the right
+    // segmentation (see LUCENE-3726):
+    assertAnalyzesToPositions(a, "???????????????????",
+                              new String[] { "????",
+                                             "???????????????????", // zero pos inc
+                                             "??????", 
+                                             "??????????"},
+                              new int[] {1, 0, 1, 1},
+                              new int[] {1, 3, 1, 1}
+                              );
+
+    // Narita Airport
+    assertAnalyzesToPositions(a, "???",
+                              new String[] { "???",
+                                             "???",
+                                             "" },
+                              new int[] {1, 0, 1},
+                              new int[] {1, 2, 1}
+                              );
+
+    // Kyoto University Baseball Club
+    assertAnalyzesToPositions(new JapaneseAnalyzer(TEST_VERSION_CURRENT), "??????????",
+                     new String[] { "???",
+                                    "?",
+                                    "??",
+                                    "???",
+                                    "??" },
+                              new int[] {1, 1, 1, 1, 1},
+                              new int[] {1, 1, 1, 1, 1});
+    // toDotFile(a, "???", "/mnt/scratch/out.dot");
+  }
+
+  
+  /**
+   * blast random strings against the analyzer
+   */
+  public void testRandom() throws IOException {
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+    checkRandomData(random, a, atLeast(10000));
+  }
+  
+  /** blast some random large strings through the analyzer */
+  public void testRandomHugeStrings() throws Exception {
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+        JapaneseAnalyzer.getDefaultStopSet(),
+        JapaneseAnalyzer.getDefaultStopTags());
+    checkRandomData(random, a, 200*RANDOM_MULTIPLIER, 8192);
+  }
+
+  // Copied from TestJapaneseTokenizer, to make sure passing
+  // user dict to analyzer works:
+  public void testUserDict3() throws Exception {
+    // Test entry that breaks into multiple tokens:
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, TestJapaneseTokenizer.readDict(),
+                                            Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+    assertTokenStreamContents(a.tokenStream("foo", new StringReader("abcd")),
+                              new String[] { "a", "b", "cd"  },
+                              new int[] { 0, 1, 2 },
+                              new int[] { 1, 2, 4 },
+                              new Integer(4)
+    );
+  }
+
+  // LUCENE-3897: this string (found by running all jawiki
+  // XML through JapaneseAnalyzer) caused AIOOBE
+  public void testCuriousString() throws Exception {
+    final String s = "&lt;li&gt;06:26 2004?3??21?? [[????:Kzhr|Kzhr]] &quot;??????&quot; ????????? &lt;em&gt;&lt;nowiki&gt;(?????: ???????: &amp;#39;???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????&amp;#39;)&lt;/nowiki&gt;&lt;/em&gt;&lt;/li&gt;";
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
+  }
+
+  // LUCENE-3897: this string (found by
+  // testHugeRandomStrings) tripped assert
+  public void testAnotherCuriousString() throws Exception {
+    final String s = "???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????";
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
+  }
+
+  // LUCENE-3897: this string (found by
+  // testHugeRandomStrings) tripped assert
+  public void testYetAnotherCuriousString() throws Exception {
+    final String s = "????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????";
+    final Analyzer a = new JapaneseAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
+                                            JapaneseAnalyzer.getDefaultStopSet(),
+                                            JapaneseAnalyzer.getDefaultStopTags());
+    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilter.java
new file mode 100644
index 0000000..2672cc9
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseBaseFormFilter.java
@@ -0,0 +1,62 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+
+public class TestJapaneseBaseFormFilter extends BaseTokenStreamTestCase {
+  private Analyzer analyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, null, true, JapaneseTokenizer.DEFAULT_MODE);
+      return new TokenStreamComponents(tokenizer, new JapaneseBaseFormFilter(tokenizer));
+    }
+  };
+  
+  public void testBasics() throws IOException {
+    assertAnalyzesTo(analyzer, "???????????????????",
+        new String[] { "???", "??", "??", "??", "?", "??", "???", "??"  }
+    );
+  }
+  
+  public void testEnglish() throws IOException {
+    assertAnalyzesTo(analyzer, "this atest",
+        new String[] { "this", "atest" });
+  }
+  
+  public void testRandomStrings() throws IOException {
+    checkRandomData(random, analyzer, atLeast(10000));
+  }
+  
+  public void testEmptyTerm() throws IOException {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+        Tokenizer tokenizer = new KeywordTokenizer(reader);
+        return new TokenStreamComponents(tokenizer, new JapaneseBaseFormFilter(tokenizer));
+      }
+    };
+    checkOneTermReuse(a, "", "");
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseKatakanaStemFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseKatakanaStemFilter.java
new file mode 100644
index 0000000..34d23b8
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseKatakanaStemFilter.java
@@ -0,0 +1,83 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+
+import java.io.IOException;
+import java.io.Reader;
+
+/**
+ * Tests for {@link JapaneseKatakanaStemFilter}
+ */
+public class TestJapaneseKatakanaStemFilter extends BaseTokenStreamTestCase {
+  private Analyzer analyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      // Use a MockTokenizer here since this filter doesn't really depend on Kuromoji
+      Tokenizer source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+      return new TokenStreamComponents(source, new JapaneseKatakanaStemFilter(source));
+    }
+  };
+  
+  /**
+   * Test a few common katakana spelling variations.
+   * <p>
+   * English translations are as follows:
+   * <ul>
+   *   <li>copy</li>
+   *   <li>coffee</li>
+   *   <li>taxi</li>
+   *   <li>party</li>
+   *   <li>party (without long sound)</li>
+   *   <li>center</li>
+   * </ul>
+   * Note that we remove a long sound in the case of "coffee" that is required.
+   * </p>
+   */
+  public void testStemVariants() throws IOException {
+    assertAnalyzesTo(analyzer, "???? ????? ???? ???????? ?????? ????",
+      new String[] { "????",  "????", "????", "??????", "??????", "????" },
+      new int[] { 0, 4,  9, 14, 20, 25 },
+      new int[] { 3, 8, 13, 19, 24, 29 });
+  }
+
+  public void testUnsupportedHalfWidthVariants() throws IOException {
+    // The below result is expected since only full-width katakana is supported
+    assertAnalyzesTo(analyzer, "??", new String[] { "??" });
+  }
+  
+  public void testRandomData() throws IOException {
+    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
+  }
+  
+  public void testEmptyTerm() throws IOException {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+        Tokenizer tokenizer = new KeywordTokenizer(reader);
+        return new TokenStreamComponents(tokenizer, new JapaneseKatakanaStemFilter(tokenizer));
+      }
+    };
+    checkOneTermReuse(a, "", "");
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseReadingFormFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseReadingFormFilter.java
new file mode 100644
index 0000000..de8bbe3
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseReadingFormFilter.java
@@ -0,0 +1,76 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.core.KeywordTokenizer;
+
+import java.io.IOException;
+import java.io.Reader;
+
+/**
+ * Tests for {@link TestJapaneseReadingFormFilter}
+ */
+public class TestJapaneseReadingFormFilter extends BaseTokenStreamTestCase {
+  private Analyzer katakanaAnalyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, null, true, JapaneseTokenizer.Mode.SEARCH);
+      return new TokenStreamComponents(tokenizer, new JapaneseReadingFormFilter(tokenizer, false));
+    }
+  };
+
+  private Analyzer romajiAnalyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, null, true, JapaneseTokenizer.Mode.SEARCH);
+      return new TokenStreamComponents(tokenizer, new JapaneseReadingFormFilter(tokenizer, true));
+    }
+  };
+
+
+  public void testKatakanaReadings() throws IOException {
+    assertAnalyzesTo(katakanaAnalyzer, "?????????????????",
+        new String[] { "????", "??", "?????", "????", "??", "?????", "??" }
+    );
+  }
+
+  public void testRomajiReadings() throws IOException {
+    assertAnalyzesTo(romajiAnalyzer, "?????????????????",
+        new String[] { "kon'ya", "ha", "robato", "sensei", "to", "hanashi", "ta" }
+    );
+  }
+
+  public void testRandomData() throws IOException {
+    checkRandomData(random, katakanaAnalyzer, 1000*RANDOM_MULTIPLIER);
+    checkRandomData(random, romajiAnalyzer, 1000*RANDOM_MULTIPLIER);
+  }
+  
+  public void testEmptyTerm() throws IOException {
+    Analyzer a = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+        Tokenizer tokenizer = new KeywordTokenizer(reader);
+        return new TokenStreamComponents(tokenizer, new JapaneseReadingFormFilter(tokenizer));
+      }
+    };
+    checkOneTermReuse(a, "", "");
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java
new file mode 100644
index 0000000..4d025cb
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseTokenizer.java
@@ -0,0 +1,632 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.LineNumberReader;
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.analysis.ja.dict.ConnectionCosts;
+import org.apache.lucene.analysis.ja.dict.UserDictionary;
+import org.apache.lucene.analysis.ja.tokenattributes.*;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.lucene.util._TestUtil;
+
+public class TestJapaneseTokenizer extends BaseTokenStreamTestCase {
+
+  public static UserDictionary readDict() {
+    InputStream is = TestJapaneseTokenizer.class.getResourceAsStream("userdict.txt");
+    if (is == null) {
+      throw new RuntimeException("Cannot find userdict.txt in test classpath!");
+    }
+    try {
+      try {
+        Reader reader = new InputStreamReader(is, IOUtils.CHARSET_UTF_8);
+        return new UserDictionary(reader);
+      } finally {
+        is.close();
+      }
+    } catch (IOException ioe) {
+      throw new RuntimeException(ioe);
+    }
+  }
+
+  private Analyzer analyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, readDict(), false, Mode.SEARCH);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+
+  private Analyzer analyzerNormal = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, readDict(), false, Mode.NORMAL);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+
+  private Analyzer analyzerNoPunct = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, readDict(), true, Mode.SEARCH);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+
+  private Analyzer extendedModeAnalyzerNoPunct = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, readDict(), true, Mode.EXTENDED);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+
+  public void testNormalMode() throws Exception {
+    assertAnalyzesTo(analyzerNormal,
+                     "???????????????????",
+                     new String[] {"???????????????????"});
+  }
+
+  public void testDecomposition1() throws Exception {
+    assertAnalyzesTo(analyzerNoPunct, "?????????????????????????????????????????????" +
+                         "???????????????????????????????????????????????????????",
+     new String[] { "???", "??",  "?", "?", "??", "??", "??", "??", "??", "??", "??", "??",      
+                    "???", "???", "???", "??", "?", "??", "??", "??", "?", "??", "???",  "??????", 
+                    "?", "???", "??", "??", "??", "?", "??",  "??", "??", "??",  "???",
+                    "??", "??", "?", "?", "???", "?", "??", "??", "??", "???", "??", "???" },
+     new int[] { 0, 2, 4, 6, 7,  8, 10, 11, 13, 14, 16, 18, 19, 21, 23, 25, 26, 28, 29, 30, 
+                 31, 33, 34, 37, 41, 42, 44, 45, 47, 49, 51, 53, 55, 56, 58, 60,
+                 62, 63, 64, 65, 67, 68, 69, 71, 72, 75, 76 },
+     new int[] { 2, 3, 6, 7, 8, 10, 11, 13, 14, 16, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31,
+                 33, 34, 36, 41, 42, 44, 45, 47, 49, 51, 52, 55, 56, 57, 60, 62,
+                 63, 64, 65, 67, 68, 69, 71, 72, 75, 76, 78 }
+    );
+  }
+  
+  public void testDecomposition2() throws Exception {
+    assertAnalyzesTo(analyzerNoPunct, "????????????????????????",
+      new String[] { "?", "??", "?", "??", "?????", "???", "?????", "??", "???", "???" },
+      new int[] { 0, 2, 3, 5, 6,  10, 13, 16, 17, 19 },
+      new int[] { 2, 3, 5, 6, 10, 13, 16, 17, 19, 21 }
+    );
+  }
+  
+  public void testDecomposition3() throws Exception {
+    assertAnalyzesTo(analyzerNoPunct, "?????????????????",
+      new String[] { "?", "??", "?", "?????",  "????????" },
+      new int[] { 0, 2, 3, 5, 10 },
+      new int[] { 2, 3, 5, 9, 15 }
+    );
+  }
+
+  public void testDecomposition4() throws Exception {
+    assertAnalyzesTo(analyzer, "???????????",
+      new String[] { "???", "??", "??", "??", "??", "???" },
+      new int[] { 0, 2, 3, 4, 5, 6 },
+      new int[] { 2, 3, 4, 5, 6, 8 }
+    );
+  }
+
+  /* Note this is really a stupid test just to see if things arent horribly slow.
+   * ideally the test would actually fail instead of hanging...
+   */
+  public void testDecomposition5() throws Exception {
+    TokenStream ts = analyzer.tokenStream("bogus", new StringReader("????????????????????????????????????????????????????????????"));
+    ts.reset();
+    while (ts.incrementToken()) {
+      
+    }
+    ts.end();
+    ts.close();
+  }
+
+  /*
+    // NOTE: intentionally fails!  Just trying to debug this
+    // one input...
+  public void testDecomposition6() throws Exception {
+    assertAnalyzesTo(analyzer, "?????????????",
+      new String[] { "???", "??", "??", "??", "??", "???" },
+      new int[] { 0, 2, 3, 4, 5, 6 },
+      new int[] { 2, 3, 4, 5, 6, 8 }
+                     );
+  }
+  */
+
+  /** Tests that sentence offset is incorporated into the resulting offsets */
+  public void testTwoSentences() throws Exception {
+    /*
+    //TokenStream ts = a.tokenStream("foo", new StringReader("???????????????????????"));
+    TokenStream ts = analyzer.tokenStream("foo", new StringReader("&#x250cdf66<!--\"<!--#<!--;?><!--#<!--#><!---->?>-->;"));
+    ts.reset();
+    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
+    while(ts.incrementToken()) {
+      System.out.println("  " + termAtt.toString());
+    }
+    System.out.println("DONE PARSE\n\n");
+    */
+
+    assertAnalyzesTo(analyzerNoPunct, "????????????????? ?????????????????",
+      new String[] { "?", "??", "?", "?????", "????????",  "?", "??", "?", "?????",  "????????"  },
+      new int[] { 0, 2, 3, 5, 10, 17, 19, 20, 22, 27 },
+      new int[] { 2, 3, 5, 9, 15, 19, 20, 22, 26, 32 }
+    );
+  }
+
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
+    checkRandomData(random, analyzerNoPunct, 10000*RANDOM_MULTIPLIER);
+  }
+  
+  /** blast some random large strings through the analyzer */
+  public void testRandomHugeStrings() throws Exception {
+    checkRandomData(random, analyzer, 200*RANDOM_MULTIPLIER, 8192);
+    checkRandomData(random, analyzerNoPunct, 200*RANDOM_MULTIPLIER, 8192);
+  }
+  
+  public void testLargeDocReliability() throws Exception {
+    for (int i = 0; i < 100; i++) {
+      String s = _TestUtil.randomUnicodeString(random, 10000);
+      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
+      ts.reset();
+      while (ts.incrementToken()) {
+      }
+    }
+  }
+  
+  /** simple test for supplementary characters */
+  public void testSurrogates() throws IOException {
+    assertAnalyzesTo(analyzer, "???????",
+      new String[] { "?", "??", "??", "??", "??", "??" });
+  }
+  
+  /** random test ensuring we don't ever split supplementaries */
+  public void testSurrogates2() throws IOException {
+    int numIterations = atLeast(10000);
+    for (int i = 0; i < numIterations; i++) {
+      if (VERBOSE) {
+        System.out.println("\nTEST: iter=" + i);
+      }
+      String s = _TestUtil.randomUnicodeString(random, 100);
+      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
+      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
+      ts.reset();
+      while (ts.incrementToken()) {
+        assertTrue(UnicodeUtil.validUTF16String(termAtt));
+      }
+    }
+  }
+
+  public void testOnlyPunctuation() throws IOException {
+    TokenStream ts = analyzerNoPunct.tokenStream("foo", new StringReader("????????"));
+    ts.reset();
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+
+  public void testOnlyPunctuationExtended() throws IOException {
+    TokenStream ts = extendedModeAnalyzerNoPunct.tokenStream("foo", new StringReader("......"));
+    ts.reset();
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+  
+  // note: test is kinda silly since kuromoji emits punctuation tokens.
+  // but, when/if we filter these out it will be useful.
+  public void testEnd() throws Exception {
+    assertTokenStreamContents(analyzerNoPunct.tokenStream("foo", new StringReader("???????????")),
+        new String[] { "???", "??", "??", "??", "??", "???" },
+        new int[] { 0, 2, 3, 4, 5, 6 },
+        new int[] { 2, 3, 4, 5, 6, 8 },
+        new Integer(8)
+    );
+
+    assertTokenStreamContents(analyzerNoPunct.tokenStream("foo", new StringReader("???????????    ")),
+        new String[] { "???", "??", "??", "??", "??", "???"  },
+        new int[] { 0, 2, 3, 4, 5, 6, 8 },
+        new int[] { 2, 3, 4, 5, 6, 8, 9 },
+        new Integer(12)
+    );
+  }
+
+  public void testUserDict() throws Exception {
+    // Not a great test because w/o userdict.txt the
+    // segmentation is the same:
+    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("????????")),
+                              new String[] { "?", "??", "", "??", "??", "??"  },
+                              new int[] { 0, 2, 4, 6, 7, 9 },
+                              new int[] { 2, 4, 6, 7, 9, 10 },
+                              new Integer(10)
+    );
+  }
+
+  public void testUserDict2() throws Exception {
+    // Better test: w/o userdict the segmentation is different:
+    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("????")),
+                              new String[] { "????"  },
+                              new int[] { 0 },
+                              new int[] { 3 },
+                              new Integer(3)
+    );
+  }
+
+  public void testUserDict3() throws Exception {
+    // Test entry that breaks into multiple tokens:
+    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("abcd")),
+                              new String[] { "a", "b", "cd"  },
+                              new int[] { 0, 1, 2 },
+                              new int[] { 1, 2, 4 },
+                              new Integer(4)
+    );
+  }
+
+  // HMM: fails (segments as a/b/cd/efghij)... because the
+  // two paths have exactly equal paths (1 KNOWN + 1
+  // UNKNOWN) and we don't seem to favor longer KNOWN /
+  // shorter UNKNOWN matches:
+
+  /*
+  public void testUserDict4() throws Exception {
+    // Test entry that has another entry as prefix
+    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("abcdefghij")),
+                              new String[] { "ab", "cd", "efg", "hij"  },
+                              new int[] { 0, 2, 4, 7 },
+                              new int[] { 2, 4, 7, 10 },
+                              new Integer(10)
+    );
+  }
+  */
+  
+  public void testSegmentation() throws Exception {
+    // Skip tests for Michelle Kwan -- UniDic segments Kwan as ?? ???
+    //		String input = "????????????????????????????????????????????????????";
+    //		String[] surfaceForms = {
+    //				"?????", "??", "?????", "??", "???", "??", "??", "??", "??",
+    //				"????", "??????", "??", "??", "??", "??",
+    //				"?????????", "??"
+    //		};
+    String input = "???????????????????????????????";
+    String[] surfaceForms = {
+        "????", "??????", "??", "??", "??", "??",
+        "?????????", "??"
+    };
+    assertAnalyzesTo(analyzer,
+                     input,
+                     surfaceForms);
+  }
+
+  public void testLatticeToDot() throws Exception {
+    final GraphvizFormatter gv2 = new GraphvizFormatter(ConnectionCosts.getInstance());
+    final Analyzer analyzer = new Analyzer() {
+      @Override
+      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+        JapaneseTokenizer tokenizer = new JapaneseTokenizer(reader, readDict(), false, Mode.SEARCH);
+        tokenizer.setGraphvizFormatter(gv2);
+        return new TokenStreamComponents(tokenizer, tokenizer);
+      }
+    };
+
+    String input = "???????????????????????????????";
+    String[] surfaceForms = {
+        "????", "??????", "??", "??", "??", "??",
+        "?????????", "??"
+    };
+    assertAnalyzesTo(analyzer,
+                     input,
+                     surfaceForms);
+    
+    assertTrue(gv2.finish().indexOf("22.0") != -1);
+  }
+
+  private void assertReadings(String input, String... readings) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    ReadingAttribute readingAtt = ts.addAttribute(ReadingAttribute.class);
+    ts.reset();
+    for(String reading : readings) {
+      assertTrue(ts.incrementToken());
+      assertEquals(reading, readingAtt.getReading());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+
+  private void assertPronunciations(String input, String... pronunciations) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    ReadingAttribute readingAtt = ts.addAttribute(ReadingAttribute.class);
+    ts.reset();
+    for(String pronunciation : pronunciations) {
+      assertTrue(ts.incrementToken());
+      assertEquals(pronunciation, readingAtt.getPronunciation());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+  
+  private void assertBaseForms(String input, String... baseForms) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    BaseFormAttribute baseFormAtt = ts.addAttribute(BaseFormAttribute.class);
+    ts.reset();
+    for(String baseForm : baseForms) {
+      assertTrue(ts.incrementToken());
+      assertEquals(baseForm, baseFormAtt.getBaseForm());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+
+  private void assertInflectionTypes(String input, String... inflectionTypes) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    InflectionAttribute inflectionAtt = ts.addAttribute(InflectionAttribute.class);
+    ts.reset();
+    for(String inflectionType : inflectionTypes) {
+      assertTrue(ts.incrementToken());
+      assertEquals(inflectionType, inflectionAtt.getInflectionType());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+
+  private void assertInflectionForms(String input, String... inflectionForms) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    InflectionAttribute inflectionAtt = ts.addAttribute(InflectionAttribute.class);
+    ts.reset();
+    for(String inflectionForm : inflectionForms) {
+      assertTrue(ts.incrementToken());
+      assertEquals(inflectionForm, inflectionAtt.getInflectionForm());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+  
+  private void assertPartsOfSpeech(String input, String... partsOfSpeech) throws IOException {
+    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
+    PartOfSpeechAttribute partOfSpeechAtt = ts.addAttribute(PartOfSpeechAttribute.class);
+    ts.reset();
+    for(String partOfSpeech : partsOfSpeech) {
+      assertTrue(ts.incrementToken());
+      assertEquals(partOfSpeech, partOfSpeechAtt.getPartOfSpeech());
+    }
+    assertFalse(ts.incrementToken());
+    ts.end();
+  }
+  
+  public void testReadings() throws Exception {
+    assertReadings("?????????????",
+                   "??",
+                   "??",
+                   "??",
+                   "??",
+                   "???",
+                   "??");
+  }
+  
+  public void testReadings2() throws Exception {
+    assertReadings("?????????????????",
+                   "?????",
+                   "??",
+                   "?????",
+                   "??",
+                   "????",
+                   "??",
+                   "???",
+                   "??",
+                   "??");
+  }
+  
+  public void testPronunciations() throws Exception {
+    assertPronunciations("?????????????",
+                         "??",
+                         "??",
+                         "??",
+                         "??",
+                         "???",
+                         "??");
+  }
+  
+  public void testPronunciations2() throws Exception {
+    // pronunciation differs from reading here
+    assertPronunciations("?????????????????",
+                         "?????",
+                         "??",
+                         "?????",
+                         "??",
+                         "????",
+                         "??",
+                         "???",
+                         "??",
+                         "??");
+  }
+  
+  public void testBasicForms() throws Exception {
+    assertBaseForms("?????????????????????",
+                    null,
+                    null,
+                    null,
+                    null,
+                    null,
+                    null,
+                    "???",
+                    null,
+                    null);
+  }
+  
+  public void testInflectionTypes() throws Exception {
+    assertInflectionTypes("?????????????????????",
+                          null,
+                          null,
+                          null,
+                          null,
+                          null,
+                          null,
+                          "?????",
+                          "??????",
+                          null);
+  }
+  
+  public void testInflectionForms() throws Exception {
+    assertInflectionForms("?????????????????????",
+                          null,
+                          null,
+                          null,
+                          null,
+                          null,
+                          null,
+                          "???",
+                          "???",
+                          null);
+  }
+  
+  public void testPartOfSpeech() throws Exception {
+    assertPartsOfSpeech("?????????????????????",
+                        "???-??-???",
+                        "??-???",
+                        "???-?????",
+                        "???-????",
+                        "???-???",
+                        "??-???-???",
+                        "???-???",
+                        "???",
+                        "??-??");
+  }
+
+  // TODO: the next 2 tests are no longer using the first/last word ids, maybe lookup the words and fix?
+  // do we have a possibility to actually lookup the first and last word from dictionary?
+  public void testYabottai() throws Exception {
+    assertAnalyzesTo(analyzer, "???????",
+                     new String[] {"???????"});
+  }
+
+  public void testTsukitosha() throws Exception {
+    assertAnalyzesTo(analyzer, "???????",
+                     new String[] {"???????"});
+  }
+
+  public void testBocchan() throws Exception {
+    doTestBocchan(1);
+  }
+
+  @Nightly
+  public void testBocchanBig() throws Exception {
+    doTestBocchan(100);
+  }
+
+  /*
+  public void testWikipedia() throws Exception {
+    final FileInputStream fis = new FileInputStream("/q/lucene/jawiki-20120220-pages-articles.xml");
+    final Reader r = new BufferedReader(new InputStreamReader(fis, "UTF-8"));
+
+    final long startTimeNS = System.nanoTime();
+    boolean done = false;
+    long compoundCount = 0;
+    long nonCompoundCount = 0;
+    long netOffset = 0;
+    while (!done) {
+      final TokenStream ts = analyzer.tokenStream("ignored", r);
+      ts.reset();
+      final PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);
+      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
+      int count = 0;
+      while (true) {
+        if (!ts.incrementToken()) {
+          done = true;
+          break;
+        }
+        count++;
+        if (posIncAtt.getPositionIncrement() == 0) {
+          compoundCount++;
+        } else {
+          nonCompoundCount++;
+          if (nonCompoundCount % 1000000 == 0) {
+            System.out.println(String.format("%.2f msec [pos=%d, %d, %d]",
+                                             (System.nanoTime()-startTimeNS)/1000000.0,
+                                             netOffset + offsetAtt.startOffset(),
+                                             nonCompoundCount,
+                                             compoundCount));
+          }
+        }
+        if (count == 100000000) {
+          System.out.println("  again...");
+          break;
+        }
+      }
+      ts.end();
+      netOffset += offsetAtt.endOffset();
+    }
+    System.out.println("compoundCount=" + compoundCount + " nonCompoundCount=" + nonCompoundCount);
+    r.close();
+  }
+  */
+
+  
+  private void doTestBocchan(int numIterations) throws Exception {
+    LineNumberReader reader = new LineNumberReader(new InputStreamReader(
+        this.getClass().getResourceAsStream("bocchan.utf-8")));
+    String line = reader.readLine();
+    reader.close();
+    
+    if (VERBOSE) {
+      System.out.println("Test for Bocchan without pre-splitting sentences");
+    }
+
+    /*
+    if (numIterations > 1) {
+      // warmup
+      for (int i = 0; i < numIterations; i++) {
+        final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(line));
+        ts.reset();
+        while(ts.incrementToken());
+      }
+    }
+    */
+
+    long totalStart = System.currentTimeMillis();
+    for (int i = 0; i < numIterations; i++) {
+      final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(line));
+      ts.reset();
+      while(ts.incrementToken());
+    }
+    String[] sentences = line.split("????");
+    if (VERBOSE) {
+      System.out.println("Total time : " + (System.currentTimeMillis() - totalStart));
+      System.out.println("Test for Bocchan with pre-splitting sentences (" + sentences.length + " sentences)");
+    }
+    totalStart = System.currentTimeMillis();
+    for (int i = 0; i < numIterations; i++) {
+      for (String sentence: sentences) {
+        final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(sentence));
+        ts.reset();
+        while(ts.incrementToken());
+      }
+    }
+    if (VERBOSE) {
+      System.out.println("Total time : " + (System.currentTimeMillis() - totalStart));
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java
new file mode 100644
index 0000000..547c9ee
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestSearchMode.java
@@ -0,0 +1,82 @@
+package org.apache.lucene.analysis.ja;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.LineNumberReader;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.util.IOUtils;
+
+public class TestSearchMode extends BaseTokenStreamTestCase {
+  private final static String SEGMENTATION_FILENAME = "search-segmentation-tests.txt";
+  private final Analyzer analyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new JapaneseTokenizer(reader, null, true, Mode.SEARCH);
+      return new TokenStreamComponents(tokenizer, tokenizer);
+    }
+  };
+
+  /** Test search mode segmentation */
+  public void testSearchSegmentation() throws IOException {
+    InputStream is = TestSearchMode.class.getResourceAsStream(SEGMENTATION_FILENAME);
+    if (is == null) {
+      throw new FileNotFoundException("Cannot find " + SEGMENTATION_FILENAME + " in test classpath");
+    }
+    try {
+      LineNumberReader reader = new LineNumberReader(new InputStreamReader(is, IOUtils.CHARSET_UTF_8));
+      String line = null;
+      while ((line = reader.readLine()) != null) {
+        // Remove comments
+        line = line.replaceAll("#.*$", "");
+        // Skip empty lines or comment lines
+        if (line.trim().isEmpty()) {
+          continue;
+        }
+        if (VERBOSE) {
+          System.out.println("Line no. " + reader.getLineNumber() + ": " + line);
+        }
+        String[] fields = line.split("\t", 2);
+        String sourceText = fields[0];
+        String[] expectedTokens = fields[1].split("\\s+");
+        int[] expectedPosIncrs = new int[expectedTokens.length];
+        int[] expectedPosLengths = new int[expectedTokens.length];
+        for(int tokIDX=0;tokIDX<expectedTokens.length;tokIDX++) {
+          if (expectedTokens[tokIDX].endsWith("/0")) {
+            expectedTokens[tokIDX] = expectedTokens[tokIDX].replace("/0", "");
+            expectedPosLengths[tokIDX] = expectedTokens.length-1;
+          } else {
+            expectedPosIncrs[tokIDX] = 1;
+            expectedPosLengths[tokIDX] = 1;
+          }
+        }
+        assertAnalyzesTo(analyzer, sourceText, expectedTokens, expectedPosIncrs);
+      }
+    } finally {
+      is.close();
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/bocchan.utf-8 b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/bocchan.utf-8
new file mode 100644
index 0000000..a4c7ea3
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/bocchan.utf-8
@@ -0,0 +1 @@
+????????????-------------------------------------------------------??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????-------------------------------------------------------??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? might is right ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? am glad to see you ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????1992???4?1??20??1???????????????????2????????????????????1987????62?10??27??1??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????5-86????????????????????????????????????1999?9??13????2004?2??27???????????????????????????????????????????http://www.aozora.gr.jp/????????????????????????????????????????????????????
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/TestTokenInfoDictionary.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/TestTokenInfoDictionary.java
new file mode 100644
index 0000000..48dec61
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/TestTokenInfoDictionary.java
@@ -0,0 +1,107 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.util.ToStringUtil;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.UnicodeUtil;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.IntsRefFSTEnum;
+import org.apache.lucene.util.fst.IntsRefFSTEnum.InputOutput;
+
+public class TestTokenInfoDictionary extends LuceneTestCase {
+
+  /** enumerates the entire FST/lookup data and just does basic sanity checks */
+  public void testEnumerateAll() throws Exception {
+    // just for debugging
+    int numTerms = 0;
+    int numWords = 0;
+    int lastWordId = -1;
+    int lastSourceId = -1;
+    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();
+    ConnectionCosts matrix = ConnectionCosts.getInstance();
+    FST<Long> fst = tid.getFST().getInternalFST();
+    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<Long>(fst);
+    InputOutput<Long> mapping;
+    IntsRef scratch = new IntsRef();
+    while ((mapping = fstEnum.next()) != null) {
+      numTerms++;
+      IntsRef input = mapping.input;
+      char chars[] = new char[input.length];
+      for (int i = 0; i < chars.length; i++) {
+        chars[i] = (char)input.ints[input.offset+i];
+      }
+      assertTrue(UnicodeUtil.validUTF16String(new String(chars)));
+      
+      Long output = mapping.output;
+      int sourceId = output.intValue();
+      // we walk in order, terms, sourceIds, and wordIds should always be increasing
+      assertTrue(sourceId > lastSourceId);
+      lastSourceId = sourceId;
+      tid.lookupWordIds(sourceId, scratch);
+      for (int i = 0; i < scratch.length; i++) {
+        numWords++;
+        int wordId = scratch.ints[scratch.offset+i];
+        assertTrue(wordId > lastWordId);
+        lastWordId = wordId;
+         
+        String baseForm = tid.getBaseForm(wordId, chars, 0, chars.length);
+        assertTrue(baseForm == null || UnicodeUtil.validUTF16String(baseForm));
+        
+        String inflectionForm = tid.getInflectionForm(wordId);
+        assertTrue(inflectionForm == null || UnicodeUtil.validUTF16String(inflectionForm));
+        if (inflectionForm != null) {
+          // check that its actually an ipadic inflection form
+          assertNotNull(ToStringUtil.getInflectedFormTranslation(inflectionForm));          
+        }
+        
+        String inflectionType = tid.getInflectionType(wordId);
+        assertTrue(inflectionType == null || UnicodeUtil.validUTF16String(inflectionType));
+        if (inflectionType != null) {
+          // check that its actually an ipadic inflection type
+          assertNotNull(ToStringUtil.getInflectionTypeTranslation(inflectionType));
+        }
+        
+        int leftId = tid.getLeftId(wordId);
+        int rightId = tid.getRightId(wordId);
+        
+        matrix.get(rightId, leftId);
+        
+        tid.getWordCost(wordId);
+        
+        String pos = tid.getPartOfSpeech(wordId);
+        assertNotNull(pos);
+        assertTrue(UnicodeUtil.validUTF16String(pos));
+        // check that its actually an ipadic pos tag
+        assertNotNull(ToStringUtil.getPOSTranslation(pos));
+        
+        String pronunciation = tid.getPronunciation(wordId, chars, 0, chars.length);
+        assertNotNull(pronunciation);
+        assertTrue(UnicodeUtil.validUTF16String(pronunciation));
+        
+        String reading = tid.getReading(wordId, chars, 0, chars.length);
+        assertNotNull(reading);
+        assertTrue(UnicodeUtil.validUTF16String(reading));
+      }
+    }
+    if (VERBOSE) {
+      System.out.println("checked " + numTerms + " terms, " + numWords + " words.");
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/UserDictionaryTest.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/UserDictionaryTest.java
new file mode 100644
index 0000000..bfd4ebc
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/dict/UserDictionaryTest.java
@@ -0,0 +1,80 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.ja.TestJapaneseTokenizer;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Test;
+
+public class UserDictionaryTest extends LuceneTestCase {
+
+  @Test
+  public void testLookup() throws IOException {
+    UserDictionary dictionary = TestJapaneseTokenizer.readDict();
+    String s = "????????";
+    int[][] dictionaryEntryResult = dictionary.lookup(s.toCharArray(), 0, s.length());
+    // Length should be three ?, ??, 
+    assertEquals(3, dictionaryEntryResult.length);
+    
+    // Test positions
+    assertEquals(0, dictionaryEntryResult[0][1]); // index of ?
+    assertEquals(2, dictionaryEntryResult[1][1]); // index of ??
+    assertEquals(4, dictionaryEntryResult[2][1]); // index of 
+    
+    // Test lengths
+    assertEquals(2, dictionaryEntryResult[0][2]); // length of ?
+    assertEquals(2, dictionaryEntryResult[1][2]); // length of ??
+    assertEquals(2, dictionaryEntryResult[2][2]); // length of 
+    
+    s = "??????????????";
+    int[][] dictionaryEntryResult2 = dictionary.lookup(s.toCharArray(), 0, s.length());
+    // Length should be six 
+    assertEquals(6, dictionaryEntryResult2.length);
+  }
+  
+  @Test
+  public void testReadings() throws IOException {
+    UserDictionary dictionary = TestJapaneseTokenizer.readDict();
+    int[][] result = dictionary.lookup("??????".toCharArray(), 0, 6);
+    assertEquals(3, result.length);
+    int wordIdNihon = result[0][0]; // wordId of ?? in ??????
+    assertEquals("?????", dictionary.getReading(wordIdNihon, "??".toCharArray(), 0, 2));
+    
+    result = dictionary.lookup("????".toCharArray(), 0, 3);
+    assertEquals(1, result.length);
+    int wordIdAsashoryu = result[0][0]; // wordId for ????
+    assertEquals("??????????", dictionary.getReading(wordIdAsashoryu, "????".toCharArray(), 0, 3));
+  }
+  
+  @Test
+  public void testPartOfSpeech() throws IOException {
+    UserDictionary dictionary = TestJapaneseTokenizer.readDict();
+    int[][] result = dictionary.lookup("??????".toCharArray(), 0, 6);
+    assertEquals(3, result.length);
+    int wordIdKeizai = result[1][0]; // wordId of ?? in ??????
+    assertEquals("????????", dictionary.getPartOfSpeech(wordIdKeizai));
+  }
+  
+  @Test
+  public void testRead() throws IOException {
+    UserDictionary dictionary = TestJapaneseTokenizer.readDict();
+    assertNotNull(dictionary);		
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/search-segmentation-tests.txt b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/search-segmentation-tests.txt
new file mode 100644
index 0000000..835446f
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/search-segmentation-tests.txt
@@ -0,0 +1,142 @@
+###
+### Tests for Kuromoji's search mode heuristic
+###
+### In search-mode, Kuromoji uses a heuristic to do extra splitting of words
+### to get a decompounding effect useful for search.  This file includes tests
+### for this heuristic and demonstrates its usefulness, but also weaknesses.
+###
+### This file's format is as follows:
+###	  <text><tab><token1> <token2> ... <token>
+###
+### This file should use UTF-8 encoding and there is one test per line.  The
+### text to be segmented and its expected surface form token sequence is 
+### separated by a tab ('\t').  Tokens are  separated by a half-width space.
+### Whitespace lines and lines starting with a '#' are ignored.  Comments
+### are not allowed on entry line.
+###
+### NOTE: These tests depends on IPADIC
+###
+### Revision history:
+###  - 2012-01-29: Initial version
+###
+
+##
+## Organizations
+##
+
+# Kansai Internationl Airport
+???	? ???/0 ?? 
+# Narita Airport
+???	??? ???/0 
+# Haneda Airport
+?	? ?/0 
+# Nara Institute of Science and Technology
+?????????????	?? ?????????????/0 ??? ?? ??? ??? ?
+# Tokyo University
+??	? ??/0 ?
+# Kyoto University
+???	?? ???/0 ?
+
+# NOTE: differs from non-compound mode:
+# Kyoto University Baseball Club
+??????????	??? ? ?? ??? ??
+
+##
+## Katakana titles
+##
+
+# Senior Software Engineer
+???????????????????	???? ???????????????????/0 ??????? ??????
+# Software Engineer
+?????????????	??????? ??????
+# Senior Project Manager
+??????????????????	???? ??????????????????/0 ???????? ???????
+# Project Manager
+???????????????	???????? ???????
+# Senior Sales Engineer
+??????????????	???? ??????????????/0 ????? ??????
+# System Architect
+??????????????	????? ??????????????/0 ?????????
+# Senior System Architect
+?????????????????	???? ?????????????????/0 ????? ?????????
+# System Administrator
+??????????????????	????? ?????????????
+??????????????????	????? ??????????????????/0 ?????????????
+# Senior System Administrator
+???????????????????????	???? ???????????????????????/0 ????? ?????????????
+
+##
+## Company names (several are fictitious)
+##
+
+# SoftBank Mobile
+????????????	??????? ?????
+# Alpine Materials
+????????????????	???????? ????????????????/0 ?????????
+# Sapporo Holdings
+???????????????	????? ??????????
+# Yamada Corporation
+?????????????	???? ?????????????/0 ?????????
+# Canon Semiconductor equipement	NOTE: Semiconductor becomes semi + conductor
+???????????????????????????	?????? ???????????????????????????/0 ?? ????????? ?????????
+# Orental Chain
+????????????	??????? ????????????/0 ?????
+# Ally Projects Japan	NOTE: Becomes one token as ???????? is not in IPADIC
+???????????????????	???????????????????
+# Peter Pan Corporation
+?????????????????	????? ?????????????????/0 ??? ?????????
+# AIM Create
+??????????	??????????
+# Mars Engineering
+???????????????	????? ???????????????/0 ?????????
+# Fuji Protein Technology
+???????????????????	??? ???????????????????/0 ???????? ????????
+
+##
+## Person names
+##
+
+# Michael Jackson
+????????????	????? ???????
+# Steve Jobs
+???????????	?????? ?????
+# Harry Potter	NOTE: Becomes one token (short word)
+??????????	??????????
+# Bill Gates	NOTE: Becomes one token (short word)
+???????	???????
+# Sean Connery	NOTE: Becomes one token (okay)
+?????????	?????????
+
+##
+## Other nouns
+##
+
+# Holdings
+??????????	??????????
+# Engineering
+?????????	?????????
+# Software Engineering
+????????????????	??????? ?????????
+# Shopping center
+???????????	??????? ????
+# Game center (arcade)	NOTE: One token because of short word
+?????????	?????????
+# Christmas shopping
+??????????????	??????? ???????
+# Download file
+???????????????	?????????? ?????
+# Technology
+????????	????????
+# Lillehammer Olympics
+????????????????	???????? ????????
+
+##
+## Problematic terms
+##
+
+# JT Engineering	NOTE: Becomes J Tien ginia ring (substrings are in IPADIC)
+????????????????	???? ????????????????/0 ????? ???? ?????
+# Anchovy pasta	NOTE: Become Anch yvipasta
+???????????	????? ???????????/0 ???????
+# Surprise gift	NOTE: Becomes one token (surprise not in IPADIC)
+?????????	?????????
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/userdict.txt b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/userdict.txt
new file mode 100644
index 0000000..f9db02c
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/userdict.txt
@@ -0,0 +1,10 @@
+# Custom segmentation for long entries
+??????,?? ?? ??,????? ???? ?????,????????
+???,? ?? ,????? ???? ?????,???????
+
+# Custom reading for sumo wrestler
+????,????,??????????,??????
+
+# Silly entry:
+abcd,a b cd,foo1 foo2 foo3,bar
+abcdefg,ab cd efg,foo1 foo2 foo4,bar
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/util/TestToStringUtil.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/util/TestToStringUtil.java
new file mode 100644
index 0000000..f95a527
--- /dev/null
+++ b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/util/TestToStringUtil.java
@@ -0,0 +1,34 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestToStringUtil extends LuceneTestCase {
+  public void testPOS() {
+    assertEquals("noun-suffix-verbal", ToStringUtil.getPOSTranslation("???-?-????"));
+  }
+  
+  public void testHepburn() {
+    assertEquals("majan", ToStringUtil.getRomanization("???????"));
+    assertEquals("uroncha", ToStringUtil.getRomanization("?????????"));
+    assertEquals("chahan", ToStringUtil.getRomanization("???????"));
+    assertEquals("chashu", ToStringUtil.getRomanization("???????"));
+    assertEquals("shumai", ToStringUtil.getRomanization("??????"));
+  }
+}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestExtendedMode.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestExtendedMode.java
deleted file mode 100644
index 32cf2de..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestExtendedMode.java
+++ /dev/null
@@ -1,72 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
-
-public class TestExtendedMode extends BaseTokenStreamTestCase {
-  private final Analyzer analyzer = new Analyzer() {
-    
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, null, true, Mode.EXTENDED);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-  
-  /** simple test for supplementary characters */
-  public void testSurrogates() throws IOException {
-    assertAnalyzesTo(analyzer, "???????",
-      new String[] { "?", "??", "??", "??", "??", "??" });
-  }
-  
-  /** random test ensuring we don't ever split supplementaries */
-  public void testSurrogates2() throws IOException {
-    int numIterations = atLeast(10000);
-    for (int i = 0; i < numIterations; i++) {
-      String s = _TestUtil.randomUnicodeString(random, 100);
-      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
-      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
-      ts.reset();
-      while (ts.incrementToken()) {
-        assertTrue(UnicodeUtil.validUTF16String(termAtt));
-      }
-    }
-  }
-  
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
-  }
-  
-  /** blast some random large strings through the analyzer */
-  public void testRandomHugeStrings() throws Exception {
-    checkRandomData(random, analyzer, 200*RANDOM_MULTIPLIER, 8192);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiAnalyzer.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiAnalyzer.java
deleted file mode 100644
index c945477..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiAnalyzer.java
+++ /dev/null
@@ -1,186 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-
-/**
- * Test Kuromoji Japanese morphological analyzer
- */
-public class TestKuromojiAnalyzer extends BaseTokenStreamTestCase {
-  /** This test fails with NPE when the 
-   * stopwords file is missing in classpath */
-  public void testResourcesAvailable() {
-    new KuromojiAnalyzer(TEST_VERSION_CURRENT);
-  }
-  
-  /**
-   * An example sentence, test removal of particles, etc by POS,
-   * lemmatization with the basic form, and that position increments
-   * and offsets are correct.
-   */
-  public void testBasics() throws IOException {
-    assertAnalyzesTo(new KuromojiAnalyzer(TEST_VERSION_CURRENT), "?????????????????",
-        new String[] { "??", "??", "??", "????" },
-        new int[] { 0, 3, 6,  9 },
-        new int[] { 2, 5, 8, 11 },
-        new int[] { 1, 2, 2,  2 }
-      );
-  }
-
-  /**
-   * Test that search mode is enabled and working by default
-   */
-  public void testDecomposition() throws IOException {
-
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-
-    // Senior software engineer:
-    assertAnalyzesToPositions(a, "???????????????????",
-                              new String[] { "????",
-                                             "???????????????????", // zero pos inc
-                                             "???????",
-                                             "??????" },
-                              new int[] { 1, 0, 1, 1},
-                              new int[] { 1, 3, 1, 1}
-                              );
-
-    // Senior project manager: also tests katakana spelling variation stemming
-    assertAnalyzesToPositions(a, "????????????????????",
-                              new String[] { "????",
-                                              "??????????????????", // trailing ?? removed by stemming, zero pos inc
-                                              "????????",
-                                              "???????"}, // trailing ?? removed by stemming
-                              new int[]{1, 0, 1, 1},
-                              new int[]{1, 3, 1, 1}
-                              );
-
-    // Kansai International Airport:
-    assertAnalyzesToPositions(a, "???",
-                              new String[] { "?",
-                                             "???", // zero pos inc
-                                             "??",
-                                             "" },
-                              new int[] {1, 0, 1, 1},
-                              new int[] {1, 3, 1, 1}
-                              );
-
-    // Konika Minolta Holdings; not quite the right
-    // segmentation (see LUCENE-3726):
-    assertAnalyzesToPositions(a, "???????????????????",
-                              new String[] { "????",
-                                             "???????????????????", // zero pos inc
-                                             "??????", 
-                                             "??????????"},
-                              new int[] {1, 0, 1, 1},
-                              new int[] {1, 3, 1, 1}
-                              );
-
-    // Narita Airport
-    assertAnalyzesToPositions(a, "???",
-                              new String[] { "???",
-                                             "???",
-                                             "" },
-                              new int[] {1, 0, 1},
-                              new int[] {1, 2, 1}
-                              );
-
-    // Kyoto University Baseball Club
-    assertAnalyzesToPositions(new KuromojiAnalyzer(TEST_VERSION_CURRENT), "??????????",
-                     new String[] { "???",
-                                    "?",
-                                    "??",
-                                    "???",
-                                    "??" },
-                              new int[] {1, 1, 1, 1, 1},
-                              new int[] {1, 1, 1, 1, 1});
-    // toDotFile(a, "???", "/mnt/scratch/out.dot");
-  }
-
-  
-  /**
-   * blast random strings against the analyzer
-   */
-  public void testRandom() throws IOException {
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-    checkRandomData(random, a, atLeast(10000));
-  }
-  
-  /** blast some random large strings through the analyzer */
-  public void testRandomHugeStrings() throws Exception {
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-        KuromojiAnalyzer.getDefaultStopSet(),
-        KuromojiAnalyzer.getDefaultStopTags());
-    checkRandomData(random, a, 200*RANDOM_MULTIPLIER, 8192);
-  }
-
-  // Copied from TestKuromojiTokenizer, to make sure passing
-  // user dict to analyzer works:
-  public void testUserDict3() throws Exception {
-    // Test entry that breaks into multiple tokens:
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, TestKuromojiTokenizer.readDict(),
-                                            Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-    assertTokenStreamContents(a.tokenStream("foo", new StringReader("abcd")),
-                              new String[] { "a", "b", "cd"  },
-                              new int[] { 0, 1, 2 },
-                              new int[] { 1, 2, 4 },
-                              new Integer(4)
-    );
-  }
-
-  // LUCENE-3897: this string (found by running all jawiki
-  // XML through KuromojiAnalyzer) caused AIOOBE
-  public void testCuriousString() throws Exception {
-    final String s = "&lt;li&gt;06:26 2004?3??21?? [[????:Kzhr|Kzhr]] &quot;??????&quot; ????????? &lt;em&gt;&lt;nowiki&gt;(?????: ???????: &amp;#39;???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????&amp;#39;)&lt;/nowiki&gt;&lt;/em&gt;&lt;/li&gt;";
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
-  }
-
-  // LUCENE-3897: this string (found by
-  // testHugeRandomStrings) tripped assert
-  public void testAnotherCuriousString() throws Exception {
-    final String s = "???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????";
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
-  }
-
-  // LUCENE-3897: this string (found by
-  // testHugeRandomStrings) tripped assert
-  public void testYetAnotherCuriousString() throws Exception {
-    final String s = "????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????";
-    final Analyzer a = new KuromojiAnalyzer(TEST_VERSION_CURRENT, null, Mode.SEARCH,
-                                            KuromojiAnalyzer.getDefaultStopSet(),
-                                            KuromojiAnalyzer.getDefaultStopTags());
-    checkAnalysisConsistency(random, a, random.nextBoolean(), s);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiBaseFormFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiBaseFormFilter.java
deleted file mode 100644
index 91d1942..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiBaseFormFilter.java
+++ /dev/null
@@ -1,62 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.io.Reader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-
-public class TestKuromojiBaseFormFilter extends BaseTokenStreamTestCase {
-  private Analyzer analyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, null, true, KuromojiTokenizer.DEFAULT_MODE);
-      return new TokenStreamComponents(tokenizer, new KuromojiBaseFormFilter(tokenizer));
-    }
-  };
-  
-  public void testBasics() throws IOException {
-    assertAnalyzesTo(analyzer, "???????????????????",
-        new String[] { "???", "??", "??", "??", "?", "??", "???", "??"  }
-    );
-  }
-  
-  public void testEnglish() throws IOException {
-    assertAnalyzesTo(analyzer, "this atest",
-        new String[] { "this", "atest" });
-  }
-  
-  public void testRandomStrings() throws IOException {
-    checkRandomData(random, analyzer, atLeast(10000));
-  }
-  
-  public void testEmptyTerm() throws IOException {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        Tokenizer tokenizer = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(tokenizer, new KuromojiBaseFormFilter(tokenizer));
-      }
-    };
-    checkOneTermReuse(a, "", "");
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiKatakanaStemFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiKatakanaStemFilter.java
deleted file mode 100644
index c61542c..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiKatakanaStemFilter.java
+++ /dev/null
@@ -1,83 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.MockTokenizer;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-
-import java.io.IOException;
-import java.io.Reader;
-
-/**
- * Tests for {@link org.apache.lucene.analysis.kuromoji.KuromojiKatakanaStemFilter}
- */
-public class TestKuromojiKatakanaStemFilter extends BaseTokenStreamTestCase {
-  private Analyzer analyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      // Use a MockTokenizer here since this filter doesn't really depend on Kuromoji
-      Tokenizer source = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
-      return new TokenStreamComponents(source, new KuromojiKatakanaStemFilter(source));
-    }
-  };
-  
-  /**
-   * Test a few common katakana spelling variations.
-   * <p>
-   * English translations are as follows:
-   * <ul>
-   *   <li>copy</li>
-   *   <li>coffee</li>
-   *   <li>taxi</li>
-   *   <li>party</li>
-   *   <li>party (without long sound)</li>
-   *   <li>center</li>
-   * </ul>
-   * Note that we remove a long sound in the case of "coffee" that is required.
-   * </p>
-   */
-  public void testStemVariants() throws IOException {
-    assertAnalyzesTo(analyzer, "???? ????? ???? ???????? ?????? ????",
-      new String[] { "????",  "????", "????", "??????", "??????", "????" },
-      new int[] { 0, 4,  9, 14, 20, 25 },
-      new int[] { 3, 8, 13, 19, 24, 29 });
-  }
-
-  public void testUnsupportedHalfWidthVariants() throws IOException {
-    // The below result is expected since only full-width katakana is supported
-    assertAnalyzesTo(analyzer, "??", new String[] { "??" });
-  }
-  
-  public void testRandomData() throws IOException {
-    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
-  }
-  
-  public void testEmptyTerm() throws IOException {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        Tokenizer tokenizer = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(tokenizer, new KuromojiKatakanaStemFilter(tokenizer));
-      }
-    };
-    checkOneTermReuse(a, "", "");
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiReadingFormFilter.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiReadingFormFilter.java
deleted file mode 100644
index 32b0432..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiReadingFormFilter.java
+++ /dev/null
@@ -1,76 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.core.KeywordTokenizer;
-
-import java.io.IOException;
-import java.io.Reader;
-
-/**
- * Tests for {@link TestKuromojiReadingFormFilter}
- */
-public class TestKuromojiReadingFormFilter extends BaseTokenStreamTestCase {
-  private Analyzer katakanaAnalyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, null, true, KuromojiTokenizer.Mode.SEARCH);
-      return new TokenStreamComponents(tokenizer, new KuromojiReadingFormFilter(tokenizer, false));
-    }
-  };
-
-  private Analyzer romajiAnalyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, null, true, KuromojiTokenizer.Mode.SEARCH);
-      return new TokenStreamComponents(tokenizer, new KuromojiReadingFormFilter(tokenizer, true));
-    }
-  };
-
-
-  public void testKatakanaReadings() throws IOException {
-    assertAnalyzesTo(katakanaAnalyzer, "?????????????????",
-        new String[] { "????", "??", "?????", "????", "??", "?????", "??" }
-    );
-  }
-
-  public void testRomajiReadings() throws IOException {
-    assertAnalyzesTo(romajiAnalyzer, "?????????????????",
-        new String[] { "kon'ya", "ha", "robato", "sensei", "to", "hanashi", "ta" }
-    );
-  }
-
-  public void testRandomData() throws IOException {
-    checkRandomData(random, katakanaAnalyzer, 1000*RANDOM_MULTIPLIER);
-    checkRandomData(random, romajiAnalyzer, 1000*RANDOM_MULTIPLIER);
-  }
-  
-  public void testEmptyTerm() throws IOException {
-    Analyzer a = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        Tokenizer tokenizer = new KeywordTokenizer(reader);
-        return new TokenStreamComponents(tokenizer, new KuromojiReadingFormFilter(tokenizer));
-      }
-    };
-    checkOneTermReuse(a, "", "");
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiTokenizer.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiTokenizer.java
deleted file mode 100644
index 8a4fd56..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestKuromojiTokenizer.java
+++ /dev/null
@@ -1,638 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedReader;
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.LineNumberReader;
-import java.io.PrintWriter;
-import java.io.Reader;
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-import org.apache.lucene.analysis.kuromoji.dict.ConnectionCosts;
-import org.apache.lucene.analysis.kuromoji.dict.UserDictionary;
-import org.apache.lucene.analysis.kuromoji.tokenattributes.*;
-import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
-import org.apache.lucene.analysis.tokenattributes.OffsetAttribute;
-import org.apache.lucene.analysis.tokenattributes.PositionIncrementAttribute;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util._TestUtil;
-import org.junit.Ignore;
-
-public class TestKuromojiTokenizer extends BaseTokenStreamTestCase {
-
-  public static UserDictionary readDict() {
-    InputStream is = TestKuromojiTokenizer.class.getResourceAsStream("userdict.txt");
-    if (is == null) {
-      throw new RuntimeException("Cannot find userdict.txt in test classpath!");
-    }
-    try {
-      try {
-        Reader reader = new InputStreamReader(is, IOUtils.CHARSET_UTF_8);
-        return new UserDictionary(reader);
-      } finally {
-        is.close();
-      }
-    } catch (IOException ioe) {
-      throw new RuntimeException(ioe);
-    }
-  }
-
-  private Analyzer analyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, readDict(), false, Mode.SEARCH);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-
-  private Analyzer analyzerNormal = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, readDict(), false, Mode.NORMAL);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-
-  private Analyzer analyzerNoPunct = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, readDict(), true, Mode.SEARCH);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-
-  private Analyzer extendedModeAnalyzerNoPunct = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, readDict(), true, Mode.EXTENDED);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-
-  public void testNormalMode() throws Exception {
-    assertAnalyzesTo(analyzerNormal,
-                     "???????????????????",
-                     new String[] {"???????????????????"});
-  }
-
-  public void testDecomposition1() throws Exception {
-    assertAnalyzesTo(analyzerNoPunct, "?????????????????????????????????????????????" +
-                         "???????????????????????????????????????????????????????",
-     new String[] { "???", "??",  "?", "?", "??", "??", "??", "??", "??", "??", "??", "??",      
-                    "???", "???", "???", "??", "?", "??", "??", "??", "?", "??", "???",  "??????", 
-                    "?", "???", "??", "??", "??", "?", "??",  "??", "??", "??",  "???",
-                    "??", "??", "?", "?", "???", "?", "??", "??", "??", "???", "??", "???" },
-     new int[] { 0, 2, 4, 6, 7,  8, 10, 11, 13, 14, 16, 18, 19, 21, 23, 25, 26, 28, 29, 30, 
-                 31, 33, 34, 37, 41, 42, 44, 45, 47, 49, 51, 53, 55, 56, 58, 60,
-                 62, 63, 64, 65, 67, 68, 69, 71, 72, 75, 76 },
-     new int[] { 2, 3, 6, 7, 8, 10, 11, 13, 14, 16, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31,
-                 33, 34, 36, 41, 42, 44, 45, 47, 49, 51, 52, 55, 56, 57, 60, 62,
-                 63, 64, 65, 67, 68, 69, 71, 72, 75, 76, 78 }
-    );
-  }
-  
-  public void testDecomposition2() throws Exception {
-    assertAnalyzesTo(analyzerNoPunct, "????????????????????????",
-      new String[] { "?", "??", "?", "??", "?????", "???", "?????", "??", "???", "???" },
-      new int[] { 0, 2, 3, 5, 6,  10, 13, 16, 17, 19 },
-      new int[] { 2, 3, 5, 6, 10, 13, 16, 17, 19, 21 }
-    );
-  }
-  
-  public void testDecomposition3() throws Exception {
-    assertAnalyzesTo(analyzerNoPunct, "?????????????????",
-      new String[] { "?", "??", "?", "?????",  "????????" },
-      new int[] { 0, 2, 3, 5, 10 },
-      new int[] { 2, 3, 5, 9, 15 }
-    );
-  }
-
-  public void testDecomposition4() throws Exception {
-    assertAnalyzesTo(analyzer, "???????????",
-      new String[] { "???", "??", "??", "??", "??", "???" },
-      new int[] { 0, 2, 3, 4, 5, 6 },
-      new int[] { 2, 3, 4, 5, 6, 8 }
-    );
-  }
-
-  /* Note this is really a stupid test just to see if things arent horribly slow.
-   * ideally the test would actually fail instead of hanging...
-   */
-  public void testDecomposition5() throws Exception {
-    TokenStream ts = analyzer.tokenStream("bogus", new StringReader("????????????????????????????????????????????????????????????"));
-    ts.reset();
-    while (ts.incrementToken()) {
-      
-    }
-    ts.end();
-    ts.close();
-  }
-
-  /*
-    // NOTE: intentionally fails!  Just trying to debug this
-    // one input...
-  public void testDecomposition6() throws Exception {
-    assertAnalyzesTo(analyzer, "?????????????",
-      new String[] { "???", "??", "??", "??", "??", "???" },
-      new int[] { 0, 2, 3, 4, 5, 6 },
-      new int[] { 2, 3, 4, 5, 6, 8 }
-                     );
-  }
-  */
-
-  /** Tests that sentence offset is incorporated into the resulting offsets */
-  public void testTwoSentences() throws Exception {
-    /*
-    //TokenStream ts = a.tokenStream("foo", new StringReader("???????????????????????"));
-    TokenStream ts = analyzer.tokenStream("foo", new StringReader("&#x250cdf66<!--\"<!--#<!--;?><!--#<!--#><!---->?>-->;"));
-    ts.reset();
-    CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
-    while(ts.incrementToken()) {
-      System.out.println("  " + termAtt.toString());
-    }
-    System.out.println("DONE PARSE\n\n");
-    */
-
-    assertAnalyzesTo(analyzerNoPunct, "????????????????? ?????????????????",
-      new String[] { "?", "??", "?", "?????", "????????",  "?", "??", "?", "?????",  "????????"  },
-      new int[] { 0, 2, 3, 5, 10, 17, 19, 20, 22, 27 },
-      new int[] { 2, 3, 5, 9, 15, 19, 20, 22, 26, 32 }
-    );
-  }
-
-  /** blast some random strings through the analyzer */
-  public void testRandomStrings() throws Exception {
-    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
-    checkRandomData(random, analyzerNoPunct, 10000*RANDOM_MULTIPLIER);
-  }
-  
-  /** blast some random large strings through the analyzer */
-  public void testRandomHugeStrings() throws Exception {
-    checkRandomData(random, analyzer, 200*RANDOM_MULTIPLIER, 8192);
-    checkRandomData(random, analyzerNoPunct, 200*RANDOM_MULTIPLIER, 8192);
-  }
-  
-  public void testLargeDocReliability() throws Exception {
-    for (int i = 0; i < 100; i++) {
-      String s = _TestUtil.randomUnicodeString(random, 10000);
-      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
-      ts.reset();
-      while (ts.incrementToken()) {
-      }
-    }
-  }
-  
-  /** simple test for supplementary characters */
-  public void testSurrogates() throws IOException {
-    assertAnalyzesTo(analyzer, "???????",
-      new String[] { "?", "??", "??", "??", "??", "??" });
-  }
-  
-  /** random test ensuring we don't ever split supplementaries */
-  public void testSurrogates2() throws IOException {
-    int numIterations = atLeast(10000);
-    for (int i = 0; i < numIterations; i++) {
-      if (VERBOSE) {
-        System.out.println("\nTEST: iter=" + i);
-      }
-      String s = _TestUtil.randomUnicodeString(random, 100);
-      TokenStream ts = analyzer.tokenStream("foo", new StringReader(s));
-      CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class);
-      ts.reset();
-      while (ts.incrementToken()) {
-        assertTrue(UnicodeUtil.validUTF16String(termAtt));
-      }
-    }
-  }
-
-  public void testOnlyPunctuation() throws IOException {
-    TokenStream ts = analyzerNoPunct.tokenStream("foo", new StringReader("????????"));
-    ts.reset();
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-
-  public void testOnlyPunctuationExtended() throws IOException {
-    TokenStream ts = extendedModeAnalyzerNoPunct.tokenStream("foo", new StringReader("......"));
-    ts.reset();
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-  
-  // note: test is kinda silly since kuromoji emits punctuation tokens.
-  // but, when/if we filter these out it will be useful.
-  public void testEnd() throws Exception {
-    assertTokenStreamContents(analyzerNoPunct.tokenStream("foo", new StringReader("???????????")),
-        new String[] { "???", "??", "??", "??", "??", "???" },
-        new int[] { 0, 2, 3, 4, 5, 6 },
-        new int[] { 2, 3, 4, 5, 6, 8 },
-        new Integer(8)
-    );
-
-    assertTokenStreamContents(analyzerNoPunct.tokenStream("foo", new StringReader("???????????    ")),
-        new String[] { "???", "??", "??", "??", "??", "???"  },
-        new int[] { 0, 2, 3, 4, 5, 6, 8 },
-        new int[] { 2, 3, 4, 5, 6, 8, 9 },
-        new Integer(12)
-    );
-  }
-
-  public void testUserDict() throws Exception {
-    // Not a great test because w/o userdict.txt the
-    // segmentation is the same:
-    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("????????")),
-                              new String[] { "?", "??", "", "??", "??", "??"  },
-                              new int[] { 0, 2, 4, 6, 7, 9 },
-                              new int[] { 2, 4, 6, 7, 9, 10 },
-                              new Integer(10)
-    );
-  }
-
-  public void testUserDict2() throws Exception {
-    // Better test: w/o userdict the segmentation is different:
-    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("????")),
-                              new String[] { "????"  },
-                              new int[] { 0 },
-                              new int[] { 3 },
-                              new Integer(3)
-    );
-  }
-
-  public void testUserDict3() throws Exception {
-    // Test entry that breaks into multiple tokens:
-    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("abcd")),
-                              new String[] { "a", "b", "cd"  },
-                              new int[] { 0, 1, 2 },
-                              new int[] { 1, 2, 4 },
-                              new Integer(4)
-    );
-  }
-
-  // HMM: fails (segments as a/b/cd/efghij)... because the
-  // two paths have exactly equal paths (1 KNOWN + 1
-  // UNKNOWN) and we don't seem to favor longer KNOWN /
-  // shorter UNKNOWN matches:
-
-  /*
-  public void testUserDict4() throws Exception {
-    // Test entry that has another entry as prefix
-    assertTokenStreamContents(analyzer.tokenStream("foo", new StringReader("abcdefghij")),
-                              new String[] { "ab", "cd", "efg", "hij"  },
-                              new int[] { 0, 2, 4, 7 },
-                              new int[] { 2, 4, 7, 10 },
-                              new Integer(10)
-    );
-  }
-  */
-  
-  public void testSegmentation() throws Exception {
-    // Skip tests for Michelle Kwan -- UniDic segments Kwan as ?? ???
-    //		String input = "????????????????????????????????????????????????????";
-    //		String[] surfaceForms = {
-    //				"?????", "??", "?????", "??", "???", "??", "??", "??", "??",
-    //				"????", "??????", "??", "??", "??", "??",
-    //				"?????????", "??"
-    //		};
-    String input = "???????????????????????????????";
-    String[] surfaceForms = {
-        "????", "??????", "??", "??", "??", "??",
-        "?????????", "??"
-    };
-    assertAnalyzesTo(analyzer,
-                     input,
-                     surfaceForms);
-  }
-
-  public void testLatticeToDot() throws Exception {
-    final GraphvizFormatter gv2 = new GraphvizFormatter(ConnectionCosts.getInstance());
-    final Analyzer analyzer = new Analyzer() {
-      @Override
-      protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-        KuromojiTokenizer tokenizer = new KuromojiTokenizer(reader, readDict(), false, Mode.SEARCH);
-        tokenizer.setGraphvizFormatter(gv2);
-        return new TokenStreamComponents(tokenizer, tokenizer);
-      }
-    };
-
-    String input = "???????????????????????????????";
-    String[] surfaceForms = {
-        "????", "??????", "??", "??", "??", "??",
-        "?????????", "??"
-    };
-    assertAnalyzesTo(analyzer,
-                     input,
-                     surfaceForms);
-    
-    assertTrue(gv2.finish().indexOf("22.0") != -1);
-  }
-
-  private void assertReadings(String input, String... readings) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    ReadingAttribute readingAtt = ts.addAttribute(ReadingAttribute.class);
-    ts.reset();
-    for(String reading : readings) {
-      assertTrue(ts.incrementToken());
-      assertEquals(reading, readingAtt.getReading());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-
-  private void assertPronunciations(String input, String... pronunciations) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    ReadingAttribute readingAtt = ts.addAttribute(ReadingAttribute.class);
-    ts.reset();
-    for(String pronunciation : pronunciations) {
-      assertTrue(ts.incrementToken());
-      assertEquals(pronunciation, readingAtt.getPronunciation());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-  
-  private void assertBaseForms(String input, String... baseForms) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    BaseFormAttribute baseFormAtt = ts.addAttribute(BaseFormAttribute.class);
-    ts.reset();
-    for(String baseForm : baseForms) {
-      assertTrue(ts.incrementToken());
-      assertEquals(baseForm, baseFormAtt.getBaseForm());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-
-  private void assertInflectionTypes(String input, String... inflectionTypes) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    InflectionAttribute inflectionAtt = ts.addAttribute(InflectionAttribute.class);
-    ts.reset();
-    for(String inflectionType : inflectionTypes) {
-      assertTrue(ts.incrementToken());
-      assertEquals(inflectionType, inflectionAtt.getInflectionType());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-
-  private void assertInflectionForms(String input, String... inflectionForms) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    InflectionAttribute inflectionAtt = ts.addAttribute(InflectionAttribute.class);
-    ts.reset();
-    for(String inflectionForm : inflectionForms) {
-      assertTrue(ts.incrementToken());
-      assertEquals(inflectionForm, inflectionAtt.getInflectionForm());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-  
-  private void assertPartsOfSpeech(String input, String... partsOfSpeech) throws IOException {
-    TokenStream ts = analyzer.tokenStream("ignored", new StringReader(input));
-    PartOfSpeechAttribute partOfSpeechAtt = ts.addAttribute(PartOfSpeechAttribute.class);
-    ts.reset();
-    for(String partOfSpeech : partsOfSpeech) {
-      assertTrue(ts.incrementToken());
-      assertEquals(partOfSpeech, partOfSpeechAtt.getPartOfSpeech());
-    }
-    assertFalse(ts.incrementToken());
-    ts.end();
-  }
-  
-  public void testReadings() throws Exception {
-    assertReadings("?????????????",
-                   "??",
-                   "??",
-                   "??",
-                   "??",
-                   "???",
-                   "??");
-  }
-  
-  public void testReadings2() throws Exception {
-    assertReadings("?????????????????",
-                   "?????",
-                   "??",
-                   "?????",
-                   "??",
-                   "????",
-                   "??",
-                   "???",
-                   "??",
-                   "??");
-  }
-  
-  public void testPronunciations() throws Exception {
-    assertPronunciations("?????????????",
-                         "??",
-                         "??",
-                         "??",
-                         "??",
-                         "???",
-                         "??");
-  }
-  
-  public void testPronunciations2() throws Exception {
-    // pronunciation differs from reading here
-    assertPronunciations("?????????????????",
-                         "?????",
-                         "??",
-                         "?????",
-                         "??",
-                         "????",
-                         "??",
-                         "???",
-                         "??",
-                         "??");
-  }
-  
-  public void testBasicForms() throws Exception {
-    assertBaseForms("?????????????????????",
-                    null,
-                    null,
-                    null,
-                    null,
-                    null,
-                    null,
-                    "???",
-                    null,
-                    null);
-  }
-  
-  public void testInflectionTypes() throws Exception {
-    assertInflectionTypes("?????????????????????",
-                          null,
-                          null,
-                          null,
-                          null,
-                          null,
-                          null,
-                          "?????",
-                          "??????",
-                          null);
-  }
-  
-  public void testInflectionForms() throws Exception {
-    assertInflectionForms("?????????????????????",
-                          null,
-                          null,
-                          null,
-                          null,
-                          null,
-                          null,
-                          "???",
-                          "???",
-                          null);
-  }
-  
-  public void testPartOfSpeech() throws Exception {
-    assertPartsOfSpeech("?????????????????????",
-                        "???-??-???",
-                        "??-???",
-                        "???-?????",
-                        "???-????",
-                        "???-???",
-                        "??-???-???",
-                        "???-???",
-                        "???",
-                        "??-??");
-  }
-
-  // TODO: the next 2 tests are no longer using the first/last word ids, maybe lookup the words and fix?
-  // do we have a possibility to actually lookup the first and last word from dictionary?
-  public void testYabottai() throws Exception {
-    assertAnalyzesTo(analyzer, "???????",
-                     new String[] {"???????"});
-  }
-
-  public void testTsukitosha() throws Exception {
-    assertAnalyzesTo(analyzer, "???????",
-                     new String[] {"???????"});
-  }
-
-  public void testBocchan() throws Exception {
-    doTestBocchan(1);
-  }
-
-  @Nightly
-  public void testBocchanBig() throws Exception {
-    doTestBocchan(100);
-  }
-
-  /*
-  public void testWikipedia() throws Exception {
-    final FileInputStream fis = new FileInputStream("/q/lucene/jawiki-20120220-pages-articles.xml");
-    final Reader r = new BufferedReader(new InputStreamReader(fis, "UTF-8"));
-
-    final long startTimeNS = System.nanoTime();
-    boolean done = false;
-    long compoundCount = 0;
-    long nonCompoundCount = 0;
-    long netOffset = 0;
-    while (!done) {
-      final TokenStream ts = analyzer.tokenStream("ignored", r);
-      ts.reset();
-      final PositionIncrementAttribute posIncAtt = ts.addAttribute(PositionIncrementAttribute.class);
-      final OffsetAttribute offsetAtt = ts.addAttribute(OffsetAttribute.class);
-      int count = 0;
-      while (true) {
-        if (!ts.incrementToken()) {
-          done = true;
-          break;
-        }
-        count++;
-        if (posIncAtt.getPositionIncrement() == 0) {
-          compoundCount++;
-        } else {
-          nonCompoundCount++;
-          if (nonCompoundCount % 1000000 == 0) {
-            System.out.println(String.format("%.2f msec [pos=%d, %d, %d]",
-                                             (System.nanoTime()-startTimeNS)/1000000.0,
-                                             netOffset + offsetAtt.startOffset(),
-                                             nonCompoundCount,
-                                             compoundCount));
-          }
-        }
-        if (count == 100000000) {
-          System.out.println("  again...");
-          break;
-        }
-      }
-      ts.end();
-      netOffset += offsetAtt.endOffset();
-    }
-    System.out.println("compoundCount=" + compoundCount + " nonCompoundCount=" + nonCompoundCount);
-    r.close();
-  }
-  */
-
-  
-  private void doTestBocchan(int numIterations) throws Exception {
-    LineNumberReader reader = new LineNumberReader(new InputStreamReader(
-        this.getClass().getResourceAsStream("bocchan.utf-8")));
-    String line = reader.readLine();
-    reader.close();
-    
-    if (VERBOSE) {
-      System.out.println("Test for Bocchan without pre-splitting sentences");
-    }
-
-    /*
-    if (numIterations > 1) {
-      // warmup
-      for (int i = 0; i < numIterations; i++) {
-        final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(line));
-        ts.reset();
-        while(ts.incrementToken());
-      }
-    }
-    */
-
-    long totalStart = System.currentTimeMillis();
-    for (int i = 0; i < numIterations; i++) {
-      final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(line));
-      ts.reset();
-      while(ts.incrementToken());
-    }
-    String[] sentences = line.split("????");
-    if (VERBOSE) {
-      System.out.println("Total time : " + (System.currentTimeMillis() - totalStart));
-      System.out.println("Test for Bocchan with pre-splitting sentences (" + sentences.length + " sentences)");
-    }
-    totalStart = System.currentTimeMillis();
-    for (int i = 0; i < numIterations; i++) {
-      for (String sentence: sentences) {
-        final TokenStream ts = analyzer.tokenStream("ignored", new StringReader(sentence));
-        ts.reset();
-        while(ts.incrementToken());
-      }
-    }
-    if (VERBOSE) {
-      System.out.println("Total time : " + (System.currentTimeMillis() - totalStart));
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestSearchMode.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestSearchMode.java
deleted file mode 100644
index cb4da18..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/TestSearchMode.java
+++ /dev/null
@@ -1,82 +0,0 @@
-package org.apache.lucene.analysis.kuromoji;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.LineNumberReader;
-import java.io.Reader;
-
-import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-import org.apache.lucene.util.IOUtils;
-
-public class TestSearchMode extends BaseTokenStreamTestCase {
-  private final static String SEGMENTATION_FILENAME = "search-segmentation-tests.txt";
-  private final Analyzer analyzer = new Analyzer() {
-    @Override
-    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
-      Tokenizer tokenizer = new KuromojiTokenizer(reader, null, true, Mode.SEARCH);
-      return new TokenStreamComponents(tokenizer, tokenizer);
-    }
-  };
-
-  /** Test search mode segmentation */
-  public void testSearchSegmentation() throws IOException {
-    InputStream is = TestSearchMode.class.getResourceAsStream(SEGMENTATION_FILENAME);
-    if (is == null) {
-      throw new FileNotFoundException("Cannot find " + SEGMENTATION_FILENAME + " in test classpath");
-    }
-    try {
-      LineNumberReader reader = new LineNumberReader(new InputStreamReader(is, IOUtils.CHARSET_UTF_8));
-      String line = null;
-      while ((line = reader.readLine()) != null) {
-        // Remove comments
-        line = line.replaceAll("#.*$", "");
-        // Skip empty lines or comment lines
-        if (line.trim().isEmpty()) {
-          continue;
-        }
-        if (VERBOSE) {
-          System.out.println("Line no. " + reader.getLineNumber() + ": " + line);
-        }
-        String[] fields = line.split("\t", 2);
-        String sourceText = fields[0];
-        String[] expectedTokens = fields[1].split("\\s+");
-        int[] expectedPosIncrs = new int[expectedTokens.length];
-        int[] expectedPosLengths = new int[expectedTokens.length];
-        for(int tokIDX=0;tokIDX<expectedTokens.length;tokIDX++) {
-          if (expectedTokens[tokIDX].endsWith("/0")) {
-            expectedTokens[tokIDX] = expectedTokens[tokIDX].replace("/0", "");
-            expectedPosLengths[tokIDX] = expectedTokens.length-1;
-          } else {
-            expectedPosIncrs[tokIDX] = 1;
-            expectedPosLengths[tokIDX] = 1;
-          }
-        }
-        assertAnalyzesTo(analyzer, sourceText, expectedTokens, expectedPosIncrs);
-      }
-    } finally {
-      is.close();
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/bocchan.utf-8 b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/bocchan.utf-8
deleted file mode 100644
index a4c7ea3..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/bocchan.utf-8
+++ /dev/null
@@ -1 +0,0 @@
-????????????-------------------------------------------------------??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????-------------------------------------------------------??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? might is right ????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????? am glad to see you ?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????1992???4?1??20??1???????????????????2????????????????????1987????62?10??27??1??????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????5-86????????????????????????????????????1999?9??13????2004?2??27???????????????????????????????????????????http://www.aozora.gr.jp/????????????????????????????????????????????????????
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/TestTokenInfoDictionary.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/TestTokenInfoDictionary.java
deleted file mode 100644
index e005e12..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/TestTokenInfoDictionary.java
+++ /dev/null
@@ -1,107 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.util.ToStringUtil;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.UnicodeUtil;
-import org.apache.lucene.util.fst.FST;
-import org.apache.lucene.util.fst.IntsRefFSTEnum;
-import org.apache.lucene.util.fst.IntsRefFSTEnum.InputOutput;
-
-public class TestTokenInfoDictionary extends LuceneTestCase {
-
-  /** enumerates the entire FST/lookup data and just does basic sanity checks */
-  public void testEnumerateAll() throws Exception {
-    // just for debugging
-    int numTerms = 0;
-    int numWords = 0;
-    int lastWordId = -1;
-    int lastSourceId = -1;
-    TokenInfoDictionary tid = TokenInfoDictionary.getInstance();
-    ConnectionCosts matrix = ConnectionCosts.getInstance();
-    FST<Long> fst = tid.getFST().getInternalFST();
-    IntsRefFSTEnum<Long> fstEnum = new IntsRefFSTEnum<Long>(fst);
-    InputOutput<Long> mapping;
-    IntsRef scratch = new IntsRef();
-    while ((mapping = fstEnum.next()) != null) {
-      numTerms++;
-      IntsRef input = mapping.input;
-      char chars[] = new char[input.length];
-      for (int i = 0; i < chars.length; i++) {
-        chars[i] = (char)input.ints[input.offset+i];
-      }
-      assertTrue(UnicodeUtil.validUTF16String(new String(chars)));
-      
-      Long output = mapping.output;
-      int sourceId = output.intValue();
-      // we walk in order, terms, sourceIds, and wordIds should always be increasing
-      assertTrue(sourceId > lastSourceId);
-      lastSourceId = sourceId;
-      tid.lookupWordIds(sourceId, scratch);
-      for (int i = 0; i < scratch.length; i++) {
-        numWords++;
-        int wordId = scratch.ints[scratch.offset+i];
-        assertTrue(wordId > lastWordId);
-        lastWordId = wordId;
-         
-        String baseForm = tid.getBaseForm(wordId, chars, 0, chars.length);
-        assertTrue(baseForm == null || UnicodeUtil.validUTF16String(baseForm));
-        
-        String inflectionForm = tid.getInflectionForm(wordId);
-        assertTrue(inflectionForm == null || UnicodeUtil.validUTF16String(inflectionForm));
-        if (inflectionForm != null) {
-          // check that its actually an ipadic inflection form
-          assertNotNull(ToStringUtil.getInflectedFormTranslation(inflectionForm));          
-        }
-        
-        String inflectionType = tid.getInflectionType(wordId);
-        assertTrue(inflectionType == null || UnicodeUtil.validUTF16String(inflectionType));
-        if (inflectionType != null) {
-          // check that its actually an ipadic inflection type
-          assertNotNull(ToStringUtil.getInflectionTypeTranslation(inflectionType));
-        }
-        
-        int leftId = tid.getLeftId(wordId);
-        int rightId = tid.getRightId(wordId);
-        
-        matrix.get(rightId, leftId);
-        
-        tid.getWordCost(wordId);
-        
-        String pos = tid.getPartOfSpeech(wordId);
-        assertNotNull(pos);
-        assertTrue(UnicodeUtil.validUTF16String(pos));
-        // check that its actually an ipadic pos tag
-        assertNotNull(ToStringUtil.getPOSTranslation(pos));
-        
-        String pronunciation = tid.getPronunciation(wordId, chars, 0, chars.length);
-        assertNotNull(pronunciation);
-        assertTrue(UnicodeUtil.validUTF16String(pronunciation));
-        
-        String reading = tid.getReading(wordId, chars, 0, chars.length);
-        assertNotNull(reading);
-        assertTrue(UnicodeUtil.validUTF16String(reading));
-      }
-    }
-    if (VERBOSE) {
-      System.out.println("checked " + numTerms + " terms, " + numWords + " words.");
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/UserDictionaryTest.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/UserDictionaryTest.java
deleted file mode 100644
index 8992342..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/dict/UserDictionaryTest.java
+++ /dev/null
@@ -1,86 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.FileNotFoundException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.io.IOException;
-
-import org.apache.lucene.analysis.kuromoji.dict.UserDictionary;
-import org.apache.lucene.analysis.kuromoji.TestKuromojiTokenizer;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Test;
-
-public class UserDictionaryTest extends LuceneTestCase {
-
-  @Test
-  public void testLookup() throws IOException {
-    UserDictionary dictionary = TestKuromojiTokenizer.readDict();
-    String s = "????????";
-    int[][] dictionaryEntryResult = dictionary.lookup(s.toCharArray(), 0, s.length());
-    // Length should be three ?, ??, 
-    assertEquals(3, dictionaryEntryResult.length);
-    
-    // Test positions
-    assertEquals(0, dictionaryEntryResult[0][1]); // index of ?
-    assertEquals(2, dictionaryEntryResult[1][1]); // index of ??
-    assertEquals(4, dictionaryEntryResult[2][1]); // index of 
-    
-    // Test lengths
-    assertEquals(2, dictionaryEntryResult[0][2]); // length of ?
-    assertEquals(2, dictionaryEntryResult[1][2]); // length of ??
-    assertEquals(2, dictionaryEntryResult[2][2]); // length of 
-    
-    s = "??????????????";
-    int[][] dictionaryEntryResult2 = dictionary.lookup(s.toCharArray(), 0, s.length());
-    // Length should be six 
-    assertEquals(6, dictionaryEntryResult2.length);
-  }
-  
-  @Test
-  public void testReadings() throws IOException {
-    UserDictionary dictionary = TestKuromojiTokenizer.readDict();
-    int[][] result = dictionary.lookup("??????".toCharArray(), 0, 6);
-    assertEquals(3, result.length);
-    int wordIdNihon = result[0][0]; // wordId of ?? in ??????
-    assertEquals("?????", dictionary.getReading(wordIdNihon, "??".toCharArray(), 0, 2));
-    
-    result = dictionary.lookup("????".toCharArray(), 0, 3);
-    assertEquals(1, result.length);
-    int wordIdAsashoryu = result[0][0]; // wordId for ????
-    assertEquals("??????????", dictionary.getReading(wordIdAsashoryu, "????".toCharArray(), 0, 3));
-  }
-  
-  @Test
-  public void testPartOfSpeech() throws IOException {
-    UserDictionary dictionary = TestKuromojiTokenizer.readDict();
-    int[][] result = dictionary.lookup("??????".toCharArray(), 0, 6);
-    assertEquals(3, result.length);
-    int wordIdKeizai = result[1][0]; // wordId of ?? in ??????
-    assertEquals("????????", dictionary.getPartOfSpeech(wordIdKeizai));
-  }
-  
-  @Test
-  public void testRead() throws IOException {
-    UserDictionary dictionary = TestKuromojiTokenizer.readDict();
-    assertNotNull(dictionary);		
-  }
-}
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/search-segmentation-tests.txt b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/search-segmentation-tests.txt
deleted file mode 100644
index 835446f..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/search-segmentation-tests.txt
+++ /dev/null
@@ -1,142 +0,0 @@
-###
-### Tests for Kuromoji's search mode heuristic
-###
-### In search-mode, Kuromoji uses a heuristic to do extra splitting of words
-### to get a decompounding effect useful for search.  This file includes tests
-### for this heuristic and demonstrates its usefulness, but also weaknesses.
-###
-### This file's format is as follows:
-###	  <text><tab><token1> <token2> ... <token>
-###
-### This file should use UTF-8 encoding and there is one test per line.  The
-### text to be segmented and its expected surface form token sequence is 
-### separated by a tab ('\t').  Tokens are  separated by a half-width space.
-### Whitespace lines and lines starting with a '#' are ignored.  Comments
-### are not allowed on entry line.
-###
-### NOTE: These tests depends on IPADIC
-###
-### Revision history:
-###  - 2012-01-29: Initial version
-###
-
-##
-## Organizations
-##
-
-# Kansai Internationl Airport
-???	? ???/0 ?? 
-# Narita Airport
-???	??? ???/0 
-# Haneda Airport
-?	? ?/0 
-# Nara Institute of Science and Technology
-?????????????	?? ?????????????/0 ??? ?? ??? ??? ?
-# Tokyo University
-??	? ??/0 ?
-# Kyoto University
-???	?? ???/0 ?
-
-# NOTE: differs from non-compound mode:
-# Kyoto University Baseball Club
-??????????	??? ? ?? ??? ??
-
-##
-## Katakana titles
-##
-
-# Senior Software Engineer
-???????????????????	???? ???????????????????/0 ??????? ??????
-# Software Engineer
-?????????????	??????? ??????
-# Senior Project Manager
-??????????????????	???? ??????????????????/0 ???????? ???????
-# Project Manager
-???????????????	???????? ???????
-# Senior Sales Engineer
-??????????????	???? ??????????????/0 ????? ??????
-# System Architect
-??????????????	????? ??????????????/0 ?????????
-# Senior System Architect
-?????????????????	???? ?????????????????/0 ????? ?????????
-# System Administrator
-??????????????????	????? ?????????????
-??????????????????	????? ??????????????????/0 ?????????????
-# Senior System Administrator
-???????????????????????	???? ???????????????????????/0 ????? ?????????????
-
-##
-## Company names (several are fictitious)
-##
-
-# SoftBank Mobile
-????????????	??????? ?????
-# Alpine Materials
-????????????????	???????? ????????????????/0 ?????????
-# Sapporo Holdings
-???????????????	????? ??????????
-# Yamada Corporation
-?????????????	???? ?????????????/0 ?????????
-# Canon Semiconductor equipement	NOTE: Semiconductor becomes semi + conductor
-???????????????????????????	?????? ???????????????????????????/0 ?? ????????? ?????????
-# Orental Chain
-????????????	??????? ????????????/0 ?????
-# Ally Projects Japan	NOTE: Becomes one token as ???????? is not in IPADIC
-???????????????????	???????????????????
-# Peter Pan Corporation
-?????????????????	????? ?????????????????/0 ??? ?????????
-# AIM Create
-??????????	??????????
-# Mars Engineering
-???????????????	????? ???????????????/0 ?????????
-# Fuji Protein Technology
-???????????????????	??? ???????????????????/0 ???????? ????????
-
-##
-## Person names
-##
-
-# Michael Jackson
-????????????	????? ???????
-# Steve Jobs
-???????????	?????? ?????
-# Harry Potter	NOTE: Becomes one token (short word)
-??????????	??????????
-# Bill Gates	NOTE: Becomes one token (short word)
-???????	???????
-# Sean Connery	NOTE: Becomes one token (okay)
-?????????	?????????
-
-##
-## Other nouns
-##
-
-# Holdings
-??????????	??????????
-# Engineering
-?????????	?????????
-# Software Engineering
-????????????????	??????? ?????????
-# Shopping center
-???????????	??????? ????
-# Game center (arcade)	NOTE: One token because of short word
-?????????	?????????
-# Christmas shopping
-??????????????	??????? ???????
-# Download file
-???????????????	?????????? ?????
-# Technology
-????????	????????
-# Lillehammer Olympics
-????????????????	???????? ????????
-
-##
-## Problematic terms
-##
-
-# JT Engineering	NOTE: Becomes J Tien ginia ring (substrings are in IPADIC)
-????????????????	???? ????????????????/0 ????? ???? ?????
-# Anchovy pasta	NOTE: Become Anch yvipasta
-???????????	????? ???????????/0 ???????
-# Surprise gift	NOTE: Becomes one token (surprise not in IPADIC)
-?????????	?????????
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/userdict.txt b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/userdict.txt
deleted file mode 100644
index f9db02c..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/userdict.txt
+++ /dev/null
@@ -1,10 +0,0 @@
-# Custom segmentation for long entries
-??????,?? ?? ??,????? ???? ?????,????????
-???,? ?? ,????? ???? ?????,???????
-
-# Custom reading for sumo wrestler
-????,????,??????????,??????
-
-# Silly entry:
-abcd,a b cd,foo1 foo2 foo3,bar
-abcdefg,ab cd efg,foo1 foo2 foo4,bar
diff --git a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/util/TestToStringUtil.java b/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/util/TestToStringUtil.java
deleted file mode 100644
index 92a6396..0000000
--- a/modules/analysis/kuromoji/src/test/org/apache/lucene/analysis/kuromoji/util/TestToStringUtil.java
+++ /dev/null
@@ -1,34 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestToStringUtil extends LuceneTestCase {
-  public void testPOS() {
-    assertEquals("noun-suffix-verbal", ToStringUtil.getPOSTranslation("???-?-????"));
-  }
-  
-  public void testHepburn() {
-    assertEquals("majan", ToStringUtil.getRomanization("???????"));
-    assertEquals("uroncha", ToStringUtil.getRomanization("?????????"));
-    assertEquals("chahan", ToStringUtil.getRomanization("???????"));
-    assertEquals("chashu", ToStringUtil.getRomanization("???????"));
-    assertEquals("shumai", ToStringUtil.getRomanization("??????"));
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/BinaryDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/BinaryDictionaryWriter.java
new file mode 100644
index 0000000..560998d
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/BinaryDictionaryWriter.java
@@ -0,0 +1,316 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.ByteBuffer;
+import java.nio.channels.Channels;
+import java.nio.channels.WritableByteChannel;
+import java.util.ArrayList;
+
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.store.OutputStreamDataOutput;
+import org.apache.lucene.util.ArrayUtil;
+import org.apache.lucene.util.CodecUtil;
+
+import org.apache.lucene.analysis.ja.dict.BinaryDictionary;
+
+public abstract class BinaryDictionaryWriter {
+  protected final Class<? extends BinaryDictionary> implClazz;
+  protected ByteBuffer buffer;
+  private int targetMapEndOffset = 0, lastWordId = -1, lastSourceId = -1;
+  private int[] targetMap = new int[8192];
+  private int[] targetMapOffsets = new int[8192];
+  private final ArrayList<String> posDict = new ArrayList<String>();
+
+  public BinaryDictionaryWriter(Class<? extends BinaryDictionary> implClazz, int size) {
+    this.implClazz = implClazz;
+    buffer = ByteBuffer.allocate(size);
+  }
+  
+  /**
+   * put the entry in map
+   * @return current position of buffer, which will be wordId of next entry
+   */
+  public int put(String[] entry) {
+    short leftId = Short.parseShort(entry[1]);
+    short rightId = Short.parseShort(entry[2]);
+    short wordCost = Short.parseShort(entry[3]);
+    
+    StringBuilder sb = new StringBuilder();
+    
+    // build up the POS string
+    for (int i = 4; i < 8; i++) {
+      String part = entry[i];
+      assert part.length() > 0;
+      if (!"*".equals(part)) {
+        if (sb.length() > 0) {
+          sb.append('-');
+        }
+        sb.append(part);
+      }
+    }
+    
+    String posData = sb.toString();
+    
+    sb.setLength(0);
+    sb.append(CSVUtil.quoteEscape(posData));
+    sb.append(',');
+    if (!"*".equals(entry[8])) {
+      sb.append(CSVUtil.quoteEscape(entry[8]));
+    }
+    sb.append(',');
+    if (!"*".equals(entry[9])) {
+      sb.append(CSVUtil.quoteEscape(entry[9]));
+    }
+    String fullPOSData = sb.toString();
+    
+    String baseForm = entry[10];
+    String reading = entry[11];
+    String pronunciation = entry[12];
+    
+    // extend buffer if necessary
+    int left = buffer.remaining();
+    // worst case: two short, 3 bytes, and features (all as utf-16)
+    int worstCase = 4 + 3 + 2*(baseForm.length() + reading.length() + pronunciation.length());
+    if (worstCase > left) {
+      ByteBuffer newBuffer = ByteBuffer.allocate(ArrayUtil.oversize(buffer.limit() + worstCase - left, 1));
+      buffer.flip();
+      newBuffer.put(buffer);
+      buffer = newBuffer;
+    }
+
+    int flags = 0;
+    if (!("*".equals(baseForm) || baseForm.equals(entry[0]))) {
+      flags |= BinaryDictionary.HAS_BASEFORM;
+    }
+    if (!reading.equals(toKatakana(entry[0]))) {
+      flags |= BinaryDictionary.HAS_READING;
+    }
+    if (!pronunciation.equals(reading)) {
+      flags |= BinaryDictionary.HAS_PRONUNCIATION;
+    }
+
+    assert leftId == rightId;
+    assert leftId < 4096; // there are still unused bits
+    // add pos mapping
+    int toFill = 1+leftId - posDict.size();
+    for (int i = 0; i < toFill; i++) {
+      posDict.add(null);
+    }
+    
+    String existing = posDict.get(leftId);
+    assert existing == null || existing.equals(fullPOSData);
+    posDict.set(leftId, fullPOSData);
+    
+    buffer.putShort((short)(leftId << 3 | flags));
+    buffer.putShort(wordCost);
+
+    if ((flags & BinaryDictionary.HAS_BASEFORM) != 0) {
+      assert baseForm.length() < 16;
+      int shared = sharedPrefix(entry[0], baseForm);
+      int suffix = baseForm.length() - shared;
+      buffer.put((byte) (shared << 4 | suffix));
+      for (int i = shared; i < baseForm.length(); i++) {
+        buffer.putChar(baseForm.charAt(i));
+      }
+    }
+    
+    if ((flags & BinaryDictionary.HAS_READING) != 0) {
+      if (isKatakana(reading)) {
+        buffer.put((byte) (reading.length() << 1 | 1));
+        writeKatakana(reading);
+      } else {
+        buffer.put((byte) (reading.length() << 1));
+        for (int i = 0; i < reading.length(); i++) {
+          buffer.putChar(reading.charAt(i));
+        }
+      }
+    }
+    
+    if ((flags & BinaryDictionary.HAS_PRONUNCIATION) != 0) {
+      // we can save 150KB here, but it makes the reader a little complicated.
+      // int shared = sharedPrefix(reading, pronunciation);
+      // buffer.put((byte) shared);
+      // pronunciation = pronunciation.substring(shared);
+      if (isKatakana(pronunciation)) {
+        buffer.put((byte) (pronunciation.length() << 1 | 1));
+        writeKatakana(pronunciation);
+      } else {
+        buffer.put((byte) (pronunciation.length() << 1));
+        for (int i = 0; i < pronunciation.length(); i++) {
+          buffer.putChar(pronunciation.charAt(i));
+        }
+      }
+    }
+    
+    return buffer.position();
+  }
+  
+  private boolean isKatakana(String s) {
+    for (int i = 0; i < s.length(); i++) {
+      char ch = s.charAt(i);
+      if (ch < 0x30A0 || ch > 0x30FF) {
+        return false;
+      }
+    }
+    return true;
+  }
+  
+  private void writeKatakana(String s) {
+    for (int i = 0; i < s.length(); i++) {
+      buffer.put((byte) (s.charAt(i) - 0x30A0));
+    }
+  }
+  
+  private String toKatakana(String s) {
+    char text[] = new char[s.length()];
+    for (int i = 0; i < s.length(); i++) {
+      char ch = s.charAt(i);
+      if (ch > 0x3040 && ch < 0x3097) {
+        text[i] = (char)(ch + 0x60);
+      } else {
+        text[i] = ch;
+      }
+    }
+    return new String(text);
+  }
+  
+  public static int sharedPrefix(String left, String right) {
+    int len = left.length() < right.length() ? left.length() : right.length();
+    for (int i = 0; i < len; i++)
+      if (left.charAt(i) != right.charAt(i))
+        return i;
+    return len;
+  }
+  
+  public void addMapping(int sourceId, int wordId) {
+    assert wordId > lastWordId : "words out of order: " + wordId + " vs lastID: " + lastWordId;
+    
+    if (sourceId > lastSourceId) {
+      assert sourceId > lastSourceId : "source ids out of order: lastSourceId=" + lastSourceId + " vs sourceId=" + sourceId;
+      targetMapOffsets = ArrayUtil.grow(targetMapOffsets, sourceId + 1);
+      for (int i = lastSourceId + 1; i <= sourceId; i++) {
+        targetMapOffsets[i] = targetMapEndOffset;
+      }
+    } else {
+      assert sourceId == lastSourceId;
+    }
+
+    targetMap = ArrayUtil.grow(targetMap, targetMapEndOffset + 1);
+    targetMap[targetMapEndOffset] = wordId;
+    targetMapEndOffset++;
+
+    lastSourceId = sourceId;
+    lastWordId = wordId;
+  }
+
+  protected final String getBaseFileName(String baseDir) throws IOException {
+    return baseDir + File.separator + implClazz.getName().replace('.', File.separatorChar);
+  }
+  
+  /**
+   * Write dictionary in file
+   * Dictionary format is:
+   * [Size of dictionary(int)], [entry:{left id(short)}{right id(short)}{word cost(short)}{length of pos info(short)}{pos info(char)}], [entry...], [entry...].....
+   * @throws IOException
+   */
+  public void write(String baseDir) throws IOException {
+    final String baseName = getBaseFileName(baseDir);
+    writeDictionary(baseName + BinaryDictionary.DICT_FILENAME_SUFFIX);
+    writeTargetMap(baseName + BinaryDictionary.TARGETMAP_FILENAME_SUFFIX);
+    writePosDict(baseName + BinaryDictionary.POSDICT_FILENAME_SUFFIX);
+  }
+  
+  // TODO: maybe this int[] should instead be the output to the FST...
+  protected void writeTargetMap(String filename) throws IOException {
+    new File(filename).getParentFile().mkdirs();
+    OutputStream os = new FileOutputStream(filename);
+    try {
+      os = new BufferedOutputStream(os);
+      final DataOutput out = new OutputStreamDataOutput(os);
+      CodecUtil.writeHeader(out, BinaryDictionary.TARGETMAP_HEADER, BinaryDictionary.VERSION);
+      
+      final int numSourceIds = lastSourceId + 1;
+      out.writeVInt(targetMapEndOffset); // <-- size of main array
+      out.writeVInt(numSourceIds + 1); // <-- size of offset array (+ 1 more entry)
+      int prev = 0, sourceId = 0;
+      for (int ofs = 0; ofs < targetMapEndOffset; ofs++) {
+        final int val = targetMap[ofs], delta = val - prev;
+        assert delta >= 0;
+        if (ofs == targetMapOffsets[sourceId]) {
+          out.writeVInt((delta << 1) | 0x01);
+          sourceId++;
+        } else {
+          out.writeVInt((delta << 1));
+        }
+        prev += delta;
+      }
+      assert sourceId == numSourceIds : "sourceId:"+sourceId+" != numSourceIds:"+numSourceIds;
+    } finally {
+      os.close();
+    }
+  }
+  
+  protected void writePosDict(String filename) throws IOException {
+    new File(filename).getParentFile().mkdirs();
+    OutputStream os = new FileOutputStream(filename);
+    try {
+      os = new BufferedOutputStream(os);
+      final DataOutput out = new OutputStreamDataOutput(os);
+      CodecUtil.writeHeader(out, BinaryDictionary.POSDICT_HEADER, BinaryDictionary.VERSION);
+      out.writeVInt(posDict.size());
+      for (String s : posDict) {
+        if (s == null) {
+          out.writeByte((byte)0);
+          out.writeByte((byte)0);
+          out.writeByte((byte)0);
+        } else {
+          String data[] = CSVUtil.parse(s);
+          assert data.length == 3 : "malformed pos/inflection: " + s;
+          out.writeString(data[0]);
+          out.writeString(data[1]);
+          out.writeString(data[2]);
+        }
+      }
+    } finally {
+      os.close();
+    }
+  }
+  
+  protected void writeDictionary(String filename) throws IOException {
+    new File(filename).getParentFile().mkdirs();
+    final FileOutputStream os = new FileOutputStream(filename);
+    try {
+      final DataOutput out = new OutputStreamDataOutput(os);
+      CodecUtil.writeHeader(out, BinaryDictionary.DICT_HEADER, BinaryDictionary.VERSION);
+      out.writeVInt(buffer.position());
+      final WritableByteChannel channel = Channels.newChannel(os);
+      // Write Buffer
+      buffer.flip();  // set position to 0, set limit to current position
+      channel.write(buffer);
+      assert buffer.remaining() == 0L;
+    } finally {
+      os.close();
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/CharacterDefinitionWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/CharacterDefinitionWriter.java
new file mode 100644
index 0000000..5f9889d
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/CharacterDefinitionWriter.java
@@ -0,0 +1,95 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.Arrays;
+
+import org.apache.lucene.analysis.ja.dict.CharacterDefinition;
+
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.store.OutputStreamDataOutput;
+import org.apache.lucene.util.CodecUtil;
+
+public final class CharacterDefinitionWriter {
+
+  private final byte[] characterCategoryMap = new byte[0x10000];
+  
+  private final boolean[] invokeMap = new boolean[CharacterDefinition.CLASS_COUNT];
+  private final boolean[] groupMap = new boolean[CharacterDefinition.CLASS_COUNT];
+    
+  /**
+   * Constructor for building. TODO: remove write access
+   */
+  public CharacterDefinitionWriter() {
+    Arrays.fill(characterCategoryMap, CharacterDefinition.DEFAULT);
+  }
+  
+  /**
+   * Put mapping from unicode code point to character class.
+   * 
+   * @param codePoint
+   *            code point
+   * @param characterClassName character class name
+   */
+  public void putCharacterCategory(int codePoint, String characterClassName) {
+    characterClassName = characterClassName.split(" ")[0]; // use first
+    // category
+    // class
+    
+    // Override Nakaguro
+    if (codePoint == 0x30FB) {
+      characterClassName = "SYMBOL";
+    }
+    characterCategoryMap[codePoint] = CharacterDefinition.lookupCharacterClass(characterClassName);
+  }
+  
+  public void putInvokeDefinition(String characterClassName, int invoke, int group, int length) {
+    final byte characterClass = CharacterDefinition.lookupCharacterClass(characterClassName);
+    invokeMap[characterClass] = invoke == 1;
+    groupMap[characterClass] = group == 1;
+    // TODO: length def ignored
+  }
+  
+  public void write(String baseDir) throws IOException {
+    String filename = baseDir + File.separator +
+      CharacterDefinition.class.getName().replace('.', File.separatorChar) + CharacterDefinition.FILENAME_SUFFIX;
+    new File(filename).getParentFile().mkdirs();
+    OutputStream os = new FileOutputStream(filename);
+    try {
+      os = new BufferedOutputStream(os);
+      final DataOutput out = new OutputStreamDataOutput(os);
+      CodecUtil.writeHeader(out, CharacterDefinition.HEADER, CharacterDefinition.VERSION);
+      out.writeBytes(characterCategoryMap, 0, characterCategoryMap.length);
+      for (int i = 0; i < CharacterDefinition.CLASS_COUNT; i++) {
+        final byte b = (byte) (
+          (invokeMap[i] ? 0x01 : 0x00) | 
+          (groupMap[i] ? 0x02 : 0x00)
+        );
+        out.writeByte(b);
+      }
+    } finally {
+      os.close();
+    }
+  }
+  
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsBuilder.java
new file mode 100644
index 0000000..eaebb5c
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsBuilder.java
@@ -0,0 +1,67 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.LineNumberReader;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
+
+public class ConnectionCostsBuilder {
+  
+  private ConnectionCostsBuilder() {
+  }
+  
+  public static ConnectionCostsWriter build(String filename) throws IOException {
+    FileInputStream inputStream = new FileInputStream(filename);
+    Charset cs = Charset.forName("US-ASCII");
+    CharsetDecoder decoder = cs.newDecoder()
+        .onMalformedInput(CodingErrorAction.REPORT)
+        .onUnmappableCharacter(CodingErrorAction.REPORT);
+    InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
+    LineNumberReader lineReader = new LineNumberReader(streamReader);
+    
+    String line = lineReader.readLine();
+    String[] dimensions = line.split("\\s+");
+    
+    assert dimensions.length == 2;
+    
+    int forwardSize = Integer.parseInt(dimensions[0]);
+    int backwardSize = Integer.parseInt(dimensions[1]);
+    
+    assert forwardSize > 0 && backwardSize > 0;
+    
+    ConnectionCostsWriter costs = new ConnectionCostsWriter(forwardSize, backwardSize);
+    
+    while ((line = lineReader.readLine()) != null) {
+      String[] fields = line.split("\\s+");
+      
+      assert fields.length == 3;
+      
+      int forwardId = Integer.parseInt(fields[0]);
+      int backwardId = Integer.parseInt(fields[1]);
+      int cost = Integer.parseInt(fields[2]);
+      
+      costs.add(forwardId, backwardId, cost);
+    }
+    return costs;
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsWriter.java
new file mode 100644
index 0000000..da3f8a8
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/ConnectionCostsWriter.java
@@ -0,0 +1,76 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedOutputStream;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+
+import org.apache.lucene.analysis.ja.dict.ConnectionCosts;
+
+import org.apache.lucene.store.DataOutput;
+import org.apache.lucene.store.OutputStreamDataOutput;
+import org.apache.lucene.util.CodecUtil;
+
+public final class ConnectionCostsWriter {
+  
+  private final short[][] costs; // array is backward IDs first since get is called using the same backward ID consecutively. maybe doesn't matter.
+  private final int forwardSize;
+  private final int backwardSize;
+  /**
+   * Constructor for building. TODO: remove write access
+   */
+  public ConnectionCostsWriter(int forwardSize, int backwardSize) {
+    this.forwardSize = forwardSize;
+    this.backwardSize = backwardSize;
+    this.costs = new short[backwardSize][forwardSize];
+  }
+  
+  public void add(int forwardId, int backwardId, int cost) {
+    this.costs[backwardId][forwardId] = (short)cost;
+  }
+  
+  public void write(String baseDir) throws IOException {
+    String filename = baseDir + File.separator +
+      ConnectionCosts.class.getName().replace('.', File.separatorChar) + ConnectionCosts.FILENAME_SUFFIX;
+    new File(filename).getParentFile().mkdirs();
+    OutputStream os = new FileOutputStream(filename);
+    try {
+      os = new BufferedOutputStream(os);
+      final DataOutput out = new OutputStreamDataOutput(os);
+      CodecUtil.writeHeader(out, ConnectionCosts.HEADER, ConnectionCosts.VERSION);
+      out.writeVInt(forwardSize);
+      out.writeVInt(backwardSize);
+      int last = 0;
+      assert costs.length == backwardSize;
+      for (short[] a : costs) {
+        assert a.length == forwardSize;
+        for (int i = 0; i < a.length; i++) {
+          int delta = (int)a[i] - last;
+          out.writeVInt((delta >> 31) ^ (delta << 1));
+          last = a[i];
+        }
+      }
+    } finally {
+      os.close();
+    }
+  }
+  
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/DictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/DictionaryBuilder.java
new file mode 100644
index 0000000..0efe4e5
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/DictionaryBuilder.java
@@ -0,0 +1,85 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+import java.io.IOException;
+
+public class DictionaryBuilder {
+  
+  public enum DictionaryFormat { IPADIC, UNIDIC };
+  
+  private DictionaryBuilder() {
+  }
+  
+  public static void build(DictionaryFormat format,
+      String inputDirname,
+      String outputDirname,
+      String encoding,
+      boolean normalizeEntry) throws IOException {
+    System.out.println("building tokeninfo dict...");
+    TokenInfoDictionaryBuilder tokenInfoBuilder = new TokenInfoDictionaryBuilder(format, encoding, normalizeEntry);    
+    TokenInfoDictionaryWriter tokenInfoDictionary = tokenInfoBuilder.build(inputDirname);
+    tokenInfoDictionary.write(outputDirname);
+    tokenInfoDictionary = null;
+    tokenInfoBuilder = null;
+    System.out.println("done");
+    
+    System.out.print("building unknown word dict...");
+    UnknownDictionaryBuilder unkBuilder = new UnknownDictionaryBuilder(encoding);
+    UnknownDictionaryWriter unkDictionary = unkBuilder.build(inputDirname);
+    unkDictionary.write(outputDirname);
+    unkDictionary = null;
+    unkBuilder = null;
+    System.out.println("done");
+    
+    System.out.print("building connection costs...");
+    ConnectionCostsWriter connectionCosts
+      = ConnectionCostsBuilder.build(inputDirname + File.separator + "matrix.def");
+    connectionCosts.write(outputDirname);
+    System.out.println("done");
+  }
+  
+  public static void main(String[] args) throws IOException, ClassNotFoundException {
+    DictionaryFormat format;
+    if (args[0].equalsIgnoreCase("ipadic")) {
+      format = DictionaryFormat.IPADIC;
+    } else if (args[0].equalsIgnoreCase("unidic")) {
+      format = DictionaryFormat.UNIDIC;
+    } else {
+      System.err.println("Illegal format " + args[0] + " using unidic instead");
+      format = DictionaryFormat.IPADIC;
+    }
+    
+    String inputDirname = args[1];
+    String outputDirname = args[2];
+    String inputEncoding = args[3];
+    boolean normalizeEntries = Boolean.parseBoolean(args[4]);
+    
+    System.out.println("dictionary builder");
+    System.out.println("");
+    System.out.println("dictionary format: " + format);
+    System.out.println("input directory: " + inputDirname);
+    System.out.println("output directory: " + outputDirname);
+    System.out.println("input encoding: " + inputEncoding);
+    System.out.println("normalize entries: " + normalizeEntries);
+    System.out.println("");
+    DictionaryBuilder.build(format, inputDirname, outputDirname, inputEncoding, normalizeEntries);
+  }
+  
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java
new file mode 100644
index 0000000..b09bf3b
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryBuilder.java
@@ -0,0 +1,227 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+
+import org.apache.lucene.analysis.ja.util.DictionaryBuilder.DictionaryFormat;
+import org.apache.lucene.util.IntsRef;
+import org.apache.lucene.util.fst.Builder;
+import org.apache.lucene.util.fst.FST;
+import org.apache.lucene.util.fst.PositiveIntOutputs;
+
+import com.ibm.icu.text.Normalizer2;
+
+/**
+ */
+public class TokenInfoDictionaryBuilder {
+  
+  /** Internal word id - incrementally assigned as entries are read and added. This will be byte offset of dictionary file */
+  private int offset = 0;
+  
+  private String encoding = "euc-jp";
+  
+  private boolean normalizeEntries = false;
+  private Normalizer2 normalizer;
+  
+  private DictionaryFormat format = DictionaryFormat.IPADIC;
+  
+  public TokenInfoDictionaryBuilder(DictionaryFormat format, String encoding, boolean normalizeEntries) {
+    this.format = format;
+    this.encoding = encoding;
+    this.normalizeEntries = normalizeEntries;
+    this.normalizer = normalizeEntries ? Normalizer2.getInstance(null, "nfkc", Normalizer2.Mode.COMPOSE) : null;
+  }
+  
+  public TokenInfoDictionaryWriter build(String dirname) throws IOException {
+    FilenameFilter filter = new FilenameFilter() {
+      @Override
+      public boolean accept(File dir, String name) {
+        return name.endsWith(".csv");
+      }
+    };
+    ArrayList<File> csvFiles = new ArrayList<File>();
+    for (File file : new File(dirname).listFiles(filter)) {
+      csvFiles.add(file);
+    }
+    Collections.sort(csvFiles);
+    return buildDictionary(csvFiles);
+  }
+
+  public TokenInfoDictionaryWriter buildDictionary(List<File> csvFiles) throws IOException {
+    TokenInfoDictionaryWriter dictionary = new TokenInfoDictionaryWriter(10 * 1024 * 1024);
+    
+    // all lines in the file
+    System.out.println("  parse...");
+    List<String[]> lines = new ArrayList<String[]>(400000);
+    for (File file : csvFiles){
+      FileInputStream inputStream = new FileInputStream(file);
+      Charset cs = Charset.forName(encoding);
+      CharsetDecoder decoder = cs.newDecoder()
+          .onMalformedInput(CodingErrorAction.REPORT)
+          .onUnmappableCharacter(CodingErrorAction.REPORT);
+      InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
+      BufferedReader reader = new BufferedReader(streamReader);
+      
+      String line = null;
+      while ((line = reader.readLine()) != null) {
+        String[] entry = CSVUtil.parse(line);
+
+        if(entry.length < 13) {
+          System.out.println("Entry in CSV is not valid: " + line);
+          continue;
+        }
+        
+        String[] formatted = formatEntry(entry);
+        lines.add(formatted);
+        
+        // NFKC normalize dictionary entry
+        if (normalizeEntries) {
+          if (normalizer.isNormalized(entry[0])){
+            continue;
+          }
+          String[] normalizedEntry = new String[entry.length];
+          for (int i = 0; i < entry.length; i++) {
+            normalizedEntry[i] = normalizer.normalize(entry[i]);
+          }
+          
+          formatted = formatEntry(normalizedEntry);
+          lines.add(formatted);
+        }
+      }
+    }
+    
+    System.out.println("  sort...");
+
+    // sort by term: we sorted the files already and use a stable sort.
+    Collections.sort(lines, new Comparator<String[]>() {
+      public int compare(String[] left, String[] right) {
+        return left[0].compareTo(right[0]);
+      }
+    });
+    
+    System.out.println("  encode...");
+
+    PositiveIntOutputs fstOutput = PositiveIntOutputs.getSingleton(true);
+    Builder<Long> fstBuilder = new Builder<Long>(FST.INPUT_TYPE.BYTE2, 0, 0, true, true, Integer.MAX_VALUE, fstOutput, null, true);
+    IntsRef scratch = new IntsRef();
+    long ord = -1; // first ord will be 0
+    String lastValue = null;
+
+    // build tokeninfo dictionary
+    for (String[] entry : lines) {
+      int next = dictionary.put(entry);
+        
+      if(next == offset){
+        System.out.println("Failed to process line: " + Arrays.toString(entry));
+        continue;
+      }
+      
+      String token = entry[0];
+      if (!token.equals(lastValue)) {
+        // new word to add to fst
+        ord++;
+        lastValue = token;
+        scratch.grow(token.length());
+        scratch.length = token.length();
+        for (int i = 0; i < token.length(); i++) {
+          scratch.ints[i] = (int) token.charAt(i);
+        }
+        fstBuilder.add(scratch, ord);
+      }
+      dictionary.addMapping((int)ord, offset);
+      offset = next;
+    }
+    
+    final FST<Long> fst = fstBuilder.finish().pack(2, 100000);
+    
+    System.out.print("  " + fst.getNodeCount() + " nodes, " + fst.getArcCount() + " arcs, " + fst.sizeInBytes() + " bytes...  ");
+    dictionary.setFST(fst);
+    System.out.println(" done");
+    
+    return dictionary;
+  }
+  
+  /*
+   * IPADIC features
+   * 
+   * 0	- surface
+   * 1	- left cost
+   * 2	- right cost
+   * 3	- word cost
+   * 4-9	- pos
+   * 10	- base form
+   * 11	- reading
+   * 12	- pronounciation
+   *
+   * UniDic features
+   * 
+   * 0	- surface
+   * 1	- left cost
+   * 2	- right cost
+   * 3	- word cost
+   * 4-9	- pos
+   * 10	- base form reading
+   * 11	- base form
+   * 12	- surface form
+   * 13	- surface reading
+   */
+  
+  public String[] formatEntry(String[] features) {
+    if (this.format == DictionaryFormat.IPADIC) {
+      return features;
+    } else {
+      String[] features2 = new String[13];
+      features2[0] = features[0];
+      features2[1] = features[1];
+      features2[2] = features[2];
+      features2[3] = features[3];
+      features2[4] = features[4];
+      features2[5] = features[5];
+      features2[6] = features[6];
+      features2[7] = features[7];
+      features2[8] = features[8];
+      features2[9] = features[9];
+      features2[10] = features[11];
+      
+      // If the surface reading is non-existent, use surface form for reading and pronunciation.
+      // This happens with punctuation in UniDic and there are possibly other cases as well
+      if (features[13].length() == 0) {
+        features2[11] = features[0];
+        features2[12] = features[0];
+      } else {
+        features2[11] = features[13];
+        features2[12] = features[13];
+      }			
+      return features2;
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryWriter.java
new file mode 100644
index 0000000..ec63f47
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/TokenInfoDictionaryWriter.java
@@ -0,0 +1,48 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+import java.io.IOException;
+
+import org.apache.lucene.analysis.ja.dict.TokenInfoDictionary;
+import org.apache.lucene.util.fst.FST;
+
+public class TokenInfoDictionaryWriter extends BinaryDictionaryWriter {
+  private FST<Long> fst;
+
+  public TokenInfoDictionaryWriter(int size) {
+    super(TokenInfoDictionary.class, size);
+  }
+  
+  public void setFST(FST<Long> fst) {
+    this.fst = fst;
+  }
+  
+  @Override
+  public void write(String baseDir) throws IOException {
+    super.write(baseDir);
+    writeFST(getBaseFileName(baseDir) + TokenInfoDictionary.FST_FILENAME_SUFFIX);
+  }
+  
+  protected void writeFST(String filename) throws IOException {
+    File f = new File(filename);
+    f.getParentFile().mkdirs();
+    fst.save(f);
+  }  
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryBuilder.java
new file mode 100644
index 0000000..4d14d1d
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryBuilder.java
@@ -0,0 +1,135 @@
+package org.apache.lucene.analysis.ja.util;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.io.LineNumberReader;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Comparator;
+import java.util.List;
+
+import org.apache.lucene.analysis.ja.dict.CharacterDefinition;
+
+public class UnknownDictionaryBuilder {
+  private static final String NGRAM_DICTIONARY_ENTRY = "NGRAM,5,5,-32768,??,???,*,*,*,*,*,*,*";
+  
+  private String encoding = "euc-jp";
+  
+  public UnknownDictionaryBuilder(String encoding) {
+    this.encoding = encoding;
+  }
+  
+  public UnknownDictionaryWriter build(String dirname) throws IOException {
+    UnknownDictionaryWriter unkDictionary = readDictionaryFile(dirname + File.separator + "unk.def");  //Should be only one file
+    readCharacterDefinition(dirname + File.separator + "char.def", unkDictionary);
+    return unkDictionary;
+  }
+  
+  public UnknownDictionaryWriter readDictionaryFile(String filename)
+      throws IOException {
+    return readDictionaryFile(filename, encoding);
+  }
+  
+  public UnknownDictionaryWriter readDictionaryFile(String filename, String encoding)
+      throws IOException {
+    UnknownDictionaryWriter dictionary = new UnknownDictionaryWriter(5 * 1024 * 1024);
+    
+    FileInputStream inputStream = new FileInputStream(filename);
+    Charset cs = Charset.forName(encoding);
+    CharsetDecoder decoder = cs.newDecoder()
+        .onMalformedInput(CodingErrorAction.REPORT)
+        .onUnmappableCharacter(CodingErrorAction.REPORT);
+    InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
+    LineNumberReader lineReader = new LineNumberReader(streamReader);
+    
+    dictionary.put(CSVUtil.parse(NGRAM_DICTIONARY_ENTRY));
+    
+    List<String[]> lines = new ArrayList<String[]>();
+    String line = null;
+    while ((line = lineReader.readLine()) != null) {
+      // note: unk.def only has 10 fields, it simplifies the writer to just append empty reading and pronunciation,
+      // even though the unknown dictionary returns hardcoded null here.
+      final String[] parsed = CSVUtil.parse(line + ",*,*"); // Probably we don't need to validate entry
+      lines.add(parsed);
+    }
+    
+    Collections.sort(lines, new Comparator<String[]>() {
+      public int compare(String[] left, String[] right) {
+        int leftId = CharacterDefinition.lookupCharacterClass(left[0]);
+        int rightId = CharacterDefinition.lookupCharacterClass(right[0]);
+        return leftId - rightId;
+      }
+    });
+    
+    for (String[] entry : lines) {
+      dictionary.put(entry);
+    }
+    
+    return dictionary;
+  }
+  
+  public void readCharacterDefinition(String filename, UnknownDictionaryWriter dictionary) throws IOException {
+    FileInputStream inputStream = new FileInputStream(filename);
+    InputStreamReader streamReader = new InputStreamReader(inputStream, encoding);
+    LineNumberReader lineReader = new LineNumberReader(streamReader);
+    
+    String line = null;
+    
+    while ((line = lineReader.readLine()) != null) {
+      line = line.replaceAll("^\\s", "");
+      line = line.replaceAll("\\s*#.*", "");
+      line = line.replaceAll("\\s+", " ");
+      
+      // Skip empty line or comment line
+      if(line.length() == 0) {
+        continue;
+      }
+      
+      if(line.startsWith("0x")) {	// Category mapping
+        String[] values = line.split(" ", 2);	// Split only first space
+        
+        if(!values[0].contains("..")) {
+          int cp = Integer.decode(values[0]).intValue();
+          dictionary.putCharacterCategory(cp, values[1]);					
+        } else {
+          String[] codePoints = values[0].split("\\.\\.");
+          int cpFrom = Integer.decode(codePoints[0]).intValue();
+          int cpTo = Integer.decode(codePoints[1]).intValue();
+          
+          for(int i = cpFrom; i <= cpTo; i++){
+            dictionary.putCharacterCategory(i, values[1]);					
+          }
+        }
+      } else {	// Invoke definition
+        String[] values = line.split(" "); // Consecutive space is merged above
+        String characterClassName = values[0];
+        int invoke = Integer.parseInt(values[1]);
+        int group = Integer.parseInt(values[2]);
+        int length = Integer.parseInt(values[3]);
+        dictionary.putInvokeDefinition(characterClassName, invoke, group, length);
+      }
+    }
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryWriter.java
new file mode 100644
index 0000000..2ba42d2
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/ja/util/UnknownDictionaryWriter.java
@@ -0,0 +1,48 @@
+package org.apache.lucene.analysis.ja.util;
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.ja.dict.CharacterDefinition;
+import org.apache.lucene.analysis.ja.dict.UnknownDictionary;
+
+public class UnknownDictionaryWriter extends BinaryDictionaryWriter {
+  private final CharacterDefinitionWriter characterDefinition = new CharacterDefinitionWriter();
+  
+  public UnknownDictionaryWriter(int size) {
+    super(UnknownDictionary.class, size);
+  }
+  
+  @Override
+  public int put(String[] entry) {
+    // Get wordId of current entry
+    int wordId = buffer.position();
+    
+    // Put entry
+    int result = super.put(entry);
+    
+    // Put entry in targetMap
+    int characterId = CharacterDefinition.lookupCharacterClass(entry[0]);
+    addMapping(characterId, wordId);
+    return result;
+  }
+  
+  /**
+   * Put mapping from unicode code point to character class.
+   * 
+   * @param codePoint code point
+   * @param characterClassName character class name
+   */
+  public void putCharacterCategory(int codePoint, String characterClassName) {
+    characterDefinition.putCharacterCategory(codePoint, characterClassName);
+  }
+  
+  public void putInvokeDefinition(String characterClassName, int invoke, int group, int length) {
+    characterDefinition.putInvokeDefinition(characterClassName, invoke, group, length);
+  }
+  
+  @Override
+  public void write(String baseDir) throws IOException {
+    super.write(baseDir);
+    characterDefinition.write(baseDir);
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/BinaryDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/BinaryDictionaryWriter.java
deleted file mode 100644
index eee0603..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/BinaryDictionaryWriter.java
+++ /dev/null
@@ -1,316 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.nio.ByteBuffer;
-import java.nio.channels.Channels;
-import java.nio.channels.WritableByteChannel;
-import java.util.ArrayList;
-
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.store.OutputStreamDataOutput;
-import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.CodecUtil;
-
-import org.apache.lucene.analysis.kuromoji.dict.BinaryDictionary;
-
-public abstract class BinaryDictionaryWriter {
-  protected final Class<? extends BinaryDictionary> implClazz;
-  protected ByteBuffer buffer;
-  private int targetMapEndOffset = 0, lastWordId = -1, lastSourceId = -1;
-  private int[] targetMap = new int[8192];
-  private int[] targetMapOffsets = new int[8192];
-  private final ArrayList<String> posDict = new ArrayList<String>();
-
-  public BinaryDictionaryWriter(Class<? extends BinaryDictionary> implClazz, int size) {
-    this.implClazz = implClazz;
-    buffer = ByteBuffer.allocate(size);
-  }
-  
-  /**
-   * put the entry in map
-   * @return current position of buffer, which will be wordId of next entry
-   */
-  public int put(String[] entry) {
-    short leftId = Short.parseShort(entry[1]);
-    short rightId = Short.parseShort(entry[2]);
-    short wordCost = Short.parseShort(entry[3]);
-    
-    StringBuilder sb = new StringBuilder();
-    
-    // build up the POS string
-    for (int i = 4; i < 8; i++) {
-      String part = entry[i];
-      assert part.length() > 0;
-      if (!"*".equals(part)) {
-        if (sb.length() > 0) {
-          sb.append('-');
-        }
-        sb.append(part);
-      }
-    }
-    
-    String posData = sb.toString();
-    
-    sb.setLength(0);
-    sb.append(CSVUtil.quoteEscape(posData));
-    sb.append(',');
-    if (!"*".equals(entry[8])) {
-      sb.append(CSVUtil.quoteEscape(entry[8]));
-    }
-    sb.append(',');
-    if (!"*".equals(entry[9])) {
-      sb.append(CSVUtil.quoteEscape(entry[9]));
-    }
-    String fullPOSData = sb.toString();
-    
-    String baseForm = entry[10];
-    String reading = entry[11];
-    String pronunciation = entry[12];
-    
-    // extend buffer if necessary
-    int left = buffer.remaining();
-    // worst case: two short, 3 bytes, and features (all as utf-16)
-    int worstCase = 4 + 3 + 2*(baseForm.length() + reading.length() + pronunciation.length());
-    if (worstCase > left) {
-      ByteBuffer newBuffer = ByteBuffer.allocate(ArrayUtil.oversize(buffer.limit() + worstCase - left, 1));
-      buffer.flip();
-      newBuffer.put(buffer);
-      buffer = newBuffer;
-    }
-
-    int flags = 0;
-    if (!("*".equals(baseForm) || baseForm.equals(entry[0]))) {
-      flags |= BinaryDictionary.HAS_BASEFORM;
-    }
-    if (!reading.equals(toKatakana(entry[0]))) {
-      flags |= BinaryDictionary.HAS_READING;
-    }
-    if (!pronunciation.equals(reading)) {
-      flags |= BinaryDictionary.HAS_PRONUNCIATION;
-    }
-
-    assert leftId == rightId;
-    assert leftId < 4096; // there are still unused bits
-    // add pos mapping
-    int toFill = 1+leftId - posDict.size();
-    for (int i = 0; i < toFill; i++) {
-      posDict.add(null);
-    }
-    
-    String existing = posDict.get(leftId);
-    assert existing == null || existing.equals(fullPOSData);
-    posDict.set(leftId, fullPOSData);
-    
-    buffer.putShort((short)(leftId << 3 | flags));
-    buffer.putShort(wordCost);
-
-    if ((flags & BinaryDictionary.HAS_BASEFORM) != 0) {
-      assert baseForm.length() < 16;
-      int shared = sharedPrefix(entry[0], baseForm);
-      int suffix = baseForm.length() - shared;
-      buffer.put((byte) (shared << 4 | suffix));
-      for (int i = shared; i < baseForm.length(); i++) {
-        buffer.putChar(baseForm.charAt(i));
-      }
-    }
-    
-    if ((flags & BinaryDictionary.HAS_READING) != 0) {
-      if (isKatakana(reading)) {
-        buffer.put((byte) (reading.length() << 1 | 1));
-        writeKatakana(reading);
-      } else {
-        buffer.put((byte) (reading.length() << 1));
-        for (int i = 0; i < reading.length(); i++) {
-          buffer.putChar(reading.charAt(i));
-        }
-      }
-    }
-    
-    if ((flags & BinaryDictionary.HAS_PRONUNCIATION) != 0) {
-      // we can save 150KB here, but it makes the reader a little complicated.
-      // int shared = sharedPrefix(reading, pronunciation);
-      // buffer.put((byte) shared);
-      // pronunciation = pronunciation.substring(shared);
-      if (isKatakana(pronunciation)) {
-        buffer.put((byte) (pronunciation.length() << 1 | 1));
-        writeKatakana(pronunciation);
-      } else {
-        buffer.put((byte) (pronunciation.length() << 1));
-        for (int i = 0; i < pronunciation.length(); i++) {
-          buffer.putChar(pronunciation.charAt(i));
-        }
-      }
-    }
-    
-    return buffer.position();
-  }
-  
-  private boolean isKatakana(String s) {
-    for (int i = 0; i < s.length(); i++) {
-      char ch = s.charAt(i);
-      if (ch < 0x30A0 || ch > 0x30FF) {
-        return false;
-      }
-    }
-    return true;
-  }
-  
-  private void writeKatakana(String s) {
-    for (int i = 0; i < s.length(); i++) {
-      buffer.put((byte) (s.charAt(i) - 0x30A0));
-    }
-  }
-  
-  private String toKatakana(String s) {
-    char text[] = new char[s.length()];
-    for (int i = 0; i < s.length(); i++) {
-      char ch = s.charAt(i);
-      if (ch > 0x3040 && ch < 0x3097) {
-        text[i] = (char)(ch + 0x60);
-      } else {
-        text[i] = ch;
-      }
-    }
-    return new String(text);
-  }
-  
-  public static int sharedPrefix(String left, String right) {
-    int len = left.length() < right.length() ? left.length() : right.length();
-    for (int i = 0; i < len; i++)
-      if (left.charAt(i) != right.charAt(i))
-        return i;
-    return len;
-  }
-  
-  public void addMapping(int sourceId, int wordId) {
-    assert wordId > lastWordId : "words out of order: " + wordId + " vs lastID: " + lastWordId;
-    
-    if (sourceId > lastSourceId) {
-      assert sourceId > lastSourceId : "source ids out of order: lastSourceId=" + lastSourceId + " vs sourceId=" + sourceId;
-      targetMapOffsets = ArrayUtil.grow(targetMapOffsets, sourceId + 1);
-      for (int i = lastSourceId + 1; i <= sourceId; i++) {
-        targetMapOffsets[i] = targetMapEndOffset;
-      }
-    } else {
-      assert sourceId == lastSourceId;
-    }
-
-    targetMap = ArrayUtil.grow(targetMap, targetMapEndOffset + 1);
-    targetMap[targetMapEndOffset] = wordId;
-    targetMapEndOffset++;
-
-    lastSourceId = sourceId;
-    lastWordId = wordId;
-  }
-
-  protected final String getBaseFileName(String baseDir) throws IOException {
-    return baseDir + File.separator + implClazz.getName().replace('.', File.separatorChar);
-  }
-  
-  /**
-   * Write dictionary in file
-   * Dictionary format is:
-   * [Size of dictionary(int)], [entry:{left id(short)}{right id(short)}{word cost(short)}{length of pos info(short)}{pos info(char)}], [entry...], [entry...].....
-   * @throws IOException
-   */
-  public void write(String baseDir) throws IOException {
-    final String baseName = getBaseFileName(baseDir);
-    writeDictionary(baseName + BinaryDictionary.DICT_FILENAME_SUFFIX);
-    writeTargetMap(baseName + BinaryDictionary.TARGETMAP_FILENAME_SUFFIX);
-    writePosDict(baseName + BinaryDictionary.POSDICT_FILENAME_SUFFIX);
-  }
-  
-  // TODO: maybe this int[] should instead be the output to the FST...
-  protected void writeTargetMap(String filename) throws IOException {
-    new File(filename).getParentFile().mkdirs();
-    OutputStream os = new FileOutputStream(filename);
-    try {
-      os = new BufferedOutputStream(os);
-      final DataOutput out = new OutputStreamDataOutput(os);
-      CodecUtil.writeHeader(out, BinaryDictionary.TARGETMAP_HEADER, BinaryDictionary.VERSION);
-      
-      final int numSourceIds = lastSourceId + 1;
-      out.writeVInt(targetMapEndOffset); // <-- size of main array
-      out.writeVInt(numSourceIds + 1); // <-- size of offset array (+ 1 more entry)
-      int prev = 0, sourceId = 0;
-      for (int ofs = 0; ofs < targetMapEndOffset; ofs++) {
-        final int val = targetMap[ofs], delta = val - prev;
-        assert delta >= 0;
-        if (ofs == targetMapOffsets[sourceId]) {
-          out.writeVInt((delta << 1) | 0x01);
-          sourceId++;
-        } else {
-          out.writeVInt((delta << 1));
-        }
-        prev += delta;
-      }
-      assert sourceId == numSourceIds : "sourceId:"+sourceId+" != numSourceIds:"+numSourceIds;
-    } finally {
-      os.close();
-    }
-  }
-  
-  protected void writePosDict(String filename) throws IOException {
-    new File(filename).getParentFile().mkdirs();
-    OutputStream os = new FileOutputStream(filename);
-    try {
-      os = new BufferedOutputStream(os);
-      final DataOutput out = new OutputStreamDataOutput(os);
-      CodecUtil.writeHeader(out, BinaryDictionary.POSDICT_HEADER, BinaryDictionary.VERSION);
-      out.writeVInt(posDict.size());
-      for (String s : posDict) {
-        if (s == null) {
-          out.writeByte((byte)0);
-          out.writeByte((byte)0);
-          out.writeByte((byte)0);
-        } else {
-          String data[] = CSVUtil.parse(s);
-          assert data.length == 3 : "malformed pos/inflection: " + s;
-          out.writeString(data[0]);
-          out.writeString(data[1]);
-          out.writeString(data[2]);
-        }
-      }
-    } finally {
-      os.close();
-    }
-  }
-  
-  protected void writeDictionary(String filename) throws IOException {
-    new File(filename).getParentFile().mkdirs();
-    final FileOutputStream os = new FileOutputStream(filename);
-    try {
-      final DataOutput out = new OutputStreamDataOutput(os);
-      CodecUtil.writeHeader(out, BinaryDictionary.DICT_HEADER, BinaryDictionary.VERSION);
-      out.writeVInt(buffer.position());
-      final WritableByteChannel channel = Channels.newChannel(os);
-      // Write Buffer
-      buffer.flip();  // set position to 0, set limit to current position
-      channel.write(buffer);
-      assert buffer.remaining() == 0L;
-    } finally {
-      os.close();
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/CharacterDefinitionWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/CharacterDefinitionWriter.java
deleted file mode 100644
index 0cec85e..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/CharacterDefinitionWriter.java
+++ /dev/null
@@ -1,95 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.util.Arrays;
-
-import org.apache.lucene.analysis.kuromoji.dict.CharacterDefinition;
-
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.store.OutputStreamDataOutput;
-import org.apache.lucene.util.CodecUtil;
-
-public final class CharacterDefinitionWriter {
-
-  private final byte[] characterCategoryMap = new byte[0x10000];
-  
-  private final boolean[] invokeMap = new boolean[CharacterDefinition.CLASS_COUNT];
-  private final boolean[] groupMap = new boolean[CharacterDefinition.CLASS_COUNT];
-    
-  /**
-   * Constructor for building. TODO: remove write access
-   */
-  public CharacterDefinitionWriter() {
-    Arrays.fill(characterCategoryMap, CharacterDefinition.DEFAULT);
-  }
-  
-  /**
-   * Put mapping from unicode code point to character class.
-   * 
-   * @param codePoint
-   *            code point
-   * @param characterClassName character class name
-   */
-  public void putCharacterCategory(int codePoint, String characterClassName) {
-    characterClassName = characterClassName.split(" ")[0]; // use first
-    // category
-    // class
-    
-    // Override Nakaguro
-    if (codePoint == 0x30FB) {
-      characterClassName = "SYMBOL";
-    }
-    characterCategoryMap[codePoint] = CharacterDefinition.lookupCharacterClass(characterClassName);
-  }
-  
-  public void putInvokeDefinition(String characterClassName, int invoke, int group, int length) {
-    final byte characterClass = CharacterDefinition.lookupCharacterClass(characterClassName);
-    invokeMap[characterClass] = invoke == 1;
-    groupMap[characterClass] = group == 1;
-    // TODO: length def ignored
-  }
-  
-  public void write(String baseDir) throws IOException {
-    String filename = baseDir + File.separator +
-      CharacterDefinition.class.getName().replace('.', File.separatorChar) + CharacterDefinition.FILENAME_SUFFIX;
-    new File(filename).getParentFile().mkdirs();
-    OutputStream os = new FileOutputStream(filename);
-    try {
-      os = new BufferedOutputStream(os);
-      final DataOutput out = new OutputStreamDataOutput(os);
-      CodecUtil.writeHeader(out, CharacterDefinition.HEADER, CharacterDefinition.VERSION);
-      out.writeBytes(characterCategoryMap, 0, characterCategoryMap.length);
-      for (int i = 0; i < CharacterDefinition.CLASS_COUNT; i++) {
-        final byte b = (byte) (
-          (invokeMap[i] ? 0x01 : 0x00) | 
-          (groupMap[i] ? 0x02 : 0x00)
-        );
-        out.writeByte(b);
-      }
-    } finally {
-      os.close();
-    }
-  }
-  
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsBuilder.java
deleted file mode 100644
index d8de296..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsBuilder.java
+++ /dev/null
@@ -1,67 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.LineNumberReader;
-import java.nio.charset.Charset;
-import java.nio.charset.CharsetDecoder;
-import java.nio.charset.CodingErrorAction;
-
-public class ConnectionCostsBuilder {
-  
-  private ConnectionCostsBuilder() {
-  }
-  
-  public static ConnectionCostsWriter build(String filename) throws IOException {
-    FileInputStream inputStream = new FileInputStream(filename);
-    Charset cs = Charset.forName("US-ASCII");
-    CharsetDecoder decoder = cs.newDecoder()
-        .onMalformedInput(CodingErrorAction.REPORT)
-        .onUnmappableCharacter(CodingErrorAction.REPORT);
-    InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
-    LineNumberReader lineReader = new LineNumberReader(streamReader);
-    
-    String line = lineReader.readLine();
-    String[] dimensions = line.split("\\s+");
-    
-    assert dimensions.length == 2;
-    
-    int forwardSize = Integer.parseInt(dimensions[0]);
-    int backwardSize = Integer.parseInt(dimensions[1]);
-    
-    assert forwardSize > 0 && backwardSize > 0;
-    
-    ConnectionCostsWriter costs = new ConnectionCostsWriter(forwardSize, backwardSize);
-    
-    while ((line = lineReader.readLine()) != null) {
-      String[] fields = line.split("\\s+");
-      
-      assert fields.length == 3;
-      
-      int forwardId = Integer.parseInt(fields[0]);
-      int backwardId = Integer.parseInt(fields[1]);
-      int cost = Integer.parseInt(fields[2]);
-      
-      costs.add(forwardId, backwardId, cost);
-    }
-    return costs;
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsWriter.java
deleted file mode 100644
index 71866ea..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/ConnectionCostsWriter.java
+++ /dev/null
@@ -1,76 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.OutputStream;
-
-import org.apache.lucene.analysis.kuromoji.dict.ConnectionCosts;
-
-import org.apache.lucene.store.DataOutput;
-import org.apache.lucene.store.OutputStreamDataOutput;
-import org.apache.lucene.util.CodecUtil;
-
-public final class ConnectionCostsWriter {
-  
-  private final short[][] costs; // array is backward IDs first since get is called using the same backward ID consecutively. maybe doesn't matter.
-  private final int forwardSize;
-  private final int backwardSize;
-  /**
-   * Constructor for building. TODO: remove write access
-   */
-  public ConnectionCostsWriter(int forwardSize, int backwardSize) {
-    this.forwardSize = forwardSize;
-    this.backwardSize = backwardSize;
-    this.costs = new short[backwardSize][forwardSize];
-  }
-  
-  public void add(int forwardId, int backwardId, int cost) {
-    this.costs[backwardId][forwardId] = (short)cost;
-  }
-  
-  public void write(String baseDir) throws IOException {
-    String filename = baseDir + File.separator +
-      ConnectionCosts.class.getName().replace('.', File.separatorChar) + ConnectionCosts.FILENAME_SUFFIX;
-    new File(filename).getParentFile().mkdirs();
-    OutputStream os = new FileOutputStream(filename);
-    try {
-      os = new BufferedOutputStream(os);
-      final DataOutput out = new OutputStreamDataOutput(os);
-      CodecUtil.writeHeader(out, ConnectionCosts.HEADER, ConnectionCosts.VERSION);
-      out.writeVInt(forwardSize);
-      out.writeVInt(backwardSize);
-      int last = 0;
-      assert costs.length == backwardSize;
-      for (short[] a : costs) {
-        assert a.length == forwardSize;
-        for (int i = 0; i < a.length; i++) {
-          int delta = (int)a[i] - last;
-          out.writeVInt((delta >> 31) ^ (delta << 1));
-          last = a[i];
-        }
-      }
-    } finally {
-      os.close();
-    }
-  }
-  
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/DictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/DictionaryBuilder.java
deleted file mode 100644
index 91b52b0..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/DictionaryBuilder.java
+++ /dev/null
@@ -1,85 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.File;
-import java.io.IOException;
-
-public class DictionaryBuilder {
-  
-  public enum DictionaryFormat { IPADIC, UNIDIC };
-  
-  private DictionaryBuilder() {
-  }
-  
-  public static void build(DictionaryFormat format,
-      String inputDirname,
-      String outputDirname,
-      String encoding,
-      boolean normalizeEntry) throws IOException {
-    System.out.println("building tokeninfo dict...");
-    TokenInfoDictionaryBuilder tokenInfoBuilder = new TokenInfoDictionaryBuilder(format, encoding, normalizeEntry);    
-    TokenInfoDictionaryWriter tokenInfoDictionary = tokenInfoBuilder.build(inputDirname);
-    tokenInfoDictionary.write(outputDirname);
-    tokenInfoDictionary = null;
-    tokenInfoBuilder = null;
-    System.out.println("done");
-    
-    System.out.print("building unknown word dict...");
-    UnknownDictionaryBuilder unkBuilder = new UnknownDictionaryBuilder(encoding);
-    UnknownDictionaryWriter unkDictionary = unkBuilder.build(inputDirname);
-    unkDictionary.write(outputDirname);
-    unkDictionary = null;
-    unkBuilder = null;
-    System.out.println("done");
-    
-    System.out.print("building connection costs...");
-    ConnectionCostsWriter connectionCosts
-      = ConnectionCostsBuilder.build(inputDirname + File.separator + "matrix.def");
-    connectionCosts.write(outputDirname);
-    System.out.println("done");
-  }
-  
-  public static void main(String[] args) throws IOException, ClassNotFoundException {
-    DictionaryFormat format;
-    if (args[0].equalsIgnoreCase("ipadic")) {
-      format = DictionaryFormat.IPADIC;
-    } else if (args[0].equalsIgnoreCase("unidic")) {
-      format = DictionaryFormat.UNIDIC;
-    } else {
-      System.err.println("Illegal format " + args[0] + " using unidic instead");
-      format = DictionaryFormat.IPADIC;
-    }
-    
-    String inputDirname = args[1];
-    String outputDirname = args[2];
-    String inputEncoding = args[3];
-    boolean normalizeEntries = Boolean.parseBoolean(args[4]);
-    
-    System.out.println("dictionary builder");
-    System.out.println("");
-    System.out.println("dictionary format: " + format);
-    System.out.println("input directory: " + inputDirname);
-    System.out.println("output directory: " + outputDirname);
-    System.out.println("input encoding: " + inputEncoding);
-    System.out.println("normalize entries: " + normalizeEntries);
-    System.out.println("");
-    DictionaryBuilder.build(format, inputDirname, outputDirname, inputEncoding, normalizeEntries);
-  }
-  
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryBuilder.java
deleted file mode 100644
index ef1bf3d..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryBuilder.java
+++ /dev/null
@@ -1,227 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FilenameFilter;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.nio.charset.Charset;
-import java.nio.charset.CharsetDecoder;
-import java.nio.charset.CodingErrorAction;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.List;
-
-import org.apache.lucene.analysis.kuromoji.util.DictionaryBuilder.DictionaryFormat;
-import org.apache.lucene.util.IntsRef;
-import org.apache.lucene.util.fst.Builder;
-import org.apache.lucene.util.fst.FST;
-import org.apache.lucene.util.fst.PositiveIntOutputs;
-
-import com.ibm.icu.text.Normalizer2;
-
-/**
- */
-public class TokenInfoDictionaryBuilder {
-  
-  /** Internal word id - incrementally assigned as entries are read and added. This will be byte offset of dictionary file */
-  private int offset = 0;
-  
-  private String encoding = "euc-jp";
-  
-  private boolean normalizeEntries = false;
-  private Normalizer2 normalizer;
-  
-  private DictionaryFormat format = DictionaryFormat.IPADIC;
-  
-  public TokenInfoDictionaryBuilder(DictionaryFormat format, String encoding, boolean normalizeEntries) {
-    this.format = format;
-    this.encoding = encoding;
-    this.normalizeEntries = normalizeEntries;
-    this.normalizer = normalizeEntries ? Normalizer2.getInstance(null, "nfkc", Normalizer2.Mode.COMPOSE) : null;
-  }
-  
-  public TokenInfoDictionaryWriter build(String dirname) throws IOException {
-    FilenameFilter filter = new FilenameFilter() {
-      @Override
-      public boolean accept(File dir, String name) {
-        return name.endsWith(".csv");
-      }
-    };
-    ArrayList<File> csvFiles = new ArrayList<File>();
-    for (File file : new File(dirname).listFiles(filter)) {
-      csvFiles.add(file);
-    }
-    Collections.sort(csvFiles);
-    return buildDictionary(csvFiles);
-  }
-
-  public TokenInfoDictionaryWriter buildDictionary(List<File> csvFiles) throws IOException {
-    TokenInfoDictionaryWriter dictionary = new TokenInfoDictionaryWriter(10 * 1024 * 1024);
-    
-    // all lines in the file
-    System.out.println("  parse...");
-    List<String[]> lines = new ArrayList<String[]>(400000);
-    for (File file : csvFiles){
-      FileInputStream inputStream = new FileInputStream(file);
-      Charset cs = Charset.forName(encoding);
-      CharsetDecoder decoder = cs.newDecoder()
-          .onMalformedInput(CodingErrorAction.REPORT)
-          .onUnmappableCharacter(CodingErrorAction.REPORT);
-      InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
-      BufferedReader reader = new BufferedReader(streamReader);
-      
-      String line = null;
-      while ((line = reader.readLine()) != null) {
-        String[] entry = CSVUtil.parse(line);
-
-        if(entry.length < 13) {
-          System.out.println("Entry in CSV is not valid: " + line);
-          continue;
-        }
-        
-        String[] formatted = formatEntry(entry);
-        lines.add(formatted);
-        
-        // NFKC normalize dictionary entry
-        if (normalizeEntries) {
-          if (normalizer.isNormalized(entry[0])){
-            continue;
-          }
-          String[] normalizedEntry = new String[entry.length];
-          for (int i = 0; i < entry.length; i++) {
-            normalizedEntry[i] = normalizer.normalize(entry[i]);
-          }
-          
-          formatted = formatEntry(normalizedEntry);
-          lines.add(formatted);
-        }
-      }
-    }
-    
-    System.out.println("  sort...");
-
-    // sort by term: we sorted the files already and use a stable sort.
-    Collections.sort(lines, new Comparator<String[]>() {
-      public int compare(String[] left, String[] right) {
-        return left[0].compareTo(right[0]);
-      }
-    });
-    
-    System.out.println("  encode...");
-
-    PositiveIntOutputs fstOutput = PositiveIntOutputs.getSingleton(true);
-    Builder<Long> fstBuilder = new Builder<Long>(FST.INPUT_TYPE.BYTE2, 0, 0, true, true, Integer.MAX_VALUE, fstOutput, null, true);
-    IntsRef scratch = new IntsRef();
-    long ord = -1; // first ord will be 0
-    String lastValue = null;
-
-    // build tokeninfo dictionary
-    for (String[] entry : lines) {
-      int next = dictionary.put(entry);
-        
-      if(next == offset){
-        System.out.println("Failed to process line: " + Arrays.toString(entry));
-        continue;
-      }
-      
-      String token = entry[0];
-      if (!token.equals(lastValue)) {
-        // new word to add to fst
-        ord++;
-        lastValue = token;
-        scratch.grow(token.length());
-        scratch.length = token.length();
-        for (int i = 0; i < token.length(); i++) {
-          scratch.ints[i] = (int) token.charAt(i);
-        }
-        fstBuilder.add(scratch, ord);
-      }
-      dictionary.addMapping((int)ord, offset);
-      offset = next;
-    }
-    
-    final FST<Long> fst = fstBuilder.finish().pack(2, 100000);
-    
-    System.out.print("  " + fst.getNodeCount() + " nodes, " + fst.getArcCount() + " arcs, " + fst.sizeInBytes() + " bytes...  ");
-    dictionary.setFST(fst);
-    System.out.println(" done");
-    
-    return dictionary;
-  }
-  
-  /*
-   * IPADIC features
-   * 
-   * 0	- surface
-   * 1	- left cost
-   * 2	- right cost
-   * 3	- word cost
-   * 4-9	- pos
-   * 10	- base form
-   * 11	- reading
-   * 12	- pronounciation
-   *
-   * UniDic features
-   * 
-   * 0	- surface
-   * 1	- left cost
-   * 2	- right cost
-   * 3	- word cost
-   * 4-9	- pos
-   * 10	- base form reading
-   * 11	- base form
-   * 12	- surface form
-   * 13	- surface reading
-   */
-  
-  public String[] formatEntry(String[] features) {
-    if (this.format == DictionaryFormat.IPADIC) {
-      return features;
-    } else {
-      String[] features2 = new String[13];
-      features2[0] = features[0];
-      features2[1] = features[1];
-      features2[2] = features[2];
-      features2[3] = features[3];
-      features2[4] = features[4];
-      features2[5] = features[5];
-      features2[6] = features[6];
-      features2[7] = features[7];
-      features2[8] = features[8];
-      features2[9] = features[9];
-      features2[10] = features[11];
-      
-      // If the surface reading is non-existent, use surface form for reading and pronunciation.
-      // This happens with punctuation in UniDic and there are possibly other cases as well
-      if (features[13].length() == 0) {
-        features2[11] = features[0];
-        features2[12] = features[0];
-      } else {
-        features2[11] = features[13];
-        features2[12] = features[13];
-      }			
-      return features2;
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryWriter.java
deleted file mode 100644
index 9fdad0b..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/TokenInfoDictionaryWriter.java
+++ /dev/null
@@ -1,48 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.File;
-import java.io.IOException;
-
-import org.apache.lucene.analysis.kuromoji.dict.TokenInfoDictionary;
-import org.apache.lucene.util.fst.FST;
-
-public class TokenInfoDictionaryWriter extends BinaryDictionaryWriter {
-  private FST<Long> fst;
-
-  public TokenInfoDictionaryWriter(int size) {
-    super(TokenInfoDictionary.class, size);
-  }
-  
-  public void setFST(FST<Long> fst) {
-    this.fst = fst;
-  }
-  
-  @Override
-  public void write(String baseDir) throws IOException {
-    super.write(baseDir);
-    writeFST(getBaseFileName(baseDir) + TokenInfoDictionary.FST_FILENAME_SUFFIX);
-  }
-  
-  protected void writeFST(String filename) throws IOException {
-    File f = new File(filename);
-    f.getParentFile().mkdirs();
-    fst.save(f);
-  }  
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryBuilder.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryBuilder.java
deleted file mode 100644
index 838a614..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryBuilder.java
+++ /dev/null
@@ -1,135 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStreamReader;
-import java.io.LineNumberReader;
-import java.nio.charset.Charset;
-import java.nio.charset.CharsetDecoder;
-import java.nio.charset.CodingErrorAction;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
-import java.util.List;
-
-import org.apache.lucene.analysis.kuromoji.dict.CharacterDefinition;
-
-public class UnknownDictionaryBuilder {
-  private static final String NGRAM_DICTIONARY_ENTRY = "NGRAM,5,5,-32768,??,???,*,*,*,*,*,*,*";
-  
-  private String encoding = "euc-jp";
-  
-  public UnknownDictionaryBuilder(String encoding) {
-    this.encoding = encoding;
-  }
-  
-  public UnknownDictionaryWriter build(String dirname) throws IOException {
-    UnknownDictionaryWriter unkDictionary = readDictionaryFile(dirname + File.separator + "unk.def");  //Should be only one file
-    readCharacterDefinition(dirname + File.separator + "char.def", unkDictionary);
-    return unkDictionary;
-  }
-  
-  public UnknownDictionaryWriter readDictionaryFile(String filename)
-      throws IOException {
-    return readDictionaryFile(filename, encoding);
-  }
-  
-  public UnknownDictionaryWriter readDictionaryFile(String filename, String encoding)
-      throws IOException {
-    UnknownDictionaryWriter dictionary = new UnknownDictionaryWriter(5 * 1024 * 1024);
-    
-    FileInputStream inputStream = new FileInputStream(filename);
-    Charset cs = Charset.forName(encoding);
-    CharsetDecoder decoder = cs.newDecoder()
-        .onMalformedInput(CodingErrorAction.REPORT)
-        .onUnmappableCharacter(CodingErrorAction.REPORT);
-    InputStreamReader streamReader = new InputStreamReader(inputStream, decoder);
-    LineNumberReader lineReader = new LineNumberReader(streamReader);
-    
-    dictionary.put(CSVUtil.parse(NGRAM_DICTIONARY_ENTRY));
-    
-    List<String[]> lines = new ArrayList<String[]>();
-    String line = null;
-    while ((line = lineReader.readLine()) != null) {
-      // note: unk.def only has 10 fields, it simplifies the writer to just append empty reading and pronunciation,
-      // even though the unknown dictionary returns hardcoded null here.
-      final String[] parsed = CSVUtil.parse(line + ",*,*"); // Probably we don't need to validate entry
-      lines.add(parsed);
-    }
-    
-    Collections.sort(lines, new Comparator<String[]>() {
-      public int compare(String[] left, String[] right) {
-        int leftId = CharacterDefinition.lookupCharacterClass(left[0]);
-        int rightId = CharacterDefinition.lookupCharacterClass(right[0]);
-        return leftId - rightId;
-      }
-    });
-    
-    for (String[] entry : lines) {
-      dictionary.put(entry);
-    }
-    
-    return dictionary;
-  }
-  
-  public void readCharacterDefinition(String filename, UnknownDictionaryWriter dictionary) throws IOException {
-    FileInputStream inputStream = new FileInputStream(filename);
-    InputStreamReader streamReader = new InputStreamReader(inputStream, encoding);
-    LineNumberReader lineReader = new LineNumberReader(streamReader);
-    
-    String line = null;
-    
-    while ((line = lineReader.readLine()) != null) {
-      line = line.replaceAll("^\\s", "");
-      line = line.replaceAll("\\s*#.*", "");
-      line = line.replaceAll("\\s+", " ");
-      
-      // Skip empty line or comment line
-      if(line.length() == 0) {
-        continue;
-      }
-      
-      if(line.startsWith("0x")) {	// Category mapping
-        String[] values = line.split(" ", 2);	// Split only first space
-        
-        if(!values[0].contains("..")) {
-          int cp = Integer.decode(values[0]).intValue();
-          dictionary.putCharacterCategory(cp, values[1]);					
-        } else {
-          String[] codePoints = values[0].split("\\.\\.");
-          int cpFrom = Integer.decode(codePoints[0]).intValue();
-          int cpTo = Integer.decode(codePoints[1]).intValue();
-          
-          for(int i = cpFrom; i <= cpTo; i++){
-            dictionary.putCharacterCategory(i, values[1]);					
-          }
-        }
-      } else {	// Invoke definition
-        String[] values = line.split(" "); // Consecutive space is merged above
-        String characterClassName = values[0];
-        int invoke = Integer.parseInt(values[1]);
-        int group = Integer.parseInt(values[2]);
-        int length = Integer.parseInt(values[3]);
-        dictionary.putInvokeDefinition(characterClassName, invoke, group, length);
-      }
-    }
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryWriter.java b/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryWriter.java
deleted file mode 100644
index a63b35c..0000000
--- a/modules/analysis/kuromoji/src/tools/java/org/apache/lucene/analysis/kuromoji/util/UnknownDictionaryWriter.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.util;
-
-import java.io.File;
-import java.io.IOException;
-
-import org.apache.lucene.analysis.kuromoji.dict.CharacterDefinition;
-import org.apache.lucene.analysis.kuromoji.dict.BinaryDictionary;
-import org.apache.lucene.analysis.kuromoji.dict.UnknownDictionary;
-
-public class UnknownDictionaryWriter extends BinaryDictionaryWriter {
-  private final CharacterDefinitionWriter characterDefinition = new CharacterDefinitionWriter();
-  
-  public UnknownDictionaryWriter(int size) {
-    super(UnknownDictionary.class, size);
-  }
-  
-  @Override
-  public int put(String[] entry) {
-    // Get wordId of current entry
-    int wordId = buffer.position();
-    
-    // Put entry
-    int result = super.put(entry);
-    
-    // Put entry in targetMap
-    int characterId = CharacterDefinition.lookupCharacterClass(entry[0]);
-    addMapping(characterId, wordId);
-    return result;
-  }
-  
-  /**
-   * Put mapping from unicode code point to character class.
-   * 
-   * @param codePoint code point
-   * @param characterClassName character class name
-   */
-  public void putCharacterCategory(int codePoint, String characterClassName) {
-    characterDefinition.putCharacterCategory(codePoint, characterClassName);
-  }
-  
-  public void putInvokeDefinition(String characterClassName, int invoke, int group, int length) {
-    characterDefinition.putInvokeDefinition(characterClassName, invoke, group, length);
-  }
-  
-  @Override
-  public void write(String baseDir) throws IOException {
-    super.write(baseDir);
-    characterDefinition.write(baseDir);
-  }
-}
diff --git a/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/ja/dict/UnknownDictionaryTest.java b/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/ja/dict/UnknownDictionaryTest.java
new file mode 100644
index 0000000..ef8878f
--- /dev/null
+++ b/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/ja/dict/UnknownDictionaryTest.java
@@ -0,0 +1,75 @@
+package org.apache.lucene.analysis.ja.dict;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.ja.util.CSVUtil;
+import org.apache.lucene.analysis.ja.util.UnknownDictionaryWriter;
+import org.apache.lucene.util.LuceneTestCase;
+import org.junit.Test;
+
+public class UnknownDictionaryTest extends LuceneTestCase {
+  public static final String FILENAME = "unk-tokeninfo-dict.obj";
+  
+  @Test
+  public void testPutCharacterCategory() {
+    UnknownDictionaryWriter unkDic = new UnknownDictionaryWriter(10 * 1024 * 1024);
+    
+    try{
+      unkDic.putCharacterCategory(0, "DUMMY_NAME");
+      fail();
+    } catch(Exception e) {
+      
+    }
+    
+    try{
+      unkDic.putCharacterCategory(-1, "KATAKANA");
+      fail();
+    } catch(Exception e) {
+      
+    }
+    
+    unkDic.putCharacterCategory(0, "DEFAULT");
+    unkDic.putCharacterCategory(1, "GREEK");
+    unkDic.putCharacterCategory(2, "HIRAGANA");
+    unkDic.putCharacterCategory(3, "KATAKANA");
+    unkDic.putCharacterCategory(4, "KANJI");
+  }
+  
+  @Test
+  public void testPut() {
+    UnknownDictionaryWriter unkDic = new UnknownDictionaryWriter(10 * 1024 * 1024);
+    try{
+      unkDic.put(CSVUtil.parse("KANJI,1285,11426,???,???,*,*,*,*,*,*,*"));
+      fail();
+    } catch(Exception e){
+      
+    }
+
+    String entry1 = "ALPHA,1285,1285,13398,???,???,*,*,*,*,*,*,*";
+    String entry2 = "HIRAGANA,1285,1285,13069,???,???,*,*,*,*,*,*,*";
+    String entry3 = "KANJI,1285,1285,11426,???,???,*,*,*,*,*,*,*";
+
+    unkDic.putCharacterCategory(0, "ALPHA");
+    unkDic.putCharacterCategory(1, "HIRAGANA");
+    unkDic.putCharacterCategory(2, "KANJI");
+    
+    unkDic.put(CSVUtil.parse(entry1));
+    unkDic.put(CSVUtil.parse(entry2));
+    unkDic.put(CSVUtil.parse(entry3));
+  }
+}
diff --git a/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionaryTest.java b/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionaryTest.java
deleted file mode 100644
index 66b820f..0000000
--- a/modules/analysis/kuromoji/src/tools/test/org/apache/lucene/analysis/kuromoji/dict/UnknownDictionaryTest.java
+++ /dev/null
@@ -1,75 +0,0 @@
-package org.apache.lucene.analysis.kuromoji.dict;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.kuromoji.util.CSVUtil;
-import org.apache.lucene.analysis.kuromoji.util.UnknownDictionaryWriter;
-import org.apache.lucene.util.LuceneTestCase;
-import org.junit.Test;
-
-public class UnknownDictionaryTest extends LuceneTestCase {
-  public static final String FILENAME = "unk-tokeninfo-dict.obj";
-  
-  @Test
-  public void testPutCharacterCategory() {
-    UnknownDictionaryWriter unkDic = new UnknownDictionaryWriter(10 * 1024 * 1024);
-    
-    try{
-      unkDic.putCharacterCategory(0, "DUMMY_NAME");
-      fail();
-    } catch(Exception e) {
-      
-    }
-    
-    try{
-      unkDic.putCharacterCategory(-1, "KATAKANA");
-      fail();
-    } catch(Exception e) {
-      
-    }
-    
-    unkDic.putCharacterCategory(0, "DEFAULT");
-    unkDic.putCharacterCategory(1, "GREEK");
-    unkDic.putCharacterCategory(2, "HIRAGANA");
-    unkDic.putCharacterCategory(3, "KATAKANA");
-    unkDic.putCharacterCategory(4, "KANJI");
-  }
-  
-  @Test
-  public void testPut() {
-    UnknownDictionaryWriter unkDic = new UnknownDictionaryWriter(10 * 1024 * 1024);
-    try{
-      unkDic.put(CSVUtil.parse("KANJI,1285,11426,???,???,*,*,*,*,*,*,*"));
-      fail();
-    } catch(Exception e){
-      
-    }
-
-    String entry1 = "ALPHA,1285,1285,13398,???,???,*,*,*,*,*,*,*";
-    String entry2 = "HIRAGANA,1285,1285,13069,???,???,*,*,*,*,*,*,*";
-    String entry3 = "KANJI,1285,1285,11426,???,???,*,*,*,*,*,*,*";
-
-    unkDic.putCharacterCategory(0, "ALPHA");
-    unkDic.putCharacterCategory(1, "HIRAGANA");
-    unkDic.putCharacterCategory(2, "KANJI");
-    
-    unkDic.put(CSVUtil.parse(entry1));
-    unkDic.put(CSVUtil.parse(entry2));
-    unkDic.put(CSVUtil.parse(entry3));
-  }
-}
diff --git a/solr/build.xml b/solr/build.xml
index bcac007..11e99a5 100644
--- a/solr/build.xml
+++ b/solr/build.xml
@@ -694,9 +694,9 @@
     <copy verbose="true" file="${analysis-common.res.dir}/snowball/italian_stop.txt"
                          tofile="${analysis.conf.dest}/stopwords_it.txt"/>
     <!-- japanese -->
-    <copy verbose="true" file="${analysis-kuromoji.res.dir}/kuromoji/stopwords.txt" 
+    <copy verbose="true" file="${analysis-kuromoji.res.dir}/ja/stopwords.txt"
                          tofile="${analysis.conf.dest}/stopwords_ja.txt"/>
-    <copy verbose="true" file="${analysis-kuromoji.res.dir}/kuromoji/stoptags.txt" 
+    <copy verbose="true" file="${analysis-kuromoji.res.dir}/ja/stoptags.txt"
                          tofile="${analysis.conf.dest}/stoptags_ja.txt"/>
   	<!-- latvian -->
     <copy verbose="true" file="${analysis-common.res.dir}/lv/stopwords.txt"
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java
new file mode 100644
index 0000000..1d36622
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/JapaneseBaseFormFilterFactory.java
@@ -0,0 +1,40 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseBaseFormFilter;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseBaseFormFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseBaseFormFilterFactory extends BaseTokenFilterFactory {
+
+  @Override
+  public TokenStream create(TokenStream input) {
+    return new JapaneseBaseFormFilter(input);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java
new file mode 100644
index 0000000..b0ae992
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/JapaneseKatakanaStemFilterFactory.java
@@ -0,0 +1,55 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseKatakanaStemFilter;
+import org.apache.solr.common.SolrException;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link JapaneseKatakanaStemFilterFactory}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseKatakanaStemFilterFactory"
+ *             minimumLength="4"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseKatakanaStemFilterFactory extends BaseTokenFilterFactory {
+  private static final String MINIMUM_LENGTH_PARAM = "minimumLength";
+  private int minimumLength;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    minimumLength = getInt(MINIMUM_LENGTH_PARAM, JapaneseKatakanaStemFilter.DEFAULT_MINIMUM_LENGTH);
+    if (minimumLength < 2) {
+      throw new SolrException(SolrException.ErrorCode.UNKNOWN,
+                              "Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
+    }
+  }
+
+  public TokenStream create(TokenStream input) {
+    return new JapaneseKatakanaStemFilter(input, minimumLength);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java
new file mode 100644
index 0000000..27d93f2
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/JapanesePartOfSpeechStopFilterFactory.java
@@ -0,0 +1,65 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter;
+import org.apache.lucene.analysis.util.CharArraySet;
+import org.apache.solr.common.ResourceLoader;
+import org.apache.solr.util.plugin.ResourceLoaderAware;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapanesePartOfSpeechStopFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapanesePartOfSpeechStopFilterFactory"
+ *             tags="stopTags.txt" 
+ *             enablePositionIncrements="true"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapanesePartOfSpeechStopFilterFactory extends BaseTokenFilterFactory implements ResourceLoaderAware  {
+  private boolean enablePositionIncrements;
+  private Set<String> stopTags;
+
+  public void inform(ResourceLoader loader) {
+    String stopTagFiles = args.get("tags");
+    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
+    try {
+      CharArraySet cas = getWordSet(loader, stopTagFiles, false);
+      stopTags = new HashSet<String>();
+      for (Object element : cas) {
+        char chars[] = (char[]) element;
+        stopTags.add(new String(chars));
+      }
+    } catch (IOException e) {
+      throw new RuntimeException(e);
+    }
+  }
+
+  public TokenStream create(TokenStream stream) {
+    return new JapanesePartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java
new file mode 100644
index 0000000..7b99c71
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/JapaneseReadingFormFilterFactory.java
@@ -0,0 +1,50 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.ja.JapaneseReadingFormFilter;
+
+import java.util.Map;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseReadingFormFilter}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.JapaneseReadingFormFilterFactory"
+ *             useRomaji="false"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseReadingFormFilterFactory extends BaseTokenFilterFactory {
+  private static final String ROMAJI_PARAM = "useRomaji";
+  private boolean useRomaji;
+  
+  @Override
+  public void init(Map<String, String> args) {
+    super.init(args);
+    useRomaji = getBoolean(ROMAJI_PARAM, false);
+  }
+
+  public TokenStream create(TokenStream input) {
+    return new JapaneseReadingFormFilter(input, useRomaji);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java
new file mode 100644
index 0000000..55be4d6
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/JapaneseTokenizerFactory.java
@@ -0,0 +1,100 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.Reader;
+import java.nio.charset.Charset;
+import java.nio.charset.CharsetDecoder;
+import java.nio.charset.CodingErrorAction;
+import java.util.Locale;
+import java.util.Map;
+
+import org.apache.lucene.analysis.Tokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer;
+import org.apache.lucene.analysis.ja.JapaneseTokenizer.Mode;
+import org.apache.lucene.analysis.ja.dict.UserDictionary;
+import org.apache.lucene.util.IOUtils;
+import org.apache.solr.common.ResourceLoader;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.util.plugin.ResourceLoaderAware;
+
+/**
+ * Factory for {@link org.apache.lucene.analysis.ja.JapaneseTokenizer}.
+ * <pre class="prettyprint">
+ * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.JapaneseTokenizerFactory"
+ *       mode=NORMAL
+ *       user-dictionary=user.txt
+ *       user-dictionary-encoding=UTF-8
+ *     /&gt;
+ *     &lt;filter class="solr.JapaneseBaseFormFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;
+ * </pre>
+ */
+public class JapaneseTokenizerFactory extends BaseTokenizerFactory implements ResourceLoaderAware {
+  private static final String MODE = "mode";
+  
+  private static final String USER_DICT_PATH = "user-dictionary";
+  
+  private static final String USER_DICT_ENCODING = "user-dictionary-encoding";
+
+  private UserDictionary userDictionary;
+  private Mode mode;
+  
+  @Override
+  public void inform(ResourceLoader loader) {
+    mode = getMode(args);
+    String userDictionaryPath = args.get(USER_DICT_PATH);
+    try {
+      if (userDictionaryPath != null) {
+        InputStream stream = loader.openResource(userDictionaryPath);
+        String encoding = args.get(USER_DICT_ENCODING);
+        if (encoding == null) {
+          encoding = IOUtils.UTF_8;
+        }
+        CharsetDecoder decoder = Charset.forName(encoding).newDecoder()
+            .onMalformedInput(CodingErrorAction.REPORT)
+            .onUnmappableCharacter(CodingErrorAction.REPORT);
+        Reader reader = new InputStreamReader(stream, decoder);
+        userDictionary = new UserDictionary(reader);
+      } else {
+        userDictionary = null;
+      }
+    } catch (Exception e) {
+      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);
+    }
+  }
+  
+  @Override
+  public Tokenizer create(Reader input) {
+    return new JapaneseTokenizer(input, userDictionary, true, mode);
+  }
+  
+  private Mode getMode(Map<String, String> args) {
+    String mode = args.get(MODE);
+    if (mode != null) {
+      return Mode.valueOf(mode.toUpperCase(Locale.ENGLISH));
+    } else {
+      return JapaneseTokenizer.DEFAULT_MODE;
+    }
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KuromojiBaseFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KuromojiBaseFormFilterFactory.java
deleted file mode 100644
index b87dcec..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KuromojiBaseFormFilterFactory.java
+++ /dev/null
@@ -1,40 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.kuromoji.KuromojiBaseFormFilter;
-
-/**
- * Factory for {@link KuromojiBaseFormFilter}.  
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KuromojiTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KuromojiBaseFormFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class KuromojiBaseFormFilterFactory extends BaseTokenFilterFactory {
-
-  @Override
-  public TokenStream create(TokenStream input) {
-    return new KuromojiBaseFormFilter(input);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KuromojiKatakanaStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KuromojiKatakanaStemFilterFactory.java
deleted file mode 100644
index f174816..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KuromojiKatakanaStemFilterFactory.java
+++ /dev/null
@@ -1,55 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.kuromoji.KuromojiKatakanaStemFilter;
-import org.apache.solr.common.SolrException;
-
-import java.util.Map;
-
-/**
- * Factory for {@link KuromojiKatakanaStemFilterFactory}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KuromojiTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KuromojiKatakanaStemFilterFactory"
- *             minimumLength="4"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class KuromojiKatakanaStemFilterFactory extends BaseTokenFilterFactory {
-  private static final String MINIMUM_LENGTH_PARAM = "minimumLength";
-  private int minimumLength;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    minimumLength = getInt(MINIMUM_LENGTH_PARAM, KuromojiKatakanaStemFilter.DEFAULT_MINIMUM_LENGTH);
-    if (minimumLength < 2) {
-      throw new SolrException(SolrException.ErrorCode.UNKNOWN,
-                              "Illegal " + MINIMUM_LENGTH_PARAM + " " + minimumLength + " (must be 2 or greater)");
-    }
-  }
-
-  public TokenStream create(TokenStream input) {
-    return new KuromojiKatakanaStemFilter(input, minimumLength);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KuromojiPartOfSpeechStopFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KuromojiPartOfSpeechStopFilterFactory.java
deleted file mode 100644
index 9ac566e..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KuromojiPartOfSpeechStopFilterFactory.java
+++ /dev/null
@@ -1,65 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.kuromoji.KuromojiPartOfSpeechStopFilter;
-import org.apache.lucene.analysis.util.CharArraySet;
-import org.apache.solr.common.ResourceLoader;
-import org.apache.solr.util.plugin.ResourceLoaderAware;
-
-/**
- * Factory for {@link KuromojiPartOfSpeechStopFilter}.  
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KuromojiTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KuromojiPartOfSpeechStopFilterFactory" 
- *             tags="stopTags.txt" 
- *             enablePositionIncrements="true"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class KuromojiPartOfSpeechStopFilterFactory extends BaseTokenFilterFactory implements ResourceLoaderAware  {
-  private boolean enablePositionIncrements;
-  private Set<String> stopTags;
-
-  public void inform(ResourceLoader loader) {
-    String stopTagFiles = args.get("tags");
-    enablePositionIncrements = getBoolean("enablePositionIncrements", false);
-    try {
-      CharArraySet cas = getWordSet(loader, stopTagFiles, false);
-      stopTags = new HashSet<String>();
-      for (Object element : cas) {
-        char chars[] = (char[]) element;
-        stopTags.add(new String(chars));
-      }
-    } catch (IOException e) {
-      throw new RuntimeException(e);
-    }
-  }
-
-  public TokenStream create(TokenStream stream) {
-    return new KuromojiPartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KuromojiReadingFormFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/KuromojiReadingFormFilterFactory.java
deleted file mode 100644
index c947937..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KuromojiReadingFormFilterFactory.java
+++ /dev/null
@@ -1,50 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.analysis.TokenStream;
-import org.apache.lucene.analysis.kuromoji.KuromojiReadingFormFilter;
-
-import java.util.Map;
-
-/**
- * Factory for {@link KuromojiReadingFormFilter}.
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KuromojiTokenizerFactory"/&gt;
- *     &lt;filter class="solr.KuromojiReadingFormFilterFactory"
- *             useRomaji="false"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class KuromojiReadingFormFilterFactory extends BaseTokenFilterFactory {
-  private static final String ROMAJI_PARAM = "useRomaji";
-  private boolean useRomaji;
-  
-  @Override
-  public void init(Map<String, String> args) {
-    super.init(args);
-    useRomaji = getBoolean(ROMAJI_PARAM, false);
-  }
-
-  public TokenStream create(TokenStream input) {
-    return new KuromojiReadingFormFilter(input, useRomaji);
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/analysis/KuromojiTokenizerFactory.java b/solr/core/src/java/org/apache/solr/analysis/KuromojiTokenizerFactory.java
deleted file mode 100644
index 6ec97f7..0000000
--- a/solr/core/src/java/org/apache/solr/analysis/KuromojiTokenizerFactory.java
+++ /dev/null
@@ -1,101 +0,0 @@
-package org.apache.solr.analysis;
-
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.Reader;
-import java.nio.charset.Charset;
-import java.nio.charset.CharsetDecoder;
-import java.nio.charset.CodingErrorAction;
-import java.util.Locale;
-import java.util.Map;
-
-import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer;
-import org.apache.lucene.analysis.kuromoji.KuromojiTokenizer.Mode;
-import org.apache.lucene.analysis.kuromoji.dict.UserDictionary;
-import org.apache.lucene.util.IOUtils;
-import org.apache.solr.analysis.BaseTokenizerFactory;
-import org.apache.solr.common.ResourceLoader;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.util.plugin.ResourceLoaderAware;
-
-/**
- * Factory for {@link KuromojiTokenizer}.  
- * <pre class="prettyprint">
- * &lt;fieldType name="text_ja" class="solr.TextField"&gt;
- *   &lt;analyzer&gt;
- *     &lt;tokenizer class="solr.KuromojiTokenizerFactory"
- *       mode=NORMAL
- *       user-dictionary=user.txt
- *       user-dictionary-encoding=UTF-8
- *     /&gt;
- *     &lt;filter class="solr.KuromojiBaseFormFilterFactory"/&gt;
- *   &lt;/analyzer&gt;
- * &lt;/fieldType&gt;
- * </pre>
- */
-public class KuromojiTokenizerFactory extends BaseTokenizerFactory implements ResourceLoaderAware {
-  private static final String MODE = "mode";
-  
-  private static final String USER_DICT_PATH = "user-dictionary";
-  
-  private static final String USER_DICT_ENCODING = "user-dictionary-encoding";
-
-  private UserDictionary userDictionary;
-  private Mode mode;
-  
-  @Override
-  public void inform(ResourceLoader loader) {
-    mode = getMode(args);
-    String userDictionaryPath = args.get(USER_DICT_PATH);
-    try {
-      if (userDictionaryPath != null) {
-        InputStream stream = loader.openResource(userDictionaryPath);
-        String encoding = args.get(USER_DICT_ENCODING);
-        if (encoding == null) {
-          encoding = IOUtils.UTF_8;
-        }
-        CharsetDecoder decoder = Charset.forName(encoding).newDecoder()
-            .onMalformedInput(CodingErrorAction.REPORT)
-            .onUnmappableCharacter(CodingErrorAction.REPORT);
-        Reader reader = new InputStreamReader(stream, decoder);
-        userDictionary = new UserDictionary(reader);
-      } else {
-        userDictionary = null;
-      }
-    } catch (Exception e) {
-      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);
-    }
-  }
-  
-  @Override
-  public Tokenizer create(Reader input) {
-    return new KuromojiTokenizer(input, userDictionary, true, mode);
-  }
-  
-  private Mode getMode(Map<String, String> args) {
-    String mode = args.get(MODE);
-    if (mode != null) {
-      return Mode.valueOf(mode.toUpperCase(Locale.ENGLISH));
-    } else {
-      return KuromojiTokenizer.DEFAULT_MODE;
-    }
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiBaseFormFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiBaseFormFilterFactory.java
index db176a5..0489921 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiBaseFormFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiBaseFormFilterFactory.java
@@ -24,15 +24,15 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.solr.core.SolrResourceLoader;
 
 /**
- * Simple tests for {@link KuromojiBaseFormFilterFactory}
+ * Simple tests for {@link JapaneseBaseFormFilterFactory}
  */
 public class TestKuromojiBaseFormFilterFactory extends BaseTokenTestCase {
   public void testBasics() throws IOException {
-    KuromojiTokenizerFactory tokenizerFactory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
     tokenizerFactory.init(DEFAULT_VERSION_PARAM);
     tokenizerFactory.inform(new SolrResourceLoader(null, null));
     TokenStream ts = tokenizerFactory.create(new StringReader("???????????????????"));
-    KuromojiBaseFormFilterFactory factory = new KuromojiBaseFormFilterFactory();
+    JapaneseBaseFormFilterFactory factory = new JapaneseBaseFormFilterFactory();
     ts = factory.create(ts);
     assertTokenStreamContents(ts,
         new String[] { "???", "??", "??", "??", "?", "??", "???", "??"  }
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiPartOfSpeechStopFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiPartOfSpeechStopFilterFactory.java
index ebaec12..016c08a 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiPartOfSpeechStopFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiPartOfSpeechStopFilterFactory.java
@@ -34,11 +34,11 @@ public class TestKuromojiPartOfSpeechStopFilterFactory extends BaseTokenTestCase
         "#  verb-main:\n" +
         "???-???\n";
     
-    KuromojiTokenizerFactory tokenizerFactory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory tokenizerFactory = new JapaneseTokenizerFactory();
     tokenizerFactory.init(DEFAULT_VERSION_PARAM);
     tokenizerFactory.inform(new SolrResourceLoader(null, null));
     TokenStream ts = tokenizerFactory.create(new StringReader("????????????????"));
-    KuromojiPartOfSpeechStopFilterFactory factory = new KuromojiPartOfSpeechStopFilterFactory();
+    JapanesePartOfSpeechStopFilterFactory factory = new JapanesePartOfSpeechStopFilterFactory();
     Map<String,String> args = new HashMap<String,String>();
     args.put("luceneMatchVersion", TEST_VERSION_CURRENT.toString());
     args.put("tags", "stoptags.txt");
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiTokenizerFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiTokenizerFactory.java
index 740a3e0..a55e3fe 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestKuromojiTokenizerFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestKuromojiTokenizerFactory.java
@@ -26,11 +26,11 @@ import org.apache.lucene.analysis.TokenStream;
 import org.apache.solr.core.SolrResourceLoader;
 
 /**
- * Simple tests for {@link KuromojiTokenizerFactory}
+ * Simple tests for {@link JapaneseTokenizerFactory}
  */
 public class TestKuromojiTokenizerFactory extends BaseTokenTestCase {
   public void testSimple() throws IOException {
-    KuromojiTokenizerFactory factory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
     factory.init(DEFAULT_VERSION_PARAM);
     factory.inform(new SolrResourceLoader(null, null));
     TokenStream ts = factory.create(new StringReader("???????????"));
@@ -45,7 +45,7 @@ public class TestKuromojiTokenizerFactory extends BaseTokenTestCase {
    * Test that search mode is enabled and working by default
    */
   public void testDefaults() throws IOException {
-    KuromojiTokenizerFactory factory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
     factory.init(DEFAULT_VERSION_PARAM);
     factory.inform(new SolrResourceLoader(null, null));
     TokenStream ts = factory.create(new StringReader("???????????????????"));
@@ -58,7 +58,7 @@ public class TestKuromojiTokenizerFactory extends BaseTokenTestCase {
    * Test mode parameter: specifying normal mode
    */
   public void testMode() throws IOException {
-    KuromojiTokenizerFactory factory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
     Map<String,String> args = new HashMap<String,String>();
     args.put("mode", "normal");
     factory.init(args);
@@ -76,7 +76,7 @@ public class TestKuromojiTokenizerFactory extends BaseTokenTestCase {
         "???,? ?? ,????? ???? ?????,???????n" +
         "# Custom reading for sumo wrestler\n" +
         "????,????,??????????,??????\n";
-    KuromojiTokenizerFactory factory = new KuromojiTokenizerFactory();
+    JapaneseTokenizerFactory factory = new JapaneseTokenizerFactory();
     Map<String,String> args = new HashMap<String,String>();
     args.put("user-dictionary", "userdict.txt");
     factory.init(args);
diff --git a/solr/example/solr/conf/schema.xml b/solr/example/solr/conf/schema.xml
index b6776b8..abc40e1 100755
--- a/solr/example/solr/conf/schema.xml
+++ b/solr/example/solr/conf/schema.xml
@@ -725,17 +725,17 @@
 
            NOTE: Search-mode improves segmentation for search at the expense of part-of-speech and reading accuracy
         -->
-        <tokenizer class="solr.KuromojiTokenizerFactory" mode="search"/>
+        <tokenizer class="solr.JapaneseTokenizerFactory" mode="search"/>
         <!-- Reduces inflected verbs and adjectives to their base/dictionary forms (???) -->	
-        <filter class="solr.KuromojiBaseFormFilterFactory"/>
+        <filter class="solr.JapaneseBaseFormFilterFactory"/>
         <!-- Removes tokens with certain part-of-speech tags -->
-        <filter class="solr.KuromojiPartOfSpeechStopFilterFactory" tags="lang/stoptags_ja.txt" enablePositionIncrements="true"/>
+        <filter class="solr.JapanesePartOfSpeechStopFilterFactory" tags="lang/stoptags_ja.txt" enablePositionIncrements="true"/>
         <!-- Normalizes full-width romaji to half-width and half-width kana to full-width (Unicode NFKC subset) -->
         <filter class="solr.CJKWidthFilterFactory"/>
         <!-- Removes common tokens typically not useful for search, but have a negative effect on ranking -->
         <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_ja.txt" enablePositionIncrements="true" />
         <!-- Normalizes common katakana spelling variations by removing any last long sound character (U+30FC) -->
-        <filter class="solr.KuromojiKatakanaStemFilterFactory" minimumLength="4"/>
+        <filter class="solr.JapaneseKatakanaStemFilterFactory" minimumLength="4"/>
         <!-- Lower-cases romaji characters -->
         <filter class="solr.LowerCaseFilterFactory"/>
       </analyzer>

