GitDiffStart: ef809a0f10e78aec3f97c878f90ff74673f98745 | Wed Dec 31 14:05:48 2014 +0000
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 3cffe2e..fb9e473 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -132,6 +132,9 @@ Upgrading from Solr 4.x
   discovery are now resolved relative to SOLR_HOME, rather than cwd.  See
   SOLR-6718.
 
+* SolrServer and associated classes have been deprecated.  Applications using
+  SolrJ should use the equivalent SolrClient classes instead.
+
 Detailed Change List
 ----------------------
 
@@ -182,7 +185,7 @@ New Features
 * SOLR-6485: ReplicationHandler should have an option to throttle the speed of
   replication (Varun Thacker, NOble Paul)
 
-* SOLR-6543: Give HttpSolrServer the ability to send PUT requests (Gregory Chanan)
+* SOLR-6543: Give HttpSolrClient the ability to send PUT requests (Gregory Chanan)
 
 * SOLR-5986: Don't allow runaway queries from harming Solr cluster health or search 
   performance (Anshum Gupta, Steve Rowe, Robert Muir)
@@ -208,7 +211,7 @@ New Features
 * SOLR-6617: /update/json/docs path will use fully qualified node names by default
              (Noble Paul)
 
-* SOLR-4715: Add CloudSolrServer constructors which accept a HttpClient instance.
+* SOLR-4715: Add CloudSolrClient constructors which accept a HttpClient instance.
   (Hardik Upadhyay, Shawn Heisey, shalin)
 
 * SOLR-5992: add "removeregex" as an atomic update operation
@@ -290,7 +293,7 @@ Bug Fixes
   NOTE: This does NOT fixed for the (deprecated) facet.date idiom, use facet.range
   instead. (Erick Erickson, Zaccheo Bagnati, Ronald Matamoros, Vamsee Yalargadda)
 
-* SOLR-6457: LBHttpSolrServer: ArrayIndexOutOfBoundsException risk if counter overflows
+* SOLR-6457: LBHttpSolrClient: ArrayIndexOutOfBoundsException risk if counter overflows
   (longkey via Noble Paul)
 
 * SOLR-6499: Log warning about multiple update request handlers
@@ -376,7 +379,7 @@ Bug Fixes
 Optimizations
 ----------------------
 
-* SOLR-6603: LBHttpSolrServer - lazily allocate skipped-zombie-servers list.
+* SOLR-6603: LBHttpSolrClient - lazily allocate skipped-zombie-servers list.
   (Christine Poerschke via shalin)
 
 * SOLR-6554: Speed up overseer operations avoiding cluster state reads from
@@ -420,8 +423,8 @@ Other Changes
 * LUCENE-5650: Tests can no longer write to CWD. Update log dir is now made relative
   to the instance dir if it is not an absolute path. (Ryan Ernst, Dawid Weiss)
 
-* SOLR-6390: Remove unnecessary checked exception for CloudSolrServer
-  constructors, improve javadocs for CloudSolrServer constructors.
+* SOLR-6390: Remove unnecessary checked exception for CloudSolrClient
+  constructors, improve javadocs for CloudSolrClient constructors.
   (Steve Davids via Shawn Heisey)
 
 * LUCENE-5901: Replaced all occurences of LUCENE_CURRENT with LATEST for luceneMatchVersion.
@@ -457,7 +460,7 @@ Other Changes
 * SOLR-6597: SolrIndexConfig parameter in one of the SolrIndexSearcher constructor has been removed.
   It was just passed and never used via that constructor. (Anshum Gupta)
 
-* SOLR-5852: Add CloudSolrServer helper method to connect to a ZK ensemble. (Varun Thacker, Furkan KAMACI,
+* SOLR-5852: Add CloudSolrClient helper method to connect to a ZK ensemble. (Varun Thacker, Furkan KAMACI,
   Shawn Heisey, Mark Miller, Erick Erickson via shalin)
 
 * SOLR-6592: Avoid waiting for the leader to see the down state if that leader is not live.
@@ -542,7 +545,7 @@ Other Changes
 * SOLR-6826: fieldType capitalization is not consistent with the rest of case-sensitive field names.
   (Alexandre Rafalovitch via Erick Erickson)
 
-* SOLR-6849: HttpSolrServer.RemoteSolrException reports the URL of the remote
+* SOLR-6849: HttpSolrClient.RemoteSolrException reports the URL of the remote
   host where the exception occurred. (Alan Woodward)
 
 * SOLR-6852: SimplePostTool no longer defaults to collection1 making core/collection/update URL
@@ -584,6 +587,9 @@ Other Changes
 
 * Fixed a typo in various solrconfig.xml files.  (sdumitriu - pull request #120)
 
+* SOLR-6895: SolrServer classes are renamed to *SolrClient.  The existing
+  classes still exist, but are deprecated. (Alan Woodward, Erik Hatcher)
+
 ==================  4.10.3 ==================
 
 Bug Fixes
diff --git a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
index 33bb0b7..a0aab81 100644
--- a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
+++ b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/SolrEntityProcessor.java
@@ -19,10 +19,10 @@ package org.apache.solr.handler.dataimport;
 
 import org.apache.http.client.HttpClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
@@ -64,7 +64,7 @@ public class SolrEntityProcessor extends EntityProcessorBase {
   public static final int TIMEOUT_SECS = 5 * 60; // 5 minutes
   public static final int ROWS_DEFAULT = 50;
   
-  private SolrServer solrServer = null;
+  private SolrClient solrClient = null;
   private String queryString;
   private int rows = ROWS_DEFAULT;
   private String[] filterQueries;
@@ -100,11 +100,11 @@ public class SolrEntityProcessor extends EntityProcessorBase {
       // (wt="javabin|xml") default is javabin
       if ("xml".equals(context.getResolvedEntityAttribute(CommonParams.WT))) {
         // TODO: it doesn't matter for this impl when passing a client currently, but we should close this!
-        solrServer = new HttpSolrServer(url.toExternalForm(), client, new XMLResponseParser());
+        solrClient = new HttpSolrClient(url.toExternalForm(), client, new XMLResponseParser());
         LOG.info("using XMLResponseParser");
       } else {
         // TODO: it doesn't matter for this impl when passing a client currently, but we should close this!
-        solrServer = new HttpSolrServer(url.toExternalForm(), client);
+        solrClient = new HttpSolrClient(url.toExternalForm(), client);
         LOG.info("using BinaryResponseParser");
       }
     } catch (MalformedURLException e) {
@@ -184,7 +184,7 @@ public class SolrEntityProcessor extends EntityProcessorBase {
     
     QueryResponse response = null;
     try {
-      response = solrServer.query(solrQuery);
+      response = solrClient.query(solrQuery);
     } catch (SolrServerException e) {
       if (ABORT.equals(onError)) {
         wrapAndThrow(SEVERE, e);
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
index 3c92c29..946b73c 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestContentStreamDataSource.java
@@ -21,7 +21,7 @@ import java.util.List;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.DirectXmlRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
@@ -67,7 +67,7 @@ public class TestContentStreamDataSource extends AbstractDataImportHandlerTestCa
     params.set("command", "full-import");
     params.set("clean", "false");
     req.setParams(params);
-    HttpSolrServer solrServer = new HttpSolrServer(buildUrl(jetty.getLocalPort(), "/solr"));
+    HttpSolrClient solrServer = new HttpSolrClient(buildUrl(jetty.getLocalPort(), "/solr"));
     solrServer.request(req);
     ModifiableSolrParams qparams = new ModifiableSolrParams();
     qparams.add("q", "*:*");
@@ -87,7 +87,7 @@ public class TestContentStreamDataSource extends AbstractDataImportHandlerTestCa
         "clean", "false", UpdateParams.COMMIT, "false", 
         UpdateParams.COMMIT_WITHIN, "1000");
     req.setParams(params);
-    HttpSolrServer solrServer = new HttpSolrServer(buildUrl(jetty.getLocalPort(), "/solr"));
+    HttpSolrClient solrServer = new HttpSolrClient(buildUrl(jetty.getLocalPort(), "/solr"));
     solrServer.request(req);
     Thread.sleep(100);
     ModifiableSolrParams queryAll = params("q", "*");
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
index 55483f5..82ceaab 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestSolrEntityProcessorEndToEnd.java
@@ -27,10 +27,9 @@ import java.util.Map.Entry;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.common.SolrInputDocument;
 import org.junit.After;
 import org.junit.AfterClass;
@@ -281,7 +280,7 @@ public class TestSolrEntityProcessorEndToEnd extends AbstractDataImportHandlerTe
       sidl.add(sd);
     }
     
-    HttpSolrServer solrServer = new HttpSolrServer(getSourceUrl());
+    HttpSolrClient solrServer = new HttpSolrClient(getSourceUrl());
     try {
       solrServer.setConnectionTimeout(15000);
       solrServer.setSoTimeout(30000);
diff --git a/solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive.java b/solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive.java
index 6eddb9b..b7d26eb 100644
--- a/solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive.java
+++ b/solr/contrib/map-reduce/src/java/org/apache/solr/hadoop/GoLive.java
@@ -33,8 +33,8 @@ import java.util.concurrent.TimeUnit;
 
 import org.apache.hadoop.fs.FileStatus;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.hadoop.MapReduceIndexerTool.Options;
 import org.slf4j.Logger;
@@ -91,7 +91,7 @@ class GoLive {
             public Request call() {
               Request req = new Request();
               LOG.info("Live merge " + dir.getPath() + " into " + mergeUrl);
-              final HttpSolrServer server = new HttpSolrServer(mergeUrl);
+              final HttpSolrClient server = new HttpSolrClient(mergeUrl);
               try {
                 CoreAdminRequest.MergeIndexes mergeRequest = new CoreAdminRequest.MergeIndexes();
                 mergeRequest.setCoreName(name);
@@ -149,7 +149,7 @@ class GoLive {
       try {
         LOG.info("Committing live merge...");
         if (options.zkHost != null) {
-          CloudSolrServer server = new CloudSolrServer(options.zkHost);
+          CloudSolrClient server = new CloudSolrClient(options.zkHost);
           server.setDefaultCollection(options.collection);
           server.commit();
           server.shutdown();
@@ -157,7 +157,7 @@ class GoLive {
           for (List<String> urls : options.shardUrls) {
             for (String url : urls) {
               // TODO: we should do these concurrently
-              HttpSolrServer server = new HttpSolrServer(url);
+              HttpSolrClient server = new HttpSolrClient(url);
               server.commit();
               server.shutdown();
             }
diff --git a/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java b/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java
index b49d940..c43586c 100644
--- a/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java
+++ b/solr/contrib/map-reduce/src/test/org/apache/solr/hadoop/MorphlineGoLiveMiniMRTest.java
@@ -49,10 +49,10 @@ import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrQuery.ORDER;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
@@ -383,7 +383,7 @@ public class MorphlineGoLiveMiniMRTest extends AbstractFullDistribZkTestBase {
     MapReduceIndexerTool tool;
     int res;
     QueryResponse results;
-    HttpSolrServer server = new HttpSolrServer(cloudJettys.get(0).url);
+    HttpSolrClient server = new HttpSolrClient(cloudJettys.get(0).url);
     String[] args = new String[]{};
 
     args = new String[] {
@@ -699,7 +699,7 @@ public class MorphlineGoLiveMiniMRTest extends AbstractFullDistribZkTestBase {
     }
   }
   
-  private SolrDocumentList executeSolrQuery(SolrServer collection, String queryString) throws SolrServerException {
+  private SolrDocumentList executeSolrQuery(SolrClient collection, String queryString) throws SolrServerException {
     SolrQuery query = new SolrQuery(queryString).setRows(2 * RECORD_COUNT).addSort("id", ORDER.asc);
     QueryResponse response = collection.query(query);
     return response.getResults();
@@ -713,7 +713,7 @@ public class MorphlineGoLiveMiniMRTest extends AbstractFullDistribZkTestBase {
       Collection<Replica> replicas = slice.getReplicas();
       long found = -1;
       for (Replica replica : replicas) {
-        HttpSolrServer client = new HttpSolrServer(
+        HttpSolrClient client = new HttpSolrClient(
             new ZkCoreNodeProps(replica).getCoreUrl());
         SolrQuery query = new SolrQuery("*:*");
         query.set("distrib", false);
diff --git a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrClient.java b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrClient.java
new file mode 100644
index 0000000..5a98e13
--- /dev/null
+++ b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrClient.java
@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.morphlines.solr;
+
+import org.apache.http.client.HttpClient;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * ConcurrentUpdateSolrServer that propagates exceptions up to the submitter of
+ * requests on blockUntilFinished()
+ */
+final class SafeConcurrentUpdateSolrClient extends ConcurrentUpdateSolrClient {
+
+  private Throwable currentException = null;
+  private final Object myLock = new Object();
+
+  private static final Logger LOGGER = LoggerFactory.getLogger(SafeConcurrentUpdateSolrClient.class);
+
+  public SafeConcurrentUpdateSolrClient(String solrServerUrl, int queueSize, int threadCount) {
+    this(solrServerUrl, null, queueSize, threadCount);
+  }
+
+  public SafeConcurrentUpdateSolrClient(String solrServerUrl, HttpClient client, int queueSize, int threadCount) {
+    super(solrServerUrl, client, queueSize, threadCount);
+  }
+
+  @Override
+  public void handleError(Throwable ex) {
+    assert ex != null;
+    synchronized (myLock) {
+      currentException = ex;
+    }
+    LOGGER.error("handleError", ex);
+  }
+
+  @Override
+  public void blockUntilFinished() {
+    super.blockUntilFinished();
+    synchronized (myLock) {
+      if (currentException != null) {
+        throw new RuntimeException(currentException);
+      }
+    }
+  }
+
+  public void clearException() {
+    synchronized (myLock) {
+      currentException = null;
+    }
+  }
+
+}
diff --git a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrServer.java b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrServer.java
deleted file mode 100644
index f98eeb2..0000000
--- a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SafeConcurrentUpdateSolrServer.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.solr.morphlines.solr;
-
-import org.apache.http.client.HttpClient;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * ConcurrentUpdateSolrServer that propagates exceptions up to the submitter of
- * requests on blockUntilFinished()
- */
-final class SafeConcurrentUpdateSolrServer extends ConcurrentUpdateSolrServer {
-
-  private Throwable currentException = null;
-  private final Object myLock = new Object();
-
-  private static final Logger LOGGER = LoggerFactory.getLogger(SafeConcurrentUpdateSolrServer.class);
-
-  public SafeConcurrentUpdateSolrServer(String solrServerUrl, int queueSize, int threadCount) {
-    this(solrServerUrl, null, queueSize, threadCount);
-  }
-
-  public SafeConcurrentUpdateSolrServer(String solrServerUrl, HttpClient client, int queueSize, int threadCount) {
-    super(solrServerUrl, client, queueSize, threadCount);
-  }
-
-  @Override
-  public void handleError(Throwable ex) {
-    assert ex != null;
-    synchronized (myLock) {
-      currentException = ex;
-    }
-    LOGGER.error("handleError", ex);
-  }
-
-  @Override
-  public void blockUntilFinished() {
-    super.blockUntilFinished();
-    synchronized (myLock) {
-      if (currentException != null) {
-        throw new RuntimeException(currentException);
-      }
-    }
-  }
-
-  public void clearException() {
-    synchronized (myLock) {
-      currentException = null;
-    }
-  }
-
-}
diff --git a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrClientDocumentLoader.java b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrClientDocumentLoader.java
new file mode 100644
index 0000000..d9c8cc3
--- /dev/null
+++ b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrClientDocumentLoader.java
@@ -0,0 +1,123 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.morphlines.solr;
+
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.apache.solr.client.solrj.response.SolrPingResponse;
+import org.apache.solr.client.solrj.response.UpdateResponse;
+import org.apache.solr.common.SolrInputDocument;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * A vehicle to load a list of Solr documents into a local or remote {@link org.apache.solr.client.solrj.SolrClient}.
+ */
+public class SolrClientDocumentLoader implements DocumentLoader {
+
+  private final SolrClient client; // proxy to local or remote solr server
+  private long numLoadedDocs = 0; // number of documents loaded in the current transaction
+  private final int batchSize;
+  private final List<SolrInputDocument> batch = new ArrayList();
+
+  private static final Logger LOGGER = LoggerFactory.getLogger(SolrClientDocumentLoader.class);
+
+  public SolrClientDocumentLoader(SolrClient client, int batchSize) {
+    if (client == null) {
+      throw new IllegalArgumentException("solr server must not be null");
+    }
+    this.client = client;
+    if (batchSize <= 0) {
+      throw new IllegalArgumentException("batchSize must be a positive number: " + batchSize);      
+    }
+    this.batchSize = batchSize;
+  }
+  
+  @Override
+  public void beginTransaction() {
+    LOGGER.trace("beginTransaction");
+    batch.clear();
+    numLoadedDocs = 0;
+    if (client instanceof SafeConcurrentUpdateSolrClient) {
+      ((SafeConcurrentUpdateSolrClient) client).clearException();
+    }
+  }
+
+  @Override
+  public void load(SolrInputDocument doc) throws IOException, SolrServerException {
+    LOGGER.trace("load doc: {}", doc);
+    batch.add(doc);
+    if (batch.size() >= batchSize) {
+      loadBatch();
+    }
+  }
+
+  @Override
+  public void commitTransaction() throws SolrServerException, IOException {
+    LOGGER.trace("commitTransaction");
+    if (batch.size() > 0) {
+      loadBatch();
+    }
+    if (numLoadedDocs > 0) {
+      if (client instanceof ConcurrentUpdateSolrClient) {
+        ((ConcurrentUpdateSolrClient) client).blockUntilFinished();
+      }
+    }
+  }
+
+  private void loadBatch() throws SolrServerException, IOException {
+    numLoadedDocs += batch.size();
+    try {
+      UpdateResponse rsp = client.add(batch);
+    } finally {
+      batch.clear();
+    }
+  }
+
+  @Override
+  public UpdateResponse rollbackTransaction() throws SolrServerException, IOException {
+    LOGGER.trace("rollback");
+    if (!(client instanceof CloudSolrClient)) {
+      return client.rollback();
+    } else {
+      return new UpdateResponse();
+    }
+  }
+
+  @Override
+  public void shutdown() {
+    LOGGER.trace("shutdown");
+    client.shutdown();
+  }
+
+  @Override
+  public SolrPingResponse ping() throws SolrServerException, IOException {
+    LOGGER.trace("ping");
+    return client.ping();
+  }
+
+  public SolrClient getSolrClient() {
+    return client;
+  }
+
+}
diff --git a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrLocator.java b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrLocator.java
index 3ba79e2..e4f65c4 100644
--- a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrLocator.java
+++ b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrLocator.java
@@ -16,13 +16,14 @@
  */
 package org.apache.solr.morphlines.solr;
 
-import java.io.File;
-import java.io.IOException;
-
-import javax.xml.parsers.ParserConfigurationException;
-
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import com.google.common.base.Preconditions;
+import com.google.common.io.Files;
+import com.typesafe.config.Config;
+import com.typesafe.config.ConfigFactory;
+import com.typesafe.config.ConfigRenderOptions;
+import com.typesafe.config.ConfigUtil;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.common.cloud.SolrZkClient;
 import org.apache.solr.core.SolrConfig;
 import org.apache.solr.core.SolrResourceLoader;
@@ -38,12 +39,9 @@ import org.slf4j.LoggerFactory;
 import org.xml.sax.InputSource;
 import org.xml.sax.SAXException;
 
-import com.google.common.base.Preconditions;
-import com.google.common.io.Files;
-import com.typesafe.config.Config;
-import com.typesafe.config.ConfigFactory;
-import com.typesafe.config.ConfigRenderOptions;
-import com.typesafe.config.ConfigUtil;
+import javax.xml.parsers.ParserConfigurationException;
+import java.io.File;
+import java.io.IOException;
 
 /**
  * Set of configuration parameters that identify the location and schema of a Solr server or
@@ -92,21 +90,21 @@ public class SolrLocator {
       if (collectionName == null || collectionName.length() == 0) {
         throw new MorphlineCompilationException("Parameter 'zkHost' requires that you also pass parameter 'collection'", config);
       }
-      CloudSolrServer cloudSolrServer = new CloudSolrServer(zkHost);
-      cloudSolrServer.setDefaultCollection(collectionName);
-      cloudSolrServer.connect();
-      return new SolrServerDocumentLoader(cloudSolrServer, batchSize);
+      CloudSolrClient cloudSolrClient = new CloudSolrClient(zkHost);
+      cloudSolrClient.setDefaultCollection(collectionName);
+      cloudSolrClient.connect();
+      return new SolrClientDocumentLoader(cloudSolrClient, batchSize);
     } else {
       if (solrUrl == null || solrUrl.length() == 0) {
         throw new MorphlineCompilationException("Missing parameter 'solrUrl'", config);
       }
       int solrServerNumThreads = 2;
       int solrServerQueueLength = solrServerNumThreads;
-      SolrServer server = new SafeConcurrentUpdateSolrServer(solrUrl, solrServerQueueLength, solrServerNumThreads);
+      SolrClient server = new SafeConcurrentUpdateSolrClient(solrUrl, solrServerQueueLength, solrServerNumThreads);
       // SolrServer server = new HttpSolrServer(solrServerUrl);
       // SolrServer server = new ConcurrentUpdateSolrServer(solrServerUrl, solrServerQueueLength, solrServerNumThreads);
       // server.setParser(new XMLResponseParser()); // binary parser is used by default
-      return new SolrServerDocumentLoader(server, batchSize);
+      return new SolrClientDocumentLoader(server, batchSize);
     }
   }
 
diff --git a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrServerDocumentLoader.java b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrServerDocumentLoader.java
index d343230..dc91b29 100644
--- a/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrServerDocumentLoader.java
+++ b/solr/contrib/morphlines-core/src/java/org/apache/solr/morphlines/solr/SolrServerDocumentLoader.java
@@ -14,110 +14,19 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package org.apache.solr.morphlines.solr;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
+package org.apache.solr.morphlines.solr;
 
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.apache.solr.client.solrj.response.SolrPingResponse;
-import org.apache.solr.client.solrj.response.UpdateResponse;
-import org.apache.solr.common.SolrInputDocument;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+import org.apache.solr.client.solrj.SolrClient;
 
 /**
- * A vehicle to load a list of Solr documents into a local or remote {@link SolrServer}.
+ * @deprecated Use {@link org.apache.solr.morphlines.solr.SolrClientDocumentLoader}
  */
-public class SolrServerDocumentLoader implements DocumentLoader {
-
-  private final SolrServer server; // proxy to local or remote solr server
-  private long numLoadedDocs = 0; // number of documents loaded in the current transaction
-  private final int batchSize;
-  private final List<SolrInputDocument> batch = new ArrayList();
-
-  private static final Logger LOGGER = LoggerFactory.getLogger(SolrServerDocumentLoader.class);
-
-  public SolrServerDocumentLoader(SolrServer server, int batchSize) {
-    if (server == null) {
-      throw new IllegalArgumentException("solr server must not be null");
-    }
-    this.server = server;
-    if (batchSize <= 0) {
-      throw new IllegalArgumentException("batchSize must be a positive number: " + batchSize);      
-    }
-    this.batchSize = batchSize;
-  }
-  
-  @Override
-  public void beginTransaction() {
-    LOGGER.trace("beginTransaction");
-    batch.clear();
-    numLoadedDocs = 0;
-    if (server instanceof SafeConcurrentUpdateSolrServer) {
-      ((SafeConcurrentUpdateSolrServer) server).clearException();
-    }
-  }
-
-  @Override
-  public void load(SolrInputDocument doc) throws IOException, SolrServerException {
-    LOGGER.trace("load doc: {}", doc);
-    batch.add(doc);
-    if (batch.size() >= batchSize) {
-      loadBatch();
-    }
-  }
-
-  @Override
-  public void commitTransaction() throws SolrServerException, IOException {
-    LOGGER.trace("commitTransaction");
-    if (batch.size() > 0) {
-      loadBatch();
-    }
-    if (numLoadedDocs > 0) {
-      if (server instanceof ConcurrentUpdateSolrServer) {
-        ((ConcurrentUpdateSolrServer) server).blockUntilFinished();
-      }
-    }
-  }
-
-  private void loadBatch() throws SolrServerException, IOException {
-    numLoadedDocs += batch.size();
-    try {
-      UpdateResponse rsp = server.add(batch);
-    } finally {
-      batch.clear();
-    }
-  }
-
-  @Override
-  public UpdateResponse rollbackTransaction() throws SolrServerException, IOException {
-    LOGGER.trace("rollback");
-    if (!(server instanceof CloudSolrServer)) {
-      return server.rollback();
-    } else {
-      return new UpdateResponse();
-    }
-  }
-
-  @Override
-  public void shutdown() {
-    LOGGER.trace("shutdown");
-    server.shutdown();
-  }
-
-  @Override
-  public SolrPingResponse ping() throws SolrServerException, IOException {
-    LOGGER.trace("ping");
-    return server.ping();
-  }
+@Deprecated
+public class SolrServerDocumentLoader extends SolrClientDocumentLoader {
 
-  public SolrServer getSolrServer() {
-    return server;
+  public SolrServerDocumentLoader(SolrClient client, int batchSize) {
+    super(client, batchSize);
   }
 
 }
diff --git a/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java b/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java
index b5698ae..336f5de 100644
--- a/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java
+++ b/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/AbstractSolrMorphlineTestBase.java
@@ -34,9 +34,9 @@ import java.util.concurrent.atomic.AtomicInteger;
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
@@ -65,7 +65,7 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
   private static Locale savedLocale;
   protected Collector collector;
   protected Command morphline;
-  protected SolrServer solrServer;
+  protected SolrClient solrClient;
   protected DocumentLoader testServer;
   
   protected static final boolean TEST_WITH_EMBEDDED_SOLR_SERVER = true;
@@ -119,19 +119,19 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
     if (EXTERNAL_SOLR_SERVER_URL != null) {
       //solrServer = new ConcurrentUpdateSolrServer(EXTERNAL_SOLR_SERVER_URL, 2, 2);
       //solrServer = new SafeConcurrentUpdateSolrServer(EXTERNAL_SOLR_SERVER_URL, 2, 2);
-      solrServer = new HttpSolrServer(EXTERNAL_SOLR_SERVER_URL);
-      ((HttpSolrServer)solrServer).setParser(new XMLResponseParser());
+      solrClient = new HttpSolrClient(EXTERNAL_SOLR_SERVER_URL);
+      ((HttpSolrClient) solrClient).setParser(new XMLResponseParser());
     } else {
       if (TEST_WITH_EMBEDDED_SOLR_SERVER) {
-        solrServer = new EmbeddedTestSolrServer(h.getCoreContainer(), "");
+        solrClient = new EmbeddedTestSolrServer(h.getCoreContainer(), "");
       } else {
         throw new RuntimeException("Not yet implemented");
-        //solrServer = new TestSolrServer(getSolrServer());
+        //solrServer = new TestSolrServer(getSolrClient());
       }
     }
 
     int batchSize = SEQ_NUM2.incrementAndGet() % 2 == 0 ? 100 : 1; //SolrInspector.DEFAULT_SOLR_SERVER_BATCH_SIZE : 1;
-    testServer = new SolrServerDocumentLoader(solrServer, batchSize);
+    testServer = new SolrClientDocumentLoader(solrClient, batchSize);
     deleteAllDocuments();
     
     tempDir = createTempDir().toFile().getAbsolutePath();
@@ -140,8 +140,8 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
   @After
   public void tearDown() throws Exception {
     collector = null;
-    solrServer.shutdown();
-    solrServer = null;
+    solrClient.shutdown();
+    solrClient = null;
     super.tearDown();
   }
 
@@ -201,8 +201,8 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
 //    return collector.getRecords().size();
     try {
       testServer.commitTransaction();
-      solrServer.commit(false, true, true);
-      QueryResponse rsp = solrServer.query(new SolrQuery(query).setRows(Integer.MAX_VALUE));
+      solrClient.commit(false, true, true);
+      QueryResponse rsp = solrClient.query(new SolrQuery(query).setRows(Integer.MAX_VALUE));
       LOGGER.debug("rsp: {}", rsp);
       int i = 0;
       for (SolrDocument doc : rsp.getResults()) {
@@ -217,7 +217,7 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
   
   private void deleteAllDocuments() throws SolrServerException, IOException {
     collector.reset();
-    SolrServer s = solrServer;
+    SolrClient s = solrClient;
     s.deleteByQuery("*:*"); // delete everything!
     s.commit();
   }
@@ -255,7 +255,7 @@ public class AbstractSolrMorphlineTestBase extends SolrTestCaseJ4 {
 
   protected void testDocumentContent(HashMap<String, ExpectedResult> expectedResultMap)
   throws Exception {
-    QueryResponse rsp = solrServer.query(new SolrQuery("*:*").setRows(Integer.MAX_VALUE));
+    QueryResponse rsp = solrClient.query(new SolrQuery("*:*").setRows(Integer.MAX_VALUE));
     // Check that every expected field/values shows up in the actual query
     for (Entry<String, ExpectedResult> current : expectedResultMap.entrySet()) {
       String field = current.getKey();
diff --git a/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/EmbeddedTestSolrServer.java b/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/EmbeddedTestSolrServer.java
index 39e3fda..3bd5390 100644
--- a/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/EmbeddedTestSolrServer.java
+++ b/solr/contrib/morphlines-core/src/test/org/apache/solr/morphlines/solr/EmbeddedTestSolrServer.java
@@ -16,13 +16,13 @@
  */
 package org.apache.solr.morphlines.solr;
 
-import java.io.IOException;
-
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.response.UpdateResponse;
 import org.apache.solr.core.CoreContainer;
 
+import java.io.IOException;
+
 /**
  * An EmbeddedSolrServer that supresses close and rollback requests as
  * necessary for testing
diff --git a/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java b/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
index f55d3f2..376f08d 100644
--- a/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
+++ b/solr/core/src/java/org/apache/solr/client/solrj/embedded/EmbeddedSolrServer.java
@@ -17,13 +17,8 @@
 
 package org.apache.solr.client.solrj.embedded;
 
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.StreamingResponseCallback;
 import org.apache.solr.common.SolrDocument;
@@ -45,8 +40,13 @@ import org.apache.solr.response.ResultContext;
 import org.apache.solr.response.SolrQueryResponse;
 import org.apache.solr.servlet.SolrRequestParsers;
 
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
 /**
- * SolrServer that connects directly to SolrCore.
+ * SolrClient that connects directly to SolrCore.
  * <p>
  * TODO -- this implementation sends the response to XML and then parses it.  
  * It *should* be able to convert the response directly into a named list.
@@ -54,7 +54,7 @@ import org.apache.solr.servlet.SolrRequestParsers;
  *
  * @since solr 1.3
  */
-public class EmbeddedSolrServer extends SolrServer
+public class EmbeddedSolrServer extends SolrClient
 {
   protected final CoreContainer coreContainer;
   protected final String coreName;
@@ -65,7 +65,7 @@ public class EmbeddedSolrServer extends SolrServer
    * @deprecated use {@link #EmbeddedSolrServer(CoreContainer, String)} instead.
    */
   @Deprecated
-  public EmbeddedSolrServer( SolrCore core )
+  public EmbeddedSolrServer(SolrCore core)
   {
     if ( core == null ) {
       throw new NullPointerException("SolrCore instance required");
@@ -88,7 +88,7 @@ public class EmbeddedSolrServer extends SolrServer
    * @param coreContainer the core container
    * @param coreName the core name
    */
-  public EmbeddedSolrServer(  CoreContainer coreContainer, String coreName )
+  public EmbeddedSolrServer(CoreContainer coreContainer, String coreName)
   {
     if ( coreContainer == null ) {
       throw new NullPointerException("CoreContainer instance required");
diff --git a/solr/core/src/java/org/apache/solr/cloud/LeaderInitiatedRecoveryThread.java b/solr/core/src/java/org/apache/solr/cloud/LeaderInitiatedRecoveryThread.java
index 76fc185..489a52e 100644
--- a/solr/core/src/java/org/apache/solr/cloud/LeaderInitiatedRecoveryThread.java
+++ b/solr/core/src/java/org/apache/solr/cloud/LeaderInitiatedRecoveryThread.java
@@ -1,12 +1,8 @@
 package org.apache.solr.cloud;
 
-import java.net.ConnectException;
-import java.net.SocketException;
-import java.util.List;
-
 import org.apache.http.NoHttpResponseException;
 import org.apache.http.conn.ConnectTimeoutException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.RequestRecovery;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
@@ -18,6 +14,10 @@ import org.apache.solr.core.CoreContainer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.net.ConnectException;
+import java.net.SocketException;
+import java.util.List;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -114,12 +114,12 @@ public class LeaderInitiatedRecoveryThread extends Thread {
         log.info("Asking core={} coreNodeName={} on " + recoveryUrl + " to recover", coreNeedingRecovery, replicaCoreNodeName);
       }
       
-      HttpSolrServer server = new HttpSolrServer(recoveryUrl);
+      HttpSolrClient client = new HttpSolrClient(recoveryUrl);
       try {
-        server.setSoTimeout(60000);
-        server.setConnectionTimeout(15000);
+        client.setSoTimeout(60000);
+        client.setConnectionTimeout(15000);
         try {
-          server.request(recoverRequestCmd);
+          client.request(recoverRequestCmd);
           
           log.info("Successfully sent " + CoreAdminAction.REQUESTRECOVERY +
               " command to core={} coreNodeName={} on " + recoveryUrl, coreNeedingRecovery, replicaCoreNodeName);
@@ -140,7 +140,7 @@ public class LeaderInitiatedRecoveryThread extends Thread {
           }                                                
         }
       } finally {
-        server.shutdown();
+        client.shutdown();
       }
       
       // wait a few seconds
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerAutoReplicaFailoverThread.java b/solr/core/src/java/org/apache/solr/cloud/OverseerAutoReplicaFailoverThread.java
index ab63e04..7e998cd 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerAutoReplicaFailoverThread.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerAutoReplicaFailoverThread.java
@@ -30,7 +30,7 @@ import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.TimeUnit;
 
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Create;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.cloud.ClusterState;
@@ -418,10 +418,10 @@ public class OverseerAutoReplicaFailoverThread implements Runnable, Closeable {
   private boolean createSolrCore(final String collection,
       final String createUrl, final String dataDir, final String ulogDir,
       final String coreNodeName, final String coreName) {
-    HttpSolrServer server = null;
+    HttpSolrClient server = null;
     try {
       log.debug("create url={}", createUrl);
-      server = new HttpSolrServer(createUrl);
+      server = new HttpSolrClient(createUrl);
       server.setConnectionTimeout(30000);
       server.setSoTimeout(60000);
       Create createCmd = new Create();
diff --git a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
index 4943a57..e559f1f 100644
--- a/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
+++ b/solr/core/src/java/org/apache/solr/cloud/OverseerCollectionProcessor.java
@@ -17,53 +17,11 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import static org.apache.solr.cloud.Assign.getNodesForNewShard;
-import static org.apache.solr.common.cloud.ZkStateReader.BASE_URL_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.CORE_NAME_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.ELECTION_NODE_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.NODE_NAME_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.REJOIN_AT_HEAD_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.REPLICA_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_VALUE_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICA;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICAPROP;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDROLE;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.BALANCESHARDUNIQUE;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.CLUSTERSTATUS;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.CREATE;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.CREATESHARD;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETE;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETEREPLICAPROP;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETESHARD;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.REMOVEROLE;
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-
+import com.google.common.collect.ImmutableSet;
 import org.apache.commons.lang.StringUtils;
 import org.apache.solr.client.solrj.SolrResponse;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
@@ -113,7 +71,48 @@ import org.apache.zookeeper.data.Stat;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.google.common.collect.ImmutableSet;
+import java.io.Closeable;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import static org.apache.solr.cloud.Assign.getNodesForNewShard;
+import static org.apache.solr.common.cloud.ZkStateReader.BASE_URL_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.CORE_NAME_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.ELECTION_NODE_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.NODE_NAME_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.PROPERTY_VALUE_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.REJOIN_AT_HEAD_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.REPLICA_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICA;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDREPLICAPROP;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.ADDROLE;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.BALANCESHARDUNIQUE;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.CLUSTERSTATUS;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.CREATE;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.CREATESHARD;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETE;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETEREPLICAPROP;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETESHARD;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.REMOVEROLE;
 
 
 public class OverseerCollectionProcessor implements Runnable, Closeable {
@@ -1802,18 +1801,18 @@ public class OverseerCollectionProcessor implements Runnable, Closeable {
 
 
   static UpdateResponse softCommit(String url) throws SolrServerException, IOException {
-    HttpSolrServer server = null;
+    HttpSolrClient client = null;
     try {
-      server = new HttpSolrServer(url);
-      server.setConnectionTimeout(30000);
-      server.setSoTimeout(120000);
+      client = new HttpSolrClient(url);
+      client.setConnectionTimeout(30000);
+      client.setSoTimeout(120000);
       UpdateRequest ureq = new UpdateRequest();
       ureq.setParams(new ModifiableSolrParams());
       ureq.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, true, true);
-      return ureq.process(server);
+      return ureq.process(client);
     } finally {
-      if (server != null) {
-        server.shutdown();
+      if (client != null) {
+        client.shutdown();
       }
     }
   }
diff --git a/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java b/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
index 52a89e3..6d1fc83 100644
--- a/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
+++ b/solr/core/src/java/org/apache/solr/cloud/RecoveryStrategy.java
@@ -21,8 +21,8 @@ import org.apache.http.client.methods.HttpUriRequest;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer.HttpUriRequestResponse;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient.HttpUriRequestResponse;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.WaitForState;
 import org.apache.solr.client.solrj.request.UpdateRequest;
@@ -200,7 +200,7 @@ public class RecoveryStrategy extends Thread implements ClosableThread {
 
   private void commitOnLeader(String leaderUrl) throws SolrServerException,
       IOException {
-    HttpSolrServer server = new HttpSolrServer(leaderUrl);
+    HttpSolrClient server = new HttpSolrClient(leaderUrl);
     try {
       server.setConnectionTimeout(30000);
       UpdateRequest ureq = new UpdateRequest();
@@ -594,7 +594,7 @@ public class RecoveryStrategy extends Thread implements ClosableThread {
   
   private void sendPrepRecoveryCmd(String leaderBaseUrl, String leaderCoreName, Slice slice)
       throws SolrServerException, IOException, InterruptedException, ExecutionException {
-    HttpSolrServer server = new HttpSolrServer(leaderBaseUrl);
+    HttpSolrClient server = new HttpSolrClient(leaderBaseUrl);
     try {
       server.setConnectionTimeout(30000);
       WaitForState prepCmd = new WaitForState();
diff --git a/solr/core/src/java/org/apache/solr/cloud/SyncStrategy.java b/solr/core/src/java/org/apache/solr/cloud/SyncStrategy.java
index 3a886da..c52f812 100644
--- a/solr/core/src/java/org/apache/solr/cloud/SyncStrategy.java
+++ b/solr/core/src/java/org/apache/solr/cloud/SyncStrategy.java
@@ -17,20 +17,13 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.ExecutorService;
-
 import org.apache.http.client.HttpClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.RequestRecovery;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.cloud.ZkCoreNodeProps;
 import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.common.params.CoreAdminParams.CoreAdminAction;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
@@ -49,6 +42,11 @@ import org.apache.solr.update.UpdateShardHandler;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.ExecutorService;
+
 public class SyncStrategy {
   protected final Logger log = LoggerFactory.getLogger(getClass());
 
@@ -269,18 +267,18 @@ public class SyncStrategy {
         recoverRequestCmd.setAction(CoreAdminAction.REQUESTRECOVERY);
         recoverRequestCmd.setCoreName(coreName);
         
-        HttpSolrServer server = new HttpSolrServer(baseUrl, client);
+        HttpSolrClient client = new HttpSolrClient(baseUrl, SyncStrategy.this.client);
         try {
-          server.setConnectionTimeout(30000);
-          server.setSoTimeout(120000);
-          server.request(recoverRequestCmd);
+          client.setConnectionTimeout(30000);
+          client.setSoTimeout(120000);
+          client.request(recoverRequestCmd);
         } catch (Throwable t) {
           SolrException.log(log, ZkCoreNodeProps.getCoreUrl(leaderProps) + ": Could not tell a replica to recover", t);
           if (t instanceof Error) {
             throw (Error) t;
           }
         } finally {
-          server.shutdown();
+          client.shutdown();
         }
       }
     };
diff --git a/solr/core/src/java/org/apache/solr/cloud/ZkController.java b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
index 52b9ad7..cbf4d4b 100644
--- a/solr/core/src/java/org/apache/solr/cloud/ZkController.java
+++ b/solr/core/src/java/org/apache/solr/cloud/ZkController.java
@@ -17,35 +17,9 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.IOException;
-import java.io.UnsupportedEncodingException;
-import java.net.InetAddress;
-import java.net.NetworkInterface;
-import java.net.URLEncoder;
-import java.net.UnknownHostException;
-import java.nio.charset.StandardCharsets;
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Properties;
-import java.util.Set;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.lang.StringUtils;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.WaitForState;
 import org.apache.solr.cloud.overseer.OverseerAction;
 import org.apache.solr.cloud.overseer.SliceMutator;
@@ -80,15 +54,6 @@ import org.apache.solr.core.SolrResourceLoader;
 import org.apache.solr.handler.component.ShardHandler;
 import org.apache.solr.update.UpdateLog;
 import org.apache.solr.update.UpdateShardHandler;
-
-import static org.apache.solr.common.cloud.ZkStateReader.BASE_URL_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.CORE_NAME_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.ELECTION_NODE_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.NODE_NAME_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.REJOIN_AT_HEAD_PROP;
-import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;
-
 import org.apache.zookeeper.CreateMode;
 import org.apache.zookeeper.KeeperException;
 import org.apache.zookeeper.KeeperException.ConnectionLossException;
@@ -100,6 +65,39 @@ import org.apache.zookeeper.data.Stat;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.File;
+import java.io.IOException;
+import java.io.UnsupportedEncodingException;
+import java.net.InetAddress;
+import java.net.NetworkInterface;
+import java.net.URLEncoder;
+import java.net.UnknownHostException;
+import java.nio.charset.StandardCharsets;
+import java.text.MessageFormat;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Enumeration;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Properties;
+import java.util.Set;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+
+import static org.apache.solr.common.cloud.ZkStateReader.BASE_URL_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.COLLECTION_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.CORE_NAME_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.ELECTION_NODE_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.NODE_NAME_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.REJOIN_AT_HEAD_PROP;
+import static org.apache.solr.common.cloud.ZkStateReader.SHARD_ID_PROP;
+
 /**
  * Handle ZooKeeper interactions.
  * 
@@ -1638,11 +1636,11 @@ public final class ZkController {
         log.info("Replica "+myCoreNodeName+
             " NOT in leader-initiated recovery, need to wait for leader to see down state.");
             
-        HttpSolrServer server = null;
-        server = new HttpSolrServer(leaderBaseUrl);
+        HttpSolrClient client = null;
+        client = new HttpSolrClient(leaderBaseUrl);
         try {
-          server.setConnectionTimeout(15000);
-          server.setSoTimeout(120000);
+          client.setConnectionTimeout(15000);
+          client.setSoTimeout(120000);
           WaitForState prepCmd = new WaitForState();
           prepCmd.setCoreName(leaderCoreName);
           prepCmd.setNodeName(getNodeName());
@@ -1658,7 +1656,7 @@ public final class ZkController {
                   "We have been closed");
             }
             try {
-              server.request(prepCmd);
+              client.request(prepCmd);
               break;
             } catch (Exception e) {
 
@@ -1692,7 +1690,7 @@ public final class ZkController {
             }
           }
         } finally {
-          server.shutdown();
+          client.shutdown();
         }
       }
     }
diff --git a/solr/core/src/java/org/apache/solr/handler/SnapPuller.java b/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
index 07c4d34..eac7376 100644
--- a/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
+++ b/solr/core/src/java/org/apache/solr/handler/SnapPuller.java
@@ -16,6 +16,43 @@
  */
 package org.apache.solr.handler;
 
+import org.apache.commons.io.IOUtils;
+import org.apache.http.client.HttpClient;
+import org.apache.lucene.index.IndexCommit;
+import org.apache.lucene.index.IndexWriter;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IOContext;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.impl.HttpClientUtil;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.ExecutorUtil;
+import org.apache.solr.common.util.FastInputStream;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.core.DirectoryFactory;
+import org.apache.solr.core.DirectoryFactory.DirContext;
+import org.apache.solr.core.IndexDeletionPolicyWrapper;
+import org.apache.solr.core.SolrCore;
+import org.apache.solr.handler.ReplicationHandler.FileInfo;
+import org.apache.solr.request.LocalSolrQueryRequest;
+import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.search.SolrIndexSearcher;
+import org.apache.solr.update.CommitUpdateCommand;
+import org.apache.solr.util.DefaultSolrThreadFactory;
+import org.apache.solr.util.FileUtils;
+import org.apache.solr.util.PropertiesInputStream;
+import org.apache.solr.util.PropertiesOutputStream;
+import org.apache.solr.util.RefCounted;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import java.io.File;
 import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
@@ -54,43 +91,6 @@ import java.util.zip.Adler32;
 import java.util.zip.Checksum;
 import java.util.zip.InflaterInputStream;
 
-import org.apache.commons.io.IOUtils;
-import org.apache.http.client.HttpClient;
-import org.apache.lucene.index.IndexCommit;
-import org.apache.lucene.index.IndexWriter;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.IOContext;
-import org.apache.lucene.store.IndexInput;
-import org.apache.lucene.store.IndexOutput;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.ExecutorUtil;
-import org.apache.solr.common.util.FastInputStream;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.core.DirectoryFactory.DirContext;
-import org.apache.solr.core.DirectoryFactory;
-import org.apache.solr.core.IndexDeletionPolicyWrapper;
-import org.apache.solr.core.SolrCore;
-import org.apache.solr.handler.ReplicationHandler.FileInfo;
-import org.apache.solr.request.LocalSolrQueryRequest;
-import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.search.SolrIndexSearcher;
-import org.apache.solr.update.CommitUpdateCommand;
-import org.apache.solr.util.DefaultSolrThreadFactory;
-import org.apache.solr.util.FileUtils;
-import org.apache.solr.util.PropertiesInputStream;
-import org.apache.solr.util.PropertiesOutputStream;
-import org.apache.solr.util.RefCounted;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
 import static org.apache.solr.handler.ReplicationHandler.ALIAS;
 import static org.apache.solr.handler.ReplicationHandler.CHECKSUM;
 import static org.apache.solr.handler.ReplicationHandler.CMD_DETAILS;
@@ -246,17 +246,17 @@ public class SnapPuller {
     params.set(CommonParams.WT, "javabin");
     params.set(CommonParams.QT, "/replication");
     QueryRequest req = new QueryRequest(params);
-    HttpSolrServer server = new HttpSolrServer(masterUrl, myHttpClient); //XXX modify to use shardhandler
+    HttpSolrClient client = new HttpSolrClient(masterUrl, myHttpClient); //XXX modify to use shardhandler
     NamedList rsp;
     try {
-      server.setSoTimeout(60000);
-      server.setConnectionTimeout(15000);
+      client.setSoTimeout(60000);
+      client.setConnectionTimeout(15000);
       
-      rsp = server.request(req);
+      rsp = client.request(req);
     } catch (SolrServerException e) {
       throw new SolrException(ErrorCode.SERVER_ERROR, e.getMessage(), e);
     } finally {
-      server.shutdown();
+      client.shutdown();
     }
     return rsp;
   }
@@ -271,11 +271,11 @@ public class SnapPuller {
     params.set(CommonParams.WT, "javabin");
     params.set(CommonParams.QT, "/replication");
     QueryRequest req = new QueryRequest(params);
-    HttpSolrServer server = new HttpSolrServer(masterUrl, myHttpClient);  //XXX modify to use shardhandler
+    HttpSolrClient client = new HttpSolrClient(masterUrl, myHttpClient);  //XXX modify to use shardhandler
     try {
-      server.setSoTimeout(60000);
-      server.setConnectionTimeout(15000);
-      NamedList response = server.request(req);
+      client.setSoTimeout(60000);
+      client.setConnectionTimeout(15000);
+      NamedList response = client.request(req);
 
       List<Map<String, Object>> files = (List<Map<String,Object>>) response.get(CMD_GET_FILE_LIST);
       if (files != null)
@@ -292,7 +292,7 @@ public class SnapPuller {
     } catch (SolrServerException e) {
       throw new IOException(e);
     } finally {
-      server.shutdown();
+      client.shutdown();
     }
   }
 
@@ -1364,12 +1364,12 @@ public class SnapPuller {
       NamedList response;
       InputStream is = null;
       
-      HttpSolrServer s = new HttpSolrServer(masterUrl, myHttpClient, null);  //XXX use shardhandler
+      HttpSolrClient client = new HttpSolrClient(masterUrl, myHttpClient, null);  //XXX use shardhandler
       try {
-        s.setSoTimeout(60000);
-        s.setConnectionTimeout(15000);
+        client.setSoTimeout(60000);
+        client.setConnectionTimeout(15000);
         QueryRequest req = new QueryRequest(params);
-        response = s.request(req);
+        response = client.request(req);
         is = (InputStream) response.get("stream");
         if(useInternal) {
           is = new InflaterInputStream(is);
@@ -1380,7 +1380,7 @@ public class SnapPuller {
         IOUtils.closeQuietly(is);
         throw new IOException("Could not download file '" + fileName + "'", e);
       } finally {
-        s.shutdown();
+        client.shutdown();
       }
     }
   }
@@ -1631,12 +1631,12 @@ public class SnapPuller {
 
       NamedList response;
       InputStream is = null;
-      HttpSolrServer s = new HttpSolrServer(masterUrl, myHttpClient, null);  //XXX use shardhandler
+      HttpSolrClient client = new HttpSolrClient(masterUrl, myHttpClient, null);  //XXX use shardhandler
       try {
-        s.setSoTimeout(60000);
-        s.setConnectionTimeout(15000);
+        client.setSoTimeout(60000);
+        client.setConnectionTimeout(15000);
         QueryRequest req = new QueryRequest(params);
-        response = s.request(req);
+        response = client.request(req);
         is = (InputStream) response.get("stream");
         if(useInternal) {
           is = new InflaterInputStream(is);
@@ -1647,7 +1647,7 @@ public class SnapPuller {
         IOUtils.closeQuietly(is);
         throw new IOException("Could not download file '" + fileName + "'", e);
       } finally {
-        s.shutdown();
+        client.shutdown();
       }
     }
   }
@@ -1657,15 +1657,15 @@ public class SnapPuller {
     params.set(COMMAND, CMD_DETAILS);
     params.set("slave", false);
     params.set(CommonParams.QT, "/replication");
-    HttpSolrServer server = new HttpSolrServer(masterUrl, myHttpClient); //XXX use shardhandler
+    HttpSolrClient client = new HttpSolrClient(masterUrl, myHttpClient); //XXX use shardhandler
     NamedList rsp;
     try {
-      server.setSoTimeout(60000);
-      server.setConnectionTimeout(15000);
+      client.setSoTimeout(60000);
+      client.setConnectionTimeout(15000);
       QueryRequest request = new QueryRequest(params);
-      rsp = server.request(request);
+      rsp = client.request(request);
     } finally {
-      server.shutdown();
+      client.shutdown();
     }
     return rsp;
   }
diff --git a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
index 236dfe1..c6e84c8 100644
--- a/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/admin/CollectionsHandler.java
@@ -80,7 +80,7 @@ import java.util.concurrent.TimeUnit;
 import org.apache.commons.lang.StringUtils;
 import org.apache.solr.client.solrj.SolrResponse;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.RequestSyncShard;
 import org.apache.solr.cloud.DistributedQueue;
@@ -773,7 +773,7 @@ public class CollectionsHandler extends RequestHandlerBase {
     ZkNodeProps leaderProps = clusterState.getLeader(collection, shard);
     ZkCoreNodeProps nodeProps = new ZkCoreNodeProps(leaderProps);
     
-    HttpSolrServer server = new HttpSolrServer(nodeProps.getBaseUrl());
+    HttpSolrClient server = new HttpSolrClient(nodeProps.getBaseUrl());
     try {
       server.setConnectionTimeout(15000);
       server.setSoTimeout(60000);
diff --git a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
index 9538250..2e07080 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandler.java
@@ -19,9 +19,9 @@ package org.apache.solr.handler.component;
 import org.apache.http.client.HttpClient;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrResponse;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.impl.LBHttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.impl.LBHttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.cloud.CloudDescriptor;
@@ -152,14 +152,14 @@ public class HttpShardHandler extends ShardHandler {
           if (urls.size() <= 1) {
             String url = urls.get(0);
             srsp.setShardAddress(url);
-            SolrServer server = new HttpSolrServer(url, httpClient);
+            SolrClient client = new HttpSolrClient(url, httpClient);
             try {
-              ssr.nl = server.request(req);
+              ssr.nl = client.request(req);
             } finally {
-              server.shutdown();
+              client.shutdown();
             }
           } else {
-            LBHttpSolrServer.Rsp rsp = httpShardHandlerFactory.makeLoadBalancedRequest(req, urls);
+            LBHttpSolrClient.Rsp rsp = httpShardHandlerFactory.makeLoadBalancedRequest(req, urls);
             ssr.nl = rsp.getResponse();
             srsp.setShardAddress(rsp.getServer());
           }
diff --git a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
index 4d46972..b217c52 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/HttpShardHandlerFactory.java
@@ -20,7 +20,7 @@ import org.apache.commons.lang.StringUtils;
 import org.apache.http.client.HttpClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.LBHttpSolrServer;
+import org.apache.solr.client.solrj.impl.LBHttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.ExecutorUtil;
@@ -64,7 +64,7 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
   );
 
   protected HttpClient defaultClient;
-  private LBHttpSolrServer loadbalancer;
+  private LBHttpSolrClient loadbalancer;
   //default values:
   int soTimeout = 0; 
   int connectionTimeout = 0; 
@@ -162,8 +162,8 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
     return this.commExecutor;
   }
 
-  protected LBHttpSolrServer createLoadbalancer(HttpClient httpClient){
-    return new LBHttpSolrServer(httpClient);
+  protected LBHttpSolrClient createLoadbalancer(HttpClient httpClient){
+    return new LBHttpSolrClient(httpClient);
   }
 
   protected <T> T getParameter(NamedList initArgs, String configKey, T defaultValue) {
@@ -202,9 +202,9 @@ public class HttpShardHandlerFactory extends ShardHandlerFactory implements org.
    * @param urls The list of solr server urls to load balance across
    * @return The response from the request
    */
-  public LBHttpSolrServer.Rsp makeLoadBalancedRequest(final QueryRequest req, List<String> urls)
+  public LBHttpSolrClient.Rsp makeLoadBalancedRequest(final QueryRequest req, List<String> urls)
     throws SolrServerException, IOException {
-    return loadbalancer.request(new LBHttpSolrServer.Req(req, urls));
+    return loadbalancer.request(new LBHttpSolrClient.Req(req, urls));
   }
 
   /**
diff --git a/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java b/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java
index 2e20729..a37a422 100644
--- a/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java
+++ b/solr/core/src/java/org/apache/solr/schema/ManagedIndexSchema.java
@@ -24,9 +24,9 @@ import org.apache.lucene.analysis.util.TokenizerFactory;
 import org.apache.solr.analysis.TokenizerChain;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrResponse;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.ZkController;
 import org.apache.solr.cloud.ZkSolrResourceLoader;
 import org.apache.solr.common.SolrException;
@@ -331,13 +331,13 @@ public final class ManagedIndexSchema extends IndexSchema {
 
     @Override
     public Integer call() throws Exception {
-      HttpSolrServer solr = new HttpSolrServer(coreUrl);
+      HttpSolrClient solr = new HttpSolrClient(coreUrl);
       int remoteVersion = -1;
       try {
         // eventually, this loop will get killed by the ExecutorService's timeout
         while (remoteVersion == -1 || remoteVersion < expectedZkVersion) {
           try {
-            HttpSolrServer.HttpUriRequestResponse mrr = solr.httpUriRequest(this);
+            HttpSolrClient.HttpUriRequestResponse mrr = solr.httpUriRequest(this);
             NamedList<Object> zkversionResp = mrr.future.get();
             if (zkversionResp != null)
               remoteVersion = (Integer)zkversionResp.get("zkversion");
@@ -371,7 +371,7 @@ public final class ManagedIndexSchema extends IndexSchema {
     }
 
     @Override
-    public SolrResponse process(SolrServer server) throws SolrServerException, IOException {
+    public SolrResponse process(SolrClient server) throws SolrServerException, IOException {
       return null;
     }
   }
diff --git a/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java b/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
index a54df0a..2ea2a3e 100644
--- a/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
+++ b/solr/core/src/java/org/apache/solr/servlet/SolrDispatchFilter.java
@@ -34,7 +34,7 @@ import org.apache.http.HeaderIterator;
 import org.apache.http.HttpEntity;
 import org.apache.http.HttpEntityEnclosingRequest;
 import org.apache.http.HttpResponse;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.cloud.Aliases;
@@ -311,7 +311,7 @@ public class SolrDispatchFilter extends BaseSolrFilter {
             String coreUrl = getRemotCoreUrl(cores, corename, origCorename);
             // don't proxy for internal update requests
             SolrParams queryParams = SolrRequestParsers.parseQueryString(req.getQueryString());
-            checkStateIsValid(cores, queryParams.get(CloudSolrServer.STATE_VERSION));
+            checkStateIsValid(cores, queryParams.get(CloudSolrClient.STATE_VERSION));
             if (coreUrl != null
                 && queryParams
                     .get(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM) == null) {
@@ -372,7 +372,7 @@ public class SolrDispatchFilter extends BaseSolrFilter {
               if( "/select".equals( path ) || "/select/".equals( path ) ) {
                 solrReq = parser.parse( core, path, req );
 
-                checkStateIsValid(cores,solrReq.getParams().get(CloudSolrServer.STATE_VERSION));
+                checkStateIsValid(cores,solrReq.getParams().get(CloudSolrClient.STATE_VERSION));
                 String qt = solrReq.getParams().get( CommonParams.QT );
                 handler = core.getRequestHandler( qt );
                 if( handler == null ) {
diff --git a/solr/core/src/java/org/apache/solr/update/SolrCmdDistributor.java b/solr/core/src/java/org/apache/solr/update/SolrCmdDistributor.java
index 8efb874..a60d271 100644
--- a/solr/core/src/java/org/apache/solr/update/SolrCmdDistributor.java
+++ b/solr/core/src/java/org/apache/solr/update/SolrCmdDistributor.java
@@ -17,25 +17,11 @@ package org.apache.solr.update;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.io.InputStream;
-import java.net.ConnectException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.Callable;
-import java.util.concurrent.CompletionService;
-import java.util.concurrent.ExecutorCompletionService;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
-
 import org.apache.http.HttpResponse;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrException;
@@ -49,12 +35,26 @@ import org.apache.solr.update.processor.DistributedUpdateProcessor.RequestReplic
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.ConnectException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CompletionService;
+import java.util.concurrent.ExecutorCompletionService;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+
 
 public class SolrCmdDistributor {
   private static final int MAX_RETRIES_ON_FORWARD = 25;
   public static Logger log = LoggerFactory.getLogger(SolrCmdDistributor.class);
   
-  private StreamingSolrServers servers;
+  private StreamingSolrClients clients;
   
   private int retryPause = 500;
   private int maxRetriesOnForward = MAX_RETRIES_ON_FORWARD;
@@ -71,16 +71,16 @@ public class SolrCmdDistributor {
   }
   
   public SolrCmdDistributor(UpdateShardHandler updateShardHandler) {
-    this.servers = new StreamingSolrServers(updateShardHandler);
+    this.clients = new StreamingSolrClients(updateShardHandler);
     this.updateExecutor = updateShardHandler.getUpdateExecutor();
     this.completionService = new ExecutorCompletionService<>(updateExecutor);
   }
   
-  public SolrCmdDistributor(StreamingSolrServers servers, int maxRetriesOnForward, int retryPause) {
-    this.servers = servers;
+  public SolrCmdDistributor(StreamingSolrClients clients, int maxRetriesOnForward, int retryPause) {
+    this.clients = clients;
     this.maxRetriesOnForward = maxRetriesOnForward;
     this.retryPause = retryPause;
-    this.updateExecutor = servers.getUpdateExecutor();
+    this.updateExecutor = clients.getUpdateExecutor();
     completionService = new ExecutorCompletionService<>(updateExecutor);
   }
   
@@ -88,7 +88,7 @@ public class SolrCmdDistributor {
     try {
       blockAndDoRetries();
     } finally {
-      servers.shutdown();
+      clients.shutdown();
     }
   }
 
@@ -96,7 +96,7 @@ public class SolrCmdDistributor {
     // NOTE: retries will be forwards to a single url
     
     List<Error> errors = new ArrayList<>(this.errors);
-    errors.addAll(servers.getErrors());
+    errors.addAll(clients.getErrors());
     List<Error> resubmitList = new ArrayList<>();
 
     for (Error err : errors) {
@@ -156,7 +156,7 @@ public class SolrCmdDistributor {
       }
     }
     
-    servers.clearErrors();
+    clients.clearErrors();
     this.errors.clear();
     for (Error err : resubmitList) {
       submit(err.req, false);
@@ -225,7 +225,7 @@ public class SolrCmdDistributor {
   }
 
   private void blockAndDoRetries() {
-    servers.blockUntilFinished();
+    clients.blockUntilFinished();
     
     // wait for any async commits to complete
     while (pending != null && pending.size() > 0) {
@@ -253,14 +253,13 @@ public class SolrCmdDistributor {
     if (req.synchronous) {
       blockAndDoRetries();
       
-      HttpSolrServer server = new HttpSolrServer(req.node.getUrl(),
-          servers.getHttpClient());
+      HttpSolrClient client = new HttpSolrClient(req.node.getUrl(), clients.getHttpClient());
       try {
-        server.request(req.uReq);
+        client.request(req.uReq);
       } catch (Exception e) {
         throw new SolrException(ErrorCode.SERVER_ERROR, "Failed synchronous update on shard " + req.node + " update: " + req.uReq , e);
       } finally {
-        server.shutdown();
+        client.shutdown();
       }
       
       return;
@@ -292,8 +291,8 @@ public class SolrCmdDistributor {
   
   private void doRequest(final Req req) {
     try {
-      SolrServer solrServer = servers.getSolrServer(req);
-      solrServer.request(req.uReq);
+      SolrClient solrClient = clients.getSolrClient(req);
+      solrClient.request(req.uReq);
     } catch (Exception e) {
       SolrException.log(log, e);
       Error error = new Error();
diff --git a/solr/core/src/java/org/apache/solr/update/StreamingSolrClients.java b/solr/core/src/java/org/apache/solr/update/StreamingSolrClients.java
new file mode 100644
index 0000000..381d7cb
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/update/StreamingSolrClients.java
@@ -0,0 +1,130 @@
+package org.apache.solr.update;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.http.HttpResponse;
+import org.apache.http.client.HttpClient;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
+import org.apache.solr.client.solrj.impl.BinaryResponseParser;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.update.SolrCmdDistributor.Error;
+import org.apache.solr.update.processor.DistributedUpdateProcessor;
+import org.apache.solr.update.processor.DistributingUpdateProcessorFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+
+public class StreamingSolrClients {
+  public static Logger log = LoggerFactory.getLogger(StreamingSolrClients.class);
+  
+  private HttpClient httpClient;
+  
+  private Map<String, ConcurrentUpdateSolrClient> solrClients = new HashMap<>();
+  private List<Error> errors = Collections.synchronizedList(new ArrayList<Error>());
+
+  private ExecutorService updateExecutor;
+
+  public StreamingSolrClients(UpdateShardHandler updateShardHandler) {
+    this.updateExecutor = updateShardHandler.getUpdateExecutor();
+    
+    httpClient = updateShardHandler.getHttpClient();
+  }
+
+  public List<Error> getErrors() {
+    return errors;
+  }
+  
+  public void clearErrors() {
+    errors.clear();
+  }
+
+  public synchronized SolrClient getSolrClient(final SolrCmdDistributor.Req req) {
+    String url = getFullUrl(req.node.getUrl());
+    ConcurrentUpdateSolrClient client = solrClients.get(url);
+    if (client == null) {
+      client = new ConcurrentUpdateSolrClient(url, httpClient, 100, 1, updateExecutor, true) {
+        @Override
+        public void handleError(Throwable ex) {
+          req.trackRequestResult(null, false);
+          log.error("error", ex);
+          Error error = new Error();
+          error.e = (Exception) ex;
+          if (ex instanceof SolrException) {
+            error.statusCode = ((SolrException) ex).code();
+          }
+          error.req = req;
+          errors.add(error);
+        }
+        @Override
+        public void onSuccess(HttpResponse resp) {
+          req.trackRequestResult(resp, true);
+        }
+      };
+      client.setParser(new BinaryResponseParser());
+      client.setRequestWriter(new BinaryRequestWriter());
+      client.setPollQueueTime(0);
+      Set<String> queryParams = new HashSet<>(2);
+      queryParams.add(DistributedUpdateProcessor.DISTRIB_FROM);
+      queryParams.add(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM);
+      client.setQueryParams(queryParams);
+      solrClients.put(url, client);
+    }
+
+    return client;
+  }
+
+  public synchronized void blockUntilFinished() {
+    for (ConcurrentUpdateSolrClient client : solrClients.values()) {
+      client.blockUntilFinished();
+    }
+  }
+  
+  public synchronized void shutdown() {
+    for (ConcurrentUpdateSolrClient client : solrClients.values()) {
+      client.shutdown();
+    }
+  }
+  
+  private String getFullUrl(String url) {
+    String fullUrl;
+    if (!url.startsWith("http://") && !url.startsWith("https://")) {
+      fullUrl = "http://" + url;
+    } else {
+      fullUrl = url;
+    }
+    return fullUrl;
+  }
+
+  public HttpClient getHttpClient() {
+    return httpClient;
+  }
+  
+  public ExecutorService getUpdateExecutor() {
+    return updateExecutor;
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/update/StreamingSolrServers.java b/solr/core/src/java/org/apache/solr/update/StreamingSolrServers.java
deleted file mode 100644
index 58474c3..0000000
--- a/solr/core/src/java/org/apache/solr/update/StreamingSolrServers.java
+++ /dev/null
@@ -1,130 +0,0 @@
-package org.apache.solr.update;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-
-import org.apache.http.HttpResponse;
-import org.apache.http.client.HttpClient;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
-import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.update.SolrCmdDistributor.Error;
-import org.apache.solr.update.processor.DistributedUpdateProcessor;
-import org.apache.solr.update.processor.DistributingUpdateProcessorFactory;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class StreamingSolrServers {
-  public static Logger log = LoggerFactory.getLogger(StreamingSolrServers.class);
-  
-  private HttpClient httpClient;
-  
-  private Map<String,ConcurrentUpdateSolrServer> solrServers = new HashMap<>();
-  private List<Error> errors = Collections.synchronizedList(new ArrayList<Error>());
-
-  private ExecutorService updateExecutor;
-
-  public StreamingSolrServers(UpdateShardHandler updateShardHandler) {
-    this.updateExecutor = updateShardHandler.getUpdateExecutor();
-    
-    httpClient = updateShardHandler.getHttpClient();
-  }
-
-  public List<Error> getErrors() {
-    return errors;
-  }
-  
-  public void clearErrors() {
-    errors.clear();
-  }
-
-  public synchronized SolrServer getSolrServer(final SolrCmdDistributor.Req req) {
-    String url = getFullUrl(req.node.getUrl());
-    ConcurrentUpdateSolrServer server = solrServers.get(url);
-    if (server == null) {
-      server = new ConcurrentUpdateSolrServer(url, httpClient, 100, 1, updateExecutor, true) {
-        @Override
-        public void handleError(Throwable ex) {
-          req.trackRequestResult(null, false);
-          log.error("error", ex);
-          Error error = new Error();
-          error.e = (Exception) ex;
-          if (ex instanceof SolrException) {
-            error.statusCode = ((SolrException) ex).code();
-          }
-          error.req = req;
-          errors.add(error);
-        }
-        @Override
-        public void onSuccess(HttpResponse resp) {
-          req.trackRequestResult(resp, true);
-        }
-      };
-      server.setParser(new BinaryResponseParser());
-      server.setRequestWriter(new BinaryRequestWriter());
-      server.setPollQueueTime(0);
-      Set<String> queryParams = new HashSet<>(2);
-      queryParams.add(DistributedUpdateProcessor.DISTRIB_FROM);
-      queryParams.add(DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM);
-      server.setQueryParams(queryParams);
-      solrServers.put(url, server);
-    }
-
-    return server;
-  }
-
-  public synchronized void blockUntilFinished() {
-    for (ConcurrentUpdateSolrServer server : solrServers.values()) {
-      server.blockUntilFinished();
-    }
-  }
-  
-  public synchronized void shutdown() {
-    for (ConcurrentUpdateSolrServer server : solrServers.values()) {
-      server.shutdown();
-    }
-  }
-  
-  private String getFullUrl(String url) {
-    String fullUrl;
-    if (!url.startsWith("http://") && !url.startsWith("https://")) {
-      fullUrl = "http://" + url;
-    } else {
-      fullUrl = url;
-    }
-    return fullUrl;
-  }
-
-  public HttpClient getHttpClient() {
-    return httpClient;
-  }
-  
-  public ExecutorService getUpdateExecutor() {
-    return updateExecutor;
-  }
-}
diff --git a/solr/core/src/java/org/apache/solr/util/SolrCLI.java b/solr/core/src/java/org/apache/solr/util/SolrCLI.java
index 14580d8..809b366 100644
--- a/solr/core/src/java/org/apache/solr/util/SolrCLI.java
+++ b/solr/core/src/java/org/apache/solr/util/SolrCLI.java
@@ -17,25 +17,6 @@ package org.apache.solr.util;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.PrintStream;
-import java.net.ConnectException;
-import java.net.SocketException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Enumeration;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeSet;
-import java.util.zip.ZipEntry;
-import java.util.zip.ZipInputStream;
-
 import org.apache.commons.cli.CommandLine;
 import org.apache.commons.cli.GnuParser;
 import org.apache.commons.cli.HelpFormatter;
@@ -61,9 +42,9 @@ import org.apache.log4j.LogManager;
 import org.apache.log4j.Logger;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.cloud.ZkController;
 import org.apache.solr.common.SolrException;
@@ -78,6 +59,25 @@ import org.noggit.JSONParser;
 import org.noggit.JSONWriter;
 import org.noggit.ObjectBuilder;
 
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.net.ConnectException;
+import java.net.SocketException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Enumeration;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeSet;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipInputStream;
+
 /**
  * Command-line utility for working with Solr.
  */
@@ -93,7 +93,7 @@ public class SolrCLI {
   }
   
   /**
-   * Helps build SolrCloud aware tools by initializing a CloudSolrServer
+   * Helps build SolrCloud aware tools by initializing a CloudSolrClient
    * instance before running the tool.
    */
   public static abstract class SolrCloudTool implements Tool {
@@ -112,16 +112,16 @@ public class SolrCLI {
       
       log.debug("Connecting to Solr cluster: " + zkHost);
       int exitStatus = 0;
-      CloudSolrServer cloudSolrServer = null;
+      CloudSolrClient cloudSolrClient = null;
       try {
-        cloudSolrServer = new CloudSolrServer(zkHost);
+        cloudSolrClient = new CloudSolrClient(zkHost);
         
         String collection = cli.getOptionValue("collection");
         if (collection != null)
-          cloudSolrServer.setDefaultCollection(collection);
+          cloudSolrClient.setDefaultCollection(collection);
         
-        cloudSolrServer.connect();
-        exitStatus = runCloudTool(cloudSolrServer, cli);
+        cloudSolrClient.connect();
+        exitStatus = runCloudTool(cloudSolrClient, cli);
       } catch (Exception exc) {
         // since this is a CLI, spare the user the stacktrace
         String excMsg = exc.getMessage();
@@ -132,9 +132,9 @@ public class SolrCLI {
           throw exc;
         }
       } finally {
-        if (cloudSolrServer != null) {
+        if (cloudSolrClient != null) {
           try {
-            cloudSolrServer.shutdown();
+            cloudSolrClient.shutdown();
           } catch (Exception ignore) {}
         }
       }
@@ -145,7 +145,7 @@ public class SolrCLI {
     /**
      * Runs a SolrCloud tool with CloudSolrServer initialized
      */
-    protected abstract int runCloudTool(CloudSolrServer cloudSolrServer, CommandLine cli)
+    protected abstract int runCloudTool(CloudSolrClient cloudSolrClient, CommandLine cli)
         throws Exception;
   }
   
@@ -872,7 +872,7 @@ public class SolrCLI {
     }
         
     @Override
-    protected int runCloudTool(CloudSolrServer cloudSolrServer, CommandLine cli) throws Exception {
+    protected int runCloudTool(CloudSolrClient cloudSolrClient, CommandLine cli) throws Exception {
       
       String collection = cli.getOptionValue("collection");
       if (collection == null)
@@ -880,7 +880,7 @@ public class SolrCLI {
       
       log.info("Running healthcheck for "+collection);
       
-      ZkStateReader zkStateReader = cloudSolrServer.getZkStateReader();
+      ZkStateReader zkStateReader = cloudSolrClient.getZkStateReader();
 
       ClusterState clusterState = zkStateReader.getClusterState();
       Set<String> liveNodes = clusterState.getLiveNodes();
@@ -890,7 +890,7 @@ public class SolrCLI {
       
       SolrQuery q = new SolrQuery("*:*");
       q.setRows(0);      
-      QueryResponse qr = cloudSolrServer.query(q);
+      QueryResponse qr = cloudSolrClient.query(q);
       String collErr = null;
       long docCount = -1;
       try {
@@ -930,7 +930,7 @@ public class SolrCLI {
             replicaStatus = ZkStateReader.DOWN;
           } else {
             // query this replica directly to get doc count and assess health
-            HttpSolrServer solr = new HttpSolrServer(coreUrl);
+            HttpSolrClient solr = new HttpSolrClient(coreUrl);
             String solrUrl = solr.getBaseURL();
             q = new SolrQuery("*:*");
             q.setRows(0);
@@ -1103,9 +1103,9 @@ public class SolrCLI {
       }
 
       int toolExitStatus = 0;
-      CloudSolrServer cloudSolrServer = null;
+      CloudSolrClient cloudSolrServer = null;
       try {
-        cloudSolrServer = new CloudSolrServer(zkHost);
+        cloudSolrServer = new CloudSolrClient(zkHost);
         System.out.println("Connecting to ZooKeeper at " + zkHost);
         cloudSolrServer.connect();
         toolExitStatus = runCloudTool(cloudSolrServer, cli);
@@ -1129,8 +1129,8 @@ public class SolrCLI {
       return toolExitStatus;
     }
 
-    protected int runCloudTool(CloudSolrServer cloudSolrServer, CommandLine cli) throws Exception {
-      Set<String> liveNodes = cloudSolrServer.getZkStateReader().getClusterState().getLiveNodes();
+    protected int runCloudTool(CloudSolrClient cloudSolrClient, CommandLine cli) throws Exception {
+      Set<String> liveNodes = cloudSolrClient.getZkStateReader().getClusterState().getLiveNodes();
       if (liveNodes.isEmpty())
         throw new IllegalStateException("No live nodes found! Cannot create a collection until " +
             "there is at least 1 live node in the cluster.");
@@ -1183,13 +1183,13 @@ public class SolrCLI {
       }
 
       // test to see if that config exists in ZK
-      if (!cloudSolrServer.getZkStateReader().getZkClient().exists("/configs/"+configSetNameInZk, true)) {
+      if (!cloudSolrClient.getZkStateReader().getZkClient().exists("/configs/"+configSetNameInZk, true)) {
         System.out.println("Uploading "+confDir.getAbsolutePath()+
-            " for config "+configSetNameInZk+" to ZooKeeper at "+cloudSolrServer.getZkHost());
-        ZkController.uploadConfigDir(cloudSolrServer.getZkStateReader().getZkClient(), confDir, configSetNameInZk);
+            " for config "+configSetNameInZk+" to ZooKeeper at "+cloudSolrClient.getZkHost());
+        ZkController.uploadConfigDir(cloudSolrClient.getZkStateReader().getZkClient(), confDir, configSetNameInZk);
       }
 
-      String baseUrl = cloudSolrServer.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);
+      String baseUrl = cloudSolrClient.getZkStateReader().getBaseUrlForNodeName(firstLiveNode);
       String collectionName = cli.getOptionValue("name");
 
       // since creating a collection is a heavy-weight operation, check for existence first
diff --git a/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java b/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
index 81b5b80..6fd9596 100644
--- a/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
+++ b/solr/core/src/test/org/apache/solr/AnalysisAfterCoreReloadTest.java
@@ -22,7 +22,7 @@ import java.io.IOException;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest.ACTION;
 import org.apache.solr.client.solrj.request.QueryRequest;
@@ -137,7 +137,7 @@ public class AnalysisAfterCoreReloadTest extends SolrTestCaseJ4 {
     }
   }
 
-  protected SolrServer getSolrCore() {
+  protected SolrClient getSolrCore() {
     return new EmbeddedSolrServer(h.getCore());
   }
 
diff --git a/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java b/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java
index 8b1f113..e6ef47e 100644
--- a/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java
+++ b/solr/core/src/test/org/apache/solr/TestDistributedGrouping.java
@@ -18,7 +18,7 @@ package org.apache.solr;
  */
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.params.CommonParams;
@@ -243,7 +243,7 @@ public class TestDistributedGrouping extends BaseDistributedSearchTestCase {
     setDistributedParams(params);
 
     int which = r.nextInt(clients.size());
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     QueryResponse rsp = client.query(params);
     NamedList nl = (NamedList<?>) rsp.getResponse().get("grouped");
     nl = (NamedList<?>) nl.getVal(0);
diff --git a/solr/core/src/test/org/apache/solr/TestDistributedSearch.java b/solr/core/src/test/org/apache/solr/TestDistributedSearch.java
index 43dac0c..d68789a 100644
--- a/solr/core/src/test/org/apache/solr/TestDistributedSearch.java
+++ b/solr/core/src/test/org/apache/solr/TestDistributedSearch.java
@@ -17,7 +17,6 @@
 
 package org.apache.solr;
 
-import java.nio.ByteBuffer;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -25,10 +24,10 @@ import java.util.Map;
 
 import org.apache.commons.lang.StringUtils;
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.response.FacetField;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.client.solrj.response.RangeFacet;
@@ -471,7 +470,7 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
     for(int numDownServers = 0; numDownServers < jettys.size()-1; numDownServers++)
     {
       List<JettySolrRunner> upJettys = new ArrayList<>(jettys);
-      List<SolrServer> upClients = new ArrayList<>(clients);
+      List<SolrClient> upClients = new ArrayList<>(clients);
       List<JettySolrRunner> downJettys = new ArrayList<>();
       List<String> upShards = new ArrayList<>(Arrays.asList(shardsArr));
       for(int i=0; i<numDownServers; i++)
@@ -554,7 +553,7 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
             "stats.field", tdate_a, 
             "stats.field", tdate_b,
             "stats.calcdistinct", "true");
-    } catch (HttpSolrServer.RemoteSolrException e) {
+    } catch (HttpSolrClient.RemoteSolrException e) {
       if (e.getMessage().startsWith("java.lang.NullPointerException"))  {
         fail("NullPointerException with stats request on empty index");
       } else  {
@@ -590,7 +589,7 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
   }
 
   protected void queryPartialResults(final List<String> upShards,
-                                     final List<SolrServer> upClients, 
+                                     final List<SolrClient> upClients,
                                      Object... q) throws Exception {
     
     final ModifiableSolrParams params = new ModifiableSolrParams();
@@ -622,7 +621,7 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
           public void run() {
             for (int j = 0; j < stress; j++) {
               int which = r.nextInt(upClients.size());
-              SolrServer client = upClients.get(which);
+              SolrClient client = upClients.get(which);
               try {
                 QueryResponse rsp = client.query(new ModifiableSolrParams(params));
                 if (verifyStress) {
@@ -643,10 +642,10 @@ public class TestDistributedSearch extends BaseDistributedSearchTestCase {
     }
   }
 
-  protected QueryResponse queryRandomUpServer(ModifiableSolrParams params, List<SolrServer> upClients) throws SolrServerException {
+  protected QueryResponse queryRandomUpServer(ModifiableSolrParams params, List<SolrClient> upClients) throws SolrServerException {
     // query a random "up" server
     int which = r.nextInt(upClients.size());
-    SolrServer client = upClients.get(which);
+    SolrClient client = upClients.get(which);
     QueryResponse rsp = client.query(params);
     return rsp;
   }
diff --git a/solr/core/src/test/org/apache/solr/TestSolrCoreProperties.java b/solr/core/src/test/org/apache/solr/TestSolrCoreProperties.java
index b6000c7..283dddc 100644
--- a/solr/core/src/test/org/apache/solr/TestSolrCoreProperties.java
+++ b/solr/core/src/test/org/apache/solr/TestSolrCoreProperties.java
@@ -74,7 +74,7 @@ public class TestSolrCoreProperties extends SolrJettyTestBase {
   public void testSimple() throws Exception {
     SolrParams params = params("q", "*:*", 
                                "echoParams", "all");
-    QueryResponse res = getSolrServer().query(params);
+    QueryResponse res = getSolrClient().query(params);
     assertEquals(0, res.getResults().getNumFound());
 
     NamedList echoedParams = (NamedList) res.getHeader().get("params");
diff --git a/solr/core/src/test/org/apache/solr/TestTolerantSearch.java b/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
index c4d81f0..d6f7816 100644
--- a/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
+++ b/solr/core/src/test/org/apache/solr/TestTolerantSearch.java
@@ -6,9 +6,9 @@ import java.io.OutputStream;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrException;
@@ -40,8 +40,8 @@ import org.junit.BeforeClass;
 
 public class TestTolerantSearch extends SolrJettyTestBase {
   
-  private static SolrServer collection1;
-  private static SolrServer collection2;
+  private static SolrClient collection1;
+  private static SolrClient collection2;
   private static String shard1;
   private static String shard2;
   private static File solrHome;
@@ -60,8 +60,8 @@ public class TestTolerantSearch extends SolrJettyTestBase {
     solrHome = createSolrHome();
     createJetty(solrHome.getAbsolutePath(), null, null);
     String url = jetty.getBaseUrl().toString();
-    collection1 = new HttpSolrServer(url);
-    collection2 = new HttpSolrServer(url + "/collection2");
+    collection1 = new HttpSolrClient(url);
+    collection2 = new HttpSolrClient(url + "/collection2");
     
     String urlCollection1 = jetty.getBaseUrl().toString() + "/" + "collection1";
     String urlCollection2 = jetty.getBaseUrl().toString() + "/" + "collection2";
diff --git a/solr/core/src/test/org/apache/solr/cloud/AliasIntegrationTest.java b/solr/core/src/test/org/apache/solr/cloud/AliasIntegrationTest.java
index 0f77a29..a4aefd8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/AliasIntegrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/AliasIntegrationTest.java
@@ -17,18 +17,13 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
 import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.request.CollectionAdminRequest;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.CreateAlias;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.DeleteAlias;
 import org.apache.solr.client.solrj.request.QueryRequest;
@@ -43,6 +38,10 @@ import org.junit.AfterClass;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * Test sync phase that occurs when Leader goes down and a new Leader is
  * elected.
@@ -138,38 +137,38 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
     query.set("collection", "testalias");
     JettySolrRunner jetty = jettys.get(random().nextInt(jettys.size()));
     int port = jetty.getLocalPort();
-    HttpSolrServer server = new HttpSolrServer(buildUrl(port) + "/testalias");
-    res = server.query(query);
+    HttpSolrClient client = new HttpSolrClient(buildUrl(port) + "/testalias");
+    res = client.query(query);
     assertEquals(3, res.getResults().getNumFound());
-    server.shutdown();
-    server = null;
+    client.shutdown();
+    client = null;
     
     // now without collections param
     query = new SolrQuery("*:*");
     jetty = jettys.get(random().nextInt(jettys.size()));
     port = jetty.getLocalPort();
-    server = new HttpSolrServer(buildUrl(port) + "/testalias");
-    res = server.query(query);
+    client = new HttpSolrClient(buildUrl(port) + "/testalias");
+    res = client.query(query);
     assertEquals(3, res.getResults().getNumFound());
-    server.shutdown();
-    server = null;
+    client.shutdown();
+    client = null;
     
     // create alias, collection2 first because it's not on every node
     createAlias("testalias", "collection2,collection1");
     
     // search with new cloud client
-    CloudSolrServer cloudSolrServer = new CloudSolrServer(zkServer.getZkAddress(), random().nextBoolean());
-    cloudSolrServer.setParallelUpdates(random().nextBoolean());
+    CloudSolrClient cloudSolrClient = new CloudSolrClient(zkServer.getZkAddress(), random().nextBoolean());
+    cloudSolrClient.setParallelUpdates(random().nextBoolean());
     query = new SolrQuery("*:*");
     query.set("collection", "testalias");
-    res = cloudSolrServer.query(query);
+    res = cloudSolrClient.query(query);
     assertEquals(5, res.getResults().getNumFound());
     
     // Try with setDefaultCollection
     query = new SolrQuery("*:*");
-    cloudSolrServer.setDefaultCollection("testalias");
-    res = cloudSolrServer.query(query);
-    cloudSolrServer.shutdown();
+    cloudSolrClient.setDefaultCollection("testalias");
+    res = cloudSolrClient.query(query);
+    cloudSolrClient.shutdown();
     assertEquals(5, res.getResults().getNumFound());
     
     // search for alias with random non cloud client
@@ -177,8 +176,8 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
     query.set("collection", "testalias");
     jetty = jettys.get(random().nextInt(jettys.size()));
     port = jetty.getLocalPort();
-    server = new HttpSolrServer(buildUrl(port) + "/testalias");
-    res = server.query(query);
+    client = new HttpSolrClient(buildUrl(port) + "/testalias");
+    res = client.query(query);
     assertEquals(5, res.getResults().getNumFound());
     
     
@@ -186,11 +185,11 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
     query = new SolrQuery("*:*");
     jetty = jettys.get(random().nextInt(jettys.size()));
     port = jetty.getLocalPort();
-    server = new HttpSolrServer(buildUrl(port) + "/testalias");
-    res = server.query(query);
+    client = new HttpSolrClient(buildUrl(port) + "/testalias");
+    res = client.query(query);
     assertEquals(5, res.getResults().getNumFound());
-    server.shutdown();
-    server = null;
+    client.shutdown();
+    client = null;
     
     // update alias
     createAlias("testalias", "collection2");
@@ -214,26 +213,26 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
     // try a std client
     // search 1 and 2, but have no collections param
     query = new SolrQuery("*:*");
-    HttpSolrServer client = new HttpSolrServer(getBaseUrl((HttpSolrServer) clients.get(0)) + "/testalias");
-    res = client.query(query);
+    HttpSolrClient httpclient = new HttpSolrClient(getBaseUrl((HttpSolrClient) clients.get(0)) + "/testalias");
+    res = httpclient.query(query);
     assertEquals(5, res.getResults().getNumFound());
-    client.shutdown();
-    client = null;
+    httpclient.shutdown();
+    httpclient = null;
     
     createAlias("testalias", "collection2");
     
     // a second alias
     createAlias("testalias2", "collection2");
     
-    client = new HttpSolrServer(getBaseUrl((HttpSolrServer) clients.get(0)) + "/testalias");
+    httpclient = new HttpSolrClient(getBaseUrl((HttpSolrClient) clients.get(0)) + "/testalias");
     SolrInputDocument doc8 = getDoc(id, 11, i1, -600, tlong, 600, t1,
         "humpty dumpy4 sat on a walls");
-    client.add(doc8);
-    client.commit();
+    httpclient.add(doc8);
+    httpclient.commit();
     res = client.query(query);
     assertEquals(3, res.getResults().getNumFound());
-    client.shutdown();
-    client = null;
+    httpclient.shutdown();
+    httpclient = null;
     
     createAlias("testalias", "collection2,collection1");
     
@@ -256,8 +255,8 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
 
   private void createAlias(String alias, String collections)
       throws SolrServerException, IOException {
-    SolrServer server = createNewSolrServer("",
-        getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("",
+        getBaseUrl((HttpSolrClient) clients.get(0)));
     if (random().nextBoolean()) {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("collections", collections);
@@ -265,33 +264,33 @@ public class AliasIntegrationTest extends AbstractFullDistribZkTestBase {
       params.set("action", CollectionAction.CREATEALIAS.toString());
       QueryRequest request = new QueryRequest(params);
       request.setPath("/admin/collections");
-      server.request(request);
+      client.request(request);
     } else {
       CreateAlias request = new CreateAlias();
       request.setAliasName(alias);
       request.setAliasedCollections(collections);
-      request.process(server);
+      request.process(client);
     }
-    server.shutdown();
+    client.shutdown();
   }
   
   private void deleteAlias(String alias) throws SolrServerException,
       IOException {
-    SolrServer server = createNewSolrServer("",
-        getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("",
+        getBaseUrl((HttpSolrClient) clients.get(0)));
     if (random().nextBoolean()) {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("name", alias);
       params.set("action", CollectionAction.DELETEALIAS.toString());
       QueryRequest request = new QueryRequest(params);
       request.setPath("/admin/collections");
-      server.request(request);
+      client.request(request);
     } else {
       DeleteAlias request = new DeleteAlias();
       request.setAliasName(alias);
-      request.process(server);
+      request.process(client);
     }
-    server.shutdown();
+    client.shutdown();
   }
   
   protected void indexDoc(List<CloudJettyRunner> skipServers, Object... fields) throws IOException,
diff --git a/solr/core/src/test/org/apache/solr/cloud/AsyncMigrateRouteKeyTest.java b/solr/core/src/test/org/apache/solr/cloud/AsyncMigrateRouteKeyTest.java
index 5ce9b9e..82414b2 100644
--- a/solr/core/src/test/org/apache/solr/cloud/AsyncMigrateRouteKeyTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/AsyncMigrateRouteKeyTest.java
@@ -19,7 +19,7 @@ package org.apache.solr.cloud;
 
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.params.CollectionParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -113,14 +113,14 @@ public class AsyncMigrateRouteKeyTest extends MigrateRouteKeyTest {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = null;
+    HttpSolrClient baseServer = null;
 
     try {
-      baseServer = new HttpSolrServer(baseUrl);
+      baseServer = new HttpSolrClient(baseUrl);
       baseServer.setConnectionTimeout(15000);
       return baseServer.request(request);
     } finally {
diff --git a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test.java b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test.java
index 67adfc6..d2b83f4 100644
--- a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test.java
+++ b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZk2Test.java
@@ -17,23 +17,15 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.FilenameFilter;
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
 import org.apache.http.client.methods.HttpGet;
 import org.apache.http.impl.client.BasicResponseHandler;
 import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Create;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
@@ -46,7 +38,13 @@ import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.handler.ReplicationHandler;
-import org.apache.solr.util.AbstractSolrTestCase;
+
+import java.io.File;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.util.Arrays;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 /**
  * This test simply does a bunch of basic things in solrcloud mode and asserts things
@@ -134,7 +132,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
       String nodeName = leaderProps.getStr(ZkStateReader.NODE_NAME_PROP);
       chaosMonkey.stopShardExcept(SHARD2, nodeName);
       
-      SolrServer client = getClient(nodeName);
+      SolrClient client = getClient(nodeName);
       
       index_specific(client, "id", docId + 1, t1, "what happens here?");
       
@@ -161,17 +159,17 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
   private void testNodeWithoutCollectionForwarding() throws Exception,
       SolrServerException, IOException {
     try {
-      final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
-      HttpSolrServer server = new HttpSolrServer(baseUrl);
-      server.setConnectionTimeout(30000);
+      final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
+      HttpSolrClient client = new HttpSolrClient(baseUrl);
+      client.setConnectionTimeout(30000);
       Create createCmd = new Create();
       createCmd.setRoles("none");
       createCmd.setCoreName(ONE_NODE_COLLECTION + "core");
       createCmd.setCollection(ONE_NODE_COLLECTION);
       createCmd.setNumShards(1);
       createCmd.setDataDir(getDataDir(createTempDir(ONE_NODE_COLLECTION).toFile().getAbsolutePath()));
-      server.request(createCmd);
-      server.shutdown();
+      client.request(createCmd);
+      client.shutdown();
     } catch (Exception e) {
       e.printStackTrace();
       fail(e.getMessage());
@@ -183,8 +181,8 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
     cloudClient.getZkStateReader().getLeaderRetry(ONE_NODE_COLLECTION, SHARD1, 30000);
     
     int docs = 2;
-    for (SolrServer client : clients) {
-      final String baseUrl = getBaseUrl((HttpSolrServer) client);
+    for (SolrClient client : clients) {
+      final String baseUrl = getBaseUrl((HttpSolrClient) client);
       addAndQueryDocs(baseUrl, docs);
       docs += 2;
     }
@@ -193,7 +191,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
   // 2 docs added every call
   private void addAndQueryDocs(final String baseUrl, int docs)
       throws Exception {
-    HttpSolrServer qclient = new HttpSolrServer(baseUrl + "/onenodecollection" + "core");
+    HttpSolrClient qclient = new HttpSolrClient(baseUrl + "/onenodecollection" + "core");
     
     // it might take a moment for the proxy node to see us in their cloud state
     waitForNon403or404or503(qclient);
@@ -209,7 +207,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
     assertEquals(docs - 1, results.getResults().getNumFound());
     qclient.shutdown();
     
-    qclient = new HttpSolrServer(baseUrl + "/onenodecollection");
+    qclient = new HttpSolrClient(baseUrl + "/onenodecollection");
     results = qclient.query(query);
     assertEquals(docs - 1, results.getResults().getNumFound());
     
@@ -351,7 +349,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
       System.err.println(controlClient.query(new SolrQuery("*:*")).getResults()
           .getNumFound());
       
-      for (SolrServer client : clients) {
+      for (SolrClient client : clients) {
         try {
           SolrQuery q = new SolrQuery("*:*");
           q.set("distrib", false);
@@ -411,7 +409,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
     checkShardConsistency(true, false);
     
     // try a backup command
-    final HttpSolrServer client = (HttpSolrServer) shardToJetty.get(SHARD2).get(0).client.solrClient;
+    final HttpSolrClient client = (HttpSolrClient) shardToJetty.get(SHARD2).get(0).client.solrClient;
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("qt", "/replication");
     params.set("command", "backup");
@@ -424,7 +422,7 @@ public class BasicDistributedZk2Test extends AbstractFullDistribZkTestBase {
     checkForBackupSuccess(client, location);
   }
 
-  private void checkForBackupSuccess(final HttpSolrServer client, File location)
+  private void checkForBackupSuccess(final HttpSolrClient client, File location)
       throws InterruptedException, IOException {
     class CheckStatus extends Thread {
       volatile String fail = null;
diff --git a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
index 9f91893..0930dcf 100644
--- a/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest.java
@@ -17,33 +17,16 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.Callable;
-import java.util.concurrent.CompletionService;
-import java.util.concurrent.ExecutorCompletionService;
-import java.util.concurrent.Future;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import org.apache.commons.lang.StringUtils;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.JSONTestUtil;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.ContentStreamUpdateRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Create;
@@ -70,6 +53,23 @@ import org.apache.solr.util.DefaultSolrThreadFactory;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CompletionService;
+import java.util.concurrent.ExecutorCompletionService;
+import java.util.concurrent.Future;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
 
 /**
  * This test simply does a bunch of basic things in solrcloud mode and asserts things
@@ -88,7 +88,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   String oddField="oddField_s";
   String missingField="ignore_exception__missing_but_valid_field_t";
 
-  private Map<String,List<SolrServer>> otherCollectionClients = new HashMap<>();
+  private Map<String,List<SolrClient>> otherCollectionClients = new HashMap<>();
 
   private String oneInstanceCollection = "oneInstanceCollection";
   private String oneInstanceCollection2 = "oneInstanceCollection2";
@@ -163,9 +163,9 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     // ask every individual replica of every shard to update+commit the same doc id
     // with an incrementing counter on each update+commit
     int foo_i_counter = 0;
-    for (SolrServer server : clients) {
+    for (SolrClient client : clients) {
       foo_i_counter++;
-      indexDoc(server, params("commit", "true"), // SOLR-4923
+      indexDoc(client, params("commit", "true"), // SOLR-4923
                sdoc(id,1, i1,100, tlong,100, "foo_i", foo_i_counter));
       // after every update+commit, check all the shards consistency
       queryAndCompareShards(params("q", "id:1", "distrib", "false", 
@@ -341,8 +341,8 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
       Thread.sleep(100);
     }
     
-    for (SolrServer client : clients) {
-      assertEquals("commitWithin did not work on node: " + ((HttpSolrServer)client).getBaseURL(), before + 1, client.query(new SolrQuery("*:*")).getResults().getNumFound());
+    for (SolrClient client : clients) {
+      assertEquals("commitWithin did not work on node: " + ((HttpSolrClient)client).getBaseURL(), before + 1, client.query(new SolrQuery("*:*")).getResults().getNumFound());
     }
     
     // TODO: This test currently fails because debug info is obtained only
@@ -381,14 +381,14 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     createCmd.setSchemaName("nonexistent_schema.xml");
     
     String url = getBaseUrl(clients.get(0));
-    final HttpSolrServer server = new HttpSolrServer(url);
+    final HttpSolrClient client = new HttpSolrClient(url);
     try {
-      server.request(createCmd);
+      client.request(createCmd);
       fail("Expected SolrCore create to fail");
     } catch (Exception e) {
       
     } finally {
-      server.shutdown();
+      client.shutdown();
     }
     
     long timeout = System.currentTimeMillis() + 15000;
@@ -410,9 +410,9 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     for (String shard : shardToJetty.keySet()) {
       // every client should give the same numDocs for this shard
       // shffle the clients in a diff order for each shard
-      List<SolrServer> solrclients = new ArrayList<>(this.clients);
+      List<SolrClient> solrclients = new ArrayList<>(this.clients);
       Collections.shuffle(solrclients, random());
-      for (SolrServer client : solrclients) {
+      for (SolrClient client : solrclients) {
         query.set("shards", shard);
         long numDocs = client.query(query).getResults().getNumFound();
         assertTrue("numDocs < 0 for shard "+shard+" via "+client,
@@ -484,7 +484,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     }
     String randShards = StringUtils.join(randomShards, ",");
     query.set("shards", randShards);
-    for (SolrServer client : this.clients) {
+    for (SolrClient client : this.clients) {
       assertEquals("numDocs for "+randShards+" via "+client,
                    randomShardCountsExpected, 
                    client.query(query).getResults().getNumFound());
@@ -496,7 +496,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     for (Long c : shardCounts.values()) {
       totalShardNumDocs += c;
     }
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       assertEquals("sum of shard numDocs on client: " + client, 
                    totalShardNumDocs,
                    client.query(query).getResults().getNumFound());
@@ -507,22 +507,22 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   }
 
   private void testStopAndStartCoresInOneInstance() throws Exception {
-    SolrServer client = clients.get(0);
+    SolrClient client = clients.get(0);
     String url3 = getBaseUrl(client);
-    final HttpSolrServer server = new HttpSolrServer(url3);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
+    final HttpSolrClient httpSolrClient = new HttpSolrClient(url3);
+    httpSolrClient.setConnectionTimeout(15000);
+    httpSolrClient.setSoTimeout(60000);
     ThreadPoolExecutor executor = new ThreadPoolExecutor(0, Integer.MAX_VALUE,
         5, TimeUnit.SECONDS, new SynchronousQueue<Runnable>(),
         new DefaultSolrThreadFactory("testExecutor"));
     int cnt = 3;
     
     // create the cores
-    createCores(server, executor, "multiunload2", 1, cnt);
+    createCores(httpSolrClient, executor, "multiunload2", 1, cnt);
     
     executor.shutdown();
     executor.awaitTermination(120, TimeUnit.SECONDS);
-    server.shutdown();
+    httpSolrClient.shutdown();
     
     ChaosMonkey.stop(cloudJettys.get(0).jetty);
     printLayout();
@@ -541,7 +541,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 
   }
 
-  protected void createCores(final HttpSolrServer server,
+  protected void createCores(final HttpSolrClient client,
       ThreadPoolExecutor executor, final String collection, final int numShards, int cnt) {
     for (int i = 0; i < cnt; i++) {
       final int freezeI = i;
@@ -558,7 +558,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
             String core3dataDir = createTempDir(collection).toFile().getAbsolutePath();
             createCmd.setDataDir(getDataDir(core3dataDir));
 
-            server.request(createCmd);
+            client.request(createCmd);
           } catch (SolrServerException e) {
             throw new RuntimeException(e);
           } catch (IOException e) {
@@ -570,17 +570,17 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     }
   }
 
-  protected String getBaseUrl(SolrServer client) {
-    String url2 = ((HttpSolrServer) client).getBaseURL()
+  protected String getBaseUrl(SolrClient client) {
+    String url2 = ((HttpSolrClient) client).getBaseURL()
         .substring(
             0,
-            ((HttpSolrServer) client).getBaseURL().length()
+            ((HttpSolrClient) client).getBaseURL().length()
                 - DEFAULT_COLLECTION.length() -1);
     return url2;
   }
 
   protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos,
-                                                     String collectionName, int numShards, int numReplicas, int maxShardsPerNode, SolrServer client, String createNodeSetStr) throws SolrServerException, IOException {
+                                                     String collectionName, int numShards, int numReplicas, int maxShardsPerNode, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException {
     // TODO: Use CollectionAdminRequest for this test
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action", CollectionAction.CREATE.toString());
@@ -603,12 +603,12 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 
     CollectionAdminResponse res = new CollectionAdminResponse();
     if (client == null) {
-      final String baseUrl = ((HttpSolrServer) clients.get(clientIndex)).getBaseURL().substring(
+      final String baseUrl = ((HttpSolrClient) clients.get(clientIndex)).getBaseURL().substring(
           0,
-          ((HttpSolrServer) clients.get(clientIndex)).getBaseURL().length()
+          ((HttpSolrClient) clients.get(clientIndex)).getBaseURL().length()
               - DEFAULT_COLLECTION.length() - 1);
       
-      SolrServer aClient = createNewSolrServer("", baseUrl);
+      SolrClient aClient = createNewSolrClient("", baseUrl);
       res.setResponse(aClient.request(request));
       aClient.shutdown();
     } else {
@@ -618,7 +618,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   }
   
   protected ZkCoreNodeProps getLeaderUrlFromZk(String collection, String slice) {
-    ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();
     ZkNodeProps leader = clusterState.getLeader(collection, slice);
     if (leader == null) {
       throw new RuntimeException("Could not find leader:" + collection + " " + slice);
@@ -647,7 +647,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     
     for (int i = 1; i < numLoops; i++) {
       // add doc to random client
-      SolrServer updateClient = clients.get(random().nextInt(clients.size()));
+      SolrClient updateClient = clients.get(random().nextInt(clients.size()));
       SolrInputDocument doc = new SolrInputDocument();
       addFields(doc, id, i, fieldA, val, fieldB, val);
       UpdateResponse ures = add(updateClient, updateParams, doc);
@@ -683,7 +683,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     indexDoc(sd);
 
     ignoreException("version conflict");
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       try {
         client.add(sd);
         fail();
@@ -700,14 +700,14 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 
     List<Integer> expected = new ArrayList<>();
     int val = 0;
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       val += 10;
       client.add(sdoc("id", 1000, "val_i", map("add",val), "foo_i",val));
       expected.add(val);
     }
 
     QueryRequest qr = new QueryRequest(params("qt", "/get", "id","1000"));
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       val += 10;
       NamedList rsp = client.request(qr);
       String match = JSONTestUtil.matchObj("/val_i", rsp.get("doc"), expected);
@@ -718,7 +718,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   private void testNumberOfCommitsWithCommitAfterAdd()
       throws SolrServerException, IOException {
     log.info("### STARTING testNumberOfCommitsWithCommitAfterAdd");
-    long startCommits = getNumCommits((HttpSolrServer) clients.get(0));
+    long startCommits = getNumCommits((HttpSolrClient) clients.get(0));
     
     ContentStreamUpdateRequest up = new ContentStreamUpdateRequest("/update");
     up.addFile(getFile("books_numeric_ids.csv"), "application/csv");
@@ -726,38 +726,38 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     up.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
     NamedList<Object> result = clients.get(0).request(up);
     
-    long endCommits = getNumCommits((HttpSolrServer) clients.get(0));
+    long endCommits = getNumCommits((HttpSolrClient) clients.get(0));
 
     assertEquals(startCommits + 1L, endCommits);
   }
 
-  private Long getNumCommits(HttpSolrServer solrServer) throws
+  private Long getNumCommits(HttpSolrClient sourceClient) throws
       SolrServerException, IOException {
-    HttpSolrServer server = new HttpSolrServer(solrServer.getBaseURL());
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
+    HttpSolrClient client = new HttpSolrClient(sourceClient.getBaseURL());
+    client.setConnectionTimeout(15000);
+    client.setSoTimeout(60000);
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("qt", "/admin/mbeans?key=updateHandler&stats=true");
     // use generic request to avoid extra processing of queries
     QueryRequest req = new QueryRequest(params);
-    NamedList<Object> resp = server.request(req);
+    NamedList<Object> resp = client.request(req);
     NamedList mbeans = (NamedList) resp.get("solr-mbeans");
     NamedList uhandlerCat = (NamedList) mbeans.get("UPDATEHANDLER");
     NamedList uhandler = (NamedList) uhandlerCat.get("updateHandler");
     NamedList stats = (NamedList) uhandler.get("stats");
     Long commits = (Long) stats.get("commits");
-    server.shutdown();
+    client.shutdown();
     return commits;
   }
 
   private void testANewCollectionInOneInstanceWithManualShardAssignement() throws Exception {
     log.info("### STARTING testANewCollectionInOneInstanceWithManualShardAssignement");
     System.clearProperty("numShards");
-    List<SolrServer> collectionClients = new ArrayList<>();
-    SolrServer client = clients.get(0);
-    final String baseUrl = ((HttpSolrServer) client).getBaseURL().substring(
+    List<SolrClient> collectionClients = new ArrayList<>();
+    SolrClient client = clients.get(0);
+    final String baseUrl = ((HttpSolrClient) client).getBaseURL().substring(
         0,
-        ((HttpSolrServer) client).getBaseURL().length()
+        ((HttpSolrClient) client).getBaseURL().length()
             - DEFAULT_COLLECTION.length() - 1);
     createSolrCore(oneInstanceCollection2, collectionClients, baseUrl, 1, "slice1");
     createSolrCore(oneInstanceCollection2, collectionClients, baseUrl, 2, "slice2");
@@ -770,16 +770,16 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
       pending.remove(future);
     }
     
-    SolrServer client1 = collectionClients.get(0);
-    SolrServer client2 = collectionClients.get(1);
-    SolrServer client3 = collectionClients.get(2);
-    SolrServer client4 = collectionClients.get(3);
+    SolrClient client1 = collectionClients.get(0);
+    SolrClient client2 = collectionClients.get(1);
+    SolrClient client3 = collectionClients.get(2);
+    SolrClient client4 = collectionClients.get(3);
     
 
     // no one should be recovering
-    waitForRecoveriesToFinish(oneInstanceCollection2, getCommonCloudSolrServer().getZkStateReader(), false, true);
+    waitForRecoveriesToFinish(oneInstanceCollection2, getCommonCloudSolrClient().getZkStateReader(), false, true);
     
-    assertAllActive(oneInstanceCollection2, getCommonCloudSolrServer().getZkStateReader());
+    assertAllActive(oneInstanceCollection2, getCommonCloudSolrClient().getZkStateReader());
     
     //printLayout();
     
@@ -800,7 +800,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     
     query.set("collection", oneInstanceCollection2);
     query.set("distrib", true);
-    long allDocs = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    long allDocs = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     
 //    System.out.println("1:" + oneDocs);
 //    System.out.println("2:" + twoDocs);
@@ -814,7 +814,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     assertEquals(3, allDocs);
     
     // we added a role of none on these creates - check for it
-    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();
     zkStateReader.updateClusterState(true);
     Map<String,Slice> slices = zkStateReader.getClusterState().getSlicesMap(oneInstanceCollection2);
     assertNotNull(slices);
@@ -822,19 +822,19 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     assertEquals("none", roles);
     
     
-    ZkCoreNodeProps props = new ZkCoreNodeProps(getCommonCloudSolrServer().getZkStateReader().getClusterState().getLeader(oneInstanceCollection2, "slice1"));
+    ZkCoreNodeProps props = new ZkCoreNodeProps(getCommonCloudSolrClient().getZkStateReader().getClusterState().getLeader(oneInstanceCollection2, "slice1"));
     
     // now test that unloading a core gets us a new leader
-    HttpSolrServer server = new HttpSolrServer(baseUrl);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
+    HttpSolrClient unloadClient = new HttpSolrClient(baseUrl);
+    unloadClient.setConnectionTimeout(15000);
+    unloadClient.setSoTimeout(60000);
     Unload unloadCmd = new Unload(true);
     unloadCmd.setCoreName(props.getCoreName());
     
     String leader = props.getCoreUrl();
     
-    server.request(unloadCmd);
-    server.shutdown();
+    unloadClient.request(unloadCmd);
+    unloadClient.shutdown();
     
     int tries = 50;
     while (leader.equals(zkStateReader.getLeaderUrl(oneInstanceCollection2, "slice1", 10000))) {
@@ -844,7 +844,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
       }
     }
 
-    for (SolrServer aClient : collectionClients) {
+    for (SolrClient aClient : collectionClients) {
       aClient.shutdown();
     }
 
@@ -852,15 +852,15 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 
   private void testSearchByCollectionName() throws SolrServerException {
     log.info("### STARTING testSearchByCollectionName");
-    SolrServer client = clients.get(0);
-    final String baseUrl = ((HttpSolrServer) client).getBaseURL().substring(
+    SolrClient client = clients.get(0);
+    final String baseUrl = ((HttpSolrClient) client).getBaseURL().substring(
         0,
-        ((HttpSolrServer) client).getBaseURL().length()
+        ((HttpSolrClient) client).getBaseURL().length()
             - DEFAULT_COLLECTION.length() - 1);
     
     // the cores each have different names, but if we add the collection name to the url
     // we should get mapped to the right core
-    SolrServer client1 = createNewSolrServer(oneInstanceCollection, baseUrl);
+    SolrClient client1 = createNewSolrClient(oneInstanceCollection, baseUrl);
     SolrQuery query = new SolrQuery("*:*");
     long oneDocs = client1.query(query).getResults().getNumFound();
     assertEquals(3, oneDocs);
@@ -869,27 +869,27 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   
   private void testUpdateByCollectionName() throws SolrServerException, IOException {
     log.info("### STARTING testUpdateByCollectionName");
-    SolrServer client = clients.get(0);
-    final String baseUrl = ((HttpSolrServer) client).getBaseURL().substring(
+    SolrClient client = clients.get(0);
+    final String baseUrl = ((HttpSolrClient) client).getBaseURL().substring(
         0,
-        ((HttpSolrServer) client).getBaseURL().length()
+        ((HttpSolrClient) client).getBaseURL().length()
             - DEFAULT_COLLECTION.length() - 1);
     
     // the cores each have different names, but if we add the collection name to the url
     // we should get mapped to the right core
     // test hitting an update url
-    SolrServer client1 = createNewSolrServer(oneInstanceCollection, baseUrl);
+    SolrClient client1 = createNewSolrClient(oneInstanceCollection, baseUrl);
     client1.commit();
     client1.shutdown();
   }
 
   private void testANewCollectionInOneInstance() throws Exception {
     log.info("### STARTING testANewCollectionInOneInstance");
-    List<SolrServer> collectionClients = new ArrayList<>();
-    SolrServer client = clients.get(0);
-    final String baseUrl = ((HttpSolrServer) client).getBaseURL().substring(
+    List<SolrClient> collectionClients = new ArrayList<>();
+    SolrClient client = clients.get(0);
+    final String baseUrl = ((HttpSolrClient) client).getBaseURL().substring(
         0,
-        ((HttpSolrServer) client).getBaseURL().length()
+        ((HttpSolrClient) client).getBaseURL().length()
             - DEFAULT_COLLECTION.length() - 1);
     createCollection(oneInstanceCollection, collectionClients, baseUrl, 1);
     createCollection(oneInstanceCollection, collectionClients, baseUrl, 2);
@@ -903,13 +903,13 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
       pending.remove(future);
     }
    
-    SolrServer client1 = collectionClients.get(0);
-    SolrServer client2 = collectionClients.get(1);
-    SolrServer client3 = collectionClients.get(2);
-    SolrServer client4 = collectionClients.get(3);
+    SolrClient client1 = collectionClients.get(0);
+    SolrClient client2 = collectionClients.get(1);
+    SolrClient client3 = collectionClients.get(2);
+    SolrClient client4 = collectionClients.get(3);
  
-    waitForRecoveriesToFinish(oneInstanceCollection, getCommonCloudSolrServer().getZkStateReader(), false);
-    assertAllActive(oneInstanceCollection, getCommonCloudSolrServer().getZkStateReader());
+    waitForRecoveriesToFinish(oneInstanceCollection, getCommonCloudSolrClient().getZkStateReader(), false);
+    assertAllActive(oneInstanceCollection, getCommonCloudSolrClient().getZkStateReader());
     
     client2.add(getDoc(id, "1")); 
     client3.add(getDoc(id, "2")); 
@@ -925,7 +925,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     
     query.set("collection", oneInstanceCollection);
     query.set("distrib", true);
-    long allDocs = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    long allDocs = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     
 //    System.out.println("1:" + oneDocs);
 //    System.out.println("2:" + twoDocs);
@@ -934,26 +934,26 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
 //    System.out.println("All Docs:" + allDocs);
     
     assertEquals(3, allDocs);
-    for(SolrServer newCollectionClient:collectionClients) {
+    for(SolrClient newCollectionClient:collectionClients) {
       newCollectionClient.shutdown();
     }
   }
 
   private void createCollection(String collection,
-      List<SolrServer> collectionClients, String baseUrl, int num) {
+      List<SolrClient> collectionClients, String baseUrl, int num) {
     createSolrCore(collection, collectionClients, baseUrl, num, null);
   }
   
   private void createSolrCore(final String collection,
-      List<SolrServer> collectionClients, final String baseUrl, final int num,
+      List<SolrClient> collectionClients, final String baseUrl, final int num,
       final String shardId) {
     Callable call = new Callable() {
       @Override
       public Object call() {
-        HttpSolrServer server = null;
+        HttpSolrClient client = null;
         try {
-          server = new HttpSolrServer(baseUrl);
-          server.setConnectionTimeout(15000);
+          client = new HttpSolrClient(baseUrl);
+          client.setConnectionTimeout(15000);
           Create createCmd = new Create();
           createCmd.setRoles("none");
           createCmd.setCoreName(collection + num);
@@ -971,13 +971,13 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
           if (shardId != null) {
             createCmd.setShardId(shardId);
           }
-          server.request(createCmd);
+          client.request(createCmd);
         } catch (Exception e) {
           e.printStackTrace();
           //fail
         } finally {
-          if (server != null) {
-            server.shutdown();
+          if (client != null) {
+            client.shutdown();
           }
         }
         return null;
@@ -987,7 +987,7 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     pending.add(completionService.submit(call));
  
     
-    collectionClients.add(createNewSolrServer(collection + num, baseUrl));
+    collectionClients.add(createNewSolrClient(collection + num, baseUrl));
   }
 
   private void testMultipleCollections() throws Exception {
@@ -1006,21 +1006,21 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     indexDoc("collection2", getDoc(id, "10000000")); 
     indexDoc("collection2", getDoc(id, "10000001")); 
     indexDoc("collection2", getDoc(id, "10000003"));
-    getCommonCloudSolrServer().setDefaultCollection("collection2");
-    getCommonCloudSolrServer().add(getDoc(id, "10000004"));
-    getCommonCloudSolrServer().setDefaultCollection(null);
+    getCommonCloudSolrClient().setDefaultCollection("collection2");
+    getCommonCloudSolrClient().add(getDoc(id, "10000004"));
+    getCommonCloudSolrClient().setDefaultCollection(null);
     
     indexDoc("collection3", getDoc(id, "20000000"));
     indexDoc("collection3", getDoc(id, "20000001")); 
-    getCommonCloudSolrServer().setDefaultCollection("collection3");
-    getCommonCloudSolrServer().add(getDoc(id, "10000005"));
-    getCommonCloudSolrServer().setDefaultCollection(null);
+    getCommonCloudSolrClient().setDefaultCollection("collection3");
+    getCommonCloudSolrClient().add(getDoc(id, "10000005"));
+    getCommonCloudSolrClient().setDefaultCollection(null);
     
     otherCollectionClients.get("collection2").get(0).commit();
     otherCollectionClients.get("collection3").get(0).commit();
     
-    getCommonCloudSolrServer().setDefaultCollection("collection1");
-    long collection1Docs = getCommonCloudSolrServer().query(new SolrQuery("*:*")).getResults()
+    getCommonCloudSolrClient().setDefaultCollection("collection1");
+    long collection1Docs = getCommonCloudSolrClient().query(new SolrQuery("*:*")).getResults()
         .getNumFound();
 
     long collection2Docs = otherCollectionClients.get("collection2").get(0)
@@ -1041,19 +1041,19 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     assertEquals(collection1Docs + collection2Docs + collection3Docs, found);
     
     // try to search multiple with cloud client
-    found = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    found = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     assertEquals(collection1Docs + collection2Docs + collection3Docs, found);
     
     query.set("collection", "collection2,collection3");
-    found = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    found = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     assertEquals(collection2Docs + collection3Docs, found);
     
     query.set("collection", "collection3");
-    found = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    found = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     assertEquals(collection3Docs, found);
     
     query.remove("collection");
-    found = getCommonCloudSolrServer().query(query).getResults().getNumFound();
+    found = getCommonCloudSolrClient().query(query).getResults().getNumFound();
     assertEquals(collection1Docs, found);
     
     assertEquals(collection3Docs, collection2Docs - 1);
@@ -1066,49 +1066,49 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
   }
   
   protected void indexDoc(String collection, SolrInputDocument doc) throws IOException, SolrServerException {
-    List<SolrServer> clients = otherCollectionClients.get(collection);
+    List<SolrClient> clients = otherCollectionClients.get(collection);
     int which = (doc.getField(id).toString().hashCode() & 0x7fffffff) % clients.size();
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     client.add(doc);
   }
   
   private void createNewCollection(final String collection) throws InterruptedException {
-    final List<SolrServer> collectionClients = new ArrayList<>();
+    final List<SolrClient> collectionClients = new ArrayList<>();
     otherCollectionClients.put(collection, collectionClients);
     int unique = 0;
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       unique++;
-      final String baseUrl = ((HttpSolrServer) client).getBaseURL()
+      final String baseUrl = ((HttpSolrClient) client).getBaseURL()
           .substring(
               0,
-              ((HttpSolrServer) client).getBaseURL().length()
+              ((HttpSolrClient) client).getBaseURL().length()
                   - DEFAULT_COLLECTION.length() -1);
       final int frozeUnique = unique;
       Callable call = new Callable() {
         @Override
         public Object call() {
-          HttpSolrServer server = null;
+          HttpSolrClient client = null;
           try {
-            server = new HttpSolrServer(baseUrl);
-            server.setConnectionTimeout(15000);
-            server.setSoTimeout(60000);
+            client = new HttpSolrClient(baseUrl);
+            client.setConnectionTimeout(15000);
+            client.setSoTimeout(60000);
             Create createCmd = new Create();
             createCmd.setCoreName(collection);
             createCmd.setDataDir(getDataDir(createTempDir(collection).toFile().getAbsolutePath()));
-            server.request(createCmd);
+            client.request(createCmd);
           } catch (Exception e) {
             e.printStackTrace();
             //fails
           } finally {
-            if (server != null) {
-              server.shutdown();
+            if (client != null) {
+              client.shutdown();
             }
           }
           return null;
         }
       };
      
-      collectionClients.add(createNewSolrServer(collection, baseUrl));
+      collectionClients.add(createNewSolrClient(collection, baseUrl));
       pending.add(completionService.submit(call));
       while (pending != null && pending.size() > 0) {
         
@@ -1119,33 +1119,33 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     }
   }
   
-  protected SolrServer createNewSolrServer(String collection, String baseUrl) {
+  protected SolrClient createNewSolrClient(String collection, String baseUrl) {
     try {
       // setup the server...
-      HttpSolrServer s = new HttpSolrServer(baseUrl + "/" + collection);
-      s.setSoTimeout(120000);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      HttpSolrClient client = new HttpSolrClient(baseUrl + "/" + collection);
+      client.setSoTimeout(120000);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     }
     catch (Exception ex) {
       throw new RuntimeException(ex);
     }
   }
 
-  volatile CloudSolrServer commondCloudSolrServer;
-  protected CloudSolrServer getCommonCloudSolrServer() {
-    if (commondCloudSolrServer == null) {
+  volatile CloudSolrClient commondCloudSolrClient;
+  protected CloudSolrClient getCommonCloudSolrClient() {
+    if (commondCloudSolrClient == null) {
       synchronized(this) {
-        commondCloudSolrServer = new CloudSolrServer(zkServer.getZkAddress(), random().nextBoolean());
-        commondCloudSolrServer.setParallelUpdates(random().nextBoolean());
-        commondCloudSolrServer.setDefaultCollection(DEFAULT_COLLECTION);
-        commondCloudSolrServer.getLbServer().setConnectionTimeout(15000);
-        commondCloudSolrServer.getLbServer().setSoTimeout(30000);
-        commondCloudSolrServer.connect();
+        commondCloudSolrClient = new CloudSolrClient(zkServer.getZkAddress(), random().nextBoolean());
+        commondCloudSolrClient.setParallelUpdates(random().nextBoolean());
+        commondCloudSolrClient.setDefaultCollection(DEFAULT_COLLECTION);
+        commondCloudSolrClient.getLbClient().setConnectionTimeout(15000);
+        commondCloudSolrClient.getLbClient().setSoTimeout(30000);
+        commondCloudSolrClient.connect();
       }
     }
-    return commondCloudSolrServer;
+    return commondCloudSolrClient;
   }
 
   @Override
@@ -1157,19 +1157,19 @@ public class BasicDistributedZkTest extends AbstractFullDistribZkTestBase {
     if (r.nextBoolean())
       params.set("collection",DEFAULT_COLLECTION);
 
-    QueryResponse rsp = getCommonCloudSolrServer().query(params);
+    QueryResponse rsp = getCommonCloudSolrClient().query(params);
     return rsp;
   }
   
   @Override
   public void tearDown() throws Exception {
     super.tearDown();
-    if (commondCloudSolrServer != null) {
-      commondCloudSolrServer.shutdown();
+    if (commondCloudSolrClient != null) {
+      commondCloudSolrClient.shutdown();
     }
     if (otherCollectionClients != null) {
-      for (List<SolrServer> clientList : otherCollectionClients.values()) {
-        for (SolrServer client : clientList) {
+      for (List<SolrClient> clientList : otherCollectionClients.values()) {
+        for (SolrClient client : clientList) {
           client.shutdown();
         }
       }
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
index 416df10..166aa53 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyNothingIsSafeTest.java
@@ -17,22 +17,16 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.net.ConnectException;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.atomic.AtomicInteger;
-
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;
 import org.apache.http.client.HttpClient;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.core.Diagnostics;
@@ -44,7 +38,12 @@ import org.junit.BeforeClass;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakLingering;
+import java.net.ConnectException;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.concurrent.atomic.AtomicInteger;
 
 @Slow
 @SuppressSSL
@@ -253,7 +252,7 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
         zkServer.run();
       }
       
-      CloudSolrServer client = createCloudClient("collection1");
+      CloudSolrClient client = createCloudClient("collection1");
       try {
           createCollection(null, "testcollection",
               1, 1, 1, client, null, "conf1");
@@ -294,11 +293,11 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
     private HttpClient httpClient = HttpClientUtil.createClient(null);
     private volatile boolean stop = false;
     int clientIndex = 0;
-    private ConcurrentUpdateSolrServer suss;
-    private List<SolrServer> clients;  
+    private ConcurrentUpdateSolrClient cusc;
+    private List<SolrClient> clients;
     private AtomicInteger fails = new AtomicInteger();
     
-    public FullThrottleStopableIndexingThread(List<SolrServer> clients,
+    public FullThrottleStopableIndexingThread(List<SolrClient> clients,
         String id, boolean doDeletes) {
       super(controlClient, cloudClient, id, doDeletes);
       setName("FullThrottleStopableIndexingThread");
@@ -306,12 +305,12 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
       this.clients = clients;
       HttpClientUtil.setConnectionTimeout(httpClient, 15000);
       HttpClientUtil.setSoTimeout(httpClient, 15000);
-      suss = new ConcurrentUpdateSolrServer(
-          ((HttpSolrServer) clients.get(0)).getBaseURL(), httpClient, 8,
+      cusc = new ConcurrentUpdateSolrClient(
+          ((HttpSolrClient) clients.get(0)).getBaseURL(), httpClient, 8,
           2) {
         @Override
         public void handleError(Throwable ex) {
-          log.warn("suss error", ex);
+          log.warn("cusc error", ex);
         }
       };
     }
@@ -330,7 +329,7 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
           String delete = deletes.remove(0);
           try {
             numDeletes++;
-            suss.deleteById(delete);
+            cusc.deleteById(delete);
           } catch (Exception e) {
             changeUrlOnError(e);
             //System.err.println("REQUEST FAILED:");
@@ -350,7 +349,7 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
               50,
               t1,
               "Saxon heptarchies that used to rip around so in old times and raise Cain.  My, you ought to seen old Henry the Eight when he was in bloom.  He WAS a blossom.  He used to marry a new wife every day, and chop off her head next morning.  And he would do it just as indifferent as if ");
-          suss.add(doc);
+          cusc.add(doc);
         } catch (Exception e) {
           changeUrlOnError(e);
           //System.err.println("REQUEST FAILED:");
@@ -373,13 +372,13 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
         if (clientIndex > clients.size() - 1) {
           clientIndex = 0;
         }
-        suss.shutdownNow();
-        suss = new ConcurrentUpdateSolrServer(
-            ((HttpSolrServer) clients.get(clientIndex)).getBaseURL(),
+        cusc.shutdownNow();
+        cusc = new ConcurrentUpdateSolrClient(
+            ((HttpSolrClient) clients.get(clientIndex)).getBaseURL(),
             httpClient, 30, 3) {
           @Override
           public void handleError(Throwable ex) {
-            log.warn("suss error", ex);
+            log.warn("cusc error", ex);
           }
         };
       }
@@ -388,8 +387,8 @@ public class ChaosMonkeyNothingIsSafeTest extends AbstractFullDistribZkTestBase
     @Override
     public void safeStop() {
       stop = true;
-      suss.blockUntilFinished();
-      suss.shutdownNow();
+      cusc.blockUntilFinished();
+      cusc.shutdownNow();
       httpClient.getConnectionManager().shutdown();
     }
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
index 959237f..44dd9dc 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeySafeLeaderTest.java
@@ -24,7 +24,7 @@ import java.util.concurrent.TimeUnit;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.core.Diagnostics;
 import org.apache.solr.update.SolrCmdDistributor;
@@ -172,7 +172,7 @@ public class ChaosMonkeySafeLeaderTest extends AbstractFullDistribZkTestBase {
       zkServer.run();
     }
     
-    CloudSolrServer client = createCloudClient("collection1");
+    CloudSolrClient client = createCloudClient("collection1");
     try {
         createCollection(null, "testcollection",
             1, 1, 1, client, null, "conf1");
diff --git a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest.java b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest.java
index bf33526..9c3be9b 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ChaosMonkeyShardSplitTest.java
@@ -18,7 +18,7 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.ClusterState;
 import org.apache.solr.common.cloud.DocCollection;
@@ -77,7 +77,7 @@ public class ChaosMonkeyShardSplitTest extends ShardSplitTest {
     Thread indexThread = null;
     OverseerRestarter killer = null;
     Thread killerThread = null;
-    final SolrServer solrServer = clients.get(0);
+    final SolrClient solrClient = clients.get(0);
 
     try {
       del("*:*");
@@ -146,8 +146,8 @@ public class ChaosMonkeyShardSplitTest extends ShardSplitTest {
     } finally {
       if (indexThread != null)
         indexThread.join();
-      if (solrServer != null)
-        solrServer.commit();
+      if (solrClient != null)
+        solrClient.commit();
       if (killer != null) {
         killer.run = false;
         if (killerThread != null) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIAsyncDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIAsyncDistributedZkTest.java
index 537edc1..0e5e522 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIAsyncDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIAsyncDistributedZkTest.java
@@ -18,9 +18,9 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.Create;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.RequestStatus;
@@ -69,16 +69,16 @@ public class CollectionsAPIAsyncDistributedZkTest extends AbstractFullDistribZkT
   }
 
   private void testSolrJAPICalls() throws Exception {
-    SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
 
     Create createCollectionRequest = new Create();
     createCollectionRequest.setCollectionName("testasynccollectioncreation");
     createCollectionRequest.setNumShards(1);
     createCollectionRequest.setConfigName("conf1");
     createCollectionRequest.setAsyncId("1001");
-    createCollectionRequest.process(server);
+    createCollectionRequest.process(client);
 
-    String state = getRequestStateAfterCompletion("1001", MAX_TIMEOUT_SECONDS, server);
+    String state = getRequestStateAfterCompletion("1001", MAX_TIMEOUT_SECONDS, client);
 
     assertEquals("CreateCollection task did not complete!", "completed", state);
 
@@ -88,9 +88,9 @@ public class CollectionsAPIAsyncDistributedZkTest extends AbstractFullDistribZkT
     createCollectionRequest.setNumShards(1);
     createCollectionRequest.setConfigName("conf1");
     createCollectionRequest.setAsyncId("1002");
-    createCollectionRequest.process(server);
+    createCollectionRequest.process(client);
 
-    state = getRequestStateAfterCompletion("1002", MAX_TIMEOUT_SECONDS, server);
+    state = getRequestStateAfterCompletion("1002", MAX_TIMEOUT_SECONDS, client);
 
     assertEquals("Recreating a collection with the same name didn't fail, should have.", "failed", state);
 
@@ -98,8 +98,8 @@ public class CollectionsAPIAsyncDistributedZkTest extends AbstractFullDistribZkT
     addReplica.setCollectionName("testasynccollectioncreation");
     addReplica.setShardName("shard1");
     addReplica.setAsyncId("1003");
-    server.request(addReplica);
-    state = getRequestStateAfterCompletion("1003", MAX_TIMEOUT_SECONDS, server);
+    client.request(addReplica);
+    state = getRequestStateAfterCompletion("1003", MAX_TIMEOUT_SECONDS, client);
     assertEquals("Add replica did not complete", "completed", state);
 
 
@@ -107,18 +107,18 @@ public class CollectionsAPIAsyncDistributedZkTest extends AbstractFullDistribZkT
     splitShardRequest.setCollectionName("testasynccollectioncreation");
     splitShardRequest.setShardName("shard1");
     splitShardRequest.setAsyncId("1004");
-    splitShardRequest.process(server);
+    splitShardRequest.process(client);
 
-    state = getRequestStateAfterCompletion("1004", MAX_TIMEOUT_SECONDS * 2, server);
+    state = getRequestStateAfterCompletion("1004", MAX_TIMEOUT_SECONDS * 2, client);
 
     assertEquals("Shard split did not complete. Last recorded state: " + state, "completed", state);
   }
 
-  private String getRequestStateAfterCompletion(String requestId, int waitForSeconds, SolrServer server)
+  private String getRequestStateAfterCompletion(String requestId, int waitForSeconds, SolrClient client)
       throws IOException, SolrServerException {
     String state = null;
     while(waitForSeconds-- > 0) {
-      state = getRequestState(requestId, server);
+      state = getRequestState(requestId, client);
       if(state.equals("completed") || state.equals("failed"))
         return state;
       try {
@@ -129,10 +129,10 @@ public class CollectionsAPIAsyncDistributedZkTest extends AbstractFullDistribZkT
     return state;
   }
 
-  private String getRequestState(String requestId, SolrServer server) throws IOException, SolrServerException {
+  private String getRequestState(String requestId, SolrClient client) throws IOException, SolrServerException {
     RequestStatus request = new RequestStatus();
     request.setRequestId(requestId);
-    CollectionAdminResponse response = request.process(server);
+    CollectionAdminResponse response = request.process(client);
     NamedList innerResponse = (NamedList) response.getResponse().get("status");
     return (String) innerResponse.get("state");
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
index 058ef7a..b47e963 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPIDistributedZkTest.java
@@ -17,39 +17,15 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import javax.management.MBeanServer;
-import javax.management.MBeanServerFactory;
-import javax.management.ObjectName;
-import java.io.File;
-import java.io.IOException;
-import java.lang.management.ManagementFactory;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Objects;
-import java.util.Set;
-import java.util.concurrent.CompletionService;
-import java.util.concurrent.ExecutorCompletionService;
-import java.util.concurrent.Future;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer.RemoteSolrException;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient.RemoteSolrException;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Create;
@@ -84,6 +60,31 @@ import org.apache.solr.util.DefaultSolrThreadFactory;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import javax.management.MBeanServer;
+import javax.management.MBeanServerFactory;
+import javax.management.ObjectName;
+import java.io.File;
+import java.io.IOException;
+import java.lang.management.ManagementFactory;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Objects;
+import java.util.Set;
+import java.util.concurrent.CompletionService;
+import java.util.concurrent.ExecutorCompletionService;
+import java.util.concurrent.Future;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
 import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
 import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
 import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
@@ -213,7 +214,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   private void deleteCollectionRemovesStaleZkCollectionsNode() throws Exception {
     
     // we can use this client because we just want base url
-    final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     
     String collectionName = "out_of_sync_collection";
     
@@ -230,7 +231,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     QueryRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
     try {
-      NamedList<Object> resp = createNewSolrServer("", baseUrl)
+      NamedList<Object> resp = createNewSolrClient("", baseUrl)
           .request(request);
       fail("Expected to fail, because collection is not in clusterstate");
     } catch (RemoteSolrException e) {
@@ -244,7 +245,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   }
 
   private void deletePartiallyCreatedCollection() throws Exception {
-    final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     String collectionName = "halfdeletedcollection";
     Create createCmd = new Create();
     createCmd.setCoreName("halfdeletedcollection_shard1_replica1");
@@ -255,7 +256,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     if (secondConfigSet) {
       createCmd.setCollectionConfigName("conf1");
     }
-    createNewSolrServer("", baseUrl).request(createCmd);
+    createNewSolrClient("", baseUrl).request(createCmd);
 
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action", CollectionAction.DELETE.toString());
@@ -263,7 +264,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     QueryRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    NamedList<Object> resp = createNewSolrServer("", baseUrl).request(request);
+    NamedList<Object> resp = createNewSolrClient("", baseUrl).request(request);
     
     checkForMissingCollection(collectionName);
     
@@ -277,19 +278,19 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     if (secondConfigSet) {
       params.set("collection.configName", "conf1");
     }
-    resp = createNewSolrServer("", baseUrl).request(request);
+    resp = createNewSolrClient("", baseUrl).request(request);
   }
   
   
   private void deleteCollectionWithDownNodes() throws Exception {
-    String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     // now try to remove a collection when a couple of its nodes are down
     if (secondConfigSet) {
       createCollection(null, "halfdeletedcollection2", 3, 3, 6,
-          createNewSolrServer("", baseUrl), null, "conf2");
+          createNewSolrClient("", baseUrl), null, "conf2");
     } else {
       createCollection(null, "halfdeletedcollection2", 3, 3, 6,
-          createNewSolrServer("", baseUrl), null);
+          createNewSolrClient("", baseUrl), null);
     }
     
     waitForRecoveriesToFinish("halfdeletedcollection2", false);
@@ -303,7 +304,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
       cloudClient.getZkStateReader().getLeaderRetry("halfdeletedcollection2", "shard" + i, 30000);
     }
     
-    baseUrl = getBaseUrl((HttpSolrServer) clients.get(2));
+    baseUrl = getBaseUrl((HttpSolrClient) clients.get(2));
     
     // remove a collection
     ModifiableSolrParams params = new ModifiableSolrParams();
@@ -312,7 +313,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     QueryRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
     
-    createNewSolrServer("", baseUrl).request(request);
+    createNewSolrClient("", baseUrl).request(request);
     
     long timeout = System.currentTimeMillis() + 10000;
     while (cloudClient.getZkStateReader().getClusterState().hasCollection("halfdeletedcollection2")) {
@@ -329,7 +330,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   }
 
   private void testErrorHandling() throws Exception {
-    final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     
     
     // try a bad action
@@ -343,7 +344,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     boolean gotExp = false;
     NamedList<Object> resp = null;
     try {
-      resp = createNewSolrServer("", baseUrl).request(request);
+      resp = createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       gotExp = true;
     }
@@ -365,7 +366,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     gotExp = false;
     resp = null;
     try {
-      resp = createNewSolrServer("", baseUrl).request(request);
+      resp = createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       gotExp = true;
     }
@@ -385,7 +386,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     request.setPath("/admin/collections");
     gotExp = false;
     try {
-      resp = createNewSolrServer("", baseUrl).request(request);
+      resp = createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       gotExp = true;
     }
@@ -405,7 +406,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     gotExp = false;
     resp = null;
     try {
-      resp = createNewSolrServer("", baseUrl).request(request);
+      resp = createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       gotExp = true;
     }
@@ -426,7 +427,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     gotExp = false;
     resp = null;
     try {
-      resp = createNewSolrServer("", baseUrl).request(request);
+      resp = createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       gotExp = true;
     }
@@ -445,7 +446,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     if (secondConfigSet) {
       createCmd.setCollectionConfigName("conf1");
     }
-    createNewSolrServer("", baseUrl).request(createCmd);
+    createNewSolrClient("", baseUrl).request(createCmd);
     
     createCmd = new Create();
     createCmd.setCoreName("halfcollection_shard1_replica1");
@@ -456,7 +457,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     if (secondConfigSet) {
       createCmd.setCollectionConfigName("conf1");
     }
-    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(1))).request(createCmd);
+    createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(1))).request(createCmd);
     
     params = new ModifiableSolrParams();
     params.set("action", CollectionAction.CREATE.toString());
@@ -476,7 +477,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     request = new QueryRequest(params);
     request.setPath("/admin/collections");
     gotExp = false;
-    resp = createNewSolrServer("", baseUrl).request(request);
+    resp = createNewSolrClient("", baseUrl).request(request);
     
     SimpleOrderedMap success = (SimpleOrderedMap) resp.get("success");
     SimpleOrderedMap failure = (SimpleOrderedMap) resp.get("failure");
@@ -506,14 +507,14 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
       createCmd.setCollectionConfigName("conf1");
     }
     
-    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(1)))
+    createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(1)))
         .request(createCmd);
     
     // try and create a SolrCore with no collection name
     createCmd.setCollection(null);
     createCmd.setCoreName("corewithnocollection2");
     
-    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(1)))
+    createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(1)))
         .request(createCmd);
     
     // in both cases, the collection should have default to the core name
@@ -524,7 +525,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
 
   private void testNodesUsedByCreate() throws Exception {
     // we can use this client because we just want base url
-    final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action", CollectionAction.CREATE.toString());
@@ -541,7 +542,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     
     QueryRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
-    createNewSolrServer("", baseUrl).request(request);
+    createNewSolrClient("", baseUrl).request(request);
     
     List<Integer> numShardsNumReplicaList = new ArrayList<>();
     numShardsNumReplicaList.add(2);
@@ -572,7 +573,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   private void testCollectionsAPI() throws Exception {
 
     boolean disableLegacy = random().nextBoolean();
-    CloudSolrServer client1 = null;
+    CloudSolrClient client1 = null;
 
     if (disableLegacy) {
       log.info("legacyCloud=false");
@@ -592,11 +593,11 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     for (int i = 0; i < cnt; i++) {
       int numShards = TestUtil.nextInt(random(), 0, shardCount) + 1;
       int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 1;
-      int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
+      int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
           .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
       
-      CloudSolrServer client = null;
+      CloudSolrClient client = null;
       try {
         if (i == 0) {
           // Test if we can create a collection through CloudSolrServer where
@@ -637,7 +638,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
       
       String url = getUrlFromZk(collection);
 
-      HttpSolrServer collectionClient = new HttpSolrServer(url);
+      HttpSolrClient collectionClient = new HttpSolrClient(url);
       
       // poll for a second - it can take a moment before we are ready to serve
       waitForNon403or404or503(collectionClient);
@@ -657,7 +658,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
         
         String url = getUrlFromZk(collection);
         
-        HttpSolrServer collectionClient = new HttpSolrServer(url);
+        HttpSolrClient collectionClient = new HttpSolrClient(url);
         
         // poll for a second - it can take a moment before we are ready to serve
         waitForNon403or404or503(collectionClient);
@@ -678,7 +679,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
       ChaosMonkey.causeConnectionLoss(jetty);
     }
     
-    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();
     for (int j = 0; j < cnt; j++) {
       waitForRecoveriesToFinish("awholynewcollection_" + j, zkStateReader, false);
       
@@ -704,7 +705,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     
     String url = getUrlFromZk(collectionName);
 
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
     
     
     // lets try and use the solrj client to index a couple documents
@@ -740,9 +741,9 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     request.setPath("/admin/collections");
     
     // we can use this client because we just want base url
-    final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(0));
+    final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(0));
     
-    createNewSolrServer("", baseUrl).request(request);
+    createNewSolrClient("", baseUrl).request(request);
 
     // reloads make take a short while
     boolean allTimesAreCorrect = waitForReloads(collectionName, urlToTimeBefore);
@@ -758,7 +759,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     request = new QueryRequest(params);
     request.setPath("/admin/collections");
  
-    createNewSolrServer("", baseUrl).request(request);
+    createNewSolrClient("", baseUrl).request(request);
     
     // ensure its out of the state
     checkForMissingCollection(collectionName);
@@ -774,7 +775,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
  
     boolean exp = false;
     try {
-      createNewSolrServer("", baseUrl).request(request);
+      createNewSolrClient("", baseUrl).request(request);
     } catch (SolrException e) {
       exp = true;
     }
@@ -794,7 +795,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     }
     request = new QueryRequest(params);
     request.setPath("/admin/collections");
-    createNewSolrServer("", baseUrl).request(request);
+    createNewSolrClient("", baseUrl).request(request);
     
     List<Integer> list = new ArrayList<>(2);
     list.add(1);
@@ -803,7 +804,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     
     url = getUrlFromZk(collectionName);
     
-    collectionClient = new HttpSolrServer(url);
+    collectionClient = new HttpSolrClient(url);
     
     // poll for a second - it can take a moment before we are ready to serve
     waitForNon403or404or503(collectionClient);
@@ -815,12 +816,12 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     }
 
     // test maxShardsPerNode
-    int numLiveNodes = getCommonCloudSolrServer().getZkStateReader().getClusterState().getLiveNodes().size();
+    int numLiveNodes = getCommonCloudSolrClient().getZkStateReader().getClusterState().getLiveNodes().size();
     int numShards = (numLiveNodes/2) + 1;
     int replicationFactor = 2;
     int maxShardsPerNode = 1;
     collectionInfos = new HashMap<>();
-    CloudSolrServer client = createCloudClient("awholynewcollection_" + cnt);
+    CloudSolrClient client = createCloudClient("awholynewcollection_" + cnt);
     try {
       exp = false;
       try {
@@ -836,12 +837,12 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
 
     
     // Test createNodeSet
-    numLiveNodes = getCommonCloudSolrServer().getZkStateReader().getClusterState().getLiveNodes().size();
+    numLiveNodes = getCommonCloudSolrClient().getZkStateReader().getClusterState().getLiveNodes().size();
     List<String> createNodeList = new ArrayList<>();
     int numOfCreateNodes = numLiveNodes/2;
     assertFalse("createNodeSet test is pointless with only " + numLiveNodes + " nodes running", numOfCreateNodes == 0);
     int i = 0;
-    for (String liveNode : getCommonCloudSolrServer().getZkStateReader().getClusterState().getLiveNodes()) {
+    for (String liveNode : getCommonCloudSolrClient().getZkStateReader().getClusterState().getLiveNodes()) {
       if (i < numOfCreateNodes) {
         createNodeList.add(liveNode);
         i++;
@@ -888,10 +889,10 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
           String collectionName = "awholynewstresscollection_" + name + "_" + i;
           int numShards = TestUtil.nextInt(random(), 0, shardCount * 2) + 1;
           int replicationFactor = TestUtil.nextInt(random(), 0, 3) + 1;
-          int maxShardsPerNode = (((numShards * 2 * replicationFactor) / getCommonCloudSolrServer()
+          int maxShardsPerNode = (((numShards * 2 * replicationFactor) / getCommonCloudSolrClient()
               .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
           
-          CloudSolrServer client = null;
+          CloudSolrClient client = null;
           try {
             if (i == 0) {
               client = createCloudClient(null);
@@ -993,7 +994,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
 
   private void collectStartTimes(String collectionName,
       Map<String,Long> urlToTime) throws SolrServerException, IOException {
-    ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader()
+    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader()
         .getClusterState();
 //    Map<String,DocCollection> collections = clusterState.getCollectionStates();
     if (clusterState.hasCollection(collectionName)) {
@@ -1008,7 +1009,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
         while (shardIt.hasNext()) {
           Entry<String,Replica> shardEntry = shardIt.next();
           ZkCoreNodeProps coreProps = new ZkCoreNodeProps(shardEntry.getValue());
-          HttpSolrServer server = new HttpSolrServer(coreProps.getBaseUrl());
+          HttpSolrClient server = new HttpSolrClient(coreProps.getBaseUrl());
           CoreAdminResponse mcr;
           try {
             mcr = CoreAdminRequest.getStatus(coreProps.getCoreName(), server);
@@ -1026,7 +1027,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   }
 
   private String getUrlFromZk(String collection) {
-    ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();
     Map<String,Slice> slices = clusterState.getSlicesMap(collection);
     
     if (slices == null) {
@@ -1122,6 +1123,58 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
 
   }
 
+  private void addReplicaTest() throws Exception {
+    String collectionName = "addReplicaColl";
+    CloudSolrClient client = createCloudClient(null);
+    try {
+      createCollection(collectionName, client, 2, 2);
+      String newReplicaName = Assign.assignNode(collectionName, client.getZkStateReader().getClusterState());
+      ArrayList<String> nodeList = new ArrayList<>(client.getZkStateReader().getClusterState().getLiveNodes());
+      Collections.shuffle(nodeList, random());
+      CollectionAdminRequest.AddReplica addReplica = new CollectionAdminRequest.AddReplica();
+      addReplica.setCollectionName(collectionName);
+      addReplica.setShardName("shard1");
+      addReplica.setNode(nodeList.get(0));
+      client.request(addReplica);
+
+      long timeout = System.currentTimeMillis() + 3000;
+      Replica newReplica = null;
+
+      for (; System.currentTimeMillis() < timeout; ) {
+        Slice slice = client.getZkStateReader().getClusterState().getSlice(collectionName, "shard1");
+        newReplica = slice.getReplica(newReplicaName);
+      }
+
+      assertNotNull(newReplica);
+
+      log.info("newReplica {},\n{} ", newReplica, client.getZkStateReader().getBaseUrlForNodeName(nodeList.get(0)));
+
+      assertEquals("Replica should be created on the right node",
+          client.getZkStateReader().getBaseUrlForNodeName(nodeList.get(0)), newReplica.getStr(ZkStateReader.BASE_URL_PROP));
+
+      newReplicaName = Assign.assignNode(collectionName, client.getZkStateReader().getClusterState());
+      addReplica = new CollectionAdminRequest.AddReplica();
+      addReplica.setCollectionName(collectionName);
+      addReplica.setShardName("shard2");
+      client.request(addReplica);
+
+      timeout = System.currentTimeMillis() + 3000;
+      newReplica = null;
+
+      for (; System.currentTimeMillis() < timeout; ) {
+        Slice slice = client.getZkStateReader().getClusterState().getSlice(collectionName, "shard2");
+        newReplica = slice.getReplica(newReplicaName);
+      }
+
+      assertNotNull(newReplica);
+
+
+    } finally {
+      client.shutdown();
+    }
+
+  }
+
   @Override
   protected QueryResponse queryServer(ModifiableSolrParams params) throws SolrServerException {
 
@@ -1131,12 +1184,12 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     if (r.nextBoolean())
       params.set("collection",DEFAULT_COLLECTION);
 
-    QueryResponse rsp = getCommonCloudSolrServer().query(params);
+    QueryResponse rsp = getCommonCloudSolrClient().query(params);
     return rsp;
   }
 
-  protected void createCollection(String COLL_NAME, CloudSolrServer client,int replicationFactor , int numShards ) throws Exception {
-    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrServer()
+  protected void createCollection(String COLL_NAME, CloudSolrClient client,int replicationFactor , int numShards ) throws Exception {
+    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     Map<String, Object> props = makeMap(
@@ -1160,7 +1213,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
   }
 
   private void clusterPropTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
 
     assertTrue("cluster property not set", setClusterProp(client, ZkStateReader.LEGACY_CLOUD, "false"));
     assertTrue("cluster property not unset ", setClusterProp(client, ZkStateReader.LEGACY_CLOUD, null));
@@ -1168,7 +1221,7 @@ public class CollectionsAPIDistributedZkTest extends AbstractFullDistribZkTestBa
     client.shutdown();
   }
 
-  public static boolean setClusterProp(CloudSolrServer client, String name , String val) throws SolrServerException, IOException, InterruptedException {
+  public static boolean setClusterProp(CloudSolrClient client, String name , String val) throws SolrServerException, IOException, InterruptedException {
     Map m = makeMap(
         "action", CollectionAction.CLUSTERPROP.toLower(),
         "name",name);
diff --git a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTests.java b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTests.java
index 823c97d..d247e1c 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTests.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CollectionsAPISolrJTests.java
@@ -21,7 +21,7 @@ import org.apache.commons.codec.binary.StringUtils;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.response.CollectionAdminResponse;
@@ -269,7 +269,7 @@ public class CollectionsAPISolrJTests extends AbstractFullDistribZkTestBase {
 
     Replica replica1 = testCollection.getReplica("core_node1");
 
-    HttpSolrServer solrServer = new HttpSolrServer(replica1.getStr("base_url"));
+    HttpSolrClient solrServer = new HttpSolrClient(replica1.getStr("base_url"));
     try {
       CoreAdminResponse status = CoreAdminRequest.getStatus(replica1.getStr("core"), solrServer);
       NamedList<Object> coreStatus = status.getCoreStatus(replica1.getStr("core"));
diff --git a/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java b/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
index fc116e5..c6c9e4e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/CustomCollectionTest.java
@@ -43,8 +43,8 @@ import org.apache.lucene.util.TestUtil;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -149,11 +149,11 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
     for (int i = 0; i < cnt; i++) {
       int numShards = 3;
-      int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrServer()
+      int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
           .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
 
-      CloudSolrServer client = null;
+      CloudSolrClient client = null;
       try {
         if (i == 0) {
           // Test if we can create a collection through CloudSolrServer where
@@ -193,15 +193,15 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
       List<Integer> list = entry.getValue();
       checkForCollection(collection, list, null);
 
-      String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collection);
+      String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collection);
 
-      HttpSolrServer collectionClient = new HttpSolrServer(url);
+      HttpSolrClient collectionClient = new HttpSolrClient(url);
 
       // poll for a second - it can take a moment before we are ready to serve
       waitForNon403or404or503(collectionClient);
       collectionClient.shutdown();
     }
-    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();
     for (int j = 0; j < cnt; j++) {
       waitForRecoveriesToFinish(COLL_PREFIX + j, zkStateReader, false);
     }
@@ -221,9 +221,9 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
     String collectionName = collectionNameList.get(random().nextInt(collectionNameList.size()));
 
-    String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
+    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);
 
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
 
 
     // lets try and use the solrj client to index a couple documents
@@ -271,7 +271,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     params.set("shard", "x");
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
-    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0))).request(request);
+    createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0))).request(request);
     waitForCollection(zkStateReader,collectionName,4);
     //wait for all the replicas to become active
     int attempts = 0;
@@ -295,11 +295,11 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
     int numShards = 4;
     replicationFactor = TestUtil.nextInt(random(), 0, 3) + 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
 
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     String shard_fld = "shard_s";
     try {
       client = createCloudClient(null);
@@ -320,10 +320,10 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     checkForCollection(collectionName, list, null);
 
 
-    url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
+    url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);
     
     collectionClient.shutdown();
-    collectionClient = new HttpSolrServer(url);
+    collectionClient = new HttpSolrClient(url);
 
     // poll for a second - it can take a moment before we are ready to serve
     waitForNon403or404or503(collectionClient);
@@ -331,7 +331,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
 
 
     collectionClient.shutdown();
-    collectionClient = new HttpSolrServer(url);
+    collectionClient = new HttpSolrClient(url);
 
 
     // lets try and use the solrj client to index a couple documents
@@ -358,11 +358,11 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     String collectionName = "routeFieldColl";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     String shard_fld = "shard_s";
     try {
       client = createCloudClient(null);
@@ -381,16 +381,16 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     checkForCollection(collectionName, list, null);
 
 
-    String url = getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
+    String url = getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);
 
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
 
     // poll for a second - it can take a moment before we are ready to serve
     waitForNon403or404or503(collectionClient);
     collectionClient.shutdown();
 
 
-    collectionClient = new HttpSolrServer(url);
+    collectionClient = new HttpSolrClient(url);
 
 
     // lets try and use the solrj client to index a couple documents
@@ -422,7 +422,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
   private void testCreateShardRepFactor() throws Exception  {
     String collectionName = "testCreateShardRepFactor";
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     try {
       client = createCloudClient(null);
       Map<String, Object> props = ZkNodeProps.makeMap(
@@ -436,7 +436,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     } finally {
       if (client != null) client.shutdown();
     }
-    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();
     waitForRecoveriesToFinish(collectionName, zkStateReader, false);
 
     ModifiableSolrParams params = new ModifiableSolrParams();
@@ -445,7 +445,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     params.set("shard", "x");
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
-    createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0))).request(request);
+    createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0))).request(request);
 
     waitForRecoveriesToFinish(collectionName, zkStateReader, false);
 
@@ -473,7 +473,7 @@ public class CustomCollectionTest extends AbstractFullDistribZkTestBase {
     if (r.nextBoolean())
       params.set("collection",DEFAULT_COLLECTION);
 
-    QueryResponse rsp = getCommonCloudSolrServer().query(params);
+    QueryResponse rsp = getCommonCloudSolrClient().query(params);
     return rsp;
   }
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
index 324c8cf..e81fb1b 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteInactiveReplicaTest.java
@@ -17,16 +17,10 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import static org.apache.solr.cloud.CollectionsAPIDistributedZkTest.setClusterProp;
-import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
-
-import java.net.URL;
-import java.util.Map;
-
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
@@ -38,6 +32,12 @@ import org.apache.solr.common.util.NamedList;
 import org.junit.After;
 import org.junit.Before;
 
+import java.net.URL;
+import java.util.Map;
+
+import static org.apache.solr.cloud.CollectionsAPIDistributedZkTest.setClusterProp;
+import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
+
 //@Ignore("Not currently valid see SOLR-5580")
 public class DeleteInactiveReplicaTest extends DeleteReplicaTest{
 
@@ -57,7 +57,7 @@ public class DeleteInactiveReplicaTest extends DeleteReplicaTest{
   }
   
   private void deleteInactiveReplicaTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
 
     String collectionName = "delDeadColl";
 
@@ -131,12 +131,12 @@ public class DeleteInactiveReplicaTest extends DeleteReplicaTest{
 
     Map m = makeMap("qt", "/admin/cores", "action", "status");
 
-    SolrServer server = new HttpSolrServer(replica1.getStr(ZkStateReader.BASE_URL_PROP));
-    NamedList<Object> resp = server.request(new QueryRequest(new MapSolrParams(m)));
+    SolrClient queryClient = new HttpSolrClient(replica1.getStr(ZkStateReader.BASE_URL_PROP));
+    NamedList<Object> resp = queryClient.request(new QueryRequest(new MapSolrParams(m)));
     assertNull("The core is up and running again",
         ((NamedList) resp.get("status")).get(replica1.getStr("core")));
-    server.shutdown();
-    server = null;
+    queryClient.shutdown();
+    queryClient = null;
 
 
     Exception exp = null;
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
index cba199d..3e86bea 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteLastCustomShardedReplicaTest.java
@@ -19,13 +19,12 @@ package org.apache.solr.cloud;
 
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.ImplicitDocRouter;
 import org.apache.solr.common.cloud.Replica;
 import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.params.CollectionParams;
 import org.apache.solr.common.params.MapSolrParams;
 import org.apache.solr.common.params.SolrParams;
 import org.junit.After;
@@ -47,7 +46,7 @@ import static org.apache.solr.common.params.CollectionParams.CollectionAction.DE
 
 @Ignore("SOLR-6347")
 public class DeleteLastCustomShardedReplicaTest extends AbstractFullDistribZkTestBase {
-  private CloudSolrServer client;
+  private CloudSolrClient client;
 
   @BeforeClass
   public static void beforeThisClass2() throws Exception {
@@ -102,7 +101,7 @@ public class DeleteLastCustomShardedReplicaTest extends AbstractFullDistribZkTes
 
     waitForRecoveriesToFinish(collectionName, false);
 
-    DocCollection testcoll = getCommonCloudSolrServer().getZkStateReader()
+    DocCollection testcoll = getCommonCloudSolrClient().getZkStateReader()
         .getClusterState().getCollection(collectionName);
     Replica replica = testcoll.getSlice("a").getReplicas().iterator().next();
 
@@ -121,7 +120,7 @@ public class DeleteLastCustomShardedReplicaTest extends AbstractFullDistribZkTes
     boolean success = false;
     DocCollection testcoll = null;
     while (System.currentTimeMillis() < endAt) {
-      testcoll = getCommonCloudSolrServer().getZkStateReader()
+      testcoll = getCommonCloudSolrClient().getZkStateReader()
           .getClusterState().getCollection(COLL_NAME);
       // In case of a custom sharded collection, the last replica deletion would also lead to
       // the deletion of the slice.
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest.java
index d2f6c59..e8f3450 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteReplicaTest.java
@@ -17,22 +17,10 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
-import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
-import static org.apache.solr.cloud.OverseerCollectionProcessor.ONLY_IF_DOWN;
-import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
-import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETEREPLICA;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.CoreAdminResponse;
@@ -48,8 +36,20 @@ import org.junit.After;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import java.io.File;
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
+import static org.apache.solr.cloud.OverseerCollectionProcessor.ONLY_IF_DOWN;
+import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
+import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
+import static org.apache.solr.common.params.CollectionParams.CollectionAction.DELETEREPLICA;
+
 public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
-  private CloudSolrServer client;
+  private CloudSolrClient client;
   
   @BeforeClass
   public static void beforeThisClass2() throws Exception {
@@ -91,13 +91,13 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
 
   private void deleteLiveReplicaTest() throws Exception {
     String collectionName = "delLiveColl";
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       createCollection(collectionName, client);
       
       waitForRecoveriesToFinish(collectionName, false);
       
-      DocCollection testcoll = getCommonCloudSolrServer().getZkStateReader()
+      DocCollection testcoll = getCommonCloudSolrClient().getZkStateReader()
           .getClusterState().getCollection(collectionName);
       
       Slice shard1 = null;
@@ -120,14 +120,14 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
 
       if (replica1 == null) fail("no active replicas found");
 
-      HttpSolrServer replica1Server = new HttpSolrServer(replica1.getStr("base_url"));
+      HttpSolrClient replica1Client = new HttpSolrClient(replica1.getStr("base_url"));
       String dataDir = null;
       try {
-        CoreAdminResponse status = CoreAdminRequest.getStatus(replica1.getStr("core"), replica1Server);
+        CoreAdminResponse status = CoreAdminRequest.getStatus(replica1.getStr("core"), replica1Client);
         NamedList<Object> coreStatus = status.getCoreStatus(replica1.getStr("core"));
         dataDir = (String) coreStatus.get("dataDir");
       } finally {
-        replica1Server.shutdown();
+        replica1Client.shutdown();
       }
       try {
         // Should not be able to delete a replica that is up if onlyIfDown=true.
@@ -149,7 +149,7 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
     }
   }
 
-  protected void tryToRemoveOnlyIfDown(String collectionName, CloudSolrServer client, Replica replica, String shard) throws IOException, SolrServerException {
+  protected void tryToRemoveOnlyIfDown(String collectionName, CloudSolrClient client, Replica replica, String shard) throws IOException, SolrServerException {
     Map m = makeMap("collection", collectionName,
         "action", DELETEREPLICA.toLower(),
         "shard", shard,
@@ -162,7 +162,7 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
   }
 
   protected void removeAndWaitForReplicaGone(String COLL_NAME,
-      CloudSolrServer client, Replica replica, String shard)
+      CloudSolrClient client, Replica replica, String shard)
       throws SolrServerException, IOException, InterruptedException {
     Map m = makeMap("collection", COLL_NAME, "action", DELETEREPLICA.toLower(), "shard",
         shard, "replica", replica.getName());
@@ -174,7 +174,7 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
     boolean success = false;
     DocCollection testcoll = null;
     while (System.currentTimeMillis() < endAt) {
-      testcoll = getCommonCloudSolrServer().getZkStateReader()
+      testcoll = getCommonCloudSolrClient().getZkStateReader()
           .getClusterState().getCollection(COLL_NAME);
       success = testcoll.getSlice(shard).getReplica(replica.getName()) == null;
       if (success) {
@@ -188,10 +188,10 @@ public class DeleteReplicaTest extends AbstractFullDistribZkTestBase {
     assertTrue("Replica not cleaned up", success);
   }
 
-  protected void createCollection(String COLL_NAME, CloudSolrServer client) throws Exception {
+  protected void createCollection(String COLL_NAME, CloudSolrClient client) throws Exception {
     int replicationFactor = 2;
     int numShards = 2;
-    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     Map<String, Object> props = makeMap(
diff --git a/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java b/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
index 0004d8d..26fdb8e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DeleteShardTest.java
@@ -19,7 +19,7 @@ package org.apache.solr.cloud;
 
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.cloud.overseer.OverseerAction;
 import org.apache.solr.common.SolrException;
@@ -94,7 +94,7 @@ public class DeleteShardTest extends AbstractFullDistribZkTestBase {
     try {
       deleteShard(SHARD1);
       fail("Deleting an active shard should not have succeeded");
-    } catch (HttpSolrServer.RemoteSolrException e) {
+    } catch (HttpSolrClient.RemoteSolrException e) {
       // expected
     }
 
@@ -143,15 +143,15 @@ public class DeleteShardTest extends AbstractFullDistribZkTestBase {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
-    baseServer.setConnectionTimeout(15000);
-    baseServer.setSoTimeout(60000);
-    baseServer.request(request);
-    baseServer.shutdown();
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
+    baseClient.setConnectionTimeout(15000);
+    baseClient.setSoTimeout(60000);
+    baseClient.request(request);
+    baseClient.shutdown();
   }
 
   protected void setSliceState(String slice, String state) throws SolrServerException, IOException,
diff --git a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
index fffcf6d..29a3cb6 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DistribCursorPagingTest.java
@@ -18,10 +18,8 @@ package org.apache.solr.cloud;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.TestUtil;
-import org.apache.lucene.util.TestUtil;
 import org.apache.lucene.util.SentinelIntSet;
 import org.apache.solr.CursorPagingTest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.request.LukeRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -636,7 +634,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   /**
    * Given a QueryResponse returned by SolrServer.query, asserts that the
    * numFound on the doc list matches the expectation
-   * @see SolrServer#query
+   * @see org.apache.solr.client.solrj.SolrClient#query
    */
   private void assertNumFound(int expected, QueryResponse rsp) {
     assertEquals(expected, extractDocList(rsp).getNumFound());
@@ -645,7 +643,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   /**
    * Given a QueryResponse returned by SolrServer.query, asserts that the
    * start on the doc list matches the expectation
-   * @see SolrServer#query
+   * @see org.apache.solr.client.solrj.SolrClient#query
    */
   private void assertStartsAt(int expected, QueryResponse rsp) {
     assertEquals(expected, extractDocList(rsp).getStart());
@@ -654,7 +652,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   /**
    * Given a QueryResponse returned by SolrServer.query, asserts that the
    * "id" of the list of documents returned matches the expected list
-   * @see SolrServer#query
+   * @see org.apache.solr.client.solrj.SolrClient#query
    */
   private void assertDocList(QueryResponse rsp, Object... ids) {
     SolrDocumentList docs = extractDocList(rsp);
@@ -669,7 +667,7 @@ public class DistribCursorPagingTest extends AbstractFullDistribZkTestBase {
   /**
    * Given a QueryResponse returned by SolrServer.query, asserts that the
    * response does include {@link #CURSOR_MARK_NEXT} key and returns it
-   * @see SolrServer#query
+   * @see org.apache.solr.client.solrj.SolrClient#query
    */
   private String assertHashNextCursorMark(QueryResponse rsp) {
     String r = rsp.getNextCursorMark();
diff --git a/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java b/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
index 9781113..17b63c5 100644
--- a/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest.java
@@ -17,16 +17,8 @@
 package org.apache.solr.cloud;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util.TestUtil;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.SolrDocument;
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -39,8 +31,6 @@ import org.slf4j.LoggerFactory;
 
 import java.io.IOException;
 import java.util.List;
-import java.util.ArrayList;
-import java.util.Collection;
 import java.util.Map;
 import java.util.Set;
 import java.util.HashSet;
diff --git a/solr/core/src/test/org/apache/solr/cloud/ExternalCollectionsTest.java b/solr/core/src/test/org/apache/solr/cloud/ExternalCollectionsTest.java
index 2f5a694..7bc6131 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ExternalCollectionsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ExternalCollectionsTest.java
@@ -17,7 +17,7 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.ClusterState;
 import org.apache.solr.common.cloud.DocCollection;
@@ -30,7 +30,7 @@ import org.junit.Before;
 import org.junit.BeforeClass;
 
 public class ExternalCollectionsTest extends AbstractFullDistribZkTestBase {
-  private CloudSolrServer client;
+  private CloudSolrClient client;
 
   @BeforeClass
   public static void beforeThisClass2() throws Exception {
diff --git a/solr/core/src/test/org/apache/solr/cloud/FullSolrCloudDistribCmdsTest.java b/solr/core/src/test/org/apache/solr/cloud/FullSolrCloudDistribCmdsTest.java
index ce2c5fc..97da78d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/FullSolrCloudDistribCmdsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/FullSolrCloudDistribCmdsTest.java
@@ -17,18 +17,13 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.lucene.util.LuceneTestCase.BadApple;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -38,13 +33,17 @@ import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.SolrZkClient;
 import org.apache.solr.common.cloud.ZkNodeProps;
 import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.CollectionParams.CollectionAction;
+import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.update.VersionInfo;
 import org.apache.solr.update.processor.DistributedUpdateProcessor;
 import org.apache.zookeeper.CreateMode;
 import org.junit.BeforeClass;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * Super basic testing, no shard restarting or anything.
  */
@@ -130,9 +129,9 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
     
     docId = testIndexQueryDeleteHierarchical(docId);
     
-    docId = testIndexingDocPerRequestWithHttpSolrServer(docId);
+    docId = testIndexingDocPerRequestWithHttpSolrClient(docId);
     
-    testIndexingWithSuss(docId);
+    testConcurrentIndexing(docId);
     
     // TODO: testOptimisticUpdate(results);
     
@@ -141,7 +140,7 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
     docId = testThatCantForwardToLeaderFails(docId);
     
     
-    docId = testIndexingBatchPerRequestWithHttpSolrServer(docId);
+    docId = testIndexingBatchPerRequestWithHttpSolrClient(docId);
   }
 
   private long testThatCantForwardToLeaderFails(long docId) throws Exception {
@@ -316,7 +315,7 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
   }
   
   
-  private long testIndexingDocPerRequestWithHttpSolrServer(long docId) throws Exception {
+  private long testIndexingDocPerRequestWithHttpSolrClient(long docId) throws Exception {
     int docs = random().nextInt(TEST_NIGHTLY ? 4013 : 97) + 1;
     for (int i = 0; i < docs; i++) {
       UpdateRequest uReq;
@@ -335,7 +334,7 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
     return docId++;
   }
   
-  private long testIndexingBatchPerRequestWithHttpSolrServer(long docId) throws Exception {
+  private long testIndexingBatchPerRequestWithHttpSolrClient(long docId) throws Exception {
     
     // remove collection
     ModifiableSolrParams params = new ModifiableSolrParams();
@@ -432,25 +431,25 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
     return -1;
   }
   
-  private long testIndexingWithSuss(long docId) throws Exception {
-    ConcurrentUpdateSolrServer suss = new ConcurrentUpdateSolrServer(
-        ((HttpSolrServer) clients.get(0)).getBaseURL(), 10, 2);
+  private long testConcurrentIndexing(long docId) throws Exception {
+    ConcurrentUpdateSolrClient concurrentClient = new ConcurrentUpdateSolrClient(
+        ((HttpSolrClient) clients.get(0)).getBaseURL(), 10, 2);
     QueryResponse results = query(cloudClient);
     long beforeCount = results.getResults().getNumFound();
     int cnt = TEST_NIGHTLY ? 2933 : 313;
     try {
-      suss.setConnectionTimeout(120000);
+      concurrentClient.setConnectionTimeout(120000);
       for (int i = 0; i < cnt; i++) {
-        index_specific(suss, id, docId++, "text_t", "some text so that it not's negligent work to parse this doc, even though it's still a pretty short doc");
+        index_specific(concurrentClient, id, docId++, "text_t", "some text so that it not's negligent work to parse this doc, even though it's still a pretty short doc");
       }
-      suss.blockUntilFinished();
+      concurrentClient.blockUntilFinished();
       
       commit();
 
       checkShardConsistency();
       assertDocCounts(VERBOSE);
     } finally {
-      suss.shutdown();
+      concurrentClient.shutdown();
     }
     results = query(cloudClient);
     assertEquals(beforeCount + cnt, results.getResults().getNumFound());
@@ -497,9 +496,9 @@ public class FullSolrCloudDistribCmdsTest extends AbstractFullDistribZkTestBase
     assertEquals(1, res.getResults().getNumFound());
   }
 
-  private QueryResponse query(SolrServer server) throws SolrServerException {
+  private QueryResponse query(SolrClient client) throws SolrServerException {
     SolrQuery query = new SolrQuery("*:*");
-    return server.query(query);
+    return client.query(query);
   }
   
   @Override
diff --git a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
index 0a4f4ac..ea50a7d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/HttpPartitionTest.java
@@ -17,22 +17,11 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.TimeUnit;
-
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.JSONTestUtil;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
@@ -52,6 +41,17 @@ import org.junit.Before;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.File;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+
 /**
  * Simulates HTTP partitions between a leader and replica but the replica does
  * not lose its ZooKeeper connection.
@@ -341,7 +341,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
         testCollectionName+"; clusterState: "+printClusterStateInfo(testCollectionName), leader);
     JettySolrRunner leaderJetty = getJettyOnPort(getReplicaPort(leader));
 
-    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);
+    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField(id, String.valueOf(2));
     doc.addField("a_t", "hello" + 2);
@@ -377,7 +377,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
       leaderSolr.shutdown();
 
       // if the add worked, then the doc must exist on the new leader
-      HttpSolrServer newLeaderSolr = getHttpSolrServer(currentLeader, testCollectionName);
+      HttpSolrClient newLeaderSolr = getHttpSolrClient(currentLeader, testCollectionName);
       try {
         assertDocExists(newLeaderSolr, testCollectionName, "2");
       } finally {
@@ -386,7 +386,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
 
     } catch (SolrException exc) {
       // this is ok provided the doc doesn't exist on the current leader
-      leaderSolr = getHttpSolrServer(currentLeader, testCollectionName);
+      leaderSolr = getHttpSolrClient(currentLeader, testCollectionName);
       try {
         leaderSolr.add(doc); // this should work
       } finally {
@@ -439,18 +439,18 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
       throws Exception {
     Replica leader = 
         cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, "shard1", 10000);
-    HttpSolrServer leaderSolr = getHttpSolrServer(leader, testCollectionName);
-    List<HttpSolrServer> replicas = 
-        new ArrayList<HttpSolrServer>(notLeaders.size());
+    HttpSolrClient leaderSolr = getHttpSolrClient(leader, testCollectionName);
+    List<HttpSolrClient> replicas =
+        new ArrayList<HttpSolrClient>(notLeaders.size());
     
     for (Replica r : notLeaders) {
-      replicas.add(getHttpSolrServer(r, testCollectionName));
+      replicas.add(getHttpSolrClient(r, testCollectionName));
     }
     try {
       for (int d = firstDocId; d <= lastDocId; d++) {
         String docId = String.valueOf(d);
         assertDocExists(leaderSolr, testCollectionName, docId);
-        for (HttpSolrServer replicaSolr : replicas) {
+        for (HttpSolrClient replicaSolr : replicas) {
           assertDocExists(replicaSolr, testCollectionName, docId);
         }
       }
@@ -458,16 +458,16 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
       if (leaderSolr != null) {
         leaderSolr.shutdown();
       }
-      for (HttpSolrServer replicaSolr : replicas) {
+      for (HttpSolrClient replicaSolr : replicas) {
         replicaSolr.shutdown();
       }
     }
   }
   
-  protected HttpSolrServer getHttpSolrServer(Replica replica, String coll) throws Exception {
+  protected HttpSolrClient getHttpSolrClient(Replica replica, String coll) throws Exception {
     ZkCoreNodeProps zkProps = new ZkCoreNodeProps(replica);
     String url = zkProps.getBaseUrl() + "/" + coll;
-    return new HttpSolrServer(url);
+    return new HttpSolrClient(url);
   }
   
   protected void sendDoc(int docId) throws Exception {
@@ -486,7 +486,7 @@ public class HttpPartitionTest extends AbstractFullDistribZkTestBase {
    * exists in the provided server, using distrib=false so it doesn't route to another replica.
    */
   @SuppressWarnings("rawtypes")
-  protected void assertDocExists(HttpSolrServer solr, String coll, String docId) throws Exception {
+  protected void assertDocExists(HttpSolrClient solr, String coll, String docId) throws Exception {
     QueryRequest qr = new QueryRequest(params("qt", "/get", "id", docId, "distrib", "false"));
     NamedList rsp = solr.request(qr);
     String match = JSONTestUtil.matchObj("/id", rsp.get("doc"), new Integer(docId));
diff --git a/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java b/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
index 1ac1359..54044f8 100644
--- a/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/LeaderFailoverAfterPartitionTest.java
@@ -110,8 +110,8 @@ public class LeaderFailoverAfterPartitionTest extends HttpPartitionTest {
     // doc should be on leader and 1 replica
     sendDoc(5);
 
-    assertDocExists(getHttpSolrServer(leader, testCollectionName), testCollectionName, "5");
-    assertDocExists(getHttpSolrServer(notLeaders.get(1), testCollectionName), testCollectionName, "5");
+    assertDocExists(getHttpSolrClient(leader, testCollectionName), testCollectionName, "5");
+    assertDocExists(getHttpSolrClient(notLeaders.get(1), testCollectionName), testCollectionName, "5");
 
     Thread.sleep(sleepMsBeforeHealPartition);
     
diff --git a/solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnCommitTest.java b/solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnCommitTest.java
index d9ef224..ef7d4bf 100644
--- a/solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnCommitTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/LeaderInitiatedRecoveryOnCommitTest.java
@@ -17,17 +17,17 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.util.List;
-
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.common.cloud.Replica;
 import org.apache.solr.common.cloud.ZkCoreNodeProps;
 import org.junit.After;
 import org.junit.Before;
 
+import java.io.File;
+import java.util.List;
+
 public class LeaderInitiatedRecoveryOnCommitTest extends BasicDistributedZkTest {
 
   private static final long sleepMsBeforeHealPartition = 2000L;
@@ -91,8 +91,8 @@ public class LeaderInitiatedRecoveryOnCommitTest extends BasicDistributedZkTest
 
     // let's find the leader of shard2 and ask him to commit
     Replica shard2Leader = cloudClient.getZkStateReader().getLeaderRetry(testCollectionName, "shard2");
-    HttpSolrServer server = new HttpSolrServer(ZkCoreNodeProps.getCoreUrl(shard2Leader.getStr("base_url"), shard2Leader.getStr("core")));
-    server.commit();
+    HttpSolrClient client = new HttpSolrClient(ZkCoreNodeProps.getCoreUrl(shard2Leader.getStr("base_url"), shard2Leader.getStr("core")));
+    client.commit();
 
     Thread.sleep(sleepMsBeforeHealPartition);
 
@@ -133,8 +133,8 @@ public class LeaderInitiatedRecoveryOnCommitTest extends BasicDistributedZkTest
     leaderProxy.close();
 
     Replica replica = notLeaders.get(0);
-    HttpSolrServer server = new HttpSolrServer(ZkCoreNodeProps.getCoreUrl(replica.getStr("base_url"), replica.getStr("core")));
-    server.commit();
+    HttpSolrClient client = new HttpSolrClient(ZkCoreNodeProps.getCoreUrl(replica.getStr("base_url"), replica.getStr("core")));
+    client.commit();
 
     Thread.sleep(sleepMsBeforeHealPartition);
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/MigrateRouteKeyTest.java b/solr/core/src/test/org/apache/solr/cloud/MigrateRouteKeyTest.java
index 6a84189..3bd56ce 100644
--- a/solr/core/src/test/org/apache/solr/cloud/MigrateRouteKeyTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/MigrateRouteKeyTest.java
@@ -20,8 +20,8 @@ package org.apache.solr.cloud;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -30,7 +30,6 @@ import org.apache.solr.common.cloud.ClusterState;
 import org.apache.solr.common.cloud.RoutingRule;
 import org.apache.solr.common.cloud.Slice;
 import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.params.CollectionParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.update.DirectUpdateHandler2;
 import org.apache.zookeeper.KeeperException;
@@ -43,8 +42,8 @@ import java.util.List;
 import java.util.Map;
 
 import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
-import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
+import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 
 public class MigrateRouteKeyTest extends BasicDistributedZkTest {
 
@@ -103,8 +102,8 @@ public class MigrateRouteKeyTest extends BasicDistributedZkTest {
     ClusterState state;Slice slice;
     boolean ruleRemoved = false;
     while (System.currentTimeMillis() - finishTime < 60000) {
-      getCommonCloudSolrServer().getZkStateReader().updateClusterState(true);
-      state = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+      getCommonCloudSolrClient().getZkStateReader().updateClusterState(true);
+      state = getCommonCloudSolrClient().getZkStateReader().getClusterState();
       slice = state.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD2);
       Map<String,RoutingRule> routingRules = slice.getRoutingRules();
       if (routingRules == null || routingRules.isEmpty() || !routingRules.containsKey(splitKey)) {
@@ -133,20 +132,20 @@ public class MigrateRouteKeyTest extends BasicDistributedZkTest {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
-    baseServer.setConnectionTimeout(15000);
-    baseServer.setSoTimeout(60000 * 5);
-    baseServer.request(request);
-    baseServer.shutdown();
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
+    baseClient.setConnectionTimeout(15000);
+    baseClient.setSoTimeout(60000 * 5);
+    baseClient.request(request);
+    baseClient.shutdown();
   }
 
   private void createCollection(String targetCollection) throws Exception {
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     try {
       client = createCloudClient(null);
       Map<String, Object> props = ZkNodeProps.makeMap(
@@ -193,8 +192,8 @@ public class MigrateRouteKeyTest extends BasicDistributedZkTest {
     Indexer indexer = new Indexer(cloudClient, splitKey, 1, 30);
     indexer.start();
 
-    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), targetCollection);
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), targetCollection);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
 
     SolrQuery solrQuery = new SolrQuery("*:*");
     assertEquals("DocCount on target collection does not match", 0, collectionClient.query(solrQuery).getResults().getNumFound());
@@ -221,8 +220,8 @@ public class MigrateRouteKeyTest extends BasicDistributedZkTest {
     collectionClient.shutdown();
     collectionClient = null;
 
-    getCommonCloudSolrServer().getZkStateReader().updateClusterState(true);
-    ClusterState state = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+    getCommonCloudSolrClient().getZkStateReader().updateClusterState(true);
+    ClusterState state = getCommonCloudSolrClient().getZkStateReader().getClusterState();
     Slice slice = state.getSlice(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD2);
     assertNotNull("Routing rule map is null", slice.getRoutingRules());
     assertFalse("Routing rule map is empty", slice.getRoutingRules().isEmpty());
@@ -234,12 +233,12 @@ public class MigrateRouteKeyTest extends BasicDistributedZkTest {
 
   static class Indexer extends Thread {
     final int seconds;
-    final CloudSolrServer cloudClient;
+    final CloudSolrClient cloudClient;
     final String splitKey;
     int splitKeyCount = 0;
     final int bitSep;
 
-    public Indexer(CloudSolrServer cloudClient, String splitKey, int bitSep, int seconds) {
+    public Indexer(CloudSolrClient cloudClient, String splitKey, int bitSep, int seconds) {
       this.seconds = seconds;
       this.cloudClient = cloudClient;
       this.splitKey = splitKey;
diff --git a/solr/core/src/test/org/apache/solr/cloud/MultiThreadedOCPTest.java b/solr/core/src/test/org/apache/solr/cloud/MultiThreadedOCPTest.java
index 8686789..f355f96 100644
--- a/solr/core/src/test/org/apache/solr/cloud/MultiThreadedOCPTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/MultiThreadedOCPTest.java
@@ -18,9 +18,9 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.Create;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.RequestStatus;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest.SplitShard;
@@ -76,7 +76,7 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
   }
 
   private void testParallelCollectionAPICalls() throws IOException, SolrServerException {
-    SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
 
     for(int i = 1 ; i <= NUM_COLLECTIONS ; i++) {
       Create createCollectionRequest = new Create();
@@ -84,7 +84,7 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
       createCollectionRequest.setNumShards(4);
       createCollectionRequest.setConfigName("conf1");
       createCollectionRequest.setAsyncId(String.valueOf(i));
-      createCollectionRequest.process(server);
+      createCollectionRequest.process(client);
     }
 
     boolean pass = false;
@@ -92,7 +92,7 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
     while(true) {
       int numRunningTasks = 0;
       for (int i = 1; i <= NUM_COLLECTIONS; i++)
-        if (getRequestState(i + "", server).equals("running"))
+        if (getRequestState(i + "", client).equals("running"))
           numRunningTasks++;
       if(numRunningTasks > 1) {
         pass = true;
@@ -107,38 +107,38 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
     }
     assertTrue("More than one tasks were supposed to be running in parallel but they weren't.", pass);
     for(int i=1;i<=NUM_COLLECTIONS;i++) {
-      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, server);
+      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, client);
       assertTrue("Task " + i + " did not complete, final state: " + state,state.equals("completed"));
     }
   }
 
   private void testTaskExclusivity() throws IOException, SolrServerException {
-    SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
     Create createCollectionRequest = new Create();
     createCollectionRequest.setCollectionName("ocptest_shardsplit");
     createCollectionRequest.setNumShards(4);
     createCollectionRequest.setConfigName("conf1");
     createCollectionRequest.setAsyncId("1000");
-    createCollectionRequest.process(server);
+    createCollectionRequest.process(client);
 
     SplitShard splitShardRequest = new SplitShard();
     splitShardRequest.setCollectionName("ocptest_shardsplit");
     splitShardRequest.setShardName(SHARD1);
     splitShardRequest.setAsyncId("1001");
-    splitShardRequest.process(server);
+    splitShardRequest.process(client);
 
     splitShardRequest = new SplitShard();
     splitShardRequest.setCollectionName("ocptest_shardsplit");
     splitShardRequest.setShardName(SHARD2);
     splitShardRequest.setAsyncId("1002");
-    splitShardRequest.process(server);
+    splitShardRequest.process(client);
 
     int iterations = 0;
     while(true) {
       int runningTasks = 0;
       int completedTasks = 0;
       for (int i=1001;i<=1002;i++) {
-        String state = getRequestState(i, server);
+        String state = getRequestState(i, client);
         if (state.equals("running"))
           runningTasks++;
         if (state.equals("completed"))
@@ -161,45 +161,45 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
       }
     }
     for (int i=1001;i<=1002;i++) {
-      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, server);
+      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, client);
       assertTrue("Task " + i + " did not complete, final state: " + state,state.equals("completed"));
     }
   }
 
   private void testDeduplicationOfSubmittedTasks() throws IOException, SolrServerException {
-    SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
     Create createCollectionRequest = new Create();
     createCollectionRequest.setCollectionName("ocptest_shardsplit2");
     createCollectionRequest.setNumShards(4);
     createCollectionRequest.setConfigName("conf1");
     createCollectionRequest.setAsyncId("3000");
-    createCollectionRequest.process(server);
+    createCollectionRequest.process(client);
 
     SplitShard splitShardRequest = new SplitShard();
     splitShardRequest.setCollectionName("ocptest_shardsplit2");
     splitShardRequest.setShardName(SHARD1);
     splitShardRequest.setAsyncId("3001");
-    splitShardRequest.process(server);
+    splitShardRequest.process(client);
 
     splitShardRequest = new SplitShard();
     splitShardRequest.setCollectionName("ocptest_shardsplit2");
     splitShardRequest.setShardName(SHARD2);
     splitShardRequest.setAsyncId("3002");
-    splitShardRequest.process(server);
+    splitShardRequest.process(client);
 
     // Now submit another task with the same id. At this time, hopefully the previous 3002 should still be in the queue.
     splitShardRequest = new SplitShard();
     splitShardRequest.setCollectionName("ocptest_shardsplit2");
     splitShardRequest.setShardName(SHARD1);
     splitShardRequest.setAsyncId("3002");
-    CollectionAdminResponse response = splitShardRequest.process(server);
+    CollectionAdminResponse response = splitShardRequest.process(client);
 
     NamedList r = response.getResponse();
     assertEquals("Duplicate request was supposed to exist but wasn't found. De-duplication of submitted task failed.",
         "Task with the same requestid already exists.", r.get("error"));
 
     for (int i=3001;i<=3002;i++) {
-      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, server);
+      String state = getRequestStateAfterCompletion(i + "", REQUEST_STATUS_TIMEOUT, client);
       assertTrue("Task " + i + " did not complete, final state: " + state,state.equals("completed"));
     }
   }
@@ -224,16 +224,16 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
 
     try {
 
-      SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+      SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
       SplitShard splitShardRequest = new SplitShard();
       splitShardRequest.setCollectionName("collection1");
       splitShardRequest.setShardName(SHARD1);
       splitShardRequest.setAsyncId("2000");
-      splitShardRequest.process(server);
+      splitShardRequest.process(client);
 
-      String state = getRequestState("2000", server);
+      String state = getRequestState("2000", client);
       while (state.equals("submitted")) {
-        state = getRequestState("2000", server);
+        state = getRequestState("2000", client);
         Thread.sleep(10);
       }
       assertTrue("SplitShard task [2000] was supposed to be in [running] but isn't. It is [" + state + "]", state.equals("running"));
@@ -246,9 +246,9 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
       SolrRequest request = new QueryRequest(params);
       request.setPath("/admin/collections");
 
-      server.request(request);
+      client.request(request);
 
-      state = getRequestState("2000", server);
+      state = getRequestState("2000", client);
 
       assertTrue("After invoking OVERSEERSTATUS, SplitShard task [2000] was still supposed to be in [running] but isn't." +
           "It is [" + state + "]", state.equals("running"));
@@ -267,13 +267,13 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
     // todo - target diff servers and use cloud clients as well as non-cloud clients
   }
 
-  private String getRequestStateAfterCompletion(String requestId, int waitForSeconds, SolrServer server)
+  private String getRequestStateAfterCompletion(String requestId, int waitForSeconds, SolrClient client)
       throws IOException, SolrServerException {
     String state = null;
     long maxWait = System.nanoTime() + TimeUnit.NANOSECONDS.convert(waitForSeconds, TimeUnit.SECONDS);
 
     while (System.nanoTime() < maxWait)  {
-      state = getRequestState(requestId, server);
+      state = getRequestState(requestId, client);
       if(state.equals("completed") || state.equals("failed"))
         return state;
       try {
@@ -285,14 +285,14 @@ public class MultiThreadedOCPTest extends AbstractFullDistribZkTestBase {
     return state;
   }
 
-  private String getRequestState(int requestId, SolrServer server) throws IOException, SolrServerException {
-    return getRequestState(String.valueOf(requestId), server);
+  private String getRequestState(int requestId, SolrClient client) throws IOException, SolrServerException {
+    return getRequestState(String.valueOf(requestId), client);
   }
 
-  private String getRequestState(String requestId, SolrServer server) throws IOException, SolrServerException {
+  private String getRequestState(String requestId, SolrClient client) throws IOException, SolrServerException {
     RequestStatus requestStatusRequest = new RequestStatus();
     requestStatusRequest.setRequestId(requestId);
-    CollectionAdminResponse response = requestStatusRequest.process(server);
+    CollectionAdminResponse response = requestStatusRequest.process(client);
 
     NamedList innerResponse = (NamedList) response.getResponse().get("status");
     return (String) innerResponse.get("state");
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
index cdfed1c..9333996 100644
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerRolesTest.java
@@ -36,7 +36,7 @@ import org.apache.lucene.util.LuceneTestCase;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.cloud.overseer.OverseerAction;
 import org.apache.solr.common.cloud.SolrZkClient;
@@ -53,7 +53,7 @@ import org.junit.BeforeClass;
 @LuceneTestCase.Slow
 @SuppressSSL     // See SOLR-5776
 public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
-  private CloudSolrServer client;
+  private CloudSolrClient client;
 
   @BeforeClass
   public static void beforeThisClass2() throws Exception {
@@ -228,10 +228,10 @@ public class OverseerRolesTest  extends AbstractFullDistribZkTestBase{
   }
 
 
-  protected void createCollection(String COLL_NAME, CloudSolrServer client) throws Exception {
+  protected void createCollection(String COLL_NAME, CloudSolrClient client) throws Exception {
     int replicationFactor = 2;
     int numShards = 4;
-    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     Map<String, Object> props = makeMap(
diff --git a/solr/core/src/test/org/apache/solr/cloud/OverseerStatusTest.java b/solr/core/src/test/org/apache/solr/cloud/OverseerStatusTest.java
index f310866..f1793e7 100644
--- a/solr/core/src/test/org/apache/solr/cloud/OverseerStatusTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/OverseerStatusTest.java
@@ -19,7 +19,7 @@ package org.apache.solr.cloud;
 
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.CollectionAdminResponse;
 import org.apache.solr.common.cloud.DocRouter;
diff --git a/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java b/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
index c09882a..20e49dc 100644
--- a/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/RemoteQueryErrorTest.java
@@ -18,7 +18,7 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrInputDocument;
 
@@ -56,17 +56,17 @@ public class RemoteQueryErrorTest extends AbstractFullDistribZkTestBase {
     checkForCollection("collection2", numShardsNumReplicaList, null);
     waitForRecoveriesToFinish("collection2", true);
 
-    for (SolrServer solrServer : clients) {
+    for (SolrClient solrClient : clients) {
       try {
         SolrInputDocument emptyDoc = new SolrInputDocument();
-        solrServer.add(emptyDoc);
+        solrClient.add(emptyDoc);
         fail("Expected unique key exceptoin");
       } catch (SolrException ex) {
         assertThat(ex.getMessage(), containsString("Document is missing mandatory uniqueKey field: id"));
       } catch(Exception ex) {
         fail("Expected a SolrException to occur, instead received: " + ex.getClass());
       } finally {
-        solrServer.shutdown();
+        solrClient.shutdown();
       }
     }
   }
diff --git a/solr/core/src/test/org/apache/solr/cloud/ReplicaPropertiesBase.java b/solr/core/src/test/org/apache/solr/cloud/ReplicaPropertiesBase.java
index 04b02dc..311514e 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ReplicaPropertiesBase.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ReplicaPropertiesBase.java
@@ -17,15 +17,9 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-
 import org.apache.commons.lang.StringUtils;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.ClusterState;
 import org.apache.solr.common.cloud.DocCollection;
@@ -35,12 +29,18 @@ import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.zookeeper.KeeperException;
 
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+
 // Collect useful operations for testing assigning properties to individual replicas
 // Could probably expand this to do something creative with getting random slices
 // and shards, but for now this will do.
 public abstract class ReplicaPropertiesBase extends AbstractFullDistribZkTestBase {
 
-  public static NamedList<Object> doPropertyAction(CloudSolrServer client, String... paramsIn) throws IOException, SolrServerException {
+  public static NamedList<Object> doPropertyAction(CloudSolrClient client, String... paramsIn) throws IOException, SolrServerException {
     assertTrue("paramsIn must be an even multiple of 2, it is: " + paramsIn.length, (paramsIn.length % 2) == 0);
     ModifiableSolrParams params = new ModifiableSolrParams();
     for (int idx = 0; idx < paramsIn.length; idx += 2) {
@@ -51,7 +51,7 @@ public abstract class ReplicaPropertiesBase extends AbstractFullDistribZkTestBas
     return client.request(request);
   }
 
-  public static void verifyPropertyNotPresent(CloudSolrServer client, String collectionName, String replicaName,
+  public static void verifyPropertyNotPresent(CloudSolrClient client, String collectionName, String replicaName,
                                 String property)
       throws KeeperException, InterruptedException {
     ClusterState clusterState = null;
@@ -76,7 +76,7 @@ public abstract class ReplicaPropertiesBase extends AbstractFullDistribZkTestBas
   // collection
   // shard
   // replica
-  public static void verifyPropertyVal(CloudSolrServer client, String collectionName,
+  public static void verifyPropertyVal(CloudSolrClient client, String collectionName,
                          String replicaName, String property, String val)
       throws InterruptedException, KeeperException {
     Replica replica = null;
@@ -102,16 +102,17 @@ public abstract class ReplicaPropertiesBase extends AbstractFullDistribZkTestBas
   // Verify that
   // 1> the property is only set once in all the replicas in a slice.
   // 2> the property is balanced evenly across all the nodes hosting collection
-  public static void verifyUniqueAcrossCollection(CloudSolrServer client, String collectionName,
+  public static void verifyUniqueAcrossCollection(CloudSolrClient client, String collectionName,
                                     String property) throws KeeperException, InterruptedException {
     verifyUnique(client, collectionName, property, true);
   }
 
-  public static void verifyUniquePropertyWithinCollection(CloudSolrServer client, String collectionName,
+  public static void verifyUniquePropertyWithinCollection(CloudSolrClient client, String collectionName,
                             String property) throws KeeperException, InterruptedException {
     verifyUnique(client, collectionName, property, false);
   }
-  public static void verifyUnique(CloudSolrServer client, String collectionName, String property, boolean balanced)
+
+  public static void verifyUnique(CloudSolrClient client, String collectionName, String property, boolean balanced)
       throws KeeperException, InterruptedException {
 
     DocCollection col = null;
diff --git a/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java b/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
index 94d6a18..76d43dd 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ReplicationFactorTest.java
@@ -31,7 +31,7 @@ import org.apache.lucene.util.LuceneTestCase.AwaitsFix;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.Replica;
@@ -205,11 +205,11 @@ public class ReplicationFactorTest extends AbstractFullDistribZkTestBase {
   
   @SuppressWarnings("rawtypes")
   protected void sendNonDirectUpdateRequestReplica(Replica replica, UpdateRequest up, int expectedRf, String collection) throws Exception {
-    HttpSolrServer solrServer = null;
+    HttpSolrClient solrServer = null;
     try {
       ZkCoreNodeProps zkProps = new ZkCoreNodeProps(replica);
       String url = zkProps.getBaseUrl() + "/" + collection;
-      solrServer = new HttpSolrServer(url);    
+      solrServer = new HttpSolrClient(url);
             
       NamedList resp = solrServer.request(up);
       NamedList hdr = (NamedList) resp.get("responseHeader");
diff --git a/solr/core/src/test/org/apache/solr/cloud/SSLMigrationTest.java b/solr/core/src/test/org/apache/solr/cloud/SSLMigrationTest.java
index 77d2c15..fff1bf4 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SSLMigrationTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SSLMigrationTest.java
@@ -29,7 +29,7 @@ import org.apache.commons.lang.StringUtils;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.LBHttpSolrServer;
+import org.apache.solr.client.solrj.impl.LBHttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
@@ -115,7 +115,7 @@ public class SSLMigrationTest extends AbstractFullDistribZkTestBase {
       urls.add(replica.getStr(ZkStateReader.BASE_URL_PROP));
     }
     //Create new SolrServer to configure new HttpClient w/ SSL config
-    new LBHttpSolrServer(urls.toArray(new String[]{})).request(request);
+    new LBHttpSolrClient(urls.toArray(new String[]{})).request(request);
   }
   
 }
\ No newline at end of file
diff --git a/solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest.java b/solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest.java
index f5bd599..a883f99 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ShardRoutingTest.java
@@ -18,10 +18,10 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
@@ -313,7 +313,7 @@ public class ShardRoutingTest extends AbstractFullDistribZkTestBase {
     assertEquals(8, nClients);
 
     int expectedVal = 0;
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       client.add(sdoc("id", "b!doc", "foo_i", map("inc",1)));
       expectedVal++;
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/ShardSplitTest.java b/solr/core/src/test/org/apache/solr/cloud/ShardSplitTest.java
index 3f2b0b3..06c3df7 100644
--- a/solr/core/src/test/org/apache/solr/cloud/ShardSplitTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/ShardSplitTest.java
@@ -18,12 +18,13 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.http.params.CoreConnectionPNames;
+import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
@@ -42,7 +43,6 @@ import org.junit.After;
 import org.junit.Before;
 
 import java.io.IOException;
-import java.net.MalformedURLException;
 import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -51,10 +51,9 @@ import java.util.Map;
 import java.util.Random;
 import java.util.Set;
 
-import org.apache.lucene.util.LuceneTestCase.Slow;
 import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
-import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
+import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
 
 @Slow
 public class ShardSplitTest extends BasicDistributedZkTest {
@@ -126,7 +125,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     try {
       splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);
       fail("Shard splitting with just one custom hash range should not succeed");
-    } catch (HttpSolrServer.RemoteSolrException e) {
+    } catch (HttpSolrClient.RemoteSolrException e) {
       log.info("Expected exception:", e);
     }
     subRanges.clear();
@@ -137,7 +136,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     try {
       splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);
       fail("Shard splitting with missing hashes in between given ranges should not succeed");
-    } catch (HttpSolrServer.RemoteSolrException e) {
+    } catch (HttpSolrClient.RemoteSolrException e) {
       log.info("Expected exception:", e);
     }
     subRanges.clear();
@@ -150,7 +149,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     try {
       splitShard(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1, subRanges, null);
       fail("Shard splitting with overlapping ranges should not succeed");
-    } catch (HttpSolrServer.RemoteSolrException e) {
+    } catch (HttpSolrClient.RemoteSolrException e) {
       log.info("Expected exception:", e);
     }
     subRanges.clear();
@@ -220,7 +219,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
           log.info("Layout after split: \n");
           printLayout();
           break;
-        } catch (HttpSolrServer.RemoteSolrException e) {
+        } catch (HttpSolrClient.RemoteSolrException e) {
           if (e.code() != 500)  {
             throw e;
           }
@@ -248,11 +247,11 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     String collectionName = "routeFieldColl";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     String shard_fld = "shard_s";
     try {
       client = createCloudClient(null);
@@ -272,9 +271,9 @@ public class ShardSplitTest extends BasicDistributedZkTest {
 
     waitForRecoveriesToFinish(false);
 
-    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
+    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);
 
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
 
     ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();
     final DocRouter router = clusterState.getCollection(collectionName).getRouter();
@@ -304,7 +303,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
       try {
         splitShard(collectionName, SHARD1, null, null);
         break;
-      } catch (HttpSolrServer.RemoteSolrException e) {
+      } catch (HttpSolrClient.RemoteSolrException e) {
         if (e.code() != 500) {
           throw e;
         }
@@ -327,11 +326,11 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     String collectionName = "splitByRouteKeyTest";
     int numShards = 4;
     int replicationFactor = 2;
-    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = (((numShards * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     HashMap<String, List<Integer>> collectionInfos = new HashMap<>();
-    CloudSolrServer client = null;
+    CloudSolrClient client = null;
     try {
       client = createCloudClient(null);
       Map<String, Object> props = ZkNodeProps.makeMap(
@@ -349,9 +348,9 @@ public class ShardSplitTest extends BasicDistributedZkTest {
 
     waitForRecoveriesToFinish(false);
 
-    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrServer().getZkStateReader().getClusterState(), collectionName);
+    String url = CustomCollectionTest.getUrlFromZk(getCommonCloudSolrClient().getZkStateReader().getClusterState(), collectionName);
 
-    HttpSolrServer collectionClient = new HttpSolrServer(url);
+    HttpSolrClient collectionClient = new HttpSolrClient(url);
 
     String splitKey = "b!";
 
@@ -389,7 +388,7 @@ public class ShardSplitTest extends BasicDistributedZkTest {
       try {
         splitShard(collectionName, null, null, splitKey);
         break;
-      } catch (HttpSolrServer.RemoteSolrException e) {
+      } catch (HttpSolrClient.RemoteSolrException e) {
         if (e.code() != 500) {
           throw e;
         }
@@ -447,23 +446,23 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     query.set("distrib", false);
 
     ZkCoreNodeProps shard1_0 = getLeaderUrlFromZk(AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1_0);
-    HttpSolrServer shard1_0Server = new HttpSolrServer(shard1_0.getCoreUrl());
+    HttpSolrClient shard1_0Client = new HttpSolrClient(shard1_0.getCoreUrl());
     QueryResponse response;
     try {
-      response = shard1_0Server.query(query);
+      response = shard1_0Client.query(query);
     } finally {
-      shard1_0Server.shutdown();
+      shard1_0Client.shutdown();
     }
     long shard10Count = response.getResults().getNumFound();
 
     ZkCoreNodeProps shard1_1 = getLeaderUrlFromZk(
         AbstractDistribZkTestBase.DEFAULT_COLLECTION, SHARD1_1);
-    HttpSolrServer shard1_1Server = new HttpSolrServer(shard1_1.getCoreUrl());
+    HttpSolrClient shard1_1Client = new HttpSolrClient(shard1_1.getCoreUrl());
     QueryResponse response2;
     try {
-      response2 = shard1_1Server.query(query);
+      response2 = shard1_1Client.query(query);
     } finally {
-      shard1_1Server.shutdown();
+      shard1_1Client.shutdown();
     }
     long shard11Count = response2.getResults().getNumFound();
 
@@ -483,12 +482,12 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     int c = 0;
     for (Replica replica : slice.getReplicas()) {
       String coreUrl = new ZkCoreNodeProps(replica).getCoreUrl();
-      HttpSolrServer server = new HttpSolrServer(coreUrl);
+      HttpSolrClient client = new HttpSolrClient(coreUrl);
       QueryResponse response;
       try {
-        response = server.query(query);
+        response = client.query(query);
       } finally {
-        server.shutdown();
+        client.shutdown();
       }
       numFound[c++] = response.getResults().getNumFound();
       log.info("Shard: " + shard + " Replica: {} has {} docs", coreUrl, String.valueOf(response.getResults().getNumFound()));
@@ -522,15 +521,15 @@ public class ShardSplitTest extends BasicDistributedZkTest {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
-    baseServer.setConnectionTimeout(30000);
-    baseServer.setSoTimeout(60000 * 5);
-    baseServer.request(request);
-    baseServer.shutdown();
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
+    baseClient.setConnectionTimeout(30000);
+    baseClient.setSoTimeout(60000 * 5);
+    baseClient.request(request);
+    baseClient.shutdown();
   }
 
   protected void indexAndUpdateCount(DocRouter router, List<DocRouter.Range> ranges, int[] docCounts, String id, int n) throws Exception {
@@ -600,23 +599,23 @@ public class ShardSplitTest extends BasicDistributedZkTest {
   }
 
   @Override
-  protected SolrServer createNewSolrServer(String collection, String baseUrl) {
-    HttpSolrServer server = (HttpSolrServer) super.createNewSolrServer(collection, baseUrl);
-    server.setSoTimeout(5 * 60 * 1000);
-    return server;
+  protected SolrClient createNewSolrClient(String collection, String baseUrl) {
+    HttpSolrClient client = (HttpSolrClient) super.createNewSolrClient(collection, baseUrl);
+    client.setSoTimeout(5 * 60 * 1000);
+    return client;
   }
 
   @Override
-  protected SolrServer createNewSolrServer(int port) {
-    HttpSolrServer server = (HttpSolrServer) super.createNewSolrServer(port);
-    server.setSoTimeout(5 * 60 * 1000);
-    return server;
+  protected SolrClient createNewSolrClient(int port) {
+    HttpSolrClient client = (HttpSolrClient) super.createNewSolrClient(port);
+    client.setSoTimeout(5 * 60 * 1000);
+    return client;
   }
 
   @Override
-  protected CloudSolrServer createCloudClient(String defaultCollection) {
-    CloudSolrServer client = super.createCloudClient(defaultCollection);
-    client.getLbServer().getHttpClient().getParams().setParameter(CoreConnectionPNames.SO_TIMEOUT, 5 * 60 * 1000);
+  protected CloudSolrClient createCloudClient(String defaultCollection) {
+    CloudSolrClient client = super.createCloudClient(defaultCollection);
+    client.getLbClient().getHttpClient().getParams().setParameter(CoreConnectionPNames.SO_TIMEOUT, 5 * 60 * 1000);
     return client;
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java b/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
index c54c7b4..c9347ff 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SharedFSAutoReplicaFailoverTest.java
@@ -142,7 +142,7 @@ public class SharedFSAutoReplicaFailoverTest extends AbstractFullDistribZkTestBa
     createCollectionRequest.setConfigName("conf1");
     createCollectionRequest.setRouterField("myOwnField");
     createCollectionRequest.setAutoAddReplicas(false);
-    CollectionAdminResponse response2 = createCollectionRequest.process(getCommonCloudSolrServer());
+    CollectionAdminResponse response2 = createCollectionRequest.process(getCommonCloudSolrClient());
 
     assertEquals(0, response2.getStatus());
     assertTrue(response2.isSuccess());
diff --git a/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java b/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
index ad00be9..bf50d8d 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SimpleCollectionCreateDeleteTest.java
@@ -17,13 +17,10 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.common.cloud.SolrZkClient;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.NamedList;
 
 public class SimpleCollectionCreateDeleteTest extends AbstractFullDistribZkTestBase {
diff --git a/solr/core/src/test/org/apache/solr/cloud/SyncSliceTest.java b/solr/core/src/test/org/apache/solr/cloud/SyncSliceTest.java
index 7e1da83..ef2278f 100644
--- a/solr/core/src/test/org/apache/solr/cloud/SyncSliceTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/SyncSliceTest.java
@@ -17,18 +17,11 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrInputDocument;
@@ -44,6 +37,13 @@ import org.junit.AfterClass;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
 /**
  * Test sync phase that occurs when Leader goes down and a new Leader is
  * elected.
@@ -128,16 +128,16 @@ public class SyncSliceTest extends AbstractFullDistribZkTestBase {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
     
-    String baseUrl = ((HttpSolrServer) shardToJetty.get("shard1").get(2).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get("shard1").get(2).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
     
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
     // we only set the connect timeout, not so timeout
-    baseServer.setConnectionTimeout(30000);
-    baseServer.request(request);
-    baseServer.shutdown();
-    baseServer = null;
+    baseClient.setConnectionTimeout(30000);
+    baseClient.request(request);
+    baseClient.shutdown();
+    baseClient = null;
     
     waitForThingsToLevelOut(15);
     
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestCollectionAPI.java b/solr/core/src/test/org/apache/solr/cloud/TestCollectionAPI.java
index f0d4a09..9292048 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestCollectionAPI.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestCollectionAPI.java
@@ -21,7 +21,7 @@ package org.apache.solr.cloud;
 import com.google.common.collect.Lists;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrInputDocument;
@@ -64,7 +64,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
 
   @Override
   public void doTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       createCollection(null, COLLECTION_NAME, 2, 2, 2, client, null, "conf1");
       createCollection(null, COLLECTION_NAME1, 1, 1, 1, client, null, "conf1");
@@ -89,7 +89,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusWithCollectionAndShard() throws IOException, SolrServerException {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.CLUSTERSTATUS.toString());
@@ -119,7 +119,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
 
 
   private void listCollection() throws IOException, SolrServerException {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.LIST.toString());
@@ -141,7 +141,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusNoCollection() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.CLUSTERSTATUS.toString());
@@ -167,7 +167,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusWithCollection() throws IOException, SolrServerException {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.CLUSTERSTATUS.toString());
@@ -189,7 +189,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusWithRouteKey() throws IOException, SolrServerException {
-    CloudSolrServer client = createCloudClient(DEFAULT_COLLECTION);
+    CloudSolrClient client = createCloudClient(DEFAULT_COLLECTION);
     try {
       SolrInputDocument doc = new SolrInputDocument();
       doc.addField("id", "a!123"); // goes to shard2. see ShardRoutingTest for details
@@ -222,7 +222,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusAliasTest() throws Exception  {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.CREATEALIAS.toString());
@@ -259,7 +259,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void clusterStatusRolesTest() throws Exception  {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       client.connect();
       Replica replica = client.getZkStateReader().getLeaderRetry(DEFAULT_COLLECTION, SHARD1);
@@ -293,7 +293,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
   }
 
   private void replicaPropTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       client.connect();
       Map<String, Slice> slices = client.getZkStateReader().getClusterState().getCollection(COLLECTION_NAME).getSlicesMap();
@@ -577,7 +577,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
 
 
   // Expects the map will have keys, but blank values.
-  private Map<String, String> getProps(CloudSolrServer client, String collectionName, String replicaName, String... props)
+  private Map<String, String> getProps(CloudSolrClient client, String collectionName, String replicaName, String... props)
       throws KeeperException, InterruptedException {
 
     client.getZkStateReader().updateClusterState(true);
@@ -592,7 +592,7 @@ public class TestCollectionAPI extends ReplicaPropertiesBase {
     }
     return propMap;
   }
-  private void missingParamsError(CloudSolrServer client, ModifiableSolrParams origParams)
+  private void missingParamsError(CloudSolrClient client, ModifiableSolrParams origParams)
       throws IOException, SolrServerException {
 
     SolrRequest request;
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestDistribDocBasedVersion.java b/solr/core/src/test/org/apache/solr/cloud/TestDistribDocBasedVersion.java
index e81ddb4..8238a04 100755
--- a/solr/core/src/test/org/apache/solr/cloud/TestDistribDocBasedVersion.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestDistribDocBasedVersion.java
@@ -17,13 +17,11 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.embedded.JettySolrRunner;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.common.params.ShardParams;
 import org.apache.solr.common.util.StrUtils;
 import org.junit.BeforeClass;
 
@@ -116,9 +114,9 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
     log.info("### STARTING doTestHardFail");
 
     // use a leader so we test both forwarding and non-forwarding logic
-    ss = shardToLeaderJetty.get(bucket1).client.solrClient;
+    solrClient = shardToLeaderJetty.get(bucket1).client.solrClient;
 
-    // ss = cloudClient;   CloudSolrServer doesn't currently support propagating error codes
+    // solrClient = cloudClient;   CloudSolrServer doesn't currently support propagating error codes
 
     doTestHardFail("p!doc1");
     doTestHardFail("q!doc1");
@@ -139,7 +137,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
     log.info("### STARTING doTestDocVersions");
     assertEquals(2, cloudClient.getZkStateReader().getClusterState().getCollection(DEFAULT_COLLECTION).getSlices().size());
 
-    ss = cloudClient;
+    solrClient = cloudClient;
 
     vadd("b!doc1", 10);
     vadd("c!doc2", 11);
@@ -183,7 +181,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
     // now test with a non-smart client
     //
     // use a leader so we test both forwarding and non-forwarding logic
-    ss = shardToLeaderJetty.get(bucket1).client.solrClient;
+    solrClient = shardToLeaderJetty.get(bucket1).client.solrClient;
 
     vadd("b!doc5", 10);
     vadd("c!doc6", 11);
@@ -237,7 +235,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
 
   }
 
-  SolrServer ss;
+  SolrClient solrClient;
 
   void vdelete(String id, long version, String... params) throws Exception {
     UpdateRequest req = new UpdateRequest();
@@ -246,7 +244,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
     for (int i=0; i<params.length; i+=2) {
       req.setParam( params[i], params[i+1]);
     }
-    ss.request(req);
+    solrClient.request(req);
     // req.process(cloudClient);
   }
 
@@ -256,7 +254,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
     for (int i=0; i<params.length; i+=2) {
       req.setParam( params[i], params[i+1]);
     }
-    ss.request(req);
+    solrClient.request(req);
   }
 
   void vaddFail(String id, long version, int errCode, String... params) throws Exception {
@@ -315,7 +313,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
       expectedIds.put(strs.get(i), Long.valueOf(verS.get(i)));
     }
 
-    ss.query(params("qt","/get", "ids",ids));
+    solrClient.query(params("qt", "/get", "ids", ids));
 
     QueryResponse rsp = cloudClient.query(params("qt","/get", "ids",ids));
     Map<String, Object> obtainedIds = new HashMap<>();
@@ -327,7 +325,7 @@ public class TestDistribDocBasedVersion extends AbstractFullDistribZkTestBase {
   }
 
   void doRTG(String ids) throws Exception {
-    ss.query(params("qt","/get", "ids",ids));
+    solrClient.query(params("qt", "/get", "ids", ids));
 
     Set<String> expectedIds = new HashSet<>( StrUtils.splitSmart(ids, ",", true) );
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudCluster.java b/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudCluster.java
index c61da70..e5a8337 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudCluster.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestMiniSolrCloudCluster.java
@@ -17,18 +17,13 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
+import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.SuppressSysoutChecks;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrInputDocument;
@@ -52,7 +47,11 @@ import org.junit.rules.TestRule;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
+import java.io.File;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 /**
  * Test of the MiniSolrCloudCluster functionality. Keep in mind, 
@@ -118,11 +117,11 @@ public class TestMiniSolrCloudCluster extends LuceneTestCase {
     assertTrue(startedServer.isRunning());
     assertEquals(NUM_SERVERS, miniCluster.getJettySolrRunners().size());
 
-    CloudSolrServer cloudSolrServer = null;
+    CloudSolrClient cloudSolrClient = null;
     SolrZkClient zkClient = null;
     try {
-      cloudSolrServer = new CloudSolrServer(miniCluster.getZkServer().getZkAddress(), true);
-      cloudSolrServer.connect();
+      cloudSolrClient = new CloudSolrClient(miniCluster.getZkServer().getZkAddress(), true);
+      cloudSolrClient.connect();
       zkClient = new SolrZkClient(miniCluster.getZkServer().getZkAddress(),
         AbstractZkTestCase.TIMEOUT, 45000, null);
 
@@ -131,20 +130,20 @@ public class TestMiniSolrCloudCluster extends LuceneTestCase {
       String configName = "solrCloudCollectionConfig";
       System.setProperty("solr.tests.mergePolicy", "org.apache.lucene.index.TieredMergePolicy");
       uploadConfigToZk(SolrTestCaseJ4.TEST_HOME() + File.separator + "collection1" + File.separator + "conf", configName);
-      createCollection(cloudSolrServer, collectionName, NUM_SHARDS, REPLICATION_FACTOR, configName);
+      createCollection(cloudSolrClient, collectionName, NUM_SHARDS, REPLICATION_FACTOR, configName);
 
       // modify/query collection
-      cloudSolrServer.setDefaultCollection(collectionName);
+      cloudSolrClient.setDefaultCollection(collectionName);
       SolrInputDocument doc = new SolrInputDocument();
       doc.setField("id", "1");
 
       ZkStateReader zkStateReader = new ZkStateReader(zkClient);
       waitForRecoveriesToFinish(collectionName, zkStateReader, true, true, 330);
-      cloudSolrServer.add(doc);
-      cloudSolrServer.commit();
+      cloudSolrClient.add(doc);
+      cloudSolrClient.commit();
       SolrQuery query = new SolrQuery();
       query.setQuery("*:*");
-      QueryResponse rsp = cloudSolrServer.query(query);
+      QueryResponse rsp = cloudSolrClient.query(query);
       assertEquals(1, rsp.getResults().getNumFound());
 
       // remove a server not hosting any replicas
@@ -173,8 +172,8 @@ public class TestMiniSolrCloudCluster extends LuceneTestCase {
         }
       }
     } finally {
-      if (cloudSolrServer != null) {
-        cloudSolrServer.shutdown();
+      if (cloudSolrClient != null) {
+        cloudSolrClient.shutdown();
       }
       if (zkClient != null) {
         zkClient.close();
@@ -217,7 +216,7 @@ public class TestMiniSolrCloudCluster extends LuceneTestCase {
     zkClient.makePath(ZkController.CONFIGS_ZKNODE + "/" + configName + "/" + nameInZk, file, false, true);
   }
 
-  protected NamedList<Object> createCollection(CloudSolrServer server, String name, int numShards,
+  protected NamedList<Object> createCollection(CloudSolrClient client, String name, int numShards,
       int replicationFactor, String configName) throws Exception {
     ModifiableSolrParams modParams = new ModifiableSolrParams();
     modParams.set(CoreAdminParams.ACTION, CollectionAction.CREATE.name());
@@ -227,7 +226,7 @@ public class TestMiniSolrCloudCluster extends LuceneTestCase {
     modParams.set("collection.configName", configName);
     QueryRequest request = new QueryRequest(modParams);
     request.setPath("/admin/collections");
-    return server.request(request);
+    return client.request(request);
   }
 
   protected void waitForRecoveriesToFinish(String collection,
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestModifyConfFiles.java b/solr/core/src/test/org/apache/solr/cloud/TestModifyConfFiles.java
index 1ab3af7..cc73065 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestModifyConfFiles.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestModifyConfFiles.java
@@ -18,7 +18,7 @@ package org.apache.solr.cloud;
 
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.cloud.SolrZkClient;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -39,7 +39,7 @@ public class TestModifyConfFiles extends AbstractFullDistribZkTestBase {
   @Override
   public void doTest() throws Exception {
     int which = r.nextInt(clients.size());
-    HttpSolrServer client = (HttpSolrServer) clients.get(which);
+    HttpSolrClient client = (HttpSolrClient) clients.get(which);
 
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("op", "write");
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
index 01593ac..21e819b 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRebalanceLeaders.java
@@ -16,19 +16,10 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.common.cloud.ClusterState;
-import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
 import org.apache.solr.common.cloud.Slice;
 import org.apache.solr.common.cloud.ZkStateReader;
@@ -38,6 +29,12 @@ import org.apache.solr.common.util.NamedList;
 import org.apache.zookeeper.KeeperException;
 import org.junit.Before;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
 
 public class TestRebalanceLeaders extends AbstractFullDistribZkTestBase {
 
@@ -65,7 +62,7 @@ public class TestRebalanceLeaders extends AbstractFullDistribZkTestBase {
 
   @Override
   public void doTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     reps = random().nextInt(9) + 1; // make sure and do at least one.
     try {
       // Mix up a bunch of different combinations of shards and replicas in order to exercise boundary cases.
@@ -247,11 +244,11 @@ public class TestRebalanceLeaders extends AbstractFullDistribZkTestBase {
     return true;
   }
 
-  byte[] getZkData(CloudSolrServer server, String path) {
+  byte[] getZkData(CloudSolrClient client, String path) {
     org.apache.zookeeper.data.Stat stat = new org.apache.zookeeper.data.Stat();
     long start = System.currentTimeMillis();
     try {
-      byte[] data = server.getZkStateReader().getZkClient().getData(path, null, stat, true);
+      byte[] data = client.getZkStateReader().getZkClient().getData(path, null, stat, true);
       if (data != null) {
         return data;
       }
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestReplicaProperties.java b/solr/core/src/test/org/apache/solr/cloud/TestReplicaProperties.java
index 42a15ca..5c854fa 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestReplicaProperties.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestReplicaProperties.java
@@ -26,7 +26,7 @@ import java.util.Map;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.cloud.ClusterState;
@@ -58,7 +58,7 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
 
   @Override
   public void doTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       // Mix up a bunch of different combinations of shards and replicas in order to exercise boundary cases.
       // shards, replicationfactor, maxreplicaspernode
@@ -81,7 +81,7 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
   }
 
   private void listCollection() throws IOException, SolrServerException {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       ModifiableSolrParams params = new ModifiableSolrParams();
       params.set("action", CollectionParams.CollectionAction.LIST.toString());
@@ -101,7 +101,7 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
 
 
   private void clusterAssignPropertyTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
+    CloudSolrClient client = createCloudClient(null);
     try {
       client.connect();
       try {
@@ -204,7 +204,7 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
     }
   }
 
-  private void verifyLeaderAssignment(CloudSolrServer client, String collectionName)
+  private void verifyLeaderAssignment(CloudSolrClient client, String collectionName)
       throws InterruptedException, KeeperException {
     String lastFailMsg = "";
     for (int idx = 0; idx < 300; ++idx) { // Keep trying while Overseer writes the ZK state for up to 30 seconds.
@@ -239,7 +239,7 @@ public class TestReplicaProperties extends ReplicaPropertiesBase {
     fail(lastFailMsg);
   }
 
-  private void addProperty(CloudSolrServer client, String... paramsIn) throws IOException, SolrServerException {
+  private void addProperty(CloudSolrClient client, String... paramsIn) throws IOException, SolrServerException {
     assertTrue("paramsIn must be an even multiple of 2, it is: " + paramsIn.length, (paramsIn.length % 2) == 0);
     ModifiableSolrParams params = new ModifiableSolrParams();
     for (int idx = 0; idx < paramsIn.length; idx += 2) {
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestRequestStatusCollectionAPI.java b/solr/core/src/test/org/apache/solr/cloud/TestRequestStatusCollectionAPI.java
index b2fae5d..b63e663 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestRequestStatusCollectionAPI.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestRequestStatusCollectionAPI.java
@@ -19,7 +19,7 @@ package org.apache.solr.cloud;
 
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.params.CollectionParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -214,12 +214,12 @@ public class TestRequestStatusCollectionAPI extends BasicDistributedZkTest {
     SolrRequest request = new QueryRequest(params);
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
-    baseServer.setConnectionTimeout(15000);
-    return baseServer.request(request);
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
+    baseClient.setConnectionTimeout(15000);
+    return baseClient.request(request);
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/cloud/TestShortCircuitedRequests.java b/solr/core/src/test/org/apache/solr/cloud/TestShortCircuitedRequests.java
index 5c214b8..8886ec4 100644
--- a/solr/core/src/test/org/apache/solr/cloud/TestShortCircuitedRequests.java
+++ b/solr/core/src/test/org/apache/solr/cloud/TestShortCircuitedRequests.java
@@ -18,7 +18,7 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.cloud.Replica;
 import org.apache.solr.common.params.ShardParams;
@@ -48,7 +48,7 @@ public class TestShortCircuitedRequests extends AbstractFullDistribZkTestBase {
     // query shard3 directly with _route_=a! so that we trigger the short circuited request path
     Replica shard3 = cloudClient.getZkStateReader().getClusterState().getLeader(DEFAULT_COLLECTION, "shard3");
     String nodeName = shard3.getNodeName();
-    SolrServer shard3Client = getClient(nodeName);
+    SolrClient shard3Client = getClient(nodeName);
     QueryResponse response = shard3Client.query(new SolrQuery("*:*").add(ShardParams._ROUTE_, "a!").add(ShardParams.SHARDS_INFO, "true"));
 
     assertEquals("Could not find doc", 1, response.getResults().getNumFound());
diff --git a/solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest.java b/solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest.java
index 774f61d..f2c1291 100644
--- a/solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest.java
@@ -17,19 +17,12 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.IOException;
-import java.util.Random;
-import java.util.concurrent.SynchronousQueue;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Create;
 import org.apache.solr.client.solrj.request.CoreAdminRequest.Unload;
 import org.apache.solr.common.SolrInputDocument;
@@ -41,6 +34,13 @@ import org.apache.solr.util.DefaultSolrThreadFactory;
 import org.junit.Before;
 import org.junit.BeforeClass;
 
+import java.io.File;
+import java.io.IOException;
+import java.util.Random;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
 /**
  * This test simply does a bunch of basic things in solrcloud mode and asserts things
  * work as expected.
@@ -92,12 +92,12 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     createCmd.setDataDir(getDataDir(coreDataDir));
     createCmd.setNumShards(2);
     
-    SolrServer client = clients.get(0);
+    SolrClient client = clients.get(0);
     String url1 = getBaseUrl(client);
-    HttpSolrServer server = new HttpSolrServer(url1);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
-    server.request(createCmd);
+    HttpSolrClient adminClient = new HttpSolrClient(url1);
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(60000);
+    adminClient.request(createCmd);
     
     createCmd = new Create();
     createCmd.setCoreName("test_unload_shard_and_collection_2");
@@ -106,7 +106,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     coreDataDir = createTempDir().toFile().getAbsolutePath();
     createCmd.setDataDir(getDataDir(coreDataDir));
     
-    server.request(createCmd);
+    adminClient.request(createCmd);
     
     // does not mean they are active and up yet :*
     waitForRecoveriesToFinish(collection, false);
@@ -114,10 +114,10 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     // now unload one of the two
     Unload unloadCmd = new Unload(false);
     unloadCmd.setCoreName("test_unload_shard_and_collection_2");
-    server.request(unloadCmd);
+    adminClient.request(unloadCmd);
     
     // there should be only one shard
-    int slices = getCommonCloudSolrServer().getZkStateReader().getClusterState().getSlices(collection).size();
+    int slices = getCommonCloudSolrClient().getZkStateReader().getClusterState().getSlices(collection).size();
     long timeoutAt = System.currentTimeMillis() + 45000;
     while (slices != 1) {
       if (System.currentTimeMillis() > timeoutAt) {
@@ -126,20 +126,20 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
       }
       
       Thread.sleep(1000);
-      slices = getCommonCloudSolrServer().getZkStateReader().getClusterState().getSlices(collection).size();
+      slices = getCommonCloudSolrClient().getZkStateReader().getClusterState().getSlices(collection).size();
     }
     
     // now unload one of the other
     unloadCmd = new Unload(false);
     unloadCmd.setCoreName("test_unload_shard_and_collection_1");
-    server.request(unloadCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(unloadCmd);
+    adminClient.shutdown();
+    adminClient = null;
     
     //printLayout();
     // the collection should be gone
     timeoutAt = System.currentTimeMillis() + 30000;
-    while (getCommonCloudSolrServer().getZkStateReader().getClusterState().hasCollection(collection)) {
+    while (getCommonCloudSolrClient().getZkStateReader().getClusterState().hasCollection(collection)) {
       if (System.currentTimeMillis() > timeoutAt) {
         printLayout();
         fail("Still found collection");
@@ -157,11 +157,11 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     File tmpDir = createTempDir().toFile();
     
     // create a new collection collection
-    SolrServer client = clients.get(0);
+    SolrClient client = clients.get(0);
     String url1 = getBaseUrl(client);
-    HttpSolrServer server = new HttpSolrServer(url1);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
+    HttpSolrClient adminClient = new HttpSolrClient(url1);
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(60000);
     
     Create createCmd = new Create();
     createCmd.setCoreName("unloadcollection1");
@@ -169,11 +169,11 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     createCmd.setNumShards(1);
     String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + "unloadcollection1" + "_1n";
     createCmd.setDataDir(getDataDir(core1DataDir));
-    server.request(createCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(createCmd);
+    adminClient.shutdown();
+    adminClient = null;
     
-    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();
+    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();
     
     zkStateReader.updateClusterState(true);
 
@@ -182,16 +182,16 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     
     client = clients.get(1);
     String url2 = getBaseUrl(client);
-    server = new HttpSolrServer(url2);
+    adminClient = new HttpSolrClient(url2);
     
     createCmd = new Create();
     createCmd.setCoreName("unloadcollection2");
     createCmd.setCollection("unloadcollection");
     String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + "unloadcollection1" + "_2n";
     createCmd.setDataDir(getDataDir(core2dataDir));
-    server.request(createCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(createCmd);
+    adminClient.shutdown();
+    adminClient = null;
     
     zkStateReader.updateClusterState(true);
     slices = zkStateReader.getClusterState().getCollection("unloadcollection").getSlices().size();
@@ -202,9 +202,9 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     ZkCoreNodeProps leaderProps = getLeaderUrlFromZk("unloadcollection", "shard1");
     
     Random random = random();
-    HttpSolrServer collectionClient;
+    HttpSolrClient collectionClient;
     if (random.nextBoolean()) {
-      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());
+      collectionClient = new HttpSolrClient(leaderProps.getCoreUrl());
       // lets try and use the solrj client to index and retrieve a couple
       // documents
       SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,
@@ -224,16 +224,16 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     // create another replica for our collection
     client = clients.get(2);
     String url3 = getBaseUrl(client);
-    server = new HttpSolrServer(url3);
+    adminClient = new HttpSolrClient(url3);
     
     createCmd = new Create();
     createCmd.setCoreName("unloadcollection3");
     createCmd.setCollection("unloadcollection");
     String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + "unloadcollection" + "_3n";
     createCmd.setDataDir(getDataDir(core3dataDir));
-    server.request(createCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(createCmd);
+    adminClient.shutdown();
+    adminClient = null;
     
     
     waitForRecoveriesToFinish("unloadcollection", zkStateReader, false);
@@ -241,7 +241,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     // so that we start with some versions when we reload...
     DirectUpdateHandler2.commitOnClose = false;
     
-    HttpSolrServer addClient = new HttpSolrServer(url3 + "/unloadcollection3");
+    HttpSolrClient addClient = new HttpSolrClient(url3 + "/unloadcollection3");
     addClient.setConnectionTimeout(30000);
 
     // add a few docs
@@ -257,7 +257,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     //collectionClient.commit();
     
     // unload the leader
-    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());
+    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());
     collectionClient.setConnectionTimeout(15000);
     collectionClient.setSoTimeout(30000);
     
@@ -283,7 +283,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     // ensure there is a leader
     zkStateReader.getLeaderRetry("unloadcollection", "shard1", 15000);
     
-    addClient = new HttpSolrServer(url2 + "/unloadcollection2");
+    addClient = new HttpSolrClient(url2 + "/unloadcollection2");
     addClient.setConnectionTimeout(30000);
     addClient.setSoTimeout(90000);
     
@@ -300,24 +300,24 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     // create another replica for our collection
     client = clients.get(3);
     String url4 = getBaseUrl(client);
-    server = new HttpSolrServer(url4);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(30000);
+    adminClient = new HttpSolrClient(url4);
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(30000);
     
     createCmd = new Create();
     createCmd.setCoreName("unloadcollection4");
     createCmd.setCollection("unloadcollection");
     String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + "unloadcollection" + "_4n";
     createCmd.setDataDir(getDataDir(core4dataDir));
-    server.request(createCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(createCmd);
+    adminClient.shutdown();
+    adminClient = null;
     
     waitForRecoveriesToFinish("unloadcollection", zkStateReader, false);
     
     // unload the leader again
     leaderProps = getLeaderUrlFromZk("unloadcollection", "shard1");
-    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());
+    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());
     collectionClient.setConnectionTimeout(15000);
     collectionClient.setSoTimeout(30000);
     
@@ -343,64 +343,64 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     DirectUpdateHandler2.commitOnClose = true;
     
     // bring the downed leader back as replica
-    server = new HttpSolrServer(leaderProps.getBaseUrl());
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(30000);
+    adminClient = new HttpSolrClient(leaderProps.getBaseUrl());
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(30000);
     
     createCmd = new Create();
     createCmd.setCoreName(leaderProps.getCoreName());
     createCmd.setCollection("unloadcollection");
     createCmd.setDataDir(getDataDir(core1DataDir));
-    server.request(createCmd);
-    server.shutdown();
-    server = null;
+    adminClient.request(createCmd);
+    adminClient.shutdown();
+    adminClient = null;
 
     waitForRecoveriesToFinish("unloadcollection", zkStateReader, false);
     
-    server = new HttpSolrServer(url2 + "/unloadcollection");
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(30000);
-    server.commit();
+    adminClient = new HttpSolrClient(url2 + "/unloadcollection");
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(30000);
+    adminClient.commit();
     SolrQuery q = new SolrQuery("*:*");
     q.set("distrib", false);
-    long found1 = server.query(q).getResults().getNumFound();
-    server.shutdown();
-    server = new HttpSolrServer(url3 + "/unloadcollection");
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(30000);
-    server.commit();
+    long found1 = adminClient.query(q).getResults().getNumFound();
+    adminClient.shutdown();
+    adminClient = new HttpSolrClient(url3 + "/unloadcollection");
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(30000);
+    adminClient.commit();
     q = new SolrQuery("*:*");
     q.set("distrib", false);
-    long found3 = server.query(q).getResults().getNumFound();
-    server.shutdown();
-    server = new HttpSolrServer(url4 + "/unloadcollection");
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(30000);
-    server.commit();
+    long found3 = adminClient.query(q).getResults().getNumFound();
+    adminClient.shutdown();
+    adminClient = new HttpSolrClient(url4 + "/unloadcollection");
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(30000);
+    adminClient.commit();
     q = new SolrQuery("*:*");
     q.set("distrib", false);
-    long found4 = server.query(q).getResults().getNumFound();
+    long found4 = adminClient.query(q).getResults().getNumFound();
     
     // all 3 shards should now have the same number of docs
     assertEquals(found1, found3);
     assertEquals(found3, found4);
-    server.shutdown();
+    adminClient.shutdown();
     
   }
   
   private void testUnloadLotsOfCores() throws Exception {
-    SolrServer client = clients.get(2);
+    SolrClient client = clients.get(2);
     String url3 = getBaseUrl(client);
-    final HttpSolrServer server = new HttpSolrServer(url3);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
+    final HttpSolrClient adminClient = new HttpSolrClient(url3);
+    adminClient.setConnectionTimeout(15000);
+    adminClient.setSoTimeout(60000);
     ThreadPoolExecutor executor = new ThreadPoolExecutor(0, Integer.MAX_VALUE,
         5, TimeUnit.SECONDS, new SynchronousQueue<Runnable>(),
         new DefaultSolrThreadFactory("testExecutor"));
     int cnt = atLeast(3);
     
     // create the cores
-    createCores(server, executor, "multiunload", 2, cnt);
+    createCores(adminClient, executor, "multiunload", 2, cnt);
     
     executor.shutdown();
     executor.awaitTermination(120, TimeUnit.SECONDS);
@@ -415,7 +415,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
           Unload unloadCmd = new Unload(true);
           unloadCmd.setCoreName("multiunload" + freezeJ);
           try {
-            server.request(unloadCmd);
+            adminClient.request(unloadCmd);
           } catch (SolrServerException e) {
             throw new RuntimeException(e);
           } catch (IOException e) {
@@ -427,7 +427,7 @@ public class UnloadDistributedZkTest extends BasicDistributedZkTest {
     }
     executor.shutdown();
     executor.awaitTermination(120, TimeUnit.SECONDS);
-    server.shutdown();
+    adminClient.shutdown();
   }
 
 
diff --git a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
index 47017ec..0d9ae42 100644
--- a/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/hdfs/HdfsWriteToMultipleCollectionsTest.java
@@ -17,11 +17,8 @@
 
 package org.apache.solr.cloud.hdfs;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope.Scope;
 import org.apache.hadoop.hdfs.MiniDFSCluster;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.store.NRTCachingDirectory;
@@ -29,7 +26,7 @@ import org.apache.lucene.util.LuceneTestCase.Nightly;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.cloud.BasicDistributedZkTest;
 import org.apache.solr.cloud.StopableIndexingThread;
 import org.apache.solr.core.CoreContainer;
@@ -44,8 +41,10 @@ import org.apache.solr.util.RefCounted;
 import org.junit.AfterClass;
 import org.junit.BeforeClass;
 
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope;
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakScope.Scope;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
 
 @Slow
 @Nightly
@@ -95,13 +94,13 @@ public class HdfsWriteToMultipleCollectionsTest extends BasicDistributedZkTest {
     for (int i = 0; i < cnt; i++) {
       waitForRecoveriesToFinish(ACOLLECTION + i, false);
     }
-    List<CloudSolrServer> cloudServers = new ArrayList<>();
+    List<CloudSolrClient> cloudClients = new ArrayList<>();
     List<StopableIndexingThread> threads = new ArrayList<>();
     for (int i = 0; i < cnt; i++) {
-      CloudSolrServer server = new CloudSolrServer(zkServer.getZkAddress());
-      server.setDefaultCollection(ACOLLECTION + i);
-      cloudServers.add(server);
-      StopableIndexingThread indexThread = new StopableIndexingThread(null, server, "1", true, docCount);
+      CloudSolrClient client = new CloudSolrClient(zkServer.getZkAddress());
+      client.setDefaultCollection(ACOLLECTION + i);
+      cloudClients.add(client);
+      StopableIndexingThread indexThread = new StopableIndexingThread(null, client, "1", true, docCount);
       threads.add(indexThread);
       indexThread.start();
     }
@@ -113,13 +112,13 @@ public class HdfsWriteToMultipleCollectionsTest extends BasicDistributedZkTest {
     }
    
     long collectionsCount = 0;
-    for (CloudSolrServer server : cloudServers) {
-      server.commit();
-      collectionsCount += server.query(new SolrQuery("*:*")).getResults().getNumFound();
+    for (CloudSolrClient client : cloudClients) {
+      client.commit();
+      collectionsCount += client.query(new SolrQuery("*:*")).getResults().getNumFound();
     }
     
-    for (CloudSolrServer server : cloudServers) {
-      server.shutdown();
+    for (CloudSolrClient client : cloudClients) {
+      client.shutdown();
     }
 
     assertEquals(addCnt, collectionsCount);
diff --git a/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java b/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
index d64c723..cdbd348 100644
--- a/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
+++ b/solr/core/src/test/org/apache/solr/cloud/hdfs/StressHdfsTest.java
@@ -33,9 +33,9 @@ import org.apache.hadoop.hdfs.server.namenode.NameNodeAdapter;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.cloud.BasicDistributedZkTest;
 import org.apache.solr.cloud.ChaosMonkey;
@@ -162,8 +162,8 @@ public class StressHdfsTest extends BasicDistributedZkTest {
     List<String> dataDirs = new ArrayList<>();
     
     int i = 0;
-    for (SolrServer client : clients) {
-      HttpSolrServer c = new HttpSolrServer(getBaseUrl(client) + "/" + DELETE_DATA_DIR_COLLECTION);
+    for (SolrClient client : clients) {
+      HttpSolrClient c = new HttpSolrClient(getBaseUrl(client) + "/" + DELETE_DATA_DIR_COLLECTION);
       try {
         int docCnt = random().nextInt(1000) + 1;
         for (int j = 0; j < docCnt; j++) {
diff --git a/solr/core/src/test/org/apache/solr/core/OpenCloseCoreStressTest.java b/solr/core/src/test/org/apache/solr/core/OpenCloseCoreStressTest.java
index d5f6251..5dc1687 100644
--- a/solr/core/src/test/org/apache/solr/core/OpenCloseCoreStressTest.java
+++ b/solr/core/src/test/org/apache/solr/core/OpenCloseCoreStressTest.java
@@ -17,23 +17,11 @@
 
 package org.apache.solr.core;
 
-import java.io.File;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.Random;
-import java.util.TreeMap;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.client.solrj.response.UpdateResponse;
@@ -44,6 +32,18 @@ import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+import java.util.Random;
+import java.util.TreeMap;
+import java.util.concurrent.atomic.AtomicBoolean;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
+
 /**
  * Incorporate the open/close stress tests into unit tests.
  */
@@ -69,8 +69,8 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
 
   File solrHomeDirectory;
 
-  List<HttpSolrServer> indexingServers = new ArrayList<>(indexingThreads);
-  List<HttpSolrServer> queryServers = new ArrayList<>(queryThreads);
+  List<HttpSolrClient> indexingClients = new ArrayList<>(indexingThreads);
+  List<HttpSolrClient> queryingClients = new ArrayList<>(queryThreads);
 
   static String savedFactory;
   
@@ -93,14 +93,14 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
   @After
   public void tearDownServer() throws Exception {
     if (jetty != null) jetty.stop();
-    for(SolrServer server:indexingServers) {
-      server.shutdown();
+    for(SolrClient client: indexingClients) {
+      client.shutdown();
     }
-    for(SolrServer server:queryServers) {
-      server.shutdown();
+    for(SolrClient client: queryingClients) {
+      client.shutdown();
     }
-    indexingServers.clear();
-    queryServers.clear();
+    indexingClients.clear();
+    queryingClients.clear();
   }
 
   @Test
@@ -145,25 +145,25 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
   }
 
 
-  private void getServers() throws Exception {
+  private void buildClients() throws Exception {
     jetty.start();
     url = buildUrl(jetty.getLocalPort(), "/solr/");
 
     // Mostly to keep annoying logging messages from being sent out all the time.
 
     for (int idx = 0; idx < indexingThreads; ++idx) {
-      HttpSolrServer server = new HttpSolrServer(url);
-      server.setDefaultMaxConnectionsPerHost(25);
-      server.setConnectionTimeout(30000);
-      server.setSoTimeout(60000);
-      indexingServers.add(server);
+      HttpSolrClient client = new HttpSolrClient(url);
+      client.setDefaultMaxConnectionsPerHost(25);
+      client.setConnectionTimeout(30000);
+      client.setSoTimeout(60000);
+      indexingClients.add(client);
     }
     for (int idx = 0; idx < queryThreads; ++idx) {
-      HttpSolrServer server = new HttpSolrServer(url);
-      server.setDefaultMaxConnectionsPerHost(25);
-      server.setConnectionTimeout(30000);
-      server.setSoTimeout(30000);
-      queryServers.add(server);
+      HttpSolrClient client = new HttpSolrClient(url);
+      client.setDefaultMaxConnectionsPerHost(25);
+      client.setConnectionTimeout(30000);
+      client.setSoTimeout(30000);
+      queryingClients.add(client);
     }
 
   }
@@ -173,7 +173,7 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
     makeCores(solrHomeDirectory, oldStyle);
 
     //MUST start the server after the cores are made.
-    getServers();
+    buildClients();
 
     try {
 
@@ -187,9 +187,9 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
         log.info(String.format(Locale.ROOT, "\n\n\n\n\nStarting a %,d second cycle, seconds left: %,d. Seconds run so far: %,d.",
             cycleSeconds, secondsRemaining, secondsRun));
 
-        Indexer idxer = new Indexer(this, url, indexingServers, indexingThreads, cycleSeconds, random());
+        Indexer idxer = new Indexer(this, url, indexingClients, indexingThreads, cycleSeconds, random());
 
-        Queries queries = new Queries(this, url, queryServers, queryThreads, random());
+        Queries queries = new Queries(this, url, queryingClients, queryThreads, random());
 
         idxer.waitOnThreads();
 
@@ -197,12 +197,12 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
 
         secondsRemaining = Math.max(secondsRemaining - resetInterval, 0);
 
-        checkResults(queryServers.get(0), queries, idxer);
+        checkResults(queryingClients.get(0), queries, idxer);
 
         secondsRun += cycleSeconds;
 
         if (secondsRemaining > 0) {
-          deleteAllDocuments(queryServers.get(0), queries);
+          deleteAllDocuments(queryingClients.get(0), queries);
         }
       } while (secondsRemaining > 0);
 
@@ -251,14 +251,14 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
   }
 
 
-  void deleteAllDocuments(HttpSolrServer server, Queries queries) {
+  void deleteAllDocuments(HttpSolrClient client, Queries queries) {
     log.info("Deleting data from last cycle, this may take a few minutes.");
 
     for (String core : coreNames) {
       try {
-        server.setBaseURL(url + core);
-        server.deleteByQuery("*:*");
-        server.optimize(true, true); // should be close to a no-op.
+        client.setBaseURL(url + core);
+        client.deleteByQuery("*:*");
+        client.optimize(true, true); // should be close to a no-op.
       } catch (Exception e) {
         e.printStackTrace();
       }
@@ -269,7 +269,7 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
     long foundDocs = 0;
     for (String core : coreNames) {
       try {
-        long found = queries.getCount(server, core);
+        long found = queries.getCount(client, core);
         assertEquals("Cores should be empty", found, 0L);
         foundDocs += found;
       } catch (Exception e) {
@@ -287,21 +287,21 @@ public class OpenCloseCoreStressTest extends SolrTestCaseJ4 {
     }
   }
 
-  private void checkResults(HttpSolrServer server, Queries queries, Indexer idxer) throws InterruptedException {
+  private void checkResults(HttpSolrClient client, Queries queries, Indexer idxer) throws InterruptedException {
     log.info("Checking if indexes have all the documents they should...");
     long totalDocsFound = 0;
     for (Map.Entry<String, Long> ent : coreCounts.entrySet()) {
-      server.setBaseURL(url + ent.getKey());
+      client.setBaseURL(url + ent.getKey());
       for (int idx = 0; idx < 3; ++idx) {
         try {
-          server.commit(true, true);
+          client.commit(true, true);
           break; // retry loop
         } catch (Exception e) {
           log.warn("Exception when committing core " + ent.getKey() + " " + e.getMessage());
           Thread.sleep(100L);
         }
       }
-      long numFound = queries.getCount(server, ent.getKey());
+      long numFound = queries.getCount(client, ent.getKey());
       totalDocsFound += numFound;
       assertEquals(String.format(Locale.ROOT, "Core %s bad!", ent.getKey()), (long) ent.getValue(), numFound);
     }
@@ -341,14 +341,14 @@ class Indexer {
 
   ArrayList<OneIndexer> _threads = new ArrayList<>();
 
-  public Indexer(OpenCloseCoreStressTest OCCST, String url, List<HttpSolrServer> servers, int numThreads, int secondsToRun, Random random) {
+  public Indexer(OpenCloseCoreStressTest OCCST, String url, List<HttpSolrClient> clients, int numThreads, int secondsToRun, Random random) {
     stopTime = System.currentTimeMillis() + (secondsToRun * 1000);
     nextTime = System.currentTimeMillis() + 60000;
     docsThisCycle.set(0);
     qTimesAccum.set(0);
     updateCounts.set(0);
     for (int idx = 0; idx < numThreads; ++idx) {
-      OneIndexer one = new OneIndexer(OCCST, url, servers.get(idx), random.nextLong());
+      OneIndexer one = new OneIndexer(OCCST, url, clients.get(idx), random.nextLong());
       _threads.add(one);
       one.start();
     }
@@ -385,13 +385,13 @@ class Indexer {
 
 class OneIndexer extends Thread {
   private final OpenCloseCoreStressTest OCCST;
-  private final HttpSolrServer server;
+  private final HttpSolrClient client;
   private final String baseUrl;
   private final Random random;
 
-  OneIndexer(OpenCloseCoreStressTest OCCST, String url, HttpSolrServer server, long seed) {
+  OneIndexer(OpenCloseCoreStressTest OCCST, String url, HttpSolrClient client, long seed) {
     this.OCCST = OCCST;
-    this.server = server;
+    this.client = client;
     this.baseUrl = url;
     this.random = new Random(seed);
   }
@@ -414,8 +414,8 @@ class OneIndexer extends Thread {
         update.add(doc);
 
         try {
-          server.setBaseURL(baseUrl + core);
-          UpdateResponse response = server.add(doc, OpenCloseCoreStressTest.COMMIT_WITHIN);
+          client.setBaseURL(baseUrl + core);
+          UpdateResponse response = client.add(doc, OpenCloseCoreStressTest.COMMIT_WITHIN);
           if (response.getStatus() != 0) {
             SolrTestCaseJ4.log.warn("Failed to index a document to core " + core + " with status " + response.getStatus());
           } else {
@@ -451,10 +451,10 @@ class Queries {
   static AtomicInteger _errors = new AtomicInteger(0);
   String baseUrl;
 
-  public Queries(OpenCloseCoreStressTest OCCST, String url, List<HttpSolrServer> servers, int numThreads, Random random) {
+  public Queries(OpenCloseCoreStressTest OCCST, String url, List<HttpSolrClient> clients, int numThreads, Random random) {
     baseUrl = url;
     for (int idx = 0; idx < numThreads; ++idx) {
-      Thread one = new OneQuery(OCCST, url, servers.get(idx), random.nextLong());
+      Thread one = new OneQuery(OCCST, url, clients.get(idx), random.nextLong());
       _threads.add(one);
       one.start();
     }
@@ -472,14 +472,14 @@ class Queries {
     }
   }
 
-  public long getCount(HttpSolrServer server, String core) {
+  public long getCount(HttpSolrClient client, String core) {
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("qt", "/select");
     params.set("q", "*:*");
     long numFound = 0;
-    server.setBaseURL(baseUrl + core);
+    client.setBaseURL(baseUrl + core);
     try {
-      QueryResponse response = server.query(params);
+      QueryResponse response = client.query(params);
       numFound = response.getResults().getNumFound();
     } catch (Exception e) {
       e.printStackTrace();
@@ -490,13 +490,13 @@ class Queries {
 
 class OneQuery extends Thread {
   OpenCloseCoreStressTest OCCST;
-  private final HttpSolrServer server;
+  private final HttpSolrClient client;
   private final String baseUrl;
   private final Random random;
 
-  OneQuery(OpenCloseCoreStressTest OCCST, String url, HttpSolrServer server, long seed) {
+  OneQuery(OpenCloseCoreStressTest OCCST, String url, HttpSolrClient client, long seed) {
     this.OCCST = OCCST;
-    this.server = server;
+    this.client = client;
     this.baseUrl = url;
     this.random = new Random(seed);
   }
@@ -514,8 +514,8 @@ class OneQuery extends Thread {
         try {
           // sleep between 250ms and 10000 ms
           Thread.sleep(100L); // Let's not go crazy here.
-          server.setBaseURL(baseUrl + core);
-          QueryResponse response = server.query(params);
+          client.setBaseURL(baseUrl + core);
+          QueryResponse response = client.query(params);
 
           if (response.getStatus() != 0) {
             SolrTestCaseJ4.log.warn("Failed to query core " + core + " with status " + response.getStatus());
diff --git a/solr/core/src/test/org/apache/solr/core/TestDynamicLoading.java b/solr/core/src/test/org/apache/solr/core/TestDynamicLoading.java
index 00ec9b4..9c0c683 100644
--- a/solr/core/src/test/org/apache/solr/core/TestDynamicLoading.java
+++ b/solr/core/src/test/org/apache/solr/core/TestDynamicLoading.java
@@ -18,6 +18,17 @@ package org.apache.solr.core;
  */
 
 
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.handler.TestBlobHandler;
+import org.apache.solr.util.RESTfulServerProvider;
+import org.apache.solr.util.RestTestHarness;
+import org.apache.solr.util.SimplePostTool;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.charset.StandardCharsets;
@@ -28,27 +39,16 @@ import java.util.Map;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipOutputStream;
 
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.handler.TestBlobHandler;
-import org.apache.solr.util.RESTfulServerProvider;
-import org.apache.solr.util.RestTestHarness;
-import org.apache.solr.util.SimplePostTool;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
 public class TestDynamicLoading extends AbstractFullDistribZkTestBase {
   static final Logger log =  LoggerFactory.getLogger(TestDynamicLoading.class);
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
@@ -85,10 +85,10 @@ public class TestDynamicLoading extends AbstractFullDistribZkTestBase {
     assertNotNull(map = (Map) map.get("error"));
     assertEquals(".system collection not available", map.get("msg"));
 
-    HttpSolrServer server = (HttpSolrServer) clients.get(random().nextInt(clients.size()));
-    String baseURL = server.getBaseURL();
+    HttpSolrClient randomClient = (HttpSolrClient) clients.get(random().nextInt(clients.size()));
+    String baseURL = randomClient.getBaseURL();
     baseURL = baseURL.substring(0, baseURL.lastIndexOf('/'));
-    TestBlobHandler.createSysColl(new HttpSolrServer(baseURL,server.getHttpClient()));
+    TestBlobHandler.createSysColl(new HttpSolrClient(baseURL,randomClient.getHttpClient()));
     map = TestSolrConfigHandler.getRespMap("/test1?wt=json", client);
 
     assertNotNull(map = (Map) map.get("error"));
diff --git a/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java b/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
index 60744ec..43dae7c 100644
--- a/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
+++ b/solr/core/src/test/org/apache/solr/core/TestSolrConfigHandler.java
@@ -35,7 +35,7 @@ import java.util.concurrent.TimeUnit;
 import com.google.common.collect.ImmutableList;
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.handler.TestSolrConfigHandlerConcurrent;
 import org.apache.solr.util.RestTestBase;
@@ -85,7 +85,7 @@ public class TestSolrConfigHandler extends RestTestBase {
       jetty.stop();
       jetty = null;
     }
-    server = null;
+    client = null;
     restTestHarness = null;
   }
 
@@ -153,7 +153,7 @@ public class TestSolrConfigHandler extends RestTestBase {
   }
 
 
-  public static void reqhandlertests(RestTestHarness writeHarness,String testServerBaseUrl, CloudSolrServer cloudSolrServer) throws Exception {
+  public static void reqhandlertests(RestTestHarness writeHarness,String testServerBaseUrl, CloudSolrClient cloudSolrServer) throws Exception {
     String payload = "{\n" +
         "'create-requesthandler' : { 'name' : '/x', 'class': 'org.apache.solr.handler.DumpRequestHandler' , 'startup' : 'lazy'}\n" +
         "}";
@@ -204,7 +204,7 @@ public class TestSolrConfigHandler extends RestTestBase {
   public static void testForResponseElement(RestTestHarness harness,
                                             String testServerBaseUrl,
                                             String uri,
-                                            CloudSolrServer cloudSolrServer,List<String> jsonPath,
+                                            CloudSolrClient cloudSolrServer,List<String> jsonPath,
                                             String expected,
                                             long maxTimeoutSeconds ) throws Exception {
 
diff --git a/solr/core/src/test/org/apache/solr/handler/TestBlobHandler.java b/solr/core/src/test/org/apache/solr/handler/TestBlobHandler.java
index 2a3fdb5..9633242 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestBlobHandler.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestBlobHandler.java
@@ -17,14 +17,6 @@ package org.apache.solr.handler;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.nio.charset.StandardCharsets;
-import java.util.Arrays;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
-
 import org.apache.http.HttpEntity;
 import org.apache.http.HttpResponse;
 import org.apache.http.client.HttpClient;
@@ -32,10 +24,10 @@ import org.apache.http.client.methods.HttpGet;
 import org.apache.http.client.methods.HttpPost;
 import org.apache.http.entity.ByteArrayEntity;
 import org.apache.http.util.EntityUtils;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CollectionAdminRequest;
 import org.apache.solr.client.solrj.response.CollectionAdminResponse;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
@@ -48,20 +40,28 @@ import org.apache.solr.util.SimplePostTool;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.TimeUnit;
+
 import static org.apache.solr.core.ConfigOverlay.getObjectByPath;
 
 public class TestBlobHandler extends AbstractFullDistribZkTestBase {
   static final Logger log =  LoggerFactory.getLogger(TestBlobHandler.class);
 
   private void doBlobHandlerTest() throws Exception {
-    SolrServer server = createNewSolrServer("", getBaseUrl((HttpSolrServer) clients.get(0)));
+    SolrClient client = createNewSolrClient("", getBaseUrl((HttpSolrClient) clients.get(0)));
 
     CollectionAdminResponse response1;
     CollectionAdminRequest.Create createCollectionRequest = new CollectionAdminRequest.Create();
     createCollectionRequest.setCollectionName(".system");
     createCollectionRequest.setNumShards(1);
     createCollectionRequest.setReplicationFactor(2);
-    response1 = createCollectionRequest.process(server);
+    response1 = createCollectionRequest.process(client);
     assertEquals(0, response1.getStatus());
     assertTrue(response1.isSuccess());
     DocCollection sysColl = cloudClient.getZkStateReader().getClusterState().getCollection(".system");
@@ -96,13 +96,13 @@ public class TestBlobHandler extends AbstractFullDistribZkTestBase {
 
   }
 
-  public static  void createSysColl(SolrServer server) throws SolrServerException, IOException {
+  public static  void createSysColl(SolrClient client) throws SolrServerException, IOException {
     CollectionAdminResponse response1;
     CollectionAdminRequest.Create createCollectionRequest = new CollectionAdminRequest.Create();
     createCollectionRequest.setCollectionName(".system");
     createCollectionRequest.setNumShards(1);
     createCollectionRequest.setReplicationFactor(2);
-    response1 = createCollectionRequest.process(server);
+    response1 = createCollectionRequest.process(client);
     assertEquals(0, response1.getStatus());
     assertTrue(response1.isSuccess());
   }
@@ -117,7 +117,7 @@ public class TestBlobHandler extends AbstractFullDistribZkTestBase {
     DirectUpdateHandler2.commitOnClose = true;
   }
 
-  public static void postAndCheck(CloudSolrServer cloudClient, String baseUrl, ByteBuffer bytes, int count) throws Exception {
+  public static void postAndCheck(CloudSolrClient cloudClient, String baseUrl, ByteBuffer bytes, int count) throws Exception {
     postData(cloudClient, baseUrl, bytes);
     String url;
     Map map;
@@ -144,7 +144,7 @@ public class TestBlobHandler extends AbstractFullDistribZkTestBase {
 
   private void compareInputAndOutput(String url, byte[] bytarr) throws IOException {
 
-    HttpClient httpClient = cloudClient.getLbServer().getHttpClient();
+    HttpClient httpClient = cloudClient.getLbClient().getHttpClient();
 
     HttpGet httpGet = new HttpGet(url);
     HttpResponse entity = httpClient.execute(httpGet);
@@ -160,7 +160,7 @@ public class TestBlobHandler extends AbstractFullDistribZkTestBase {
 
   }
 
-  public static String postData(CloudSolrServer cloudClient, String baseUrl, ByteBuffer bytarr) throws IOException {
+  public static String postData(CloudSolrClient cloudClient, String baseUrl, ByteBuffer bytarr) throws IOException {
     HttpPost httpPost = null;
     HttpEntity entity;
     String response;
@@ -168,7 +168,7 @@ public class TestBlobHandler extends AbstractFullDistribZkTestBase {
       httpPost = new HttpPost(baseUrl+"/.system/blob/test");
       httpPost.setHeader("Content-Type","application/octet-stream");
       httpPost.setEntity(new ByteArrayEntity(bytarr.array(), bytarr.arrayOffset(), bytarr.limit()));
-      entity = cloudClient.getLbServer().getHttpClient().execute(httpPost).getEntity();
+      entity = cloudClient.getLbClient().getHttpClient().execute(httpPost).getEntity();
       return EntityUtils.toString(entity, StandardCharsets.UTF_8);
     } finally {
       httpPost.releaseConnection();
diff --git a/solr/core/src/test/org/apache/solr/handler/TestConfigReload.java b/solr/core/src/test/org/apache/solr/handler/TestConfigReload.java
index c46cbfa..7cc45a7 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestConfigReload.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestConfigReload.java
@@ -29,8 +29,8 @@ import java.util.concurrent.TimeUnit;
 import org.apache.http.HttpEntity;
 import org.apache.http.client.methods.HttpGet;
 import org.apache.http.util.EntityUtils;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.cloud.ZkController;
 import org.apache.solr.common.cloud.DocCollection;
@@ -59,11 +59,11 @@ public class TestConfigReload extends AbstractFullDistribZkTestBase {
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
@@ -128,7 +128,7 @@ public class TestConfigReload extends AbstractFullDistribZkTestBase {
     HttpGet get = new HttpGet(uri) ;
     HttpEntity entity = null;
     try {
-      entity = cloudClient.getLbServer().getHttpClient().execute(get).getEntity();
+      entity = cloudClient.getLbClient().getHttpClient().execute(get).getEntity();
       String response = EntityUtils.toString(entity, StandardCharsets.UTF_8);
       return (Map) ObjectBuilder.getVal(new JSONParser(new StringReader(response)));
     } finally {
diff --git a/solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java b/solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java
index f46fbc2..7d4548b 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestReplicationHandler.java
@@ -16,26 +16,6 @@
  */
 package org.apache.solr.handler;
 
-import java.io.BufferedReader;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.OutputStreamWriter;
-import java.io.Writer;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.nio.charset.StandardCharsets;
-import java.nio.file.Paths;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Date;
-import java.util.Set;
-import java.util.concurrent.TimeUnit;
-
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.store.FSDirectory;
 import org.apache.lucene.util.IOUtils;
@@ -44,10 +24,10 @@ import org.apache.lucene.util.TestUtil;
 import org.apache.solr.BaseDistributedSearchTestCase;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -71,6 +51,26 @@ import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.OutputStreamWriter;
+import java.io.Writer;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Paths;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.Date;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+
 /**
  * Test for ReplicationHandler
  *
@@ -87,7 +87,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       + File.separator;
 
   JettySolrRunner masterJetty, slaveJetty, repeaterJetty;
-  SolrServer masterClient, slaveClient, repeaterClient;
+  SolrClient masterClient, slaveClient, repeaterClient;
   SolrInstance master = null, slave = null, repeater = null;
 
   static String context = "/solr";
@@ -110,12 +110,12 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     master = new SolrInstance(createTempDir("solr-instance").toFile(), "master", null);
     master.setUp();
     masterJetty = createJetty(master);
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     slave = new SolrInstance(createTempDir("solr-instance").toFile(), "slave", masterJetty.getLocalPort());
     slave.setUp();
     slaveJetty = createJetty(slave);
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
   }
 
   public void clearIndexWithReplication() throws Exception {
@@ -150,22 +150,22 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return jetty;
   }
 
-  private static SolrServer createNewSolrServer(int port) {
+  private static SolrClient createNewSolrClient(int port) {
     try {
-      // setup the server...
-      HttpSolrServer s = new HttpSolrServer(buildUrl(port));
-      s.setConnectionTimeout(15000);
-      s.setSoTimeout(60000);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      // setup the client...
+      HttpSolrClient client = new HttpSolrClient(buildUrl(port));
+      client.setConnectionTimeout(15000);
+      client.setSoTimeout(60000);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     }
     catch (Exception ex) {
       throw new RuntimeException(ex);
     }
   }
 
-  int index(SolrServer s, Object... fields) throws Exception {
+  int index(SolrClient s, Object... fields) throws Exception {
     SolrInputDocument doc = new SolrInputDocument();
     for (int i = 0; i < fields.length; i += 2) {
       doc.addField((String) (fields[i]), fields[i + 1]);
@@ -173,7 +173,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return s.add(doc).getStatus();
   }
 
-  NamedList query(String query, SolrServer s) throws SolrServerException {
+  NamedList query(String query, SolrClient s) throws SolrServerException {
     NamedList res = new SimpleOrderedMap();
     ModifiableSolrParams params = new ModifiableSolrParams();
 
@@ -188,15 +188,15 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
   }
 
   /** will sleep up to 30 seconds, looking for expectedDocCount */
-  private NamedList rQuery(int expectedDocCount, String query, SolrServer server) throws Exception {
+  private NamedList rQuery(int expectedDocCount, String query, SolrClient client) throws Exception {
     int timeSlept = 0;
-    NamedList res = query(query, server);
+    NamedList res = query(query, client);
     while (expectedDocCount != numFound(res)
            && timeSlept < 30000) {
       log.info("Waiting for " + expectedDocCount + " docs");
       timeSlept += 100;
       Thread.sleep(100);
-      res = query(query, server);
+      res = query(query, client);
     }
     log.info("Waited for {}ms and found {} docs", timeSlept, numFound(res));
     return res;
@@ -206,7 +206,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return ((SolrDocumentList) res.get("response")).getNumFound();
   }
 
-  private NamedList<Object> getDetails(SolrServer s) throws Exception {
+  private NamedList<Object> getDetails(SolrClient s) throws Exception {
     
 
     ModifiableSolrParams params = new ModifiableSolrParams();
@@ -227,7 +227,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return details;
   }
   
-  private NamedList<Object> getCommits(SolrServer s) throws Exception {
+  private NamedList<Object> getCommits(SolrClient s) throws Exception {
     
 
     ModifiableSolrParams params = new ModifiableSolrParams();
@@ -244,7 +244,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return res;
   }
   
-  private NamedList<Object> getIndexVersion(SolrServer s) throws Exception {
+  private NamedList<Object> getIndexVersion(SolrClient s) throws Exception {
     
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("command","indexversion");
@@ -260,7 +260,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     return res;
   }
   
-  private NamedList<Object> reloadCore(SolrServer s, String core) throws Exception {
+  private NamedList<Object> reloadCore(SolrClient s, String core) throws Exception {
     
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action","reload");
@@ -314,12 +314,12 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     SolrInstance repeater = null;
     JettySolrRunner repeaterJetty = null;
-    SolrServer repeaterClient = null;
+    SolrClient repeaterClient = null;
     try {
       repeater = new SolrInstance(createTempDir("solr-instance").toFile(), "repeater", masterJetty.getLocalPort());
       repeater.setUp();
       repeaterJetty = createJetty(repeater);
-      repeaterClient = createNewSolrServer(repeaterJetty.getLocalPort());
+      repeaterClient = createNewSolrClient(repeaterJetty.getLocalPort());
 
       
       NamedList<Object> details = getDetails(repeaterClient);
@@ -530,7 +530,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     masterJetty = createJetty(master);
     masterClient.shutdown();
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     slave.setTestPort(masterJetty.getLocalPort());
     slave.copyConfigFile(slave.getSolrConfigFile(), "solrconfig.xml");
@@ -549,7 +549,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     //add a doc with new field and commit on master to trigger snappull from slave.
     index(masterClient, "id", "2000", "name", "name = " + 2000, "newname", "newname = " + 2000);
@@ -626,7 +626,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     slaveJetty.stop();
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     masterClient.deleteByQuery("*:*");
     slaveClient.deleteByQuery("*:*");
@@ -762,14 +762,14 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       slaveJetty.stop();
       slaveJetty = createJetty(slave);
       slaveClient.shutdown();
-      slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+      slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
       master.copyConfigFile(CONF_DIR + "solrconfig-master3.xml",
           "solrconfig.xml");
       masterJetty.stop();
       masterJetty = createJetty(master);
       masterClient.shutdown();
-      masterClient = createNewSolrServer(masterJetty.getLocalPort());
+      masterClient = createNewSolrClient(masterJetty.getLocalPort());
       
       masterClient.deleteByQuery("*:*");
       slaveClient.deleteByQuery("*:*");
@@ -884,7 +884,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     slaveJetty.stop();
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     try {
       repeater = new SolrInstance(createTempDir("solr-instance").toFile(), "repeater", null);
@@ -895,7 +895,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       if (repeaterClient != null) {
         repeaterClient.shutdown();
       }
-      repeaterClient = createNewSolrServer(repeaterJetty.getLocalPort());
+      repeaterClient = createNewSolrClient(repeaterJetty.getLocalPort());
       
       for (int i = 0; i < 3; i++)
         index(masterClient, "id", i, "name", "name = " + i);
@@ -948,7 +948,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     
   }
 
-  private void assertVersions(SolrServer client1, SolrServer client2) throws Exception {
+  private void assertVersions(SolrClient client1, SolrClient client2) throws Exception {
     NamedList<Object> details = getDetails(client1);
     ArrayList<NamedList<Object>> commits = (ArrayList<NamedList<Object>>) details.get("commits");
     Long maxVersionClient1 = getVersion(client1);
@@ -975,7 +975,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     assertEquals(maxVersionClient2, version);
   }
 
-  private Long getVersion(SolrServer client) throws Exception {
+  private Long getVersion(SolrClient client) throws Exception {
     NamedList<Object> details;
     ArrayList<NamedList<Object>> commits;
     details = getDetails(client);
@@ -1025,7 +1025,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     masterJetty = createJetty(master);
     masterClient.shutdown();
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
     
     for (int i = 0; i < nDocs; i++)
       index(masterClient, "id", i, "name", "name = " + i);
@@ -1043,7 +1043,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     //start slave
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     //get docs from slave and check if number is equal to master
     NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
@@ -1077,7 +1077,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       
       masterJetty = createJetty(master);
       masterClient.shutdown();
-      masterClient = createNewSolrServer(masterJetty.getLocalPort());
+      masterClient = createNewSolrClient(masterJetty.getLocalPort());
       
       for (int i = 0; i < nDocs; i++)
         index(masterClient, "id", i, "name", "name = " + i);
@@ -1090,7 +1090,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       masterJetty.stop();
       masterJetty.start(true);
       
-      // masterClient = createNewSolrServer(masterJetty.getLocalPort());
+      // masterClient = createNewSolrClient(masterJetty.getLocalPort());
       
       NamedList masterQueryRsp = rQuery(nDocs, "*:*", masterClient);
       SolrDocumentList masterQueryResult = (SolrDocumentList) masterQueryRsp
@@ -1103,7 +1103,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
       // start slave
       slaveJetty = createJetty(slave);
       slaveClient.shutdown();
-      slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+      slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
       
       // get docs from slave and check if number is equal to master
       NamedList slaveQueryRsp = rQuery(nDocs, "*:*", slaveClient);
@@ -1137,7 +1137,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     masterJetty = createJetty(master);
     masterClient.shutdown();
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     masterClient.deleteByQuery("*:*");
     for (int i = 0; i < docs; i++)
@@ -1155,7 +1155,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     //start slave
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
     
     //get docs from slave and check if number is equal to master
     NamedList slaveQueryRsp = rQuery(docs, "*:*", slaveClient);
@@ -1236,7 +1236,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
     masterJetty = createJetty(master);
     masterClient.shutdown();
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     slave.setTestPort(masterJetty.getLocalPort());
     slave.copyConfigFile(slave.getSolrConfigFile(), "solrconfig.xml");
@@ -1244,7 +1244,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     slaveJetty.stop();
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     slaveClient.deleteByQuery("*:*");
     slaveClient.commit();
@@ -1297,7 +1297,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     useFactory(null);
     masterJetty = createJetty(master);
     masterClient.shutdown();
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     //index docs
     final int totalDocs = TestUtil.nextInt(random(), 50, 100);
@@ -1323,14 +1323,14 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     //Start again and replicate the data
     useFactory(null);
     masterJetty = createJetty(master);
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
 
     //start slave
     slave.setTestPort(masterJetty.getLocalPort());
     slave.copyConfigFile(CONF_DIR + "solrconfig-slave1.xml", "solrconfig.xml");
     slaveJetty = createJetty(slave);
     slaveClient.shutdown();
-    slaveClient = createNewSolrServer(slaveJetty.getLocalPort());
+    slaveClient = createNewSolrClient(slaveJetty.getLocalPort());
 
     long startTime = System.nanoTime();
 
@@ -1359,9 +1359,9 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
 
   private class AddExtraDocs implements Runnable {
 
-    SolrServer masterClient;
+    SolrClient masterClient;
     int startId;
-    public AddExtraDocs(SolrServer masterClient, int startId) {
+    public AddExtraDocs(SolrClient masterClient, int startId) {
       this.masterClient = masterClient;
       this.startId = startId;
     }
@@ -1404,7 +1404,7 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
     out.close();
   }
 
-  private UpdateResponse emptyUpdate(SolrServer client, String... params) 
+  private UpdateResponse emptyUpdate(SolrClient client, String... params)
     throws SolrServerException, IOException {
 
     UpdateRequest req = new UpdateRequest();
@@ -1417,12 +1417,12 @@ public class TestReplicationHandler extends SolrTestCaseJ4 {
    * time for collection is after the specified "min".  Will loop for 
    * at most "timeout" milliseconds before throwing an assertion failure.
    * 
-   * @param client The SolrServer to poll
+   * @param client The SolrClient to poll
    * @param timeout the max milliseconds to continue polling for
    * @param min the startTime value must exceed this value before the method will return, if null this method will return the first startTime value encountered.
    * @return the startTime value of collection
    */
-  private Date watchCoreStartAt(SolrServer client, final long timeout, 
+  private Date watchCoreStartAt(SolrClient client, final long timeout,
                                 final Date min) throws InterruptedException, IOException, SolrServerException {
     final long sleepInterval = 200;
     long timeSlept = 0;
diff --git a/solr/core/src/test/org/apache/solr/handler/TestReplicationHandlerBackup.java b/solr/core/src/test/org/apache/solr/handler/TestReplicationHandlerBackup.java
index 371c9b0..963197d 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestReplicationHandlerBackup.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestReplicationHandlerBackup.java
@@ -17,15 +17,6 @@ package org.apache.solr.handler;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.FilenameFilter;
-import java.io.IOException;
-import java.io.InputStream;
-import java.net.URL;
-import java.nio.file.Path;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
 import org.apache.commons.io.IOUtils;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
@@ -37,21 +28,30 @@ import org.apache.lucene.store.SimpleFSDirectory;
 import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.util.FileUtils;
 import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 
+import java.io.File;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.URL;
+import java.nio.file.Path;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
 @SolrTestCaseJ4.SuppressSSL     // Currently unknown why SSL does not work with this test
 public class TestReplicationHandlerBackup extends SolrJettyTestBase {
 
   JettySolrRunner masterJetty;
   TestReplicationHandler.SolrInstance master = null;
-  SolrServer masterClient;
+  SolrClient masterClient;
   
   private static final String CONF_DIR = "solr"
       + File.separator + "collection1" + File.separator + "conf"
@@ -70,15 +70,15 @@ public class TestReplicationHandlerBackup extends SolrJettyTestBase {
     return jetty;
   }
 
-  private static SolrServer createNewSolrServer(int port) {
+  private static SolrClient createNewSolrClient(int port) {
     try {
-      // setup the server...
-      HttpSolrServer s = new HttpSolrServer(buildUrl(port, context));
-      s.setConnectionTimeout(15000);
-      s.setSoTimeout(60000);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      // setup the client...
+      HttpSolrClient client = new HttpSolrClient(buildUrl(port, context));
+      client.setConnectionTimeout(15000);
+      client.setSoTimeout(60000);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     }
     catch (Exception ex) {
       throw new RuntimeException(ex);
@@ -101,7 +101,7 @@ public class TestReplicationHandlerBackup extends SolrJettyTestBase {
     master.copyConfigFile(CONF_DIR + configFile, "solrconfig.xml");
 
     masterJetty = createJetty(master);
-    masterClient = createNewSolrServer(masterJetty.getLocalPort());
+    masterClient = createNewSolrClient(masterJetty.getLocalPort());
   }
 
   @Override
diff --git a/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerCloud.java b/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerCloud.java
index 2676bbc..90d9cf3 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerCloud.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerCloud.java
@@ -24,8 +24,8 @@ import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
@@ -43,11 +43,11 @@ public class TestSolrConfigHandlerCloud extends AbstractFullDistribZkTestBase {
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
diff --git a/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerConcurrent.java b/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerConcurrent.java
index a725bda..23e2f40 100644
--- a/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerConcurrent.java
+++ b/solr/core/src/test/org/apache/solr/handler/TestSolrConfigHandlerConcurrent.java
@@ -31,11 +31,10 @@ import java.util.concurrent.TimeUnit;
 import org.apache.http.HttpEntity;
 import org.apache.http.client.methods.HttpGet;
 import org.apache.http.util.EntityUtils;
-import org.apache.lucene.queryparser.xml.ParserException;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.common.cloud.DocCollection;
 import org.apache.solr.common.cloud.Replica;
@@ -51,7 +50,6 @@ import org.slf4j.LoggerFactory;
 
 import static java.util.Arrays.asList;
 import static org.apache.solr.core.ConfigOverlay.getObjectByPath;
-import static org.apache.solr.rest.schema.TestBulkSchemaAPI.getAsMap;
 import static org.noggit.ObjectBuilder.getVal;
 
 
@@ -62,11 +60,11 @@ public class TestSolrConfigHandlerConcurrent extends AbstractFullDistribZkTestBa
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
@@ -193,11 +191,11 @@ public class TestSolrConfigHandlerConcurrent extends AbstractFullDistribZkTestBa
 
   }
 
-  public static Map getAsMap(String uri, CloudSolrServer cloudClient) throws Exception {
+  public static Map getAsMap(String uri, CloudSolrClient cloudClient) throws Exception {
     HttpGet get = new HttpGet(uri) ;
     HttpEntity entity = null;
     try {
-      entity = cloudClient.getLbServer().getHttpClient().execute(get).getEntity();
+      entity = cloudClient.getLbClient().getHttpClient().execute(get).getEntity();
       String response = EntityUtils.toString(entity, StandardCharsets.UTF_8);
       try {
         return (Map) ObjectBuilder.getVal(new JSONParser(new StringReader(response)));
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java b/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java
index c6a93ab..cbc93d6 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/CoreAdminHandlerTest.java
@@ -17,14 +17,12 @@
 
 package org.apache.solr.handler.admin;
 
-import java.io.File;
-import java.util.Map;
-
+import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
 import org.apache.commons.codec.Charsets;
 import org.apache.commons.io.FileUtils;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrInputDocument;
@@ -41,7 +39,8 @@ import org.junit.Test;
 import org.junit.rules.RuleChain;
 import org.junit.rules.TestRule;
 
-import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
+import java.io.File;
+import java.util.Map;
 
 public class CoreAdminHandlerTest extends SolrTestCaseJ4 {
   
@@ -214,26 +213,26 @@ public class CoreAdminHandlerTest extends SolrTestCaseJ4 {
     File corex = new File(solrHomeDirectory, "corex");
     FileUtils.write(new File(corex, "core.properties"), "", Charsets.UTF_8.toString());
     JettySolrRunner runner = new JettySolrRunner(solrHomeDirectory.getAbsolutePath(), "/solr", 0);
-    HttpSolrServer server = null;
+    HttpSolrClient client = null;
     try {
       runner.start();
-      server = new HttpSolrServer("http://localhost:" + runner.getLocalPort() + "/solr/corex");
-      server.setConnectionTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
-      server.setSoTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
+      client = new HttpSolrClient("http://localhost:" + runner.getLocalPort() + "/solr/corex");
+      client.setConnectionTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
+      client.setSoTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
       SolrInputDocument doc = new SolrInputDocument();
       doc.addField("id", "123");
-      server.add(doc);
-      server.commit();
-      server.shutdown();
+      client.add(doc);
+      client.commit();
+      client.shutdown();
 
-      server = new HttpSolrServer("http://localhost:" + runner.getLocalPort() + "/solr");
-      server.setConnectionTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
-      server.setSoTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
+      client = new HttpSolrClient("http://localhost:" + runner.getLocalPort() + "/solr");
+      client.setConnectionTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
+      client.setSoTimeout(SolrTestCaseJ4.DEFAULT_CONNECTION_TIMEOUT);
       CoreAdminRequest.Unload req = new CoreAdminRequest.Unload(false);
       req.setDeleteInstanceDir(true);
       req.setCoreName("corex");
-      req.process(server);
-      server.shutdown();
+      req.process(client);
+      client.shutdown();
 
       runner.stop();
 
@@ -242,8 +241,8 @@ public class CoreAdminHandlerTest extends SolrTestCaseJ4 {
     } catch (Exception e) {
       log.error("Exception testing core unload with deleteInstanceDir=true", e);
     } finally {
-      if (server != null) {
-        server.shutdown();
+      if (client != null) {
+        client.shutdown();
       }
       if (!runner.isStopped())  {
         runner.stop();
diff --git a/solr/core/src/test/org/apache/solr/handler/admin/ShowFileRequestHandlerTest.java b/solr/core/src/test/org/apache/solr/handler/admin/ShowFileRequestHandlerTest.java
index 667619a..e882ba7 100644
--- a/solr/core/src/test/org/apache/solr/handler/admin/ShowFileRequestHandlerTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/admin/ShowFileRequestHandlerTest.java
@@ -17,15 +17,14 @@ package org.apache.solr.handler.admin;
  * limitations under the License.
  */
 
-import org.apache.solr.client.solrj.ResponseParser;
 import org.apache.solr.SolrJettyTestBase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.ResponseParser;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.SolrException;
-import org.apache.solr.util.ExternalPaths;
+import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrCore;
 import org.apache.solr.response.SolrQueryResponse;
 import org.junit.BeforeClass;
@@ -47,12 +46,12 @@ public class ShowFileRequestHandlerTest extends SolrJettyTestBase {
   }
 
   public void test404ViaHttp() throws SolrServerException {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     QueryRequest request = new QueryRequest(params("file",
                                                    "does-not-exist-404.txt"));
     request.setPath("/admin/file");
     try {
-      QueryResponse resp = request.process(server);
+      QueryResponse resp = request.process(client);
       fail("didn't get 404 exception");
     } catch (SolrException e) {
       assertEquals(404, e.code());
@@ -82,17 +81,17 @@ public class ShowFileRequestHandlerTest extends SolrJettyTestBase {
   }
 
   public void testDirList() throws SolrServerException {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     //assertQ(req("qt", "/admin/file")); TODO file bug that SolrJettyTestBase extends SolrTestCaseJ4
     QueryRequest request = new QueryRequest();
     request.setPath("/admin/file");
-    QueryResponse resp = request.process(server);
+    QueryResponse resp = request.process(client);
     assertEquals(0,resp.getStatus());
     assertTrue(((NamedList) resp.getResponse().get("files")).size() > 0);//some files
   }
 
   public void testGetRawFile() throws SolrServerException, IOException {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     //assertQ(req("qt", "/admin/file")); TODO file bug that SolrJettyTestBase extends SolrTestCaseJ4
     QueryRequest request = new QueryRequest(params("file","schema.xml"));
     request.setPath("/admin/file");
@@ -120,8 +119,8 @@ public class ShowFileRequestHandlerTest extends SolrJettyTestBase {
       }
     });
 
-    server.request( request );//runs request
-    //request.process(server); but we don't have a NamedList response
+    client.request(request);//runs request
+    //request.process(client); but we don't have a NamedList response
     assertTrue(readFile.get());
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
index 90f5e21..4a4b6bc 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedDebugComponentTest.java
@@ -1,22 +1,12 @@
 package org.apache.solr.handler.component;
 
-import java.io.File;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.lang.StringUtils;
 import org.apache.solr.SolrJettyTestBase;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrException;
@@ -27,6 +17,16 @@ import org.junit.AfterClass;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
+import java.io.File;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Set;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -46,8 +46,8 @@ import org.junit.Test;
 
 public class DistributedDebugComponentTest extends SolrJettyTestBase {
   
-  private static SolrServer collection1;
-  private static SolrServer collection2;
+  private static SolrClient collection1;
+  private static SolrClient collection2;
   private static String shard1;
   private static String shard2;
   private static File solrHome;
@@ -65,8 +65,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     solrHome = createSolrHome();
     createJetty(solrHome.getAbsolutePath(), null, null);
     String url = jetty.getBaseUrl().toString();
-    collection1 = new HttpSolrServer(url);
-    collection2 = new HttpSolrServer(url + "/collection2");
+    collection1 = new HttpSolrClient(url);
+    collection2 = new HttpSolrClient(url + "/collection2");
     
     String urlCollection1 = jetty.getBaseUrl().toString() + "/" + "collection1";
     String urlCollection2 = jetty.getBaseUrl().toString() + "/" + "collection2";
@@ -155,7 +155,7 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     final int NUM_ITERS = atLeast(50);
 
     for (int i = 0; i < NUM_ITERS; i++) { 
-      SolrServer client = random().nextBoolean() ? collection1 : collection2;
+      SolrClient client = random().nextBoolean() ? collection1 : collection2;
       
       SolrQuery q = new SolrQuery();
       q.set("distrib", "true");
@@ -259,10 +259,10 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     
   }
   
-  private void verifyDebugSections(SolrQuery query, SolrServer server) throws SolrServerException {
+  private void verifyDebugSections(SolrQuery query, SolrClient client) throws SolrServerException {
     query.set("debugQuery", "true");
     query.remove("debug");
-    QueryResponse response = server.query(query);
+    QueryResponse response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertInDebug(response, "track");
     assertInDebug(response, "rawquerystring");
@@ -275,7 +275,7 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     
     query.set("debug", "true");
     query.remove("debugQuery");
-    response = server.query(query);
+    response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertInDebug(response, "track");
     assertInDebug(response, "rawquerystring");
@@ -286,8 +286,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     assertInDebug(response, "explain");
     assertInDebug(response, "timing");
     
-    query.set("debug",  "track");
-    response = server.query(query);
+    query.set("debug", "track");
+    response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertInDebug(response, "track");
     assertNotInDebug(response, "rawquerystring");
@@ -298,8 +298,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     assertNotInDebug(response, "explain");
     assertNotInDebug(response, "timing");
     
-    query.set("debug",  "query");
-    response = server.query(query);
+    query.set("debug", "query");
+    response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertNotInDebug(response, "track");
     assertInDebug(response, "rawquerystring");
@@ -310,8 +310,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     assertNotInDebug(response, "explain");
     assertNotInDebug(response, "timing");
     
-    query.set("debug",  "results");
-    response = server.query(query);
+    query.set("debug", "results");
+    response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertNotInDebug(response, "track");
     assertNotInDebug(response, "rawquerystring");
@@ -322,8 +322,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     assertInDebug(response, "explain");
     assertNotInDebug(response, "timing");
     
-    query.set("debug",  "timing");
-    response = server.query(query);
+    query.set("debug", "timing");
+    response = client.query(query);
     assertFalse(response.getDebugMap().isEmpty());
     assertNotInDebug(response, "track");
     assertNotInDebug(response, "rawquerystring");
@@ -334,8 +334,8 @@ public class DistributedDebugComponentTest extends SolrJettyTestBase {
     assertNotInDebug(response, "explain");
     assertInDebug(response, "timing");
     
-    query.set("debug",  "false");
-    response = server.query(query);
+    query.set("debug", "false");
+    response = client.query(query);
     assertNull(response.getDebugMap());
   }
   
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
index eea99e2..17f0030 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLargeTest.java
@@ -22,7 +22,7 @@ import java.util.List;
 import java.io.IOException;
 
 import org.apache.solr.BaseDistributedSearchTestCase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.FieldStatsInfo;
 import org.apache.solr.client.solrj.response.PivotField;
@@ -763,10 +763,10 @@ public class DistributedFacetPivotLargeTest extends BaseDistributedSearchTestCas
     commit();
 
     final int maxDocs = 50;
-    final SolrServer zeroShard = clients.get(0);
-    final SolrServer oneShard = clients.get(1);
-    final SolrServer twoShard = clients.get(2);
-    final SolrServer threeShard = clients.get(3); // edge case: never gets any matching docs
+    final SolrClient zeroShard = clients.get(0);
+    final SolrClient oneShard = clients.get(1);
+    final SolrClient twoShard = clients.get(2);
+    final SolrClient threeShard = clients.get(3); // edge case: never gets any matching docs
 
     for(Integer i=0;i<maxDocs;i++){//50 entries
       addPivotDoc(zeroShard, "id", getDocNum(), "place_s", "cardiff", "company_t", "microsoft polecat bbc","pay_i",2400,"hiredate_dt", "2012-07-01T12:30:00Z","real_b","true");
@@ -817,10 +817,10 @@ public class DistributedFacetPivotLargeTest extends BaseDistributedSearchTestCas
   /**
    * Builds up a SolrInputDocument using the specified fields, then adds it to the 
    * specified client as well as the control client 
-   * @see #indexDoc(SolrServer,SolrParams,SolrInputDocument...)
+   * @see #indexDoc(org.apache.solr.client.solrj.SolrClient,SolrParams,SolrInputDocument...)
    * @see #sdoc
    */
-  private void addPivotDoc(SolrServer client, Object... fields) 
+  private void addPivotDoc(SolrClient client, Object... fields)
     throws IOException, SolrServerException {
 
     indexDoc(client, params(), sdoc(fields));
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLongTailTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLongTailTest.java
index 54cb064..d675d8e 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLongTailTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotLongTailTest.java
@@ -17,16 +17,10 @@ package org.apache.solr.handler.component;
  * limitations under the License.
  */
 
-import java.util.Date;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
 import java.util.List;
-import java.io.IOException;
 
 import org.apache.solr.BaseDistributedSearchTestCase;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.response.FieldStatsInfo;
 import org.apache.solr.client.solrj.response.PivotField;
 import org.apache.solr.common.params.FacetParams;
@@ -60,9 +54,9 @@ public class DistributedFacetPivotLongTailTest extends BaseDistributedSearchTest
   @Override
   public void doTest() throws Exception {
 
-    final SolrServer shard0 = clients.get(0);
-    final SolrServer shard1 = clients.get(1);
-    final SolrServer shard2 = clients.get(2);
+    final SolrClient shard0 = clients.get(0);
+    final SolrClient shard1 = clients.get(1);
+    final SolrClient shard2 = clients.get(2);
     
     // the 5 top foo_s terms have 100 docs each on every shard
     for (int i = 0; i < 100; i++) {
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotSmallAdvancedTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotSmallAdvancedTest.java
index 6ee1e4e..e269dea 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotSmallAdvancedTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedFacetPivotSmallAdvancedTest.java
@@ -18,8 +18,7 @@ package org.apache.solr.handler.component;
  */
 
 import org.apache.solr.BaseDistributedSearchTestCase;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.response.FieldStatsInfo;
 import org.apache.solr.client.solrj.response.PivotField;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -27,9 +26,6 @@ import org.apache.solr.common.params.FacetParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.SolrParams;
 
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.Comparator;
 import java.util.List;
 
 /**
@@ -50,8 +46,8 @@ public class DistributedFacetPivotSmallAdvancedTest extends BaseDistributedSearc
   public void doTest() throws Exception {
 
     del("*:*");
-    final SolrServer shard0 = clients.get(0);
-    final SolrServer shard1 = clients.get(1);
+    final SolrClient shard0 = clients.get(0);
+    final SolrClient shard1 = clients.get(1);
 
     // NOTE: we use the literal (4 character) string "null" as a company name
     // to help ensure there isn't any bugs where the literal string is treated as if it 
diff --git a/solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java b/solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java
index cf16d3d..fedc945 100644
--- a/solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java
+++ b/solr/core/src/test/org/apache/solr/handler/component/DistributedSpellCheckComponentTest.java
@@ -26,7 +26,7 @@ import junit.framework.Assert;
 import org.apache.lucene.util.LuceneTestCase.Slow;
 import org.apache.lucene.util.LuceneTestCase.SuppressTempFileChecks;
 import org.apache.solr.BaseDistributedSearchTestCase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.SpellingParams;
@@ -79,7 +79,7 @@ public class DistributedSpellCheckComponentTest extends BaseDistributedSearchTes
     // query a random server
     params.set("shards", shards);
     int which = r.nextInt(clients.size());
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     client.query(params);
   }
   
diff --git a/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java b/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
index 2c2a754..a276afc 100644
--- a/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
+++ b/solr/core/src/test/org/apache/solr/request/TestRemoteStreaming.java
@@ -19,13 +19,12 @@ package org.apache.solr.request;
 
 import org.apache.commons.io.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrException;
@@ -69,11 +68,11 @@ public class TestRemoteStreaming extends SolrJettyTestBase {
   @Before
   public void doBefore() throws IOException, SolrServerException {
     //add document and commit, and ensure it's there
-    SolrServer server1 = getSolrServer();
+    SolrClient client = getSolrClient();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField( "id", "1234" );
-    server1.add(doc);
-    server1.commit();
+    client.add(doc);
+    client.commit();
     assertTrue(searchFindsIt());
   }
 
@@ -85,10 +84,10 @@ public class TestRemoteStreaming extends SolrJettyTestBase {
 
   @Test
   public void testStreamUrl() throws Exception {
-    HttpSolrServer solrServer = (HttpSolrServer) getSolrServer();
-    String streamUrl = solrServer.getBaseURL()+"/select?q=*:*&fl=id&wt=csv";
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    String streamUrl = client.getBaseURL()+"/select?q=*:*&fl=id&wt=csv";
 
-    String getUrl = solrServer.getBaseURL()+"/debug/dump?wt=xml&stream.url="+URLEncoder.encode(streamUrl,"UTF-8");
+    String getUrl = client.getBaseURL()+"/debug/dump?wt=xml&stream.url="+URLEncoder.encode(streamUrl,"UTF-8");
     String content = getUrlForString(getUrl);
     assertTrue(content.contains("1234"));
     //System.out.println(content);
@@ -116,7 +115,7 @@ public class TestRemoteStreaming extends SolrJettyTestBase {
     query.setQuery( "*:*" );//for anything
     query.add("stream.url",makeDeleteAllUrl());
     try {
-      getSolrServer().query(query);
+      getSolrClient().query(query);
       fail();
     } catch (SolrException se) {
       assertSame(ErrorCode.BAD_REQUEST, ErrorCode.getErrorCode(se.code()));
@@ -140,7 +139,7 @@ public class TestRemoteStreaming extends SolrJettyTestBase {
         return "/select";
       }
     };
-    QueryResponse rsp = queryRequest.process(getSolrServer());
+    QueryResponse rsp = queryRequest.process(getSolrClient());
     //!! should *fail* above for security purposes
     String handler = (String) rsp.getHeader().get("handler");
     System.out.println(handler);
@@ -148,15 +147,15 @@ public class TestRemoteStreaming extends SolrJettyTestBase {
 
   /** Compose a url that if you get it, it will delete all the data. */
   private String makeDeleteAllUrl() throws UnsupportedEncodingException {
-    HttpSolrServer solrServer = (HttpSolrServer) getSolrServer();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
     String deleteQuery = "<delete><query>*:*</query></delete>";
-    return solrServer.getBaseURL()+"/update?commit=true&stream.body="+ URLEncoder.encode(deleteQuery, "UTF-8");
+    return client.getBaseURL()+"/update?commit=true&stream.body="+ URLEncoder.encode(deleteQuery, "UTF-8");
   }
 
   private boolean searchFindsIt() throws SolrServerException {
     SolrQuery query = new SolrQuery();
     query.setQuery( "id:1234" );
-    QueryResponse rsp = getSolrServer().query(query);
+    QueryResponse rsp = getSolrClient().query(query);
     return rsp.getResults().getNumFound() != 0;
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java b/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
index c77ae85..3c69feb 100644
--- a/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
+++ b/solr/core/src/test/org/apache/solr/rest/schema/TestBulkSchemaAPI.java
@@ -72,7 +72,7 @@ public class TestBulkSchemaAPI extends RestTestBase {
       jetty.stop();
       jetty = null;
     }
-    server = null;
+    client = null;
     restTestHarness = null;
   }
 
diff --git a/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaDynamicFieldResource.java b/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaDynamicFieldResource.java
index 05c9c9e..60a72bf 100644
--- a/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaDynamicFieldResource.java
+++ b/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaDynamicFieldResource.java
@@ -62,7 +62,7 @@ public class TestManagedSchemaDynamicFieldResource extends RestTestBase {
       jetty.stop();
       jetty = null;
     }
-    server = null;
+    client = null;
     restTestHarness = null;
   }
 
diff --git a/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaFieldResource.java b/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaFieldResource.java
index d146187..4fa6953 100644
--- a/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaFieldResource.java
+++ b/solr/core/src/test/org/apache/solr/rest/schema/TestManagedSchemaFieldResource.java
@@ -62,7 +62,7 @@ public class TestManagedSchemaFieldResource extends RestTestBase {
       jetty.stop();
       jetty = null;
     }
-    server = null;
+    client = null;
     restTestHarness = null;
   }
   
diff --git a/solr/core/src/test/org/apache/solr/schema/TestBinaryField.java b/solr/core/src/test/org/apache/solr/schema/TestBinaryField.java
index f117535..8924c3d 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestBinaryField.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestBinaryField.java
@@ -16,21 +16,22 @@
  */
 package org.apache.solr.schema;
 
-import java.io.File;
-import java.nio.ByteBuffer;
-import java.util.List;
-
 import org.apache.commons.io.FileUtils;
-
+import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.beans.Field;
 import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.*;
-import org.apache.solr.SolrJettyTestBase;
+import org.apache.solr.common.SolrDocument;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
 import org.junit.BeforeClass;
 
+import java.io.File;
+import java.nio.ByteBuffer;
+import java.util.List;
+
 public class TestBinaryField extends SolrJettyTestBase {
 
   @BeforeClass
@@ -61,7 +62,7 @@ public class TestBinaryField extends SolrJettyTestBase {
 
 
   public void testSimple() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     byte[] buf = new byte[10];
     for (int i = 0; i < 10; i++) {
       buf[i] = (byte) i;
@@ -70,21 +71,21 @@ public class TestBinaryField extends SolrJettyTestBase {
     doc = new SolrInputDocument();
     doc.addField("id", 1);
     doc.addField("data", ByteBuffer.wrap(buf, 2, 5));
-    server.add(doc);
+    client.add(doc);
 
     doc = new SolrInputDocument();
     doc.addField("id", 2);
     doc.addField("data", ByteBuffer.wrap(buf, 4, 3));
-    server.add(doc);
+    client.add(doc);
 
     doc = new SolrInputDocument();
     doc.addField("id", 3);
     doc.addField("data", buf);
-    server.add(doc);
+    client.add(doc);
 
-    server.commit();
+    client.commit();
 
-    QueryResponse resp = server.query(new SolrQuery("*:*"));
+    QueryResponse resp = client.query(new SolrQuery("*:*"));
     SolrDocumentList res = resp.getResults();
     List<Bean> beans = resp.getBeans(Bean.class);
     assertEquals(3, res.size());
diff --git a/solr/core/src/test/org/apache/solr/schema/TestBulkSchemaConcurrent.java b/solr/core/src/test/org/apache/solr/schema/TestBulkSchemaConcurrent.java
index 2506b8e..b1c8fec 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestBulkSchemaConcurrent.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestBulkSchemaConcurrent.java
@@ -19,8 +19,8 @@ package org.apache.solr.schema;
 
 
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.common.cloud.ZkStateReader;
 import org.apache.solr.util.RESTfulServerProvider;
@@ -60,11 +60,11 @@ public class TestBulkSchemaConcurrent  extends AbstractFullDistribZkTestBase {
   }
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
diff --git a/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchema.java b/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchema.java
index 15422d1..3af0813 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchema.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchema.java
@@ -17,10 +17,9 @@ package org.apache.solr.schema;
  */
 
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
-import org.apache.solr.common.SolrException;
 import org.apache.solr.common.cloud.SolrZkClient;
 import org.apache.solr.common.params.CoreAdminParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -56,7 +55,7 @@ public class TestCloudManagedSchema extends AbstractFullDistribZkTestBase {
     QueryRequest request = new QueryRequest(params);
     request.setPath("/admin/cores");
     int which = r.nextInt(clients.size());
-    HttpSolrServer client = (HttpSolrServer)clients.get(which);
+    HttpSolrClient client = (HttpSolrClient)clients.get(which);
     String previousBaseURL = client.getBaseURL();
     // Strip /collection1 step from baseURL - requests fail otherwise
     client.setBaseURL(previousBaseURL.substring(0, previousBaseURL.lastIndexOf("/")));
diff --git a/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchemaConcurrent.java b/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchemaConcurrent.java
index 50e365a..d675161 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchemaConcurrent.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestCloudManagedSchemaConcurrent.java
@@ -16,9 +16,9 @@ package org.apache.solr.schema;
  * limitations under the License.
  */
 
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.common.cloud.ClusterState;
 import org.apache.solr.common.cloud.Replica;
@@ -85,11 +85,11 @@ public class TestCloudManagedSchemaConcurrent extends AbstractFullDistribZkTestB
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
   
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
diff --git a/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java b/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java
index 1d2e4ae..aac3b2f 100644
--- a/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java
+++ b/solr/core/src/test/org/apache/solr/schema/TestCloudSchemaless.java
@@ -17,8 +17,8 @@ package org.apache.solr.schema;
  */
 
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
@@ -90,11 +90,11 @@ public class TestCloudSchemaless extends AbstractFullDistribZkTestBase {
   private List<RestTestHarness> restTestHarnesses = new ArrayList<>();
 
   private void setupHarnesses() {
-    for (final SolrServer client : clients) {
+    for (final SolrClient client : clients) {
       RestTestHarness harness = new RestTestHarness(new RESTfulServerProvider() {
         @Override
         public String getBaseURL() {
-          return ((HttpSolrServer)client).getBaseURL();
+          return ((HttpSolrClient)client).getBaseURL();
         }
       });
       restTestHarnesses.add(harness);
@@ -120,12 +120,12 @@ public class TestCloudSchemaless extends AbstractFullDistribZkTestBase {
     // First, add a bunch of documents in a single update with the same new field.
     // This tests that the replicas properly handle schema additions.
 
-    int slices =  getCommonCloudSolrServer().getZkStateReader().getClusterState()
+    int slices =  getCommonCloudSolrClient().getZkStateReader().getClusterState()
       .getActiveSlices("collection1").size();
     int trials = 50;
     // generate enough docs so that we can expect at least a doc per slice
     int numDocsPerTrial = (int)(slices * (Math.log(slices) + 1));
-    SolrServer ss = clients.get(random().nextInt(clients.size()));
+    SolrClient randomClient = clients.get(random().nextInt(clients.size()));
     int docNumber = 0;
     for (int i = 0; i < trials; ++i) {
       List<SolrInputDocument> docs = new ArrayList<>();
@@ -137,9 +137,9 @@ public class TestCloudSchemaless extends AbstractFullDistribZkTestBase {
         docs.add(doc);
       }
 
-      ss.add(docs);
+      randomClient.add(docs);
     }
-    ss.commit();
+    randomClient.commit();
 
     String [] expectedFields = getExpectedFieldResponses(docNumber);
     // Check that all the fields were added
@@ -175,8 +175,8 @@ public class TestCloudSchemaless extends AbstractFullDistribZkTestBase {
       }
 
       try {
-        ss.add(docs);
-        ss.commit();
+        randomClient.add(docs);
+        randomClient.commit();
         fail("Expected Bad Request Exception");
       } catch (SolrException se) {
         assertEquals(ErrorCode.BAD_REQUEST, ErrorCode.getErrorCode(se.code()));
diff --git a/solr/core/src/test/org/apache/solr/search/TestSolrJ.java b/solr/core/src/test/org/apache/solr/search/TestSolrJ.java
index 1940c8f..4aca50f 100644
--- a/solr/core/src/test/org/apache/solr/search/TestSolrJ.java
+++ b/solr/core/src/test/org/apache/solr/search/TestSolrJ.java
@@ -19,10 +19,10 @@ package org.apache.solr.search;
 
 
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.common.SolrInputDocument;
 
 import java.io.IOException;
@@ -41,7 +41,7 @@ public class TestSolrJ extends SolrTestCaseJ4 {
     // doCommitPerf();
   }
 
-  public static SolrServer server;
+  public static SolrClient client;
   public static String idField = "id";
   public static Exception ex;
 
@@ -56,13 +56,13 @@ public class TestSolrJ extends SolrTestCaseJ4 {
     final int nConnections = Integer.parseInt(args[i++]);
     final int maxSleep = Integer.parseInt(args[i++]);
 
-    ConcurrentUpdateSolrServer sserver = null;
+    ConcurrentUpdateSolrClient concurrentClient = null;
 
-    // server = sserver = new ConcurrentUpdateSolrServer(addr,32,8);
-    server = sserver = new ConcurrentUpdateSolrServer(addr,64,nConnections);
+    // server = concurrentClient = new ConcurrentUpdateSolrServer(addr,32,8);
+    client = concurrentClient = new ConcurrentUpdateSolrClient(addr,64,nConnections);
 
-    server.deleteByQuery("*:*");
-    server.commit();
+    client.deleteByQuery("*:*");
+    client.commit();
 
     long start = System.currentTimeMillis();
 
@@ -94,8 +94,8 @@ public class TestSolrJ extends SolrTestCaseJ4 {
       threads[threadNum].join();
     }
 
-    if (sserver != null) {
-      sserver.blockUntilFinished();
+    if (concurrentClient != null) {
+      concurrentClient.blockUntilFinished();
     }
 
     long end = System.currentTimeMillis();
@@ -145,7 +145,7 @@ public class TestSolrJ extends SolrTestCaseJ4 {
       }
 
       SolrInputDocument doc = getDocument(i);
-      server.add(doc);
+      client.add(doc);
 
       if (maxSleep > 0) {
         int sleep = r.nextInt(maxSleep);
@@ -163,7 +163,7 @@ public class TestSolrJ extends SolrTestCaseJ4 {
 
 
   public void doCommitPerf() throws Exception {
-    HttpSolrServer client = new HttpSolrServer("http://127.0.0.1:8983/solr");
+    HttpSolrClient client = new HttpSolrClient("http://127.0.0.1:8983/solr");
 
     long start = System.currentTimeMillis();
 
diff --git a/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java b/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java
index f50fca6..74ba1a1 100644
--- a/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java
+++ b/solr/core/src/test/org/apache/solr/search/stats/TestDefaultStatsCache.java
@@ -18,7 +18,7 @@ package org.apache.solr.search.stats;
  */
 
 import org.apache.solr.BaseDistributedSearchTestCase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocumentList;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -97,7 +97,7 @@ public class TestDefaultStatsCache extends BaseDistributedSearchTestCase {
     // query a random server
     params.set("shards", shards);
     int which = r.nextInt(clients.size());
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     QueryResponse rsp = client.query(params);
     checkResponse(controlRsp, rsp);
   }
diff --git a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTestBase.java b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTestBase.java
index 3d23e27..09b8020 100644
--- a/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTestBase.java
+++ b/solr/core/src/test/org/apache/solr/servlet/CacheHeaderTestBase.java
@@ -16,11 +16,6 @@
  */
 package org.apache.solr.servlet;
 
-import java.net.URI;
-import java.net.URISyntaxException;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-
 import org.apache.http.HttpResponse;
 import org.apache.http.client.HttpClient;
 import org.apache.http.client.methods.HttpGet;
@@ -31,13 +26,18 @@ import org.apache.http.client.utils.URLEncodedUtils;
 import org.apache.http.message.BasicNameValuePair;
 import org.apache.http.util.EntityUtils;
 import org.apache.solr.SolrJettyTestBase;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.junit.Test;
 
+import java.net.URI;
+import java.net.URISyntaxException;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+
 public abstract class CacheHeaderTestBase extends SolrJettyTestBase {
 
   protected HttpRequestBase getSelectMethod(String method, String... params) throws URISyntaxException {
-    HttpSolrServer httpserver = (HttpSolrServer)getSolrServer();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
     HttpRequestBase m = null;
     
     ArrayList<BasicNameValuePair> qparams = new ArrayList<>();
@@ -49,7 +49,7 @@ public abstract class CacheHeaderTestBase extends SolrJettyTestBase {
       qparams.add(new BasicNameValuePair(params[i * 2], params[i * 2 + 1]));
     }
 
-    URI uri = URI.create(httpserver.getBaseURL() + "/select?" +
+    URI uri = URI.create(client.getBaseURL() + "/select?" +
                          URLEncodedUtils.format(qparams, StandardCharsets.UTF_8));
    
     if ("GET".equals(method)) {
@@ -64,7 +64,7 @@ public abstract class CacheHeaderTestBase extends SolrJettyTestBase {
   }
 
   protected HttpRequestBase getUpdateMethod(String method, String... params) throws URISyntaxException {
-    HttpSolrServer httpserver = (HttpSolrServer)getSolrServer();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
     HttpRequestBase m = null;
     
     ArrayList<BasicNameValuePair> qparams = new ArrayList<>();
@@ -72,7 +72,7 @@ public abstract class CacheHeaderTestBase extends SolrJettyTestBase {
       qparams.add(new BasicNameValuePair(params[i*2], params[i*2+1]));
     }
 
-    URI uri = URI.create(httpserver.getBaseURL() + "/update?" + 
+    URI uri = URI.create(client.getBaseURL() + "/update?" +
                          URLEncodedUtils.format(qparams, StandardCharsets.UTF_8));
     
     if ("GET".equals(method)) {
@@ -87,8 +87,8 @@ public abstract class CacheHeaderTestBase extends SolrJettyTestBase {
   }
   
   protected HttpClient getClient() {
-    HttpSolrServer httpserver = (HttpSolrServer)getSolrServer();
-    return httpserver.getHttpClient();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    return client.getHttpClient();
   }
 
   protected void checkResponseBody(String method, HttpResponse resp)
diff --git a/solr/core/src/test/org/apache/solr/servlet/ResponseHeaderTest.java b/solr/core/src/test/org/apache/solr/servlet/ResponseHeaderTest.java
index e64eae7..82d996f 100644
--- a/solr/core/src/test/org/apache/solr/servlet/ResponseHeaderTest.java
+++ b/solr/core/src/test/org/apache/solr/servlet/ResponseHeaderTest.java
@@ -32,7 +32,7 @@ import org.apache.http.client.methods.HttpGet;
 import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.handler.component.ResponseBuilder;
 import org.apache.solr.handler.component.SearchComponent;
 import org.apache.solr.response.SolrQueryResponse;
@@ -61,7 +61,7 @@ public class ResponseHeaderTest extends SolrJettyTestBase {
   
   @Test
   public void testHttpResponse() throws SolrServerException, IOException {
-    HttpSolrServer client = (HttpSolrServer)getSolrServer();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
     HttpClient httpClient = client.getHttpClient();
     URI uri = URI.create(client.getBaseURL() + "/withHeaders?q=*:*");
     HttpGet httpGet = new HttpGet(uri);
diff --git a/solr/core/src/test/org/apache/solr/update/MockStreamingSolrClients.java b/solr/core/src/test/org/apache/solr/update/MockStreamingSolrClients.java
new file mode 100644
index 0000000..264b7c2
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/update/MockStreamingSolrClients.java
@@ -0,0 +1,93 @@
+package org.apache.solr.update;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.common.util.NamedList;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.net.ConnectException;
+import java.net.SocketException;
+
+public class MockStreamingSolrClients extends StreamingSolrClients {
+  public static Logger log = LoggerFactory
+      .getLogger(MockStreamingSolrClients.class);
+  
+  public enum Exp {CONNECT_EXCEPTION, SOCKET_EXCEPTION};
+  
+  private volatile Exp exp = null;
+  
+  public MockStreamingSolrClients(UpdateShardHandler updateShardHandler) {
+    super(updateShardHandler);
+  }
+  
+  @Override
+  public synchronized SolrClient getSolrClient(final SolrCmdDistributor.Req req) {
+    SolrClient client = super.getSolrClient(req);
+    return new MockSolrClient(client);
+  }
+  
+  public void setExp(Exp exp) {
+    this.exp = exp;
+  }
+
+  private IOException exception() {
+    switch (exp) {
+      case CONNECT_EXCEPTION:
+        return new ConnectException();
+      case SOCKET_EXCEPTION:
+        return new SocketException();
+      default:
+        break;
+    }
+    return null;
+  }
+
+  class MockSolrClient extends SolrClient {
+
+    private SolrClient solrClient;
+
+    public MockSolrClient(SolrClient solrClient) {
+      this.solrClient = solrClient;
+    }
+    
+    @Override
+    public NamedList<Object> request(SolrRequest request)
+        throws SolrServerException, IOException {
+      if (exp != null) {
+        if (LuceneTestCase.random().nextBoolean()) {
+          throw exception();
+        } else {
+          throw new SolrServerException(exception());
+        }
+      }
+      
+      return solrClient.request(request);
+    }
+
+
+    @Override
+    public void shutdown() {}
+    
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/update/MockStreamingSolrServers.java b/solr/core/src/test/org/apache/solr/update/MockStreamingSolrServers.java
deleted file mode 100644
index 39d262f..0000000
--- a/solr/core/src/test/org/apache/solr/update/MockStreamingSolrServers.java
+++ /dev/null
@@ -1,93 +0,0 @@
-package org.apache.solr.update;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.net.ConnectException;
-import java.net.SocketException;
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.common.util.NamedList;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class MockStreamingSolrServers extends StreamingSolrServers {
-  public static Logger log = LoggerFactory
-      .getLogger(MockStreamingSolrServers.class);
-  
-  public enum Exp {CONNECT_EXCEPTION, SOCKET_EXCEPTION};
-  
-  private volatile Exp exp = null;
-  
-  public MockStreamingSolrServers(UpdateShardHandler updateShardHandler) {
-    super(updateShardHandler);
-  }
-  
-  @Override
-  public synchronized SolrServer getSolrServer(final SolrCmdDistributor.Req req) {
-    SolrServer server = super.getSolrServer(req);
-    return new MockSolrServer(server);
-  }
-  
-  public void setExp(Exp exp) {
-    this.exp = exp;
-  }
-
-  private IOException exception() {
-    switch (exp) {
-      case CONNECT_EXCEPTION:
-        return new ConnectException();
-      case SOCKET_EXCEPTION:
-        return new SocketException();
-      default:
-        break;
-    }
-    return null;
-  }
-
-  class MockSolrServer extends SolrServer {
-
-    private SolrServer solrServer;
-
-    public MockSolrServer(SolrServer solrServer) {
-      this.solrServer = solrServer;
-    }
-    
-    @Override
-    public NamedList<Object> request(SolrRequest request)
-        throws SolrServerException, IOException {
-      if (exp != null) {
-        if (LuceneTestCase.random().nextBoolean()) {
-          throw exception();
-        } else {
-          throw new SolrServerException(exception());
-        }
-      }
-      
-      return solrServer.request(request);
-    }
-
-
-    @Override
-    public void shutdown() {}
-    
-  }
-}
diff --git a/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java b/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
index 4d2ebfd..17c9b47 100644
--- a/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
+++ b/solr/core/src/test/org/apache/solr/update/PeerSyncTest.java
@@ -17,20 +17,20 @@ package org.apache.solr.update;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.util.Arrays;
-
 import org.apache.solr.BaseDistributedSearchTestCase;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.common.util.StrUtils;
 
-import static org.apache.solr.update.processor.DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM;
+import java.io.IOException;
+import java.util.Arrays;
+
 import static org.apache.solr.update.processor.DistributedUpdateProcessor.DistribPhase;
+import static org.apache.solr.update.processor.DistributingUpdateProcessorFactory.DISTRIB_UPDATE_PARAM;
 
 @SuppressSSL(bugUrl = "https://issues.apache.org/jira/browse/SOLR-5776")
 public class PeerSyncTest extends BaseDistributedSearchTestCase {
@@ -58,9 +58,9 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
     handle.put("score", SKIPVAL);
     handle.put("maxScore", SKIPVAL);
 
-    SolrServer client0 = clients.get(0);
-    SolrServer client1 = clients.get(1);
-    SolrServer client2 = clients.get(2);
+    SolrClient client0 = clients.get(0);
+    SolrClient client1 = clients.get(1);
+    SolrClient client2 = clients.get(2);
 
     long v = 0;
     add(client0, seenLeader, sdoc("id","1","_version_",++v));
@@ -128,7 +128,7 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
 
     // test that delete by query is returned even if not requested, and that it doesn't delete newer stuff than it should
     v=2000;
-    SolrServer client = client0;
+    SolrClient client = client0;
     add(client, seenLeader, sdoc("id","2000","_version_",++v));
     add(client, seenLeader, sdoc("id","2001","_version_",++v));
     delQ(client, params(DISTRIB_UPDATE_PARAM,FROM_LEADER,"_version_",Long.toString(-++v)), "id:2001 OR id:2002");
@@ -173,9 +173,9 @@ public class PeerSyncTest extends BaseDistributedSearchTestCase {
   }
 
 
-  void assertSync(SolrServer server, int numVersions, boolean expectedResult, String... syncWith) throws IOException, SolrServerException {
+  void assertSync(SolrClient client, int numVersions, boolean expectedResult, String... syncWith) throws IOException, SolrServerException {
     QueryRequest qr = new QueryRequest(params("qt","/get", "getVersions",Integer.toString(numVersions), "sync", StrUtils.join(Arrays.asList(syncWith), ',')));
-    NamedList rsp = server.request(qr);
+    NamedList rsp = client.request(qr);
     assertEquals(expectedResult, (Boolean) rsp.get("sync"));
   }
 
diff --git a/solr/core/src/test/org/apache/solr/update/SolrCmdDistributorTest.java b/solr/core/src/test/org/apache/solr/update/SolrCmdDistributorTest.java
index cd3f4b1..6b18632 100644
--- a/solr/core/src/test/org/apache/solr/update/SolrCmdDistributorTest.java
+++ b/solr/core/src/test/org/apache/solr/update/SolrCmdDistributorTest.java
@@ -20,10 +20,10 @@ package org.apache.solr.update;
 import org.apache.lucene.index.LogDocMergePolicy;
 import org.apache.solr.BaseDistributedSearchTestCase;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.LukeRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrDocumentList;
@@ -40,7 +40,7 @@ import org.apache.solr.core.SolrCore;
 import org.apache.solr.core.SolrEventListener;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.servlet.SolrDispatchFilter;
-import org.apache.solr.update.MockStreamingSolrServers.Exp;
+import org.apache.solr.update.MockStreamingSolrClients.Exp;
 import org.apache.solr.update.SolrCmdDistributor.Error;
 import org.apache.solr.update.SolrCmdDistributor.Node;
 import org.apache.solr.update.SolrCmdDistributor.RetryNode;
@@ -107,7 +107,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
   protected void createServers(int numShards) throws Exception {
     controlJetty = createJetty(new File(getSolrHome()), testDir + "/control/data", null, getSolrConfigFile(), getSchemaFile());
 
-    controlClient = createNewSolrServer(controlJetty.getLocalPort());
+    controlClient = createNewSolrClient(controlJetty.getLocalPort());
 
     shardsArr = new String[numShards];
     StringBuilder sb = new StringBuilder();
@@ -117,7 +117,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
           testDir + "/shard" + i + "/data", null, getSolrConfigFile(),
           getSchemaFile());
       jettys.add(j);
-      clients.add(createNewSolrServer(j.getLocalPort()));
+      clients.add(createNewSolrClient(j.getLocalPort()));
       String shardStr = buildUrl(j.getLocalPort());
       shardsArr[i] = shardStr;
       sb.append(shardStr);
@@ -137,7 +137,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
     List<Node> nodes = new ArrayList<>();
 
     ZkNodeProps nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP,
-        ((HttpSolrServer) controlClient).getBaseURL(),
+        ((HttpSolrClient) controlClient).getBaseURL(),
         ZkStateReader.CORE_NAME_PROP, "");
     nodes.add(new StdNode(new ZkCoreNodeProps(nodeProps)));
 
@@ -164,7 +164,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
         .getNumFound();
     assertEquals(1, numFound);
     
-    HttpSolrServer client = (HttpSolrServer) clients.get(0);
+    HttpSolrClient client = (HttpSolrClient) clients.get(0);
     nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP,
         client.getBaseURL(), ZkStateReader.CORE_NAME_PROP, "");
     nodes.add(new StdNode(new ZkCoreNodeProps(nodeProps)));
@@ -239,7 +239,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
         .getNumFound();
     assertEquals(results.toString(), 2, numFound);
     
-    for (SolrServer c : clients) {
+    for (SolrClient c : clients) {
       c.optimize();
       //System.out.println(clients.get(0).request(new LukeRequest()));
     }
@@ -249,11 +249,11 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
     int cnt = atLeast(303);
     for (int i = 0; i < cnt; i++) {
       nodes.clear();
-      for (SolrServer c : clients) {
+      for (SolrClient c : clients) {
         if (random().nextBoolean()) {
           continue;
         }
-        HttpSolrServer httpClient = (HttpSolrServer) c;
+        HttpSolrClient httpClient = (HttpSolrClient) c;
         nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP,
             httpClient.getBaseURL(), ZkStateReader.CORE_NAME_PROP, "");
         nodes.add(new StdNode(new ZkCoreNodeProps(nodeProps)));
@@ -269,8 +269,8 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
     
     nodes.clear();
     
-    for (SolrServer c : clients) {
-      HttpSolrServer httpClient = (HttpSolrServer) c;
+    for (SolrClient c : clients) {
+      HttpSolrClient httpClient = (HttpSolrClient) c;
       nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP,
           httpClient.getBaseURL(), ZkStateReader.CORE_NAME_PROP, "");
       
@@ -311,7 +311,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
 
     assertEquals(shardCount, commits.get());
     
-    for (SolrServer c : clients) {
+    for (SolrClient c : clients) {
       NamedList<Object> resp = c.request(new LukeRequest());
       assertEquals("SOLR-3428: We only did adds - there should be no deletes",
           ((NamedList<Object>) resp.get("index")).get("numDocs"),
@@ -328,11 +328,11 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
   }
 
   private void testMaxRetries() throws IOException {
-    final MockStreamingSolrServers ss = new MockStreamingSolrServers(updateShardHandler);
-    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(ss, 5, 0);
-    ss.setExp(Exp.CONNECT_EXCEPTION);
+    final MockStreamingSolrClients streamingClients = new MockStreamingSolrClients(updateShardHandler);
+    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(streamingClients, 5, 0);
+    streamingClients.setExp(Exp.CONNECT_EXCEPTION);
     ArrayList<Node> nodes = new ArrayList<>();
-    final HttpSolrServer solrclient1 = (HttpSolrServer) clients.get(0);
+    final HttpSolrClient solrclient1 = (HttpSolrClient) clients.get(0);
     
     final AtomicInteger retries = new AtomicInteger();
     ZkNodeProps nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP, solrclient1.getBaseURL(), ZkStateReader.CORE_NAME_PROP, "");
@@ -359,12 +359,12 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
   }
   
   private void testOneRetry() throws Exception {
-    final HttpSolrServer solrclient = (HttpSolrServer) clients.get(0);
+    final HttpSolrClient solrclient = (HttpSolrClient) clients.get(0);
     long numFoundBefore = solrclient.query(new SolrQuery("*:*")).getResults()
         .getNumFound();
-    final MockStreamingSolrServers ss = new MockStreamingSolrServers(updateShardHandler);
-    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(ss, 5, 0);
-    ss.setExp(Exp.CONNECT_EXCEPTION);
+    final MockStreamingSolrClients streamingClients = new MockStreamingSolrClients(updateShardHandler);
+    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(streamingClients, 5, 0);
+    streamingClients.setExp(Exp.CONNECT_EXCEPTION);
     ArrayList<Node> nodes = new ArrayList<>();
 
     ZkNodeProps nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP, solrclient.getBaseURL(),
@@ -375,7 +375,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
     RetryNode retryNode = new RetryNode(new ZkCoreNodeProps(nodeProps), null, "collection1", "shard1") {
       @Override
       public boolean checkRetry() {
-        ss.setExp(null);
+        streamingClients.setExp(null);
         retries.incrementAndGet();
         return true;
       }
@@ -405,12 +405,12 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
   }
 
   private void testRetryNodeWontRetrySocketError() throws Exception {
-    final HttpSolrServer solrclient = (HttpSolrServer) clients.get(0);
+    final HttpSolrClient solrclient = (HttpSolrClient) clients.get(0);
     long numFoundBefore = solrclient.query(new SolrQuery("*:*")).getResults()
         .getNumFound();
-    final MockStreamingSolrServers ss = new MockStreamingSolrServers(updateShardHandler);
-    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(ss, 5, 0);
-    ss.setExp(Exp.SOCKET_EXCEPTION);
+    final MockStreamingSolrClients streamingClients = new MockStreamingSolrClients(updateShardHandler);
+    SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(streamingClients, 5, 0);
+    streamingClients.setExp(Exp.SOCKET_EXCEPTION);
     ArrayList<Node> nodes = new ArrayList<>();
 
     ZkNodeProps nodeProps = new ZkNodeProps(ZkStateReader.BASE_URL_PROP, solrclient.getBaseURL(),
@@ -436,7 +436,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
     CommitUpdateCommand ccmd = new CommitUpdateCommand(null, false);
     cmdDistrib.distribAdd(cmd, nodes, params);
     
-    ss.setExp(null);
+    streamingClients.setExp(null);
     cmdDistrib.distribCommit(ccmd, nodes, params);
     cmdDistrib.finish();
     
@@ -455,7 +455,7 @@ public class SolrCmdDistributorTest extends BaseDistributedSearchTestCase {
   private void testRetryNodeAgainstBadAddress() throws SolrServerException, IOException {
     // Test RetryNode
     SolrCmdDistributor cmdDistrib = new SolrCmdDistributor(updateShardHandler);
-    final HttpSolrServer solrclient = (HttpSolrServer) clients.get(0);
+    final HttpSolrClient solrclient = (HttpSolrClient) clients.get(0);
     long numFoundBefore = solrclient.query(new SolrQuery("*:*")).getResults()
         .getNumFound();
     
diff --git a/solr/solrj/build.xml b/solr/solrj/build.xml
index 4e5016a..c42e69a 100644
--- a/solr/solrj/build.xml
+++ b/solr/solrj/build.xml
@@ -22,7 +22,7 @@
 
   <!-- violates the servlet-api restrictions, but it is safe to do so in this test: -->
   <property name="forbidden-tests-excludes" value="
-    org/apache/solr/client/solrj/impl/BasicHttpSolrServerTest$DebugServlet.class
+    org/apache/solr/client/solrj/impl/BasicHttpSolrClientTest$DebugServlet.class
   "/>
 
   <import file="../common-build.xml"/>
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/SolrClient.java b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrClient.java
new file mode 100644
index 0000000..0dd035b
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrClient.java
@@ -0,0 +1,352 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj;
+
+import org.apache.solr.client.solrj.SolrRequest.METHOD;
+import org.apache.solr.client.solrj.beans.DocumentObjectBinder;
+import org.apache.solr.client.solrj.impl.StreamingBinaryResponseParser;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.SolrPing;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.client.solrj.response.SolrPingResponse;
+import org.apache.solr.client.solrj.response.UpdateResponse;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.io.IOException;
+import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+/**
+ * Abstraction through which all communication with a Solr server may be routed
+ *
+ * @since 5.0, replaced {@code SolrServer}
+ */
+public abstract class SolrClient implements Serializable {
+
+  private static final long serialVersionUID = 1L;
+  private DocumentObjectBinder binder;
+
+  /**
+   * Adds a collection of documents
+   * @param docs  the collection of documents
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse add(Collection<SolrInputDocument> docs) throws SolrServerException, IOException {
+    return add(docs, -1);
+  }
+
+  /**
+   * Adds a collection of documents, specifying max time before they become committed
+   * @param docs  the collection of documents
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since solr 3.5
+   */
+  public UpdateResponse add(Collection<SolrInputDocument> docs, int commitWithinMs) throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.add(docs);
+    req.setCommitWithin(commitWithinMs);
+    return req.process(this);
+  }
+
+  /**
+   * Adds a collection of beans
+   * @param beans  the collection of beans
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse addBeans(Collection<?> beans) throws SolrServerException, IOException {
+    return addBeans(beans, -1);
+  }
+
+  /**
+   * Adds a collection of beans specifying max time before they become committed
+   * @param beans  the collection of beans
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since solr 3.5
+   */
+  public UpdateResponse addBeans(Collection<?> beans, int commitWithinMs) throws SolrServerException, IOException {
+    DocumentObjectBinder binder = this.getBinder();
+    ArrayList<SolrInputDocument> docs =  new ArrayList<>(beans.size());
+    for (Object bean : beans) {
+      docs.add(binder.toSolrInputDocument(bean));
+    }
+    return add(docs, commitWithinMs);
+  }
+
+  /**
+   * Adds a single document
+   * @param doc  the input document
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse add(SolrInputDocument doc) throws SolrServerException, IOException {
+    return add(doc, -1);
+  }
+
+  /**
+   * Adds a single document specifying max time before it becomes committed
+   * @param doc  the input document
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since solr 3.5
+   */
+  public UpdateResponse add(SolrInputDocument doc, int commitWithinMs) throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.add(doc);
+    req.setCommitWithin(commitWithinMs);
+    return req.process(this);
+  }
+
+  /**
+   * Adds a single bean
+   * @param obj  the input bean
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse addBean(Object obj) throws IOException, SolrServerException {
+    return addBean(obj, -1);
+  }
+
+  /**
+   * Adds a single bean specifying max time before it becomes committed
+   * @param obj  the input bean
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since solr 3.5
+   */
+  public UpdateResponse addBean(Object obj, int commitWithinMs) throws IOException, SolrServerException {
+    return add(getBinder().toSolrInputDocument(obj),commitWithinMs);
+  }
+
+  /**
+   * Performs an explicit commit, causing pending documents to be committed for indexing
+   * <p>
+   * waitFlush=true and waitSearcher=true to be inline with the defaults for plain HTTP access
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse commit() throws SolrServerException, IOException {
+    return commit(true, true);
+  }
+
+  /**
+   * Performs an explicit optimize, causing a merge of all segments to one.
+   * <p>
+   * waitFlush=true and waitSearcher=true to be inline with the defaults for plain HTTP access
+   * <p>
+   * Note: In most cases it is not required to do explicit optimize
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse optimize() throws SolrServerException, IOException {
+    return optimize(true, true, 1);
+  }
+
+  /**
+   * Performs an explicit commit, causing pending documents to be committed for indexing
+   * @param waitFlush  block until index changes are flushed to disk
+   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse commit(boolean waitFlush, boolean waitSearcher) throws SolrServerException, IOException {
+    return new UpdateRequest().setAction(UpdateRequest.ACTION.COMMIT, waitFlush, waitSearcher).process( this );
+  }
+
+  /**
+   * Performs an explicit commit, causing pending documents to be committed for indexing
+   * @param waitFlush  block until index changes are flushed to disk
+   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible
+   * @param softCommit makes index changes visible while neither fsync-ing index files nor writing a new index descriptor
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse commit(boolean waitFlush, boolean waitSearcher, boolean softCommit) throws SolrServerException, IOException {
+    return new UpdateRequest().setAction(UpdateRequest.ACTION.COMMIT, waitFlush, waitSearcher, softCommit).process( this );
+  }
+
+  /**
+   * Performs an explicit optimize, causing a merge of all segments to one.
+   * <p>
+   * Note: In most cases it is not required to do explicit optimize
+   * @param waitFlush  block until index changes are flushed to disk
+   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse optimize(boolean waitFlush, boolean waitSearcher) throws SolrServerException, IOException {
+    return optimize(waitFlush, waitSearcher, 1);
+  }
+
+  /**
+   * Performs an explicit optimize, causing a merge of all segments to one.
+   * <p>
+   * Note: In most cases it is not required to do explicit optimize
+   * @param waitFlush  block until index changes are flushed to disk
+   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
+   * @param maxSegments  optimizes down to at most this number of segments
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse optimize(boolean waitFlush, boolean waitSearcher, int maxSegments) throws SolrServerException, IOException {
+    return new UpdateRequest().setAction(UpdateRequest.ACTION.OPTIMIZE, waitFlush, waitSearcher, maxSegments).process( this );
+  }
+
+  /**
+   * Performs a rollback of all non-committed documents pending.
+   * <p>
+   * Note that this is not a true rollback as in databases. Content you have previously
+   * added may have been committed due to autoCommit, buffer full, other client performing
+   * a commit etc.
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse rollback() throws SolrServerException, IOException {
+    return new UpdateRequest().rollback().process( this );
+  }
+
+  /**
+   * Deletes a single document by unique ID
+   * @param id  the ID of the document to delete
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse deleteById(String id) throws SolrServerException, IOException {
+    return deleteById(id, -1);
+  }
+
+  /**
+   * Deletes a single document by unique ID, specifying max time before commit
+   * @param id  the ID of the document to delete
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since 3.6
+   */
+  public UpdateResponse deleteById(String id, int commitWithinMs) throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.deleteById(id);
+    req.setCommitWithin(commitWithinMs);
+    return req.process(this);
+  }
+
+  /**
+   * Deletes a list of documents by unique ID
+   * @param ids  the list of document IDs to delete 
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse deleteById(List<String> ids) throws SolrServerException, IOException {
+    return deleteById(ids, -1);
+  }
+
+  /**
+   * Deletes a list of documents by unique ID, specifying max time before commit
+   * @param ids  the list of document IDs to delete 
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since 3.6
+   */
+  public UpdateResponse deleteById(List<String> ids, int commitWithinMs) throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.deleteById(ids);
+    req.setCommitWithin(commitWithinMs);
+    return req.process(this);
+  }
+
+  /**
+   * Deletes documents from the index based on a query
+   * @param query  the query expressing what documents to delete
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public UpdateResponse deleteByQuery(String query) throws SolrServerException, IOException {
+    return deleteByQuery(query, -1);
+  }
+
+  /**
+   * Deletes documents from the index based on a query, specifying max time before commit
+   * @param query  the query expressing what documents to delete
+   * @param commitWithinMs  max time (in ms) before a commit will happen 
+   * @throws IOException If there is a low-level I/O error.
+   * @since 3.6
+   */
+  public UpdateResponse deleteByQuery(String query, int commitWithinMs) throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.deleteByQuery(query);
+    req.setCommitWithin(commitWithinMs);
+    return req.process(this);
+  }
+
+  /**
+   * Issues a ping request to check if the server is alive
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public SolrPingResponse ping() throws SolrServerException, IOException {
+    return new SolrPing().process(this);
+  }
+
+  /**
+   * Performs a query to the Solr server
+   * @param params  an object holding all key/value parameters to send along the request
+   */
+  public QueryResponse query(SolrParams params) throws SolrServerException {
+    return new QueryRequest(params).process(this);
+  }
+
+  /**
+   * Performs a query to the Solr server
+   * @param params  an object holding all key/value parameters to send along the request
+   * @param method  specifies the HTTP method to use for the request, such as GET or POST
+   */
+  public QueryResponse query(SolrParams params, METHOD method) throws SolrServerException {
+    return new QueryRequest(params, method).process(this);
+  }
+
+  /**
+   * Query solr, and stream the results.  Unlike the standard query, this will 
+   * send events for each Document rather then add them to the QueryResponse.
+   *
+   * Although this function returns a 'QueryResponse' it should be used with care
+   * since it excludes anything that was passed to callback.  Also note that
+   * future version may pass even more info to the callback and may not return 
+   * the results in the QueryResponse.
+   *
+   * @since solr 4.0
+   */
+  public QueryResponse queryAndStreamResponse(SolrParams params, StreamingResponseCallback callback) throws SolrServerException, IOException
+  {
+    ResponseParser parser = new StreamingBinaryResponseParser(callback);
+    QueryRequest req = new QueryRequest(params);
+    req.setStreamingResponseCallback(callback);
+    req.setResponseParser(parser);
+    return req.process(this);
+  }
+
+  /**
+   * SolrServer implementations need to implement how a request is actually processed
+   */
+  public abstract NamedList<Object> request(final SolrRequest request) throws SolrServerException, IOException;
+
+  public DocumentObjectBinder getBinder() {
+    if(binder == null){
+      binder = new DocumentObjectBinder();
+    }
+    return binder;
+  }
+
+  /**
+   * Release allocated resources.
+   *
+   * @since solr 4.0
+   */
+  public abstract void shutdown();
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java
index 05346ca..a542417 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrRequest.java
@@ -109,5 +109,5 @@ public abstract class SolrRequest implements Serializable
 
   public abstract SolrParams getParams();
   public abstract Collection<ContentStream> getContentStreams() throws IOException;
-  public abstract SolrResponse process( SolrServer server ) throws SolrServerException, IOException;
+  public abstract SolrResponse process( SolrClient server ) throws SolrServerException, IOException;
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/SolrServer.java b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrServer.java
index 9da6e71..0238214 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/SolrServer.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/SolrServer.java
@@ -17,335 +17,9 @@
 
 package org.apache.solr.client.solrj;
 
-import java.io.IOException;
-import java.io.Serializable;
-import java.util.Collection;
-import java.util.ArrayList;
-import java.util.List;
-
-import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.client.solrj.request.SolrPing;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.client.solrj.response.SolrPingResponse;
-import org.apache.solr.client.solrj.response.UpdateResponse;
-import org.apache.solr.client.solrj.SolrRequest.METHOD;
-import org.apache.solr.client.solrj.beans.DocumentObjectBinder;
-import org.apache.solr.client.solrj.impl.StreamingBinaryResponseParser;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.NamedList;
-
 /**
- *
- * @since solr 1.3
+ * @deprecated Use {@link org.apache.solr.client.solrj.SolrClient}
  */
-public abstract class SolrServer implements Serializable
-{
-  private static final long serialVersionUID = 1L;
-  private DocumentObjectBinder binder;
-
-  /**
-   * Adds a collection of documents
-   * @param docs  the collection of documents
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse add(Collection<SolrInputDocument> docs) throws SolrServerException, IOException {
-    return add(docs, -1);
-  }
-
-  /**
-   * Adds a collection of documents, specifying max time before they become committed
-   * @param docs  the collection of documents
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since solr 3.5
-   */
-  public UpdateResponse add(Collection<SolrInputDocument> docs, int commitWithinMs) throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.add(docs);
-    req.setCommitWithin(commitWithinMs);
-    return req.process(this);
-  }
-
-  /**
-   * Adds a collection of beans
-   * @param beans  the collection of beans
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse addBeans(Collection<?> beans ) throws SolrServerException, IOException {
-    return addBeans(beans, -1);
-  }
-  
-  /**
-   * Adds a collection of beans specifying max time before they become committed
-   * @param beans  the collection of beans
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since solr 3.5
-   */
-  public UpdateResponse addBeans(Collection<?> beans, int commitWithinMs) throws SolrServerException, IOException {
-    DocumentObjectBinder binder = this.getBinder();
-    ArrayList<SolrInputDocument> docs =  new ArrayList<>(beans.size());
-    for (Object bean : beans) {
-      docs.add(binder.toSolrInputDocument(bean));
-    }
-    return add(docs, commitWithinMs);
-  }
-
-  /**
-   * Adds a single document
-   * @param doc  the input document
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse add(SolrInputDocument doc ) throws SolrServerException, IOException {
-    return add(doc, -1);
-  }
-
-  /**
-   * Adds a single document specifying max time before it becomes committed
-   * @param doc  the input document
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since solr 3.5
-   */
-  public UpdateResponse add(SolrInputDocument doc, int commitWithinMs) throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.add(doc);
-    req.setCommitWithin(commitWithinMs);
-    return req.process(this);
-  }
-
-  /**
-   * Adds a single bean
-   * @param obj  the input bean
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse addBean(Object obj) throws IOException, SolrServerException {
-    return addBean(obj, -1);
-  }
-
-  /**
-   * Adds a single bean specifying max time before it becomes committed
-   * @param obj  the input bean
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since solr 3.5
-   */
-  public UpdateResponse addBean(Object obj, int commitWithinMs) throws IOException, SolrServerException {
-    return add(getBinder().toSolrInputDocument(obj),commitWithinMs);
-  }
-
-  /** 
-   * Performs an explicit commit, causing pending documents to be committed for indexing
-   * <p>
-   * waitFlush=true and waitSearcher=true to be inline with the defaults for plain HTTP access
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse commit( ) throws SolrServerException, IOException {
-    return commit(true, true);
-  }
-
-  /** 
-   * Performs an explicit optimize, causing a merge of all segments to one.
-   * <p>
-   * waitFlush=true and waitSearcher=true to be inline with the defaults for plain HTTP access
-   * <p>
-   * Note: In most cases it is not required to do explicit optimize
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse optimize( ) throws SolrServerException, IOException {
-    return optimize(true, true, 1);
-  }
-  
-  /** 
-   * Performs an explicit commit, causing pending documents to be committed for indexing
-   * @param waitFlush  block until index changes are flushed to disk
-   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse commit( boolean waitFlush, boolean waitSearcher ) throws SolrServerException, IOException {
-    return new UpdateRequest().setAction( UpdateRequest.ACTION.COMMIT, waitFlush, waitSearcher ).process( this );
-  }
-
-  /**
-   * Performs an explicit commit, causing pending documents to be committed for indexing
-   * @param waitFlush  block until index changes are flushed to disk
-   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible
-   * @param softCommit makes index changes visible while neither fsync-ing index files nor writing a new index descriptor
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse commit( boolean waitFlush, boolean waitSearcher, boolean softCommit ) throws SolrServerException, IOException {
-    return new UpdateRequest().setAction( UpdateRequest.ACTION.COMMIT, waitFlush, waitSearcher, softCommit ).process( this );
-  }
-
-  /** 
-   * Performs an explicit optimize, causing a merge of all segments to one.
-   * <p>
-   * Note: In most cases it is not required to do explicit optimize
-   * @param waitFlush  block until index changes are flushed to disk
-   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse optimize( boolean waitFlush, boolean waitSearcher ) throws SolrServerException, IOException {
-    return optimize(waitFlush, waitSearcher, 1);
-  }
-
-  /** 
-   * Performs an explicit optimize, causing a merge of all segments to one.
-   * <p>
-   * Note: In most cases it is not required to do explicit optimize
-   * @param waitFlush  block until index changes are flushed to disk
-   * @param waitSearcher  block until a new searcher is opened and registered as the main query searcher, making the changes visible 
-   * @param maxSegments  optimizes down to at most this number of segments
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse optimize(boolean waitFlush, boolean waitSearcher, int maxSegments ) throws SolrServerException, IOException {
-    return new UpdateRequest().setAction( UpdateRequest.ACTION.OPTIMIZE, waitFlush, waitSearcher, maxSegments ).process( this );
-  }
-  
-  /**
-   * Performs a rollback of all non-committed documents pending.
-   * <p>
-   * Note that this is not a true rollback as in databases. Content you have previously
-   * added may have been committed due to autoCommit, buffer full, other client performing
-   * a commit etc.
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse rollback() throws SolrServerException, IOException {
-    return new UpdateRequest().rollback().process( this );
-  }
-  
-  /**
-   * Deletes a single document by unique ID
-   * @param id  the ID of the document to delete
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse deleteById(String id) throws SolrServerException, IOException {
-    return deleteById(id, -1);
-  }
-
-  /**
-   * Deletes a single document by unique ID, specifying max time before commit
-   * @param id  the ID of the document to delete
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since 3.6
-   */
-  public UpdateResponse deleteById(String id, int commitWithinMs) throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.deleteById(id);
-    req.setCommitWithin(commitWithinMs);
-    return req.process(this);
-  }
-
-  /**
-   * Deletes a list of documents by unique ID
-   * @param ids  the list of document IDs to delete 
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse deleteById(List<String> ids) throws SolrServerException, IOException {
-    return deleteById(ids, -1);
-  }
-
-  /**
-   * Deletes a list of documents by unique ID, specifying max time before commit
-   * @param ids  the list of document IDs to delete 
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since 3.6
-   */
-  public UpdateResponse deleteById(List<String> ids, int commitWithinMs) throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.deleteById(ids);
-    req.setCommitWithin(commitWithinMs);
-    return req.process(this);
-  }
-
-  /**
-   * Deletes documents from the index based on a query
-   * @param query  the query expressing what documents to delete
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public UpdateResponse deleteByQuery(String query) throws SolrServerException, IOException {
-    return deleteByQuery(query, -1);
-  }
-
-  /**
-   * Deletes documents from the index based on a query, specifying max time before commit
-   * @param query  the query expressing what documents to delete
-   * @param commitWithinMs  max time (in ms) before a commit will happen 
-   * @throws IOException If there is a low-level I/O error.
-   * @since 3.6
-   */
-  public UpdateResponse deleteByQuery(String query, int commitWithinMs) throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.deleteByQuery(query);
-    req.setCommitWithin(commitWithinMs);
-    return req.process(this);
-  }
-
-  /**
-   * Issues a ping request to check if the server is alive
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public SolrPingResponse ping() throws SolrServerException, IOException {
-    return new SolrPing().process( this );
-  }
-
-  /**
-   * Performs a query to the Solr server
-   * @param params  an object holding all key/value parameters to send along the request
-   */
-  public QueryResponse query(SolrParams params) throws SolrServerException {
-    return new QueryRequest( params ).process( this );
-  }
-  
-  /**
-   * Performs a query to the Solr server
-   * @param params  an object holding all key/value parameters to send along the request
-   * @param method  specifies the HTTP method to use for the request, such as GET or POST
-   */
-  public QueryResponse query(SolrParams params, METHOD method) throws SolrServerException {
-    return new QueryRequest( params, method ).process( this );
-  }
-
-  /**
-   * Query solr, and stream the results.  Unlike the standard query, this will 
-   * send events for each Document rather then add them to the QueryResponse.
-   * 
-   * Although this function returns a 'QueryResponse' it should be used with care
-   * since it excludes anything that was passed to callback.  Also note that
-   * future version may pass even more info to the callback and may not return 
-   * the results in the QueryResponse.
-   *
-   * @since solr 4.0
-   */
-  public QueryResponse queryAndStreamResponse( SolrParams params, StreamingResponseCallback callback ) throws SolrServerException, IOException
-  {
-    ResponseParser parser = new StreamingBinaryResponseParser( callback );
-    QueryRequest req = new QueryRequest( params );
-    req.setStreamingResponseCallback( callback );
-    req.setResponseParser( parser );    
-    return req.process(this);
-  }
-
-  /**
-   * SolrServer implementations need to implement how a request is actually processed
-   */ 
-  public abstract NamedList<Object> request( final SolrRequest request ) throws SolrServerException, IOException;
-
-  public DocumentObjectBinder getBinder() {
-    if(binder == null){
-      binder = new DocumentObjectBinder();
-    }
-    return binder;
-  }
-  
-  /**
-   * Release allocated resources.
-   * 
-   * @since solr 4.0
-   */
-  public abstract void shutdown();
+@Deprecated
+public abstract class SolrServer extends SolrClient {
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java
new file mode 100644
index 0000000..fcb7bc0
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrClient.java
@@ -0,0 +1,1156 @@
+package org.apache.solr.client.solrj.impl;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.http.NoHttpResponseException;
+import org.apache.http.client.HttpClient;
+import org.apache.http.conn.ConnectTimeoutException;
+import org.apache.solr.client.solrj.ResponseParser;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.IsUpdateRequest;
+import org.apache.solr.client.solrj.request.RequestWriter;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.util.ClientUtils;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.cloud.Aliases;
+import org.apache.solr.common.cloud.ClusterState;
+import org.apache.solr.common.cloud.DocCollection;
+import org.apache.solr.common.cloud.DocRouter;
+import org.apache.solr.common.cloud.ImplicitDocRouter;
+import org.apache.solr.common.cloud.Replica;
+import org.apache.solr.common.cloud.Slice;
+import org.apache.solr.common.cloud.ZkCoreNodeProps;
+import org.apache.solr.common.cloud.ZkNodeProps;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.cloud.ZooKeeperException;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.ShardParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SolrjNamedThreadFactory;
+import org.apache.solr.common.util.StrUtils;
+import org.apache.zookeeper.KeeperException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.net.ConnectException;
+import java.net.SocketException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeoutException;
+
+/**
+ * SolrJ client class to communicate with SolrCloud.
+ * Instances of this class communicate with Zookeeper to discover
+ * Solr endpoints for SolrCloud collections, and then use the 
+ * {@link LBHttpSolrClient} to issue requests.
+ * 
+ * This class assumes the id field for your documents is called
+ * 'id' - if this is not the case, you must set the right name
+ * with {@link #setIdField(String)}.
+ */
+@SuppressWarnings("serial")
+public class CloudSolrClient extends SolrClient {
+  protected static final Logger log = LoggerFactory.getLogger(CloudSolrClient.class);
+
+  private volatile ZkStateReader zkStateReader;
+  private String zkHost; // the zk server connect string
+  private int zkConnectTimeout = 10000;
+  private int zkClientTimeout = 10000;
+  private volatile String defaultCollection;
+  private final LBHttpSolrClient lbClient;
+  private final boolean shutdownLBHttpSolrServer;
+  private HttpClient myClient;
+  private final boolean clientIsInternal;
+  //no of times collection state to be reloaded if stale state error is received
+  private static final int MAX_STALE_RETRIES = 5;
+  Random rand = new Random();
+  
+  private final boolean updatesToLeaders;
+  private boolean parallelUpdates = true;
+  private ExecutorService threadPool = Executors
+      .newCachedThreadPool(new SolrjNamedThreadFactory(
+          "CloudSolrServer ThreadPool"));
+  private String idField = "id";
+  public static final String STATE_VERSION = "_stateVer_";
+  private final Set<String> NON_ROUTABLE_PARAMS;
+  {
+    NON_ROUTABLE_PARAMS = new HashSet<>();
+    NON_ROUTABLE_PARAMS.add(UpdateParams.EXPUNGE_DELETES);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.MAX_OPTIMIZE_SEGMENTS);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.COMMIT);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.WAIT_SEARCHER);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.OPEN_SEARCHER);
+    
+    NON_ROUTABLE_PARAMS.add(UpdateParams.SOFT_COMMIT);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.PREPARE_COMMIT);
+    NON_ROUTABLE_PARAMS.add(UpdateParams.OPTIMIZE);
+    
+    // Not supported via SolrCloud
+    // NON_ROUTABLE_PARAMS.add(UpdateParams.ROLLBACK);
+
+  }
+  private volatile long timeToLive = 60* 1000L;
+
+
+  protected Map<String, ExpiringCachedDocCollection> collectionStateCache = new ConcurrentHashMap<String, ExpiringCachedDocCollection>(){
+    @Override
+    public ExpiringCachedDocCollection get(Object key) {
+      ExpiringCachedDocCollection val = super.get(key);
+      if(val == null) return null;
+      if(val.isExpired(timeToLive)) {
+        super.remove(key);
+        return null;
+      }
+      return val;
+    }
+
+  };
+
+  class ExpiringCachedDocCollection {
+    DocCollection cached;
+    long cachedAt;
+
+    ExpiringCachedDocCollection(DocCollection cached) {
+      this.cached = cached;
+      this.cachedAt = System.currentTimeMillis();
+    }
+
+    boolean isExpired(long timeToLive) {
+      return (System.currentTimeMillis() - cachedAt) > timeToLive;
+    }
+  }
+
+  /**
+   * Create a new client object that connects to Zookeeper and is always aware
+   * of the SolrCloud state. If there is a fully redundant Zookeeper quorum and
+   * SolrCloud has enough replicas for every shard in a collection, there is no
+   * single point of failure. Updates will be sent to shard leaders by default.
+   * 
+   * @param zkHost
+   *          The client endpoint of the zookeeper quorum containing the cloud
+   *          state. The full specification for this string is one or more comma
+   *          separated HOST:PORT values, followed by an optional chroot value
+   *          that starts with a forward slash. Using a chroot allows multiple
+   *          applications to coexist in one ensemble. For full details, see the
+   *          Zookeeper documentation. Some examples:
+   *          <p/>
+   *          "host1:2181"
+   *          <p/>
+   *          "host1:2181,host2:2181,host3:2181/mysolrchroot"
+   *          <p/>
+   *          "zoo1.example.com:2181,zoo2.example.com:2181,zoo3.example.com:2181"
+   */
+  public CloudSolrClient(String zkHost) {
+      this.zkHost = zkHost;
+      this.clientIsInternal = true;
+      this.myClient = HttpClientUtil.createClient(null);
+      this.lbClient = new LBHttpSolrClient(myClient);
+      this.lbClient.setRequestWriter(new BinaryRequestWriter());
+      this.lbClient.setParser(new BinaryResponseParser());
+      this.updatesToLeaders = true;
+      shutdownLBHttpSolrServer = true;
+      lbClient.addQueryParams(STATE_VERSION);
+  }
+
+  /**
+   * Create a new client object that connects to Zookeeper and is always aware
+   * of the SolrCloud state. If there is a fully redundant Zookeeper quorum and
+   * SolrCloud has enough replicas for every shard in a collection, there is no
+   * single point of failure. Updates will be sent to shard leaders by default.
+   *
+   * @param zkHost
+   *          The client endpoint of the zookeeper quorum containing the cloud
+   *          state. The full specification for this string is one or more comma
+   *          separated HOST:PORT values, followed by an optional chroot value
+   *          that starts with a forward slash. Using a chroot allows multiple
+   *          applications to coexist in one ensemble. For full details, see the
+   *          Zookeeper documentation. Some examples:
+   *          <p/>
+   *          "host1:2181"
+   *          <p/>
+   *          "host1:2181,host2:2181,host3:2181/mysolrchroot"
+   *          <p/>
+   *          "zoo1.example.com:2181,zoo2.example.com:2181,zoo3.example.com:2181"
+   * @param httpClient
+   *          the {@link HttpClient} instance to be used for all requests. The
+   *          provided httpClient should use a multi-threaded connection manager.
+   */
+  public CloudSolrClient(String zkHost, HttpClient httpClient)  {
+    this.zkHost = zkHost;
+    this.clientIsInternal = httpClient == null;
+    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
+    this.lbClient = new LBHttpSolrClient(myClient);
+    this.lbClient.setRequestWriter(new BinaryRequestWriter());
+    this.lbClient.setParser(new BinaryResponseParser());
+    this.updatesToLeaders = true;
+    shutdownLBHttpSolrServer = true;
+    lbClient.addQueryParams(STATE_VERSION);
+  }
+  
+  /**
+   * Create a new client object using multiple string values in a Collection
+   * instead of a standard zkHost connection string. Note that this method will
+   * not be used if there is only one String argument - that will use
+   * {@link #CloudSolrClient(String)} instead.
+   * 
+   * @param zkHosts
+   *          A Java Collection (List, Set, etc) of HOST:PORT strings, one for
+   *          each host in the zookeeper ensemble. Note that with certain
+   *          Collection types like HashSet, the order of hosts in the final
+   *          connect string may not be in the same order you added them.
+   * @param chroot
+   *          A chroot value for zookeeper, starting with a forward slash. If no
+   *          chroot is required, use null.
+   * @throws IllegalArgumentException
+   *           if the chroot value does not start with a forward slash.
+   * @see #CloudSolrClient(String)
+   */
+  public CloudSolrClient(Collection<String> zkHosts, String chroot) {
+    this(zkHosts, chroot, null);
+  }
+
+  /**
+   * Create a new client object using multiple string values in a Collection
+   * instead of a standard zkHost connection string. Note that this method will
+   * not be used if there is only one String argument - that will use
+   * {@link #CloudSolrClient(String)} instead.
+   *
+   * @param zkHosts
+   *          A Java Collection (List, Set, etc) of HOST:PORT strings, one for
+   *          each host in the zookeeper ensemble. Note that with certain
+   *          Collection types like HashSet, the order of hosts in the final
+   *          connect string may not be in the same order you added them.
+   * @param chroot
+   *          A chroot value for zookeeper, starting with a forward slash. If no
+   *          chroot is required, use null.
+   * @param httpClient
+   *          the {@link HttpClient} instance to be used for all requests. The provided httpClient should use a
+   *          multi-threaded connection manager.
+   * @throws IllegalArgumentException
+   *           if the chroot value does not start with a forward slash.
+   * @see #CloudSolrClient(String)
+   */
+  public CloudSolrClient(Collection<String> zkHosts, String chroot, HttpClient httpClient) {
+    StringBuilder zkBuilder = new StringBuilder();
+    int lastIndexValue = zkHosts.size() - 1;
+    int i = 0;
+    for (String zkHost : zkHosts) {
+      zkBuilder.append(zkHost);
+      if (i < lastIndexValue) {
+        zkBuilder.append(",");
+      }
+      i++;
+    }
+    if (chroot != null) {
+      if (chroot.startsWith("/")) {
+        zkBuilder.append(chroot);
+      } else {
+        throw new IllegalArgumentException(
+            "The chroot must start with a forward slash.");
+      }
+    }
+
+    /* Log the constructed connection string and then initialize. */
+    log.info("Final constructed zkHost string: " + zkBuilder.toString());
+
+    this.zkHost = zkBuilder.toString();
+    this.clientIsInternal = httpClient == null;
+    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
+    this.lbClient = new LBHttpSolrClient(myClient);
+    this.lbClient.setRequestWriter(new BinaryRequestWriter());
+    this.lbClient.setParser(new BinaryResponseParser());
+    this.updatesToLeaders = true;
+    shutdownLBHttpSolrServer = true;
+  }
+  
+  /**
+   * @param zkHost
+   *          A zookeeper client endpoint.
+   * @param updatesToLeaders
+   *          If true, sends updates only to shard leaders.
+   * @see #CloudSolrClient(String) for full description and details on zkHost
+   */
+  public CloudSolrClient(String zkHost, boolean updatesToLeaders) {
+    this(zkHost, updatesToLeaders, null);
+  }
+
+  /**
+   * @param zkHost
+   *          A zookeeper client endpoint.
+   * @param updatesToLeaders
+   *          If true, sends updates only to shard leaders.
+   * @param httpClient
+   *          the {@link HttpClient} instance to be used for all requests. The provided httpClient should use a
+   *          multi-threaded connection manager.
+   * @see #CloudSolrClient(String) for full description and details on zkHost
+   */
+  public CloudSolrClient(String zkHost, boolean updatesToLeaders, HttpClient httpClient) {
+    this.zkHost = zkHost;
+    this.clientIsInternal = httpClient == null;
+    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
+    this.lbClient = new LBHttpSolrClient(myClient);
+    this.lbClient.setRequestWriter(new BinaryRequestWriter());
+    this.lbClient.setParser(new BinaryResponseParser());
+    this.updatesToLeaders = updatesToLeaders;
+    shutdownLBHttpSolrServer = true;
+    lbClient.addQueryParams(STATE_VERSION);
+  }
+
+  /**Sets the cache ttl for DocCollection Objects cached  . This is only applicable for collections which are persisted outside of clusterstate.json
+   * @param seconds ttl value in seconds
+   */
+  public void setCollectionCacheTTl(int seconds){
+    assert seconds > 0;
+    timeToLive = seconds*1000L;
+  }
+
+  /**
+   * @param zkHost
+   *          A zookeeper client endpoint.
+   * @param lbClient
+   *          LBHttpSolrServer instance for requests.
+   * @see #CloudSolrClient(String) for full description and details on zkHost
+   */
+  public CloudSolrClient(String zkHost, LBHttpSolrClient lbClient) {
+    this(zkHost, lbClient, true);
+  }
+  
+  /**
+   * @param zkHost
+   *          A zookeeper client endpoint.
+   * @param lbClient
+   *          LBHttpSolrServer instance for requests.
+   * @param updatesToLeaders
+   *          If true, sends updates only to shard leaders.
+   * @see #CloudSolrClient(String) for full description and details on zkHost
+   */
+  public CloudSolrClient(String zkHost, LBHttpSolrClient lbClient, boolean updatesToLeaders) {
+    this.zkHost = zkHost;
+    this.lbClient = lbClient;
+    this.updatesToLeaders = updatesToLeaders;
+    shutdownLBHttpSolrServer = false;
+    this.clientIsInternal = false;
+    lbClient.addQueryParams(STATE_VERSION);
+  }
+  
+  public ResponseParser getParser() {
+    return lbClient.getParser();
+  }
+  
+  /**
+   * Note: This setter method is <b>not thread-safe</b>.
+   * 
+   * @param processor
+   *          Default Response Parser chosen to parse the response if the parser
+   *          were not specified as part of the request.
+   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
+   */
+  public void setParser(ResponseParser processor) {
+    lbClient.setParser(processor);
+  }
+  
+  public RequestWriter getRequestWriter() {
+    return lbClient.getRequestWriter();
+  }
+  
+  public void setRequestWriter(RequestWriter requestWriter) {
+    lbClient.setRequestWriter(requestWriter);
+  }
+
+  /**
+   * @return the zkHost value used to connect to zookeeper.
+   */
+  public String getZkHost() {
+    return zkHost;
+  }
+
+  public ZkStateReader getZkStateReader() {
+    return zkStateReader;
+  }
+
+  /**
+   * @param idField the field to route documents on.
+   */
+  public void setIdField(String idField) {
+    this.idField = idField;
+  }
+
+  /**
+   * @return the field that updates are routed on.
+   */
+  public String getIdField() {
+    return idField;
+  }
+  
+  /** Sets the default collection for request */
+  public void setDefaultCollection(String collection) {
+    this.defaultCollection = collection;
+  }
+
+  /** Gets the default collection for request */
+  public String getDefaultCollection() {
+    return defaultCollection;
+  }
+
+  /** Set the connect timeout to the zookeeper ensemble in ms */
+  public void setZkConnectTimeout(int zkConnectTimeout) {
+    this.zkConnectTimeout = zkConnectTimeout;
+  }
+
+  /** Set the timeout to the zookeeper ensemble in ms */
+  public void setZkClientTimeout(int zkClientTimeout) {
+    this.zkClientTimeout = zkClientTimeout;
+  }
+
+  /**
+   * Connect to the zookeeper ensemble.
+   * This is an optional method that may be used to force a connect before any other requests are sent.
+   *
+   */
+  public void connect() {
+    if (zkStateReader == null) {
+      synchronized (this) {
+        if (zkStateReader == null) {
+          ZkStateReader zk = null;
+          try {
+            zk = new ZkStateReader(zkHost, zkClientTimeout,
+                zkConnectTimeout);
+            zk.createClusterStateWatchersAndUpdate();
+            zkStateReader = zk;
+          } catch (InterruptedException e) {
+            if (zk != null) zk.close();
+            Thread.currentThread().interrupt();
+            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
+                "", e);
+          } catch (KeeperException e) {
+            if (zk != null) zk.close();
+            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
+                "", e);
+          } catch (IOException e) {
+            if (zk != null) zk.close();
+            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
+                "", e);
+          } catch (TimeoutException e) {
+            if (zk != null) zk.close();
+            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
+                "", e);
+          } catch (Exception e) {
+            if (zk != null) zk.close();
+            // do not wrap because clients may be relying on the underlying exception being thrown
+            throw e;
+          }
+        }
+      }
+    }
+  }
+
+  public void setParallelUpdates(boolean parallelUpdates) {
+    this.parallelUpdates = parallelUpdates;
+  }
+
+  private NamedList<Object> directUpdate(AbstractUpdateRequest request, ClusterState clusterState) throws SolrServerException {
+    UpdateRequest updateRequest = (UpdateRequest) request;
+    ModifiableSolrParams params = (ModifiableSolrParams) request.getParams();
+    ModifiableSolrParams routableParams = new ModifiableSolrParams();
+    ModifiableSolrParams nonRoutableParams = new ModifiableSolrParams();
+
+    if(params != null) {
+      nonRoutableParams.add(params);
+      routableParams.add(params);
+      for(String param : NON_ROUTABLE_PARAMS) {
+        routableParams.remove(param);
+      }
+    }
+
+    String collection = nonRoutableParams.get(UpdateParams.COLLECTION, defaultCollection);
+    if (collection == null) {
+      throw new SolrServerException("No collection param specified on request and no default collection has been set.");
+    }
+
+
+    //Check to see if the collection is an alias.
+    Aliases aliases = zkStateReader.getAliases();
+    if(aliases != null) {
+      Map<String, String> collectionAliases = aliases.getCollectionAliasMap();
+      if(collectionAliases != null && collectionAliases.containsKey(collection)) {
+        collection = collectionAliases.get(collection);
+      }
+    }
+
+    DocCollection col = getDocCollection(clusterState, collection);
+
+    DocRouter router = col.getRouter();
+    
+    if (router instanceof ImplicitDocRouter) {
+      // short circuit as optimization
+      return null;
+    }
+
+    //Create the URL map, which is keyed on slice name.
+    //The value is a list of URLs for each replica in the slice.
+    //The first value in the list is the leader for the slice.
+    Map<String,List<String>> urlMap = buildUrlMap(col);
+    if (urlMap == null) {
+      // we could not find a leader yet - use unoptimized general path
+      return null;
+    }
+
+    NamedList<Throwable> exceptions = new NamedList<>();
+    NamedList<NamedList> shardResponses = new NamedList<>();
+
+    Map<String, LBHttpSolrClient.Req> routes = updateRequest.getRoutes(router, col, urlMap, routableParams, this.idField);
+    if (routes == null) {
+      return null;
+    }
+
+    long start = System.nanoTime();
+
+    if (parallelUpdates) {
+      final Map<String, Future<NamedList<?>>> responseFutures = new HashMap<>(routes.size());
+      for (final Map.Entry<String, LBHttpSolrClient.Req> entry : routes.entrySet()) {
+        final String url = entry.getKey();
+        final LBHttpSolrClient.Req lbRequest = entry.getValue();
+        responseFutures.put(url, threadPool.submit(new Callable<NamedList<?>>() {
+          @Override
+          public NamedList<?> call() throws Exception {
+            return lbClient.request(lbRequest).getResponse();
+          }
+        }));
+      }
+
+      for (final Map.Entry<String, Future<NamedList<?>>> entry: responseFutures.entrySet()) {
+        final String url = entry.getKey();
+        final Future<NamedList<?>> responseFuture = entry.getValue();
+        try {
+          shardResponses.add(url, responseFuture.get());
+        } catch (InterruptedException e) {
+          Thread.currentThread().interrupt();
+          throw new RuntimeException(e);
+        } catch (ExecutionException e) {
+          exceptions.add(url, e.getCause());
+        }
+      }
+
+      if (exceptions.size() > 0) {
+        throw new RouteException(ErrorCode.SERVER_ERROR, exceptions, routes);
+      }
+    } else {
+      for (Map.Entry<String, LBHttpSolrClient.Req> entry : routes.entrySet()) {
+        String url = entry.getKey();
+        LBHttpSolrClient.Req lbRequest = entry.getValue();
+        try {
+          NamedList<Object> rsp = lbClient.request(lbRequest).getResponse();
+          shardResponses.add(url, rsp);
+        } catch (Exception e) {
+          throw new SolrServerException(e);
+        }
+      }
+    }
+
+    UpdateRequest nonRoutableRequest = null;
+    List<String> deleteQuery = updateRequest.getDeleteQuery();
+    if (deleteQuery != null && deleteQuery.size() > 0) {
+      UpdateRequest deleteQueryRequest = new UpdateRequest();
+      deleteQueryRequest.setDeleteQuery(deleteQuery);
+      nonRoutableRequest = deleteQueryRequest;
+    }
+    
+    Set<String> paramNames = nonRoutableParams.getParameterNames();
+    
+    Set<String> intersection = new HashSet<>(paramNames);
+    intersection.retainAll(NON_ROUTABLE_PARAMS);
+    
+    if (nonRoutableRequest != null || intersection.size() > 0) {
+      if (nonRoutableRequest == null) {
+        nonRoutableRequest = new UpdateRequest();
+      }
+      nonRoutableRequest.setParams(nonRoutableParams);
+      List<String> urlList = new ArrayList<>();
+      urlList.addAll(routes.keySet());
+      Collections.shuffle(urlList, rand);
+      LBHttpSolrClient.Req req = new LBHttpSolrClient.Req(nonRoutableRequest, urlList);
+      try {
+        LBHttpSolrClient.Rsp rsp = lbClient.request(req);
+        shardResponses.add(urlList.get(0), rsp.getResponse());
+      } catch (Exception e) {
+        throw new SolrException(ErrorCode.SERVER_ERROR, urlList.get(0), e);
+      }
+    }
+
+    long end = System.nanoTime();
+
+    RouteResponse rr =  condenseResponse(shardResponses, (long)((end - start)/1000000));
+    rr.setRouteResponses(shardResponses);
+    rr.setRoutes(routes);
+    return rr;
+  }
+
+  private Map<String,List<String>> buildUrlMap(DocCollection col) {
+    Map<String, List<String>> urlMap = new HashMap<>();
+    Collection<Slice> slices = col.getActiveSlices();
+    Iterator<Slice> sliceIterator = slices.iterator();
+    while (sliceIterator.hasNext()) {
+      Slice slice = sliceIterator.next();
+      String name = slice.getName();
+      List<String> urls = new ArrayList<>();
+      Replica leader = slice.getLeader();
+      if (leader == null) {
+        // take unoptimized general path - we cannot find a leader yet
+        return null;
+      }
+      ZkCoreNodeProps zkProps = new ZkCoreNodeProps(leader);
+      String url = zkProps.getCoreUrl();
+      urls.add(url);
+      Collection<Replica> replicas = slice.getReplicas();
+      Iterator<Replica> replicaIterator = replicas.iterator();
+      while (replicaIterator.hasNext()) {
+        Replica replica = replicaIterator.next();
+        if (!replica.getNodeName().equals(leader.getNodeName()) &&
+            !replica.getName().equals(leader.getName())) {
+          ZkCoreNodeProps zkProps1 = new ZkCoreNodeProps(replica);
+          String url1 = zkProps1.getCoreUrl();
+          urls.add(url1);
+        }
+      }
+      urlMap.put(name, urls);
+    }
+    return urlMap;
+  }
+
+  public RouteResponse condenseResponse(NamedList response, long timeMillis) {
+    RouteResponse condensed = new RouteResponse();
+    int status = 0;
+    Integer rf = null;
+    Integer minRf = null;
+    for(int i=0; i<response.size(); i++) {
+      NamedList shardResponse = (NamedList)response.getVal(i);
+      NamedList header = (NamedList)shardResponse.get("responseHeader");      
+      Integer shardStatus = (Integer)header.get("status");
+      int s = shardStatus.intValue();
+      if(s > 0) {
+          status = s;
+      }
+      Object rfObj = header.get(UpdateRequest.REPFACT);
+      if (rfObj != null && rfObj instanceof Integer) {
+        Integer routeRf = (Integer)rfObj;
+        if (rf == null || routeRf < rf)
+          rf = routeRf;
+      }
+      minRf = (Integer)header.get(UpdateRequest.MIN_REPFACT);
+    }
+
+    NamedList cheader = new NamedList();
+    cheader.add("status", status);
+    cheader.add("QTime", timeMillis);
+    if (rf != null)
+      cheader.add(UpdateRequest.REPFACT, rf);
+    if (minRf != null)
+      cheader.add(UpdateRequest.MIN_REPFACT, minRf);
+    
+    condensed.add("responseHeader", cheader);
+    return condensed;
+  }
+
+  public static class RouteResponse extends NamedList {
+    private NamedList routeResponses;
+    private Map<String, LBHttpSolrClient.Req> routes;
+
+    public void setRouteResponses(NamedList routeResponses) {
+      this.routeResponses = routeResponses;
+    }
+
+    public NamedList getRouteResponses() {
+      return routeResponses;
+    }
+
+    public void setRoutes(Map<String, LBHttpSolrClient.Req> routes) {
+      this.routes = routes;
+    }
+
+    public Map<String, LBHttpSolrClient.Req> getRoutes() {
+      return routes;
+    }
+
+  }
+
+  public static class RouteException extends SolrException {
+
+    private NamedList<Throwable> throwables;
+    private Map<String, LBHttpSolrClient.Req> routes;
+
+    public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<String, LBHttpSolrClient.Req> routes){
+      super(errorCode, throwables.getVal(0).getMessage(), throwables.getVal(0));
+      this.throwables = throwables;
+      this.routes = routes;
+    }
+
+    public NamedList<Throwable> getThrowables() {
+      return throwables;
+    }
+
+    public Map<String, LBHttpSolrClient.Req> getRoutes() {
+      return this.routes;
+    }
+  }
+
+  @Override
+  public NamedList<Object> request(SolrRequest request) throws SolrServerException, IOException {
+    SolrParams reqParams = request.getParams();
+    String collection = (reqParams != null) ? reqParams.get("collection", getDefaultCollection()) : getDefaultCollection();
+    return requestWithRetryOnStaleState(request, 0, collection);
+  }
+
+  /**
+   * As this class doesn't watch external collections on the client side,
+   * there's a chance that the request will fail due to cached stale state,
+   * which means the state must be refreshed from ZK and retried.
+   */
+  protected NamedList<Object> requestWithRetryOnStaleState(SolrRequest request, int retryCount, String collection)
+      throws SolrServerException, IOException {
+
+    connect(); // important to call this before you start working with the ZkStateReader
+
+    // build up a _stateVer_ param to pass to the server containing all of the
+    // external collection state versions involved in this request, which allows
+    // the server to notify us that our cached state for one or more of the external
+    // collections is stale and needs to be refreshed ... this code has no impact on internal collections
+    String stateVerParam = null;
+    List<DocCollection> requestedCollections = null;
+    if (collection != null && !request.getPath().startsWith("/admin")) { // don't do _stateVer_ checking for admin requests
+      Set<String> requestedCollectionNames = getCollectionList(getZkStateReader().getClusterState(), collection);
+
+      StringBuilder stateVerParamBuilder = null;
+      for (String requestedCollection : requestedCollectionNames) {
+        // track the version of state we're using on the client side using the _stateVer_ param
+        DocCollection coll = getDocCollection(getZkStateReader().getClusterState(), requestedCollection);
+        int collVer = coll.getZNodeVersion();
+        if (coll.getStateFormat()>1) {
+          if(requestedCollections == null) requestedCollections = new ArrayList<>(requestedCollectionNames.size());
+          requestedCollections.add(coll);
+
+          if (stateVerParamBuilder == null) {
+            stateVerParamBuilder = new StringBuilder();
+          } else {
+            stateVerParamBuilder.append("|"); // hopefully pipe is not an allowed char in a collection name
+          }
+
+          stateVerParamBuilder.append(coll.getName()).append(":").append(collVer);
+        }
+      }
+
+      if (stateVerParamBuilder != null) {
+        stateVerParam = stateVerParamBuilder.toString();
+      }
+    }
+
+    if (request.getParams() instanceof ModifiableSolrParams) {
+      ModifiableSolrParams params = (ModifiableSolrParams) request.getParams();
+      if (stateVerParam != null) {
+        params.set(STATE_VERSION, stateVerParam);
+      } else {
+        params.remove(STATE_VERSION);
+      }
+    } // else: ??? how to set this ???
+
+    NamedList<Object> resp = null;
+    try {
+      resp = sendRequest(request);
+    } catch (Exception exc) {
+
+      Throwable rootCause = SolrException.getRootCause(exc);
+      // don't do retry support for admin requests or if the request doesn't have a collection specified
+      if (collection == null || request.getPath().startsWith("/admin")) {
+        if (exc instanceof SolrServerException) {
+          throw (SolrServerException)exc;
+        } else if (exc instanceof IOException) {
+          throw (IOException)exc;
+        }else if (exc instanceof RuntimeException) {
+          throw (RuntimeException) exc;
+        }
+        else {
+          throw new SolrServerException(rootCause);
+        }
+      }
+
+      int errorCode = (rootCause instanceof SolrException) ?
+          ((SolrException)rootCause).code() : SolrException.ErrorCode.UNKNOWN.code;
+
+      log.error("Request to collection {} failed due to ("+errorCode+
+          ") {}, retry? "+retryCount, collection, rootCause.toString());
+
+      boolean wasCommError =
+          (rootCause instanceof ConnectException ||
+              rootCause instanceof ConnectTimeoutException ||
+              rootCause instanceof NoHttpResponseException ||
+              rootCause instanceof SocketException);
+
+      boolean stateWasStale = false;
+      if (retryCount < MAX_STALE_RETRIES  &&
+          requestedCollections != null    &&
+          !requestedCollections.isEmpty() &&
+          SolrException.ErrorCode.getErrorCode(errorCode) == SolrException.ErrorCode.INVALID_STATE)
+      {
+        // cached state for one or more external collections was stale
+        // re-issue request using updated state
+        stateWasStale = true;
+
+        // just re-read state for all of them, which is a little heavy handed but hopefully a rare occurrence
+        for (DocCollection ext : requestedCollections) {
+          collectionStateCache.remove(ext.getName());
+        }
+      }
+
+      // if we experienced a communication error, it's worth checking the state
+      // with ZK just to make sure the node we're trying to hit is still part of the collection
+      if (retryCount < MAX_STALE_RETRIES &&
+          !stateWasStale &&
+          requestedCollections != null &&
+          !requestedCollections.isEmpty() &&
+          wasCommError) {
+        for (DocCollection ext : requestedCollections) {
+          DocCollection latestStateFromZk = getDocCollection(zkStateReader.getClusterState(), ext.getName());
+          if (latestStateFromZk.getZNodeVersion() != ext.getZNodeVersion()) {
+            // looks like we couldn't reach the server because the state was stale == retry
+            stateWasStale = true;
+            // we just pulled state from ZK, so update the cache so that the retry uses it
+            collectionStateCache.put(ext.getName(), new ExpiringCachedDocCollection(latestStateFromZk));
+          }
+        }
+      }
+
+      if (requestedCollections != null) {
+        requestedCollections.clear(); // done with this
+      }
+
+      // if the state was stale, then we retry the request once with new state pulled from Zk
+      if (stateWasStale) {
+        log.warn("Re-trying request to  collection(s) "+collection+" after stale state error from server.");
+        resp = requestWithRetryOnStaleState(request, retryCount+1, collection);
+      } else {
+        if (exc instanceof SolrServerException) {
+          throw (SolrServerException)exc;
+        } else if (exc instanceof IOException) {
+          throw (IOException)exc;
+        } else {
+          throw new SolrServerException(rootCause);
+        }
+      }
+    }
+
+    return resp;
+  }
+
+  protected NamedList<Object> sendRequest(SolrRequest request)
+      throws SolrServerException, IOException {
+    connect();
+    
+    ClusterState clusterState = zkStateReader.getClusterState();
+    
+    boolean sendToLeaders = false;
+    List<String> replicas = null;
+    
+    if (request instanceof IsUpdateRequest) {
+      if (request instanceof UpdateRequest) {
+        NamedList<Object> response = directUpdate((AbstractUpdateRequest) request,
+            clusterState);
+        if (response != null) {
+          return response;
+        }
+      }
+      sendToLeaders = true;
+      replicas = new ArrayList<>();
+    }
+    
+    SolrParams reqParams = request.getParams();
+    if (reqParams == null) {
+      reqParams = new ModifiableSolrParams();
+    }
+    List<String> theUrlList = new ArrayList<>();
+    if (request.getPath().equals("/admin/collections")
+        || request.getPath().equals("/admin/cores")) {
+      Set<String> liveNodes = clusterState.getLiveNodes();
+      for (String liveNode : liveNodes) {
+        theUrlList.add(zkStateReader.getBaseUrlForNodeName(liveNode));
+      }
+    } else {
+      String collection = reqParams.get(UpdateParams.COLLECTION, defaultCollection);
+      
+      if (collection == null) {
+        throw new SolrServerException(
+            "No collection param specified on request and no default collection has been set.");
+      }
+      
+      Set<String> collectionsList = getCollectionList(clusterState, collection);
+      if (collectionsList.size() == 0) {
+        throw new SolrException(ErrorCode.BAD_REQUEST,
+            "Could not find collection: " + collection);
+      }
+
+      String shardKeys =  reqParams.get(ShardParams._ROUTE_);
+      if(shardKeys == null) {
+        shardKeys = reqParams.get(ShardParams.SHARD_KEYS); // deprecated
+      }
+
+      // TODO: not a big deal because of the caching, but we could avoid looking
+      // at every shard
+      // when getting leaders if we tweaked some things
+      
+      // Retrieve slices from the cloud state and, for each collection
+      // specified,
+      // add it to the Map of slices.
+      Map<String,Slice> slices = new HashMap<>();
+      for (String collectionName : collectionsList) {
+        DocCollection col = getDocCollection(clusterState, collectionName);
+        Collection<Slice> routeSlices = col.getRouter().getSearchSlices(shardKeys, reqParams , col);
+        ClientUtils.addSlices(slices, collectionName, routeSlices, true);
+      }
+      Set<String> liveNodes = clusterState.getLiveNodes();
+
+      List<String> leaderUrlList = null;
+      List<String> urlList = null;
+      List<String> replicasList = null;
+      
+      // build a map of unique nodes
+      // TODO: allow filtering by group, role, etc
+      Map<String,ZkNodeProps> nodes = new HashMap<>();
+      List<String> urlList2 = new ArrayList<>();
+      for (Slice slice : slices.values()) {
+        for (ZkNodeProps nodeProps : slice.getReplicasMap().values()) {
+          ZkCoreNodeProps coreNodeProps = new ZkCoreNodeProps(nodeProps);
+          String node = coreNodeProps.getNodeName();
+          if (!liveNodes.contains(coreNodeProps.getNodeName())
+              || !coreNodeProps.getState().equals(ZkStateReader.ACTIVE)) continue;
+          if (nodes.put(node, nodeProps) == null) {
+            if (!sendToLeaders || (sendToLeaders && coreNodeProps.isLeader())) {
+              String url;
+              if (reqParams.get(UpdateParams.COLLECTION) == null) {
+                url = ZkCoreNodeProps.getCoreUrl(
+                    nodeProps.getStr(ZkStateReader.BASE_URL_PROP),
+                    defaultCollection);
+              } else {
+                url = coreNodeProps.getCoreUrl();
+              }
+              urlList2.add(url);
+            } else if (sendToLeaders) {
+              String url;
+              if (reqParams.get(UpdateParams.COLLECTION) == null) {
+                url = ZkCoreNodeProps.getCoreUrl(
+                    nodeProps.getStr(ZkStateReader.BASE_URL_PROP),
+                    defaultCollection);
+              } else {
+                url = coreNodeProps.getCoreUrl();
+              }
+              replicas.add(url);
+            }
+          }
+        }
+      }
+      
+      if (sendToLeaders) {
+        leaderUrlList = urlList2;
+        replicasList = replicas;
+      } else {
+        urlList = urlList2;
+      }
+      
+      if (sendToLeaders) {
+        theUrlList = new ArrayList<>(leaderUrlList.size());
+        theUrlList.addAll(leaderUrlList);
+      } else {
+        theUrlList = new ArrayList<>(urlList.size());
+        theUrlList.addAll(urlList);
+      }
+      if(theUrlList.isEmpty()) {
+        throw new SolrException(SolrException.ErrorCode.INVALID_STATE, "Not enough nodes to handle the request");
+      }
+
+      Collections.shuffle(theUrlList, rand);
+      if (sendToLeaders) {
+        ArrayList<String> theReplicas = new ArrayList<>(
+            replicasList.size());
+        theReplicas.addAll(replicasList);
+        Collections.shuffle(theReplicas, rand);
+        theUrlList.addAll(theReplicas);
+      }
+      
+    }
+    
+    LBHttpSolrClient.Req req = new LBHttpSolrClient.Req(request, theUrlList);
+    LBHttpSolrClient.Rsp rsp = lbClient.request(req);
+    return rsp.getResponse();
+  }
+
+  private Set<String> getCollectionList(ClusterState clusterState,
+      String collection) {
+    // Extract each comma separated collection name and store in a List.
+    List<String> rawCollectionsList = StrUtils.splitSmart(collection, ",", true);
+    Set<String> collectionsList = new HashSet<>();
+    // validate collections
+    for (String collectionName : rawCollectionsList) {
+      if (!clusterState.getCollections().contains(collectionName)) {
+        Aliases aliases = zkStateReader.getAliases();
+        String alias = aliases.getCollectionAlias(collectionName);
+        if (alias != null) {
+          List<String> aliasList = StrUtils.splitSmart(alias, ",", true);
+          collectionsList.addAll(aliasList);
+          continue;
+        }
+
+          throw new SolrException(ErrorCode.BAD_REQUEST, "Collection not found: " + collectionName);
+        }
+
+      collectionsList.add(collectionName);
+    }
+    return collectionsList;
+  }
+
+  @Override
+  public void shutdown() {
+    if (zkStateReader != null) {
+      synchronized(this) {
+        if (zkStateReader!= null)
+          zkStateReader.close();
+        zkStateReader = null;
+      }
+    }
+    
+    if (shutdownLBHttpSolrServer) {
+      lbClient.shutdown();
+    }
+    
+    if (clientIsInternal && myClient!=null) {
+      myClient.getConnectionManager().shutdown();
+    }
+
+    if(this.threadPool != null && !this.threadPool.isShutdown()) {
+      this.threadPool.shutdown();
+    }
+  }
+
+  public LBHttpSolrClient getLbClient() {
+    return lbClient;
+  }
+  
+  public boolean isUpdatesToLeaders() {
+    return updatesToLeaders;
+  }
+
+  protected DocCollection getDocCollection(ClusterState clusterState, String collection) throws SolrException {
+    ExpiringCachedDocCollection cachedState = collectionStateCache != null ? collectionStateCache.get(collection) : null;
+    if (cachedState != null && cachedState.cached != null) {
+      return cachedState.cached;
+    }
+
+    DocCollection col = clusterState.getCollectionOrNull(collection);
+    if(col == null ) return  null;
+    if(col.getStateFormat() >1) collectionStateCache.put(collection, new ExpiringCachedDocCollection(col));
+    return col;
+  }
+
+
+  /**
+   * Useful for determining the minimum achieved replication factor across
+   * all shards involved in processing an update request, typically useful
+   * for gauging the replication factor of a batch. 
+   */
+  @SuppressWarnings("rawtypes")
+  public int getMinAchievedReplicationFactor(String collection, NamedList resp) {
+    // it's probably already on the top-level header set by condense
+    NamedList header = (NamedList)resp.get("responseHeader");
+    Integer achRf = (Integer)header.get(UpdateRequest.REPFACT);
+    if (achRf != null)
+      return achRf.intValue();
+
+    // not on the top-level header, walk the shard route tree
+    Map<String,Integer> shardRf = getShardReplicationFactor(collection, resp);
+    for (Integer rf : shardRf.values()) {
+      if (achRf == null || rf < achRf) {
+        achRf = rf;
+      }
+    }    
+    return (achRf != null) ? achRf.intValue() : -1;
+  }
+  
+  /**
+   * Walks the NamedList response after performing an update request looking for
+   * the replication factor that was achieved in each shard involved in the request.
+   * For single doc updates, there will be only one shard in the return value. 
+   */
+  @SuppressWarnings("rawtypes")
+  public Map<String,Integer> getShardReplicationFactor(String collection, NamedList resp) {
+    connect();
+    
+    Map<String,Integer> results = new HashMap<String,Integer>();
+    if (resp instanceof CloudSolrClient.RouteResponse) {
+      NamedList routes = ((CloudSolrClient.RouteResponse)resp).getRouteResponses();
+      ClusterState clusterState = zkStateReader.getClusterState();     
+      Map<String,String> leaders = new HashMap<String,String>();
+      for (Slice slice : clusterState.getActiveSlices(collection)) {
+        Replica leader = slice.getLeader();
+        if (leader != null) {
+          ZkCoreNodeProps zkProps = new ZkCoreNodeProps(leader);
+          String leaderUrl = zkProps.getBaseUrl() + "/" + zkProps.getCoreName();
+          leaders.put(leaderUrl, slice.getName());
+          String altLeaderUrl = zkProps.getBaseUrl() + "/" + collection;
+          leaders.put(altLeaderUrl, slice.getName());
+        }
+      }
+      
+      Iterator<Map.Entry<String,Object>> routeIter = routes.iterator();
+      while (routeIter.hasNext()) {
+        Map.Entry<String,Object> next = routeIter.next();
+        String host = next.getKey();
+        NamedList hostResp = (NamedList)next.getValue();
+        Integer rf = (Integer)((NamedList)hostResp.get("responseHeader")).get(UpdateRequest.REPFACT);
+        if (rf != null) {
+          String shard = leaders.get(host);
+          if (shard == null) {
+            if (host.endsWith("/"))
+              shard = leaders.get(host.substring(0,host.length()-1));
+            if (shard == null) {
+              shard = host;
+            }
+          }
+          results.put(shard, rf);
+        }
+      }
+    }    
+    return results;
+  }
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
index 1df84ee..4e2a2e7 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/CloudSolrServer.java
@@ -1,5 +1,3 @@
-package org.apache.solr.client.solrj.impl;
-
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -17,1140 +15,47 @@ package org.apache.solr.client.solrj.impl;
  * limitations under the License.
  */
 
-import java.io.IOException;
-import java.net.ConnectException;
-import java.net.SocketException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeoutException;
+package org.apache.solr.client.solrj.impl;
 
-import org.apache.http.NoHttpResponseException;
 import org.apache.http.client.HttpClient;
-import org.apache.http.conn.ConnectTimeoutException;
-import org.apache.solr.client.solrj.ResponseParser;
-import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
-import org.apache.solr.client.solrj.request.IsUpdateRequest;
-import org.apache.solr.client.solrj.request.RequestWriter;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.util.ClientUtils;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.cloud.Aliases;
-import org.apache.solr.common.cloud.ClusterState;
-import org.apache.solr.common.cloud.DocCollection;
-import org.apache.solr.common.cloud.DocRouter;
-import org.apache.solr.common.cloud.ImplicitDocRouter;
-import org.apache.solr.common.cloud.Replica;
-import org.apache.solr.common.cloud.Slice;
-import org.apache.solr.common.cloud.ZkCoreNodeProps;
-import org.apache.solr.common.cloud.ZkNodeProps;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.common.cloud.ZooKeeperException;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.ShardParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.params.UpdateParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.apache.solr.common.util.StrUtils;
-import org.apache.zookeeper.KeeperException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+
+import java.util.Collection;
 
 /**
- * SolrJ client class to communicate with SolrCloud.
- * Instances of this class communicate with Zookeeper to discover
- * Solr endpoints for SolrCloud collections, and then use the 
- * {@link LBHttpSolrServer} to issue requests.
- * 
- * This class assumes the id field for your documents is called
- * 'id' - if this is not the case, you must set the right name
- * with {@link #setIdField(String)}.
+ * @deprecated Use {@link org.apache.solr.client.solrj.impl.CloudSolrClient}
  */
-@SuppressWarnings("serial")
-public class CloudSolrServer extends SolrServer {
-  protected static final Logger log = LoggerFactory.getLogger(CloudSolrServer.class);
-
-  private volatile ZkStateReader zkStateReader;
-  private String zkHost; // the zk server connect string
-  private int zkConnectTimeout = 10000;
-  private int zkClientTimeout = 10000;
-  private volatile String defaultCollection;
-  private final LBHttpSolrServer lbServer;
-  private final boolean shutdownLBHttpSolrServer;
-  private HttpClient myClient;
-  private final boolean clientIsInternal;
-  //no of times collection state to be reloaded if stale state error is received
-  private static final int MAX_STALE_RETRIES = 5;
-  Random rand = new Random();
-  
-  private final boolean updatesToLeaders;
-  private boolean parallelUpdates = true;
-  private ExecutorService threadPool = Executors
-      .newCachedThreadPool(new SolrjNamedThreadFactory(
-          "CloudSolrServer ThreadPool"));
-  private String idField = "id";
-  public static final String STATE_VERSION = "_stateVer_";
-  private final Set<String> NON_ROUTABLE_PARAMS;
-  {
-    NON_ROUTABLE_PARAMS = new HashSet<>();
-    NON_ROUTABLE_PARAMS.add(UpdateParams.EXPUNGE_DELETES);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.MAX_OPTIMIZE_SEGMENTS);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.COMMIT);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.WAIT_SEARCHER);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.OPEN_SEARCHER);
-    
-    NON_ROUTABLE_PARAMS.add(UpdateParams.SOFT_COMMIT);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.PREPARE_COMMIT);
-    NON_ROUTABLE_PARAMS.add(UpdateParams.OPTIMIZE);
-    
-    // Not supported via SolrCloud
-    // NON_ROUTABLE_PARAMS.add(UpdateParams.ROLLBACK);
-
-  }
-  private volatile long timeToLive = 60* 1000L;
-
-
-  protected Map<String, ExpiringCachedDocCollection> collectionStateCache = new ConcurrentHashMap<String, ExpiringCachedDocCollection>(){
-    @Override
-    public ExpiringCachedDocCollection get(Object key) {
-      ExpiringCachedDocCollection val = super.get(key);
-      if(val == null) return null;
-      if(val.isExpired(timeToLive)) {
-        super.remove(key);
-        return null;
-      }
-      return val;
-    }
-
-  };
-
-  class ExpiringCachedDocCollection {
-    DocCollection cached;
-    long cachedAt;
-
-    ExpiringCachedDocCollection(DocCollection cached) {
-      this.cached = cached;
-      this.cachedAt = System.currentTimeMillis();
-    }
-
-    boolean isExpired(long timeToLive) {
-      return (System.currentTimeMillis() - cachedAt) > timeToLive;
-    }
-  }
+@Deprecated
+public class CloudSolrServer extends CloudSolrClient {
 
-  /**
-   * Create a new client object that connects to Zookeeper and is always aware
-   * of the SolrCloud state. If there is a fully redundant Zookeeper quorum and
-   * SolrCloud has enough replicas for every shard in a collection, there is no
-   * single point of failure. Updates will be sent to shard leaders by default.
-   * 
-   * @param zkHost
-   *          The client endpoint of the zookeeper quorum containing the cloud
-   *          state. The full specification for this string is one or more comma
-   *          separated HOST:PORT values, followed by an optional chroot value
-   *          that starts with a forward slash. Using a chroot allows multiple
-   *          applications to coexist in one ensemble. For full details, see the
-   *          Zookeeper documentation. Some examples:
-   *          <p/>
-   *          "host1:2181"
-   *          <p/>
-   *          "host1:2181,host2:2181,host3:2181/mysolrchroot"
-   *          <p/>
-   *          "zoo1.example.com:2181,zoo2.example.com:2181,zoo3.example.com:2181"
-   */
   public CloudSolrServer(String zkHost) {
-      this.zkHost = zkHost;
-      this.clientIsInternal = true;
-      this.myClient = HttpClientUtil.createClient(null);
-      this.lbServer = new LBHttpSolrServer(myClient);
-      this.lbServer.setRequestWriter(new BinaryRequestWriter());
-      this.lbServer.setParser(new BinaryResponseParser());
-      this.updatesToLeaders = true;
-      shutdownLBHttpSolrServer = true;
-      lbServer.addQueryParams(STATE_VERSION);
+    super(zkHost);
   }
 
-  /**
-   * Create a new client object that connects to Zookeeper and is always aware
-   * of the SolrCloud state. If there is a fully redundant Zookeeper quorum and
-   * SolrCloud has enough replicas for every shard in a collection, there is no
-   * single point of failure. Updates will be sent to shard leaders by default.
-   *
-   * @param zkHost
-   *          The client endpoint of the zookeeper quorum containing the cloud
-   *          state. The full specification for this string is one or more comma
-   *          separated HOST:PORT values, followed by an optional chroot value
-   *          that starts with a forward slash. Using a chroot allows multiple
-   *          applications to coexist in one ensemble. For full details, see the
-   *          Zookeeper documentation. Some examples:
-   *          <p/>
-   *          "host1:2181"
-   *          <p/>
-   *          "host1:2181,host2:2181,host3:2181/mysolrchroot"
-   *          <p/>
-   *          "zoo1.example.com:2181,zoo2.example.com:2181,zoo3.example.com:2181"
-   * @param httpClient
-   *          the {@link HttpClient} instance to be used for all requests. The
-   *          provided httpClient should use a multi-threaded connection manager.
-   */
-  public CloudSolrServer(String zkHost, HttpClient httpClient)  {
-    this.zkHost = zkHost;
-    this.clientIsInternal = httpClient == null;
-    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
-    this.lbServer = new LBHttpSolrServer(myClient);
-    this.lbServer.setRequestWriter(new BinaryRequestWriter());
-    this.lbServer.setParser(new BinaryResponseParser());
-    this.updatesToLeaders = true;
-    shutdownLBHttpSolrServer = true;
-    lbServer.addQueryParams(STATE_VERSION);
+  public CloudSolrServer(String zkHost, HttpClient httpClient) {
+    super(zkHost, httpClient);
   }
-  
-  /**
-   * Create a new client object using multiple string values in a Collection
-   * instead of a standard zkHost connection string. Note that this method will
-   * not be used if there is only one String argument - that will use
-   * {@link #CloudSolrServer(String)} instead.
-   * 
-   * @param zkHosts
-   *          A Java Collection (List, Set, etc) of HOST:PORT strings, one for
-   *          each host in the zookeeper ensemble. Note that with certain
-   *          Collection types like HashSet, the order of hosts in the final
-   *          connect string may not be in the same order you added them.
-   * @param chroot
-   *          A chroot value for zookeeper, starting with a forward slash. If no
-   *          chroot is required, use null.
-   * @throws IllegalArgumentException
-   *           if the chroot value does not start with a forward slash.
-   * @see #CloudSolrServer(String)
-   */
+
   public CloudSolrServer(Collection<String> zkHosts, String chroot) {
-    this(zkHosts, chroot, null);
+    super(zkHosts, chroot);
   }
 
-  /**
-   * Create a new client object using multiple string values in a Collection
-   * instead of a standard zkHost connection string. Note that this method will
-   * not be used if there is only one String argument - that will use
-   * {@link #CloudSolrServer(String)} instead.
-   *
-   * @param zkHosts
-   *          A Java Collection (List, Set, etc) of HOST:PORT strings, one for
-   *          each host in the zookeeper ensemble. Note that with certain
-   *          Collection types like HashSet, the order of hosts in the final
-   *          connect string may not be in the same order you added them.
-   * @param chroot
-   *          A chroot value for zookeeper, starting with a forward slash. If no
-   *          chroot is required, use null.
-   * @param httpClient
-   *          the {@link HttpClient} instance to be used for all requests. The provided httpClient should use a
-   *          multi-threaded connection manager.
-   * @throws IllegalArgumentException
-   *           if the chroot value does not start with a forward slash.
-   * @see #CloudSolrServer(String)
-   */
   public CloudSolrServer(Collection<String> zkHosts, String chroot, HttpClient httpClient) {
-    StringBuilder zkBuilder = new StringBuilder();
-    int lastIndexValue = zkHosts.size() - 1;
-    int i = 0;
-    for (String zkHost : zkHosts) {
-      zkBuilder.append(zkHost);
-      if (i < lastIndexValue) {
-        zkBuilder.append(",");
-      }
-      i++;
-    }
-    if (chroot != null) {
-      if (chroot.startsWith("/")) {
-        zkBuilder.append(chroot);
-      } else {
-        throw new IllegalArgumentException(
-            "The chroot must start with a forward slash.");
-      }
-    }
-
-    /* Log the constructed connection string and then initialize. */
-    log.info("Final constructed zkHost string: " + zkBuilder.toString());
-
-    this.zkHost = zkBuilder.toString();
-    this.clientIsInternal = httpClient == null;
-    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
-    this.lbServer = new LBHttpSolrServer(myClient);
-    this.lbServer.setRequestWriter(new BinaryRequestWriter());
-    this.lbServer.setParser(new BinaryResponseParser());
-    this.updatesToLeaders = true;
-    shutdownLBHttpSolrServer = true;
+    super(zkHosts, chroot, httpClient);
   }
-  
-  /**
-   * @param zkHost
-   *          A zookeeper client endpoint.
-   * @param updatesToLeaders
-   *          If true, sends updates only to shard leaders.
-   * @see #CloudSolrServer(String) for full description and details on zkHost
-   */
+
   public CloudSolrServer(String zkHost, boolean updatesToLeaders) {
-    this(zkHost, updatesToLeaders, null);
+    super(zkHost, updatesToLeaders);
   }
 
-  /**
-   * @param zkHost
-   *          A zookeeper client endpoint.
-   * @param updatesToLeaders
-   *          If true, sends updates only to shard leaders.
-   * @param httpClient
-   *          the {@link HttpClient} instance to be used for all requests. The provided httpClient should use a
-   *          multi-threaded connection manager.
-   * @see #CloudSolrServer(String) for full description and details on zkHost
-   */
   public CloudSolrServer(String zkHost, boolean updatesToLeaders, HttpClient httpClient) {
-    this.zkHost = zkHost;
-    this.clientIsInternal = httpClient == null;
-    this.myClient = httpClient == null ? HttpClientUtil.createClient(null) : httpClient;
-    this.lbServer = new LBHttpSolrServer(myClient);
-    this.lbServer.setRequestWriter(new BinaryRequestWriter());
-    this.lbServer.setParser(new BinaryResponseParser());
-    this.updatesToLeaders = updatesToLeaders;
-    shutdownLBHttpSolrServer = true;
-    lbServer.addQueryParams(STATE_VERSION);
-  }
-
-  /**Sets the cache ttl for DocCollection Objects cached  . This is only applicable for collections which are persisted outside of clusterstate.json
-   * @param seconds ttl value in seconds
-   */
-  public void setCollectionCacheTTl(int seconds){
-    assert seconds > 0;
-    timeToLive = seconds*1000L;
-  }
-
-  /**
-   * @param zkHost
-   *          A zookeeper client endpoint.
-   * @param lbServer
-   *          LBHttpSolrServer instance for requests.
-   * @see #CloudSolrServer(String) for full description and details on zkHost
-   */
-  public CloudSolrServer(String zkHost, LBHttpSolrServer lbServer) {
-    this(zkHost, lbServer, true);
-  }
-  
-  /**
-   * @param zkHost
-   *          A zookeeper client endpoint.
-   * @param lbServer
-   *          LBHttpSolrServer instance for requests.
-   * @param updatesToLeaders
-   *          If true, sends updates only to shard leaders.
-   * @see #CloudSolrServer(String) for full description and details on zkHost
-   */
-  public CloudSolrServer(String zkHost, LBHttpSolrServer lbServer, boolean updatesToLeaders) {
-    this.zkHost = zkHost;
-    this.lbServer = lbServer;
-    this.updatesToLeaders = updatesToLeaders;
-    shutdownLBHttpSolrServer = false;
-    this.clientIsInternal = false;
-    lbServer.addQueryParams(STATE_VERSION);
-  }
-  
-  public ResponseParser getParser() {
-    return lbServer.getParser();
-  }
-  
-  /**
-   * Note: This setter method is <b>not thread-safe</b>.
-   * 
-   * @param processor
-   *          Default Response Parser chosen to parse the response if the parser
-   *          were not specified as part of the request.
-   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
-   */
-  public void setParser(ResponseParser processor) {
-    lbServer.setParser(processor);
-  }
-  
-  public RequestWriter getRequestWriter() {
-    return lbServer.getRequestWriter();
-  }
-  
-  public void setRequestWriter(RequestWriter requestWriter) {
-    lbServer.setRequestWriter(requestWriter);
-  }
-
-  /**
-   * @return the zkHost value used to connect to zookeeper.
-   */
-  public String getZkHost() {
-    return zkHost;
-  }
-
-  public ZkStateReader getZkStateReader() {
-    return zkStateReader;
-  }
-
-  /**
-   * @param idField the field to route documents on.
-   */
-  public void setIdField(String idField) {
-    this.idField = idField;
-  }
-
-  /**
-   * @return the field that updates are routed on.
-   */
-  public String getIdField() {
-    return idField;
-  }
-  
-  /** Sets the default collection for request */
-  public void setDefaultCollection(String collection) {
-    this.defaultCollection = collection;
-  }
-
-  /** Gets the default collection for request */
-  public String getDefaultCollection() {
-    return defaultCollection;
-  }
-
-  /** Set the connect timeout to the zookeeper ensemble in ms */
-  public void setZkConnectTimeout(int zkConnectTimeout) {
-    this.zkConnectTimeout = zkConnectTimeout;
-  }
-
-  /** Set the timeout to the zookeeper ensemble in ms */
-  public void setZkClientTimeout(int zkClientTimeout) {
-    this.zkClientTimeout = zkClientTimeout;
-  }
-
-  /**
-   * Connect to the zookeeper ensemble.
-   * This is an optional method that may be used to force a connect before any other requests are sent.
-   *
-   */
-  public void connect() {
-    if (zkStateReader == null) {
-      synchronized (this) {
-        if (zkStateReader == null) {
-          ZkStateReader zk = null;
-          try {
-            zk = new ZkStateReader(zkHost, zkClientTimeout,
-                zkConnectTimeout);
-            zk.createClusterStateWatchersAndUpdate();
-            zkStateReader = zk;
-          } catch (InterruptedException e) {
-            if (zk != null) zk.close();
-            Thread.currentThread().interrupt();
-            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
-                "", e);
-          } catch (KeeperException e) {
-            if (zk != null) zk.close();
-            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
-                "", e);
-          } catch (IOException e) {
-            if (zk != null) zk.close();
-            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
-                "", e);
-          } catch (TimeoutException e) {
-            if (zk != null) zk.close();
-            throw new ZooKeeperException(SolrException.ErrorCode.SERVER_ERROR,
-                "", e);
-          } catch (Exception e) {
-            if (zk != null) zk.close();
-            // do not wrap because clients may be relying on the underlying exception being thrown
-            throw e;
-          }
-        }
-      }
-    }
-  }
-
-  public void setParallelUpdates(boolean parallelUpdates) {
-    this.parallelUpdates = parallelUpdates;
-  }
-
-  private NamedList<Object> directUpdate(AbstractUpdateRequest request, ClusterState clusterState) throws SolrServerException {
-    UpdateRequest updateRequest = (UpdateRequest) request;
-    ModifiableSolrParams params = (ModifiableSolrParams) request.getParams();
-    ModifiableSolrParams routableParams = new ModifiableSolrParams();
-    ModifiableSolrParams nonRoutableParams = new ModifiableSolrParams();
-
-    if(params != null) {
-      nonRoutableParams.add(params);
-      routableParams.add(params);
-      for(String param : NON_ROUTABLE_PARAMS) {
-        routableParams.remove(param);
-      }
-    }
-
-    String collection = nonRoutableParams.get(UpdateParams.COLLECTION, defaultCollection);
-    if (collection == null) {
-      throw new SolrServerException("No collection param specified on request and no default collection has been set.");
-    }
-
-
-    //Check to see if the collection is an alias.
-    Aliases aliases = zkStateReader.getAliases();
-    if(aliases != null) {
-      Map<String, String> collectionAliases = aliases.getCollectionAliasMap();
-      if(collectionAliases != null && collectionAliases.containsKey(collection)) {
-        collection = collectionAliases.get(collection);
-      }
-    }
-
-    DocCollection col = getDocCollection(clusterState, collection);
-
-    DocRouter router = col.getRouter();
-    
-    if (router instanceof ImplicitDocRouter) {
-      // short circuit as optimization
-      return null;
-    }
-
-    //Create the URL map, which is keyed on slice name.
-    //The value is a list of URLs for each replica in the slice.
-    //The first value in the list is the leader for the slice.
-    Map<String,List<String>> urlMap = buildUrlMap(col);
-    if (urlMap == null) {
-      // we could not find a leader yet - use unoptimized general path
-      return null;
-    }
-
-    NamedList<Throwable> exceptions = new NamedList<>();
-    NamedList<NamedList> shardResponses = new NamedList<>();
-
-    Map<String, LBHttpSolrServer.Req> routes = updateRequest.getRoutes(router, col, urlMap, routableParams, this.idField);
-    if (routes == null) {
-      return null;
-    }
-
-    long start = System.nanoTime();
-
-    if (parallelUpdates) {
-      final Map<String, Future<NamedList<?>>> responseFutures = new HashMap<>(routes.size());
-      for (final Map.Entry<String, LBHttpSolrServer.Req> entry : routes.entrySet()) {
-        final String url = entry.getKey();
-        final LBHttpSolrServer.Req lbRequest = entry.getValue();
-        responseFutures.put(url, threadPool.submit(new Callable<NamedList<?>>() {
-          @Override
-          public NamedList<?> call() throws Exception {
-            return lbServer.request(lbRequest).getResponse();
-          }
-        }));
-      }
-
-      for (final Map.Entry<String, Future<NamedList<?>>> entry: responseFutures.entrySet()) {
-        final String url = entry.getKey();
-        final Future<NamedList<?>> responseFuture = entry.getValue();
-        try {
-          shardResponses.add(url, responseFuture.get());
-        } catch (InterruptedException e) {
-          Thread.currentThread().interrupt();
-          throw new RuntimeException(e);
-        } catch (ExecutionException e) {
-          exceptions.add(url, e.getCause());
-        }
-      }
-
-      if (exceptions.size() > 0) {
-        throw new RouteException(ErrorCode.SERVER_ERROR, exceptions, routes);
-      }
-    } else {
-      for (Map.Entry<String, LBHttpSolrServer.Req> entry : routes.entrySet()) {
-        String url = entry.getKey();
-        LBHttpSolrServer.Req lbRequest = entry.getValue();
-        try {
-          NamedList<Object> rsp = lbServer.request(lbRequest).getResponse();
-          shardResponses.add(url, rsp);
-        } catch (Exception e) {
-          throw new SolrServerException(e);
-        }
-      }
-    }
-
-    UpdateRequest nonRoutableRequest = null;
-    List<String> deleteQuery = updateRequest.getDeleteQuery();
-    if (deleteQuery != null && deleteQuery.size() > 0) {
-      UpdateRequest deleteQueryRequest = new UpdateRequest();
-      deleteQueryRequest.setDeleteQuery(deleteQuery);
-      nonRoutableRequest = deleteQueryRequest;
-    }
-    
-    Set<String> paramNames = nonRoutableParams.getParameterNames();
-    
-    Set<String> intersection = new HashSet<>(paramNames);
-    intersection.retainAll(NON_ROUTABLE_PARAMS);
-    
-    if (nonRoutableRequest != null || intersection.size() > 0) {
-      if (nonRoutableRequest == null) {
-        nonRoutableRequest = new UpdateRequest();
-      }
-      nonRoutableRequest.setParams(nonRoutableParams);
-      List<String> urlList = new ArrayList<>();
-      urlList.addAll(routes.keySet());
-      Collections.shuffle(urlList, rand);
-      LBHttpSolrServer.Req req = new LBHttpSolrServer.Req(nonRoutableRequest, urlList);
-      try {
-        LBHttpSolrServer.Rsp rsp = lbServer.request(req);
-        shardResponses.add(urlList.get(0), rsp.getResponse());
-      } catch (Exception e) {
-        throw new SolrException(ErrorCode.SERVER_ERROR, urlList.get(0), e);
-      }
-    }
-
-    long end = System.nanoTime();
-
-    RouteResponse rr =  condenseResponse(shardResponses, (long)((end - start)/1000000));
-    rr.setRouteResponses(shardResponses);
-    rr.setRoutes(routes);
-    return rr;
-  }
-
-  private Map<String,List<String>> buildUrlMap(DocCollection col) {
-    Map<String, List<String>> urlMap = new HashMap<>();
-    Collection<Slice> slices = col.getActiveSlices();
-    Iterator<Slice> sliceIterator = slices.iterator();
-    while (sliceIterator.hasNext()) {
-      Slice slice = sliceIterator.next();
-      String name = slice.getName();
-      List<String> urls = new ArrayList<>();
-      Replica leader = slice.getLeader();
-      if (leader == null) {
-        // take unoptimized general path - we cannot find a leader yet
-        return null;
-      }
-      ZkCoreNodeProps zkProps = new ZkCoreNodeProps(leader);
-      String url = zkProps.getCoreUrl();
-      urls.add(url);
-      Collection<Replica> replicas = slice.getReplicas();
-      Iterator<Replica> replicaIterator = replicas.iterator();
-      while (replicaIterator.hasNext()) {
-        Replica replica = replicaIterator.next();
-        if (!replica.getNodeName().equals(leader.getNodeName()) &&
-            !replica.getName().equals(leader.getName())) {
-          ZkCoreNodeProps zkProps1 = new ZkCoreNodeProps(replica);
-          String url1 = zkProps1.getCoreUrl();
-          urls.add(url1);
-        }
-      }
-      urlMap.put(name, urls);
-    }
-    return urlMap;
-  }
-
-  public RouteResponse condenseResponse(NamedList response, long timeMillis) {
-    RouteResponse condensed = new RouteResponse();
-    int status = 0;
-    Integer rf = null;
-    Integer minRf = null;
-    for(int i=0; i<response.size(); i++) {
-      NamedList shardResponse = (NamedList)response.getVal(i);
-      NamedList header = (NamedList)shardResponse.get("responseHeader");      
-      Integer shardStatus = (Integer)header.get("status");
-      int s = shardStatus.intValue();
-      if(s > 0) {
-          status = s;
-      }
-      Object rfObj = header.get(UpdateRequest.REPFACT);
-      if (rfObj != null && rfObj instanceof Integer) {
-        Integer routeRf = (Integer)rfObj;
-        if (rf == null || routeRf < rf)
-          rf = routeRf;
-      }
-      minRf = (Integer)header.get(UpdateRequest.MIN_REPFACT);
-    }
-
-    NamedList cheader = new NamedList();
-    cheader.add("status", status);
-    cheader.add("QTime", timeMillis);
-    if (rf != null)
-      cheader.add(UpdateRequest.REPFACT, rf);
-    if (minRf != null)
-      cheader.add(UpdateRequest.MIN_REPFACT, minRf);
-    
-    condensed.add("responseHeader", cheader);
-    return condensed;
-  }
-
-  public static class RouteResponse extends NamedList {
-    private NamedList routeResponses;
-    private Map<String, LBHttpSolrServer.Req> routes;
-
-    public void setRouteResponses(NamedList routeResponses) {
-      this.routeResponses = routeResponses;
-    }
-
-    public NamedList getRouteResponses() {
-      return routeResponses;
-    }
-
-    public void setRoutes(Map<String, LBHttpSolrServer.Req> routes) {
-      this.routes = routes;
-    }
-
-    public Map<String, LBHttpSolrServer.Req> getRoutes() {
-      return routes;
-    }
-
-  }
-
-  public static class RouteException extends SolrException {
-
-    private NamedList<Throwable> throwables;
-    private Map<String, LBHttpSolrServer.Req> routes;
-
-    public RouteException(ErrorCode errorCode, NamedList<Throwable> throwables, Map<String, LBHttpSolrServer.Req> routes){
-      super(errorCode, throwables.getVal(0).getMessage(), throwables.getVal(0));
-      this.throwables = throwables;
-      this.routes = routes;
-    }
-
-    public NamedList<Throwable> getThrowables() {
-      return throwables;
-    }
-
-    public Map<String, LBHttpSolrServer.Req> getRoutes() {
-      return this.routes;
-    }
+    super(zkHost, updatesToLeaders, httpClient);
   }
 
-  @Override
-  public NamedList<Object> request(SolrRequest request) throws SolrServerException, IOException {
-    SolrParams reqParams = request.getParams();
-    String collection = (reqParams != null) ? reqParams.get("collection", getDefaultCollection()) : getDefaultCollection();
-    return requestWithRetryOnStaleState(request, 0, collection);
+  public CloudSolrServer(String zkHost, LBHttpSolrClient lbClient) {
+    super(zkHost, lbClient);
   }
 
-  /**
-   * As this class doesn't watch external collections on the client side,
-   * there's a chance that the request will fail due to cached stale state,
-   * which means the state must be refreshed from ZK and retried.
-   */
-  protected NamedList<Object> requestWithRetryOnStaleState(SolrRequest request, int retryCount, String collection)
-      throws SolrServerException, IOException {
-
-    connect(); // important to call this before you start working with the ZkStateReader
-
-    // build up a _stateVer_ param to pass to the server containing all of the
-    // external collection state versions involved in this request, which allows
-    // the server to notify us that our cached state for one or more of the external
-    // collections is stale and needs to be refreshed ... this code has no impact on internal collections
-    String stateVerParam = null;
-    List<DocCollection> requestedCollections = null;
-    if (collection != null && !request.getPath().startsWith("/admin")) { // don't do _stateVer_ checking for admin requests
-      Set<String> requestedCollectionNames = getCollectionList(getZkStateReader().getClusterState(), collection);
-
-      StringBuilder stateVerParamBuilder = null;
-      for (String requestedCollection : requestedCollectionNames) {
-        // track the version of state we're using on the client side using the _stateVer_ param
-        DocCollection coll = getDocCollection(getZkStateReader().getClusterState(), requestedCollection);
-        int collVer = coll.getZNodeVersion();
-        if (coll.getStateFormat()>1) {
-          if(requestedCollections == null) requestedCollections = new ArrayList<>(requestedCollectionNames.size());
-          requestedCollections.add(coll);
-
-          if (stateVerParamBuilder == null) {
-            stateVerParamBuilder = new StringBuilder();
-          } else {
-            stateVerParamBuilder.append("|"); // hopefully pipe is not an allowed char in a collection name
-          }
-
-          stateVerParamBuilder.append(coll.getName()).append(":").append(collVer);
-        }
-      }
-
-      if (stateVerParamBuilder != null) {
-        stateVerParam = stateVerParamBuilder.toString();
-      }
-    }
-
-    if (request.getParams() instanceof ModifiableSolrParams) {
-      ModifiableSolrParams params = (ModifiableSolrParams) request.getParams();
-      if (stateVerParam != null) {
-        params.set(STATE_VERSION, stateVerParam);
-      } else {
-        params.remove(STATE_VERSION);
-      }
-    } // else: ??? how to set this ???
-
-    NamedList<Object> resp = null;
-    try {
-      resp = sendRequest(request);
-    } catch (Exception exc) {
-
-      Throwable rootCause = SolrException.getRootCause(exc);
-      // don't do retry support for admin requests or if the request doesn't have a collection specified
-      if (collection == null || request.getPath().startsWith("/admin")) {
-        if (exc instanceof SolrServerException) {
-          throw (SolrServerException)exc;
-        } else if (exc instanceof IOException) {
-          throw (IOException)exc;
-        }else if (exc instanceof RuntimeException) {
-          throw (RuntimeException) exc;
-        }
-        else {
-          throw new SolrServerException(rootCause);
-        }
-      }
-
-      int errorCode = (rootCause instanceof SolrException) ?
-          ((SolrException)rootCause).code() : SolrException.ErrorCode.UNKNOWN.code;
-
-      log.error("Request to collection {} failed due to ("+errorCode+
-          ") {}, retry? "+retryCount, collection, rootCause.toString());
-
-      boolean wasCommError =
-          (rootCause instanceof ConnectException ||
-              rootCause instanceof ConnectTimeoutException ||
-              rootCause instanceof NoHttpResponseException ||
-              rootCause instanceof SocketException);
-
-      boolean stateWasStale = false;
-      if (retryCount < MAX_STALE_RETRIES  &&
-          requestedCollections != null    &&
-          !requestedCollections.isEmpty() &&
-          SolrException.ErrorCode.getErrorCode(errorCode) == SolrException.ErrorCode.INVALID_STATE)
-      {
-        // cached state for one or more external collections was stale
-        // re-issue request using updated state
-        stateWasStale = true;
-
-        // just re-read state for all of them, which is a little heavy handed but hopefully a rare occurrence
-        for (DocCollection ext : requestedCollections) {
-          collectionStateCache.remove(ext.getName());
-        }
-      }
-
-      // if we experienced a communication error, it's worth checking the state
-      // with ZK just to make sure the node we're trying to hit is still part of the collection
-      if (retryCount < MAX_STALE_RETRIES &&
-          !stateWasStale &&
-          requestedCollections != null &&
-          !requestedCollections.isEmpty() &&
-          wasCommError) {
-        for (DocCollection ext : requestedCollections) {
-          DocCollection latestStateFromZk = getDocCollection(zkStateReader.getClusterState(), ext.getName());
-          if (latestStateFromZk.getZNodeVersion() != ext.getZNodeVersion()) {
-            // looks like we couldn't reach the server because the state was stale == retry
-            stateWasStale = true;
-            // we just pulled state from ZK, so update the cache so that the retry uses it
-            collectionStateCache.put(ext.getName(), new ExpiringCachedDocCollection(latestStateFromZk));
-          }
-        }
-      }
-
-      if (requestedCollections != null) {
-        requestedCollections.clear(); // done with this
-      }
-
-      // if the state was stale, then we retry the request once with new state pulled from Zk
-      if (stateWasStale) {
-        log.warn("Re-trying request to  collection(s) "+collection+" after stale state error from server.");
-        resp = requestWithRetryOnStaleState(request, retryCount+1, collection);
-      } else {
-        if (exc instanceof SolrServerException) {
-          throw (SolrServerException)exc;
-        } else if (exc instanceof IOException) {
-          throw (IOException)exc;
-        } else {
-          throw new SolrServerException(rootCause);
-        }
-      }
-    }
-
-    return resp;
-  }
-
-  protected NamedList<Object> sendRequest(SolrRequest request)
-      throws SolrServerException, IOException {
-    connect();
-    
-    ClusterState clusterState = zkStateReader.getClusterState();
-    
-    boolean sendToLeaders = false;
-    List<String> replicas = null;
-    
-    if (request instanceof IsUpdateRequest) {
-      if (request instanceof UpdateRequest) {
-        NamedList<Object> response = directUpdate((AbstractUpdateRequest) request,
-            clusterState);
-        if (response != null) {
-          return response;
-        }
-      }
-      sendToLeaders = true;
-      replicas = new ArrayList<>();
-    }
-    
-    SolrParams reqParams = request.getParams();
-    if (reqParams == null) {
-      reqParams = new ModifiableSolrParams();
-    }
-    List<String> theUrlList = new ArrayList<>();
-    if (request.getPath().equals("/admin/collections")
-        || request.getPath().equals("/admin/cores")) {
-      Set<String> liveNodes = clusterState.getLiveNodes();
-      for (String liveNode : liveNodes) {
-        theUrlList.add(zkStateReader.getBaseUrlForNodeName(liveNode));
-      }
-    } else {
-      String collection = reqParams.get(UpdateParams.COLLECTION, defaultCollection);
-      
-      if (collection == null) {
-        throw new SolrServerException(
-            "No collection param specified on request and no default collection has been set.");
-      }
-      
-      Set<String> collectionsList = getCollectionList(clusterState, collection);
-      if (collectionsList.size() == 0) {
-        throw new SolrException(ErrorCode.BAD_REQUEST,
-            "Could not find collection: " + collection);
-      }
-
-      String shardKeys =  reqParams.get(ShardParams._ROUTE_);
-      if(shardKeys == null) {
-        shardKeys = reqParams.get(ShardParams.SHARD_KEYS); // deprecated
-      }
-
-      // TODO: not a big deal because of the caching, but we could avoid looking
-      // at every shard
-      // when getting leaders if we tweaked some things
-      
-      // Retrieve slices from the cloud state and, for each collection
-      // specified,
-      // add it to the Map of slices.
-      Map<String,Slice> slices = new HashMap<>();
-      for (String collectionName : collectionsList) {
-        DocCollection col = getDocCollection(clusterState, collectionName);
-        Collection<Slice> routeSlices = col.getRouter().getSearchSlices(shardKeys, reqParams , col);
-        ClientUtils.addSlices(slices, collectionName, routeSlices, true);
-      }
-      Set<String> liveNodes = clusterState.getLiveNodes();
-
-      List<String> leaderUrlList = null;
-      List<String> urlList = null;
-      List<String> replicasList = null;
-      
-      // build a map of unique nodes
-      // TODO: allow filtering by group, role, etc
-      Map<String,ZkNodeProps> nodes = new HashMap<>();
-      List<String> urlList2 = new ArrayList<>();
-      for (Slice slice : slices.values()) {
-        for (ZkNodeProps nodeProps : slice.getReplicasMap().values()) {
-          ZkCoreNodeProps coreNodeProps = new ZkCoreNodeProps(nodeProps);
-          String node = coreNodeProps.getNodeName();
-          if (!liveNodes.contains(coreNodeProps.getNodeName())
-              || !coreNodeProps.getState().equals(ZkStateReader.ACTIVE)) continue;
-          if (nodes.put(node, nodeProps) == null) {
-            if (!sendToLeaders || (sendToLeaders && coreNodeProps.isLeader())) {
-              String url;
-              if (reqParams.get(UpdateParams.COLLECTION) == null) {
-                url = ZkCoreNodeProps.getCoreUrl(
-                    nodeProps.getStr(ZkStateReader.BASE_URL_PROP),
-                    defaultCollection);
-              } else {
-                url = coreNodeProps.getCoreUrl();
-              }
-              urlList2.add(url);
-            } else if (sendToLeaders) {
-              String url;
-              if (reqParams.get(UpdateParams.COLLECTION) == null) {
-                url = ZkCoreNodeProps.getCoreUrl(
-                    nodeProps.getStr(ZkStateReader.BASE_URL_PROP),
-                    defaultCollection);
-              } else {
-                url = coreNodeProps.getCoreUrl();
-              }
-              replicas.add(url);
-            }
-          }
-        }
-      }
-      
-      if (sendToLeaders) {
-        leaderUrlList = urlList2;
-        replicasList = replicas;
-      } else {
-        urlList = urlList2;
-      }
-      
-      if (sendToLeaders) {
-        theUrlList = new ArrayList<>(leaderUrlList.size());
-        theUrlList.addAll(leaderUrlList);
-      } else {
-        theUrlList = new ArrayList<>(urlList.size());
-        theUrlList.addAll(urlList);
-      }
-      if(theUrlList.isEmpty()) {
-        throw new SolrException(SolrException.ErrorCode.INVALID_STATE, "Not enough nodes to handle the request");
-      }
-
-      Collections.shuffle(theUrlList, rand);
-      if (sendToLeaders) {
-        ArrayList<String> theReplicas = new ArrayList<>(
-            replicasList.size());
-        theReplicas.addAll(replicasList);
-        Collections.shuffle(theReplicas, rand);
-        theUrlList.addAll(theReplicas);
-      }
-      
-    }
-    
-    LBHttpSolrServer.Req req = new LBHttpSolrServer.Req(request, theUrlList);
-    LBHttpSolrServer.Rsp rsp = lbServer.request(req);
-    return rsp.getResponse();
-  }
-
-  private Set<String> getCollectionList(ClusterState clusterState,
-      String collection) {
-    // Extract each comma separated collection name and store in a List.
-    List<String> rawCollectionsList = StrUtils.splitSmart(collection, ",", true);
-    Set<String> collectionsList = new HashSet<>();
-    // validate collections
-    for (String collectionName : rawCollectionsList) {
-      if (!clusterState.getCollections().contains(collectionName)) {
-        Aliases aliases = zkStateReader.getAliases();
-        String alias = aliases.getCollectionAlias(collectionName);
-        if (alias != null) {
-          List<String> aliasList = StrUtils.splitSmart(alias, ",", true);
-          collectionsList.addAll(aliasList);
-          continue;
-        }
-
-          throw new SolrException(ErrorCode.BAD_REQUEST, "Collection not found: " + collectionName);
-        }
-
-      collectionsList.add(collectionName);
-    }
-    return collectionsList;
-  }
-
-  @Override
-  public void shutdown() {
-    if (zkStateReader != null) {
-      synchronized(this) {
-        if (zkStateReader!= null)
-          zkStateReader.close();
-        zkStateReader = null;
-      }
-    }
-    
-    if (shutdownLBHttpSolrServer) {
-      lbServer.shutdown();
-    }
-    
-    if (clientIsInternal && myClient!=null) {
-      myClient.getConnectionManager().shutdown();
-    }
-
-    if(this.threadPool != null && !this.threadPool.isShutdown()) {
-      this.threadPool.shutdown();
-    }
-  }
-
-  public LBHttpSolrServer getLbServer() {
-    return lbServer;
-  }
-  
-  public boolean isUpdatesToLeaders() {
-    return updatesToLeaders;
-  }
-
-  protected DocCollection getDocCollection(ClusterState clusterState, String collection) throws SolrException {
-    ExpiringCachedDocCollection cachedState = collectionStateCache != null ? collectionStateCache.get(collection) : null;
-    if (cachedState != null && cachedState.cached != null) {
-      return cachedState.cached;
-    }
-
-    DocCollection col = clusterState.getCollectionOrNull(collection);
-    if(col == null ) return  null;
-    if(col.getStateFormat() >1) collectionStateCache.put(collection, new ExpiringCachedDocCollection(col));
-    return col;
-  }
-
-
-  /**
-   * Useful for determining the minimum achieved replication factor across
-   * all shards involved in processing an update request, typically useful
-   * for gauging the replication factor of a batch. 
-   */
-  @SuppressWarnings("rawtypes")
-  public int getMinAchievedReplicationFactor(String collection, NamedList resp) {
-    // it's probably already on the top-level header set by condense
-    NamedList header = (NamedList)resp.get("responseHeader");
-    Integer achRf = (Integer)header.get(UpdateRequest.REPFACT);
-    if (achRf != null)
-      return achRf.intValue();
-
-    // not on the top-level header, walk the shard route tree
-    Map<String,Integer> shardRf = getShardReplicationFactor(collection, resp);
-    for (Integer rf : shardRf.values()) {
-      if (achRf == null || rf < achRf) {
-        achRf = rf;
-      }
-    }    
-    return (achRf != null) ? achRf.intValue() : -1;
-  }
-  
-  /**
-   * Walks the NamedList response after performing an update request looking for
-   * the replication factor that was achieved in each shard involved in the request.
-   * For single doc updates, there will be only one shard in the return value. 
-   */
-  @SuppressWarnings("rawtypes")
-  public Map<String,Integer> getShardReplicationFactor(String collection, NamedList resp) {
-    connect();
-    
-    Map<String,Integer> results = new HashMap<String,Integer>();
-    if (resp instanceof CloudSolrServer.RouteResponse) {
-      NamedList routes = ((CloudSolrServer.RouteResponse)resp).getRouteResponses();      
-      ClusterState clusterState = zkStateReader.getClusterState();     
-      Map<String,String> leaders = new HashMap<String,String>();
-      for (Slice slice : clusterState.getActiveSlices(collection)) {
-        Replica leader = slice.getLeader();
-        if (leader != null) {
-          ZkCoreNodeProps zkProps = new ZkCoreNodeProps(leader);
-          String leaderUrl = zkProps.getBaseUrl() + "/" + zkProps.getCoreName();
-          leaders.put(leaderUrl, slice.getName());
-          String altLeaderUrl = zkProps.getBaseUrl() + "/" + collection;
-          leaders.put(altLeaderUrl, slice.getName());
-        }
-      }
-      
-      Iterator<Map.Entry<String,Object>> routeIter = routes.iterator();
-      while (routeIter.hasNext()) {
-        Map.Entry<String,Object> next = routeIter.next();
-        String host = next.getKey();
-        NamedList hostResp = (NamedList)next.getValue();
-        Integer rf = (Integer)((NamedList)hostResp.get("responseHeader")).get(UpdateRequest.REPFACT);
-        if (rf != null) {
-          String shard = leaders.get(host);
-          if (shard == null) {
-            if (host.endsWith("/"))
-              shard = leaders.get(host.substring(0,host.length()-1));
-            if (shard == null) {
-              shard = host;
-            }
-          }
-          results.put(shard, rf);
-        }
-      }
-    }    
-    return results;
+  public CloudSolrServer(String zkHost, LBHttpSolrClient lbClient, boolean updatesToLeaders) {
+    super(zkHost, lbClient, updatesToLeaders);
   }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClient.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClient.java
new file mode 100644
index 0000000..e6b3aca
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClient.java
@@ -0,0 +1,486 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.http.HttpResponse;
+import org.apache.http.HttpStatus;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.entity.ContentProducer;
+import org.apache.http.entity.EntityTemplate;
+import org.apache.solr.client.solrj.ResponseParser;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.request.RequestWriter;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.util.ClientUtils;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SolrjNamedThreadFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.LinkedList;
+import java.util.Locale;
+import java.util.Queue;
+import java.util.Set;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+
+/**
+ * ConcurrentUpdateSolrClient buffers all added documents and writes
+ * them into open HTTP connections. This class is thread safe.
+ * 
+ * Params from {@link UpdateRequest} are converted to http request
+ * parameters. When params change between UpdateRequests a new HTTP
+ * request is started.
+ * 
+ * Although any SolrClient request can be made with this implementation, it is
+ * only recommended to use ConcurrentUpdateSolrClient with /update
+ * requests. The class {@link HttpSolrClient} is better suited for the
+ * query interface.
+ */
+public class ConcurrentUpdateSolrClient extends SolrClient {
+  private static final long serialVersionUID = 1L;
+  static final Logger log = LoggerFactory
+      .getLogger(ConcurrentUpdateSolrClient.class);
+  private HttpSolrClient client;
+  final BlockingQueue<UpdateRequest> queue;
+  final ExecutorService scheduler;
+  final Queue<Runner> runners;
+  volatile CountDownLatch lock = null; // used to block everything
+  final int threadCount;
+  boolean shutdownExecutor = false;
+  int pollQueueTime = 250;
+  private final boolean streamDeletes;
+
+  /**
+   * Uses an internally managed HttpClient instance.
+   * 
+   * @param solrServerUrl
+   *          The Solr server URL
+   * @param queueSize
+   *          The buffer size before the documents are sent to the server
+   * @param threadCount
+   *          The number of background threads used to empty the queue
+   */
+  public ConcurrentUpdateSolrClient(String solrServerUrl, int queueSize,
+                                    int threadCount) {
+    this(solrServerUrl, null, queueSize, threadCount);
+    shutdownExecutor = true;
+  }
+  
+  public ConcurrentUpdateSolrClient(String solrServerUrl,
+                                    HttpClient client, int queueSize, int threadCount) {
+    this(solrServerUrl, client, queueSize, threadCount, Executors.newCachedThreadPool(
+        new SolrjNamedThreadFactory("concurrentUpdateScheduler")));
+    shutdownExecutor = true;
+  }
+
+  /**
+   * Uses the supplied HttpClient to send documents to the Solr server.
+   */
+  public ConcurrentUpdateSolrClient(String solrServerUrl,
+                                    HttpClient client, int queueSize, int threadCount, ExecutorService es) {
+    this(solrServerUrl, client, queueSize, threadCount, es, false);
+  }
+  
+  /**
+   * Uses the supplied HttpClient to send documents to the Solr server.
+   */
+  public ConcurrentUpdateSolrClient(String solrServerUrl,
+                                    HttpClient client, int queueSize, int threadCount, ExecutorService es, boolean streamDeletes) {
+    this.client = new HttpSolrClient(solrServerUrl, client);
+    this.client.setFollowRedirects(false);
+    queue = new LinkedBlockingQueue<>(queueSize);
+    this.threadCount = threadCount;
+    runners = new LinkedList<>();
+    scheduler = es;
+    this.streamDeletes = streamDeletes;
+  }
+
+  public Set<String> getQueryParams() {
+    return this.client.getQueryParams();
+  }
+
+  /**
+   * Expert Method.
+   * @param queryParams set of param keys to only send via the query string
+   */
+  public void setQueryParams(Set<String> queryParams) {
+    this.client.setQueryParams(queryParams);
+  }
+  
+  /**
+   * Opens a connection and sends everything...
+   */
+  class Runner implements Runnable {
+    final Lock runnerLock = new ReentrantLock();
+
+    @Override
+    public void run() {
+      runnerLock.lock();
+
+      log.debug("starting runner: {}", this);
+      HttpPost method = null;
+      HttpResponse response = null;            
+      try {
+        while (!queue.isEmpty()) {
+          try {
+            final UpdateRequest updateRequest = 
+                queue.poll(pollQueueTime, TimeUnit.MILLISECONDS);
+            if (updateRequest == null)
+              break;
+                       
+            String contentType = client.requestWriter.getUpdateContentType();
+            final boolean isXml = ClientUtils.TEXT_XML.equals(contentType);
+
+            final ModifiableSolrParams origParams = new ModifiableSolrParams(updateRequest.getParams());
+
+            EntityTemplate template = new EntityTemplate(new ContentProducer() {
+
+              @Override
+              public void writeTo(OutputStream out) throws IOException {
+                try {
+                  if (isXml) {
+                    out.write("<stream>".getBytes(StandardCharsets.UTF_8)); // can be anything
+                  }                                    
+                  UpdateRequest req = updateRequest;
+                  while (req != null) {                                        
+                    SolrParams currentParams = new ModifiableSolrParams(req.getParams());
+                    if (!origParams.toNamedList().equals(currentParams.toNamedList())) {
+                      queue.add(req); // params are different, push back to queue
+                      break;
+                    }
+                    
+                    client.requestWriter.write(req, out);
+                    if (isXml) {
+                      // check for commit or optimize
+                      SolrParams params = req.getParams();
+                      if (params != null) {
+                        String fmt = null;
+                        if (params.getBool(UpdateParams.OPTIMIZE, false)) {
+                          fmt = "<optimize waitSearcher=\"%s\" />";
+                        } else if (params.getBool(UpdateParams.COMMIT, false)) {
+                          fmt = "<commit waitSearcher=\"%s\" />";
+                        }
+                        if (fmt != null) {
+                          byte[] content = String.format(Locale.ROOT,
+                              fmt,
+                              params.getBool(UpdateParams.WAIT_SEARCHER, false)
+                                  + "").getBytes(StandardCharsets.UTF_8);
+                          out.write(content);
+                        }
+                      }
+                    }
+                    out.flush();
+                    req = queue.poll(pollQueueTime, TimeUnit.MILLISECONDS);
+                  }
+                  
+                  if (isXml) {
+                    out.write("</stream>".getBytes(StandardCharsets.UTF_8));
+                  }
+
+                } catch (InterruptedException e) {
+                  Thread.currentThread().interrupt();
+                  log.warn("", e);
+                }
+              }
+            });
+            
+            // The parser 'wt=' and 'version=' params are used instead of the
+            // original params
+            ModifiableSolrParams requestParams = new ModifiableSolrParams(origParams);
+            requestParams.set(CommonParams.WT, client.parser.getWriterType());
+            requestParams.set(CommonParams.VERSION, client.parser.getVersion());
+
+            method = new HttpPost(client.getBaseURL() + "/update"
+                + ClientUtils.toQueryString(requestParams, false));
+            method.setEntity(template);
+            method.addHeader("User-Agent", HttpSolrClient.AGENT);
+            method.addHeader("Content-Type", contentType);
+                        
+            response = client.getHttpClient().execute(method);
+            int statusCode = response.getStatusLine().getStatusCode();
+            if (statusCode != HttpStatus.SC_OK) {
+              StringBuilder msg = new StringBuilder();
+              msg.append(response.getStatusLine().getReasonPhrase());
+              msg.append("\n\n\n\n");
+              msg.append("request: ").append(method.getURI());
+
+              SolrException solrExc = new SolrException(ErrorCode.getErrorCode(statusCode), msg.toString());
+              // parse out the metadata from the SolrException
+              try {
+                NamedList<Object> resp =
+                    client.parser.processResponse(response.getEntity().getContent(),
+                        response.getEntity().getContentType().getValue());
+                NamedList<Object> error = (NamedList<Object>) resp.get("error");
+                if (error != null)
+                  solrExc.setMetadata((NamedList<String>) error.get("metadata"));
+              } catch (Exception exc) {
+                // don't want to fail to report error if parsing the response fails
+                log.warn("Failed to parse error response from "+ client.getBaseURL()+" due to: "+exc);
+              }
+
+              handleError(solrExc);
+            } else {
+              onSuccess(response);
+            }
+          } finally {
+            try {
+              if (response != null) {
+                response.getEntity().getContent().close();
+              }
+            } catch (Exception ex) {
+              log.warn("", ex);
+            }
+          }
+        }
+      } catch (Throwable e) {
+        if (e instanceof OutOfMemoryError) {
+          throw (OutOfMemoryError) e;
+        }
+        handleError(e);
+      } finally {
+        synchronized (runners) {
+          if (runners.size() == 1 && !queue.isEmpty()) {
+            // keep this runner alive
+            scheduler.execute(this);
+          } else {
+            runners.remove(this);
+            if (runners.isEmpty())
+              runners.notifyAll();
+          }
+        }
+
+        log.debug("finished: {}", this);
+        runnerLock.unlock();
+      }
+    }
+  }
+
+  @Override
+  public NamedList<Object> request(final SolrRequest request)
+      throws SolrServerException, IOException {
+    if (!(request instanceof UpdateRequest)) {
+      return client.request(request);
+    }
+    UpdateRequest req = (UpdateRequest) request;
+
+    // this happens for commit...
+    if (streamDeletes) {
+      if ((req.getDocuments() == null || req.getDocuments().isEmpty())
+          && (req.getDeleteById() == null || req.getDeleteById().isEmpty())
+          && (req.getDeleteByIdMap() == null || req.getDeleteByIdMap().isEmpty())) {
+        if (req.getDeleteQuery() == null) {
+          blockUntilFinished();
+          return client.request(request);
+        }
+      }
+    } else {
+      if ((req.getDocuments() == null || req.getDocuments().isEmpty())) {
+        blockUntilFinished();
+        return client.request(request);
+      }
+    }
+
+
+    SolrParams params = req.getParams();
+    if (params != null) {
+      // check if it is waiting for the searcher
+      if (params.getBool(UpdateParams.WAIT_SEARCHER, false)) {
+        log.info("blocking for commit/optimize");
+        blockUntilFinished(); // empty the queue
+        return client.request(request);
+      }
+    }
+
+    try {
+      CountDownLatch tmpLock = lock;
+      if (tmpLock != null) {
+        tmpLock.await();
+      }
+
+      boolean success = queue.offer(req);
+
+      for (;;) {
+        synchronized (runners) {
+          // see if queue is half full and we can add more runners
+          // special case: if only using a threadCount of 1 and the queue
+          // is filling up, allow 1 add'l runner to help process the queue
+          if (runners.isEmpty() || (queue.remainingCapacity() < queue.size() && runners.size() < threadCount))
+          {
+            // We need more runners, so start a new one.
+            Runner r = new Runner();
+            runners.add(r);
+            scheduler.execute(r);
+          } else {
+            // break out of the retry loop if we added the element to the queue
+            // successfully, *and*
+            // while we are still holding the runners lock to prevent race
+            // conditions.
+            if (success)
+              break;
+          }
+        }
+
+        // Retry to add to the queue w/o the runners lock held (else we risk
+        // temporary deadlock)
+        // This retry could also fail because
+        // 1) existing runners were not able to take off any new elements in the
+        // queue
+        // 2) the queue was filled back up since our last try
+        // If we succeed, the queue may have been completely emptied, and all
+        // runners stopped.
+        // In all cases, we should loop back to the top to see if we need to
+        // start more runners.
+        //
+        if (!success) {
+          success = queue.offer(req, 100, TimeUnit.MILLISECONDS);
+        }
+      }
+    } catch (InterruptedException e) {
+      log.error("interrupted", e);
+      throw new IOException(e.getLocalizedMessage());
+    }
+
+    // RETURN A DUMMY result
+    NamedList<Object> dummy = new NamedList<>();
+    dummy.add("NOTE", "the request is processed in a background stream");
+    return dummy;
+  }
+
+  public synchronized void blockUntilFinished() {
+    lock = new CountDownLatch(1);
+    try {
+      synchronized (runners) {
+        while (!runners.isEmpty()) {
+          try {
+            runners.wait();
+          } catch (InterruptedException e) {
+            Thread.interrupted();
+          }
+          
+          if (scheduler.isTerminated())
+            break;
+                      
+          // if we reach here, then we probably got the notifyAll, but need to check if
+          // the queue is empty before really considering this is finished (SOLR-4260)
+          int queueSize = queue.size();
+          if (queueSize > 0) {
+            log.warn("No more runners, but queue still has "+
+              queueSize+" adding more runners to process remaining requests on queue");
+            Runner r = new Runner();
+            runners.add(r);
+            scheduler.execute(r);
+          }
+        }
+      }
+    } finally {
+      lock.countDown();
+      lock = null;
+    }
+  }
+
+  public void handleError(Throwable ex) {
+    log.error("error", ex);
+  }
+  
+  /**
+   * Intended to be used as an extension point for doing post processing after a request completes.
+   */
+  public void onSuccess(HttpResponse resp) {
+    // no-op by design, override to add functionality
+  }
+
+  @Override
+  public void shutdown() {
+    client.shutdown();
+    if (shutdownExecutor) {
+      scheduler.shutdown();
+      try {
+        if (!scheduler.awaitTermination(60, TimeUnit.SECONDS)) {
+          scheduler.shutdownNow();
+          if (!scheduler.awaitTermination(60, TimeUnit.SECONDS)) log
+              .error("ExecutorService did not terminate");
+        }
+      } catch (InterruptedException ie) {
+        scheduler.shutdownNow();
+        Thread.currentThread().interrupt();
+      }
+    }
+  }
+  
+  public void setConnectionTimeout(int timeout) {
+    HttpClientUtil.setConnectionTimeout(client.getHttpClient(), timeout);
+  }
+
+  /**
+   * set soTimeout (read timeout) on the underlying HttpConnectionManager. This is desirable for queries, but probably
+   * not for indexing.
+   */
+  public void setSoTimeout(int timeout) {
+    HttpClientUtil.setSoTimeout(client.getHttpClient(), timeout);
+  }
+
+  public void shutdownNow() {
+    client.shutdown();
+    if (shutdownExecutor) {
+      scheduler.shutdownNow(); // Cancel currently executing tasks
+      try {
+        if (!scheduler.awaitTermination(30, TimeUnit.SECONDS)) 
+          log.error("ExecutorService did not terminate");
+      } catch (InterruptedException ie) {
+        scheduler.shutdownNow();
+        Thread.currentThread().interrupt();
+      }
+    }    
+  }
+  
+  public void setParser(ResponseParser responseParser) {
+    client.setParser(responseParser);
+  }
+  
+  
+  /**
+   * @param pollQueueTime time for an open connection to wait for updates when
+   * the queue is empty. 
+   */
+  public void setPollQueueTime(int pollQueueTime) {
+    this.pollQueueTime = pollQueueTime;
+  }
+
+  public void setRequestWriter(RequestWriter requestWriter) {
+    client.setRequestWriter(requestWriter);
+  }
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServer.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServer.java
index a784966..9ace82a 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServer.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServer.java
@@ -17,470 +17,30 @@
 
 package org.apache.solr.client.solrj.impl;
 
-import java.io.IOException;
-import java.io.OutputStream;
-import java.nio.charset.StandardCharsets;
-import java.util.LinkedList;
-import java.util.Locale;
-import java.util.Queue;
-import java.util.Set;
-import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
-
-import org.apache.http.HttpResponse;
-import org.apache.http.HttpStatus;
 import org.apache.http.client.HttpClient;
-import org.apache.http.client.methods.HttpPost;
-import org.apache.http.entity.ContentProducer;
-import org.apache.http.entity.EntityTemplate;
-import org.apache.solr.client.solrj.ResponseParser;
-import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.request.RequestWriter;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.util.ClientUtils;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.params.UpdateParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+
+import java.util.concurrent.ExecutorService;
 
 /**
- * ConcurrentUpdateSolrServer buffers all added documents and writes
- * them into open HTTP connections. This class is thread safe.
- * 
- * Params from {@link UpdateRequest} are converted to http request
- * parameters. When params change between UpdateRequests a new HTTP
- * request is started.
- * 
- * Although any SolrServer request can be made with this implementation, it is
- * only recommended to use ConcurrentUpdateSolrServer with /update
- * requests. The class {@link HttpSolrServer} is better suited for the
- * query interface.
+ * @deprecated Use {@link org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient}
  */
-public class ConcurrentUpdateSolrServer extends SolrServer {
-  private static final long serialVersionUID = 1L;
-  static final Logger log = LoggerFactory
-      .getLogger(ConcurrentUpdateSolrServer.class);
-  private HttpSolrServer server;
-  final BlockingQueue<UpdateRequest> queue;
-  final ExecutorService scheduler;
-  final Queue<Runner> runners;
-  volatile CountDownLatch lock = null; // used to block everything
-  final int threadCount;
-  boolean shutdownExecutor = false;
-  int pollQueueTime = 250;
-  private final boolean streamDeletes;
-
-  /**
-   * Uses an internally managed HttpClient instance.
-   * 
-   * @param solrServerUrl
-   *          The Solr server URL
-   * @param queueSize
-   *          The buffer size before the documents are sent to the server
-   * @param threadCount
-   *          The number of background threads used to empty the queue
-   */
-  public ConcurrentUpdateSolrServer(String solrServerUrl, int queueSize,
-      int threadCount) {
-    this(solrServerUrl, null, queueSize, threadCount);
-    shutdownExecutor = true;
-  }
-  
-  public ConcurrentUpdateSolrServer(String solrServerUrl,
-      HttpClient client, int queueSize, int threadCount) {
-    this(solrServerUrl, client, queueSize, threadCount, Executors.newCachedThreadPool(
-        new SolrjNamedThreadFactory("concurrentUpdateScheduler")));
-    shutdownExecutor = true;
-  }
-
-  /**
-   * Uses the supplied HttpClient to send documents to the Solr server.
-   */
-  public ConcurrentUpdateSolrServer(String solrServerUrl,
-      HttpClient client, int queueSize, int threadCount, ExecutorService es) {
-    this(solrServerUrl, client, queueSize, threadCount, es, false);
-  }
-  
-  /**
-   * Uses the supplied HttpClient to send documents to the Solr server.
-   */
-  public ConcurrentUpdateSolrServer(String solrServerUrl,
-      HttpClient client, int queueSize, int threadCount, ExecutorService es, boolean streamDeletes) {
-    this.server = new HttpSolrServer(solrServerUrl, client);
-    this.server.setFollowRedirects(false);
-    queue = new LinkedBlockingQueue<>(queueSize);
-    this.threadCount = threadCount;
-    runners = new LinkedList<>();
-    scheduler = es;
-    this.streamDeletes = streamDeletes;
-  }
-
-  public Set<String> getQueryParams() {
-    return this.server.getQueryParams();
-  }
-
-  /**
-   * Expert Method.
-   * @param queryParams set of param keys to only send via the query string
-   */
-  public void setQueryParams(Set<String> queryParams) {
-    this.server.setQueryParams(queryParams);
-  }
-  
-  /**
-   * Opens a connection and sends everything...
-   */
-  class Runner implements Runnable {
-    final Lock runnerLock = new ReentrantLock();
-
-    @Override
-    public void run() {
-      runnerLock.lock();
-
-      log.debug("starting runner: {}", this);
-      HttpPost method = null;
-      HttpResponse response = null;            
-      try {
-        while (!queue.isEmpty()) {
-          try {
-            final UpdateRequest updateRequest = 
-                queue.poll(pollQueueTime, TimeUnit.MILLISECONDS);
-            if (updateRequest == null)
-              break;
-                       
-            String contentType = server.requestWriter.getUpdateContentType();
-            final boolean isXml = ClientUtils.TEXT_XML.equals(contentType);
-
-            final ModifiableSolrParams origParams = new ModifiableSolrParams(updateRequest.getParams());
-
-            EntityTemplate template = new EntityTemplate(new ContentProducer() {
-
-              @Override
-              public void writeTo(OutputStream out) throws IOException {
-                try {
-                  if (isXml) {
-                    out.write("<stream>".getBytes(StandardCharsets.UTF_8)); // can be anything
-                  }                                    
-                  UpdateRequest req = updateRequest;
-                  while (req != null) {                                        
-                    SolrParams currentParams = new ModifiableSolrParams(req.getParams());
-                    if (!origParams.toNamedList().equals(currentParams.toNamedList())) {
-                      queue.add(req); // params are different, push back to queue
-                      break;
-                    }
-                    
-                    server.requestWriter.write(req, out);
-                    if (isXml) {
-                      // check for commit or optimize
-                      SolrParams params = req.getParams();
-                      if (params != null) {
-                        String fmt = null;
-                        if (params.getBool(UpdateParams.OPTIMIZE, false)) {
-                          fmt = "<optimize waitSearcher=\"%s\" />";
-                        } else if (params.getBool(UpdateParams.COMMIT, false)) {
-                          fmt = "<commit waitSearcher=\"%s\" />";
-                        }
-                        if (fmt != null) {
-                          byte[] content = String.format(Locale.ROOT,
-                              fmt,
-                              params.getBool(UpdateParams.WAIT_SEARCHER, false)
-                                  + "").getBytes(StandardCharsets.UTF_8);
-                          out.write(content);
-                        }
-                      }
-                    }
-                    out.flush();
-                    req = queue.poll(pollQueueTime, TimeUnit.MILLISECONDS);
-                  }
-                  
-                  if (isXml) {
-                    out.write("</stream>".getBytes(StandardCharsets.UTF_8));
-                  }
-
-                } catch (InterruptedException e) {
-                  Thread.currentThread().interrupt();
-                  log.warn("", e);
-                }
-              }
-            });
-            
-            // The parser 'wt=' and 'version=' params are used instead of the
-            // original params
-            ModifiableSolrParams requestParams = new ModifiableSolrParams(origParams);
-            requestParams.set(CommonParams.WT, server.parser.getWriterType());
-            requestParams.set(CommonParams.VERSION, server.parser.getVersion());
-
-            method = new HttpPost(server.getBaseURL() + "/update"
-                + ClientUtils.toQueryString(requestParams, false));
-            method.setEntity(template);
-            method.addHeader("User-Agent", HttpSolrServer.AGENT);
-            method.addHeader("Content-Type", contentType);
-                        
-            response = server.getHttpClient().execute(method);
-            int statusCode = response.getStatusLine().getStatusCode();
-            if (statusCode != HttpStatus.SC_OK) {
-              StringBuilder msg = new StringBuilder();
-              msg.append(response.getStatusLine().getReasonPhrase());
-              msg.append("\n\n\n\n");
-              msg.append("request: ").append(method.getURI());
+@Deprecated
+public class ConcurrentUpdateSolrServer extends ConcurrentUpdateSolrClient {
 
-              SolrException solrExc = new SolrException(ErrorCode.getErrorCode(statusCode), msg.toString());
-              // parse out the metadata from the SolrException
-              try {
-                NamedList<Object> resp =
-                    server.parser.processResponse(response.getEntity().getContent(),
-                        response.getEntity().getContentType().getValue());
-                NamedList<Object> error = (NamedList<Object>) resp.get("error");
-                if (error != null)
-                  solrExc.setMetadata((NamedList<String>) error.get("metadata"));
-              } catch (Exception exc) {
-                // don't want to fail to report error if parsing the response fails
-                log.warn("Failed to parse error response from "+server.getBaseURL()+" due to: "+exc);
-              }
-
-              handleError(solrExc);
-            } else {
-              onSuccess(response);
-            }
-          } finally {
-            try {
-              if (response != null) {
-                response.getEntity().getContent().close();
-              }
-            } catch (Exception ex) {
-              log.warn("", ex);
-            }
-          }
-        }
-      } catch (Throwable e) {
-        if (e instanceof OutOfMemoryError) {
-          throw (OutOfMemoryError) e;
-        }
-        handleError(e);
-      } finally {
-        synchronized (runners) {
-          if (runners.size() == 1 && !queue.isEmpty()) {
-            // keep this runner alive
-            scheduler.execute(this);
-          } else {
-            runners.remove(this);
-            if (runners.isEmpty())
-              runners.notifyAll();
-          }
-        }
-
-        log.debug("finished: {}", this);
-        runnerLock.unlock();
-      }
-    }
+  public ConcurrentUpdateSolrServer(String solrServerUrl, int queueSize, int threadCount) {
+    super(solrServerUrl, queueSize, threadCount);
   }
 
-  @Override
-  public NamedList<Object> request(final SolrRequest request)
-      throws SolrServerException, IOException {
-    if (!(request instanceof UpdateRequest)) {
-      return server.request(request);
-    }
-    UpdateRequest req = (UpdateRequest) request;
-
-    // this happens for commit...
-    if (streamDeletes) {
-      if ((req.getDocuments() == null || req.getDocuments().isEmpty())
-          && (req.getDeleteById() == null || req.getDeleteById().isEmpty())
-          && (req.getDeleteByIdMap() == null || req.getDeleteByIdMap().isEmpty())) {
-        if (req.getDeleteQuery() == null) {
-          blockUntilFinished();
-          return server.request(request);
-        }
-      }
-    } else {
-      if ((req.getDocuments() == null || req.getDocuments().isEmpty())) {
-        blockUntilFinished();
-        return server.request(request);
-      }
-    }
-
-
-    SolrParams params = req.getParams();
-    if (params != null) {
-      // check if it is waiting for the searcher
-      if (params.getBool(UpdateParams.WAIT_SEARCHER, false)) {
-        log.info("blocking for commit/optimize");
-        blockUntilFinished(); // empty the queue
-        return server.request(request);
-      }
-    }
-
-    try {
-      CountDownLatch tmpLock = lock;
-      if (tmpLock != null) {
-        tmpLock.await();
-      }
-
-      boolean success = queue.offer(req);
-
-      for (;;) {
-        synchronized (runners) {
-          // see if queue is half full and we can add more runners
-          // special case: if only using a threadCount of 1 and the queue
-          // is filling up, allow 1 add'l runner to help process the queue
-          if (runners.isEmpty() || (queue.remainingCapacity() < queue.size() && runners.size() < threadCount))
-          {
-            // We need more runners, so start a new one.
-            Runner r = new Runner();
-            runners.add(r);
-            scheduler.execute(r);
-          } else {
-            // break out of the retry loop if we added the element to the queue
-            // successfully, *and*
-            // while we are still holding the runners lock to prevent race
-            // conditions.
-            if (success)
-              break;
-          }
-        }
-
-        // Retry to add to the queue w/o the runners lock held (else we risk
-        // temporary deadlock)
-        // This retry could also fail because
-        // 1) existing runners were not able to take off any new elements in the
-        // queue
-        // 2) the queue was filled back up since our last try
-        // If we succeed, the queue may have been completely emptied, and all
-        // runners stopped.
-        // In all cases, we should loop back to the top to see if we need to
-        // start more runners.
-        //
-        if (!success) {
-          success = queue.offer(req, 100, TimeUnit.MILLISECONDS);
-        }
-      }
-    } catch (InterruptedException e) {
-      log.error("interrupted", e);
-      throw new IOException(e.getLocalizedMessage());
-    }
-
-    // RETURN A DUMMY result
-    NamedList<Object> dummy = new NamedList<>();
-    dummy.add("NOTE", "the request is processed in a background stream");
-    return dummy;
+  public ConcurrentUpdateSolrServer(String solrServerUrl, HttpClient client, int queueSize, int threadCount) {
+    super(solrServerUrl, client, queueSize, threadCount);
   }
 
-  public synchronized void blockUntilFinished() {
-    lock = new CountDownLatch(1);
-    try {
-      synchronized (runners) {
-        while (!runners.isEmpty()) {
-          try {
-            runners.wait();
-          } catch (InterruptedException e) {
-            Thread.interrupted();
-          }
-          
-          if (scheduler.isTerminated())
-            break;
-                      
-          // if we reach here, then we probably got the notifyAll, but need to check if
-          // the queue is empty before really considering this is finished (SOLR-4260)
-          int queueSize = queue.size();
-          if (queueSize > 0) {
-            log.warn("No more runners, but queue still has "+
-              queueSize+" adding more runners to process remaining requests on queue");
-            Runner r = new Runner();
-            runners.add(r);
-            scheduler.execute(r);
-          }
-        }
-      }
-    } finally {
-      lock.countDown();
-      lock = null;
-    }
+  public ConcurrentUpdateSolrServer(String solrServerUrl, HttpClient client, int queueSize, int threadCount, ExecutorService es) {
+    super(solrServerUrl, client, queueSize, threadCount, es);
   }
 
-  public void handleError(Throwable ex) {
-    log.error("error", ex);
-  }
-  
-  /**
-   * Intended to be used as an extension point for doing post processing after a request completes.
-   */
-  public void onSuccess(HttpResponse resp) {
-    // no-op by design, override to add functionality
+  public ConcurrentUpdateSolrServer(String solrServerUrl, HttpClient client, int queueSize, int threadCount, ExecutorService es, boolean streamDeletes) {
+    super(solrServerUrl, client, queueSize, threadCount, es, streamDeletes);
   }
 
-  @Override
-  public void shutdown() {
-    server.shutdown();
-    if (shutdownExecutor) {
-      scheduler.shutdown();
-      try {
-        if (!scheduler.awaitTermination(60, TimeUnit.SECONDS)) {
-          scheduler.shutdownNow();
-          if (!scheduler.awaitTermination(60, TimeUnit.SECONDS)) log
-              .error("ExecutorService did not terminate");
-        }
-      } catch (InterruptedException ie) {
-        scheduler.shutdownNow();
-        Thread.currentThread().interrupt();
-      }
-    }
-  }
-  
-  public void setConnectionTimeout(int timeout) {
-    HttpClientUtil.setConnectionTimeout(server.getHttpClient(), timeout);
-  }
-
-  /**
-   * set soTimeout (read timeout) on the underlying HttpConnectionManager. This is desirable for queries, but probably
-   * not for indexing.
-   */
-  public void setSoTimeout(int timeout) {
-    HttpClientUtil.setSoTimeout(server.getHttpClient(), timeout);
-  }
-
-  public void shutdownNow() {
-    server.shutdown();
-    if (shutdownExecutor) {
-      scheduler.shutdownNow(); // Cancel currently executing tasks
-      try {
-        if (!scheduler.awaitTermination(30, TimeUnit.SECONDS)) 
-          log.error("ExecutorService did not terminate");
-      } catch (InterruptedException ie) {
-        scheduler.shutdownNow();
-        Thread.currentThread().interrupt();
-      }
-    }    
-  }
-  
-  public void setParser(ResponseParser responseParser) {
-    server.setParser(responseParser);
-  }
-  
-  
-  /**
-   * @param pollQueueTime time for an open connection to wait for updates when
-   * the queue is empty. 
-   */
-  public void setPollQueueTime(int pollQueueTime) {
-    this.pollQueueTime = pollQueueTime;
-  }
-
-  public void setRequestWriter(RequestWriter requestWriter) {
-    server.setRequestWriter(requestWriter);
-  }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrClient.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrClient.java
new file mode 100644
index 0000000..ae19299
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrClient.java
@@ -0,0 +1,815 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.commons.io.IOUtils;
+import org.apache.http.Header;
+import org.apache.http.HttpResponse;
+import org.apache.http.HttpStatus;
+import org.apache.http.NameValuePair;
+import org.apache.http.NoHttpResponseException;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.entity.UrlEncodedFormEntity;
+import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.client.methods.HttpPut;
+import org.apache.http.client.methods.HttpRequestBase;
+import org.apache.http.client.methods.HttpUriRequest;
+import org.apache.http.conn.ClientConnectionManager;
+import org.apache.http.entity.ContentType;
+import org.apache.http.entity.InputStreamEntity;
+import org.apache.http.entity.mime.FormBodyPart;
+import org.apache.http.entity.mime.HttpMultipartMode;
+import org.apache.http.entity.mime.MultipartEntity;
+import org.apache.http.entity.mime.content.InputStreamBody;
+import org.apache.http.entity.mime.content.StringBody;
+import org.apache.http.impl.client.DefaultHttpClient;
+import org.apache.http.message.BasicHeader;
+import org.apache.http.message.BasicNameValuePair;
+import org.apache.http.util.EntityUtils;
+import org.apache.solr.client.solrj.ResponseParser;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrClient;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.request.RequestWriter;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.response.UpdateResponse;
+import org.apache.solr.client.solrj.util.ClientUtils;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.util.ContentStream;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SolrjNamedThreadFactory;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.ConnectException;
+import java.net.SocketTimeoutException;
+import java.nio.charset.StandardCharsets;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Locale;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+
+public class HttpSolrClient extends SolrClient {
+
+  private static final String UTF_8 = StandardCharsets.UTF_8.name();
+  private static final String DEFAULT_PATH = "/select";
+  private static final long serialVersionUID = -946812319974801896L;
+  
+  /**
+   * User-Agent String.
+   */
+  public static final String AGENT = "Solr[" + HttpSolrClient.class.getName() + "] 1.0";
+  
+  private static Logger log = LoggerFactory.getLogger(HttpSolrClient.class);
+  
+  /**
+   * The URL of the Solr server.
+   */
+  protected volatile String baseUrl;
+  
+  /**
+   * Default value: null / empty.
+   * <p/>
+   * Parameters that are added to every request regardless. This may be a place
+   * to add something like an authentication token.
+   */
+  protected ModifiableSolrParams invariantParams;
+  
+  /**
+   * Default response parser is BinaryResponseParser
+   * <p/>
+   * This parser represents the default Response Parser chosen to parse the
+   * response if the parser were not specified as part of the request.
+   * 
+   * @see org.apache.solr.client.solrj.impl.BinaryResponseParser
+   */
+  protected volatile ResponseParser parser;
+  
+  /**
+   * The RequestWriter used to write all requests to Solr
+   * 
+   * @see org.apache.solr.client.solrj.request.RequestWriter
+   */
+  protected volatile RequestWriter requestWriter = new RequestWriter();
+  
+  private final HttpClient httpClient;
+  
+  private volatile boolean followRedirects = false;
+  
+  private volatile int maxRetries = 0;
+  
+  private volatile boolean useMultiPartPost;
+  private final boolean internalClient;
+
+  private volatile Set<String> queryParams = Collections.emptySet();
+
+  /**
+   * @param baseURL
+   *          The URL of the Solr server. For example, "
+   *          <code>http://localhost:8983/solr/</code>" if you are using the
+   *          standard distribution Solr webapp on your local machine.
+   */
+  public HttpSolrClient(String baseURL) {
+    this(baseURL, null, new BinaryResponseParser());
+  }
+  
+  public HttpSolrClient(String baseURL, HttpClient client) {
+    this(baseURL, client, new BinaryResponseParser());
+  }
+  
+  public HttpSolrClient(String baseURL, HttpClient client, ResponseParser parser) {
+    this.baseUrl = baseURL;
+    if (baseUrl.endsWith("/")) {
+      baseUrl = baseUrl.substring(0, baseUrl.length() - 1);
+    }
+    if (baseUrl.indexOf('?') >= 0) {
+      throw new RuntimeException(
+          "Invalid base url for solrj.  The base URL must not contain parameters: "
+              + baseUrl);
+    }
+    
+    if (client != null) {
+      httpClient = client;
+      internalClient = false;
+    } else {
+      internalClient = true;
+      ModifiableSolrParams params = new ModifiableSolrParams();
+      params.set(HttpClientUtil.PROP_MAX_CONNECTIONS, 128);
+      params.set(HttpClientUtil.PROP_MAX_CONNECTIONS_PER_HOST, 32);
+      params.set(HttpClientUtil.PROP_FOLLOW_REDIRECTS, followRedirects);
+      httpClient = HttpClientUtil.createClient(params);
+    }
+    
+    this.parser = parser;
+  }
+  
+  public Set<String> getQueryParams() {
+    return queryParams;
+  }
+
+  /**
+   * Expert Method
+   * @param queryParams set of param keys to only send via the query string
+   * Note that the param will be sent as a query string if the key is part
+   * of this Set or the SolrRequest's query params.
+   * @see org.apache.solr.client.solrj.SolrRequest#getQueryParams
+   */
+  public void setQueryParams(Set<String> queryParams) {
+    this.queryParams = queryParams;
+  }
+  
+  /**
+   * Process the request. If
+   * {@link org.apache.solr.client.solrj.SolrRequest#getResponseParser()} is
+   * null, then use {@link #getParser()}
+   * 
+   * @param request
+   *          The {@link org.apache.solr.client.solrj.SolrRequest} to process
+   * @return The {@link org.apache.solr.common.util.NamedList} result
+   * @throws IOException If there is a low-level I/O error.
+   * 
+   * @see #request(org.apache.solr.client.solrj.SolrRequest,
+   *      org.apache.solr.client.solrj.ResponseParser)
+   */
+  @Override
+  public NamedList<Object> request(final SolrRequest request)
+      throws SolrServerException, IOException {
+    ResponseParser responseParser = request.getResponseParser();
+    if (responseParser == null) {
+      responseParser = parser;
+    }
+    return request(request, responseParser);
+  }
+  
+  public NamedList<Object> request(final SolrRequest request, final ResponseParser processor) throws SolrServerException, IOException {
+    return executeMethod(createMethod(request),processor);
+  }
+  
+  /**
+   * @lucene.experimental
+   */
+  public static class HttpUriRequestResponse {
+    public HttpUriRequest httpUriRequest;
+    public Future<NamedList<Object>> future;
+  }
+  
+  /**
+   * @lucene.experimental
+   */
+  public HttpUriRequestResponse httpUriRequest(final SolrRequest request)
+      throws SolrServerException, IOException {
+    ResponseParser responseParser = request.getResponseParser();
+    if (responseParser == null) {
+      responseParser = parser;
+    }
+    return httpUriRequest(request, responseParser);
+  }
+  
+  /**
+   * @lucene.experimental
+   */
+  public HttpUriRequestResponse httpUriRequest(final SolrRequest request, final ResponseParser processor) throws SolrServerException, IOException {
+    HttpUriRequestResponse mrr = new HttpUriRequestResponse();
+    final HttpRequestBase method = createMethod(request);
+    ExecutorService pool = Executors.newFixedThreadPool(1, new SolrjNamedThreadFactory("httpUriRequest"));
+    try {
+      mrr.future = pool.submit(new Callable<NamedList<Object>>(){
+
+        @Override
+        public NamedList<Object> call() throws Exception {
+          return executeMethod(method, processor);
+        }});
+ 
+    } finally {
+      pool.shutdown();
+    }
+    assert method != null;
+    mrr.httpUriRequest = method;
+    return mrr;
+  }
+
+  protected ModifiableSolrParams calculateQueryParams(Set<String> queryParamNames,
+      ModifiableSolrParams wparams) {
+    ModifiableSolrParams queryModParams = new ModifiableSolrParams();
+    if (queryParamNames != null) {
+      for (String param : queryParamNames) {
+        String[] value = wparams.getParams(param) ;
+        if (value != null) {
+          for (String v : value) {
+            queryModParams.add(param, v);
+          }
+          wparams.remove(param);
+        }
+      }
+    }
+    return queryModParams;
+  }
+
+  protected HttpRequestBase createMethod(final SolrRequest request) throws IOException, SolrServerException {
+    HttpRequestBase method = null;
+    InputStream is = null;
+    SolrParams params = request.getParams();
+    Collection<ContentStream> streams = requestWriter.getContentStreams(request);
+    String path = requestWriter.getPath(request);
+    if (path == null || !path.startsWith("/")) {
+      path = DEFAULT_PATH;
+    }
+    
+    ResponseParser parser = request.getResponseParser();
+    if (parser == null) {
+      parser = this.parser;
+    }
+    
+    // The parser 'wt=' and 'version=' params are used instead of the original
+    // params
+    ModifiableSolrParams wparams = new ModifiableSolrParams(params);
+    if (parser != null) {
+      wparams.set(CommonParams.WT, parser.getWriterType());
+      wparams.set(CommonParams.VERSION, parser.getVersion());
+    }
+    if (invariantParams != null) {
+      wparams.add(invariantParams);
+    }
+    
+    int tries = maxRetries + 1;
+    try {
+      while( tries-- > 0 ) {
+        // Note: since we aren't do intermittent time keeping
+        // ourselves, the potential non-timeout latency could be as
+        // much as tries-times (plus scheduling effects) the given
+        // timeAllowed.
+        try {
+          if( SolrRequest.METHOD.GET == request.getMethod() ) {
+            if( streams != null ) {
+              throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, "GET can't send streams!" );
+            }
+            method = new HttpGet( baseUrl + path + ClientUtils.toQueryString( wparams, false ) );
+          }
+          else if( SolrRequest.METHOD.POST == request.getMethod() || SolrRequest.METHOD.PUT == request.getMethod() ) {
+
+            String url = baseUrl + path;
+            boolean hasNullStreamName = false;
+            if (streams != null) {
+              for (ContentStream cs : streams) {
+                if (cs.getName() == null) {
+                  hasNullStreamName = true;
+                  break;
+                }
+              }
+            }
+            boolean isMultipart = ((this.useMultiPartPost && SolrRequest.METHOD.POST == request.getMethod())
+              || ( streams != null && streams.size() > 1 )) && !hasNullStreamName;
+
+            LinkedList<NameValuePair> postOrPutParams = new LinkedList<>();
+            if (streams == null || isMultipart) {
+              // send server list and request list as query string params
+              ModifiableSolrParams queryParams = calculateQueryParams(this.queryParams, wparams);
+              queryParams.add(calculateQueryParams(request.getQueryParams(), wparams));
+              String fullQueryUrl = url + ClientUtils.toQueryString( queryParams, false );
+              HttpEntityEnclosingRequestBase postOrPut = SolrRequest.METHOD.POST == request.getMethod() ?
+                new HttpPost(fullQueryUrl) : new HttpPut(fullQueryUrl);
+              if (!isMultipart) {
+                postOrPut.addHeader("Content-Type",
+                    "application/x-www-form-urlencoded; charset=UTF-8");
+              }
+
+              List<FormBodyPart> parts = new LinkedList<>();
+              Iterator<String> iter = wparams.getParameterNamesIterator();
+              while (iter.hasNext()) {
+                String p = iter.next();
+                String[] vals = wparams.getParams(p);
+                if (vals != null) {
+                  for (String v : vals) {
+                    if (isMultipart) {
+                      parts.add(new FormBodyPart(p, new StringBody(v, StandardCharsets.UTF_8)));
+                    } else {
+                      postOrPutParams.add(new BasicNameValuePair(p, v));
+                    }
+                  }
+                }
+              }
+
+              if (isMultipart && streams != null) {
+                for (ContentStream content : streams) {
+                  String contentType = content.getContentType();
+                  if(contentType==null) {
+                    contentType = BinaryResponseParser.BINARY_CONTENT_TYPE; // default
+                  }
+                  String name = content.getName();
+                  if(name==null) {
+                    name = "";
+                  }
+                  parts.add(new FormBodyPart(name, 
+                       new InputStreamBody(
+                           content.getStream(), 
+                           contentType, 
+                           content.getName())));
+                }
+              }
+              
+              if (parts.size() > 0) {
+                MultipartEntity entity = new MultipartEntity(HttpMultipartMode.STRICT);
+                for(FormBodyPart p: parts) {
+                  entity.addPart(p);
+                }
+                postOrPut.setEntity(entity);
+              } else {
+                //not using multipart
+                postOrPut.setEntity(new UrlEncodedFormEntity(postOrPutParams, StandardCharsets.UTF_8));
+              }
+
+              method = postOrPut;
+            }
+            // It is has one stream, it is the post body, put the params in the URL
+            else {
+              String pstr = ClientUtils.toQueryString(wparams, false);
+              HttpEntityEnclosingRequestBase postOrPut = SolrRequest.METHOD.POST == request.getMethod() ?
+                new HttpPost(url + pstr) : new HttpPut(url + pstr);
+
+              // Single stream as body
+              // Using a loop just to get the first one
+              final ContentStream[] contentStream = new ContentStream[1];
+              for (ContentStream content : streams) {
+                contentStream[0] = content;
+                break;
+              }
+              if (contentStream[0] instanceof RequestWriter.LazyContentStream) {
+                postOrPut.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {
+                  @Override
+                  public Header getContentType() {
+                    return new BasicHeader("Content-Type", contentStream[0].getContentType());
+                  }
+                  
+                  @Override
+                  public boolean isRepeatable() {
+                    return false;
+                  }
+                  
+                });
+              } else {
+                postOrPut.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {
+                  @Override
+                  public Header getContentType() {
+                    return new BasicHeader("Content-Type", contentStream[0].getContentType());
+                  }
+                  
+                  @Override
+                  public boolean isRepeatable() {
+                    return false;
+                  }
+                });
+              }
+              method = postOrPut;
+            }
+          }
+          else {
+            throw new SolrServerException("Unsupported method: "+request.getMethod() );
+          }
+        }
+        catch( NoHttpResponseException r ) {
+          method = null;
+          if(is != null) {
+            is.close();
+          }
+          // If out of tries then just rethrow (as normal error).
+          if (tries < 1) {
+            throw r;
+          }
+        }
+      }
+    } catch (IOException ex) {
+      throw new SolrServerException("error reading streams", ex);
+    }
+    
+    return method;
+  }
+  
+  protected NamedList<Object> executeMethod(HttpRequestBase method, final ResponseParser processor) throws SolrServerException {
+    method.addHeader("User-Agent", AGENT);
+    
+    InputStream respBody = null;
+    boolean shouldClose = true;
+    boolean success = false;
+    try {
+      // Execute the method.
+      final HttpResponse response = httpClient.execute(method);
+      int httpStatus = response.getStatusLine().getStatusCode();
+      
+      // Read the contents
+      respBody = response.getEntity().getContent();
+      Header ctHeader = response.getLastHeader("content-type");
+      String contentType;
+      if (ctHeader != null) {
+        contentType = ctHeader.getValue();
+      } else {
+        contentType = "";
+      }
+      
+      // handle some http level checks before trying to parse the response
+      switch (httpStatus) {
+        case HttpStatus.SC_OK:
+        case HttpStatus.SC_BAD_REQUEST:
+        case HttpStatus.SC_CONFLICT:  // 409
+          break;
+        case HttpStatus.SC_MOVED_PERMANENTLY:
+        case HttpStatus.SC_MOVED_TEMPORARILY:
+          if (!followRedirects) {
+            throw new SolrServerException("Server at " + getBaseURL()
+                + " sent back a redirect (" + httpStatus + ").");
+          }
+          break;
+        default:
+          if (processor == null) {
+            throw new RemoteSolrException(baseUrl, httpStatus, "non ok status: " + httpStatus
+                + ", message:" + response.getStatusLine().getReasonPhrase(),
+                null);
+          }
+      }
+      if (processor == null) {
+        
+        // no processor specified, return raw stream
+        NamedList<Object> rsp = new NamedList<>();
+        rsp.add("stream", respBody);
+        // Only case where stream should not be closed
+        shouldClose = false;
+        success = true;
+        return rsp;
+      }
+      
+      String procCt = processor.getContentType();
+      if (procCt != null) {
+        String procMimeType = ContentType.parse(procCt).getMimeType().trim().toLowerCase(Locale.ROOT);
+        String mimeType = ContentType.parse(contentType).getMimeType().trim().toLowerCase(Locale.ROOT);
+        if (!procMimeType.equals(mimeType)) {
+          // unexpected mime type
+          String msg = "Expected mime type " + procMimeType + " but got " + mimeType + ".";
+          Header encodingHeader = response.getEntity().getContentEncoding();
+          String encoding;
+          if (encodingHeader != null) {
+            encoding = encodingHeader.getValue();
+          } else {
+            encoding = "UTF-8"; // try UTF-8
+          }
+          try {
+            msg = msg + " " + IOUtils.toString(respBody, encoding);
+          } catch (IOException e) {
+            throw new RemoteSolrException(baseUrl, httpStatus, "Could not parse response with encoding " + encoding, e);
+          }
+          throw new RemoteSolrException(baseUrl, httpStatus, msg, null);
+        }
+      }
+      
+      NamedList<Object> rsp = null;
+      String charset = EntityUtils.getContentCharSet(response.getEntity());
+      try {
+        rsp = processor.processResponse(respBody, charset);
+      } catch (Exception e) {
+        throw new RemoteSolrException(baseUrl, httpStatus, e.getMessage(), e);
+      }
+      if (httpStatus != HttpStatus.SC_OK) {
+        NamedList<String> metadata = null;
+        String reason = null;
+        try {
+          NamedList err = (NamedList) rsp.get("error");
+          if (err != null) {
+            reason = (String) err.get("msg");
+            if(reason == null) {
+              reason = (String) err.get("trace");
+            }
+            metadata = (NamedList<String>)err.get("metadata");
+          }
+        } catch (Exception ex) {}
+        if (reason == null) {
+          StringBuilder msg = new StringBuilder();
+          msg.append(response.getStatusLine().getReasonPhrase());
+          msg.append("\n\n");
+          msg.append("request: " + method.getURI());
+          reason = java.net.URLDecoder.decode(msg.toString(), UTF_8);
+        }
+        RemoteSolrException rss = new RemoteSolrException(baseUrl, httpStatus, reason, null);
+        if (metadata != null) rss.setMetadata(metadata);
+        throw rss;
+      }
+      success = true;
+      return rsp;
+    } catch (ConnectException e) {
+      throw new SolrServerException("Server refused connection at: "
+          + getBaseURL(), e);
+    } catch (SocketTimeoutException e) {
+      throw new SolrServerException(
+          "Timeout occured while waiting response from server at: "
+              + getBaseURL(), e);
+    } catch (IOException e) {
+      throw new SolrServerException(
+          "IOException occured when talking to server at: " + getBaseURL(), e);
+    } finally {
+      if (respBody != null && shouldClose) {
+        try {
+          respBody.close();
+        } catch (IOException e) {
+          log.error("", e);
+        } finally {
+          if (!success) {
+            method.abort();
+          }
+        }
+      }
+    }
+  }
+  
+  // -------------------------------------------------------------------
+  // -------------------------------------------------------------------
+  
+  /**
+   * Retrieve the default list of parameters are added to every request
+   * regardless.
+   * 
+   * @see #invariantParams
+   */
+  public ModifiableSolrParams getInvariantParams() {
+    return invariantParams;
+  }
+  
+  public String getBaseURL() {
+    return baseUrl;
+  }
+  
+  public void setBaseURL(String baseURL) {
+    this.baseUrl = baseURL;
+  }
+  
+  public ResponseParser getParser() {
+    return parser;
+  }
+  
+  /**
+   * Note: This setter method is <b>not thread-safe</b>.
+   * 
+   * @param processor
+   *          Default Response Parser chosen to parse the response if the parser
+   *          were not specified as part of the request.
+   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
+   */
+  public void setParser(ResponseParser processor) {
+    parser = processor;
+  }
+  
+  /**
+   * Return the HttpClient this instance uses.
+   */
+  public HttpClient getHttpClient() {
+    return httpClient;
+  }
+  
+  /**
+   * HttpConnectionParams.setConnectionTimeout
+   * 
+   * @param timeout
+   *          Timeout in milliseconds
+   **/
+  public void setConnectionTimeout(int timeout) {
+    HttpClientUtil.setConnectionTimeout(httpClient, timeout);
+  }
+  
+  /**
+   * Set SoTimeout (read timeout). This is desirable
+   * for queries, but probably not for indexing.
+   * 
+   * @param timeout
+   *          Timeout in milliseconds
+   **/
+  public void setSoTimeout(int timeout) {
+    HttpClientUtil.setSoTimeout(httpClient, timeout);
+  }
+  
+  /**
+   * Configure whether the client should follow redirects or not.
+   * <p>
+   * This defaults to false under the assumption that if you are following a
+   * redirect to get to a Solr installation, something is misconfigured
+   * somewhere.
+   * </p>
+   */
+  public void setFollowRedirects(boolean followRedirects) {
+    this.followRedirects = followRedirects;
+    HttpClientUtil.setFollowRedirects(httpClient,  followRedirects);
+  }
+  
+  /**
+   * Allow server->client communication to be compressed. Currently gzip and
+   * deflate are supported. If the server supports compression the response will
+   * be compressed. This method is only allowed if the http client is of type
+   * DefatulHttpClient.
+   */
+  public void setAllowCompression(boolean allowCompression) {
+    if (httpClient instanceof DefaultHttpClient) {
+      HttpClientUtil.setAllowCompression((DefaultHttpClient) httpClient, allowCompression);
+    } else {
+      throw new UnsupportedOperationException(
+          "HttpClient instance was not of type DefaultHttpClient");
+    }
+  }
+  
+  /**
+   * Set maximum number of retries to attempt in the event of transient errors.
+   * <p>
+   * Maximum number of retries to attempt in the event of transient errors.
+   * Default: 0 (no) retries. No more than 1 recommended.
+   * </p>
+   * @param maxRetries
+   *          No more than 1 recommended
+   */
+  public void setMaxRetries(int maxRetries) {
+    if (maxRetries > 1) {
+      log.warn("HttpSolrServer: maximum Retries " + maxRetries
+          + " > 1. Maximum recommended retries is 1.");
+    }
+    this.maxRetries = maxRetries;
+  }
+  
+  public void setRequestWriter(RequestWriter requestWriter) {
+    this.requestWriter = requestWriter;
+  }
+  
+  /**
+   * Adds the documents supplied by the given iterator.
+   * 
+   * @param docIterator
+   *          the iterator which returns SolrInputDocument instances
+   * 
+   * @return the response from the SolrServer
+   */
+  public UpdateResponse add(Iterator<SolrInputDocument> docIterator)
+      throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.setDocIterator(docIterator);
+    return req.process(this);
+  }
+  
+  /**
+   * Adds the beans supplied by the given iterator.
+   * 
+   * @param beanIterator
+   *          the iterator which returns Beans
+   * 
+   * @return the response from the SolrServer
+   */
+  public UpdateResponse addBeans(final Iterator<?> beanIterator)
+      throws SolrServerException, IOException {
+    UpdateRequest req = new UpdateRequest();
+    req.setDocIterator(new Iterator<SolrInputDocument>() {
+      
+      @Override
+      public boolean hasNext() {
+        return beanIterator.hasNext();
+      }
+      
+      @Override
+      public SolrInputDocument next() {
+        Object o = beanIterator.next();
+        if (o == null) return null;
+        return getBinder().toSolrInputDocument(o);
+      }
+      
+      @Override
+      public void remove() {
+        beanIterator.remove();
+      }
+    });
+    return req.process(this);
+  }
+  
+  /**
+   * Close the {@link ClientConnectionManager} from the internal client.
+   */
+  @Override
+  public void shutdown() {
+    if (httpClient != null && internalClient) {
+      httpClient.getConnectionManager().shutdown();
+    }
+  }
+
+  /**
+   * Set the maximum number of connections that can be open to a single host at
+   * any given time. If http client was created outside the operation is not
+   * allowed.
+   */
+  public void setDefaultMaxConnectionsPerHost(int max) {
+    if (internalClient) {
+      HttpClientUtil.setMaxConnectionsPerHost(httpClient, max);
+    } else {
+      throw new UnsupportedOperationException(
+          "Client was created outside of HttpSolrServer");
+    }
+  }
+  
+  /**
+   * Set the maximum number of connections that can be open at any given time.
+   * If http client was created outside the operation is not allowed.
+   */
+  public void setMaxTotalConnections(int max) {
+    if (internalClient) {
+      HttpClientUtil.setMaxConnections(httpClient, max);
+    } else {
+      throw new UnsupportedOperationException(
+          "Client was created outside of HttpSolrServer");
+    }
+  }
+  
+  public boolean isUseMultiPartPost() {
+    return useMultiPartPost;
+  }
+
+  /**
+   * Set the multipart connection properties
+   */
+  public void setUseMultiPartPost(boolean useMultiPartPost) {
+    this.useMultiPartPost = useMultiPartPost;
+  }
+
+  /**
+   * Subclass of SolrException that allows us to capture an arbitrary HTTP
+   * status code that may have been returned by the remote server or a 
+   * proxy along the way.
+   */
+  public static class RemoteSolrException extends SolrException {
+    /**
+     * @param remoteHost the host the error was received from
+     * @param code Arbitrary HTTP status code
+     * @param msg Exception Message
+     * @param th Throwable to wrap with this Exception
+     */
+    public RemoteSolrException(String remoteHost, int code, String msg, Throwable th) {
+      super(code, "Error from server at " + remoteHost + ": " + msg, th);
+    }
+  }
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrServer.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrServer.java
index 7b2bcd7..ef5d439 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrServer.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/HttpSolrServer.java
@@ -14,810 +14,28 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package org.apache.solr.client.solrj.impl;
 
-import org.apache.commons.io.IOUtils;
-import org.apache.http.Header;
-import org.apache.http.HttpResponse;
-import org.apache.http.HttpStatus;
-import org.apache.http.NameValuePair;
-import org.apache.http.NoHttpResponseException;
 import org.apache.http.client.HttpClient;
-import org.apache.http.client.entity.UrlEncodedFormEntity;
-import org.apache.http.client.methods.HttpEntityEnclosingRequestBase;
-import org.apache.http.client.methods.HttpGet;
-import org.apache.http.client.methods.HttpPost;
-import org.apache.http.client.methods.HttpPut;
-import org.apache.http.client.methods.HttpRequestBase;
-import org.apache.http.client.methods.HttpUriRequest;
-import org.apache.http.conn.ClientConnectionManager;
-import org.apache.http.entity.ContentType;
-import org.apache.http.entity.InputStreamEntity;
-import org.apache.http.entity.mime.FormBodyPart;
-import org.apache.http.entity.mime.HttpMultipartMode;
-import org.apache.http.entity.mime.MultipartEntity;
-import org.apache.http.entity.mime.content.InputStreamBody;
-import org.apache.http.entity.mime.content.StringBody;
-import org.apache.http.impl.client.DefaultHttpClient;
-import org.apache.http.message.BasicHeader;
-import org.apache.http.message.BasicNameValuePair;
-import org.apache.http.util.EntityUtils;
 import org.apache.solr.client.solrj.ResponseParser;
-import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.request.RequestWriter;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.response.UpdateResponse;
-import org.apache.solr.client.solrj.util.ClientUtils;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.ContentStream;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.net.ConnectException;
-import java.net.SocketTimeoutException;
-import java.nio.charset.StandardCharsets;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Locale;
-import java.util.Set;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-
-public class HttpSolrServer extends SolrServer {
-  private static final String UTF_8 = StandardCharsets.UTF_8.name();
-  private static final String DEFAULT_PATH = "/select";
-  private static final long serialVersionUID = -946812319974801896L;
-  
-  /**
-   * User-Agent String.
-   */
-  public static final String AGENT = "Solr[" + HttpSolrServer.class.getName() + "] 1.0";
-  
-  private static Logger log = LoggerFactory.getLogger(HttpSolrServer.class);
-  
-  /**
-   * The URL of the Solr server.
-   */
-  protected volatile String baseUrl;
-  
-  /**
-   * Default value: null / empty.
-   * <p/>
-   * Parameters that are added to every request regardless. This may be a place
-   * to add something like an authentication token.
-   */
-  protected ModifiableSolrParams invariantParams;
-  
-  /**
-   * Default response parser is BinaryResponseParser
-   * <p/>
-   * This parser represents the default Response Parser chosen to parse the
-   * response if the parser were not specified as part of the request.
-   * 
-   * @see org.apache.solr.client.solrj.impl.BinaryResponseParser
-   */
-  protected volatile ResponseParser parser;
-  
-  /**
-   * The RequestWriter used to write all requests to Solr
-   * 
-   * @see org.apache.solr.client.solrj.request.RequestWriter
-   */
-  protected volatile RequestWriter requestWriter = new RequestWriter();
-  
-  private final HttpClient httpClient;
-  
-  private volatile boolean followRedirects = false;
-  
-  private volatile int maxRetries = 0;
-  
-  private volatile boolean useMultiPartPost;
-  private final boolean internalClient;
 
-  private volatile Set<String> queryParams = Collections.emptySet();
+/**
+ * @deprecated Use {@link org.apache.solr.client.solrj.impl.HttpSolrClient}
+ */
+@Deprecated
+public class HttpSolrServer extends HttpSolrClient {
 
-  /**
-   * @param baseURL
-   *          The URL of the Solr server. For example, "
-   *          <code>http://localhost:8983/solr/</code>" if you are using the
-   *          standard distribution Solr webapp on your local machine.
-   */
   public HttpSolrServer(String baseURL) {
-    this(baseURL, null, new BinaryResponseParser());
-  }
-  
-  public HttpSolrServer(String baseURL, HttpClient client) {
-    this(baseURL, client, new BinaryResponseParser());
-  }
-  
-  public HttpSolrServer(String baseURL, HttpClient client, ResponseParser parser) {
-    this.baseUrl = baseURL;
-    if (baseUrl.endsWith("/")) {
-      baseUrl = baseUrl.substring(0, baseUrl.length() - 1);
-    }
-    if (baseUrl.indexOf('?') >= 0) {
-      throw new RuntimeException(
-          "Invalid base url for solrj.  The base URL must not contain parameters: "
-              + baseUrl);
-    }
-    
-    if (client != null) {
-      httpClient = client;
-      internalClient = false;
-    } else {
-      internalClient = true;
-      ModifiableSolrParams params = new ModifiableSolrParams();
-      params.set(HttpClientUtil.PROP_MAX_CONNECTIONS, 128);
-      params.set(HttpClientUtil.PROP_MAX_CONNECTIONS_PER_HOST, 32);
-      params.set(HttpClientUtil.PROP_FOLLOW_REDIRECTS, followRedirects);
-      httpClient =  HttpClientUtil.createClient(params);
-    }
-    
-    this.parser = parser;
-  }
-  
-  public Set<String> getQueryParams() {
-    return queryParams;
-  }
-
-  /**
-   * Expert Method
-   * @param queryParams set of param keys to only send via the query string
-   * Note that the param will be sent as a query string if the key is part
-   * of this Set or the SolrRequest's query params.
-   * @see org.apache.solr.client.solrj.SolrRequest#getQueryParams
-   */
-  public void setQueryParams(Set<String> queryParams) {
-    this.queryParams = queryParams;
-  }
-  
-  /**
-   * Process the request. If
-   * {@link org.apache.solr.client.solrj.SolrRequest#getResponseParser()} is
-   * null, then use {@link #getParser()}
-   * 
-   * @param request
-   *          The {@link org.apache.solr.client.solrj.SolrRequest} to process
-   * @return The {@link org.apache.solr.common.util.NamedList} result
-   * @throws IOException If there is a low-level I/O error.
-   * 
-   * @see #request(org.apache.solr.client.solrj.SolrRequest,
-   *      org.apache.solr.client.solrj.ResponseParser)
-   */
-  @Override
-  public NamedList<Object> request(final SolrRequest request)
-      throws SolrServerException, IOException {
-    ResponseParser responseParser = request.getResponseParser();
-    if (responseParser == null) {
-      responseParser = parser;
-    }
-    return request(request, responseParser);
-  }
-  
-  public NamedList<Object> request(final SolrRequest request, final ResponseParser processor) throws SolrServerException, IOException {
-    return executeMethod(createMethod(request),processor);
-  }
-  
-  /**
-   * @lucene.experimental
-   */
-  public static class HttpUriRequestResponse {
-    public HttpUriRequest httpUriRequest;
-    public Future<NamedList<Object>> future;
-  }
-  
-  /**
-   * @lucene.experimental
-   */
-  public HttpUriRequestResponse httpUriRequest(final SolrRequest request)
-      throws SolrServerException, IOException {
-    ResponseParser responseParser = request.getResponseParser();
-    if (responseParser == null) {
-      responseParser = parser;
-    }
-    return httpUriRequest(request, responseParser);
-  }
-  
-  /**
-   * @lucene.experimental
-   */
-  public HttpUriRequestResponse httpUriRequest(final SolrRequest request, final ResponseParser processor) throws SolrServerException, IOException {
-    HttpUriRequestResponse mrr = new HttpUriRequestResponse();
-    final HttpRequestBase method = createMethod(request);
-    ExecutorService pool = Executors.newFixedThreadPool(1, new SolrjNamedThreadFactory("httpUriRequest"));
-    try {
-      mrr.future = pool.submit(new Callable<NamedList<Object>>(){
-
-        @Override
-        public NamedList<Object> call() throws Exception {
-          return executeMethod(method, processor);
-        }});
- 
-    } finally {
-      pool.shutdown();
-    }
-    assert method != null;
-    mrr.httpUriRequest = method;
-    return mrr;
-  }
-
-  protected ModifiableSolrParams calculateQueryParams(Set<String> queryParamNames,
-      ModifiableSolrParams wparams) {
-    ModifiableSolrParams queryModParams = new ModifiableSolrParams();
-    if (queryParamNames != null) {
-      for (String param : queryParamNames) {
-        String[] value = wparams.getParams(param) ;
-        if (value != null) {
-          for (String v : value) {
-            queryModParams.add(param, v);
-          }
-          wparams.remove(param);
-        }
-      }
-    }
-    return queryModParams;
-  }
-
-  protected HttpRequestBase createMethod(final SolrRequest request) throws IOException, SolrServerException {
-    HttpRequestBase method = null;
-    InputStream is = null;
-    SolrParams params = request.getParams();
-    Collection<ContentStream> streams = requestWriter.getContentStreams(request);
-    String path = requestWriter.getPath(request);
-    if (path == null || !path.startsWith("/")) {
-      path = DEFAULT_PATH;
-    }
-    
-    ResponseParser parser = request.getResponseParser();
-    if (parser == null) {
-      parser = this.parser;
-    }
-    
-    // The parser 'wt=' and 'version=' params are used instead of the original
-    // params
-    ModifiableSolrParams wparams = new ModifiableSolrParams(params);
-    if (parser != null) {
-      wparams.set(CommonParams.WT, parser.getWriterType());
-      wparams.set(CommonParams.VERSION, parser.getVersion());
-    }
-    if (invariantParams != null) {
-      wparams.add(invariantParams);
-    }
-    
-    int tries = maxRetries + 1;
-    try {
-      while( tries-- > 0 ) {
-        // Note: since we aren't do intermittent time keeping
-        // ourselves, the potential non-timeout latency could be as
-        // much as tries-times (plus scheduling effects) the given
-        // timeAllowed.
-        try {
-          if( SolrRequest.METHOD.GET == request.getMethod() ) {
-            if( streams != null ) {
-              throw new SolrException( SolrException.ErrorCode.BAD_REQUEST, "GET can't send streams!" );
-            }
-            method = new HttpGet( baseUrl + path + ClientUtils.toQueryString( wparams, false ) );
-          }
-          else if( SolrRequest.METHOD.POST == request.getMethod() || SolrRequest.METHOD.PUT == request.getMethod() ) {
-
-            String url = baseUrl + path;
-            boolean hasNullStreamName = false;
-            if (streams != null) {
-              for (ContentStream cs : streams) {
-                if (cs.getName() == null) {
-                  hasNullStreamName = true;
-                  break;
-                }
-              }
-            }
-            boolean isMultipart = ((this.useMultiPartPost && SolrRequest.METHOD.POST == request.getMethod())
-              || ( streams != null && streams.size() > 1 )) && !hasNullStreamName;
-
-            LinkedList<NameValuePair> postOrPutParams = new LinkedList<>();
-            if (streams == null || isMultipart) {
-              // send server list and request list as query string params
-              ModifiableSolrParams queryParams = calculateQueryParams(this.queryParams, wparams);
-              queryParams.add(calculateQueryParams(request.getQueryParams(), wparams));
-              String fullQueryUrl = url + ClientUtils.toQueryString( queryParams, false );
-              HttpEntityEnclosingRequestBase postOrPut = SolrRequest.METHOD.POST == request.getMethod() ?
-                new HttpPost(fullQueryUrl) : new HttpPut(fullQueryUrl);
-              if (!isMultipart) {
-                postOrPut.addHeader("Content-Type",
-                    "application/x-www-form-urlencoded; charset=UTF-8");
-              }
-
-              List<FormBodyPart> parts = new LinkedList<>();
-              Iterator<String> iter = wparams.getParameterNamesIterator();
-              while (iter.hasNext()) {
-                String p = iter.next();
-                String[] vals = wparams.getParams(p);
-                if (vals != null) {
-                  for (String v : vals) {
-                    if (isMultipart) {
-                      parts.add(new FormBodyPart(p, new StringBody(v, StandardCharsets.UTF_8)));
-                    } else {
-                      postOrPutParams.add(new BasicNameValuePair(p, v));
-                    }
-                  }
-                }
-              }
-
-              if (isMultipart && streams != null) {
-                for (ContentStream content : streams) {
-                  String contentType = content.getContentType();
-                  if(contentType==null) {
-                    contentType = BinaryResponseParser.BINARY_CONTENT_TYPE; // default
-                  }
-                  String name = content.getName();
-                  if(name==null) {
-                    name = "";
-                  }
-                  parts.add(new FormBodyPart(name, 
-                       new InputStreamBody(
-                           content.getStream(), 
-                           contentType, 
-                           content.getName())));
-                }
-              }
-              
-              if (parts.size() > 0) {
-                MultipartEntity entity = new MultipartEntity(HttpMultipartMode.STRICT);
-                for(FormBodyPart p: parts) {
-                  entity.addPart(p);
-                }
-                postOrPut.setEntity(entity);
-              } else {
-                //not using multipart
-                postOrPut.setEntity(new UrlEncodedFormEntity(postOrPutParams, StandardCharsets.UTF_8));
-              }
-
-              method = postOrPut;
-            }
-            // It is has one stream, it is the post body, put the params in the URL
-            else {
-              String pstr = ClientUtils.toQueryString(wparams, false);
-              HttpEntityEnclosingRequestBase postOrPut = SolrRequest.METHOD.POST == request.getMethod() ?
-                new HttpPost(url + pstr) : new HttpPut(url + pstr);
-
-              // Single stream as body
-              // Using a loop just to get the first one
-              final ContentStream[] contentStream = new ContentStream[1];
-              for (ContentStream content : streams) {
-                contentStream[0] = content;
-                break;
-              }
-              if (contentStream[0] instanceof RequestWriter.LazyContentStream) {
-                postOrPut.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {
-                  @Override
-                  public Header getContentType() {
-                    return new BasicHeader("Content-Type", contentStream[0].getContentType());
-                  }
-                  
-                  @Override
-                  public boolean isRepeatable() {
-                    return false;
-                  }
-                  
-                });
-              } else {
-                postOrPut.setEntity(new InputStreamEntity(contentStream[0].getStream(), -1) {
-                  @Override
-                  public Header getContentType() {
-                    return new BasicHeader("Content-Type", contentStream[0].getContentType());
-                  }
-                  
-                  @Override
-                  public boolean isRepeatable() {
-                    return false;
-                  }
-                });
-              }
-              method = postOrPut;
-            }
-          }
-          else {
-            throw new SolrServerException("Unsupported method: "+request.getMethod() );
-          }
-        }
-        catch( NoHttpResponseException r ) {
-          method = null;
-          if(is != null) {
-            is.close();
-          }
-          // If out of tries then just rethrow (as normal error).
-          if (tries < 1) {
-            throw r;
-          }
-        }
-      }
-    } catch (IOException ex) {
-      throw new SolrServerException("error reading streams", ex);
-    }
-    
-    return method;
-  }
-  
-  protected NamedList<Object> executeMethod(HttpRequestBase method, final ResponseParser processor) throws SolrServerException {
-    method.addHeader("User-Agent", AGENT);
-    
-    InputStream respBody = null;
-    boolean shouldClose = true;
-    boolean success = false;
-    try {
-      // Execute the method.
-      final HttpResponse response = httpClient.execute(method);
-      int httpStatus = response.getStatusLine().getStatusCode();
-      
-      // Read the contents
-      respBody = response.getEntity().getContent();
-      Header ctHeader = response.getLastHeader("content-type");
-      String contentType;
-      if (ctHeader != null) {
-        contentType = ctHeader.getValue();
-      } else {
-        contentType = "";
-      }
-      
-      // handle some http level checks before trying to parse the response
-      switch (httpStatus) {
-        case HttpStatus.SC_OK:
-        case HttpStatus.SC_BAD_REQUEST:
-        case HttpStatus.SC_CONFLICT:  // 409
-          break;
-        case HttpStatus.SC_MOVED_PERMANENTLY:
-        case HttpStatus.SC_MOVED_TEMPORARILY:
-          if (!followRedirects) {
-            throw new SolrServerException("Server at " + getBaseURL()
-                + " sent back a redirect (" + httpStatus + ").");
-          }
-          break;
-        default:
-          if (processor == null) {
-            throw new RemoteSolrException(baseUrl, httpStatus, "non ok status: " + httpStatus
-                + ", message:" + response.getStatusLine().getReasonPhrase(),
-                null);
-          }
-      }
-      if (processor == null) {
-        
-        // no processor specified, return raw stream
-        NamedList<Object> rsp = new NamedList<>();
-        rsp.add("stream", respBody);
-        // Only case where stream should not be closed
-        shouldClose = false;
-        success = true;
-        return rsp;
-      }
-      
-      String procCt = processor.getContentType();
-      if (procCt != null) {
-        String procMimeType = ContentType.parse(procCt).getMimeType().trim().toLowerCase(Locale.ROOT);
-        String mimeType = ContentType.parse(contentType).getMimeType().trim().toLowerCase(Locale.ROOT);
-        if (!procMimeType.equals(mimeType)) {
-          // unexpected mime type
-          String msg = "Expected mime type " + procMimeType + " but got " + mimeType + ".";
-          Header encodingHeader = response.getEntity().getContentEncoding();
-          String encoding;
-          if (encodingHeader != null) {
-            encoding = encodingHeader.getValue();
-          } else {
-            encoding = "UTF-8"; // try UTF-8
-          }
-          try {
-            msg = msg + " " + IOUtils.toString(respBody, encoding);
-          } catch (IOException e) {
-            throw new RemoteSolrException(baseUrl, httpStatus, "Could not parse response with encoding " + encoding, e);
-          }
-          RemoteSolrException e = new RemoteSolrException(baseUrl, httpStatus, msg, null);
-          throw e;
-        }
-      }
-      
-//      if(true) {
-//        ByteArrayOutputStream copy = new ByteArrayOutputStream();
-//        IOUtils.copy(respBody, copy);
-//        String val = new String(copy.toByteArray());
-//        System.out.println(">RESPONSE>"+val+"<"+val.length());
-//        respBody = new ByteArrayInputStream(copy.toByteArray());
-//      }
-      
-      NamedList<Object> rsp = null;
-      String charset = EntityUtils.getContentCharSet(response.getEntity());
-      try {
-        rsp = processor.processResponse(respBody, charset);
-      } catch (Exception e) {
-        throw new RemoteSolrException(baseUrl, httpStatus, e.getMessage(), e);
-      }
-      if (httpStatus != HttpStatus.SC_OK) {
-        NamedList<String> metadata = null;
-        String reason = null;
-        try {
-          NamedList err = (NamedList) rsp.get("error");
-          if (err != null) {
-            reason = (String) err.get("msg");
-            if(reason == null) {
-              reason = (String) err.get("trace");
-            }
-            metadata = (NamedList<String>)err.get("metadata");
-          }
-        } catch (Exception ex) {}
-        if (reason == null) {
-          StringBuilder msg = new StringBuilder();
-          msg.append(response.getStatusLine().getReasonPhrase());
-          msg.append("\n\n");
-          msg.append("request: " + method.getURI());
-          reason = java.net.URLDecoder.decode(msg.toString(), UTF_8);
-        }
-        RemoteSolrException rss = new RemoteSolrException(baseUrl, httpStatus, reason, null);
-        if (metadata != null) rss.setMetadata(metadata);
-        throw rss;
-      }
-      success = true;
-      return rsp;
-    } catch (ConnectException e) {
-      throw new SolrServerException("Server refused connection at: "
-          + getBaseURL(), e);
-    } catch (SocketTimeoutException e) {
-      throw new SolrServerException(
-          "Timeout occured while waiting response from server at: "
-              + getBaseURL(), e);
-    } catch (IOException e) {
-      throw new SolrServerException(
-          "IOException occured when talking to server at: " + getBaseURL(), e);
-    } finally {
-      if (respBody != null && shouldClose) {
-        try {
-          respBody.close();
-        } catch (IOException e) {
-          log.error("", e);
-        } finally {
-          if (!success) {
-            method.abort();
-          }
-        }
-      }
-    }
-  }
-  
-  // -------------------------------------------------------------------
-  // -------------------------------------------------------------------
-  
-  /**
-   * Retrieve the default list of parameters are added to every request
-   * regardless.
-   * 
-   * @see #invariantParams
-   */
-  public ModifiableSolrParams getInvariantParams() {
-    return invariantParams;
-  }
-  
-  public String getBaseURL() {
-    return baseUrl;
-  }
-  
-  public void setBaseURL(String baseURL) {
-    this.baseUrl = baseURL;
-  }
-  
-  public ResponseParser getParser() {
-    return parser;
-  }
-  
-  /**
-   * Note: This setter method is <b>not thread-safe</b>.
-   * 
-   * @param processor
-   *          Default Response Parser chosen to parse the response if the parser
-   *          were not specified as part of the request.
-   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
-   */
-  public void setParser(ResponseParser processor) {
-    parser = processor;
-  }
-  
-  /**
-   * Return the HttpClient this instance uses.
-   */
-  public HttpClient getHttpClient() {
-    return httpClient;
-  }
-  
-  /**
-   * HttpConnectionParams.setConnectionTimeout
-   * 
-   * @param timeout
-   *          Timeout in milliseconds
-   **/
-  public void setConnectionTimeout(int timeout) {
-    HttpClientUtil.setConnectionTimeout(httpClient, timeout);
-  }
-  
-  /**
-   * Set SoTimeout (read timeout). This is desirable
-   * for queries, but probably not for indexing.
-   * 
-   * @param timeout
-   *          Timeout in milliseconds
-   **/
-  public void setSoTimeout(int timeout) {
-    HttpClientUtil.setSoTimeout(httpClient, timeout);
-  }
-  
-  /**
-   * Configure whether the client should follow redirects or not.
-   * <p>
-   * This defaults to false under the assumption that if you are following a
-   * redirect to get to a Solr installation, something is misconfigured
-   * somewhere.
-   * </p>
-   */
-  public void setFollowRedirects(boolean followRedirects) {
-    this.followRedirects = followRedirects;
-    HttpClientUtil.setFollowRedirects(httpClient,  followRedirects);
-  }
-  
-  /**
-   * Allow server->client communication to be compressed. Currently gzip and
-   * deflate are supported. If the server supports compression the response will
-   * be compressed. This method is only allowed if the http client is of type
-   * DefatulHttpClient.
-   */
-  public void setAllowCompression(boolean allowCompression) {
-    if (httpClient instanceof DefaultHttpClient) {
-      HttpClientUtil.setAllowCompression((DefaultHttpClient) httpClient, allowCompression);
-    } else {
-      throw new UnsupportedOperationException(
-          "HttpClient instance was not of type DefaultHttpClient");
-    }
-  }
-  
-  /**
-   * Set maximum number of retries to attempt in the event of transient errors.
-   * <p>
-   * Maximum number of retries to attempt in the event of transient errors.
-   * Default: 0 (no) retries. No more than 1 recommended.
-   * </p>
-   * @param maxRetries
-   *          No more than 1 recommended
-   */
-  public void setMaxRetries(int maxRetries) {
-    if (maxRetries > 1) {
-      log.warn("HttpSolrServer: maximum Retries " + maxRetries
-          + " > 1. Maximum recommended retries is 1.");
-    }
-    this.maxRetries = maxRetries;
-  }
-  
-  public void setRequestWriter(RequestWriter requestWriter) {
-    this.requestWriter = requestWriter;
-  }
-  
-  /**
-   * Adds the documents supplied by the given iterator.
-   * 
-   * @param docIterator
-   *          the iterator which returns SolrInputDocument instances
-   * 
-   * @return the response from the SolrServer
-   */
-  public UpdateResponse add(Iterator<SolrInputDocument> docIterator)
-      throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.setDocIterator(docIterator);
-    return req.process(this);
-  }
-  
-  /**
-   * Adds the beans supplied by the given iterator.
-   * 
-   * @param beanIterator
-   *          the iterator which returns Beans
-   * 
-   * @return the response from the SolrServer
-   */
-  public UpdateResponse addBeans(final Iterator<?> beanIterator)
-      throws SolrServerException, IOException {
-    UpdateRequest req = new UpdateRequest();
-    req.setDocIterator(new Iterator<SolrInputDocument>() {
-      
-      @Override
-      public boolean hasNext() {
-        return beanIterator.hasNext();
-      }
-      
-      @Override
-      public SolrInputDocument next() {
-        Object o = beanIterator.next();
-        if (o == null) return null;
-        return getBinder().toSolrInputDocument(o);
-      }
-      
-      @Override
-      public void remove() {
-        beanIterator.remove();
-      }
-    });
-    return req.process(this);
-  }
-  
-  /**
-   * Close the {@link ClientConnectionManager} from the internal client.
-   */
-  @Override
-  public void shutdown() {
-    if (httpClient != null && internalClient) {
-      httpClient.getConnectionManager().shutdown();
-    }
+    super(baseURL);
   }
 
-  /**
-   * Set the maximum number of connections that can be open to a single host at
-   * any given time. If http client was created outside the operation is not
-   * allowed.
-   */
-  public void setDefaultMaxConnectionsPerHost(int max) {
-    if (internalClient) {
-      HttpClientUtil.setMaxConnectionsPerHost(httpClient, max);
-    } else {
-      throw new UnsupportedOperationException(
-          "Client was created outside of HttpSolrServer");
-    }
-  }
-  
-  /**
-   * Set the maximum number of connections that can be open at any given time.
-   * If http client was created outside the operation is not allowed.
-   */
-  public void setMaxTotalConnections(int max) {
-    if (internalClient) {
-      HttpClientUtil.setMaxConnections(httpClient, max);
-    } else {
-      throw new UnsupportedOperationException(
-          "Client was created outside of HttpSolrServer");
-    }
-  }
-  
-  public boolean isUseMultiPartPost() {
-    return useMultiPartPost;
+  public HttpSolrServer(String baseURL, HttpClient client) {
+    super(baseURL, client);
   }
 
-  /**
-   * Set the multipart connection properties
-   */
-  public void setUseMultiPartPost(boolean useMultiPartPost) {
-    this.useMultiPartPost = useMultiPartPost;
+  public HttpSolrServer(String baseURL, HttpClient client, ResponseParser parser) {
+    super(baseURL, client, parser);
   }
 
-  /**
-   * Subclass of SolrException that allows us to capture an arbitrary HTTP
-   * status code that may have been returned by the remote server or a 
-   * proxy along the way.
-   */
-  public static class RemoteSolrException extends SolrException {
-    /**
-     * @param remoteHost the host the error was received from
-     * @param code Arbitrary HTTP status code
-     * @param msg Exception Message
-     * @param th Throwable to wrap with this Exception
-     */
-    public RemoteSolrException(String remoteHost, int code, String msg, Throwable th) {
-      super(code, "Error from server at " + remoteHost + ": " + msg, th);
-    }
-  }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrClient.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrClient.java
new file mode 100644
index 0000000..615ad23
--- /dev/null
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrClient.java
@@ -0,0 +1,685 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.http.client.HttpClient;
+import org.apache.solr.client.solrj.*;
+import org.apache.solr.client.solrj.request.IsUpdateRequest;
+import org.apache.solr.client.solrj.request.RequestWriter;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.common.util.SolrjNamedThreadFactory;
+import org.apache.solr.common.SolrException;
+
+import java.io.IOException;
+import java.lang.ref.WeakReference;
+import java.net.ConnectException;
+import java.net.MalformedURLException;
+import java.net.SocketException;
+import java.net.SocketTimeoutException;
+import java.net.URL;
+import java.util.concurrent.*;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.*;
+
+/**
+ * LBHttpSolrClient or "LoadBalanced HttpSolrClient" is a load balancing wrapper around
+ * {@link HttpSolrClient}. This is useful when you
+ * have multiple Solr servers and the requests need to be Load Balanced among them.
+ *
+ * Do <b>NOT</b> use this class for indexing in master/slave scenarios since documents must be sent to the
+ * correct master; no inter-node routing is done.
+ *
+ * In SolrCloud (leader/replica) scenarios, it is usually better to use
+ * {@link CloudSolrClient}, but this class may be used
+ * for updates because the server will forward them to the appropriate leader.
+ *
+ * <p/>
+ * It offers automatic failover when a server goes down and it detects when the server comes back up.
+ * <p/>
+ * Load balancing is done using a simple round-robin on the list of servers.
+ * <p/>
+ * If a request to a server fails by an IOException due to a connection timeout or read timeout then the host is taken
+ * off the list of live servers and moved to a 'dead server list' and the request is resent to the next live server.
+ * This process is continued till it tries all the live servers. If at least one server is alive, the request succeeds,
+ * and if not it fails.
+ * <blockquote><pre>
+ * SolrClient lbHttpSolrClient = new LBHttpSolrClient("http://host1:8080/solr/", "http://host2:8080/solr", "http://host2:8080/solr");
+ * //or if you wish to pass the HttpClient do as follows
+ * httpClient httpClient = new HttpClient();
+ * SolrClient lbHttpSolrClient = new LBHttpSolrClient(httpClient, "http://host1:8080/solr/", "http://host2:8080/solr", "http://host2:8080/solr");
+ * </pre></blockquote>
+ * This detects if a dead server comes alive automatically. The check is done in fixed intervals in a dedicated thread.
+ * This interval can be set using {@link #setAliveCheckInterval} , the default is set to one minute.
+ * <p/>
+ * <b>When to use this?</b><br/> This can be used as a software load balancer when you do not wish to setup an external
+ * load balancer. Alternatives to this code are to use
+ * a dedicated hardware load balancer or using Apache httpd with mod_proxy_balancer as a load balancer. See <a
+ * href="http://en.wikipedia.org/wiki/Load_balancing_(computing)">Load balancing on Wikipedia</a>
+ *
+ * @since solr 1.4
+ */
+public class LBHttpSolrClient extends SolrClient {
+  private static Set<Integer> RETRY_CODES = new HashSet<>(4);
+
+  static {
+    RETRY_CODES.add(404);
+    RETRY_CODES.add(403);
+    RETRY_CODES.add(503);
+    RETRY_CODES.add(500);
+  }
+
+  // keys to the maps are currently of the form "http://localhost:8983/solr"
+  // which should be equivalent to HttpSolrServer.getBaseURL()
+  private final Map<String, ServerWrapper> aliveServers = new LinkedHashMap<>();
+  // access to aliveServers should be synchronized on itself
+  
+  protected final Map<String, ServerWrapper> zombieServers = new ConcurrentHashMap<>();
+
+  // changes to aliveServers are reflected in this array, no need to synchronize
+  private volatile ServerWrapper[] aliveServerList = new ServerWrapper[0];
+
+
+  private ScheduledExecutorService aliveCheckExecutor;
+
+  private final HttpClient httpClient;
+  private final boolean clientIsInternal;
+  private final AtomicInteger counter = new AtomicInteger(-1);
+
+  private static final SolrQuery solrQuery = new SolrQuery("*:*");
+  private volatile ResponseParser parser;
+  private volatile RequestWriter requestWriter;
+
+  private Set<String> queryParams = new HashSet<>();
+
+  static {
+    solrQuery.setRows(0);
+    /**
+     * Default sort (if we don't supply a sort) is by score and since
+     * we request 0 rows any sorting and scoring is not necessary.
+     * SolrQuery.DOCID schema-independently specifies a non-scoring sort.
+     * <code>_docid_ asc</code> sort is efficient,
+     * <code>_docid_ desc</code> sort is not, so choose ascending DOCID sort.
+     */
+    solrQuery.setSort(SolrQuery.DOCID, SolrQuery.ORDER.asc);
+    // not a top-level request, we are interested only in the server being sent to i.e. it need not distribute our request to further servers    
+    solrQuery.setDistrib(false);
+  }
+
+  protected static class ServerWrapper {
+
+    final HttpSolrClient client;
+
+    long lastUsed;     // last time used for a real request
+    long lastChecked;  // last time checked for liveness
+
+    // "standard" servers are used by default.  They normally live in the alive list
+    // and move to the zombie list when unavailable.  When they become available again,
+    // they move back to the alive list.
+    boolean standard = true;
+
+    int failedPings = 0;
+
+    public ServerWrapper(HttpSolrClient client) {
+      this.client = client;
+    }
+
+    @Override
+    public String toString() {
+      return client.getBaseURL();
+    }
+
+    public String getKey() {
+      return client.getBaseURL();
+    }
+
+    @Override
+    public int hashCode() {
+      return this.getKey().hashCode();
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj) return true;
+      if (!(obj instanceof ServerWrapper)) return false;
+      return this.getKey().equals(((ServerWrapper)obj).getKey());
+    }
+  }
+
+  public static class Req {
+    protected SolrRequest request;
+    protected List<String> servers;
+    protected int numDeadServersToTry;
+
+    public Req(SolrRequest request, List<String> servers) {
+      this.request = request;
+      this.servers = servers;
+      this.numDeadServersToTry = servers.size();
+    }
+
+    public SolrRequest getRequest() {
+      return request;
+    }
+    public List<String> getServers() {
+      return servers;
+    }
+
+    /** @return the number of dead servers to try if there are no live servers left */
+    public int getNumDeadServersToTry() {
+      return numDeadServersToTry;
+    }
+
+    /** @param numDeadServersToTry The number of dead servers to try if there are no live servers left.
+     * Defaults to the number of servers in this request. */
+    public void setNumDeadServersToTry(int numDeadServersToTry) {
+      this.numDeadServersToTry = numDeadServersToTry;
+    }
+  }
+
+  public static class Rsp {
+    protected String server;
+    protected NamedList<Object> rsp;
+
+    /** The response from the server */
+    public NamedList<Object> getResponse() {
+      return rsp;
+    }
+
+    /** The server that returned the response */
+    public String getServer() {
+      return server;
+    }
+  }
+
+  public LBHttpSolrClient(String... solrServerUrls) throws MalformedURLException {
+    this(null, solrServerUrls);
+  }
+  
+  /** The provided httpClient should use a multi-threaded connection manager */ 
+  public LBHttpSolrClient(HttpClient httpClient, String... solrServerUrl) {
+    this(httpClient, new BinaryResponseParser(), solrServerUrl);
+  }
+
+  /** The provided httpClient should use a multi-threaded connection manager */  
+  public LBHttpSolrClient(HttpClient httpClient, ResponseParser parser, String... solrServerUrl) {
+    clientIsInternal = (httpClient == null);
+    this.parser = parser;
+    if (httpClient == null) {
+      ModifiableSolrParams params = new ModifiableSolrParams();
+      params.set(HttpClientUtil.PROP_USE_RETRY, false);
+      this.httpClient = HttpClientUtil.createClient(params);
+    } else {
+      this.httpClient = httpClient;
+    }
+    for (String s : solrServerUrl) {
+      ServerWrapper wrapper = new ServerWrapper(makeSolrClient(s));
+      aliveServers.put(wrapper.getKey(), wrapper);
+    }
+    updateAliveList();
+  }
+  
+  public Set<String> getQueryParams() {
+    return queryParams;
+  }
+
+  /**
+   * Expert Method.
+   * @param queryParams set of param keys to only send via the query string
+   */
+  public void setQueryParams(Set<String> queryParams) {
+    this.queryParams = queryParams;
+  }
+  public void addQueryParams(String queryOnlyParam) {
+    this.queryParams.add(queryOnlyParam) ;
+  }
+
+  public static String normalize(String server) {
+    if (server.endsWith("/"))
+      server = server.substring(0, server.length() - 1);
+    return server;
+  }
+
+  protected HttpSolrClient makeSolrClient(String server) {
+    HttpSolrClient client = new HttpSolrClient(server, httpClient, parser);
+    if (requestWriter != null) {
+      client.setRequestWriter(requestWriter);
+    }
+    if (queryParams != null) {
+      client.setQueryParams(queryParams);
+    }
+    return client;
+  }
+
+  /**
+   * Tries to query a live server from the list provided in Req. Servers in the dead pool are skipped.
+   * If a request fails due to an IOException, the server is moved to the dead pool for a certain period of
+   * time, or until a test request on that server succeeds.
+   *
+   * Servers are queried in the exact order given (except servers currently in the dead pool are skipped).
+   * If no live servers from the provided list remain to be tried, a number of previously skipped dead servers will be tried.
+   * Req.getNumDeadServersToTry() controls how many dead servers will be tried.
+   *
+   * If no live servers are found a SolrServerException is thrown.
+   *
+   * @param req contains both the request as well as the list of servers to query
+   *
+   * @return the result of the request
+   *
+   * @throws IOException If there is a low-level I/O error.
+   */
+  public Rsp request(Req req) throws SolrServerException, IOException {
+    Rsp rsp = new Rsp();
+    Exception ex = null;
+    boolean isUpdate = req.request instanceof IsUpdateRequest;
+    List<ServerWrapper> skipped = null;
+
+    for (String serverStr : req.getServers()) {
+      serverStr = normalize(serverStr);
+      // if the server is currently a zombie, just skip to the next one
+      ServerWrapper wrapper = zombieServers.get(serverStr);
+      if (wrapper != null) {
+        // System.out.println("ZOMBIE SERVER QUERIED: " + serverStr);
+        final int numDeadServersToTry = req.getNumDeadServersToTry();
+        if (numDeadServersToTry > 0) {
+          if (skipped == null) {
+            skipped = new ArrayList<>(numDeadServersToTry);
+            skipped.add(wrapper);
+          }
+          else if (skipped.size() < numDeadServersToTry) {
+            skipped.add(wrapper);
+          }
+        }
+        continue;
+      }
+      rsp.server = serverStr;
+      HttpSolrClient client = makeSolrClient(serverStr);
+
+      ex = doRequest(client, req, rsp, isUpdate, false, null);
+      if (ex == null) {
+        return rsp; // SUCCESS
+      }
+    }
+
+    // try the servers we previously skipped
+    if (skipped != null) {
+      for (ServerWrapper wrapper : skipped) {
+        ex = doRequest(wrapper.client, req, rsp, isUpdate, true, wrapper.getKey());
+        if (ex == null) {
+          return rsp; // SUCCESS
+        }
+      }
+    }
+
+
+    if (ex == null) {
+      throw new SolrServerException("No live SolrServers available to handle this request");
+    } else {
+      throw new SolrServerException("No live SolrServers available to handle this request:" + zombieServers.keySet(), ex);
+    }
+
+  }
+
+  protected Exception addZombie(HttpSolrClient server, Exception e) {
+
+    ServerWrapper wrapper;
+
+    wrapper = new ServerWrapper(server);
+    wrapper.lastUsed = System.currentTimeMillis();
+    wrapper.standard = false;
+    zombieServers.put(wrapper.getKey(), wrapper);
+    startAliveCheckExecutor();
+    return e;
+  }  
+
+  protected Exception doRequest(HttpSolrClient client, Req req, Rsp rsp, boolean isUpdate,
+      boolean isZombie, String zombieKey) throws SolrServerException, IOException {
+    Exception ex = null;
+    try {
+      rsp.rsp = client.request(req.getRequest());
+      if (isZombie) {
+        zombieServers.remove(zombieKey);
+      }
+    } catch (SolrException e) {
+      // we retry on 404 or 403 or 503 or 500
+      // unless it's an update - then we only retry on connect exception
+      if (!isUpdate && RETRY_CODES.contains(e.code())) {
+        ex = (!isZombie) ? addZombie(client, e) : e;
+      } else {
+        // Server is alive but the request was likely malformed or invalid
+        if (isZombie) {
+          zombieServers.remove(zombieKey);
+        }
+        throw e;
+      }
+    } catch (SocketException e) {
+      if (!isUpdate || e instanceof ConnectException) {
+        ex = (!isZombie) ? addZombie(client, e) : e;
+      } else {
+        throw e;
+      }
+    } catch (SocketTimeoutException e) {
+      if (!isUpdate) {
+        ex = (!isZombie) ? addZombie(client, e) : e;
+      } else {
+        throw e;
+      }
+    } catch (SolrServerException e) {
+      Throwable rootCause = e.getRootCause();
+      if (!isUpdate && rootCause instanceof IOException) {
+        ex = (!isZombie) ? addZombie(client, e) : e;
+      } else if (isUpdate && rootCause instanceof ConnectException) {
+        ex = (!isZombie) ? addZombie(client, e) : e;
+      } else {
+        throw e;
+      }
+    } catch (Exception e) {
+      throw new SolrServerException(e);
+    }
+
+    return ex;
+  }
+
+  private void updateAliveList() {
+    synchronized (aliveServers) {
+      aliveServerList = aliveServers.values().toArray(new ServerWrapper[aliveServers.size()]);
+    }
+  }
+
+  private ServerWrapper removeFromAlive(String key) {
+    synchronized (aliveServers) {
+      ServerWrapper wrapper = aliveServers.remove(key);
+      if (wrapper != null)
+        updateAliveList();
+      return wrapper;
+    }
+  }
+
+  private void addToAlive(ServerWrapper wrapper) {
+    synchronized (aliveServers) {
+      ServerWrapper prev = aliveServers.put(wrapper.getKey(), wrapper);
+      // TODO: warn if there was a previous entry?
+      updateAliveList();
+    }
+  }
+
+  public void addSolrServer(String server) throws MalformedURLException {
+    HttpSolrClient client = makeSolrClient(server);
+    addToAlive(new ServerWrapper(client));
+  }
+
+  public String removeSolrServer(String server) {
+    try {
+      server = new URL(server).toExternalForm();
+    } catch (MalformedURLException e) {
+      throw new RuntimeException(e);
+    }
+    if (server.endsWith("/")) {
+      server = server.substring(0, server.length() - 1);
+    }
+
+    // there is a small race condition here - if the server is in the process of being moved between
+    // lists, we could fail to remove it.
+    removeFromAlive(server);
+    zombieServers.remove(server);
+    return null;
+  }
+
+  public void setConnectionTimeout(int timeout) {
+    HttpClientUtil.setConnectionTimeout(httpClient, timeout);
+  }
+
+  /**
+   * set soTimeout (read timeout) on the underlying HttpConnectionManager. This is desirable for queries, but probably
+   * not for indexing.
+   */
+  public void setSoTimeout(int timeout) {
+    HttpClientUtil.setSoTimeout(httpClient, timeout);
+  }
+
+  @Override
+  public void shutdown() {
+    if (aliveCheckExecutor != null) {
+      aliveCheckExecutor.shutdownNow();
+    }
+    if(clientIsInternal) {
+      httpClient.getConnectionManager().shutdown();
+    }
+  }
+
+  /**
+   * Tries to query a live server. A SolrServerException is thrown if all servers are dead.
+   * If the request failed due to IOException then the live server is moved to dead pool and the request is
+   * retried on another live server.  After live servers are exhausted, any servers previously marked as dead
+   * will be tried before failing the request.
+   *
+   * @param request the SolrRequest.
+   *
+   * @return response
+   *
+   * @throws IOException If there is a low-level I/O error.
+   */
+  @Override
+  public NamedList<Object> request(final SolrRequest request)
+          throws SolrServerException, IOException {
+    Exception ex = null;
+    ServerWrapper[] serverList = aliveServerList;
+    
+    int maxTries = serverList.length;
+    Map<String,ServerWrapper> justFailed = null;
+
+    for (int attempts=0; attempts<maxTries; attempts++) {
+      int count = counter.incrementAndGet() & Integer.MAX_VALUE;
+      ServerWrapper wrapper = serverList[count % serverList.length];
+      wrapper.lastUsed = System.currentTimeMillis();
+
+      try {
+        return wrapper.client.request(request);
+      } catch (SolrException e) {
+        // Server is alive but the request was malformed or invalid
+        throw e;
+      } catch (SolrServerException e) {
+        if (e.getRootCause() instanceof IOException) {
+          ex = e;
+          moveAliveToDead(wrapper);
+          if (justFailed == null) justFailed = new HashMap<>();
+          justFailed.put(wrapper.getKey(), wrapper);
+        } else {
+          throw e;
+        }
+      } catch (Exception e) {
+        throw new SolrServerException(e);
+      }
+    }
+
+
+    // try other standard servers that we didn't try just now
+    for (ServerWrapper wrapper : zombieServers.values()) {
+      if (wrapper.standard==false || justFailed!=null && justFailed.containsKey(wrapper.getKey())) continue;
+      try {
+        NamedList<Object> rsp = wrapper.client.request(request);
+        // remove from zombie list *before* adding to alive to avoid a race that could lose a server
+        zombieServers.remove(wrapper.getKey());
+        addToAlive(wrapper);
+        return rsp;
+      } catch (SolrException e) {
+        // Server is alive but the request was malformed or invalid
+        throw e;
+      } catch (SolrServerException e) {
+        if (e.getRootCause() instanceof IOException) {
+          ex = e;
+          // still dead
+        } else {
+          throw e;
+        }
+      } catch (Exception e) {
+        throw new SolrServerException(e);
+      }
+    }
+
+
+    if (ex == null) {
+      throw new SolrServerException("No live SolrServers available to handle this request");
+    } else {
+      throw new SolrServerException("No live SolrServers available to handle this request", ex);
+    }
+  }
+  
+  /**
+   * Takes up one dead server and check for aliveness. The check is done in a roundrobin. Each server is checked for
+   * aliveness once in 'x' millis where x is decided by the setAliveCheckinterval() or it is defaulted to 1 minute
+   *
+   * @param zombieServer a server in the dead pool
+   */
+  private void checkAZombieServer(ServerWrapper zombieServer) {
+    long currTime = System.currentTimeMillis();
+    try {
+      zombieServer.lastChecked = currTime;
+      QueryResponse resp = zombieServer.client.query(solrQuery);
+      if (resp.getStatus() == 0) {
+        // server has come back up.
+        // make sure to remove from zombies before adding to alive to avoid a race condition
+        // where another thread could mark it down, move it back to zombie, and then we delete
+        // from zombie and lose it forever.
+        ServerWrapper wrapper = zombieServers.remove(zombieServer.getKey());
+        if (wrapper != null) {
+          wrapper.failedPings = 0;
+          if (wrapper.standard) {
+            addToAlive(wrapper);
+          }
+        } else {
+          // something else already moved the server from zombie to alive
+        }
+      }
+    } catch (Exception e) {
+      //Expected. The server is still down.
+      zombieServer.failedPings++;
+
+      // If the server doesn't belong in the standard set belonging to this load balancer
+      // then simply drop it after a certain number of failed pings.
+      if (!zombieServer.standard && zombieServer.failedPings >= NONSTANDARD_PING_LIMIT) {
+        zombieServers.remove(zombieServer.getKey());
+      }
+    }
+  }
+
+  private void moveAliveToDead(ServerWrapper wrapper) {
+    wrapper = removeFromAlive(wrapper.getKey());
+    if (wrapper == null)
+      return;  // another thread already detected the failure and removed it
+    zombieServers.put(wrapper.getKey(), wrapper);
+    startAliveCheckExecutor();
+  }
+
+  private int interval = CHECK_INTERVAL;
+
+  /**
+   * LBHttpSolrServer keeps pinging the dead servers at fixed interval to find if it is alive. Use this to set that
+   * interval
+   *
+   * @param interval time in milliseconds
+   */
+  public void setAliveCheckInterval(int interval) {
+    if (interval <= 0) {
+      throw new IllegalArgumentException("Alive check interval must be " +
+              "positive, specified value = " + interval);
+    }
+    this.interval = interval;
+  }
+
+  private void startAliveCheckExecutor() {
+    // double-checked locking, but it's OK because we don't *do* anything with aliveCheckExecutor
+    // if it's not null.
+    if (aliveCheckExecutor == null) {
+      synchronized (this) {
+        if (aliveCheckExecutor == null) {
+          aliveCheckExecutor = Executors.newSingleThreadScheduledExecutor(
+              new SolrjNamedThreadFactory("aliveCheckExecutor"));
+          aliveCheckExecutor.scheduleAtFixedRate(
+                  getAliveCheckRunner(new WeakReference<>(this)),
+                  this.interval, this.interval, TimeUnit.MILLISECONDS);
+        }
+      }
+    }
+  }
+
+  private static Runnable getAliveCheckRunner(final WeakReference<LBHttpSolrClient> lbRef) {
+    return new Runnable() {
+      @Override
+      public void run() {
+        LBHttpSolrClient lb = lbRef.get();
+        if (lb != null && lb.zombieServers != null) {
+          for (ServerWrapper zombieServer : lb.zombieServers.values()) {
+            lb.checkAZombieServer(zombieServer);
+          }
+        }
+      }
+    };
+  }
+
+  /**
+   * Return the HttpClient this instance uses.
+   */
+  public HttpClient getHttpClient() {
+    return httpClient;
+  }
+
+  public ResponseParser getParser() {
+    return parser;
+  }
+
+  /**
+   * Changes the {@link ResponseParser} that will be used for the internal
+   * SolrServer objects.
+   *
+   * @param parser Default Response Parser chosen to parse the response if the parser
+   *               were not specified as part of the request.
+   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
+   */
+  public void setParser(ResponseParser parser) {
+    this.parser = parser;
+  }
+
+  /**
+   * Changes the {@link RequestWriter} that will be used for the internal
+   * SolrServer objects.
+   *
+   * @param requestWriter Default RequestWriter, used to encode requests sent to the server.
+   */
+  public void setRequestWriter(RequestWriter requestWriter) {
+    this.requestWriter = requestWriter;
+  }
+  
+  public RequestWriter getRequestWriter() {
+    return requestWriter;
+  }
+  
+  @Override
+  protected void finalize() throws Throwable {
+    try {
+      if(this.aliveCheckExecutor!=null)
+        this.aliveCheckExecutor.shutdownNow();
+    } finally {
+      super.finalize();
+    }
+  }
+
+  // defaults
+  private static final int CHECK_INTERVAL = 60 * 1000; //1 minute between checks
+  private static final int NONSTANDARD_PING_LIMIT = 5;  // number of times we'll ping dead servers not in the server list
+
+}
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrServer.java b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrServer.java
index 24e583d..ee28241 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrServer.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/impl/LBHttpSolrServer.java
@@ -14,673 +14,30 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package org.apache.solr.client.solrj.impl;
 
 import org.apache.http.client.HttpClient;
-import org.apache.solr.client.solrj.*;
-import org.apache.solr.client.solrj.request.IsUpdateRequest;
-import org.apache.solr.client.solrj.request.RequestWriter;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.apache.solr.common.SolrException;
+import org.apache.solr.client.solrj.ResponseParser;
 
-import java.io.IOException;
-import java.lang.ref.WeakReference;
-import java.net.ConnectException;
 import java.net.MalformedURLException;
-import java.net.SocketException;
-import java.net.SocketTimeoutException;
-import java.net.URL;
-import java.util.concurrent.*;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.*;
 
 /**
- * LBHttpSolrServer or "LoadBalanced HttpSolrServer" is a load balancing wrapper around
- * {@link org.apache.solr.client.solrj.impl.HttpSolrServer}. This is useful when you
- * have multiple SolrServers and the requests need to be Load Balanced among them.
- *
- * Do <b>NOT</b> use this class for indexing in master/slave scenarios since documents must be sent to the
- * correct master; no inter-node routing is done.
- *
- * In SolrCloud (leader/replica) scenarios, it is usually better to use
- * {@link org.apache.solr.client.solrj.impl.CloudSolrServer}, but this class may be used
- * for updates because the server will forward them to the appropriate leader.
- *
- * Also see the <a href="http://wiki.apache.org/solr/LBHttpSolrServer">wiki</a> page.
- *
- * <p/>
- * It offers automatic failover when a server goes down and it detects when the server comes back up.
- * <p/>
- * Load balancing is done using a simple round-robin on the list of servers.
- * <p/>
- * If a request to a server fails by an IOException due to a connection timeout or read timeout then the host is taken
- * off the list of live servers and moved to a 'dead server list' and the request is resent to the next live server.
- * This process is continued till it tries all the live servers. If at least one server is alive, the request succeeds,
- * and if not it fails.
- * <blockquote><pre>
- * SolrServer lbHttpSolrServer = new LBHttpSolrServer("http://host1:8080/solr/","http://host2:8080/solr","http://host2:8080/solr");
- * //or if you wish to pass the HttpClient do as follows
- * httpClient httpClient =  new HttpClient();
- * SolrServer lbHttpSolrServer = new LBHttpSolrServer(httpClient,"http://host1:8080/solr/","http://host2:8080/solr","http://host2:8080/solr");
- * </pre></blockquote>
- * This detects if a dead server comes alive automatically. The check is done in fixed intervals in a dedicated thread.
- * This interval can be set using {@link #setAliveCheckInterval} , the default is set to one minute.
- * <p/>
- * <b>When to use this?</b><br/> This can be used as a software load balancer when you do not wish to setup an external
- * load balancer. Alternatives to this code are to use
- * a dedicated hardware load balancer or using Apache httpd with mod_proxy_balancer as a load balancer. See <a
- * href="http://en.wikipedia.org/wiki/Load_balancing_(computing)">Load balancing on Wikipedia</a>
- *
- * @since solr 1.4
+ * @deprecated Use {@link org.apache.solr.client.solrj.impl.LBHttpSolrClient}
  */
-public class LBHttpSolrServer extends SolrServer {
-  private static Set<Integer> RETRY_CODES = new HashSet<>(4);
-
-  static {
-    RETRY_CODES.add(404);
-    RETRY_CODES.add(403);
-    RETRY_CODES.add(503);
-    RETRY_CODES.add(500);
-  }
-
-  // keys to the maps are currently of the form "http://localhost:8983/solr"
-  // which should be equivalent to HttpSolrServer.getBaseURL()
-  private final Map<String, ServerWrapper> aliveServers = new LinkedHashMap<>();
-  // access to aliveServers should be synchronized on itself
-  
-  protected final Map<String, ServerWrapper> zombieServers = new ConcurrentHashMap<>();
-
-  // changes to aliveServers are reflected in this array, no need to synchronize
-  private volatile ServerWrapper[] aliveServerList = new ServerWrapper[0];
-
-
-  private ScheduledExecutorService aliveCheckExecutor;
-
-  private final HttpClient httpClient;
-  private final boolean clientIsInternal;
-  private final AtomicInteger counter = new AtomicInteger(-1);
-
-  private static final SolrQuery solrQuery = new SolrQuery("*:*");
-  private volatile ResponseParser parser;
-  private volatile RequestWriter requestWriter;
-
-  private Set<String> queryParams = new HashSet<>();
-
-  static {
-    solrQuery.setRows(0);
-    /**
-     * Default sort (if we don't supply a sort) is by score and since
-     * we request 0 rows any sorting and scoring is not necessary.
-     * SolrQuery.DOCID schema-independently specifies a non-scoring sort.
-     * <code>_docid_ asc</code> sort is efficient,
-     * <code>_docid_ desc</code> sort is not, so choose ascending DOCID sort.
-     */
-    solrQuery.setSort(SolrQuery.DOCID, SolrQuery.ORDER.asc);
-    // not a top-level request, we are interested only in the server being sent to i.e. it need not distribute our request to further servers    
-    solrQuery.setDistrib(false);
-  }
-
-  protected static class ServerWrapper {
-    final HttpSolrServer solrServer;
-
-    long lastUsed;     // last time used for a real request
-    long lastChecked;  // last time checked for liveness
-
-    // "standard" servers are used by default.  They normally live in the alive list
-    // and move to the zombie list when unavailable.  When they become available again,
-    // they move back to the alive list.
-    boolean standard = true;
-
-    int failedPings = 0;
-
-    public ServerWrapper(HttpSolrServer solrServer) {
-      this.solrServer = solrServer;
-    }
-
-    @Override
-    public String toString() {
-      return solrServer.getBaseURL();
-    }
-
-    public String getKey() {
-      return solrServer.getBaseURL();
-    }
-
-    @Override
-    public int hashCode() {
-      return this.getKey().hashCode();
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (this == obj) return true;
-      if (!(obj instanceof ServerWrapper)) return false;
-      return this.getKey().equals(((ServerWrapper)obj).getKey());
-    }
-  }
-
-  public static class Req {
-    protected SolrRequest request;
-    protected List<String> servers;
-    protected int numDeadServersToTry;
-
-    public Req(SolrRequest request, List<String> servers) {
-      this.request = request;
-      this.servers = servers;
-      this.numDeadServersToTry = servers.size();
-    }
-
-    public SolrRequest getRequest() {
-      return request;
-    }
-    public List<String> getServers() {
-      return servers;
-    }
-
-    /** @return the number of dead servers to try if there are no live servers left */
-    public int getNumDeadServersToTry() {
-      return numDeadServersToTry;
-    }
-
-    /** @param numDeadServersToTry The number of dead servers to try if there are no live servers left.
-     * Defaults to the number of servers in this request. */
-    public void setNumDeadServersToTry(int numDeadServersToTry) {
-      this.numDeadServersToTry = numDeadServersToTry;
-    }
-  }
-
-  public static class Rsp {
-    protected String server;
-    protected NamedList<Object> rsp;
-
-    /** The response from the server */
-    public NamedList<Object> getResponse() {
-      return rsp;
-    }
-
-    /** The server that returned the response */
-    public String getServer() {
-      return server;
-    }
-  }
+@Deprecated
+public class LBHttpSolrServer extends LBHttpSolrClient {
 
   public LBHttpSolrServer(String... solrServerUrls) throws MalformedURLException {
-    this(null, solrServerUrls);
+    super(solrServerUrls);
   }
-  
-  /** The provided httpClient should use a multi-threaded connection manager */ 
+
   public LBHttpSolrServer(HttpClient httpClient, String... solrServerUrl) {
-    this(httpClient, new BinaryResponseParser(), solrServerUrl);
+    super(httpClient, solrServerUrl);
   }
 
-  /** The provided httpClient should use a multi-threaded connection manager */  
   public LBHttpSolrServer(HttpClient httpClient, ResponseParser parser, String... solrServerUrl) {
-    clientIsInternal = (httpClient == null);
-    this.parser = parser;
-    if (httpClient == null) {
-      ModifiableSolrParams params = new ModifiableSolrParams();
-      params.set(HttpClientUtil.PROP_USE_RETRY, false);
-      this.httpClient = HttpClientUtil.createClient(params);
-    } else {
-      this.httpClient = httpClient;
-    }
-    for (String s : solrServerUrl) {
-      ServerWrapper wrapper = new ServerWrapper(makeServer(s));
-      aliveServers.put(wrapper.getKey(), wrapper);
-    }
-    updateAliveList();
-  }
-  
-  public Set<String> getQueryParams() {
-    return queryParams;
-  }
-
-  /**
-   * Expert Method.
-   * @param queryParams set of param keys to only send via the query string
-   */
-  public void setQueryParams(Set<String> queryParams) {
-    this.queryParams = queryParams;
-  }
-  public void addQueryParams(String queryOnlyParam) {
-    this.queryParams.add(queryOnlyParam) ;
-  }
-
-  public static String normalize(String server) {
-    if (server.endsWith("/"))
-      server = server.substring(0, server.length() - 1);
-    return server;
-  }
-
-  protected HttpSolrServer makeServer(String server) {
-    HttpSolrServer s = new HttpSolrServer(server, httpClient, parser);
-    if (requestWriter != null) {
-      s.setRequestWriter(requestWriter);
-    }
-    if (queryParams != null) {
-      s.setQueryParams(queryParams);
-    }
-    return s;
-  }
-
-  /**
-   * Tries to query a live server from the list provided in Req. Servers in the dead pool are skipped.
-   * If a request fails due to an IOException, the server is moved to the dead pool for a certain period of
-   * time, or until a test request on that server succeeds.
-   *
-   * Servers are queried in the exact order given (except servers currently in the dead pool are skipped).
-   * If no live servers from the provided list remain to be tried, a number of previously skipped dead servers will be tried.
-   * Req.getNumDeadServersToTry() controls how many dead servers will be tried.
-   *
-   * If no live servers are found a SolrServerException is thrown.
-   *
-   * @param req contains both the request as well as the list of servers to query
-   *
-   * @return the result of the request
-   *
-   * @throws IOException If there is a low-level I/O error.
-   */
-  public Rsp request(Req req) throws SolrServerException, IOException {
-    Rsp rsp = new Rsp();
-    Exception ex = null;
-    boolean isUpdate = req.request instanceof IsUpdateRequest;
-    List<ServerWrapper> skipped = null;
-
-    for (String serverStr : req.getServers()) {
-      serverStr = normalize(serverStr);
-      // if the server is currently a zombie, just skip to the next one
-      ServerWrapper wrapper = zombieServers.get(serverStr);
-      if (wrapper != null) {
-        // System.out.println("ZOMBIE SERVER QUERIED: " + serverStr);
-        final int numDeadServersToTry = req.getNumDeadServersToTry();
-        if (numDeadServersToTry > 0) {
-          if (skipped == null) {
-            skipped = new ArrayList<>(numDeadServersToTry);
-            skipped.add(wrapper);
-          }
-          else if (skipped.size() < numDeadServersToTry) {
-            skipped.add(wrapper);
-          }
-        }
-        continue;
-      }
-      rsp.server = serverStr;
-      HttpSolrServer server = makeServer(serverStr);
-
-      ex = doRequest(server, req, rsp, isUpdate, false, null);
-      if (ex == null) {
-        return rsp; // SUCCESS
-      }
-    }
-
-    // try the servers we previously skipped
-    if (skipped != null) {
-      for (ServerWrapper wrapper : skipped) {
-        ex = doRequest(wrapper.solrServer, req, rsp, isUpdate, true, wrapper.getKey());
-        if (ex == null) {
-          return rsp; // SUCCESS
-        }
-      }
-    }
-
-
-    if (ex == null) {
-      throw new SolrServerException("No live SolrServers available to handle this request");
-    } else {
-      throw new SolrServerException("No live SolrServers available to handle this request:" + zombieServers.keySet(), ex);
-    }
-
+    super(httpClient, parser, solrServerUrl);
   }
 
-  protected Exception addZombie(HttpSolrServer server, Exception e) {
-
-    ServerWrapper wrapper;
-
-    wrapper = new ServerWrapper(server);
-    wrapper.lastUsed = System.currentTimeMillis();
-    wrapper.standard = false;
-    zombieServers.put(wrapper.getKey(), wrapper);
-    startAliveCheckExecutor();
-    return e;
-  }  
-
-  protected Exception doRequest(HttpSolrServer server, Req req, Rsp rsp, boolean isUpdate,
-      boolean isZombie, String zombieKey) throws SolrServerException, IOException {
-    Exception ex = null;
-    try {
-      rsp.rsp = server.request(req.getRequest());
-      if (isZombie) {
-        zombieServers.remove(zombieKey);
-      }
-    } catch (SolrException e) {
-      // we retry on 404 or 403 or 503 or 500
-      // unless it's an update - then we only retry on connect exception
-      if (!isUpdate && RETRY_CODES.contains(e.code())) {
-        ex = (!isZombie) ? addZombie(server, e) : e;
-      } else {
-        // Server is alive but the request was likely malformed or invalid
-        if (isZombie) {
-          zombieServers.remove(zombieKey);
-        }
-        throw e;
-      }
-    } catch (SocketException e) {
-      if (!isUpdate || e instanceof ConnectException) {
-        ex = (!isZombie) ? addZombie(server, e) : e;
-      } else {
-        throw e;
-      }
-    } catch (SocketTimeoutException e) {
-      if (!isUpdate) {
-        ex = (!isZombie) ? addZombie(server, e) : e;
-      } else {
-        throw e;
-      }
-    } catch (SolrServerException e) {
-      Throwable rootCause = e.getRootCause();
-      if (!isUpdate && rootCause instanceof IOException) {
-        ex = (!isZombie) ? addZombie(server, e) : e;
-      } else if (isUpdate && rootCause instanceof ConnectException) {
-        ex = (!isZombie) ? addZombie(server, e) : e;
-      } else {
-        throw e;
-      }
-    } catch (Exception e) {
-      throw new SolrServerException(e);
-    }
-
-    return ex;
-  }
-
-  private void updateAliveList() {
-    synchronized (aliveServers) {
-      aliveServerList = aliveServers.values().toArray(new ServerWrapper[aliveServers.size()]);
-    }
-  }
-
-  private ServerWrapper removeFromAlive(String key) {
-    synchronized (aliveServers) {
-      ServerWrapper wrapper = aliveServers.remove(key);
-      if (wrapper != null)
-        updateAliveList();
-      return wrapper;
-    }
-  }
-
-  private void addToAlive(ServerWrapper wrapper) {
-    synchronized (aliveServers) {
-      ServerWrapper prev = aliveServers.put(wrapper.getKey(), wrapper);
-      // TODO: warn if there was a previous entry?
-      updateAliveList();
-    }
-  }
-
-  public void addSolrServer(String server) throws MalformedURLException {
-    HttpSolrServer solrServer = makeServer(server);
-    addToAlive(new ServerWrapper(solrServer));
-  }
-
-  public String removeSolrServer(String server) {
-    try {
-      server = new URL(server).toExternalForm();
-    } catch (MalformedURLException e) {
-      throw new RuntimeException(e);
-    }
-    if (server.endsWith("/")) {
-      server = server.substring(0, server.length() - 1);
-    }
-
-    // there is a small race condition here - if the server is in the process of being moved between
-    // lists, we could fail to remove it.
-    removeFromAlive(server);
-    zombieServers.remove(server);
-    return null;
-  }
-
-  public void setConnectionTimeout(int timeout) {
-    HttpClientUtil.setConnectionTimeout(httpClient, timeout);
-  }
-
-  /**
-   * set soTimeout (read timeout) on the underlying HttpConnectionManager. This is desirable for queries, but probably
-   * not for indexing.
-   */
-  public void setSoTimeout(int timeout) {
-    HttpClientUtil.setSoTimeout(httpClient, timeout);
-  }
-
-  @Override
-  public void shutdown() {
-    if (aliveCheckExecutor != null) {
-      aliveCheckExecutor.shutdownNow();
-    }
-    if(clientIsInternal) {
-      httpClient.getConnectionManager().shutdown();
-    }
-  }
-
-  /**
-   * Tries to query a live server. A SolrServerException is thrown if all servers are dead.
-   * If the request failed due to IOException then the live server is moved to dead pool and the request is
-   * retried on another live server.  After live servers are exhausted, any servers previously marked as dead
-   * will be tried before failing the request.
-   *
-   * @param request the SolrRequest.
-   *
-   * @return response
-   *
-   * @throws IOException If there is a low-level I/O error.
-   */
-  @Override
-  public NamedList<Object> request(final SolrRequest request)
-          throws SolrServerException, IOException {
-    Exception ex = null;
-    ServerWrapper[] serverList = aliveServerList;
-    
-    int maxTries = serverList.length;
-    Map<String,ServerWrapper> justFailed = null;
-
-    for (int attempts=0; attempts<maxTries; attempts++) {
-      int count = counter.incrementAndGet() & Integer.MAX_VALUE;
-      ServerWrapper wrapper = serverList[count % serverList.length];
-      wrapper.lastUsed = System.currentTimeMillis();
-
-      try {
-        return wrapper.solrServer.request(request);
-      } catch (SolrException e) {
-        // Server is alive but the request was malformed or invalid
-        throw e;
-      } catch (SolrServerException e) {
-        if (e.getRootCause() instanceof IOException) {
-          ex = e;
-          moveAliveToDead(wrapper);
-          if (justFailed == null) justFailed = new HashMap<>();
-          justFailed.put(wrapper.getKey(), wrapper);
-        } else {
-          throw e;
-        }
-      } catch (Exception e) {
-        throw new SolrServerException(e);
-      }
-    }
-
-
-    // try other standard servers that we didn't try just now
-    for (ServerWrapper wrapper : zombieServers.values()) {
-      if (wrapper.standard==false || justFailed!=null && justFailed.containsKey(wrapper.getKey())) continue;
-      try {
-        NamedList<Object> rsp = wrapper.solrServer.request(request);
-        // remove from zombie list *before* adding to alive to avoid a race that could lose a server
-        zombieServers.remove(wrapper.getKey());
-        addToAlive(wrapper);
-        return rsp;
-      } catch (SolrException e) {
-        // Server is alive but the request was malformed or invalid
-        throw e;
-      } catch (SolrServerException e) {
-        if (e.getRootCause() instanceof IOException) {
-          ex = e;
-          // still dead
-        } else {
-          throw e;
-        }
-      } catch (Exception e) {
-        throw new SolrServerException(e);
-      }
-    }
-
-
-    if (ex == null) {
-      throw new SolrServerException("No live SolrServers available to handle this request");
-    } else {
-      throw new SolrServerException("No live SolrServers available to handle this request", ex);
-    }
-  }
-  
-  /**
-   * Takes up one dead server and check for aliveness. The check is done in a roundrobin. Each server is checked for
-   * aliveness once in 'x' millis where x is decided by the setAliveCheckinterval() or it is defaulted to 1 minute
-   *
-   * @param zombieServer a server in the dead pool
-   */
-  private void checkAZombieServer(ServerWrapper zombieServer) {
-    long currTime = System.currentTimeMillis();
-    try {
-      zombieServer.lastChecked = currTime;
-      QueryResponse resp = zombieServer.solrServer.query(solrQuery);
-      if (resp.getStatus() == 0) {
-        // server has come back up.
-        // make sure to remove from zombies before adding to alive to avoid a race condition
-        // where another thread could mark it down, move it back to zombie, and then we delete
-        // from zombie and lose it forever.
-        ServerWrapper wrapper = zombieServers.remove(zombieServer.getKey());
-        if (wrapper != null) {
-          wrapper.failedPings = 0;
-          if (wrapper.standard) {
-            addToAlive(wrapper);
-          }
-        } else {
-          // something else already moved the server from zombie to alive
-        }
-      }
-    } catch (Exception e) {
-      //Expected. The server is still down.
-      zombieServer.failedPings++;
-
-      // If the server doesn't belong in the standard set belonging to this load balancer
-      // then simply drop it after a certain number of failed pings.
-      if (!zombieServer.standard && zombieServer.failedPings >= NONSTANDARD_PING_LIMIT) {
-        zombieServers.remove(zombieServer.getKey());
-      }
-    }
-  }
-
-  private void moveAliveToDead(ServerWrapper wrapper) {
-    wrapper = removeFromAlive(wrapper.getKey());
-    if (wrapper == null)
-      return;  // another thread already detected the failure and removed it
-    zombieServers.put(wrapper.getKey(), wrapper);
-    startAliveCheckExecutor();
-  }
-
-  private int interval = CHECK_INTERVAL;
-
-  /**
-   * LBHttpSolrServer keeps pinging the dead servers at fixed interval to find if it is alive. Use this to set that
-   * interval
-   *
-   * @param interval time in milliseconds
-   */
-  public void setAliveCheckInterval(int interval) {
-    if (interval <= 0) {
-      throw new IllegalArgumentException("Alive check interval must be " +
-              "positive, specified value = " + interval);
-    }
-    this.interval = interval;
-  }
-
-  private void startAliveCheckExecutor() {
-    // double-checked locking, but it's OK because we don't *do* anything with aliveCheckExecutor
-    // if it's not null.
-    if (aliveCheckExecutor == null) {
-      synchronized (this) {
-        if (aliveCheckExecutor == null) {
-          aliveCheckExecutor = Executors.newSingleThreadScheduledExecutor(
-              new SolrjNamedThreadFactory("aliveCheckExecutor"));
-          aliveCheckExecutor.scheduleAtFixedRate(
-                  getAliveCheckRunner(new WeakReference<>(this)),
-                  this.interval, this.interval, TimeUnit.MILLISECONDS);
-        }
-      }
-    }
-  }
-
-  private static Runnable getAliveCheckRunner(final WeakReference<LBHttpSolrServer> lbRef) {
-    return new Runnable() {
-      @Override
-      public void run() {
-        LBHttpSolrServer lb = lbRef.get();
-        if (lb != null && lb.zombieServers != null) {
-          for (ServerWrapper zombieServer : lb.zombieServers.values()) {
-            lb.checkAZombieServer(zombieServer);
-          }
-        }
-      }
-    };
-  }
-
-  /**
-   * Return the HttpClient this instance uses.
-   */
-  public HttpClient getHttpClient() {
-    return httpClient;
-  }
-
-  public ResponseParser getParser() {
-    return parser;
-  }
-
-  /**
-   * Changes the {@link ResponseParser} that will be used for the internal
-   * SolrServer objects.
-   *
-   * @param parser Default Response Parser chosen to parse the response if the parser
-   *               were not specified as part of the request.
-   * @see org.apache.solr.client.solrj.SolrRequest#getResponseParser()
-   */
-  public void setParser(ResponseParser parser) {
-    this.parser = parser;
-  }
-
-  /**
-   * Changes the {@link RequestWriter} that will be used for the internal
-   * SolrServer objects.
-   *
-   * @param requestWriter Default RequestWriter, used to encode requests sent to the server.
-   */
-  public void setRequestWriter(RequestWriter requestWriter) {
-    this.requestWriter = requestWriter;
-  }
-  
-  public RequestWriter getRequestWriter() {
-    return requestWriter;
-  }
-  
-  @Override
-  protected void finalize() throws Throwable {
-    try {
-      if(this.aliveCheckExecutor!=null)
-        this.aliveCheckExecutor.shutdownNow();
-    } finally {
-      super.finalize();
-    }
-  }
-
-  // defaults
-  private static final int CHECK_INTERVAL = 60 * 1000; //1 minute between checks
-  private static final int NONSTANDARD_PING_LIMIT = 5;  // number of times we'll ping dead servers not in the server list
-
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/AbstractUpdateRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/AbstractUpdateRequest.java
index acfc525..a2bdcf5 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/AbstractUpdateRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/AbstractUpdateRequest.java
@@ -17,7 +17,7 @@ package org.apache.solr.client.solrj.request;
  */
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.UpdateResponse;
 import org.apache.solr.common.params.ModifiableSolrParams;
@@ -117,11 +117,11 @@ public abstract class AbstractUpdateRequest extends SolrRequest implements IsUpd
   }
 
   @Override
-  public UpdateResponse process( SolrServer server ) throws SolrServerException, IOException
+  public UpdateResponse process(SolrClient client) throws SolrServerException, IOException
   {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     UpdateResponse res = new UpdateResponse();
-    res.setResponse( server.request( this ) );
+    res.setResponse(client.request(this));
     long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     res.setElapsedTime(endTime - startTime);
     return res;
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
index c404f8d..d2fa1bd 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CollectionAdminRequest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.request;
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.CollectionAdminResponse;
 import org.apache.solr.common.SolrException;
@@ -78,7 +78,7 @@ public class CollectionAdminRequest extends SolrRequest {
   }
 
   @Override
-  public CollectionAdminResponse process(SolrServer server) throws SolrServerException, IOException
+  public CollectionAdminResponse process(SolrClient server) throws SolrServerException, IOException
   {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     CollectionAdminResponse res = new CollectionAdminResponse();
@@ -814,8 +814,7 @@ public class CollectionAdminRequest extends SolrRequest {
     private String propertyName;
     private Boolean onlyActiveNodes;
     private Boolean shardUnique;
-
-
+    
     public String getPropertyName() {
       return propertyName;
     }
@@ -859,5 +858,6 @@ public class CollectionAdminRequest extends SolrRequest {
         params.set("shardUnique", shardUnique);
       return params;
     }
+
   }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CoreAdminRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CoreAdminRequest.java
index 3d15a73..2c4a2c1 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/CoreAdminRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/CoreAdminRequest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.request;
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.CoreAdminResponse;
 import org.apache.solr.common.cloud.ZkStateReader;
@@ -503,11 +503,11 @@ public class CoreAdminRequest extends SolrRequest
   }
 
   @Override
-  public CoreAdminResponse process(SolrServer server) throws SolrServerException, IOException 
+  public CoreAdminResponse process(SolrClient client) throws SolrServerException, IOException
   {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     CoreAdminResponse res = new CoreAdminResponse();
-    res.setResponse( server.request( this ) );
+    res.setResponse(client.request(this));
     long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     res.setElapsedTime(endTime - startTime);
     return res;
@@ -517,57 +517,57 @@ public class CoreAdminRequest extends SolrRequest
   //
   //---------------------------------------------------------------------------------------
 
-  public static CoreAdminResponse reloadCore( String name, SolrServer server ) throws SolrServerException, IOException
+  public static CoreAdminResponse reloadCore(String name, SolrClient client) throws SolrServerException, IOException
   {
     CoreAdminRequest req = new CoreAdminRequest();
-    req.setCoreName( name );
-    req.setAction( CoreAdminAction.RELOAD );
-    return req.process( server );
+    req.setCoreName(name);
+    req.setAction(CoreAdminAction.RELOAD);
+    return req.process(client);
   }
 
-  public static CoreAdminResponse unloadCore( String name, SolrServer server ) throws SolrServerException, IOException
+  public static CoreAdminResponse unloadCore(String name, SolrClient client) throws SolrServerException, IOException
   {
-    return unloadCore(name, false, server);
+    return unloadCore(name, false, client);
   }
 
-  public static CoreAdminResponse unloadCore(String name, boolean deleteIndex, SolrServer server) throws SolrServerException, IOException {
-    return unloadCore(name, deleteIndex, false, server);
+  public static CoreAdminResponse unloadCore(String name, boolean deleteIndex, SolrClient client) throws SolrServerException, IOException {
+    return unloadCore(name, deleteIndex, false, client);
   }
 
-  public static CoreAdminResponse unloadCore(String name, boolean deleteIndex, boolean deleteInstanceDir, SolrServer server) throws SolrServerException, IOException {
+  public static CoreAdminResponse unloadCore(String name, boolean deleteIndex, boolean deleteInstanceDir, SolrClient client) throws SolrServerException, IOException {
     Unload req = new Unload(deleteIndex);
     req.setCoreName(name);
     req.setDeleteInstanceDir(deleteInstanceDir);
-    return req.process(server);
+    return req.process(client);
   }
 
-  public static CoreAdminResponse renameCore(String coreName, String newName, SolrServer server ) throws SolrServerException, IOException
+  public static CoreAdminResponse renameCore(String coreName, String newName, SolrClient client ) throws SolrServerException, IOException
   {
     CoreAdminRequest req = new CoreAdminRequest();
     req.setCoreName(coreName);
     req.setOtherCoreName(newName);
     req.setAction( CoreAdminAction.RENAME );
-    return req.process( server );
+    return req.process( client );
   }
 
-  public static CoreAdminResponse getStatus( String name, SolrServer server ) throws SolrServerException, IOException
+  public static CoreAdminResponse getStatus( String name, SolrClient client ) throws SolrServerException, IOException
   {
     CoreAdminRequest req = new CoreAdminRequest();
     req.setCoreName( name );
     req.setAction( CoreAdminAction.STATUS );
-    return req.process( server );
+    return req.process( client );
   }
   
-  public static CoreAdminResponse createCore( String name, String instanceDir, SolrServer server ) throws SolrServerException, IOException 
+  public static CoreAdminResponse createCore( String name, String instanceDir, SolrClient client ) throws SolrServerException, IOException
   {
-    return CoreAdminRequest.createCore(name, instanceDir, server, null, null);
+    return CoreAdminRequest.createCore(name, instanceDir, client, null, null);
   }
   
-  public static CoreAdminResponse createCore( String name, String instanceDir, SolrServer server, String configFile, String schemaFile ) throws SolrServerException, IOException { 
-    return createCore(name, instanceDir, server, configFile, schemaFile, null, null);
+  public static CoreAdminResponse createCore( String name, String instanceDir, SolrClient client, String configFile, String schemaFile ) throws SolrServerException, IOException {
+    return createCore(name, instanceDir, client, configFile, schemaFile, null, null);
   }
   
-  public static CoreAdminResponse createCore( String name, String instanceDir, SolrServer server, String configFile, String schemaFile, String dataDir, String tlogDir ) throws SolrServerException, IOException 
+  public static CoreAdminResponse createCore( String name, String instanceDir, SolrClient client, String configFile, String schemaFile, String dataDir, String tlogDir ) throws SolrServerException, IOException
   {
     CoreAdminRequest.Create req = new CoreAdminRequest.Create();
     req.setCoreName( name );
@@ -584,24 +584,24 @@ public class CoreAdminRequest extends SolrRequest
     if(schemaFile != null){
       req.setSchemaName(schemaFile);
     }
-    return req.process( server );
+    return req.process( client );
   }
 
   @Deprecated
-  public static CoreAdminResponse persist(String fileName, SolrServer server) throws SolrServerException, IOException 
+  public static CoreAdminResponse persist(String fileName, SolrClient client) throws SolrServerException, IOException
   {
     CoreAdminRequest.Persist req = new CoreAdminRequest.Persist();
     req.setFileName(fileName);
-    return req.process(server);
+    return req.process(client);
   }
 
   public static CoreAdminResponse mergeIndexes(String name,
-      String[] indexDirs, String[] srcCores, SolrServer server) throws SolrServerException,
+      String[] indexDirs, String[] srcCores, SolrClient client) throws SolrServerException,
       IOException {
     CoreAdminRequest.MergeIndexes req = new CoreAdminRequest.MergeIndexes();
     req.setCoreName(name);
     req.setIndexDirs(Arrays.asList(indexDirs));
     req.setSrcCores(Arrays.asList(srcCores));
-    return req.process(server);
+    return req.process(client);
   }
 }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/DirectXmlRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/DirectXmlRequest.java
index 3c48a75..d222ce1 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/DirectXmlRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/DirectXmlRequest.java
@@ -17,18 +17,18 @@
 
 package org.apache.solr.client.solrj.request;
 
-import java.io.IOException;
-import java.util.Collection;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.UpdateResponse;
 import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.ContentStream;
 
+import java.io.IOException;
+import java.util.Collection;
+import java.util.concurrent.TimeUnit;
+
 /**
  * Send arbitrary XML to a request handler
  * 
@@ -62,11 +62,11 @@ public class DirectXmlRequest extends SolrRequest implements IsUpdateRequest
   }
 
   @Override
-  public UpdateResponse process( SolrServer server ) throws SolrServerException, IOException
+  public UpdateResponse process(SolrClient client) throws SolrServerException, IOException
   {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     UpdateResponse res = new UpdateResponse();
-    res.setResponse( server.request( this ) );
+    res.setResponse(client.request(this));
     res.setElapsedTime( TimeUnit.MILLISECONDS.convert(System.nanoTime()-startTime, TimeUnit.NANOSECONDS) );
     return res;
   }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/DocumentAnalysisRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/DocumentAnalysisRequest.java
index fa84111..0a5017b 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/DocumentAnalysisRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/DocumentAnalysisRequest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.request;
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.DocumentAnalysisResponse;
 import org.apache.solr.client.solrj.util.ClientUtils;
@@ -87,10 +87,10 @@ public class DocumentAnalysisRequest extends SolrRequest {
    * {@inheritDoc}
    */
   @Override
-  public DocumentAnalysisResponse process(SolrServer server) throws SolrServerException, IOException {
+  public DocumentAnalysisResponse process(SolrClient client) throws SolrServerException, IOException {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     DocumentAnalysisResponse res = new DocumentAnalysisResponse();
-    res.setResponse(server.request(this));
+    res.setResponse(client.request(this));
     long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     res.setElapsedTime(endTime - startTime);
     return res;
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/FieldAnalysisRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/FieldAnalysisRequest.java
index 47f340d..5ba9da4 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/FieldAnalysisRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/FieldAnalysisRequest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.request;
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.FieldAnalysisResponse;
 import org.apache.solr.common.params.AnalysisParams;
@@ -96,7 +96,7 @@ public class FieldAnalysisRequest extends SolrRequest {
    * {@inheritDoc}
    */
   @Override
-  public FieldAnalysisResponse process(SolrServer server) throws SolrServerException, IOException {
+  public FieldAnalysisResponse process(SolrClient server) throws SolrServerException, IOException {
     if (fieldTypes == null && fieldNames == null) {
       throw new IllegalStateException("At least one field type or field name need to be specified");
     }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/LukeRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/LukeRequest.java
index 8cd5305..2f7c779 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/LukeRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/LukeRequest.java
@@ -17,21 +17,21 @@
 
 package org.apache.solr.client.solrj.request;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.LukeResponse;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.ContentStream;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+
 /**
  * 
  *
@@ -115,11 +115,11 @@ public class LukeRequest extends SolrRequest
   }
 
   @Override
-  public LukeResponse process( SolrServer server ) throws SolrServerException, IOException 
+  public LukeResponse process( SolrClient client ) throws SolrServerException, IOException
   {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     LukeResponse res = new LukeResponse();
-    res.setResponse( server.request( this ) );
+    res.setResponse(client.request(this));
     long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     res.setElapsedTime(endTime - startTime);
     return res;
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
index 1e153ae..b8e4237 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/QueryRequest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.request;
 
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrException;
@@ -84,11 +84,11 @@ public class QueryRequest extends SolrRequest
   }
 
   @Override
-  public QueryResponse process( SolrServer server ) throws SolrServerException 
+  public QueryResponse process( SolrClient client ) throws SolrServerException
   {
     try {
       long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
-      QueryResponse res = new QueryResponse( server.request( this ), server );
+      QueryResponse res = new QueryResponse( client.request( this ), client );
       long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
       res.setElapsedTime(endTime - startTime);
       return res;
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/SolrPing.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/SolrPing.java
index 710c536..2a343a8 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/SolrPing.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/SolrPing.java
@@ -17,20 +17,20 @@
 
 package org.apache.solr.client.solrj.request;
 
-import java.io.IOException;
-import java.util.Collection;
-import java.util.concurrent.TimeUnit;
-
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.SolrPingResponse;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.ModifiableSolrParams;
 import org.apache.solr.common.util.ContentStream;
 
+import java.io.IOException;
+import java.util.Collection;
+import java.util.concurrent.TimeUnit;
+
 /**
- * Verify that there is a working Solr core at the URL of a {@link SolrServer}.
+ * Verify that there is a working Solr core at the URL of a {@link org.apache.solr.client.solrj.SolrClient}.
  * To use this class, the solrconfig.xml for the relevant core must include the
  * request handler for <code>/admin/ping</code>.
  * 
@@ -63,11 +63,11 @@ public class SolrPing extends SolrRequest {
   }
   
   @Override
-  public SolrPingResponse process(SolrServer server)
+  public SolrPingResponse process(SolrClient client)
       throws SolrServerException, IOException {
     long startTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     SolrPingResponse res = new SolrPingResponse();
-    res.setResponse(server.request(this));
+    res.setResponse(client.request(this));
     long endTime = TimeUnit.MILLISECONDS.convert(System.nanoTime(), TimeUnit.NANOSECONDS);
     res.setElapsedTime(endTime - startTime);
     return res;
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/request/UpdateRequest.java b/solr/solrj/src/java/org/apache/solr/client/solrj/request/UpdateRequest.java
index ed13295..a6510d5 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/request/UpdateRequest.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/request/UpdateRequest.java
@@ -30,7 +30,7 @@ import java.util.Map.Entry;
 import java.util.Set;
 import java.util.LinkedHashMap;
 
-import org.apache.solr.client.solrj.impl.LBHttpSolrServer;
+import org.apache.solr.client.solrj.impl.LBHttpSolrClient;
 import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.cloud.DocCollection;
@@ -171,7 +171,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
    * @param idField the id field
    * @return a Map of urls to requests
    */
-  public Map<String,LBHttpSolrServer.Req> getRoutes(DocRouter router,
+  public Map<String,LBHttpSolrClient.Req> getRoutes(DocRouter router,
       DocCollection col, Map<String,List<String>> urlMap,
       ModifiableSolrParams params, String idField) {
     
@@ -180,7 +180,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
       return null;
     }
     
-    Map<String,LBHttpSolrServer.Req> routes = new HashMap<>();
+    Map<String,LBHttpSolrClient.Req> routes = new HashMap<>();
     if (documents != null) {
       Set<Entry<SolrInputDocument,Map<String,Object>>> entries = documents.entrySet();
       for (Entry<SolrInputDocument,Map<String,Object>> entry : entries) {
@@ -196,7 +196,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
         }
         List<String> urls = urlMap.get(slice.getName());
         String leaderUrl = urls.get(0);
-        LBHttpSolrServer.Req request = (LBHttpSolrServer.Req) routes
+        LBHttpSolrClient.Req request = (LBHttpSolrClient.Req) routes
             .get(leaderUrl);
         if (request == null) {
           UpdateRequest updateRequest = new UpdateRequest();
@@ -204,7 +204,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
           updateRequest.setCommitWithin(getCommitWithin());
           updateRequest.setParams(params);
           updateRequest.setPath(getPath());
-          request = new LBHttpSolrServer.Req(updateRequest, urls);
+          request = new LBHttpSolrClient.Req(updateRequest, urls);
           routes.put(leaderUrl, request);
         }
         UpdateRequest urequest = (UpdateRequest) request.getRequest();
@@ -234,7 +234,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
         }
         List<String> urls = urlMap.get(slice.getName());
         String leaderUrl = urls.get(0);
-        LBHttpSolrServer.Req request = routes.get(leaderUrl);
+        LBHttpSolrClient.Req request = routes.get(leaderUrl);
         if (request != null) {
           UpdateRequest urequest = (UpdateRequest) request.getRequest();
           urequest.deleteById(deleteId, version);
@@ -242,7 +242,7 @@ public class UpdateRequest extends AbstractUpdateRequest {
           UpdateRequest urequest = new UpdateRequest();
           urequest.setParams(params);
           urequest.deleteById(deleteId, version);
-          request = new LBHttpSolrServer.Req(urequest, urls);
+          request = new LBHttpSolrClient.Req(urequest, urls);
           routes.put(leaderUrl, request);
         }
       }
diff --git a/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java b/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
index cc165e5..ff9f9c3 100644
--- a/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
+++ b/solr/solrj/src/java/org/apache/solr/client/solrj/response/QueryResponse.java
@@ -25,7 +25,7 @@ import java.util.List;
 import java.util.Map;
 import java.util.TreeMap;
 
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.beans.DocumentObjectBinder;
 import org.apache.solr.common.SolrDocumentList;
 import org.apache.solr.common.params.CursorMarkParams;
@@ -85,18 +85,18 @@ public class QueryResponse extends SolrResponseBase
   private Map<String,String> _explainMap = null;
 
   // utility variable used for automatic binding -- it should not be serialized
-  private transient final SolrServer solrServer;
+  private transient final SolrClient solrClient;
   
   public QueryResponse(){
-    solrServer = null;
+    solrClient = null;
   }
   
   /**
    * Utility constructor to set the solrServer and namedList
    */
-  public QueryResponse( NamedList<Object> res , SolrServer solrServer){
+  public QueryResponse( NamedList<Object> res , SolrClient solrClient){
     this.setResponse( res );
-    this.solrServer = solrServer;
+    this.solrClient = solrClient;
   }
 
   @Override
@@ -564,9 +564,9 @@ public class QueryResponse extends SolrResponseBase
   }
   
   public <T> List<T> getBeans(Class<T> type){
-    return solrServer == null ? 
+    return solrClient == null ?
       new DocumentObjectBinder().getBeans(type,_results):
-      solrServer.getBinder().getBeans(type, _results);
+      solrClient.getBinder().getBeans(type, _results);
   }
 
   public Map<String, FieldStatsInfo> getFieldStatsInfo() {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/LargeVolumeTestBase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/LargeVolumeTestBase.java
index b191f41..b100177 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/LargeVolumeTestBase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/LargeVolumeTestBase.java
@@ -17,9 +17,6 @@
 
 package org.apache.solr.client.solrj;
 
-import java.util.ArrayList;
-import java.util.List;
-
 import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.response.QueryResponse;
@@ -29,6 +26,9 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  *
  * @since solr 1.3
@@ -43,8 +43,8 @@ public abstract class LargeVolumeTestBase extends SolrJettyTestBase
 
   @Test
   public void testMultiThreaded() throws Exception {
-    SolrServer gserver = this.getSolrServer();
-    gserver.deleteByQuery( "*:*" ); // delete everything!
+    SolrClient client = this.getSolrClient();
+    client.deleteByQuery("*:*"); // delete everything!
     
     DocThread[] threads = new DocThread[threadCount];
     for (int i=0; i<threadCount; i++) {
@@ -59,28 +59,28 @@ public abstract class LargeVolumeTestBase extends SolrJettyTestBase
 
     // some of the commits could have failed because maxWarmingSearchers exceeded,
     // so do a final commit to make sure everything is visible.
-    gserver.commit();
+    client.commit();
     
     query(threadCount * numdocs);
     log.info("done");
   }
 
   private void query(int count) throws SolrServerException {
-    SolrServer gserver = this.getSolrServer();
+    SolrClient client = this.getSolrClient();
     SolrQuery query = new SolrQuery("*:*");
-    QueryResponse response = gserver.query(query);
+    QueryResponse response = client.query(query);
     assertEquals(0, response.getStatus());
     assertEquals(count, response.getResults().getNumFound());
   }
 
   public class DocThread extends Thread {
     
-    final SolrServer tserver;
+    final SolrClient client;
     final String name;
     
     public DocThread( String name )
     {
-      tserver = createNewSolrServer();
+      client = createNewSolrClient();
       this.name = name;
     }
     
@@ -91,13 +91,13 @@ public abstract class LargeVolumeTestBase extends SolrJettyTestBase
         List<SolrInputDocument> docs = new ArrayList<>();
         for (int i = 0; i < numdocs; i++) {
           if (i > 0 && i % 200 == 0) {
-            resp = tserver.add(docs);
+            resp = client.add(docs);
             assertEquals(0, resp.getStatus());
             docs = new ArrayList<>();
           }
           if (i > 0 && i % 5000 == 0) {
             log.info(getName() + " - Committing " + i);
-            resp = tserver.commit();
+            resp = client.commit();
             assertEquals(0, resp.getStatus());
           }
           SolrInputDocument doc = new SolrInputDocument();
@@ -105,20 +105,20 @@ public abstract class LargeVolumeTestBase extends SolrJettyTestBase
           doc.addField("cat", "foocat");
           docs.add(doc);
         }
-        resp = tserver.add(docs);
+        resp = client.add(docs);
         assertEquals(0, resp.getStatus());
 
         try {
-        resp = tserver.commit();
+        resp = client.commit();
         assertEquals(0, resp.getStatus());
-        resp = tserver.optimize();
+        resp = client.optimize();
         assertEquals(0, resp.getStatus());
         } catch (Exception e) {
           // a commit/optimize can fail with a too many warming searchers exception
           log.info("Caught benign exception during commit: " + e.getMessage());
         }
-        if (!(tserver instanceof EmbeddedSolrServer)) {
-          tserver.shutdown();
+        if (!(client instanceof EmbeddedSolrServer)) {
+          client.shutdown();
         }
 
       } catch (Exception e) {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
index 2b004a0..a24d29b 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/MergeIndexesExampleTestBase.java
@@ -17,10 +17,6 @@
 
 package org.apache.solr.client.solrj;
 
-import java.io.File;
-import java.io.IOException;
-import java.util.Arrays;
-
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
@@ -33,6 +29,10 @@ import org.apache.solr.core.CoreContainer;
 import org.apache.solr.core.SolrCore;
 import org.junit.BeforeClass;
 
+import java.io.File;
+import java.io.IOException;
+import java.util.Arrays;
+
 /**
  * Abstract base class for testing merge indexes command
  *
@@ -91,22 +91,22 @@ public abstract class MergeIndexesExampleTestBase extends SolrExampleTestBase {
   }
 
   @Override
-  protected final SolrServer getSolrServer() {
+  protected final SolrClient getSolrClient() {
     throw new UnsupportedOperationException();
   }
 
   @Override
-  protected final SolrServer createNewSolrServer() {
+  protected final SolrClient createNewSolrClient() {
     throw new UnsupportedOperationException();
   }
 
-  protected abstract SolrServer getSolrCore0();
+  protected abstract SolrClient getSolrCore0();
 
-  protected abstract SolrServer getSolrCore1();
+  protected abstract SolrClient getSolrCore1();
 
-  protected abstract SolrServer getSolrAdmin();
+  protected abstract SolrClient getSolrAdmin();
 
-  protected abstract SolrServer getSolrCore(String name);
+  protected abstract SolrClient getSolrCore(String name);
 
   protected abstract String getIndexDirCore1();
 
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
index 2ec187d..9c85ae1 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleBinaryTest.java
@@ -18,12 +18,9 @@
 package org.apache.solr.client.solrj;
 
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
-import org.apache.solr.client.solrj.SolrExampleTests;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.util.ExternalPaths;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.junit.BeforeClass;
 
 
@@ -39,22 +36,22 @@ public class SolrExampleBinaryTest extends SolrExampleTests {
   }
 
   @Override
-  public SolrServer createNewSolrServer()
+  public SolrClient createNewSolrClient()
   {
     try {
       // setup the server...
       String url = jetty.getBaseUrl().toString() + "/collection1";
-      HttpSolrServer s = new HttpSolrServer( url );
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      s.setUseMultiPartPost(random().nextBoolean());
+      HttpSolrClient client = new HttpSolrClient( url );
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      client.setUseMultiPartPost(random().nextBoolean());
 
       // where the magic happens
-      s.setParser(new BinaryResponseParser());
-      s.setRequestWriter(new BinaryRequestWriter());
+      client.setParser(new BinaryResponseParser());
+      client.setRequestWriter(new BinaryRequestWriter());
 
-      return s;
+      return client;
     }
     catch( Exception ex ) {
       throw new RuntimeException( ex );
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestBase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestBase.java
index 58d6c30..057e3b0 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestBase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestBase.java
@@ -57,10 +57,10 @@ abstract public class SolrExampleTestBase extends AbstractSolrTestCase {
   /**
    * Subclasses need to initialize the server impl
    */
-  protected abstract SolrServer getSolrServer();
+  protected abstract SolrClient getSolrClient();
   
   /**
    * Create a new solr server
    */
-  protected abstract SolrServer createNewSolrServer();
+  protected abstract SolrClient createNewSolrClient();
 }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
index a6438a4..d28b103 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTests.java
@@ -24,8 +24,8 @@ import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest.ACTION;
@@ -85,10 +85,10 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testExampleConfig() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
+    client.deleteByQuery( "*:*" );// delete everything!
     
     // Now add something...
     SolrInputDocument doc = new SolrInputDocument();
@@ -99,21 +99,21 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     Assert.assertEquals( null, doc.getField("foo") );
     Assert.assertTrue(doc.getField("name").getValue() != null );
         
-    UpdateResponse upres = server.add( doc ); 
+    UpdateResponse upres = client.add( doc );
     // System.out.println( "ADD:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
-    upres = server.commit( true, true );
+    upres = client.commit( true, true );
     // System.out.println( "COMMIT:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
-    upres = server.optimize( true, true );
+    upres = client.optimize( true, true );
     // System.out.println( "OPTIMIZE:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
     SolrQuery query = new SolrQuery();
     query.setQuery( "id:"+docID );
-    QueryResponse response = server.query( query );
+    QueryResponse response = client.query( query );
     
     Assert.assertEquals(docID, response.getResults().get(0).getFieldValue("id") );
     
@@ -144,15 +144,15 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc5.addField( "timestamp_dt", new java.util.Date(), 1.0f );
     docs.add(doc5);
     
-    upres = server.add( docs ); 
+    upres = client.add( docs );
     // System.out.println( "ADD:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
-    upres = server.commit( true, true );
+    upres = client.commit( true, true );
     // System.out.println( "COMMIT:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
-    upres = server.optimize( true, true );
+    upres = client.optimize( true, true );
     // System.out.println( "OPTIMIZE:"+upres.getResponse() );
     Assert.assertEquals(0, upres.getStatus());
     
@@ -165,7 +165,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.addFacetField("timestamp_dt");
     query.removeFilterQuery("inStock:true");
     
-    response = server.query( query );
+    response = client.query( query );
     Assert.assertEquals(0, response.getStatus());
     Assert.assertEquals(5, response.getResults().getNumFound() );
     Assert.assertEquals(3, response.getFacetQuery().size());    
@@ -175,7 +175,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     // test a second query, test making a copy of the main query
     SolrQuery query2 = query.getCopy();
     query2.addFilterQuery("inStock:true");
-    response = server.query( query2 );
+    response = client.query( query2 );
     Assert.assertEquals(1, query2.getFilterQueries().length);
     Assert.assertEquals(0, response.getStatus());
     Assert.assertEquals(2, response.getResults().getNumFound() );
@@ -188,7 +188,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.addFacetQuery("price:[* TO 2]");
     query.addFacetQuery("price:[2 TO 4]");
 
-    response = server.query( query );
+    response = client.query( query );
     assertTrue("echoed params are not a NamedList: " +
                response.getResponseHeader().get("params").getClass(),
                response.getResponseHeader().get("params") instanceof NamedList);
@@ -213,13 +213,13 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     if (jetty != null) {
       // check system wide system handler + "/admin/info/system"
       String url = jetty.getBaseUrl().toString();
-      HttpSolrServer client = new HttpSolrServer(url);
+      HttpSolrClient adminClient = new HttpSolrClient(url);
       SolrQuery q = new SolrQuery();
       q.set("qt", "/admin/info/system");
-      QueryResponse rsp = client.query(q);
+      QueryResponse rsp = adminClient.query(q);
       assertNotNull(rsp.getResponse().get("mode"));
       assertNotNull(rsp.getResponse().get("lucene"));
-      client.shutdown();
+      adminClient.shutdown();
     }
   }
 
@@ -230,10 +230,10 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
  @Test
  public void testAddRetrieve() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
+    client.deleteByQuery("*:*");// delete everything!
     
     // Now add something...
     SolrInputDocument doc1 = new SolrInputDocument();
@@ -251,28 +251,28 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     docs.add( doc2 );
     
     // Add the documents
-    server.add( docs );
-    server.commit();
+    client.add(docs);
+    client.commit();
     
     SolrQuery query = new SolrQuery();
     query.setQuery( "*:*" );
     query.addSortField( "price", SolrQuery.ORDER.asc );
-    QueryResponse rsp = server.query( query );
+    QueryResponse rsp = client.query( query );
     
-    assertEquals( 2, rsp.getResults().getNumFound() );
+    assertEquals(2, rsp.getResults().getNumFound());
     // System.out.println( rsp.getResults() );
     
     // Now do it again
-    server.add( docs );
-    server.commit();
+    client.add( docs );
+    client.commit();
     
-    rsp = server.query( query );
+    rsp = client.query( query );
     assertEquals( 2, rsp.getResults().getNumFound() );
     // System.out.println( rsp.getResults() );
 
     // query outside ascii range
     query.setQuery("name:h\uD866\uDF05llo");
-    rsp = server.query( query );
+    rsp = client.query( query );
     assertEquals( 1, rsp.getResults().getNumFound() );
 
   }
@@ -284,26 +284,26 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testGetEmptyResults() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
      
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
      
     // Add two docs
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField( "id", "id1", 1.0f );
     doc.addField( "name", "doc1", 1.0f );
     doc.addField( "price", 10 );
-    server.add( doc );
+    client.add(doc);
     
     doc = new SolrInputDocument();
     doc.addField( "id", "id2", 1.0f );
-    server.add( doc );
-    server.commit();
+    client.add(doc);
+    client.commit();
     
     // Make sure we get empty docs for unknown field
-    SolrDocumentList out = server.query( new SolrQuery( "*:*" ).set("fl", "foofoofoo" ) ).getResults();
+    SolrDocumentList out = client.query( new SolrQuery( "*:*" ).set("fl", "foofoofoo" ) ).getResults();
     assertEquals( 2, out.getNumFound() );
     assertEquals( 0, out.get(0).size() );
     assertEquals( 0, out.get(1).size() );
@@ -338,30 +338,30 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     Random random = random();
     int numIterations = atLeast(3);
     
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // save the old parser, so we can set it back.
     ResponseParser oldParser = null;
-    if (server instanceof HttpSolrServer) {
-      HttpSolrServer cserver = (HttpSolrServer) server;
-      oldParser = cserver.getParser();
+    if (client instanceof HttpSolrClient) {
+      HttpSolrClient httpSolrClient = (HttpSolrClient) client;
+      oldParser = httpSolrClient.getParser();
     }
     
     try {
       for (int iteration = 0; iteration < numIterations; iteration++) {
         // choose format
-        if (server instanceof HttpSolrServer) {
+        if (client instanceof HttpSolrClient) {
           if (random.nextBoolean()) {
-            ((HttpSolrServer) server).setParser(new BinaryResponseParser());
+            ((HttpSolrClient) client).setParser(new BinaryResponseParser());
           } else {
-            ((HttpSolrServer) server).setParser(new XMLResponseParser());
+            ((HttpSolrClient) client).setParser(new XMLResponseParser());
           }
         }
 
         int numDocs = TestUtil.nextInt(random(), 1, 10 * RANDOM_MULTIPLIER);
         
         // Empty the database...
-        server.deleteByQuery("*:*");// delete everything!
+        client.deleteByQuery("*:*");// delete everything!
         
         List<SolrInputDocument> docs = new ArrayList<>();
         for (int i = 0; i < numDocs; i++) {
@@ -372,14 +372,14 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
           docs.add(doc);
         }
         
-        server.add(docs);
-        server.commit();
+        client.add(docs);
+        client.commit();
         
         SolrQuery query = new SolrQuery();
         query.setQuery("*:*");
         query.setRows(numDocs);
         
-        QueryResponse rsp = server.query( query );
+        QueryResponse rsp = client.query( query );
         
         for (int i = 0; i < numDocs; i++) {
           String expected = (String) docs.get(i).getFieldValue("unicode_s");
@@ -390,7 +390,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     } finally {
       if (oldParser != null) {
         // set the old parser back
-        ((HttpSolrServer)server).setParser(oldParser);
+        ((HttpSolrClient)client).setParser(oldParser);
       }
     }
   }
@@ -398,14 +398,14 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testErrorHandling() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
 
     SolrQuery query = new SolrQuery();
     query.set(CommonParams.QT, "/analysis/field");
     query.set(AnalysisParams.FIELD_TYPE, "int");
     query.set(AnalysisParams.FIELD_VALUE, "ignore_exception");
     try {
-      server.query( query );
+      client.query( query );
       Assert.fail("should have a number format exception");
     }
     catch(SolrException ex) {
@@ -420,7 +420,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     try {
       //the df=text here is a kluge for the test to supply a default field in case there is none in schema.xml
       // alternatively, the resulting assertion could be modified to assert that no default field is specified.
-      server.deleteByQuery( "{!df=text} ??::?? ignore_exception" ); // query syntax error
+      client.deleteByQuery( "{!df=text} ??::?? ignore_exception" ); // query syntax error
       Assert.fail("should have a number format exception");
     }
     catch(SolrException ex) {
@@ -437,9 +437,9 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc.addField("id", "DOCID2", 1.0f);
     doc.addField("name", "hello", 1.0f);
 
-    if (server instanceof HttpSolrServer) {
+    if (client instanceof HttpSolrClient) {
       try {
-        server.add(doc);
+        client.add(doc);
         fail("Should throw exception!");
       } catch (SolrException ex) {
         assertEquals(400, ex.code());
@@ -448,21 +448,21 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       } catch (Throwable t) {
         Assert.fail("should have thrown a SolrException! not: " + t);
       }
-    } else if (server instanceof ConcurrentUpdateSolrServer) {
+    } else if (client instanceof ConcurrentUpdateSolrClient) {
       //XXX concurrentupdatesolrserver reports errors differently
-      ConcurrentUpdateSolrServer cs = (ConcurrentUpdateSolrServer) server;
-      Field field = getCUSSExceptionField(cs);
-      field.set(cs,  null);
-      cs.add(doc);
-      cs.blockUntilFinished();
-      Throwable lastError = (Throwable)field.get(cs);
+      ConcurrentUpdateSolrClient concurrentClient = (ConcurrentUpdateSolrClient) client;
+      Field field = getConcurrentClientExceptionField(concurrentClient);
+      field.set(concurrentClient, null);
+      concurrentClient.add(doc);
+      concurrentClient.blockUntilFinished();
+      Throwable lastError = (Throwable)field.get(concurrentClient);
       assertNotNull("Should throw exception!", lastError); //XXX 
     } else {
-      log.info("Ignorig update test for client:" + server.getClass().getName());
+      log.info("Ignoring update test for client:" + client.getClass().getName());
     }
   }
   
-  private static Field getCUSSExceptionField(Object cs)
+  private static Field getConcurrentClientExceptionField(Object cs)
       throws SecurityException, NoSuchFieldException, IllegalArgumentException {
     Field field = cs.getClass().getDeclaredField("lastError");
     field.setAccessible(true);
@@ -472,31 +472,31 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testAugmentFields() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
+    client.deleteByQuery("*:*");// delete everything!
     
     // Now add something...
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField( "id", "111", 1.0f );
     doc.addField( "name", "doc1", 1.0f );
     doc.addField( "price", 11 );
-    server.add( doc );
-    server.commit(); // make sure this gets in first
+    client.add(doc);
+    client.commit(); // make sure this gets in first
     
     doc = new SolrInputDocument();
     doc.addField( "id", "222", 1.0f );
     doc.addField( "name", "doc2", 1.0f );
     doc.addField( "price", 22 );
-    server.add( doc );
-    server.commit();
+    client.add(doc);
+    client.commit();
     
     SolrQuery query = new SolrQuery();
     query.setQuery( "*:*" );
     query.set( CommonParams.FL, "id,price,[docid],[explain style=nl],score,aaa:[value v=aaa],ten:[value v=10 t=int]" );
     query.addSortField( "price", SolrQuery.ORDER.asc );
-    QueryResponse rsp = server.query( query );
+    QueryResponse rsp = client.query( query );
     
     SolrDocumentList out = rsp.getResults();
     assertEquals( 2, out.getNumFound() );
@@ -523,10 +523,10 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testUpdateRequestWithParameters() throws Exception {
-    SolrServer server1 = createNewSolrServer();
+    SolrClient client = createNewSolrClient();
     
-    server1.deleteByQuery( "*:*" );
-    server1.commit();
+    client.deleteByQuery("*:*");
+    client.commit();
     
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "id1");
@@ -534,47 +534,47 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     UpdateRequest req = new UpdateRequest();
     req.setParam("overwrite", "false");
     req.add(doc);
-    server1.request(req);
-    server1.request(req);
-    server1.commit();
+    client.request(req);
+    client.request(req);
+    client.commit();
     
     SolrQuery query = new SolrQuery();
     query.setQuery("*:*");
-    QueryResponse rsp = server1.query(query);
+    QueryResponse rsp = client.query(query);
     
     SolrDocumentList out = rsp.getResults();
     assertEquals(2, out.getNumFound());
-    if (!(server1 instanceof EmbeddedSolrServer)) {
+    if (!(client instanceof EmbeddedSolrServer)) {
       /* Do not close in case of using EmbeddedSolrServer,
        * as that would close the CoreContainer */
-      server1.shutdown();
+      client.shutdown();
     }
   }
   
  @Test
  public void testContentStreamRequest() throws Exception {
-    SolrServer server = getSolrServer();
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
-    QueryResponse rsp = server.query( new SolrQuery( "*:*") );
-    Assert.assertEquals( 0, rsp.getResults().getNumFound() );
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
+    QueryResponse rsp = client.query( new SolrQuery( "*:*") );
+    Assert.assertEquals(0, rsp.getResults().getNumFound());
 
     ContentStreamUpdateRequest up = new ContentStreamUpdateRequest("/update");
     up.addFile(getFile("solrj/books.csv"), "application/csv");
     up.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
-    NamedList<Object> result = server.request(up);
+    NamedList<Object> result = client.request(up);
     assertNotNull("Couldn't upload books.csv", result);
-    rsp = server.query( new SolrQuery( "*:*") );
+    rsp = client.query( new SolrQuery( "*:*") );
     Assert.assertEquals( 10, rsp.getResults().getNumFound() );
  }
 
  @Test
  public void testMultiContentStreamRequest() throws Exception {
-    SolrServer server = getSolrServer();
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
-    QueryResponse rsp = server.query( new SolrQuery( "*:*") );
-    Assert.assertEquals( 0, rsp.getResults().getNumFound() );
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
+    QueryResponse rsp = client.query( new SolrQuery( "*:*") );
+    Assert.assertEquals(0, rsp.getResults().getNumFound());
 
     ContentStreamUpdateRequest up = new ContentStreamUpdateRequest("/update");
     up.addFile(getFile("solrj/docs1.xml"),"application/xml"); // 2
@@ -582,49 +582,49 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     up.setParam("a", "\u1234");
     up.setParam(CommonParams.HEADER_ECHO_PARAMS, CommonParams.EchoParamStyle.ALL.toString());
     up.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
-    NamedList<Object> result = server.request(up);
+    NamedList<Object> result = client.request(up);
     Assert.assertEquals("\u1234",
         ((NamedList)((NamedList) result.get("responseHeader")).get("params")).get("a"));
     assertNotNull("Couldn't upload xml files", result);
-    rsp = server.query( new SolrQuery( "*:*") );
+    rsp = client.query( new SolrQuery( "*:*") );
     Assert.assertEquals( 5 , rsp.getResults().getNumFound() );
   }
   
  @Test
  public void testLukeHandler() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
+    client.deleteByQuery("*:*");// delete everything!
     
     SolrInputDocument[] doc = new SolrInputDocument[5];
     for( int i=0; i<doc.length; i++ ) {
       doc[i] = new SolrInputDocument();
       doc[i].setField( "id", "ID"+i, 1.0f );
-      server.add( doc[i] );
+      client.add(doc[i]);
     }
-    server.commit();
+    client.commit();
     assertNumFound( "*:*", doc.length ); // make sure it got in
     
     LukeRequest luke = new LukeRequest();
     luke.setShowSchema( false );
-    LukeResponse rsp = luke.process( server );
+    LukeResponse rsp = luke.process( client );
     assertNull( rsp.getFieldTypeInfo() ); // if you don't ask for it, the schema is null
     
     luke.setShowSchema( true );
-    rsp = luke.process( server );
+    rsp = luke.process( client );
     assertNotNull( rsp.getFieldTypeInfo() ); 
   }
 
  @Test
  public void testStatistics() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
 
     String f = "val_i";
@@ -636,54 +636,54 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       doc.setField( "id", "doc"+i++ );
       doc.setField( "name", "doc: "+num );
       doc.setField( f, num );
-      server.add( doc );
+      client.add(doc);
     }
-    server.commit();
+    client.commit();
     assertNumFound( "*:*", nums.length ); // make sure they all got in
     
     SolrQuery query = new SolrQuery( "*:*" );
     query.setRows( 0 );
     query.setGetFieldStatistics( f );
     
-    QueryResponse rsp = server.query( query );
+    QueryResponse rsp = client.query( query );
     FieldStatsInfo stats = rsp.getFieldStatsInfo().get( f );
-    assertNotNull( stats );
+    assertNotNull(stats);
     
     assertEquals( 23.0, ((Double)stats.getMin()).doubleValue(), 0 );
-    assertEquals( 94.0, ((Double)stats.getMax()).doubleValue(), 0 );
+    assertEquals(94.0, ((Double) stats.getMax()).doubleValue(), 0);
     assertEquals( new Long(nums.length), stats.getCount() );
     assertEquals( new Long(0), stats.getMissing() );
-    assertEquals( "26.4", stats.getStddev().toString().substring(0,4) );
+    assertEquals( "26.4", stats.getStddev().toString().substring(0, 4) );
     
     // now lets try again with a new set...  (odd median)
     //----------------------------------------------------
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
-    assertNumFound( "*:*", 0 ); // make sure it got in
+    client.deleteByQuery( "*:*" );// delete everything!
+    client.commit();
+    assertNumFound("*:*", 0); // make sure it got in
     nums = new int[] { 5, 7, 10, 19, 20 };
     for( int num : nums ) {
       SolrInputDocument doc = new SolrInputDocument();
       doc.setField( "id", "doc"+i++ );
       doc.setField( "name", "doc: "+num );
       doc.setField( f, num );
-      server.add( doc );
+      client.add( doc );
     }
-    server.commit();
+    client.commit();
     assertNumFound( "*:*", nums.length ); // make sure they all got in
     
-    rsp = server.query( query );
+    rsp = client.query( query );
     stats = rsp.getFieldStatsInfo().get( f );
     assertNotNull( stats );
     
-    assertEquals( 5.0, ((Double)stats.getMin()).doubleValue(), 0 );
+    assertEquals(5.0, ((Double) stats.getMin()).doubleValue(), 0);
     assertEquals( 20.0, ((Double)stats.getMax()).doubleValue(), 0 );
-    assertEquals( new Long(nums.length), stats.getCount() );
+    assertEquals(new Long(nums.length), stats.getCount());
     assertEquals( new Long(0), stats.getMissing() );
     
     // Now try again with faceting
     //---------------------------------
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
     nums = new int[] { 1, 2, 3, 4, 5, 10, 11, 12, 13, 14 };
     for( i=0; i<nums.length; i++ ) {
@@ -693,15 +693,15 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       doc.setField( "name", "doc: "+num );
       doc.setField( f, num );
       doc.setField( "inStock", i < 5 );
-      server.add( doc );
+      client.add( doc );
     }
-    server.commit();
+    client.commit();
     assertNumFound( "inStock:true",  5 ); // make sure they all got in
     assertNumFound( "inStock:false", 5 ); // make sure they all got in
 
     // facet on 'inStock'
-    query.addStatsFieldFacets( f, "inStock" );
-    rsp = server.query( query );
+    query.addStatsFieldFacets(f, "inStock");
+    rsp = client.query( query );
     stats = rsp.getFieldStatsInfo().get( f );
     assertNotNull( stats );
     
@@ -727,26 +727,26 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testPingHandler() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
     
     // should be ok
-    server.ping();
+    client.ping();
     
   }
   
   @Test
   public void testFaceting() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
     
     ArrayList<SolrInputDocument> docs = new ArrayList<>(10);
@@ -767,8 +767,8 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       }
       docs.add( doc );
     }
-    server.add( docs );
-    server.commit();
+    client.add(docs);
+    client.commit();
     
     SolrQuery query = new SolrQuery( "*:*" );
     query.remove( FacetParams.FACET_FIELD );
@@ -777,8 +777,8 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.setFacet( true );
     query.setRows( 0 );
     
-    QueryResponse rsp = server.query( query );
-    assertEquals( docs.size(), rsp.getResults().getNumFound() );
+    QueryResponse rsp = client.query( query );
+    assertEquals(docs.size(), rsp.getResults().getNumFound());
     
     List<FacetField> facets = rsp.getFacetFields();
     assertEquals( 1, facets.size() );
@@ -790,19 +790,19 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     
     // should be the same facets with minCount=0
     query.setFilterQueries( "features:two" );
-    rsp = server.query( query );
+    rsp = client.query( query );
     ff = rsp.getFacetField( "features" );
-    assertEquals( "[two (5), four (2), five (1), three (1)]", ff.getValues().toString() );
+    assertEquals("[two (5), four (2), five (1), three (1)]", ff.getValues().toString());
     
     // with minCount > 3
-    query.setFacetMinCount( 4 );
-    rsp = server.query( query );
+    query.setFacetMinCount(4);
+    rsp = client.query( query );
     ff = rsp.getFacetField( "features" );
     assertEquals( "[two (5)]", ff.getValues().toString() );
 
     // with minCount > 3
-    query.setFacetMinCount( -1 );
-    rsp = server.query( query );
+    query.setFacetMinCount(-1);
+    rsp = client.query( query );
     ff = rsp.getFacetField( "features" );
     
     // System.out.println( rsp.getResults().getNumFound() + " :::: 444: "+ff.getValues() );
@@ -815,11 +815,11 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     
   @Test
   public void testPivotFacetsStats() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
 
     // Empty the database...
-    server.deleteByQuery("*:*");// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got in
 
     int id = 1;
@@ -836,8 +836,8 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     docs.add(makeTestDoc("id", id++, "features", "bbb", "manu", "ztc", "cat", "b", "inStock", false, "popularity", 38, "price", 47.98));
     docs.add(makeTestDoc("id", id++, "features", "bbb", "manu", "ztc", "cat", "b", "inStock", true, "popularity", -38));
     docs.add(makeTestDoc("id", id++, "cat", "b")); // something not matching all fields
-    server.add(docs);
-    server.commit();
+    client.add(docs);
+    client.commit();
 
     for (String pivot : new String[] { "{!key=pivot_key stats=s1}features,manu",
                                        "{!key=pivot_key stats=s1}features,manu,cat",
@@ -854,7 +854,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       query.setFacetMinCount(0);
       query.setRows(0);
 
-      QueryResponse rsp = server.query(query);
+      QueryResponse rsp = client.query(query);
 
       // check top (ie: non-pivot) stats
       Map<String, FieldStatsInfo> map = rsp.getFieldStatsInfo();
@@ -942,17 +942,17 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testPivotFacetsStatsNotSupported() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
 
     // Empty the database...
-    server.deleteByQuery("*:*");// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got in
 
     // results of this test should be the same regardless of whether any docs in index
     if (random().nextBoolean()) {
-      server.add(makeTestDoc("id", 1, "features", "aaa", "cat", "a", "inStock", true, "popularity", 12, "price", .017));
-      server.commit();
+      client.add(makeTestDoc("id", 1, "features", "aaa", "cat", "a", "inStock", true, "popularity", 12, "price", .017));
+      client.commit();
     }
 
     ignoreException("is not currently supported");
@@ -962,7 +962,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.addFacetPivotField("{!stats=s1}features,manu");
     query.addGetFieldStatistics("{!key=inStock_val tag=s1}inStock");
     try {
-      server.query(query);
+      client.query(query);
       fail("SolrException should be thrown on query");
     } catch (SolrException e) {
       assertEquals("Pivot facet on boolean is not currently supported, bad request returned", 400, e.code());
@@ -977,7 +977,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.setFacetMinCount(0);
     query.setRows(0);
     try {
-      server.query(query);
+      client.query(query);
       fail("SolrException should be thrown on query");
     } catch (SolrException e) {
       assertEquals(400, e.code());
@@ -993,7 +993,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.setFacetMinCount(0);
     query.setRows(0);
     try {
-      server.query(query);
+      client.query(query);
       fail("SolrException should be thrown on query");
     } catch (SolrException e) {
       assertEquals("Pivot facet on string is not currently supported, bad request returned", 400, e.code());
@@ -1009,11 +1009,11 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   }
     
   private void doPivotFacetTest(boolean missing) throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
     
     int id = 1;
@@ -1030,8 +1030,8 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     docs.add( makeTestDoc( "id", id++, "features", "bbb",  "cat", "b", "inStock", false ) );
     docs.add( makeTestDoc( "id", id++, "features", "bbb",  "cat", "b", "inStock", true ) );
     docs.add( makeTestDoc( "id", id++,  "cat", "b" ) ); // something not matching all fields
-    server.add( docs );
-    server.commit();
+    client.add(docs);
+    client.commit();
     
     SolrQuery query = new SolrQuery( "*:*" );
     query.addFacetPivotField("features,cat", "cat,features", "features,cat,inStock" );
@@ -1039,8 +1039,8 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query.setFacetMissing( missing );
     query.setRows( 0 );
     
-    QueryResponse rsp = server.query( query );
-    assertEquals( docs.size(), rsp.getResults().getNumFound() );
+    QueryResponse rsp = client.query( query );
+    assertEquals(docs.size(), rsp.getResults().getNumFound());
     
     NamedList<List<PivotField>> pivots = rsp.getFacetPivot();
     assertEquals( 3, pivots.size() );
@@ -1200,10 +1200,10 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     query = new SolrQuery( "*:*" );
     query.addFacetPivotField( "{!ex=mytag key=mykey}features,cat" );
     query.addFilterQuery("{!tag=mytag}-(features:bbb AND cat:a AND inStock:true)");//filters out one
-    query.setFacetMinCount( 0 );
-    query.setRows( 0 );
+    query.setFacetMinCount(0);
+    query.setRows(0);
 
-    rsp = server.query( query );
+    rsp = client.query( query );
     assertEquals( docs.size() - 1, rsp.getResults().getNumFound() );//one less due to filter
 
     //The rest of this test should be just like the original since we've
@@ -1240,10 +1240,10 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testChineseDefaults() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound( "*:*", 0 ); // make sure it got in
 
     // Beijing medical University
@@ -1254,28 +1254,28 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     req.add(doc);
 
     req.setAction(ACTION.COMMIT, true, true );
-    req.process( server );
+    req.process( client );
 
     // Beijing university should match:
     SolrQuery query = new SolrQuery("???");
-    QueryResponse rsp = server.query( query );
+    QueryResponse rsp = client.query( query );
     assertEquals(1, rsp.getResults().getNumFound());
   }
 
   @Test
   public void testRealtimeGet() throws Exception
   {    
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery( "*:*" );// delete everything!
+    client.deleteByQuery("*:*");// delete everything!
     
     // Now add something...
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField( "id", "DOCID", 1.0f );
     doc.addField( "name", "hello", 1.0f );
-    server.add( doc );
-    server.commit();  // Since the transaction log is disabled in the example, we need to commit
+    client.add(doc);
+    client.commit();  // Since the transaction log is disabled in the example, we need to commit
     
     SolrQuery q = new SolrQuery();
     q.setRequestHandler("/get");
@@ -1285,7 +1285,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     // First Try with the BinaryResponseParser
     QueryRequest req = new QueryRequest( q );
     req.setResponseParser(new BinaryResponseParser());
-    QueryResponse rsp = req.process(server);
+    QueryResponse rsp = req.process(client);
     SolrDocument out = (SolrDocument)rsp.getResponse().get("doc");
     assertEquals("DOCID", out.get("id"));
     assertEquals("hello", out.get("name"));
@@ -1293,7 +1293,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
     // Then with the XMLResponseParser
     req.setResponseParser(new XMLResponseParser());
-    rsp = req.process(server);
+    rsp = req.process(client);
     out = (SolrDocument)rsp.getResponse().get("doc");
     assertEquals("DOCID", out.get("id"));
     assertEquals("hello", out.get("name"));
@@ -1303,18 +1303,18 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
   @Test
   public void testUpdateField() throws Exception {
     //no versions
-    SolrServer server = getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit();
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "unique");
     doc.addField("name", "gadget");
     doc.addField("price_f", 1);
-    server.add(doc);
-    server.commit();
+    client.add(doc);
+    client.commit();
     SolrQuery q = new SolrQuery("*:*");
     q.setFields("id","price_f","name", "_version_");
-    QueryResponse resp = server.query(q);
+    QueryResponse resp = client.query(q);
     assertEquals("Doc count does not match", 1, resp.getResults().getNumFound());
     Long version = (Long)resp.getResults().get(0).getFirstValue("_version_");
     assertNotNull("no version returned", version);
@@ -1329,12 +1329,12 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc.addField("_version_", version+1);
     doc.addField("price_f", oper);
     try {
-      server.add(doc);
-      if(server instanceof HttpSolrServer) { //XXX concurrent server reports exceptions differently
+      client.add(doc);
+      if(client instanceof HttpSolrClient) { //XXX concurrent client reports exceptions differently
         fail("Operation should throw an exception!");
       } else {
-        server.commit(); //just to be sure the client has sent the doc
-        assertTrue("CUSS did not report an error", ((Throwable)getCUSSExceptionField(server).get(server)).getMessage().contains("Conflict"));
+        client.commit(); //just to be sure the client has sent the doc
+        assertTrue("ConcurrentUpdateSolrClient did not report an error", ((Throwable) getConcurrentClientExceptionField(client).get(client)).getMessage().contains("Conflict"));
       }
     } catch (SolrException se) {
       assertTrue("No identifiable error message", se.getMessage().contains("version conflict for unique"));
@@ -1345,9 +1345,9 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc.addField("id", "unique");
     doc.addField("_version_", version);
     doc.addField("price_f", oper);
-    server.add(doc);
-    server.commit();
-    resp = server.query(q);
+    client.add(doc);
+    client.commit();
+    resp = client.query(q);
     assertEquals("Doc count does not match", 1, resp.getResults().getNumFound());
     assertEquals("price was not updated?", 100.0f, resp.getResults().get(0).getFirstValue("price_f"));
     assertEquals("no name?", "gadget", resp.getResults().get(0).getFirstValue("name"));
@@ -1357,9 +1357,9 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc = new SolrInputDocument();
     doc.addField("id", "unique");
     doc.addField("price_f", oper);
-    server.add(doc);
-    server.commit();
-    resp = server.query(q);
+    client.add(doc);
+    client.commit();
+    resp = client.query(q);
     assertEquals("Doc count does not match", 1, resp.getResults().getNumFound());
     assertEquals("price was not updated?", 200.0f, resp.getResults().get(0).getFirstValue("price_f"));
     assertEquals("no name?", "gadget", resp.getResults().get(0).getFirstValue("name"));
@@ -1367,20 +1367,20 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testUpdateMultiValuedField() throws Exception {
-    SolrServer solrServer = getSolrServer();
+    SolrClient solrClient = getSolrClient();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "123");
-    solrServer.add(doc);
-    solrServer.commit(true, true);
-    QueryResponse response = solrServer.query(new SolrQuery("id:123"));
+    solrClient.add(doc);
+    solrClient.commit(true, true);
+    QueryResponse response = solrClient.query(new SolrQuery("id:123"));
     assertEquals("Failed to add doc to cloud server", 1, response.getResults().getNumFound());
 
     Map<String, List<String>> operation = new HashMap<>();
     operation.put("set", Arrays.asList("first", "second", "third"));
     doc.addField("multi_ss", operation);
-    solrServer.add(doc);
-    solrServer.commit(true, true);
-    response = solrServer.query(new SolrQuery("id:123"));
+    solrClient.add(doc);
+    solrClient.commit(true, true);
+    response = solrClient.query(new SolrQuery("id:123"));
     assertTrue("Multi-valued field did not return a collection", response.getResults().get(0).get("multi_ss") instanceof List);
     List<String> values = (List<String>) response.getResults().get(0).get("multi_ss");
     assertEquals("Field values was not updated with all values via atomic update", 3, values.size());
@@ -1389,42 +1389,42 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     operation.put("add", Arrays.asList("fourth", "fifth"));
     doc.removeField("multi_ss");
     doc.addField("multi_ss", operation);
-    solrServer.add(doc);
-    solrServer.commit(true, true);
-    response = solrServer.query(new SolrQuery("id:123"));
+    solrClient.add(doc);
+    solrClient.commit(true, true);
+    response = solrClient.query(new SolrQuery("id:123"));
     values = (List<String>) response.getResults().get(0).get("multi_ss");
     assertEquals("Field values was not updated with all values via atomic update", 5, values.size());
   }
 
   @Test
   public void testSetNullUpdates() throws Exception {
-    SolrServer solrServer = getSolrServer();
+    SolrClient solrClient = getSolrClient();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "testSetNullUpdates");
     doc.addField("single_s", "test-value");
     doc.addField("multi_ss", Arrays.asList("first", "second"));
-    solrServer.add(doc);
-    solrServer.commit(true, true);
+    solrClient.add(doc);
+    solrClient.commit(true, true);
     doc.removeField("single_s");
     doc.removeField("multi_ss");
     Map<String, Object> map = Maps.newHashMap();
     map.put("set", null);
     doc.addField("multi_ss", map);
-    solrServer.add(doc);
-    solrServer.commit(true, true);
-    QueryResponse response = solrServer.query(new SolrQuery("id:testSetNullUpdates"));
+    solrClient.add(doc);
+    solrClient.commit(true, true);
+    QueryResponse response = solrClient.query(new SolrQuery("id:testSetNullUpdates"));
     assertNotNull("Entire doc was replaced because null update was not written", response.getResults().get(0).getFieldValue("single_s"));
     assertNull("Null update failed. Value still exists in document", response.getResults().get(0).getFieldValue("multi_ss"));
   }
 
   public void testSetNullUpdateOrder() throws Exception {
-    SolrServer solrServer = getSolrServer();
+    SolrClient solrClient = getSolrClient();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "testSetNullUpdateOrder");
     doc.addField("single_s", "test-value");
     doc.addField("multi_ss", Arrays.asList("first", "second"));
-    solrServer.add(doc);
-    solrServer.commit(true, true);
+    solrClient.add(doc);
+    solrClient.commit(true, true);
 
     Map<String, Object> map = Maps.newHashMap();
     map.put("set", null);
@@ -1432,20 +1432,20 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     doc.addField("multi_ss", map);
     doc.addField("id", "testSetNullUpdateOrder");
     doc.addField("single_s", "test-value2");
-    solrServer.add(doc);
-    solrServer.commit();
+    solrClient.add(doc);
+    solrClient.commit();
 
-    QueryResponse response = solrServer.query(new SolrQuery("id:testSetNullUpdateOrder"));
+    QueryResponse response = solrClient.query(new SolrQuery("id:testSetNullUpdateOrder"));
     assertEquals("Field included after set null=true not updated via atomic update", "test-value2",
         response.getResults().get(0).getFieldValue("single_s"));
   }
   
   @Test
   public void testQueryWithParams() throws SolrServerException {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     SolrQuery q = new SolrQuery("query");
     q.setParam("debug", true);
-    QueryResponse resp = server.query(q);
+    QueryResponse resp = client.query(q);
     assertEquals(
         "server didn't respond with debug=true, didn't we pass in the parameter?",
         "true",
@@ -1455,9 +1455,9 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testChildDoctransformer() throws IOException, SolrServerException {
-    SolrServer server = getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit();
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit();
 
     int numRootDocs = TestUtil.nextInt(random(), 10, 100);
     int maxDepth = TestUtil.nextInt(random(), 2, 5);
@@ -1465,22 +1465,22 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
     Map<String,SolrInputDocument> allDocs = new HashMap<>();
 
     for (int i =0; i < numRootDocs; i++) {
-      server.add(genNestedDocuments(allDocs, 0, maxDepth));
+      client.add(genNestedDocuments(allDocs, 0, maxDepth));
     }
 
-    server.commit();
+    client.commit();
 
     // sanity check
     SolrQuery q = new SolrQuery("*:*");
-    QueryResponse resp = server.query(q);
-    assertEquals("Doc count does not match", 
-                 allDocs.size(), resp.getResults().getNumFound());
+    QueryResponse resp = client.query(q);
+    assertEquals("Doc count does not match",
+        allDocs.size(), resp.getResults().getNumFound());
 
 
     // base check - we know there is an exact number of these root docs
     q = new SolrQuery("level_i:0");
     q.setFields("*", "[child parentFilter=\"level_i:0\"]");
-    resp = server.query(q);
+    resp = client.query(q);
     assertEquals("topLevel count does not match", numRootDocs,
                  resp.getResults().getNumFound());
     for (SolrDocument outDoc : resp.getResults()) {
@@ -1512,7 +1512,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       q.setFields("id,[child parentFilter=\"" + parentFilter +
                   "\" childFilter=\"" + childFilter + 
                   "\" limit=\"" + maxKidCount + "\"]");
-      resp = server.query(q);
+      resp = client.query(q);
       for (SolrDocument outDoc : resp.getResults()) {
         String docId = (String)outDoc.getFieldValue("id");
         SolrInputDocument origDoc = allDocs.get(docId);
@@ -1560,7 +1560,7 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
       q.setFields("id,[child parentFilter=\"" + parentFilter +
                   "\" childFilter=\"" + childFilter + 
                   "\" limit=\"" + maxKidCount + "\"]");
-      resp = server.query(q);
+      resp = client.query(q);
       for (SolrDocument outDoc : resp.getResults()) {
         String docId = (String)outDoc.getFieldValue("id");
         SolrInputDocument origDoc = allDocs.get(docId);
@@ -1588,58 +1588,58 @@ abstract public class SolrExampleTests extends SolrExampleTestsBase
 
   @Test
   public void testFieldGlobbing() throws Exception  {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
 
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "testFieldGlobbing");
     doc.addField("x_s", "x");
     doc.addField("y_s", "y");
     doc.addField("z_s", "z");
-    server.add(doc);
-    server.commit();
+    client.add(doc);
+    client.commit();
 
     // id and glob
-    QueryResponse response = server.query(new SolrQuery("id:testFieldGlobbing").addField("id").addField("*_s"));
+    QueryResponse response = client.query(new SolrQuery("id:testFieldGlobbing").addField("id").addField("*_s"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 4, response.getResults().get(0).getFieldNames().size());
 
     // just globs
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("*_s"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("*_s"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 3, response.getResults().get(0).getFieldNames().size());
 
     // just id
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("id"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("id"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 1, response.getResults().get(0).getFieldNames().size());
 
     // id and pseudo field and glob
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("id").addField("[docid]").addField("*_s"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("id").addField("[docid]").addField("*_s"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 5, response.getResults().get(0).getFieldNames().size());
 
     // pseudo field and glob
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("[docid]").addField("*_s"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("[docid]").addField("*_s"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 4, response.getResults().get(0).getFieldNames().size());
 
     // just a pseudo field
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("[docid]"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("[docid]"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 1, response.getResults().get(0).getFieldNames().size());
 
     // only score
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("score"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("score"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 1, response.getResults().get(0).getFieldNames().size());
 
     // pseudo field and score
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("score").addField("[docid]"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("score").addField("[docid]"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 2, response.getResults().get(0).getFieldNames().size());
 
     // score and globs
-    response = server.query(new SolrQuery("id:testFieldGlobbing").addField("score").addField("*_s"));
+    response = client.query(new SolrQuery("id:testFieldGlobbing").addField("score").addField("*_s"));
     assertEquals("Document not found", 1, response.getResults().getNumFound());
     assertEquals("All requested fields were not returned", 4, response.getResults().get(0).getFieldNames().size());
   }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestsBase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestsBase.java
index 5e56819..0ee63d1 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestsBase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleTestsBase.java
@@ -17,16 +17,10 @@
 
 package org.apache.solr.client.solrj;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import junit.framework.Assert;
-
 import org.apache.solr.SolrJettyTestBase;
-import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest.ACTION;
+import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.client.solrj.util.ClientUtils;
 import org.apache.solr.common.SolrDocument;
@@ -36,6 +30,11 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.atomic.AtomicInteger;
+
 abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
   private static Logger log = LoggerFactory
       .getLogger(SolrExampleTestsBase.class);
@@ -46,10 +45,10 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
   @Test
   public void testCommitWithinOnAdd() throws Exception {
     // make sure it is empty...
-    SolrServer server = getSolrServer();
-    server.deleteByQuery("*:*");// delete everything!
-    server.commit();
-    QueryResponse rsp = server.query(new SolrQuery("*:*"));
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
+    QueryResponse rsp = client.query(new SolrQuery("*:*"));
     Assert.assertEquals(0, rsp.getResults().getNumFound());
     
     // Now try a timed commit...
@@ -61,9 +60,9 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     up.add(doc3);
     up.setCommitWithin(500); // a smaller commitWithin caused failures on the
                              // following assert
-    up.process(server);
+    up.process(client);
     
-    rsp = server.query(new SolrQuery("*:*"));
+    rsp = client.query(new SolrQuery("*:*"));
     Assert.assertEquals(0, rsp.getResults().getNumFound());
     
     // TODO: not a great way to test this - timing is easily out
@@ -71,7 +70,7 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     Thread.sleep(1000); // wait 1 sec
     
     // now check that it comes out...
-    rsp = server.query(new SolrQuery("id:id3"));
+    rsp = client.query(new SolrQuery("id:id3"));
     
     int cnt = 0;
     while (rsp.getResults().getNumFound() == 0) {
@@ -84,7 +83,7 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
       
       Thread.sleep(2000); // wait 2 seconds...
       
-      rsp = server.query(new SolrQuery("id:id3"));
+      rsp = client.query(new SolrQuery("id:id3"));
     }
     
     Assert.assertEquals(1, rsp.getResults().getNumFound());
@@ -94,12 +93,12 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     doc4.addField("id", "id4", 1.0f);
     doc4.addField("name", "doc4", 1.0f);
     doc4.addField("price", 10);
-    server.add(doc4, 500);
+    client.add(doc4, 500);
     
     Thread.sleep(1000); // wait 1 sec
     
     // now check that it comes out...
-    rsp = server.query(new SolrQuery("id:id4"));
+    rsp = client.query(new SolrQuery("id:id4"));
     
     cnt = 0;
     while (rsp.getResults().getNumFound() == 0) {
@@ -112,7 +111,7 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
       
       Thread.sleep(2000); // wait 2 seconds...
       
-      rsp = server.query(new SolrQuery("id:id3"));
+      rsp = client.query(new SolrQuery("id:id3"));
     }
     
     Assert.assertEquals(1, rsp.getResults().getNumFound());
@@ -121,10 +120,10 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
   @Test
   public void testCommitWithinOnDelete() throws Exception {
     // make sure it is empty...
-    SolrServer server = getSolrServer();
-    server.deleteByQuery("*:*");// delete everything!
-    server.commit();
-    QueryResponse rsp = server.query(new SolrQuery("*:*"));
+    SolrClient client = getSolrClient();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
+    QueryResponse rsp = client.query(new SolrQuery("*:*"));
     Assert.assertEquals(0, rsp.getResults().getNumFound());
     
     // Now add one document...
@@ -132,21 +131,21 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     doc3.addField("id", "id3", 1.0f);
     doc3.addField("name", "doc3", 1.0f);
     doc3.addField("price", 10);
-    server.add(doc3);
-    server.commit();
+    client.add(doc3);
+    client.commit();
     
     // now check that it comes out...
-    rsp = server.query(new SolrQuery("id:id3"));
+    rsp = client.query(new SolrQuery("id:id3"));
     Assert.assertEquals(1, rsp.getResults().getNumFound());
     
     // now test commitWithin on a delete
     UpdateRequest up = new UpdateRequest();
     up.setCommitWithin(1000);
     up.deleteById("id3");
-    up.process(server);
+    up.process(client);
     
     // the document should still be there
-    rsp = server.query(new SolrQuery("id:id3"));
+    rsp = client.query(new SolrQuery("id:id3"));
     Assert.assertEquals(1, rsp.getResults().getNumFound());
     
     // check if the doc has been deleted every 250 ms for 30 seconds
@@ -154,7 +153,7 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     do {
       Thread.sleep(250); // wait 250 ms
       
-      rsp = server.query(new SolrQuery("id:id3"));
+      rsp = client.query(new SolrQuery("id:id3"));
       if (rsp.getResults().getNumFound() == 0) {
         return;
       }
@@ -165,10 +164,10 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
   
   @Test
   public void testAddDelete() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     
     // Empty the database...
-    server.deleteByQuery("*:*");// delete everything!
+    client.deleteByQuery("*:*");// delete everything!
     
     SolrInputDocument[] doc = new SolrInputDocument[3];
     for (int i = 0; i < 3; i++) {
@@ -177,28 +176,28 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     }
     String id = (String) doc[0].getField("id").getFirstValue();
     
-    server.add(doc[0]);
-    server.commit();
+    client.add(doc[0]);
+    client.commit();
     assertNumFound("*:*", 1); // make sure it got in
     
     // make sure it got in there
-    server.deleteById(id);
-    server.commit();
+    client.deleteById(id);
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got out
     
     // add it back
-    server.add(doc[0]);
-    server.commit();
+    client.add(doc[0]);
+    client.commit();
     assertNumFound("*:*", 1); // make sure it got in
-    server.deleteByQuery("id:\"" + ClientUtils.escapeQueryChars(id) + "\"");
-    server.commit();
+    client.deleteByQuery("id:\"" + ClientUtils.escapeQueryChars(id) + "\"");
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got out
     
     // Add two documents
     for (SolrInputDocument d : doc) {
-      server.add(d);
+      client.add(d);
     }
-    server.commit();
+    client.commit();
     assertNumFound("*:*", 3); // make sure it got in
     
     // should be able to handle multiple delete commands in a single go
@@ -206,17 +205,17 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
     for (SolrInputDocument d : doc) {
       ids.add(d.getFieldValue("id").toString());
     }
-    server.deleteById(ids);
-    server.commit();
+    client.deleteById(ids);
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got out
   }
   
   @Test
   public void testStreamingRequest() throws Exception {
-    SolrServer server = getSolrServer();
+    SolrClient client = getSolrClient();
     // Empty the database...
-    server.deleteByQuery("*:*");// delete everything!
-    server.commit();
+    client.deleteByQuery("*:*");// delete everything!
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got in
     
     // Add some docs to the index
@@ -228,40 +227,40 @@ abstract public class SolrExampleTestsBase extends SolrJettyTestBase {
       req.add(doc);
     }
     req.setAction(ACTION.COMMIT, true, true);
-    req.process(server);
+    req.process(client);
     
     // Make sure it ran OK
     SolrQuery query = new SolrQuery("*:*");
     query.set(CommonParams.FL, "id,score,_docid_");
-    QueryResponse response = server.query(query);
+    QueryResponse response = client.query(query);
     assertEquals(0, response.getStatus());
     assertEquals(10, response.getResults().getNumFound());
     
     // Now make sure each document gets output
     final AtomicInteger cnt = new AtomicInteger(0);
-    server.queryAndStreamResponse(query, new StreamingResponseCallback() {
-      
+    client.queryAndStreamResponse(query, new StreamingResponseCallback() {
+
       @Override
       public void streamDocListInfo(long numFound, long start, Float maxScore) {
         assertEquals(10, numFound);
       }
-      
+
       @Override
       public void streamSolrDocument(SolrDocument doc) {
         cnt.incrementAndGet();
-        
+
         // Make sure the transformer works for streaming
         Float score = (Float) doc.get("score");
         assertEquals("should have score", new Float(1.0), score);
       }
-      
+
     });
     assertEquals(10, cnt.get());
   }
   
   protected void assertNumFound(String query, int num)
       throws SolrServerException, IOException {
-    QueryResponse rsp = getSolrServer().query(new SolrQuery(query));
+    QueryResponse rsp = getSolrClient().query(new SolrQuery(query));
     if (num != rsp.getResults().getNumFound()) {
       fail("expected: " + num + " but had: " + rsp.getResults().getNumFound()
           + " :: " + rsp.getResults());
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleXMLTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleXMLTest.java
index 8a4dec7..40c9da4 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleXMLTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExampleXMLTest.java
@@ -18,10 +18,9 @@
 package org.apache.solr.client.solrj;
 
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.request.RequestWriter;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 
 /**
@@ -36,17 +35,17 @@ public class SolrExampleXMLTest extends SolrExampleTests {
   }
   
   @Override
-  public SolrServer createNewSolrServer() {
+  public SolrClient createNewSolrClient() {
     try {
       String url = jetty.getBaseUrl().toString() + "/collection1";
-      HttpSolrServer s = new HttpSolrServer(url);
-      s.setUseMultiPartPost(random().nextBoolean());
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      s.setParser(new XMLResponseParser());
-      s.setRequestWriter(new RequestWriter());
-      return s;
+      HttpSolrClient client = new HttpSolrClient(url);
+      client.setUseMultiPartPost(random().nextBoolean());
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      client.setParser(new XMLResponseParser());
+      client.setRequestWriter(new RequestWriter());
+      return client;
     } catch (Exception ex) {
       throw new RuntimeException(ex);
     }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExceptionTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExceptionTest.java
index 265f5c0..31df23f 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExceptionTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrExceptionTest.java
@@ -20,7 +20,7 @@ package org.apache.solr.client.solrj;
 import org.apache.http.client.HttpClient;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 
 /**
  * 
@@ -39,7 +39,7 @@ public class SolrExceptionTest extends LuceneTestCase {
       // set a 1ms timeout to let the connection fail faster.
       HttpClient httpClient = HttpClientUtil.createClient(null);
       HttpClientUtil.setConnectionTimeout(httpClient,  1);
-      SolrServer client = new HttpSolrServer("http://[ff01::114]:11235/solr/", httpClient);
+      SolrClient client = new HttpSolrClient("http://[ff01::114]:11235/solr/", httpClient);
       SolrQuery query = new SolrQuery("test123");
       client.query(query);
       client.shutdown();
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrSchemalessExampleTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrSchemalessExampleTest.java
index 6e17147..49879e7 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/SolrSchemalessExampleTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/SolrSchemalessExampleTest.java
@@ -24,7 +24,7 @@ import org.apache.http.client.methods.HttpPost;
 import org.apache.http.entity.InputStreamEntity;
 import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -33,8 +33,6 @@ import org.slf4j.LoggerFactory;
 
 import java.io.ByteArrayInputStream;
 import java.io.File;
-import java.io.FileOutputStream;
-import java.io.FileWriter;
 import java.io.OutputStreamWriter;
 import java.util.Properties;
 
@@ -68,41 +66,41 @@ public class SolrSchemalessExampleTest extends SolrExampleTestsBase {
   }
   @Test
   public void testArbitraryJsonIndexing() throws Exception  {
-    HttpSolrServer server = (HttpSolrServer) getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got in
 
     // two docs, one with uniqueKey, another without it
     String json = "{\"id\":\"abc1\", \"name\": \"name1\"} {\"name\" : \"name2\"}";
-    HttpClient httpClient = server.getHttpClient();
-    HttpPost post = new HttpPost(server.getBaseURL() + "/update/json/docs");
+    HttpClient httpClient = client.getHttpClient();
+    HttpPost post = new HttpPost(client.getBaseURL() + "/update/json/docs");
     post.setHeader("Content-Type", "application/json");
     post.setEntity(new InputStreamEntity(new ByteArrayInputStream(json.getBytes("UTF-8")), -1));
     HttpResponse response = httpClient.execute(post);
     assertEquals(200, response.getStatusLine().getStatusCode());
-    server.commit();
+    client.commit();
     assertNumFound("*:*", 2);
   }
 
 
   @Override
-  public SolrServer createNewSolrServer() {
+  public SolrClient createNewSolrClient() {
     try {
       // setup the server...
       String url = jetty.getBaseUrl().toString() + "/collection1";
-      HttpSolrServer s = new HttpSolrServer(url);
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      s.setUseMultiPartPost(random().nextBoolean());
+      HttpSolrClient client = new HttpSolrClient(url);
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      client.setUseMultiPartPost(random().nextBoolean());
       
       if (random().nextBoolean()) {
-        s.setParser(new BinaryResponseParser());
-        s.setRequestWriter(new BinaryRequestWriter());
+        client.setParser(new BinaryResponseParser());
+        client.setRequestWriter(new BinaryRequestWriter());
       }
       
-      return s;
+      return client;
     } catch (Exception ex) {
       throw new RuntimeException(ex);
     }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java b/solr/solrj/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
index f89f3f0..3b9d0b6 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/TestBatchUpdate.java
@@ -20,11 +20,10 @@ import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.beans.Field;
 import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.RequestWriter;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -50,28 +49,28 @@ public class TestBatchUpdate extends SolrJettyTestBase {
 
   @Test
   public void testWithXml() throws Exception {
-    HttpSolrServer httpSolrServer = (HttpSolrServer) getSolrServer();
-    httpSolrServer.setRequestWriter(new RequestWriter());
-    httpSolrServer.deleteByQuery( "*:*" ); // delete everything!
-    doIt(httpSolrServer);
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    client.setRequestWriter(new RequestWriter());
+    client.deleteByQuery("*:*"); // delete everything!
+    doIt(client);
   }
 
   @Test
   public void testWithBinary()throws Exception{
-    HttpSolrServer httpSolrServer = (HttpSolrServer) getSolrServer();
-    httpSolrServer.setRequestWriter(new BinaryRequestWriter());
-    httpSolrServer.deleteByQuery( "*:*" ); // delete everything!
-    doIt(httpSolrServer);
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    client.setRequestWriter(new BinaryRequestWriter());
+    client.deleteByQuery("*:*"); // delete everything!
+    doIt(client);
   }
 
   @Test
   public void testWithBinaryBean()throws Exception{
-    HttpSolrServer httpSolrServer = (HttpSolrServer) getSolrServer();
-    httpSolrServer.setRequestWriter(new BinaryRequestWriter());
-    httpSolrServer.deleteByQuery( "*:*" ); // delete everything!
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    client.setRequestWriter(new BinaryRequestWriter());
+    client.deleteByQuery("*:*"); // delete everything!
     final int[] counter = new int[1];
     counter[0] = 0;
-    httpSolrServer.addBeans(new Iterator<Bean>() {
+    client.addBeans(new Iterator<Bean>() {
 
       @Override
       public boolean hasNext() {
@@ -91,9 +90,9 @@ public class TestBatchUpdate extends SolrJettyTestBase {
         //do nothing
       }
     });
-    httpSolrServer.commit();
+    client.commit();
     SolrQuery query = new SolrQuery("*:*");
-    QueryResponse response = httpSolrServer.query(query);
+    QueryResponse response = client.query(query);
     assertEquals(0, response.getStatus());
     assertEquals(numdocs, response.getResults().getNumFound());
   }
@@ -105,10 +104,10 @@ public class TestBatchUpdate extends SolrJettyTestBase {
     String cat;
   }
        
-  private void doIt(HttpSolrServer httpSolrServer) throws SolrServerException, IOException {
+  private void doIt(HttpSolrClient client) throws SolrServerException, IOException {
     final int[] counter = new int[1];
     counter[0] = 0;
-    httpSolrServer.add(new Iterator<SolrInputDocument>() {
+    client.add(new Iterator<SolrInputDocument>() {
 
       @Override
       public boolean hasNext() {
@@ -129,9 +128,9 @@ public class TestBatchUpdate extends SolrJettyTestBase {
 
       }
     });
-    httpSolrServer.commit();
+    client.commit();
     SolrQuery query = new SolrQuery("*:*");
-    QueryResponse response = httpSolrServer.query(query);
+    QueryResponse response = client.query(query);
     assertEquals(0, response.getStatus());
     assertEquals(numdocs, response.getResults().getNumFound());
   }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrClient.java b/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrClient.java
new file mode 100644
index 0000000..dd538b9
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrClient.java
@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj;
+
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;
+import junit.framework.Assert;
+import org.apache.commons.io.FileUtils;
+import org.apache.http.client.HttpClient;
+import org.apache.lucene.util.IOUtils;
+import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.lucene.util.QuickPatchThreadsFilter;
+import org.apache.solr.SolrIgnoredThreadsFilter;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.embedded.JettySolrRunner;
+import org.apache.solr.client.solrj.impl.HttpClientUtil;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.impl.LBHttpSolrClient;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.client.solrj.response.SolrResponseBase;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * Test for LBHttpSolrClient
+ *
+ * @since solr 1.4
+ */
+@Slow
+@ThreadLeakFilters(defaultFilters = true, filters = {
+    SolrIgnoredThreadsFilter.class,
+    QuickPatchThreadsFilter.class
+})
+public class TestLBHttpSolrClient extends SolrTestCaseJ4 {
+
+  private static final Logger log = LoggerFactory.getLogger(TestLBHttpSolrClient.class);
+
+  SolrInstance[] solr = new SolrInstance[3];
+  HttpClient httpClient;
+
+  // TODO: fix this test to not require FSDirectory
+  static String savedFactory;
+
+  @BeforeClass
+  public static void beforeClass() {
+    savedFactory = System.getProperty("solr.DirectoryFactory");
+    System.setProperty("solr.directoryFactory", "org.apache.solr.core.MockFSDirectoryFactory");
+    System.setProperty("tests.shardhandler.randomSeed", Long.toString(random().nextLong()));
+  }
+
+  @AfterClass
+  public static void afterClass() {
+    if (savedFactory == null) {
+      System.clearProperty("solr.directoryFactory");
+    } else {
+      System.setProperty("solr.directoryFactory", savedFactory);
+    }
+    System.clearProperty("tests.shardhandler.randomSeed");
+  }
+  
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    httpClient = HttpClientUtil.createClient(null);
+    HttpClientUtil.setConnectionTimeout(httpClient,  1000);
+    for (int i = 0; i < solr.length; i++) {
+      solr[i] = new SolrInstance("solr/collection1" + i, createTempDir("instance-" + i).toFile(), 0);
+      solr[i].setUp();
+      solr[i].startJetty();
+      addDocs(solr[i]);
+    }
+  }
+
+  private void addDocs(SolrInstance solrInstance) throws IOException, SolrServerException {
+    List<SolrInputDocument> docs = new ArrayList<>();
+    for (int i = 0; i < 10; i++) {
+      SolrInputDocument doc = new SolrInputDocument();
+      doc.addField("id", i);
+      doc.addField("name", solrInstance.name);
+      docs.add(doc);
+    }
+    HttpSolrClient client = new HttpSolrClient(solrInstance.getUrl(), httpClient);
+    SolrResponseBase resp;
+    try {
+      resp = client.add(docs);
+      assertEquals(0, resp.getStatus());
+      resp = client.commit();
+    } finally {
+      client.shutdown();
+    }
+    assertEquals(0, resp.getStatus());
+  }
+
+  @Override
+  public void tearDown() throws Exception {
+    for (SolrInstance aSolr : solr) {
+      if (aSolr != null)  {
+        aSolr.tearDown();
+      }
+    }
+    httpClient.getConnectionManager().shutdown();
+    super.tearDown();
+  }
+
+  public void testSimple() throws Exception {
+    String[] s = new String[solr.length];
+    for (int i = 0; i < solr.length; i++) {
+      s[i] = solr[i].getUrl();
+    }
+    LBHttpSolrClient client = new LBHttpSolrClient(httpClient, s);
+    client.setAliveCheckInterval(500);
+    SolrQuery solrQuery = new SolrQuery("*:*");
+    Set<String> names = new HashSet<>();
+    QueryResponse resp = null;
+    for (String value : s) {
+      resp = client.query(solrQuery);
+      assertEquals(10, resp.getResults().getNumFound());
+      names.add(resp.getResults().get(0).getFieldValue("name").toString());
+    }
+    assertEquals(3, names.size());
+
+    // Kill a server and test again
+    solr[1].jetty.stop();
+    solr[1].jetty = null;
+    names.clear();
+    for (String value : s) {
+      resp = client.query(solrQuery);
+      assertEquals(10, resp.getResults().getNumFound());
+      names.add(resp.getResults().get(0).getFieldValue("name").toString());
+    }
+    assertEquals(2, names.size());
+    assertFalse(names.contains("solr1"));
+
+    // Start the killed server once again
+    solr[1].startJetty();
+    // Wait for the alive check to complete
+    Thread.sleep(1200);
+    names.clear();
+    for (String value : s) {
+      resp = client.query(solrQuery);
+      assertEquals(10, resp.getResults().getNumFound());
+      names.add(resp.getResults().get(0).getFieldValue("name").toString());
+    }
+    assertEquals(3, names.size());
+  }
+
+  public void testTwoServers() throws Exception {
+    LBHttpSolrClient client = new LBHttpSolrClient(httpClient, solr[0].getUrl(), solr[1].getUrl());
+    client.setAliveCheckInterval(500);
+    SolrQuery solrQuery = new SolrQuery("*:*");
+    QueryResponse resp = null;
+    solr[0].jetty.stop();
+    solr[0].jetty = null;
+    resp = client.query(solrQuery);
+    String name = resp.getResults().get(0).getFieldValue("name").toString();
+    Assert.assertEquals("solr/collection11", name);
+    resp = client.query(solrQuery);
+    name = resp.getResults().get(0).getFieldValue("name").toString();
+    Assert.assertEquals("solr/collection11", name);
+    solr[1].jetty.stop();
+    solr[1].jetty = null;
+    solr[0].startJetty();
+    Thread.sleep(1200);
+    try {
+      resp = client.query(solrQuery);
+    } catch(SolrServerException e) {
+      // try again after a pause in case the error is lack of time to start server
+      Thread.sleep(3000);
+      resp = client.query(solrQuery);
+    }
+    name = resp.getResults().get(0).getFieldValue("name").toString();
+    Assert.assertEquals("solr/collection10", name);
+  }
+
+  public void testReliability() throws Exception {
+    String[] s = new String[solr.length];
+    for (int i = 0; i < solr.length; i++) {
+      s[i] = solr[i].getUrl();
+    }
+    ModifiableSolrParams params = new ModifiableSolrParams();
+    params.set(HttpClientUtil.PROP_CONNECTION_TIMEOUT, 250);
+    params.set(HttpClientUtil.PROP_SO_TIMEOUT, 250);
+    HttpClient myHttpClient = HttpClientUtil.createClient(params);
+
+    LBHttpSolrClient client = new LBHttpSolrClient(myHttpClient, s);
+    client.setAliveCheckInterval(500);
+
+    // Kill a server and test again
+    solr[1].jetty.stop();
+    solr[1].jetty = null;
+
+    // query the servers
+    for (String value : s)
+      client.query(new SolrQuery("*:*"));
+
+    // Start the killed server once again
+    solr[1].startJetty();
+    // Wait for the alive check to complete
+    waitForServer(30000, client, 3, "solr1");
+  }
+  
+  // wait maximum ms for serverName to come back up
+  private void waitForServer(int maximum, LBHttpSolrClient client, int nServers, String serverName) throws Exception {
+    long endTime = System.currentTimeMillis() + maximum;
+    while (System.currentTimeMillis() < endTime) {
+      QueryResponse resp;
+      try {
+        resp = client.query(new SolrQuery("*:*"));
+      } catch (Exception e) {
+        log.warn("", e);
+        continue;
+      }
+      String name = resp.getResults().get(0).getFieldValue("name").toString();
+      if (name.equals(serverName))
+        return;
+    }
+  }
+  
+  private class SolrInstance {
+    String name;
+    File homeDir;
+    File dataDir;
+    File confDir;
+    int port;
+    JettySolrRunner jetty;
+
+    public SolrInstance(String name, File homeDir, int port) {
+      this.name = name;
+      this.homeDir = homeDir;
+      this.port = port;
+
+      dataDir = new File(homeDir + "/collection1", "data");
+      confDir = new File(homeDir + "/collection1", "conf");
+    }
+
+    public String getHomeDir() {
+      return homeDir.toString();
+    }
+
+    public String getUrl() {
+      return buildUrl(port, "/solr");
+    }
+
+    public String getSchemaFile() {
+      return "solrj/solr/collection1/conf/schema-replication1.xml";
+    }
+
+    public String getConfDir() {
+      return confDir.toString();
+    }
+
+    public String getDataDir() {
+      return dataDir.toString();
+    }
+
+    public String getSolrConfigFile() {
+      return "solrj/solr/collection1/conf/solrconfig-slave1.xml";
+    }
+
+    public String getSolrXmlFile() {
+      return "solrj/solr/solr.xml";
+    }
+
+
+    public void setUp() throws Exception {
+      homeDir.mkdirs();
+      dataDir.mkdirs();
+      confDir.mkdirs();
+
+      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSolrXmlFile()), new File(homeDir, "solr.xml"));
+
+      File f = new File(confDir, "solrconfig.xml");
+      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSolrConfigFile()), f);
+      f = new File(confDir, "schema.xml");
+      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSchemaFile()), f);
+    }
+
+    public void tearDown() throws Exception {
+      if (jetty != null) jetty.stop();
+      IOUtils.rm(homeDir.toPath());
+    }
+
+    public void startJetty() throws Exception {
+      jetty = new JettySolrRunner(getHomeDir(), "/solr", port, "bad_solrconfig.xml", null, true, null, sslConfig);
+      jetty.setDataDir(getDataDir());
+      jetty.start();
+      int newPort = jetty.getLocalPort();
+      if (port != 0 && newPort != port) {
+        fail("TESTING FAILURE: could not grab requested port.");
+      }
+      this.port = newPort;
+//      System.out.println("waiting.........");
+//      Thread.sleep(5000);
+    }
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java b/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
deleted file mode 100644
index 559b1f5..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/TestLBHttpSolrServer.java
+++ /dev/null
@@ -1,325 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.client.solrj;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import junit.framework.Assert;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.http.client.HttpClient;
-import org.apache.lucene.util.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.lucene.util.QuickPatchThreadsFilter;
-import org.apache.lucene.util.TestUtil;
-import org.apache.solr.SolrIgnoredThreadsFilter;
-import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpClientUtil;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
-import org.apache.solr.client.solrj.impl.LBHttpSolrServer;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.client.solrj.response.SolrResponseBase;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.util.AbstractSolrTestCase;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;
-
-/**
- * Test for LBHttpSolrServer
- *
- * @since solr 1.4
- */
-@Slow
-@ThreadLeakFilters(defaultFilters = true, filters = {
-    SolrIgnoredThreadsFilter.class,
-    QuickPatchThreadsFilter.class
-})
-public class TestLBHttpSolrServer extends SolrTestCaseJ4 {
-  private static final Logger log = LoggerFactory
-      .getLogger(TestLBHttpSolrServer.class);
-  SolrInstance[] solr = new SolrInstance[3];
-  HttpClient httpClient;
-
-  // TODO: fix this test to not require FSDirectory
-  static String savedFactory;
-
-  @BeforeClass
-  public static void beforeClass() {
-    savedFactory = System.getProperty("solr.DirectoryFactory");
-    System.setProperty("solr.directoryFactory", "org.apache.solr.core.MockFSDirectoryFactory");
-    System.setProperty("tests.shardhandler.randomSeed", Long.toString(random().nextLong()));
-  }
-
-  @AfterClass
-  public static void afterClass() {
-    if (savedFactory == null) {
-      System.clearProperty("solr.directoryFactory");
-    } else {
-      System.setProperty("solr.directoryFactory", savedFactory);
-    }
-    System.clearProperty("tests.shardhandler.randomSeed");
-  }
-  
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    httpClient = HttpClientUtil.createClient(null);
-    HttpClientUtil.setConnectionTimeout(httpClient,  1000);
-    for (int i = 0; i < solr.length; i++) {
-      solr[i] = new SolrInstance("solr/collection1" + i, createTempDir("instance-" + i).toFile(), 0);
-      solr[i].setUp();
-      solr[i].startJetty();
-      addDocs(solr[i]);
-    }
-  }
-
-  private void addDocs(SolrInstance solrInstance) throws IOException, SolrServerException {
-    List<SolrInputDocument> docs = new ArrayList<>();
-    for (int i = 0; i < 10; i++) {
-      SolrInputDocument doc = new SolrInputDocument();
-      doc.addField("id", i);
-      doc.addField("name", solrInstance.name);
-      docs.add(doc);
-    }
-    HttpSolrServer solrServer = new HttpSolrServer(solrInstance.getUrl(), httpClient);
-    SolrResponseBase resp;
-    try {
-      resp = solrServer.add(docs);
-      assertEquals(0, resp.getStatus());
-      resp = solrServer.commit();
-    } finally {
-      solrServer.shutdown();
-    }
-    assertEquals(0, resp.getStatus());
-  }
-
-  @Override
-  public void tearDown() throws Exception {
-    for (SolrInstance aSolr : solr) {
-      if (aSolr != null)  {
-        aSolr.tearDown();
-      }
-    }
-    httpClient.getConnectionManager().shutdown();
-    super.tearDown();
-  }
-
-  public void testSimple() throws Exception {
-    String[] s = new String[solr.length];
-    for (int i = 0; i < solr.length; i++) {
-      s[i] = solr[i].getUrl();
-    }
-    LBHttpSolrServer lbHttpSolrServer = new LBHttpSolrServer(httpClient, s);
-    lbHttpSolrServer.setAliveCheckInterval(500);
-    SolrQuery solrQuery = new SolrQuery("*:*");
-    Set<String> names = new HashSet<>();
-    QueryResponse resp = null;
-    for (String value : s) {
-      resp = lbHttpSolrServer.query(solrQuery);
-      assertEquals(10, resp.getResults().getNumFound());
-      names.add(resp.getResults().get(0).getFieldValue("name").toString());
-    }
-    assertEquals(3, names.size());
-
-    // Kill a server and test again
-    solr[1].jetty.stop();
-    solr[1].jetty = null;
-    names.clear();
-    for (String value : s) {
-      resp = lbHttpSolrServer.query(solrQuery);
-      assertEquals(10, resp.getResults().getNumFound());
-      names.add(resp.getResults().get(0).getFieldValue("name").toString());
-    }
-    assertEquals(2, names.size());
-    assertFalse(names.contains("solr1"));
-
-    // Start the killed server once again
-    solr[1].startJetty();
-    // Wait for the alive check to complete
-    Thread.sleep(1200);
-    names.clear();
-    for (String value : s) {
-      resp = lbHttpSolrServer.query(solrQuery);
-      assertEquals(10, resp.getResults().getNumFound());
-      names.add(resp.getResults().get(0).getFieldValue("name").toString());
-    }
-    assertEquals(3, names.size());
-  }
-
-  public void testTwoServers() throws Exception {
-    LBHttpSolrServer lbHttpSolrServer = new LBHttpSolrServer(httpClient, solr[0].getUrl(), solr[1].getUrl());
-    lbHttpSolrServer.setAliveCheckInterval(500);
-    SolrQuery solrQuery = new SolrQuery("*:*");
-    QueryResponse resp = null;
-    solr[0].jetty.stop();
-    solr[0].jetty = null;
-    resp = lbHttpSolrServer.query(solrQuery);
-    String name = resp.getResults().get(0).getFieldValue("name").toString();
-    Assert.assertEquals("solr/collection11", name);
-    resp = lbHttpSolrServer.query(solrQuery);
-    name = resp.getResults().get(0).getFieldValue("name").toString();
-    Assert.assertEquals("solr/collection11", name);
-    solr[1].jetty.stop();
-    solr[1].jetty = null;
-    solr[0].startJetty();
-    Thread.sleep(1200);
-    try {
-      resp = lbHttpSolrServer.query(solrQuery);
-    } catch(SolrServerException e) {
-      // try again after a pause in case the error is lack of time to start server
-      Thread.sleep(3000);
-      resp = lbHttpSolrServer.query(solrQuery);
-    }
-    name = resp.getResults().get(0).getFieldValue("name").toString();
-    Assert.assertEquals("solr/collection10", name);
-  }
-
-  public void testReliability() throws Exception {
-    String[] s = new String[solr.length];
-    for (int i = 0; i < solr.length; i++) {
-      s[i] = solr[i].getUrl();
-    }
-    ModifiableSolrParams params = new ModifiableSolrParams();
-    params.set(HttpClientUtil.PROP_CONNECTION_TIMEOUT, 250);
-    params.set(HttpClientUtil.PROP_SO_TIMEOUT, 250);
-    HttpClient myHttpClient = HttpClientUtil.createClient(params);
-
-    LBHttpSolrServer lbHttpSolrServer = new LBHttpSolrServer(myHttpClient, s);
-    lbHttpSolrServer.setAliveCheckInterval(500);
-
-    // Kill a server and test again
-    solr[1].jetty.stop();
-    solr[1].jetty = null;
-
-    // query the servers
-    for (String value : s)
-      lbHttpSolrServer.query(new SolrQuery("*:*"));
-
-    // Start the killed server once again
-    solr[1].startJetty();
-    // Wait for the alive check to complete
-    waitForServer(30000, lbHttpSolrServer, 3, "solr1");
-  }
-  
-  // wait maximum ms for serverName to come back up
-  private void waitForServer(int maximum, LBHttpSolrServer server, int nServers, String serverName) throws Exception {
-    long endTime = System.currentTimeMillis() + maximum;
-    while (System.currentTimeMillis() < endTime) {
-      QueryResponse resp;
-      try {
-        resp = server.query(new SolrQuery("*:*"));
-      } catch (Exception e) {
-        log.warn("", e);
-        continue;
-      }
-      String name = resp.getResults().get(0).getFieldValue("name").toString();
-      if (name.equals(serverName))
-        return;
-    }
-  }
-  
-  private class SolrInstance {
-    String name;
-    File homeDir;
-    File dataDir;
-    File confDir;
-    int port;
-    JettySolrRunner jetty;
-
-    public SolrInstance(String name, File homeDir, int port) {
-      this.name = name;
-      this.homeDir = homeDir;
-      this.port = port;
-
-      dataDir = new File(homeDir + "/collection1", "data");
-      confDir = new File(homeDir + "/collection1", "conf");
-    }
-
-    public String getHomeDir() {
-      return homeDir.toString();
-    }
-
-    public String getUrl() {
-      return buildUrl(port, "/solr");
-    }
-
-    public String getSchemaFile() {
-      return "solrj/solr/collection1/conf/schema-replication1.xml";
-    }
-
-    public String getConfDir() {
-      return confDir.toString();
-    }
-
-    public String getDataDir() {
-      return dataDir.toString();
-    }
-
-    public String getSolrConfigFile() {
-      return "solrj/solr/collection1/conf/solrconfig-slave1.xml";
-    }
-
-    public String getSolrXmlFile() {
-      return "solrj/solr/solr.xml";
-    }
-
-
-    public void setUp() throws Exception {
-      homeDir.mkdirs();
-      dataDir.mkdirs();
-      confDir.mkdirs();
-
-      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSolrXmlFile()), new File(homeDir, "solr.xml"));
-
-      File f = new File(confDir, "solrconfig.xml");
-      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSolrConfigFile()), f);
-      f = new File(confDir, "schema.xml");
-      FileUtils.copyFile(SolrTestCaseJ4.getFile(getSchemaFile()), f);
-    }
-
-    public void tearDown() throws Exception {
-      if (jetty != null) jetty.stop();
-      IOUtils.rm(homeDir.toPath());
-    }
-
-    public void startJetty() throws Exception {
-      jetty = new JettySolrRunner(getHomeDir(), "/solr", port, "bad_solrconfig.xml", null, true, null, sslConfig);
-      jetty.setDataDir(getDataDir());
-      jetty.start();
-      int newPort = jetty.getLocalPort();
-      if (port != 0 && newPort != port) {
-        fail("TESTING FAILURE: could not grab requested port.");
-      }
-      this.port = newPort;
-//      System.out.println("waiting.........");
-//      Thread.sleep(5000);
-    }
-  }
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/AbstractEmbeddedSolrServerTestCase.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/AbstractEmbeddedSolrServerTestCase.java
index b55c023..c76728c 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/AbstractEmbeddedSolrServerTestCase.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/AbstractEmbeddedSolrServerTestCase.java
@@ -20,7 +20,7 @@ package org.apache.solr.client.solrj.embedded;
 import java.io.File;
 
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.core.CoreContainer;
 import org.junit.After;
 import org.junit.Before;
@@ -79,15 +79,15 @@ public abstract class AbstractEmbeddedSolrServerTestCase extends SolrTestCaseJ4
 
   }
 
-  protected SolrServer getSolrCore0() {
+  protected SolrClient getSolrCore0() {
     return getSolrCore("core0");
   }
 
-  protected SolrServer getSolrCore1() {
+  protected SolrClient getSolrCore1() {
     return getSolrCore("core1");
   }
 
-  protected SolrServer getSolrCore(String name) {
+  protected SolrClient getSolrCore(String name) {
     return new EmbeddedSolrServer(cores, name);
   }
 
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/MergeIndexesEmbeddedTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/MergeIndexesEmbeddedTest.java
index 8b1fbf4..026bbec 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/MergeIndexesEmbeddedTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/MergeIndexesEmbeddedTest.java
@@ -18,7 +18,7 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.client.solrj.MergeIndexesExampleTestBase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.core.SolrCore;
 
 /**
@@ -37,22 +37,22 @@ public class MergeIndexesEmbeddedTest extends MergeIndexesExampleTestBase {
   }
 
   @Override
-  protected SolrServer getSolrCore0() {
+  protected SolrClient getSolrCore0() {
     return new EmbeddedSolrServer(cores, "core0");
   }
 
   @Override
-  protected SolrServer getSolrCore1() {
+  protected SolrClient getSolrCore1() {
     return new EmbeddedSolrServer(cores, "core1");
   }
 
   @Override
-  protected SolrServer getSolrCore(String name) {
+  protected SolrClient getSolrCore(String name) {
     return new EmbeddedSolrServer(cores, name);
   }
 
   @Override
-  protected SolrServer getSolrAdmin() {
+  protected SolrClient getSolrAdmin() {
     return new EmbeddedSolrServer(cores, "core0");
   }
 
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
index 3fd1da1..b7dbfd4 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleJettyTest.java
@@ -17,12 +17,6 @@
 
 package org.apache.solr.client.solrj.embedded;
 
-import java.io.ByteArrayInputStream;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.util.Map;
-
-import org.apache.http.HttpEntity;
 import org.apache.http.HttpResponse;
 import org.apache.http.client.HttpClient;
 import org.apache.http.client.methods.HttpPost;
@@ -30,15 +24,17 @@ import org.apache.http.entity.InputStreamEntity;
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.solr.client.solrj.SolrExampleTests;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.common.SolrDocument;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.Assert;
 import org.junit.BeforeClass;
 import org.junit.Test;
 import org.noggit.ObjectBuilder;
 
+import java.io.ByteArrayInputStream;
+import java.util.Map;
+
 /**
  * TODO? perhaps use:
  *  http://docs.codehaus.org/display/JETTY/ServletTester
@@ -59,8 +55,8 @@ public class SolrExampleJettyTest extends SolrExampleTests {
     try {
       // setup the server...
       String url = "http" + (isSSLMode() ? "s" : "") +  "://127.0.0.1/?core=xxx";
-      HttpSolrServer s = new HttpSolrServer( url );
-      Assert.fail("HttpSolrServer should not allow a path with a parameter: "+s.getBaseURL() );
+      HttpSolrClient client = new HttpSolrClient(url);
+      Assert.fail("HttpSolrServer should not allow a path with a parameter: " + client.getBaseURL());
     }
     catch( Exception ex ) {
       // expected
@@ -69,21 +65,21 @@ public class SolrExampleJettyTest extends SolrExampleTests {
 
   @Test
   public void testArbitraryJsonIndexing() throws Exception  {
-    HttpSolrServer server = (HttpSolrServer) getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit();
+    HttpSolrClient client = (HttpSolrClient) getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit();
     assertNumFound("*:*", 0); // make sure it got in
 
     // two docs, one with uniqueKey, another without it
     String json = "{\"id\":\"abc1\", \"name\": \"name1\"} {\"name\" : \"name2\"}";
-    HttpClient httpClient = server.getHttpClient();
-    HttpPost post = new HttpPost(server.getBaseURL() + "/update/json/docs");
+    HttpClient httpClient = client.getHttpClient();
+    HttpPost post = new HttpPost(client.getBaseURL() + "/update/json/docs");
     post.setHeader("Content-Type", "application/json");
     post.setEntity(new InputStreamEntity(new ByteArrayInputStream(json.getBytes("UTF-8")), -1));
     HttpResponse response = httpClient.execute(post);
     assertEquals(200, response.getStatusLine().getStatusCode());
-    server.commit();
-    QueryResponse rsp = getSolrServer().query(new SolrQuery("*:*"));
+    client.commit();
+    QueryResponse rsp = getSolrClient().query(new SolrQuery("*:*"));
     assertEquals(2,rsp.getResults().getNumFound());
 
     SolrDocument doc = rsp.getResults().get(0);
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingBinaryTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingBinaryTest.java
index 8e58811..97e090d 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingBinaryTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingBinaryTest.java
@@ -19,20 +19,20 @@ package org.apache.solr.client.solrj.embedded;
 
 import org.apache.solr.SolrTestCaseJ4.SuppressSSL;
 import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.impl.BinaryRequestWriter;
 import org.apache.solr.client.solrj.impl.BinaryResponseParser;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
 
 @Slow
 @SuppressSSL(bugUrl = "https://issues.apache.org/jira/browse/SOLR-5776")
 public class SolrExampleStreamingBinaryTest extends SolrExampleStreamingTest {
 
   @Override
-  public SolrServer createNewSolrServer() {
-    ConcurrentUpdateSolrServer s = (ConcurrentUpdateSolrServer)super.createNewSolrServer();
-    s.setParser(new BinaryResponseParser());
-    s.setRequestWriter(new BinaryRequestWriter());
-    return s;
+  public SolrClient createNewSolrClient() {
+    ConcurrentUpdateSolrClient client = (ConcurrentUpdateSolrClient)super.createNewSolrClient();
+    client.setParser(new BinaryResponseParser());
+    client.setRequestWriter(new BinaryRequestWriter());
+    return client;
   }
 }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
index 14aa88d..efe07e3 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/SolrExampleStreamingTest.java
@@ -18,22 +18,19 @@
 package org.apache.solr.client.solrj.embedded;
 
 import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrExampleTests;
-import org.apache.solr.client.solrj.SolrServer;
-import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrServer;
+import org.apache.solr.client.solrj.impl.ConcurrentUpdateSolrClient;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.request.RequestWriter;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.util.ExternalPaths;
+import org.junit.BeforeClass;
 
-import java.util.EnumSet;
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.EnumSet;
 import java.util.List;
-import java.util.ArrayList;
-
-import org.junit.BeforeClass;
-import org.junit.After;
 
 /**
  * 
@@ -51,13 +48,13 @@ public class SolrExampleStreamingTest extends SolrExampleTests {
   }
 
   @Override
-  public SolrServer createNewSolrServer()
+  public SolrClient createNewSolrClient()
   {
     try {
       // setup the server...
       String url = jetty.getBaseUrl().toString() + "/collection1";
       // smaller queue size hits locks more often
-      ConcurrentUpdateSolrServer s = new ConcurrentUpdateSolrServer( url, 2, 5 ) {
+      ConcurrentUpdateSolrClient concurrentClient = new ConcurrentUpdateSolrClient( url, 2, 5 ) {
         
         public Throwable lastError = null;
         @Override
@@ -66,9 +63,9 @@ public class SolrExampleStreamingTest extends SolrExampleTests {
         }
       };
 
-      s.setParser(new XMLResponseParser());
-      s.setRequestWriter(new RequestWriter());
-      return s;
+      concurrentClient.setParser(new XMLResponseParser());
+      concurrentClient.setRequestWriter(new RequestWriter());
+      return concurrentClient;
     }
     
     catch( Exception ex ) {
@@ -79,7 +76,7 @@ public class SolrExampleStreamingTest extends SolrExampleTests {
   public void testWaitOptions() throws Exception {
     // SOLR-3903
     final List<Throwable> failures = new ArrayList<>();
-    ConcurrentUpdateSolrServer s = new ConcurrentUpdateSolrServer
+    ConcurrentUpdateSolrClient concurrentClient = new ConcurrentUpdateSolrClient
       (jetty.getBaseUrl().toString() + "/collection1", 2, 2) {
         @Override
         public void handleError(Throwable ex) {
@@ -96,13 +93,13 @@ public class SolrExampleStreamingTest extends SolrExampleTests {
           document.addField("id", docId++ );
           updateRequest.add(document);
           updateRequest.setAction(action, waitSearch, waitFlush);
-          s.request(updateRequest);
+          concurrentClient.request(updateRequest);
         }
       }
     }
-    s.commit();
-    s.blockUntilFinished();
-    s.shutdown();
+    concurrentClient.commit();
+    concurrentClient.blockUntilFinished();
+    concurrentClient.shutdown();
 
     if (0 != failures.size()) {
       assertEquals(failures.size() + " Unexpected Exception, starting with...", 
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
index acdd856..684dec8 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/embedded/TestSolrProperties.java
@@ -20,7 +20,7 @@ package org.apache.solr.client.solrj.embedded;
 import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
 import org.apache.solr.SolrTestCaseJ4;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.request.AbstractUpdateRequest.ACTION;
 import org.apache.solr.client.solrj.request.CoreAdminRequest;
 import org.apache.solr.client.solrj.request.QueryRequest;
@@ -56,11 +56,11 @@ public class TestSolrProperties extends AbstractEmbeddedSolrServerTestCase {
     return new File(SOLR_HOME, SOLR_XML);
   }
 
-  protected SolrServer getSolrAdmin() {
+  protected SolrClient getSolrAdmin() {
     return new EmbeddedSolrServer(cores, "core0");
   }
   
-  protected SolrServer getRenamedSolrAdmin() {
+  protected SolrClient getRenamedSolrAdmin() {
     return new EmbeddedSolrServer(cores, "renamed_core");
   }
 
@@ -130,7 +130,7 @@ public class TestSolrProperties extends AbstractEmbeddedSolrServerTestCase {
 
     // Now test reloading it should have a newer open time
     String name = "core0";
-    SolrServer coreadmin = getSolrAdmin();
+    SolrClient coreadmin = getSolrAdmin();
     CoreAdminResponse mcr = CoreAdminRequest.getStatus(name, coreadmin);
     long before = mcr.getStartTime(name).getTime();
     CoreAdminRequest.reloadCore(name, coreadmin);
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrClientTest.java
new file mode 100644
index 0000000..1a5aed3
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrClientTest.java
@@ -0,0 +1,651 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.http.Header;
+import org.apache.http.HttpEntity;
+import org.apache.http.HttpResponse;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.solr.SolrJettyTestBase;
+import org.apache.solr.client.solrj.SolrQuery;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.SolrRequest.METHOD;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrException.ErrorCode;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.solr.util.SSLTestConfig;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import javax.servlet.ServletException;
+import javax.servlet.http.HttpServlet;
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.Socket;
+import java.util.Enumeration;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.Map;
+import java.util.Set;
+import java.util.TreeSet;
+
+public class BasicHttpSolrClientTest extends SolrJettyTestBase {
+  
+  public static class RedirectServlet extends HttpServlet {
+    @Override
+    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      resp.sendRedirect("/solr/collection1/select?" + req.getQueryString());
+    }
+  }
+  
+  public static class SlowServlet extends HttpServlet {
+    @Override
+    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      try {
+        Thread.sleep(5000);
+      } catch (InterruptedException e) {}
+    }
+  }
+  
+  public static class DebugServlet extends HttpServlet {
+    public static void clear() {
+      lastMethod = null;
+      headers = null;
+      parameters = null;
+      errorCode = null;
+      queryString = null;
+    }
+    
+    public static Integer errorCode = null;
+    public static String lastMethod = null;
+    public static HashMap<String,String> headers = null;
+    public static Map<String,String[]> parameters = null;
+    public static String queryString = null;
+    
+    public static void setErrorCode(Integer code) {
+      errorCode = code;
+    }
+    
+
+    @Override
+    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      lastMethod = "get";
+      recordRequest(req, resp);
+    }
+    
+    private void setHeaders(HttpServletRequest req) {
+      Enumeration<String> headerNames = req.getHeaderNames();
+      headers = new HashMap<>();
+      while (headerNames.hasMoreElements()) {
+        final String name = headerNames.nextElement();
+        headers.put(name, req.getHeader(name));
+      }
+    }
+
+    private void setParameters(HttpServletRequest req) {
+      parameters = req.getParameterMap();
+    }
+
+    private void setQueryString(HttpServletRequest req) {
+      queryString = req.getQueryString();
+    }
+
+    @Override
+    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      lastMethod = "post";
+      recordRequest(req, resp);
+    }
+
+    @Override
+    protected void doPut(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      lastMethod = "put";
+      recordRequest(req, resp);
+    }
+    
+    private void recordRequest(HttpServletRequest req, HttpServletResponse resp) {
+      setHeaders(req);
+      setParameters(req);
+      setQueryString(req);
+      if (null != errorCode) {
+        try { 
+          resp.sendError(errorCode); 
+        } catch (IOException e) {
+          throw new RuntimeException("sendError IO fail in DebugServlet", e);
+        }
+      }
+    }
+  }
+  
+  @BeforeClass
+  public static void beforeTest() throws Exception {
+    createJetty(legacyExampleCollection1SolrHome(), null, null);
+    jetty.getDispatchFilter().getServletHandler()
+        .addServletWithMapping(RedirectServlet.class, "/redirect/*");
+    jetty.getDispatchFilter().getServletHandler()
+        .addServletWithMapping(SlowServlet.class, "/slow/*");
+    jetty.getDispatchFilter().getServletHandler()
+        .addServletWithMapping(DebugServlet.class, "/debug/*");
+  }
+  
+  @Test
+  public void testTimeout() throws Exception {
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() +
+                                               "/slow/foo");
+    SolrQuery q = new SolrQuery("*:*");
+    client.setSoTimeout(2000);
+    try {
+      QueryResponse response = client.query(q, METHOD.GET);
+      fail("No exception thrown.");
+    } catch (SolrServerException e) {
+      assertTrue(e.getMessage().contains("Timeout"));
+    }
+    client.shutdown();
+  }
+  
+  /**
+   * test that SolrExceptions thrown by HttpSolrClient can
+   * correctly encapsulate http status codes even when not on the list of
+   * ErrorCodes solr may return.
+   */
+  public void testSolrExceptionCodeNotFromSolr() throws IOException, SolrServerException {
+    final int status = 527;
+    assertEquals(status + " didn't generate an UNKNOWN error code, someone modified the list of valid ErrorCode's w/o changing this test to work a different way",
+                 ErrorCode.UNKNOWN, ErrorCode.getErrorCode(status));
+
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() +
+                                               "/debug/foo");
+    try {
+      DebugServlet.setErrorCode(status);
+      try {
+        SolrQuery q = new SolrQuery("foo");
+        client.query(q, METHOD.GET);
+        fail("Didn't get excepted exception from oversided request");
+      } catch (SolrException e) {
+        System.out.println(e);
+        assertEquals("Unexpected exception status code", status, e.code());
+      }
+    } finally {
+      client.shutdown();
+      DebugServlet.clear();
+    }
+  }
+
+  @Test
+  public void testQuery(){
+    DebugServlet.clear();
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/debug/foo");
+    SolrQuery q = new SolrQuery("foo");
+    q.setParam("a", "\u1234");
+    try {
+      client.query(q, METHOD.GET);
+    } catch (Throwable t) {}
+    
+    //default method
+    assertEquals("get", DebugServlet.lastMethod);
+    //agent
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    //default wt
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    //default version
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    //agent
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    //keepalive
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    //content-type
+    assertEquals(null, DebugServlet.headers.get("Content-Type"));
+    //param encoding
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+
+    //POST
+    DebugServlet.clear();
+    try {
+      client.query(q, METHOD.POST);
+    } catch (Throwable t) {}
+    assertEquals("post", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+
+    //PUT
+    DebugServlet.clear();
+    try {
+      client.query(q, METHOD.PUT);
+    } catch (Throwable t) {}
+    assertEquals("put", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+
+    //XML/GET
+    client.setParser(new XMLResponseParser());
+    DebugServlet.clear();
+    try {
+      client.query(q, METHOD.GET);
+    } catch (Throwable t) {}
+    assertEquals("get", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+
+    //XML/POST
+    client.setParser(new XMLResponseParser());
+    DebugServlet.clear();
+    try {
+      client.query(q, METHOD.POST);
+    } catch (Throwable t) {}
+    assertEquals("post", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+
+    client.setParser(new XMLResponseParser());
+    DebugServlet.clear();
+    try {
+      client.query(q, METHOD.PUT);
+    } catch (Throwable t) {}
+    assertEquals("put", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+    client.shutdown();
+  }
+
+  @Test
+  public void testDelete(){
+    DebugServlet.clear();
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/debug/foo");
+    try {
+      client.deleteById("id");
+    } catch (Throwable t) {}
+    
+    //default method
+    assertEquals("post", DebugServlet.lastMethod);
+    //agent
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    //default wt
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    //default version
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    //agent
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    //keepalive
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+
+    //XML
+    client.setParser(new XMLResponseParser());
+    try {
+      client.deleteByQuery("*:*");
+    } catch (Throwable t) {}
+    
+    assertEquals("post", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
+    client.shutdown();
+  }
+  
+  @Test
+  public void testUpdate(){
+    DebugServlet.clear();
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/debug/foo");
+    UpdateRequest req = new UpdateRequest();
+    req.add(new SolrInputDocument());
+    req.setParam("a", "\u1234");
+    try {
+      client.request(req);
+    } catch (Throwable t) {}
+    
+    //default method
+    assertEquals("post", DebugServlet.lastMethod);
+    //agent
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    //default wt
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    //default version
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    //content type
+    assertEquals("application/xml; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+    //parameter encoding
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+
+    //XML response
+    client.setParser(new XMLResponseParser());
+    try {
+      client.request(req);
+    } catch (Throwable t) {}
+    assertEquals("post", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals("application/xml; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    
+    //javabin request
+    client.setParser(new BinaryResponseParser());
+    client.setRequestWriter(new BinaryRequestWriter());
+    DebugServlet.clear();
+    try {
+      client.request(req);
+    } catch (Throwable t) {}
+    assertEquals("post", DebugServlet.lastMethod);
+    assertEquals("Solr[" + HttpSolrClient.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
+    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
+    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
+    assertEquals(client.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
+    assertEquals("application/javabin", DebugServlet.headers.get("Content-Type"));
+    assertEquals(1, DebugServlet.parameters.get("a").length);
+    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
+    client.shutdown();
+  }
+  
+  @Test
+  public void testRedirect() throws Exception {
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/redirect/foo");
+    SolrQuery q = new SolrQuery("*:*");
+    // default = false
+    try {
+      QueryResponse response = client.query(q);
+      fail("Should have thrown an exception.");
+    } catch (SolrServerException e) {
+      assertTrue(e.getMessage().contains("redirect"));
+    }
+    client.setFollowRedirects(true);
+    try {
+      QueryResponse response = client.query(q);
+    } catch (Throwable t) {
+      fail("Exception was thrown:" + t);
+    }
+    //And back again:
+    client.setFollowRedirects(false);
+    try {
+      QueryResponse response = client.query(q);
+      fail("Should have thrown an exception.");
+    } catch (SolrServerException e) {
+      assertTrue(e.getMessage().contains("redirect"));
+    }
+    client.shutdown();
+  }
+  
+  @Test
+  public void testCompression() throws Exception {
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/debug/foo");
+    SolrQuery q = new SolrQuery("*:*");
+    
+    // verify request header gets set
+    DebugServlet.clear();
+    try {
+      client.query(q);
+    } catch (Throwable t) {}
+    assertNull(DebugServlet.headers.get("Accept-Encoding"));
+    client.setAllowCompression(true);
+    try {
+      client.query(q);
+    } catch (Throwable t) {}
+    assertNotNull(DebugServlet.headers.get("Accept-Encoding"));
+    client.setAllowCompression(false);
+    try {
+      client.query(q);
+    } catch (Throwable t) {}
+    assertNull(DebugServlet.headers.get("Accept-Encoding"));
+    
+    // verify server compresses output
+    HttpGet get = new HttpGet(jetty.getBaseUrl().toString() + "/collection1" +
+                              "/select?q=foo&wt=xml");
+    get.setHeader("Accept-Encoding", "gzip");
+    HttpClient httpclient = HttpClientUtil.createClient(null);
+    HttpEntity entity = null;
+    try {
+      HttpResponse response = httpclient.execute(get);
+      entity = response.getEntity();
+      Header ceheader = entity.getContentEncoding();
+      assertEquals("gzip", ceheader.getValue());
+      
+    } finally {
+      if(entity!=null) {
+        entity.getContent().close();
+      }
+      httpclient.getConnectionManager().shutdown();
+    }
+    
+    // verify compressed response can be handled
+    client = new HttpSolrClient(jetty.getBaseUrl().toString() + "/collection1");
+    client.setAllowCompression(true);
+    q = new SolrQuery("foo");
+    QueryResponse response = client.query(q);
+    assertEquals(0, response.getStatus());
+    client.shutdown();
+  }
+  
+  @Test
+  public void testSetParametersExternalClient(){
+    HttpClient httpClient = HttpClientUtil.createClient(null);
+    HttpSolrClient solrClient = new HttpSolrClient(jetty.getBaseUrl().toString(),
+                                               httpClient);
+    try {
+      solrClient.setMaxTotalConnections(1);
+      fail("Operation should not succeed.");
+    } catch (UnsupportedOperationException e) {}
+    try {
+      solrClient.setDefaultMaxConnectionsPerHost(1);
+      fail("Operation should not succeed.");
+    } catch (UnsupportedOperationException e) {}
+    solrClient.shutdown();
+    httpClient.getConnectionManager().shutdown();
+  }
+
+  @Test
+  public void testGetRawStream() throws SolrServerException, IOException{
+    HttpClient client = HttpClientUtil.createClient(null);
+    HttpSolrClient solrClient = new HttpSolrClient(jetty.getBaseUrl().toString() + "/collection1",
+                                               client, null);
+    QueryRequest req = new QueryRequest();
+    NamedList response = solrClient.request(req);
+    InputStream stream = (InputStream)response.get("stream");
+    assertNotNull(stream);
+    stream.close();
+    client.getConnectionManager().shutdown();
+  }
+
+  /**
+   * A trivial test that verifies the example keystore used for SSL testing can be 
+   * found using the base class. this helps future-proof against the possibility of 
+   * something moving/breaking the keystore path in a way that results in the SSL 
+   * randomization logic being forced to silently never use SSL.  (We can't enforce 
+   * this type of check in the base class because then it would not be usable by client 
+   * code depending on the test framework
+   */
+  public void testExampleKeystorePath() {
+    assertNotNull("Example keystore is null, meaning that something has changed in the " +
+                  "structure of the example configs and/or ExternalPaths.java - " + 
+                  "SSL randomization is broken",
+                  SSLTestConfig.TEST_KEYSTORE);
+  }
+
+
+  private int findUnusedPort() {
+    for (int port = 0; port < 65535; port++) {
+      Socket s = new Socket();
+      try {
+        s.bind(null);
+        int availablePort = s.getLocalPort();
+        s.close();
+        return availablePort;
+      } catch (IOException e) {
+        e.printStackTrace();
+      }
+    }
+    throw new RuntimeException("Could not find unused TCP port.");
+  }
+
+  private Set<String> setOf(String... keys) {
+    Set<String> set = new TreeSet<String>();
+    if (keys != null) {
+      for (String k : keys) {
+        set.add(k);
+      }
+    }
+    return set;
+  }
+
+  private void setReqParamsOf(UpdateRequest req, String... keys) {
+    if (keys != null) {
+      for (String k : keys) {
+        req.setParam(k, k+"Value");
+      }
+    }
+  }
+
+  private void verifyServletState(HttpSolrClient client, SolrRequest request) {
+    // check query String
+    Iterator<String> paramNames = request.getParams().getParameterNamesIterator();
+    while (paramNames.hasNext()) {
+      String name = paramNames.next();
+      String [] values = request.getParams().getParams(name);
+      if (values != null) {
+        for (String value : values) {
+          boolean shouldBeInQueryString = client.getQueryParams().contains(name)
+            || (request.getQueryParams() != null && request.getQueryParams().contains(name));
+          assertEquals(shouldBeInQueryString, DebugServlet.queryString.contains(name + "=" + value));
+          // in either case, it should be in the parameters
+          assertNotNull(DebugServlet.parameters.get(name));
+          assertEquals(1, DebugServlet.parameters.get(name).length);
+          assertEquals(value, DebugServlet.parameters.get(name)[0]);
+        }
+      }
+    }
+  }
+
+  @Test
+  public void testQueryString() throws Exception {
+    HttpSolrClient client = new HttpSolrClient(jetty.getBaseUrl().toString() +
+                                               "/debug/foo");
+
+    // test without request query params
+    DebugServlet.clear();
+    client.setQueryParams(setOf("serverOnly"));
+    UpdateRequest req = new UpdateRequest();
+    setReqParamsOf(req, "serverOnly", "notServer");
+    try {
+      client.request(req);
+    } catch (Throwable t) {}
+    verifyServletState(client, req);
+
+    // test without server query params
+    DebugServlet.clear();
+    client.setQueryParams(setOf());
+    req = new UpdateRequest();
+    req.setQueryParams(setOf("requestOnly"));
+    setReqParamsOf(req, "requestOnly", "notRequest");
+    try {
+      client.request(req);
+    } catch (Throwable t) {}
+    verifyServletState(client, req);
+
+    // test with both request and server query params
+    DebugServlet.clear();
+    req = new UpdateRequest();
+    client.setQueryParams(setOf("serverOnly", "both"));
+    req.setQueryParams(setOf("requestOnly", "both"));
+    setReqParamsOf(req, "serverOnly", "requestOnly", "both", "neither");
+     try {
+      client.request(req);
+    } catch (Throwable t) {}
+    verifyServletState(client, req);
+
+    // test with both request and server query params with single stream
+    DebugServlet.clear();
+    req = new UpdateRequest();
+    req.add(new SolrInputDocument());
+    client.setQueryParams(setOf("serverOnly", "both"));
+    req.setQueryParams(setOf("requestOnly", "both"));
+    setReqParamsOf(req, "serverOnly", "requestOnly", "both", "neither");
+     try {
+      client.request(req);
+    } catch (Throwable t) {}
+    // NOTE: single stream requests send all the params
+    // as part of the query string.  So add "neither" to the request
+    // so it passes the verification step.
+    req.setQueryParams(setOf("requestOnly", "both", "neither"));
+    verifyServletState(client, req);
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrServerTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrServerTest.java
deleted file mode 100644
index 1a5d23a..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/BasicHttpSolrServerTest.java
+++ /dev/null
@@ -1,660 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.client.solrj.impl;
-
-import java.io.IOException;
-import java.io.InputStream;
-import java.net.MalformedURLException;
-import java.net.Socket;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeSet;
-
-import javax.servlet.ServletException;
-import javax.servlet.http.HttpServlet;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-
-import org.apache.http.Header;
-import org.apache.http.HttpEntity;
-import org.apache.http.HttpResponse;
-import org.apache.http.client.HttpClient;
-import org.apache.http.client.methods.HttpGet;
-import org.apache.solr.SolrJettyTestBase;
-import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrRequest.METHOD;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrException.ErrorCode;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.solr.util.ExternalPaths;
-import org.apache.solr.util.SSLTestConfig;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class BasicHttpSolrServerTest extends SolrJettyTestBase {
-  
-  public static class RedirectServlet extends HttpServlet {
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.sendRedirect("/solr/collection1/select?" + req.getQueryString());
-    }
-  }
-  
-  public static class SlowServlet extends HttpServlet {
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      try {
-        Thread.sleep(5000);
-      } catch (InterruptedException e) {}
-    }
-  }
-  
-  public static class DebugServlet extends HttpServlet {
-    public static void clear() {
-      lastMethod = null;
-      headers = null;
-      parameters = null;
-      errorCode = null;
-      queryString = null;
-    }
-    
-    public static Integer errorCode = null;
-    public static String lastMethod = null;
-    public static HashMap<String,String> headers = null;
-    public static Map<String,String[]> parameters = null;
-    public static String queryString = null;
-    
-    public static void setErrorCode(Integer code) {
-      errorCode = code;
-    }
-    
-
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      lastMethod = "get";
-      recordRequest(req, resp);
-    }
-    
-    private void setHeaders(HttpServletRequest req) {
-      Enumeration<String> headerNames = req.getHeaderNames();
-      headers = new HashMap<>();
-      while (headerNames.hasMoreElements()) {
-        final String name = headerNames.nextElement();
-        headers.put(name, req.getHeader(name));
-      }
-    }
-
-    private void setParameters(HttpServletRequest req) {
-      parameters = req.getParameterMap();
-    }
-
-    private void setQueryString(HttpServletRequest req) {
-      queryString = req.getQueryString();
-    }
-
-    @Override
-    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      lastMethod = "post";
-      recordRequest(req, resp);
-    }
-
-    @Override
-    protected void doPut(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      lastMethod = "put";
-      recordRequest(req, resp);
-    }
-    
-    private void recordRequest(HttpServletRequest req, HttpServletResponse resp) {
-      setHeaders(req);
-      setParameters(req);
-      setQueryString(req);
-      if (null != errorCode) {
-        try { 
-          resp.sendError(errorCode); 
-        } catch (IOException e) {
-          throw new RuntimeException("sendError IO fail in DebugServlet", e);
-        }
-      }
-    }
-  }
-  
-  @BeforeClass
-  public static void beforeTest() throws Exception {
-    createJetty(legacyExampleCollection1SolrHome(), null, null);
-    jetty.getDispatchFilter().getServletHandler()
-        .addServletWithMapping(RedirectServlet.class, "/redirect/*");
-    jetty.getDispatchFilter().getServletHandler()
-        .addServletWithMapping(SlowServlet.class, "/slow/*");
-    jetty.getDispatchFilter().getServletHandler()
-        .addServletWithMapping(DebugServlet.class, "/debug/*");
-  }
-  
-  @Test
-  public void testTimeout() throws Exception {
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/slow/foo");
-    SolrQuery q = new SolrQuery("*:*");
-    server.setSoTimeout(2000);
-    try {
-      QueryResponse response = server.query(q, METHOD.GET);
-      fail("No exception thrown.");
-    } catch (SolrServerException e) {
-      assertTrue(e.getMessage().contains("Timeout"));
-    }
-    server.shutdown();
-  }
-  
-  /**
-   * test that SolrExceptions thrown by HttpSolrServer can
-   * correctly encapsulate http status codes even when not on the list of
-   * ErrorCodes solr may return.
-   */
-  public void testSolrExceptionCodeNotFromSolr() throws IOException, SolrServerException {
-    final int status = 527;
-    assertEquals(status + " didn't generate an UNKNOWN error code, someone modified the list of valid ErrorCode's w/o changing this test to work a different way",
-                 ErrorCode.UNKNOWN, ErrorCode.getErrorCode(status));
-
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/debug/foo");
-    try {
-      DebugServlet.setErrorCode(status);
-      try {
-        SolrQuery q = new SolrQuery("foo");
-        server.query(q, METHOD.GET);
-        fail("Didn't get excepted exception from oversided request");
-      } catch (SolrException e) {
-        System.out.println(e);
-        assertEquals("Unexpected exception status code", status, e.code());
-      }
-    } finally {
-      server.shutdown();
-      DebugServlet.clear();
-    }
-  }
-
-  @Test
-  public void testQuery(){
-    DebugServlet.clear();
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/debug/foo");
-    SolrQuery q = new SolrQuery("foo");
-    q.setParam("a", "\u1234");
-    try {
-      server.query(q, METHOD.GET);
-    } catch (Throwable t) {}
-    
-    //default method
-    assertEquals("get", DebugServlet.lastMethod);
-    //agent
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    //default wt
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    //default version
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    //agent
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    //keepalive
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    //content-type
-    assertEquals(null, DebugServlet.headers.get("Content-Type"));
-    //param encoding
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-
-    //POST
-    DebugServlet.clear();
-    try {
-      server.query(q, METHOD.POST);
-    } catch (Throwable t) {}
-    assertEquals("post", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-
-    //PUT
-    DebugServlet.clear();
-    try {
-      server.query(q, METHOD.PUT);
-    } catch (Throwable t) {}
-    assertEquals("put", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-
-    //XML/GET
-    server.setParser(new XMLResponseParser());
-    DebugServlet.clear();
-    try {
-      server.query(q, METHOD.GET);
-    } catch (Throwable t) {}
-    assertEquals("get", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-
-    //XML/POST
-    server.setParser(new XMLResponseParser());
-    DebugServlet.clear();
-    try {
-      server.query(q, METHOD.POST);
-    } catch (Throwable t) {}
-    assertEquals("post", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-
-    server.setParser(new XMLResponseParser());
-    DebugServlet.clear();
-    try {
-      server.query(q, METHOD.PUT);
-    } catch (Throwable t) {}
-    assertEquals("put", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    assertEquals("application/x-www-form-urlencoded; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-    server.shutdown();
-  }
-
-  @Test
-  public void testDelete(){
-    DebugServlet.clear();
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/debug/foo");
-    try {
-      server.deleteById("id");
-    } catch (Throwable t) {}
-    
-    //default method
-    assertEquals("post", DebugServlet.lastMethod);
-    //agent
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    //default wt
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    //default version
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    //agent
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    //keepalive
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-
-    //XML
-    server.setParser(new XMLResponseParser());
-    try {
-      server.deleteByQuery("*:*");
-    } catch (Throwable t) {}
-    
-    assertEquals("post", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals("keep-alive", DebugServlet.headers.get("Connection"));
-    server.shutdown();
-  }
-  
-  @Test
-  public void testUpdate(){
-    DebugServlet.clear();
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() + 
-                                               "/debug/foo");
-    UpdateRequest req = new UpdateRequest();
-    req.add(new SolrInputDocument());
-    req.setParam("a", "\u1234");
-    try {
-      server.request(req);
-    } catch (Throwable t) {}
-    
-    //default method
-    assertEquals("post", DebugServlet.lastMethod);
-    //agent
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    //default wt
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    //default version
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    //content type
-    assertEquals("application/xml; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-    //parameter encoding
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-
-    //XML response
-    server.setParser(new XMLResponseParser());
-    try {
-      server.request(req);
-    } catch (Throwable t) {}
-    assertEquals("post", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("xml", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals("application/xml; charset=UTF-8", DebugServlet.headers.get("Content-Type"));
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    
-    //javabin request
-    server.setParser(new BinaryResponseParser());
-    server.setRequestWriter(new BinaryRequestWriter());
-    DebugServlet.clear();
-    try {
-      server.request(req);
-    } catch (Throwable t) {}
-    assertEquals("post", DebugServlet.lastMethod);
-    assertEquals("Solr[" + org.apache.solr.client.solrj.impl.HttpSolrServer.class.getName() + "] 1.0", DebugServlet.headers.get("User-Agent"));
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.WT).length);
-    assertEquals("javabin", DebugServlet.parameters.get(CommonParams.WT)[0]);
-    assertEquals(1, DebugServlet.parameters.get(CommonParams.VERSION).length);
-    assertEquals(server.getParser().getVersion(), DebugServlet.parameters.get(CommonParams.VERSION)[0]);
-    assertEquals("application/javabin", DebugServlet.headers.get("Content-Type"));
-    assertEquals(1, DebugServlet.parameters.get("a").length);
-    assertEquals("\u1234", DebugServlet.parameters.get("a")[0]);
-    server.shutdown();
-  }
-  
-  @Test
-  public void testRedirect() throws Exception {
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/redirect/foo");
-    SolrQuery q = new SolrQuery("*:*");
-    // default = false
-    try {
-      QueryResponse response = server.query(q);
-      fail("Should have thrown an exception.");
-    } catch (SolrServerException e) {
-      assertTrue(e.getMessage().contains("redirect"));
-    }
-    server.setFollowRedirects(true);
-    try {
-      QueryResponse response = server.query(q);
-    } catch (Throwable t) {
-      fail("Exception was thrown:" + t);
-    }
-    //And back again:
-    server.setFollowRedirects(false);
-    try {
-      QueryResponse response = server.query(q);
-      fail("Should have thrown an exception.");
-    } catch (SolrServerException e) {
-      assertTrue(e.getMessage().contains("redirect"));
-    }
-    server.shutdown();
-  }
-  
-  @Test
-  public void testCompression() throws Exception {
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/debug/foo");
-    SolrQuery q = new SolrQuery("*:*");
-    
-    // verify request header gets set
-    DebugServlet.clear();
-    try {
-      server.query(q);
-    } catch (Throwable t) {}
-    assertNull(DebugServlet.headers.get("Accept-Encoding"));
-    server.setAllowCompression(true);
-    try {
-      server.query(q);
-    } catch (Throwable t) {}
-    assertNotNull(DebugServlet.headers.get("Accept-Encoding"));
-    server.setAllowCompression(false);
-    try {
-      server.query(q);
-    } catch (Throwable t) {}
-    assertNull(DebugServlet.headers.get("Accept-Encoding"));
-    
-    // verify server compresses output
-    HttpGet get = new HttpGet(jetty.getBaseUrl().toString() + "/collection1" +
-                              "/select?q=foo&wt=xml");
-    get.setHeader("Accept-Encoding", "gzip");
-    HttpClient client = HttpClientUtil.createClient(null);
-    HttpEntity entity = null;
-    try {
-      HttpResponse response = client.execute(get);
-      entity = response.getEntity();
-      Header ceheader = entity.getContentEncoding();
-      assertEquals("gzip", ceheader.getValue());
-      
-    } finally {
-      if(entity!=null) {
-        entity.getContent().close();
-      }
-      client.getConnectionManager().shutdown();
-    }
-    
-    // verify compressed response can be handled
-    server = new HttpSolrServer(jetty.getBaseUrl().toString() + "/collection1");
-    server.setAllowCompression(true);
-    q = new SolrQuery("foo");
-    QueryResponse response = server.query(q);
-    assertEquals(0, response.getStatus());
-    server.shutdown();
-  }
-  
-  @Test
-  public void testSetParametersExternalClient(){
-    HttpClient client = HttpClientUtil.createClient(null);
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString(), 
-                                               client);
-    try {
-      server.setMaxTotalConnections(1);
-      fail("Operation should not succeed.");
-    } catch (UnsupportedOperationException e) {}
-    try {
-      server.setDefaultMaxConnectionsPerHost(1);
-      fail("Operation should not succeed.");
-    } catch (UnsupportedOperationException e) {}
-    server.shutdown();
-    client.getConnectionManager().shutdown();
-  }
-
-  @Test
-  public void testGetRawStream() throws SolrServerException, IOException{
-    HttpClient client = HttpClientUtil.createClient(null);
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() + "/collection1", 
-                                               client, null);
-    QueryRequest req = new QueryRequest();
-    NamedList response = server.request(req);
-    InputStream stream = (InputStream)response.get("stream");
-    assertNotNull(stream);
-    stream.close();
-    client.getConnectionManager().shutdown();
-  }
-
-  /**
-   * A trivial test that verifies the example keystore used for SSL testing can be 
-   * found using the base class. this helps future-proof against the possibility of 
-   * something moving/breaking the keystore path in a way that results in the SSL 
-   * randomization logic being forced to silently never use SSL.  (We can't enforce 
-   * this type of check in the base class because then it would not be usable by client 
-   * code depending on the test framework
-   */
-  public void testExampleKeystorePath() {
-    assertNotNull("Example keystore is null, meaning that something has changed in the " +
-                  "structure of the example configs and/or ExternalPaths.java - " + 
-                  "SSL randomization is broken",
-                  SSLTestConfig.TEST_KEYSTORE);
-  }
-
-
-  private int findUnusedPort() {
-    for (int port = 0; port < 65535; port++) {
-      Socket s = new Socket();
-      try {
-        s.bind(null);
-        int availablePort = s.getLocalPort();
-        s.close();
-        return availablePort;
-      } catch (IOException e) {
-        e.printStackTrace();
-      }
-    }
-    throw new RuntimeException("Could not find unused TCP port.");
-  }
-
-  private Set<String> setOf(String... keys) {
-    Set<String> set = new TreeSet<String>();
-    if (keys != null) {
-      for (String k : keys) {
-        set.add(k);
-      }
-    }
-    return set;
-  }
-
-  private void setReqParamsOf(UpdateRequest req, String... keys) {
-    if (keys != null) {
-      for (String k : keys) {
-        req.setParam(k, k+"Value");
-      }
-    }
-  }
-
-  private void verifyServletState(HttpSolrServer server, SolrRequest request) {
-    // check query String
-    Iterator<String> paramNames = request.getParams().getParameterNamesIterator();
-    while (paramNames.hasNext()) {
-      String name = paramNames.next();
-      String [] values = request.getParams().getParams(name);
-      if (values != null) {
-        for (String value : values) {
-          boolean shouldBeInQueryString = server.getQueryParams().contains(name)
-            || (request.getQueryParams() != null && request.getQueryParams().contains(name));
-          assertEquals(shouldBeInQueryString, DebugServlet.queryString.contains(name + "=" + value));
-          // in either case, it should be in the parameters
-          assertNotNull(DebugServlet.parameters.get(name));
-          assertEquals(1, DebugServlet.parameters.get(name).length);
-          assertEquals(value, DebugServlet.parameters.get(name)[0]);
-        }
-      }
-    }
-  }
-
-  @Test
-  public void testQueryString() throws Exception {
-    HttpSolrServer server = new HttpSolrServer(jetty.getBaseUrl().toString() +
-                                               "/debug/foo");
-
-    // test without request query params
-    DebugServlet.clear();
-    server.setQueryParams(setOf("serverOnly"));
-    UpdateRequest req = new UpdateRequest();
-    setReqParamsOf(req, "serverOnly", "notServer");
-    try {
-      server.request(req);
-    } catch (Throwable t) {}
-    verifyServletState(server, req);
-
-    // test without server query params
-    DebugServlet.clear();
-    server.setQueryParams(setOf());
-    req = new UpdateRequest();
-    req.setQueryParams(setOf("requestOnly"));
-    setReqParamsOf(req, "requestOnly", "notRequest");
-    try {
-      server.request(req);
-    } catch (Throwable t) {}
-    verifyServletState(server, req);
-
-    // test with both request and server query params
-    DebugServlet.clear();
-    req = new UpdateRequest();
-    server.setQueryParams(setOf("serverOnly", "both"));
-    req.setQueryParams(setOf("requestOnly", "both"));
-    setReqParamsOf(req, "serverOnly", "requestOnly", "both", "neither");
-     try {
-      server.request(req);
-    } catch (Throwable t) {}
-    verifyServletState(server, req);
-
-    // test with both request and server query params with single stream
-    DebugServlet.clear();
-    req = new UpdateRequest();
-    req.add(new SolrInputDocument());
-    server.setQueryParams(setOf("serverOnly", "both"));
-    req.setQueryParams(setOf("requestOnly", "both"));
-    setReqParamsOf(req, "serverOnly", "requestOnly", "both", "neither");
-     try {
-      server.request(req);
-    } catch (Throwable t) {}
-    // NOTE: single stream requests send all the params
-    // as part of the query string.  So add "neither" to the request
-    // so it passes the verification step.
-    req.setQueryParams(setOf("requestOnly", "both", "neither"));
-    verifyServletState(server, req);
-  }
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientMultiConstructorTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientMultiConstructorTest.java
new file mode 100644
index 0000000..47d769c
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientMultiConstructorTest.java
@@ -0,0 +1,82 @@
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.lucene.util.LuceneTestCase;
+import org.apache.lucene.util.TestUtil;
+import org.junit.Test;
+
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.LinkedHashSet;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+public class CloudSolrClientMultiConstructorTest extends LuceneTestCase {
+  
+  /*
+   * NOTE: If you only include one String argument, it will NOT use the
+   * constructor with the variable argument list, which is the one that
+   * we are testing here.
+   */
+  Collection<String> hosts;
+
+  @Test
+  public void testWithChroot() {
+    boolean setOrList = random().nextBoolean();
+    int numOfZKServers = TestUtil.nextInt(random(), 1, 5);
+    boolean withChroot = random().nextBoolean();
+
+    final String chroot = "/mychroot";
+
+    StringBuilder sb = new StringBuilder();
+    CloudSolrClient client;
+
+    if(setOrList) {
+      /*
+        A LinkedHashSet is required here for testing, or we can't guarantee
+        the order of entries in the final string.
+       */
+      hosts = new LinkedHashSet<>();
+    } else {
+      hosts = new ArrayList<>();
+    }
+
+    for(int i=0; i<numOfZKServers; i++) {
+      String ZKString = "host" + i + ":2181";
+      hosts.add(ZKString);
+      sb.append(ZKString);
+      if(i<numOfZKServers -1) sb.append(",");
+    }
+
+    if(withChroot) {
+      sb.append(chroot);
+      client = new CloudSolrClient(hosts, "/mychroot");
+    } else {
+      client = new CloudSolrClient(hosts, null);
+    }
+
+    assertEquals(sb.toString(), client.getZkHost());
+    client.shutdown();
+  }
+  
+  @Test(expected = IllegalArgumentException.class)
+  public void testBadChroot() {
+    hosts = new ArrayList<>();
+    hosts.add("host1:2181");
+    new CloudSolrClient(hosts, "foo");
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java
new file mode 100644
index 0000000..ecad354
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrClientTest.java
@@ -0,0 +1,459 @@
+package org.apache.solr.client.solrj.impl;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
+import org.apache.http.client.HttpClient;
+import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrQuery;
+import org.apache.solr.client.solrj.SolrServerException;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
+import org.apache.solr.cloud.AbstractZkTestCase;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrException;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.cloud.ClusterState;
+import org.apache.solr.common.cloud.DocCollection;
+import org.apache.solr.common.cloud.DocRouter;
+import org.apache.solr.common.cloud.Replica;
+import org.apache.solr.common.cloud.Slice;
+import org.apache.solr.common.cloud.ZkStateReader;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.ShardParams;
+import org.apache.solr.common.util.NamedList;
+import org.apache.zookeeper.KeeperException;
+import org.junit.After;
+import org.junit.AfterClass;
+import org.junit.Before;
+import org.junit.BeforeClass;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.TimeoutException;
+
+
+/**
+ * This test would be faster if we simulated the zk state instead.
+ */
+@Slow
+public class CloudSolrClientTest extends AbstractFullDistribZkTestBase {
+  static Logger log = LoggerFactory.getLogger(CloudSolrClientTest.class);
+
+  private static final String SOLR_HOME = getFile("solrj" + File.separator + "solr").getAbsolutePath();
+
+  @BeforeClass
+  public static void beforeSuperClass() {
+      AbstractZkTestCase.SOLRHOME = new File(SOLR_HOME());
+  }
+  
+  @AfterClass
+  public static void afterSuperClass() {
+    
+  }
+  
+  protected String getCloudSolrConfig() {
+    return "solrconfig.xml";
+  }
+  
+  @Override
+  public String getSolrHome() {
+    return SOLR_HOME;
+  }
+  
+  public static String SOLR_HOME() {
+    return SOLR_HOME;
+  }
+  
+  @Before
+  @Override
+  public void setUp() throws Exception {
+    super.setUp();
+    // we expect this time of exception as shards go up and down...
+    //ignoreException(".*");
+    
+    System.setProperty("numShards", Integer.toString(sliceCount));
+  }
+  
+  @Override
+  @After
+  public void tearDown() throws Exception {
+    super.tearDown();
+    resetExceptionIgnores();
+  }
+  
+  public CloudSolrClientTest() {
+    super();
+    sliceCount = 2;
+    shardCount = 3;
+  }
+
+  @Override
+  public void doTest() throws Exception {
+    allTests();
+    stateVersionParamTest();
+    customHttpClientTest();
+  }
+
+  private void allTests() throws Exception {
+
+    String collectionName = "clientTestExternColl";
+    createCollection(collectionName, controlClientCloud, 2, 2);
+    waitForRecoveriesToFinish(collectionName, false);
+    CloudSolrClient cloudClient = createCloudClient(collectionName);
+
+    assertNotNull(cloudClient);
+    
+    handle.clear();
+    handle.put("timestamp", SKIPVAL);
+    
+    waitForThingsToLevelOut(30);
+
+    controlClient.deleteByQuery("*:*");
+    cloudClient.deleteByQuery("*:*");
+
+
+    controlClient.commit();
+    this.cloudClient.commit();
+
+    SolrInputDocument doc1 = new SolrInputDocument();
+    doc1.addField(id, "0");
+    doc1.addField("a_t", "hello1");
+    SolrInputDocument doc2 = new SolrInputDocument();
+    doc2.addField(id, "2");
+    doc2.addField("a_t", "hello2");
+    
+    UpdateRequest request = new UpdateRequest();
+    request.add(doc1);
+    request.add(doc2);
+    request.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, false);
+    
+    // Test single threaded routed updates for UpdateRequest
+    NamedList<Object> response = cloudClient.request(request);
+    CloudSolrClient.RouteResponse rr = (CloudSolrClient.RouteResponse) response;
+    Map<String,LBHttpSolrClient.Req> routes = rr.getRoutes();
+    Iterator<Map.Entry<String,LBHttpSolrClient.Req>> it = routes.entrySet()
+        .iterator();
+    while (it.hasNext()) {
+      Map.Entry<String,LBHttpSolrClient.Req> entry = it.next();
+      String url = entry.getKey();
+      UpdateRequest updateRequest = (UpdateRequest) entry.getValue()
+          .getRequest();
+      SolrInputDocument doc = updateRequest.getDocuments().get(0);
+      String id = doc.getField("id").getValue().toString();
+      ModifiableSolrParams params = new ModifiableSolrParams();
+      params.add("q", "id:" + id);
+      params.add("distrib", "false");
+      QueryRequest queryRequest = new QueryRequest(params);
+      HttpSolrClient solrClient = new HttpSolrClient(url);
+      QueryResponse queryResponse = queryRequest.process(solrClient);
+      SolrDocumentList docList = queryResponse.getResults();
+      assertTrue(docList.getNumFound() == 1);
+    }
+    
+    // Test the deleteById routing for UpdateRequest
+    
+    UpdateRequest delRequest = new UpdateRequest();
+    delRequest.deleteById("0");
+    delRequest.deleteById("2");
+    delRequest.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, false);
+    cloudClient.request(delRequest);
+    ModifiableSolrParams qParams = new ModifiableSolrParams();
+    qParams.add("q", "*:*");
+    QueryRequest qRequest = new QueryRequest(qParams);
+    QueryResponse qResponse = qRequest.process(cloudClient);
+    SolrDocumentList docs = qResponse.getResults();
+    assertTrue(docs.getNumFound() == 0);
+    
+    // Test Multi-Threaded routed updates for UpdateRequest
+    
+    CloudSolrClient threadedClient = null;
+    try {
+      threadedClient = new CloudSolrClient(zkServer.getZkAddress());
+      threadedClient.setParallelUpdates(true);
+      threadedClient.setDefaultCollection(collectionName);
+      response = threadedClient.request(request);
+      rr = (CloudSolrClient.RouteResponse) response;
+      routes = rr.getRoutes();
+      it = routes.entrySet()
+          .iterator();
+      while (it.hasNext()) {
+        Map.Entry<String,LBHttpSolrClient.Req> entry = it.next();
+        String url = entry.getKey();
+        UpdateRequest updateRequest = (UpdateRequest) entry.getValue()
+            .getRequest();
+        SolrInputDocument doc = updateRequest.getDocuments().get(0);
+        String id = doc.getField("id").getValue().toString();
+        ModifiableSolrParams params = new ModifiableSolrParams();
+        params.add("q", "id:" + id);
+        params.add("distrib", "false");
+        QueryRequest queryRequest = new QueryRequest(params);
+        HttpSolrClient solrClient = new HttpSolrClient(url);
+        QueryResponse queryResponse = queryRequest.process(solrClient);
+        SolrDocumentList docList = queryResponse.getResults();
+        assertTrue(docList.getNumFound() == 1);
+      }
+    } finally {
+      threadedClient.shutdown();
+    }
+
+    // Test that queries with _route_ params are routed by the client
+
+    // Track request counts on each node before query calls
+    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();
+    DocCollection col = clusterState.getCollection(collectionName);
+    Map<String, Long> requestCountsMap = Maps.newHashMap();
+    for (Slice slice : col.getSlices()) {
+      for (Replica replica : slice.getReplicas()) {
+        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
+        requestCountsMap.put(baseURL, getNumRequests(baseURL,collectionName));
+      }
+    }
+
+    // Collect the base URLs of the replicas of shard that's expected to be hit
+    DocRouter router = col.getRouter();
+    Collection<Slice> expectedSlices = router.getSearchSlicesSingle("0", null, col);
+    Set<String> expectedBaseURLs = Sets.newHashSet();
+    for (Slice expectedSlice : expectedSlices) {
+      for (Replica replica : expectedSlice.getReplicas()) {
+        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
+        expectedBaseURLs.add(baseURL);
+      }
+    }
+
+    assertTrue("expected urls is not fewer than all urls! expected=" + expectedBaseURLs
+        + "; all=" + requestCountsMap.keySet(),
+        expectedBaseURLs.size() < requestCountsMap.size());
+
+    // Calculate a number of shard keys that route to the same shard.
+    int n;
+    if (TEST_NIGHTLY) {
+      n = random().nextInt(999) + 2;
+    } else {
+      n = random().nextInt(9) + 2;
+    }
+    
+    List<String> sameShardRoutes = Lists.newArrayList();
+    sameShardRoutes.add("0");
+    for (int i = 1; i < n; i++) {
+      String shardKey = Integer.toString(i);
+      Collection<Slice> slices = router.getSearchSlicesSingle(shardKey, null, col);
+      log.info("Expected Slices {}", slices);
+      if (expectedSlices.equals(slices)) {
+        sameShardRoutes.add(shardKey);
+      }
+    }
+
+    assertTrue(sameShardRoutes.size() > 1);
+
+    // Do N queries with _route_ parameter to the same shard
+    for (int i = 0; i < n; i++) {
+      ModifiableSolrParams solrParams = new ModifiableSolrParams();
+      solrParams.set(CommonParams.Q, "*:*");
+      solrParams.set(ShardParams._ROUTE_, sameShardRoutes.get(random().nextInt(sameShardRoutes.size())));
+      log.info("output  : {}" ,cloudClient.query(solrParams));
+    }
+
+    // Request counts increase from expected nodes should aggregate to 1000, while there should be
+    // no increase in unexpected nodes.
+    int increaseFromExpectedUrls = 0;
+    int increaseFromUnexpectedUrls = 0;
+    Map<String, Long> numRequestsToUnexpectedUrls = Maps.newHashMap();
+    for (Slice slice : col.getSlices()) {
+      for (Replica replica : slice.getReplicas()) {
+        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
+
+        Long prevNumRequests = requestCountsMap.get(baseURL);
+        Long curNumRequests = getNumRequests(baseURL, collectionName);
+
+        long delta = curNumRequests - prevNumRequests;
+        if (expectedBaseURLs.contains(baseURL)) {
+          increaseFromExpectedUrls += delta;
+        } else {
+          increaseFromUnexpectedUrls += delta;
+          numRequestsToUnexpectedUrls.put(baseURL, delta);
+        }
+      }
+    }
+
+    assertEquals("Unexpected number of requests to expected URLs", n, increaseFromExpectedUrls);
+    assertEquals("Unexpected number of requests to unexpected URLs: " + numRequestsToUnexpectedUrls,
+        0, increaseFromUnexpectedUrls);
+
+    controlClient.deleteByQuery("*:*");
+    cloudClient.deleteByQuery("*:*");
+
+    controlClient.commit();
+    cloudClient.commit();
+    cloudClient.shutdown();
+  }
+
+  private Long getNumRequests(String baseUrl, String collectionName) throws
+      SolrServerException, IOException {
+    HttpSolrClient client = new HttpSolrClient(baseUrl + "/"+ collectionName);
+    client.setConnectionTimeout(15000);
+    client.setSoTimeout(60000);
+    ModifiableSolrParams params = new ModifiableSolrParams();
+    params.set("qt", "/admin/mbeans");
+    params.set("stats", "true");
+    params.set("key", "standard");
+    params.set("cat", "QUERYHANDLER");
+    // use generic request to avoid extra processing of queries
+    QueryRequest req = new QueryRequest(params);
+    NamedList<Object> resp = client.request(req);
+    return (Long) resp.findRecursive("solr-mbeans", "QUERYHANDLER",
+        "standard", "stats", "requests");
+  }
+  
+  @Override
+  protected void indexr(Object... fields) throws Exception {
+    SolrInputDocument doc = getDoc(fields);
+    indexDoc(doc);
+  }
+
+  private void stateVersionParamTest() throws Exception {
+    CloudSolrClient client = createCloudClient(null);
+    try {
+      String collectionName = "checkStateVerCol";
+      createCollection(collectionName, client, 2, 2);
+      waitForRecoveriesToFinish(collectionName, false);
+      DocCollection coll = client.getZkStateReader().getClusterState().getCollection(collectionName);
+      Replica r = coll.getSlices().iterator().next().getReplicas().iterator().next();
+
+      HttpSolrClient solrClient = new HttpSolrClient(r.getStr(ZkStateReader.BASE_URL_PROP) + "/"+collectionName);
+
+
+      SolrQuery q = new SolrQuery().setQuery("*:*");
+
+      log.info("should work query, result {}", solrClient.query(q));
+      //no problem
+      q.setParam(CloudSolrClient.STATE_VERSION, collectionName + ":" + coll.getZNodeVersion());
+      log.info("2nd query , result {}", solrClient.query(q));
+      //no error yet good
+
+      q.setParam(CloudSolrClient.STATE_VERSION, collectionName+":"+ (coll.getZNodeVersion() -1)); //an older version expect error
+
+      HttpSolrClient.RemoteSolrException sse = null;
+      try {
+        solrClient.query(q);
+        log.info("expected query error");
+      } catch (HttpSolrClient.RemoteSolrException e) {
+        sse = e;
+      }
+      solrClient.shutdown();
+      assertNotNull(sse);
+      assertEquals(" Error code should be ", sse.code(), SolrException.ErrorCode.INVALID_STATE.code);
+
+      //now send the request to another node that does n ot serve the collection
+
+      Set<String> allNodesOfColl = new HashSet<>();
+      for (Slice slice : coll.getSlices()) {
+        for (Replica replica : slice.getReplicas()) {
+          allNodesOfColl.add(replica.getStr(ZkStateReader.BASE_URL_PROP));
+        }
+      }
+      String theNode = null;
+      for (String s : client.getZkStateReader().getClusterState().getLiveNodes()) {
+        String n = client.getZkStateReader().getBaseUrlForNodeName(s);
+        if(!allNodesOfColl.contains(s)){
+          theNode = n;
+          break;
+        }
+      }
+      log.info("thenode which does not serve this collection{} ",theNode);
+      assertNotNull(theNode);
+      solrClient = new HttpSolrClient(theNode + "/"+collectionName);
+
+      q.setParam(CloudSolrClient.STATE_VERSION, collectionName+":"+coll.getZNodeVersion());
+
+      try {
+        solrClient.query(q);
+        log.info("error was expected");
+      } catch (HttpSolrClient.RemoteSolrException e) {
+        sse = e;
+      }
+      solrClient.shutdown();
+      assertNotNull(sse);
+      assertEquals(" Error code should be ",  sse.code() , SolrException.ErrorCode.INVALID_STATE.code);
+    } finally {
+      client.shutdown();
+    }
+
+  }
+
+  public void testShutdown() throws MalformedURLException {
+    CloudSolrClient client = new CloudSolrClient("[ff01::114]:33332");
+    try {
+      client.setZkConnectTimeout(100);
+      client.connect();
+      fail("Expected exception");
+    } catch (SolrException e) {
+      assertTrue(e.getCause() instanceof TimeoutException);
+    } finally {
+      client.shutdown();
+    }
+  }
+
+  public void testWrongZkChrootTest() throws MalformedURLException {
+    CloudSolrClient client = null;
+    try {
+      client = new CloudSolrClient(zkServer.getZkAddress() + "/xyz/foo");
+      client.setDefaultCollection(DEFAULT_COLLECTION);
+      client.setZkClientTimeout(1000 * 60);
+      client.connect();
+      fail("Expected exception");
+    } catch(SolrException e) {
+      assertTrue(e.getCause() instanceof KeeperException);
+    } finally {
+      client.shutdown();
+    }
+    // see SOLR-6146 - this test will fail by virtue of the zkClient tracking performed
+    // in the afterClass method of the base class
+  }
+
+  public void customHttpClientTest() {
+    CloudSolrClient solrClient = null;
+    ModifiableSolrParams params = new ModifiableSolrParams();
+    params.set(HttpClientUtil.PROP_SO_TIMEOUT, 1000);
+    HttpClient client = null;
+
+    try {
+      client = HttpClientUtil.createClient(params);
+      solrClient = new CloudSolrClient(zkServer.getZkAddress(), client);
+      assertTrue(solrClient.getLbClient().getHttpClient() == client);
+    } finally {
+      solrClient.shutdown();
+      client.getConnectionManager().shutdown();
+    }
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerMultiConstructorTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerMultiConstructorTest.java
deleted file mode 100644
index 0e26255..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerMultiConstructorTest.java
+++ /dev/null
@@ -1,82 +0,0 @@
-package org.apache.solr.client.solrj.impl;
-
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.LinkedHashSet;
-
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestUtil;
-import org.junit.Test;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-public class CloudSolrServerMultiConstructorTest extends LuceneTestCase {
-  
-  /*
-   * NOTE: If you only include one String argument, it will NOT use the
-   * constructor with the variable argument list, which is the one that
-   * we are testing here.
-   */
-  Collection<String> hosts;
-
-  @Test
-  public void testWithChroot() {
-    boolean setOrList = random().nextBoolean();
-    int numOfZKServers = TestUtil.nextInt(random(), 1, 5);
-    boolean withChroot = random().nextBoolean();
-
-    final String chroot = "/mychroot";
-
-    StringBuilder sb = new StringBuilder();
-    CloudSolrServer client;
-
-    if(setOrList) {
-      /*
-        A LinkedHashSet is required here for testing, or we can't guarantee
-        the order of entries in the final string.
-       */
-      hosts = new LinkedHashSet<>();
-    } else {
-      hosts = new ArrayList<>();
-    }
-
-    for(int i=0; i<numOfZKServers; i++) {
-      String ZKString = "host" + i + ":2181";
-      hosts.add(ZKString);
-      sb.append(ZKString);
-      if(i<numOfZKServers -1) sb.append(",");
-    }
-
-    if(withChroot) {
-      sb.append(chroot);
-      client = new CloudSolrServer(hosts, "/mychroot");
-    } else {
-      client = new CloudSolrServer(hosts, null);
-    }
-
-    assertEquals(sb.toString(), client.getZkHost());
-    client.shutdown();
-  }
-  
-  @Test(expected = IllegalArgumentException.class)
-  public void testBadChroot() {
-    hosts = new ArrayList<>();
-    hosts.add("host1:2181");
-    new CloudSolrServer(hosts, "foo");
-  }
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java
deleted file mode 100644
index e18f696..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/CloudSolrServerTest.java
+++ /dev/null
@@ -1,460 +0,0 @@
-package org.apache.solr.client.solrj.impl;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.TimeoutException;
-
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-
-import org.apache.http.client.HttpClient;
-import org.apache.lucene.util.LuceneTestCase.Slow;
-import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
-import org.apache.solr.client.solrj.request.QueryRequest;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.cloud.AbstractFullDistribZkTestBase;
-import org.apache.solr.cloud.AbstractZkTestCase;
-import org.apache.solr.common.SolrDocumentList;
-import org.apache.solr.common.SolrException;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.cloud.ClusterState;
-import org.apache.solr.common.cloud.DocCollection;
-import org.apache.solr.common.cloud.DocRouter;
-import org.apache.solr.common.cloud.Replica;
-import org.apache.solr.common.cloud.Slice;
-import org.apache.solr.common.cloud.ZkStateReader;
-import org.apache.solr.common.params.CommonParams;
-import org.apache.solr.common.params.ModifiableSolrParams;
-import org.apache.solr.common.params.ShardParams;
-import org.apache.solr.common.util.NamedList;
-import org.apache.zookeeper.KeeperException;
-import org.junit.After;
-import org.junit.AfterClass;
-import org.junit.Before;
-import org.junit.BeforeClass;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-
-/**
- * This test would be faster if we simulated the zk state instead.
- */
-@Slow
-public class CloudSolrServerTest extends AbstractFullDistribZkTestBase {
-  static Logger log = LoggerFactory.getLogger(CloudSolrServerTest.class);
-
-  private static final String SOLR_HOME = getFile("solrj" + File.separator + "solr").getAbsolutePath();
-
-  @BeforeClass
-  public static void beforeSuperClass() {
-      AbstractZkTestCase.SOLRHOME = new File(SOLR_HOME());
-  }
-  
-  @AfterClass
-  public static void afterSuperClass() {
-    
-  }
-  
-  protected String getCloudSolrConfig() {
-    return "solrconfig.xml";
-  }
-  
-  @Override
-  public String getSolrHome() {
-    return SOLR_HOME;
-  }
-  
-  public static String SOLR_HOME() {
-    return SOLR_HOME;
-  }
-  
-  @Before
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    // we expect this time of exception as shards go up and down...
-    //ignoreException(".*");
-    
-    System.setProperty("numShards", Integer.toString(sliceCount));
-  }
-  
-  @Override
-  @After
-  public void tearDown() throws Exception {
-    super.tearDown();
-    resetExceptionIgnores();
-  }
-  
-  public CloudSolrServerTest() {
-    super();
-    sliceCount = 2;
-    shardCount = 3;
-  }
-
-  @Override
-  public void doTest() throws Exception {
-    allTests();
-    stateVersionParamTest();
-    customHttpClientTest();
-  }
-
-  private void allTests() throws Exception {
-
-    String collectionName = "clientTestExternColl";
-    createCollection(collectionName, controlClientCloud, 2, 2);
-    waitForRecoveriesToFinish(collectionName, false);
-    CloudSolrServer cloudClient = createCloudClient(collectionName);
-
-    assertNotNull(cloudClient);
-    
-    handle.clear();
-    handle.put("timestamp", SKIPVAL);
-    
-    waitForThingsToLevelOut(30);
-
-    controlClient.deleteByQuery("*:*");
-    cloudClient.deleteByQuery("*:*");
-
-
-    controlClient.commit();
-    this.cloudClient.commit();
-
-    SolrInputDocument doc1 = new SolrInputDocument();
-    doc1.addField(id, "0");
-    doc1.addField("a_t", "hello1");
-    SolrInputDocument doc2 = new SolrInputDocument();
-    doc2.addField(id, "2");
-    doc2.addField("a_t", "hello2");
-    
-    UpdateRequest request = new UpdateRequest();
-    request.add(doc1);
-    request.add(doc2);
-    request.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, false);
-    
-    // Test single threaded routed updates for UpdateRequest
-    NamedList<Object> response = cloudClient.request(request);
-    CloudSolrServer.RouteResponse rr = (CloudSolrServer.RouteResponse) response;
-    Map<String,LBHttpSolrServer.Req> routes = rr.getRoutes();
-    Iterator<Map.Entry<String,LBHttpSolrServer.Req>> it = routes.entrySet()
-        .iterator();
-    while (it.hasNext()) {
-      Map.Entry<String,LBHttpSolrServer.Req> entry = it.next();
-      String url = entry.getKey();
-      UpdateRequest updateRequest = (UpdateRequest) entry.getValue()
-          .getRequest();
-      SolrInputDocument doc = updateRequest.getDocuments().get(0);
-      String id = doc.getField("id").getValue().toString();
-      ModifiableSolrParams params = new ModifiableSolrParams();
-      params.add("q", "id:" + id);
-      params.add("distrib", "false");
-      QueryRequest queryRequest = new QueryRequest(params);
-      HttpSolrServer solrServer = new HttpSolrServer(url);
-      QueryResponse queryResponse = queryRequest.process(solrServer);
-      SolrDocumentList docList = queryResponse.getResults();
-      assertTrue(docList.getNumFound() == 1);
-    }
-    
-    // Test the deleteById routing for UpdateRequest
-    
-    UpdateRequest delRequest = new UpdateRequest();
-    delRequest.deleteById("0");
-    delRequest.deleteById("2");
-    delRequest.setAction(AbstractUpdateRequest.ACTION.COMMIT, false, false);
-    cloudClient.request(delRequest);
-    ModifiableSolrParams qParams = new ModifiableSolrParams();
-    qParams.add("q", "*:*");
-    QueryRequest qRequest = new QueryRequest(qParams);
-    QueryResponse qResponse = qRequest.process(cloudClient);
-    SolrDocumentList docs = qResponse.getResults();
-    assertTrue(docs.getNumFound() == 0);
-    
-    // Test Multi-Threaded routed updates for UpdateRequest
-    
-    CloudSolrServer threadedClient = null;
-    try {
-      threadedClient = new CloudSolrServer(zkServer.getZkAddress());
-      threadedClient.setParallelUpdates(true);
-      threadedClient.setDefaultCollection(collectionName);
-      response = threadedClient.request(request);
-      rr = (CloudSolrServer.RouteResponse) response;
-      routes = rr.getRoutes();
-      it = routes.entrySet()
-          .iterator();
-      while (it.hasNext()) {
-        Map.Entry<String,LBHttpSolrServer.Req> entry = it.next();
-        String url = entry.getKey();
-        UpdateRequest updateRequest = (UpdateRequest) entry.getValue()
-            .getRequest();
-        SolrInputDocument doc = updateRequest.getDocuments().get(0);
-        String id = doc.getField("id").getValue().toString();
-        ModifiableSolrParams params = new ModifiableSolrParams();
-        params.add("q", "id:" + id);
-        params.add("distrib", "false");
-        QueryRequest queryRequest = new QueryRequest(params);
-        HttpSolrServer solrServer = new HttpSolrServer(url);
-        QueryResponse queryResponse = queryRequest.process(solrServer);
-        SolrDocumentList docList = queryResponse.getResults();
-        assertTrue(docList.getNumFound() == 1);
-      }
-    } finally {
-      threadedClient.shutdown();
-    }
-
-    // Test that queries with _route_ params are routed by the client
-
-    // Track request counts on each node before query calls
-    ClusterState clusterState = cloudClient.getZkStateReader().getClusterState();
-    DocCollection col = clusterState.getCollection(collectionName);
-    Map<String, Long> requestCountsMap = Maps.newHashMap();
-    for (Slice slice : col.getSlices()) {
-      for (Replica replica : slice.getReplicas()) {
-        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
-        requestCountsMap.put(baseURL, getNumRequests(baseURL,collectionName));
-      }
-    }
-
-    // Collect the base URLs of the replicas of shard that's expected to be hit
-    DocRouter router = col.getRouter();
-    Collection<Slice> expectedSlices = router.getSearchSlicesSingle("0", null, col);
-    Set<String> expectedBaseURLs = Sets.newHashSet();
-    for (Slice expectedSlice : expectedSlices) {
-      for (Replica replica : expectedSlice.getReplicas()) {
-        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
-        expectedBaseURLs.add(baseURL);
-      }
-    }
-
-    assertTrue("expected urls is not fewer than all urls! expected=" + expectedBaseURLs
-        + "; all=" + requestCountsMap.keySet(),
-        expectedBaseURLs.size() < requestCountsMap.size());
-
-    // Calculate a number of shard keys that route to the same shard.
-    int n;
-    if (TEST_NIGHTLY) {
-      n = random().nextInt(999) + 2;
-    } else {
-      n = random().nextInt(9) + 2;
-    }
-    
-    List<String> sameShardRoutes = Lists.newArrayList();
-    sameShardRoutes.add("0");
-    for (int i = 1; i < n; i++) {
-      String shardKey = Integer.toString(i);
-      Collection<Slice> slices = router.getSearchSlicesSingle(shardKey, null, col);
-      log.info("Expected Slices {}", slices);
-      if (expectedSlices.equals(slices)) {
-        sameShardRoutes.add(shardKey);
-      }
-    }
-
-    assertTrue(sameShardRoutes.size() > 1);
-
-    // Do N queries with _route_ parameter to the same shard
-    for (int i = 0; i < n; i++) {
-      ModifiableSolrParams solrParams = new ModifiableSolrParams();
-      solrParams.set(CommonParams.Q, "*:*");
-      solrParams.set(ShardParams._ROUTE_, sameShardRoutes.get(random().nextInt(sameShardRoutes.size())));
-      log.info("output  : {}" ,cloudClient.query(solrParams));
-    }
-
-    // Request counts increase from expected nodes should aggregate to 1000, while there should be
-    // no increase in unexpected nodes.
-    int increaseFromExpectedUrls = 0;
-    int increaseFromUnexpectedUrls = 0;
-    Map<String, Long> numRequestsToUnexpectedUrls = Maps.newHashMap();
-    for (Slice slice : col.getSlices()) {
-      for (Replica replica : slice.getReplicas()) {
-        String baseURL = (String) replica.get(ZkStateReader.BASE_URL_PROP);
-
-        Long prevNumRequests = requestCountsMap.get(baseURL);
-        Long curNumRequests = getNumRequests(baseURL, collectionName);
-
-        long delta = curNumRequests - prevNumRequests;
-        if (expectedBaseURLs.contains(baseURL)) {
-          increaseFromExpectedUrls += delta;
-        } else {
-          increaseFromUnexpectedUrls += delta;
-          numRequestsToUnexpectedUrls.put(baseURL, delta);
-        }
-      }
-    }
-
-    assertEquals("Unexpected number of requests to expected URLs", n, increaseFromExpectedUrls);
-    assertEquals("Unexpected number of requests to unexpected URLs: " + numRequestsToUnexpectedUrls,
-        0, increaseFromUnexpectedUrls);
-
-    controlClient.deleteByQuery("*:*");
-    cloudClient.deleteByQuery("*:*");
-
-    controlClient.commit();
-    cloudClient.commit();
-    cloudClient.shutdown();
-  }
-
-  private Long getNumRequests(String baseUrl, String collectionName) throws
-      SolrServerException, IOException {
-    HttpSolrServer server = new HttpSolrServer(baseUrl + "/"+ collectionName);
-    server.setConnectionTimeout(15000);
-    server.setSoTimeout(60000);
-    ModifiableSolrParams params = new ModifiableSolrParams();
-    params.set("qt", "/admin/mbeans");
-    params.set("stats", "true");
-    params.set("key", "standard");
-    params.set("cat", "QUERYHANDLER");
-    // use generic request to avoid extra processing of queries
-    QueryRequest req = new QueryRequest(params);
-    NamedList<Object> resp = server.request(req);
-    return (Long) resp.findRecursive("solr-mbeans", "QUERYHANDLER",
-        "standard", "stats", "requests");
-  }
-  
-  @Override
-  protected void indexr(Object... fields) throws Exception {
-    SolrInputDocument doc = getDoc(fields);
-    indexDoc(doc);
-  }
-
-  private void stateVersionParamTest() throws Exception {
-    CloudSolrServer client = createCloudClient(null);
-    try {
-      String collectionName = "checkStateVerCol";
-      createCollection(collectionName, client, 2, 2);
-      waitForRecoveriesToFinish(collectionName, false);
-      DocCollection coll = client.getZkStateReader().getClusterState().getCollection(collectionName);
-      Replica r = coll.getSlices().iterator().next().getReplicas().iterator().next();
-
-      HttpSolrServer httpSolrServer = new HttpSolrServer(r.getStr(ZkStateReader.BASE_URL_PROP) + "/"+collectionName);
-
-
-      SolrQuery q = new SolrQuery().setQuery("*:*");
-
-      log.info("should work query, result {}", httpSolrServer.query(q));
-      //no problem
-      q.setParam(CloudSolrServer.STATE_VERSION, collectionName+":"+coll.getZNodeVersion());
-      log.info("2nd query , result {}", httpSolrServer.query(q));
-      //no error yet good
-
-      q.setParam(CloudSolrServer.STATE_VERSION, collectionName+":"+ (coll.getZNodeVersion() -1)); //an older version expect error
-
-      HttpSolrServer.RemoteSolrException sse = null;
-      try {
-        httpSolrServer.query(q);
-        log.info("expected query error");
-      } catch (HttpSolrServer.RemoteSolrException e) {
-        sse = e;
-      }
-      httpSolrServer.shutdown();
-      assertNotNull(sse);
-      assertEquals(" Error code should be ",  sse.code() , SolrException.ErrorCode.INVALID_STATE.code);
-
-      //now send the request to another node that does n ot serve the collection
-
-      Set<String> allNodesOfColl = new HashSet<>();
-      for (Slice slice : coll.getSlices()) {
-        for (Replica replica : slice.getReplicas()) {
-          allNodesOfColl.add(replica.getStr(ZkStateReader.BASE_URL_PROP));
-        }
-      }
-      String theNode = null;
-      for (String s : client.getZkStateReader().getClusterState().getLiveNodes()) {
-        String n = client.getZkStateReader().getBaseUrlForNodeName(s);
-        if(!allNodesOfColl.contains(s)){
-          theNode = n;
-          break;
-        }
-      }
-      log.info("thenode which does not serve this collection{} ",theNode);
-      assertNotNull(theNode);
-      httpSolrServer = new HttpSolrServer(theNode + "/"+collectionName);
-
-      q.setParam(CloudSolrServer.STATE_VERSION, collectionName+":"+coll.getZNodeVersion());
-
-      try {
-        httpSolrServer.query(q);
-        log.info("error was expected");
-      } catch (HttpSolrServer.RemoteSolrException e) {
-        sse = e;
-      }
-      httpSolrServer.shutdown();
-      assertNotNull(sse);
-      assertEquals(" Error code should be ",  sse.code() , SolrException.ErrorCode.INVALID_STATE.code);
-    } finally {
-      client.shutdown();
-    }
-
-  }
-
-  public void testShutdown() throws MalformedURLException {
-    CloudSolrServer server = new CloudSolrServer("[ff01::114]:33332");
-    try {
-      server.setZkConnectTimeout(100);
-      server.connect();
-      fail("Expected exception");
-    } catch (SolrException e) {
-      assertTrue(e.getCause() instanceof TimeoutException);
-    } finally {
-      server.shutdown();
-    }
-  }
-
-  public void testWrongZkChrootTest() throws MalformedURLException {
-    CloudSolrServer server = null;
-    try {
-      server = new CloudSolrServer(zkServer.getZkAddress() + "/xyz/foo");
-      server.setDefaultCollection(DEFAULT_COLLECTION);
-      server.setZkClientTimeout(1000*60);
-      server.connect();
-      fail("Expected exception");
-    } catch(SolrException e) {
-      assertTrue(e.getCause() instanceof KeeperException);
-    } finally {
-      server.shutdown();
-    }
-    // see SOLR-6146 - this test will fail by virtue of the zkClient tracking performed
-    // in the afterClass method of the base class
-  }
-
-  public void customHttpClientTest() {
-    CloudSolrServer server = null;
-    ModifiableSolrParams params = new ModifiableSolrParams();
-    params.set(HttpClientUtil.PROP_SO_TIMEOUT, 1000);
-    HttpClient client = null;
-
-    try {
-      client = HttpClientUtil.createClient(params);
-      server = new CloudSolrServer(zkServer.getZkAddress(), client);
-      assertTrue(server.getLbServer().getHttpClient() == client);
-    } finally {
-      server.shutdown();
-      client.getConnectionManager().shutdown();
-    }
-  }
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClientTest.java
new file mode 100644
index 0000000..77100ee
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrClientTest.java
@@ -0,0 +1,225 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.http.HttpResponse;
+import org.apache.solr.SolrJettyTestBase;
+import org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.util.SolrjNamedThreadFactory;
+import org.junit.BeforeClass;
+import org.junit.Test;
+
+import javax.servlet.ServletException;
+import javax.servlet.http.HttpServlet;
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+import java.io.EOFException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.Enumeration;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+public class ConcurrentUpdateSolrClientTest extends SolrJettyTestBase {
+
+  /**
+   * Mock endpoint where the CUSS being tested in this class sends requests.
+   */
+  public static class TestServlet extends HttpServlet 
+    implements JavaBinUpdateRequestCodec.StreamingUpdateHandler
+  {   
+    private static final long serialVersionUID = 1L;
+
+    public static void clear() {
+      lastMethod = null;
+      headers = null;
+      parameters = null;
+      errorCode = null;
+      numReqsRcvd.set(0);
+      numDocsRcvd.set(0);
+    }
+    
+    public static Integer errorCode = null;
+    public static String lastMethod = null;
+    public static HashMap<String,String> headers = null;
+    public static Map<String,String[]> parameters = null;
+    public static AtomicInteger numReqsRcvd = new AtomicInteger(0);
+    public static AtomicInteger numDocsRcvd = new AtomicInteger(0);
+    
+    public static void setErrorCode(Integer code) {
+      errorCode = code;
+    }
+        
+    private void setHeaders(HttpServletRequest req) {
+      Enumeration<String> headerNames = req.getHeaderNames();
+      headers = new HashMap<>();
+      while (headerNames.hasMoreElements()) {
+        final String name = headerNames.nextElement();
+        headers.put(name, req.getHeader(name));
+      }
+    }
+
+    private void setParameters(HttpServletRequest req) {
+      //parameters = req.getParameterMap();
+    }
+
+    @Override
+    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
+        throws ServletException, IOException {
+      
+      numReqsRcvd.incrementAndGet();
+      lastMethod = "post";
+      recordRequest(req, resp);
+            
+      InputStream reqIn = req.getInputStream();
+      JavaBinUpdateRequestCodec javabin = new JavaBinUpdateRequestCodec();
+      for (;;) {
+        try {
+          javabin.unmarshal(reqIn, this);
+        } catch (EOFException e) {
+          break; // this is expected
+        }
+      }      
+    }
+    
+    private void recordRequest(HttpServletRequest req, HttpServletResponse resp) {
+      setHeaders(req);
+      setParameters(req);
+      if (null != errorCode) {
+        try { 
+          resp.sendError(errorCode); 
+        } catch (IOException e) {
+          throw new RuntimeException("sendError IO fail in TestServlet", e);
+        }
+      }
+    }
+
+    @Override
+    public void update(SolrInputDocument document, UpdateRequest req, Integer commitWithin, Boolean override) {
+      numDocsRcvd.incrementAndGet();
+    }
+  } // end TestServlet
+  
+  @BeforeClass
+  public static void beforeTest() throws Exception {
+    createJetty(legacyExampleCollection1SolrHome(), null, null);
+    jetty.getDispatchFilter().getServletHandler()
+        .addServletWithMapping(TestServlet.class, "/cuss/*");
+  }
+  
+  @Test
+  public void testConcurrentUpdate() throws Exception {
+    TestServlet.clear();
+    
+    String serverUrl = jetty.getBaseUrl().toString() + "/cuss/foo";
+        
+    int cussThreadCount = 2;
+    int cussQueueSize = 100;
+    
+    // for tracking callbacks from CUSS
+    final AtomicInteger successCounter = new AtomicInteger(0);
+    final AtomicInteger errorCounter = new AtomicInteger(0);    
+    final StringBuilder errors = new StringBuilder();     
+    
+    @SuppressWarnings("serial")
+    ConcurrentUpdateSolrClient concurrentClient = new ConcurrentUpdateSolrClient(serverUrl, cussQueueSize, cussThreadCount) {
+      @Override
+      public void handleError(Throwable ex) {
+        errorCounter.incrementAndGet();
+        errors.append(" "+ex);
+      }
+      @Override
+      public void onSuccess(HttpResponse resp) {
+        successCounter.incrementAndGet();
+      }
+    };
+    
+    concurrentClient.setParser(new BinaryResponseParser());
+    concurrentClient.setRequestWriter(new BinaryRequestWriter());
+    concurrentClient.setPollQueueTime(0);
+    
+    // ensure it doesn't block where there's nothing to do yet
+    concurrentClient.blockUntilFinished();
+    
+    int poolSize = 5;
+    ExecutorService threadPool = Executors.newFixedThreadPool(poolSize, new SolrjNamedThreadFactory("testCUSS"));
+
+    int numDocs = 100;
+    int numRunnables = 5;
+    for (int r=0; r < numRunnables; r++)
+      threadPool.execute(new SendDocsRunnable(String.valueOf(r), numDocs, concurrentClient));
+    
+    // ensure all docs are sent
+    threadPool.awaitTermination(5, TimeUnit.SECONDS);
+    threadPool.shutdown();
+    
+    // wait until all requests are processed by CUSS 
+    concurrentClient.blockUntilFinished();
+    concurrentClient.shutdownNow();
+    
+    assertEquals("post", TestServlet.lastMethod);
+        
+    // expect all requests to be successful
+    int expectedSuccesses = TestServlet.numReqsRcvd.get();
+    assertTrue(expectedSuccesses > 0); // at least one request must have been sent
+    
+    assertTrue("Expected no errors but got "+errorCounter.get()+
+        ", due to: "+errors.toString(), errorCounter.get() == 0);
+    assertTrue("Expected "+expectedSuccesses+" successes, but got "+successCounter.get(), 
+        successCounter.get() == expectedSuccesses);
+    
+    int expectedDocs = numDocs * numRunnables;
+    assertTrue("Expected CUSS to send "+expectedDocs+" but got "+TestServlet.numDocsRcvd.get(), 
+        TestServlet.numDocsRcvd.get() == expectedDocs);
+  }
+  
+  class SendDocsRunnable implements Runnable {
+    
+    private String id;
+    private int numDocs;
+    private ConcurrentUpdateSolrClient cuss;
+    
+    SendDocsRunnable(String id, int numDocs, ConcurrentUpdateSolrClient cuss) {
+      this.id = id;
+      this.numDocs = numDocs;
+      this.cuss = cuss;
+    }
+
+    @Override
+    public void run() {
+      for (int d=0; d < numDocs; d++) {
+        SolrInputDocument doc = new SolrInputDocument();
+        String docId = id+"_"+d;
+        doc.setField("id", docId);    
+        UpdateRequest req = new UpdateRequest();
+        req.add(doc);        
+        try {
+          cuss.request(req);
+        } catch (Throwable t) {
+          t.printStackTrace();
+        }
+      }      
+    }    
+  }
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServerTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServerTest.java
deleted file mode 100644
index 05b6e36..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ConcurrentUpdateSolrServerTest.java
+++ /dev/null
@@ -1,227 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.solr.client.solrj.impl;
-
-import java.io.EOFException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicInteger;
-
-import javax.servlet.ServletException;
-import javax.servlet.http.HttpServlet;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-
-import org.apache.http.HttpResponse;
-import org.apache.solr.SolrJettyTestBase;
-import org.apache.solr.client.solrj.request.JavaBinUpdateRequestCodec;
-import org.apache.solr.client.solrj.request.UpdateRequest;
-import org.apache.solr.common.SolrInputDocument;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.apache.solr.util.ExternalPaths;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-public class ConcurrentUpdateSolrServerTest extends SolrJettyTestBase {
-
-  /**
-   * Mock endpoint where the CUSS being tested in this class sends requests.
-   */
-  public static class TestServlet extends HttpServlet 
-    implements JavaBinUpdateRequestCodec.StreamingUpdateHandler
-  {   
-    private static final long serialVersionUID = 1L;
-
-    public static void clear() {
-      lastMethod = null;
-      headers = null;
-      parameters = null;
-      errorCode = null;
-      numReqsRcvd.set(0);
-      numDocsRcvd.set(0);
-    }
-    
-    public static Integer errorCode = null;
-    public static String lastMethod = null;
-    public static HashMap<String,String> headers = null;
-    public static Map<String,String[]> parameters = null;
-    public static AtomicInteger numReqsRcvd = new AtomicInteger(0);
-    public static AtomicInteger numDocsRcvd = new AtomicInteger(0);
-    
-    public static void setErrorCode(Integer code) {
-      errorCode = code;
-    }
-        
-    private void setHeaders(HttpServletRequest req) {
-      Enumeration<String> headerNames = req.getHeaderNames();
-      headers = new HashMap<>();
-      while (headerNames.hasMoreElements()) {
-        final String name = headerNames.nextElement();
-        headers.put(name, req.getHeader(name));
-      }
-    }
-
-    private void setParameters(HttpServletRequest req) {
-      //parameters = req.getParameterMap();
-    }
-
-    @Override
-    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      
-      numReqsRcvd.incrementAndGet();
-      lastMethod = "post";
-      recordRequest(req, resp);
-            
-      InputStream reqIn = req.getInputStream();
-      JavaBinUpdateRequestCodec javabin = new JavaBinUpdateRequestCodec();
-      for (;;) {
-        try {
-          javabin.unmarshal(reqIn, this);
-        } catch (EOFException e) {
-          break; // this is expected
-        }
-      }      
-    }
-    
-    private void recordRequest(HttpServletRequest req, HttpServletResponse resp) {
-      setHeaders(req);
-      setParameters(req);
-      if (null != errorCode) {
-        try { 
-          resp.sendError(errorCode); 
-        } catch (IOException e) {
-          throw new RuntimeException("sendError IO fail in TestServlet", e);
-        }
-      }
-    }
-
-    @Override
-    public void update(SolrInputDocument document, UpdateRequest req, Integer commitWithin, Boolean override) {
-      numDocsRcvd.incrementAndGet();
-    }
-  } // end TestServlet
-  
-  @BeforeClass
-  public static void beforeTest() throws Exception {
-    createJetty(legacyExampleCollection1SolrHome(), null, null);
-    jetty.getDispatchFilter().getServletHandler()
-        .addServletWithMapping(TestServlet.class, "/cuss/*");
-  }
-  
-  @Test
-  public void testConcurrentUpdate() throws Exception {
-    TestServlet.clear();
-    
-    String serverUrl = jetty.getBaseUrl().toString() + "/cuss/foo";
-        
-    int cussThreadCount = 2;
-    int cussQueueSize = 100;
-    
-    // for tracking callbacks from CUSS
-    final AtomicInteger successCounter = new AtomicInteger(0);
-    final AtomicInteger errorCounter = new AtomicInteger(0);    
-    final StringBuilder errors = new StringBuilder();     
-    
-    @SuppressWarnings("serial")
-    ConcurrentUpdateSolrServer cuss = new ConcurrentUpdateSolrServer(serverUrl, cussQueueSize, cussThreadCount) {
-      @Override
-      public void handleError(Throwable ex) {
-        errorCounter.incrementAndGet();
-        errors.append(" "+ex);
-      }
-      @Override
-      public void onSuccess(HttpResponse resp) {
-        successCounter.incrementAndGet();
-      }
-    };
-    
-    cuss.setParser(new BinaryResponseParser());
-    cuss.setRequestWriter(new BinaryRequestWriter());
-    cuss.setPollQueueTime(0);
-    
-    // ensure it doesn't block where there's nothing to do yet
-    cuss.blockUntilFinished();
-    
-    int poolSize = 5;
-    ExecutorService threadPool = Executors.newFixedThreadPool(poolSize, new SolrjNamedThreadFactory("testCUSS"));
-
-    int numDocs = 100;
-    int numRunnables = 5;
-    for (int r=0; r < numRunnables; r++)
-      threadPool.execute(new SendDocsRunnable(String.valueOf(r), numDocs, cuss));
-    
-    // ensure all docs are sent
-    threadPool.awaitTermination(5, TimeUnit.SECONDS);
-    threadPool.shutdown();
-    
-    // wait until all requests are processed by CUSS 
-    cuss.blockUntilFinished();
-    cuss.shutdownNow();    
-    
-    assertEquals("post", TestServlet.lastMethod);
-        
-    // expect all requests to be successful
-    int expectedSuccesses = TestServlet.numReqsRcvd.get();
-    assertTrue(expectedSuccesses > 0); // at least one request must have been sent
-    
-    assertTrue("Expected no errors but got "+errorCounter.get()+
-        ", due to: "+errors.toString(), errorCounter.get() == 0);
-    assertTrue("Expected "+expectedSuccesses+" successes, but got "+successCounter.get(), 
-        successCounter.get() == expectedSuccesses);
-    
-    int expectedDocs = numDocs * numRunnables;
-    assertTrue("Expected CUSS to send "+expectedDocs+" but got "+TestServlet.numDocsRcvd.get(), 
-        TestServlet.numDocsRcvd.get() == expectedDocs);
-  }
-  
-  class SendDocsRunnable implements Runnable {
-    
-    private String id;
-    private int numDocs;
-    private ConcurrentUpdateSolrServer cuss;
-    
-    SendDocsRunnable(String id, int numDocs, ConcurrentUpdateSolrServer cuss) {
-      this.id = id;
-      this.numDocs = numDocs;
-      this.cuss = cuss;
-    }
-
-    @Override
-    public void run() {
-      for (int d=0; d < numDocs; d++) {
-        SolrInputDocument doc = new SolrInputDocument();
-        String docId = id+"_"+d;
-        doc.setField("id", docId);    
-        UpdateRequest req = new UpdateRequest();
-        req.add(doc);        
-        try {
-          cuss.request(req);
-        } catch (Throwable t) {
-          t.printStackTrace();
-        }
-      }      
-    }    
-  }
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ExternalHttpClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ExternalHttpClientTest.java
index 33bf059..99f7394 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ExternalHttpClientTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/ExternalHttpClientTest.java
@@ -26,7 +26,6 @@ import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.response.QueryResponse;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -36,15 +35,15 @@ public class ExternalHttpClientTest extends SolrJettyTestBase {
   public static void beforeTest() throws Exception {
     createJetty(legacyExampleCollection1SolrHome(), null, null);
     jetty.getDispatchFilter().getServletHandler()
-        .addServletWithMapping(BasicHttpSolrServerTest.SlowServlet.class, "/slow/*");
+        .addServletWithMapping(BasicHttpSolrClientTest.SlowServlet.class, "/slow/*");
   }
 
   /**
-   * The internal client created by HttpSolrServer is a SystemDefaultHttpClient
+   * The internal client created by HttpSolrClient is a SystemDefaultHttpClient
    * which takes care of merging request level params (such as timeout) with the
    * configured defaults.
    *
-   * However, if an external HttpClient is passed to HttpSolrServer,
+   * However, if an external HttpClient is passed to HttpSolrClient,
    * the logic in InternalHttpClient.executeMethod replaces the configured defaults
    * by request level params if they exist. That is why we must test a setting such
    * as timeout with an external client to assert that the defaults are indeed being
@@ -57,21 +56,21 @@ public class ExternalHttpClientTest extends SolrJettyTestBase {
     HttpClientBuilder builder = HttpClientBuilder.create();
     RequestConfig config = RequestConfig.custom().setSocketTimeout(2000).build();
     builder.setDefaultRequestConfig(config);
-    HttpSolrServer server = null;
+    HttpSolrClient solrClient = null;
     try (CloseableHttpClient httpClient = builder.build()) {
-      server = new HttpSolrServer(jetty.getBaseUrl().toString() +
+      solrClient = new HttpSolrClient(jetty.getBaseUrl().toString() +
           "/slow/foo", httpClient);
 
       SolrQuery q = new SolrQuery("*:*");
       try {
-        QueryResponse response = server.query(q, SolrRequest.METHOD.GET);
+        QueryResponse response = solrClient.query(q, SolrRequest.METHOD.GET);
         fail("No exception thrown.");
       } catch (SolrServerException e) {
         assertTrue(e.getMessage().contains("Timeout"));
       }
     } finally {
-      if (server != null) {
-        server.shutdown();
+      if (solrClient != null) {
+        solrClient.shutdown();
       }
     }
   }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrClientTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrClientTest.java
new file mode 100644
index 0000000..969b3a8
--- /dev/null
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrClientTest.java
@@ -0,0 +1,56 @@
+/**
+ * 
+ */
+package org.apache.solr.client.solrj.impl;
+
+import org.apache.solr.client.solrj.ResponseParser;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.junit.Test;
+
+import java.net.MalformedURLException;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/**
+ * Test the LBHttpSolrClient.
+ */
+public class LBHttpSolrClientTest {
+  
+  /**
+   * Test method for {@link LBHttpSolrClient#LBHttpSolrClient(org.apache.http.client.HttpClient, org.apache.solr.client.solrj.ResponseParser, java.lang.String[])}.
+   * 
+   * Validate that the parser passed in is used in the <code>HttpSolrClient</code> instances created.
+   * 
+   * @throws MalformedURLException If URL is invalid, no URL passed, so won't happen.
+   */
+  @Test
+  public void testLBHttpSolrClientHttpClientResponseParserStringArray() throws MalformedURLException {
+    LBHttpSolrClient testClient = new LBHttpSolrClient(HttpClientUtil.createClient(new ModifiableSolrParams()), (ResponseParser) null);
+    HttpSolrClient httpSolrClient = testClient.makeSolrClient("http://127.0.0.1:8080");
+    assertNull("Generated server should have null parser.", httpSolrClient.getParser());
+
+    ResponseParser parser = new BinaryResponseParser();
+    testClient = new LBHttpSolrClient(HttpClientUtil.createClient(new ModifiableSolrParams()), parser);
+    httpSolrClient = testClient.makeSolrClient("http://127.0.0.1:8080");
+    assertEquals("Invalid parser passed to generated server.", parser, httpSolrClient.getParser());
+  }
+  
+}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrServerTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrServerTest.java
deleted file mode 100644
index b1b1fa7..0000000
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/impl/LBHttpSolrServerTest.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/**
- * 
- */
-package org.apache.solr.client.solrj.impl;
-
-import static org.junit.Assert.*;
-
-import java.net.MalformedURLException;
-
-import org.apache.solr.client.solrj.ResponseParser;
-import org.junit.Test;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.solr.common.params.ModifiableSolrParams;
-
-/**
- * Test the LBHttpSolrServer.
- */
-public class LBHttpSolrServerTest {
-  
-  /**
-   * Test method for {@link org.apache.solr.client.solrj.impl.LBHttpSolrServer#LBHttpSolrServer(org.apache.http.client.HttpClient, org.apache.solr.client.solrj.ResponseParser, java.lang.String[])}.
-   * 
-   * Validate that the parser passed in is used in the <code>HttpSolrServer</code> instances created.
-   * 
-   * @throws MalformedURLException If URL is invalid, no URL passed, so won't happen.
-   */
-  @Test
-  public void testLBHttpSolrServerHttpClientResponseParserStringArray() throws MalformedURLException {
-    LBHttpSolrServer testServer = new LBHttpSolrServer(HttpClientUtil.createClient(new ModifiableSolrParams()), (ResponseParser) null);
-    HttpSolrServer httpServer = testServer.makeServer("http://127.0.0.1:8080");
-    assertNull("Generated server should have null parser.", httpServer.getParser());
-
-    ResponseParser parser = new BinaryResponseParser();
-    testServer = new LBHttpSolrServer(HttpClientUtil.createClient(new ModifiableSolrParams()), parser);
-    httpServer = testServer.makeServer("http://127.0.0.1:8080");
-    assertEquals("Invalid parser passed to generated server.", parser, httpServer.getParser());
-  }
-  
-}
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/request/SolrPingTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/request/SolrPingTest.java
index d568a4e..5178438 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/request/SolrPingTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/request/SolrPingTest.java
@@ -52,8 +52,8 @@ public class SolrPingTest extends SolrJettyTestBase {
     SolrInputDocument doc = new SolrInputDocument();
     doc.setField("id", 1);
     doc.setField("terms_s", "samsung");
-    getSolrServer().add(doc);
-    getSolrServer().commit(true, true);
+    getSolrClient().add(doc);
+    getSolrClient().commit(true, true);
   }
   
   @Test
@@ -61,9 +61,9 @@ public class SolrPingTest extends SolrJettyTestBase {
     SolrPing ping = new SolrPing();
     SolrPingResponse rsp = null;
     ping.setActionEnable();
-    ping.process(getSolrServer());
+    ping.process(getSolrClient());
     ping.removeAction();
-    rsp = ping.process(getSolrServer());
+    rsp = ping.process(getSolrClient());
     Assert.assertNotNull(rsp);
   }
   
@@ -73,12 +73,12 @@ public class SolrPingTest extends SolrJettyTestBase {
     SolrPingResponse rsp = null;
     ping.setActionDisable();
     try {
-      ping.process(getSolrServer());
+      ping.process(getSolrClient());
     } catch (Exception e) {
       throw new Exception("disable action failed!");
     }
     ping.setActionPing();
-    rsp = ping.process(getSolrServer());
+    rsp = ping.process(getSolrClient());
     // the above line should fail with a 503 SolrException.
     Assert.assertNotNull(rsp);
   }
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestCoreAdmin.java b/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestCoreAdmin.java
index 0c71a67..e187e63 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestCoreAdmin.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/request/TestCoreAdmin.java
@@ -17,16 +17,12 @@
 
 package org.apache.solr.client.solrj.request;
 
-import static org.hamcrest.CoreMatchers.notNullValue;
-import static org.hamcrest.core.Is.is;
-
-import java.io.File;
-
+import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;
+import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.TestUtil;
 import org.apache.solr.SolrIgnoredThreadsFilter;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.AbstractEmbeddedSolrServerTestCase;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.response.CoreAdminResponse;
@@ -43,8 +39,10 @@ import org.junit.rules.TestRule;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.carrotsearch.randomizedtesting.annotations.ThreadLeakFilters;
-import com.carrotsearch.randomizedtesting.rules.SystemPropertiesRestoreRule;
+import java.io.File;
+
+import static org.hamcrest.CoreMatchers.notNullValue;
+import static org.hamcrest.core.Is.is;
 
 @ThreadLeakFilters(defaultFilters = true, filters = {SolrIgnoredThreadsFilter.class})
 public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
@@ -68,14 +66,14 @@ public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
     return solrXml;
   }
   
-  protected SolrServer getSolrAdmin() {
+  protected SolrClient getSolrAdmin() {
     return new EmbeddedSolrServer(cores, "core0");
   }
 
   @Test
   public void testConfigSet() throws Exception {
 
-    SolrServer server = getSolrAdmin();
+    SolrClient client = getSolrAdmin();
     File testDir = createTempDir(LuceneTestCase.getTestClass().getSimpleName()).toFile();
 
     File newCoreInstanceDir = new File(testDir, "newcore");
@@ -85,7 +83,7 @@ public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
     req.setInstanceDir(newCoreInstanceDir.getAbsolutePath());
     req.setConfigSet("configset-2");
 
-    CoreAdminResponse response = req.process(server);
+    CoreAdminResponse response = req.process(client);
     assertThat((String) response.getResponse().get("core"), is("corewithconfigset"));
 
     try (SolrCore core = cores.getCore("corewithconfigset")) {
@@ -97,7 +95,7 @@ public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
   @Test
   public void testCustomUlogDir() throws Exception {
     
-    SolrServer server = getSolrAdmin();
+    SolrClient client = getSolrAdmin();
     
     File dataDir = createTempDir("data").toFile();
     
@@ -116,7 +114,7 @@ public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
     // These should be the inverse of defaults.
     req.setIsLoadOnStartup(false);
     req.setIsTransient(true);
-    req.process(server);
+    req.process(client);
 
     // Show that the newly-created core has values for load on startup and transient different than defaults due to the
     // above.
@@ -134,7 +132,7 @@ public class TestCoreAdmin extends AbstractEmbeddedSolrServerTestCase {
     }
 
     assertEquals(new File(dataDir, "ulog" + File.separator + "tlog").getAbsolutePath(), logDir.getAbsolutePath());
-    server.shutdown();
+    client.shutdown();
     
   }
   
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/response/NoOpResponseParserTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/response/NoOpResponseParserTest.java
index d82395a..3f2b216 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/response/NoOpResponseParserTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/response/NoOpResponseParserTest.java
@@ -18,13 +18,12 @@ package org.apache.solr.client.solrj.response;
  */
 
 import org.apache.commons.io.IOUtils;
-import org.apache.lucene.util.LuceneTestCase;
 import org.apache.solr.SolrJettyTestBase;
 import org.apache.solr.client.solrj.ResponseParser;
 import org.apache.solr.client.solrj.SolrQuery;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.impl.NoOpResponseParser;
 import org.apache.solr.client.solrj.impl.XMLResponseParser;
 import org.apache.solr.client.solrj.request.QueryRequest;
@@ -32,7 +31,6 @@ import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.core.SolrResourceLoader;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -63,11 +61,11 @@ public class NoOpResponseParserTest extends SolrJettyTestBase {
   @Before
   public void doBefore() throws IOException, SolrServerException {
     //add document and commit, and ensure it's there
-    SolrServer server1 = getSolrServer();
+    SolrClient client = getSolrClient();
     SolrInputDocument doc = new SolrInputDocument();
     doc.addField("id", "1234");
-    server1.add(doc);
-    server1.commit();
+    client.add(doc);
+    client.commit();
   }
 
   /**
@@ -75,15 +73,15 @@ public class NoOpResponseParserTest extends SolrJettyTestBase {
    */
   @Test
   public void testQueryParse() throws Exception {
-    HttpSolrServer server = (HttpSolrServer) createNewSolrServer();
+    HttpSolrClient client = (HttpSolrClient) createNewSolrClient();
     SolrQuery query = new SolrQuery("id:1234");
     QueryRequest req = new QueryRequest(query);
-    server.setParser(new NoOpResponseParser());
-    NamedList<Object> resp = server.request(req);
+    client.setParser(new NoOpResponseParser());
+    NamedList<Object> resp = client.request(req);
     String responseString = (String) resp.get("response");
 
     assertResponse(responseString);
-    server.shutdown();
+    client.shutdown();
   }
 
   private void assertResponse(String responseString) throws IOException {
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java b/solr/solrj/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
index b6769a1..7a86fc7 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/response/TermsResponseTest.java
@@ -24,7 +24,6 @@ import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.response.TermsResponse.Term;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.Before;
 import org.junit.BeforeClass;
 import org.junit.Test;
@@ -53,8 +52,8 @@ public class TermsResponseTest extends SolrJettyTestBase {
     SolrInputDocument doc = new SolrInputDocument();
     doc.setField("id", 1);
     doc.setField("terms_s", "samsung");
-    getSolrServer().add(doc);
-    getSolrServer().commit(true, true);
+    getSolrClient().add(doc);
+    getSolrClient().commit(true, true);
 
     SolrQuery query = new SolrQuery();
     query.setRequestHandler("/terms");
@@ -66,7 +65,7 @@ public class TermsResponseTest extends SolrJettyTestBase {
     query.setTermsMinCount(1);
     
     QueryRequest request = new QueryRequest(query);
-    List<Term> terms = request.process(getSolrServer()).getTermsResponse().getTerms("terms_s");
+    List<Term> terms = request.process(getSolrClient()).getTermsResponse().getTerms("terms_s");
 
     Assert.assertNotNull(terms);
     Assert.assertEquals(terms.size(), 1);
diff --git a/solr/solrj/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java b/solr/solrj/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
index a666c79..e7780f6 100644
--- a/solr/solrj/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
+++ b/solr/solrj/src/test/org/apache/solr/client/solrj/response/TestSpellCheckResponse.java
@@ -25,7 +25,6 @@ import org.apache.solr.client.solrj.response.SpellCheckResponse.Correction;
 import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.params.CommonParams;
 import org.apache.solr.common.params.SpellingParams;
-import org.apache.solr.util.ExternalPaths;
 import org.junit.BeforeClass;
 import org.junit.Test;
 
@@ -47,34 +46,34 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
 
   @Test
   public void testSpellCheckResponse() throws Exception {
-    getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit(true, true);
+    getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit(true, true);
     SolrInputDocument doc = new SolrInputDocument();
     doc.setField("id", "111");
     doc.setField(field, "Samsung");
-    server.add(doc);
-    server.commit(true, true);
+    client.add(doc);
+    client.commit(true, true);
 
     SolrQuery query = new SolrQuery("*:*");
     query.set(CommonParams.QT, "/spell");
     query.set("spellcheck", true);
     query.set(SpellingParams.SPELLCHECK_Q, "samsang");
     QueryRequest request = new QueryRequest(query);
-    SpellCheckResponse response = request.process(server).getSpellCheckResponse();
+    SpellCheckResponse response = request.process(client).getSpellCheckResponse();
     Assert.assertEquals("samsung", response.getFirstSuggestion("samsang"));
   }
 
   @Test
   public void testSpellCheckResponse_Extended() throws Exception {
-    getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit(true, true);
+    getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit(true, true);
     SolrInputDocument doc = new SolrInputDocument();
     doc.setField("id", "111");
     doc.setField(field, "Samsung");
-    server.add(doc);
-    server.commit(true, true);
+    client.add(doc);
+    client.commit(true, true);
 
     SolrQuery query = new SolrQuery("*:*");
     query.set(CommonParams.QT, "/spell");
@@ -82,7 +81,7 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
     query.set(SpellingParams.SPELLCHECK_Q, "samsang");
     query.set(SpellingParams.SPELLCHECK_EXTENDED_RESULTS, true);
     QueryRequest request = new QueryRequest(query);
-    SpellCheckResponse response = request.process(server).getSpellCheckResponse();
+    SpellCheckResponse response = request.process(client).getSpellCheckResponse();
     assertEquals("samsung", response.getFirstSuggestion("samsang"));
 
     SpellCheckResponse.Suggestion sug = response.getSuggestion("samsang");
@@ -106,30 +105,30 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
   
   @Test
   public void testSpellCheckCollationResponse() throws Exception {
-    getSolrServer();
-    server.deleteByQuery("*:*");
-    server.commit(true, true);
+    getSolrClient();
+    client.deleteByQuery("*:*");
+    client.commit(true, true);
     SolrInputDocument doc = new SolrInputDocument();
     doc.setField("id", "0");
     doc.setField("name", "faith hope and love");
-    server.add(doc);
+    client.add(doc);
     doc = new SolrInputDocument();
     doc.setField("id", "1");
     doc.setField("name", "faith hope and loaves");
-    server.add(doc);
+    client.add(doc);
     doc = new SolrInputDocument();
     doc.setField("id", "2");
     doc.setField("name", "fat hops and loaves");
-    server.add(doc);
+    client.add(doc);
     doc = new SolrInputDocument();
     doc.setField("id", "3");
     doc.setField("name", "faith of homer");
-    server.add(doc);
+    client.add(doc);
     doc = new SolrInputDocument();
     doc.setField("id", "4");
     doc.setField("name", "fat of homer");
-    server.add(doc);    
-    server.commit(true, true);
+    client.add(doc);
+    client.commit(true, true);
      
     //Test Backwards Compatibility
     SolrQuery query = new SolrQuery("name:(+fauth +home +loane)");
@@ -138,8 +137,8 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
     query.set(SpellingParams.SPELLCHECK_COUNT, 10);
     query.set(SpellingParams.SPELLCHECK_COLLATE, true);
     QueryRequest request = new QueryRequest(query);
-    SpellCheckResponse response = request.process(server).getSpellCheckResponse();
-    response = request.process(server).getSpellCheckResponse();
+    SpellCheckResponse response = request.process(client).getSpellCheckResponse();
+    response = request.process(client).getSpellCheckResponse();
     assertTrue("name:(+faith +hope +loaves)".equals(response.getCollatedResult()));
     
     //Test Expanded Collation Results
@@ -147,7 +146,7 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
     query.set(SpellingParams.SPELLCHECK_MAX_COLLATION_TRIES, 10);
     query.set(SpellingParams.SPELLCHECK_MAX_COLLATIONS, 2); 
     request = new QueryRequest(query);
-    response = request.process(server).getSpellCheckResponse();
+    response = request.process(client).getSpellCheckResponse();
     assertTrue("name:(+faith +hope +love)".equals(response.getCollatedResult()) || "name:(+faith +hope +loaves)".equals(response.getCollatedResult()));
     
     List<Collation> collations = response.getCollatedResults();
@@ -178,7 +177,7 @@ public class TestSpellCheckResponse extends SolrJettyTestBase {
     }
     
     query.set(SpellingParams.SPELLCHECK_COLLATE_EXTENDED_RESULTS, false);
-    response = request.process(server).getSpellCheckResponse();
+    response = request.process(client).getSpellCheckResponse();
     {
       collations = response.getCollatedResults();
       assertEquals(2, collations.size());
diff --git a/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java b/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
index 13a96fe..244649b8 100644
--- a/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
+++ b/solr/test-framework/src/java/org/apache/solr/BaseDistributedSearchTestCase.java
@@ -17,31 +17,15 @@ package org.apache.solr;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collections;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.Set;
-import java.util.SortedMap;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import junit.framework.Assert;
-
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.Constants;
 import org.apache.lucene.util.TestUtil;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrResponse;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.QueryResponse;
 import org.apache.solr.client.solrj.response.UpdateResponse;
@@ -59,6 +43,21 @@ import org.junit.Test;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.File;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.SortedMap;
+import java.util.concurrent.atomic.AtomicInteger;
+
 /**
  * Helper base class for distributed search test cases
  *
@@ -185,7 +184,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
   protected boolean fixShardCount = false;
 
   protected JettySolrRunner controlJetty;
-  protected List<SolrServer> clients = new ArrayList<>();
+  protected List<SolrClient> clients = new ArrayList<>();
   protected List<JettySolrRunner> jettys = new ArrayList<>();
   
   protected String context;
@@ -193,7 +192,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
   protected String shards;
   protected String[] shardsArr;
   protected File testDir;
-  protected SolrServer controlClient;
+  protected SolrClient controlClient;
 
   // to stress with higher thread counts and requests, make sure the junit
   // xml formatter is not being used (all output will be buffered before
@@ -293,7 +292,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
   protected void createServers(int numShards) throws Exception {
     controlJetty = createControlJetty();
 
-    controlClient = createNewSolrServer(controlJetty.getLocalPort());
+    controlClient = createNewSolrClient(controlJetty.getLocalPort());
 
     shardsArr = new String[numShards];
     StringBuilder sb = new StringBuilder();
@@ -303,7 +302,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
           testDir + "/shard" + i + "/data", null, getSolrConfigFile(),
           getSchemaFile());
       jettys.add(j);
-      clients.add(createNewSolrServer(j.getLocalPort()));
+      clients.add(createNewSolrClient(j.getLocalPort()));
       String shardStr = buildUrl(j.getLocalPort());
       shardsArr[i] = shardStr;
       sb.append(shardStr);
@@ -342,9 +341,9 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
 
   protected void destroyServers() throws Exception {
     controlJetty.stop();
-    ((HttpSolrServer) controlClient).shutdown();
+    ((HttpSolrClient) controlClient).shutdown();
     for (JettySolrRunner jetty : jettys) jetty.stop();
-    for (SolrServer client : clients) ((HttpSolrServer) client).shutdown();
+    for (SolrClient client : clients) ((HttpSolrClient) client).shutdown();
     clients.clear();
     jettys.clear();
   }
@@ -387,15 +386,15 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
     return null;
   }
 
-  protected SolrServer createNewSolrServer(int port) {
+  protected SolrClient createNewSolrClient(int port) {
     try {
-      // setup the server...
-      HttpSolrServer s = new HttpSolrServer(buildUrl(port));
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setSoTimeout(90000);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      // setup the client...
+      HttpSolrClient client = new HttpSolrClient(buildUrl(port));
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setSoTimeout(90000);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     }
     catch (Exception ex) {
       throw new RuntimeException(ex);
@@ -438,7 +437,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
     controlClient.add(doc);
 
     int which = (doc.getField(id).toString().hashCode() & 0x7fffffff) % clients.size();
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     client.add(doc);
   }
   
@@ -446,38 +445,38 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
    * Indexes the document in both the control client and the specified client asserting
    * that the respones are equivilent
    */
-  protected UpdateResponse indexDoc(SolrServer server, SolrParams params, SolrInputDocument... sdocs) throws IOException, SolrServerException {
+  protected UpdateResponse indexDoc(SolrClient client, SolrParams params, SolrInputDocument... sdocs) throws IOException, SolrServerException {
     UpdateResponse controlRsp = add(controlClient, params, sdocs);
-    UpdateResponse specificRsp = add(server, params, sdocs);
+    UpdateResponse specificRsp = add(client, params, sdocs);
     compareSolrResponses(specificRsp, controlRsp);
     return specificRsp;
   }
 
-  protected UpdateResponse add(SolrServer server, SolrParams params, SolrInputDocument... sdocs) throws IOException, SolrServerException {
+  protected UpdateResponse add(SolrClient client, SolrParams params, SolrInputDocument... sdocs) throws IOException, SolrServerException {
     UpdateRequest ureq = new UpdateRequest();
     ureq.setParams(new ModifiableSolrParams(params));
     for (SolrInputDocument sdoc : sdocs) {
       ureq.add(sdoc);
     }
-    return ureq.process(server);
+    return ureq.process(client);
   }
 
-  protected UpdateResponse del(SolrServer server, SolrParams params, Object... ids) throws IOException, SolrServerException {
+  protected UpdateResponse del(SolrClient client, SolrParams params, Object... ids) throws IOException, SolrServerException {
     UpdateRequest ureq = new UpdateRequest();
     ureq.setParams(new ModifiableSolrParams(params));
     for (Object id: ids) {
       ureq.deleteById(id.toString());
     }
-    return ureq.process(server);
+    return ureq.process(client);
   }
 
-  protected UpdateResponse delQ(SolrServer server, SolrParams params, String... queries) throws IOException, SolrServerException {
+  protected UpdateResponse delQ(SolrClient client, SolrParams params, String... queries) throws IOException, SolrServerException {
     UpdateRequest ureq = new UpdateRequest();
     ureq.setParams(new ModifiableSolrParams(params));
     for (String q: queries) {
       ureq.deleteByQuery(q);
     }
-    return ureq.process(server);
+    return ureq.process(client);
   }
 
   protected void index_specific(int serverNumber, Object... fields) throws Exception {
@@ -487,20 +486,20 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
     }
     controlClient.add(doc);
 
-    SolrServer client = clients.get(serverNumber);
+    SolrClient client = clients.get(serverNumber);
     client.add(doc);
   }
 
   protected void del(String q) throws Exception {
     controlClient.deleteByQuery(q);
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       client.deleteByQuery(q);
     }
   }// serial commit...
 
   protected void commit() throws Exception {
     controlClient.commit();
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       client.commit();
     }
   }
@@ -508,7 +507,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
   protected QueryResponse queryServer(ModifiableSolrParams params) throws SolrServerException {
     // query a random server
     int which = r.nextInt(clients.size());
-    SolrServer client = clients.get(which);
+    SolrClient client = clients.get(which);
     QueryResponse rsp = client.query(params);
     return rsp;
   }
@@ -570,7 +569,7 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
           public void run() {
             for (int j = 0; j < stress; j++) {
               int which = r.nextInt(clients.size());
-              SolrServer client = clients.get(which);
+              SolrClient client = clients.get(which);
               try {
                 QueryResponse rsp = client.query(new ModifiableSolrParams(params));
                 if (verifyStress) {
@@ -592,13 +591,13 @@ public abstract class BaseDistributedSearchTestCase extends SolrTestCaseJ4 {
     return rsp;
   }
   
-  public QueryResponse queryAndCompare(SolrParams params, SolrServer... servers) throws SolrServerException {
-    return queryAndCompare(params, Arrays.<SolrServer>asList(servers));
+  public QueryResponse queryAndCompare(SolrParams params, SolrClient... clients) throws SolrServerException {
+    return queryAndCompare(params, Arrays.<SolrClient>asList(clients));
   }
-  public QueryResponse queryAndCompare(SolrParams params, Iterable<SolrServer> servers) throws SolrServerException {
+  public QueryResponse queryAndCompare(SolrParams params, Iterable<SolrClient> clients) throws SolrServerException {
     QueryResponse first = null;
-    for (SolrServer server : servers) {
-      QueryResponse rsp = server.query(new ModifiableSolrParams(params));
+    for (SolrClient client : clients) {
+      QueryResponse rsp = client.query(new ModifiableSolrParams(params));
       if (first == null) {
         first = rsp;
       } else {
diff --git a/solr/test-framework/src/java/org/apache/solr/SolrJettyTestBase.java b/solr/test-framework/src/java/org/apache/solr/SolrJettyTestBase.java
index cb2e7ae..a33a938 100644
--- a/solr/test-framework/src/java/org/apache/solr/SolrJettyTestBase.java
+++ b/solr/test-framework/src/java/org/apache/solr/SolrJettyTestBase.java
@@ -17,19 +17,12 @@ package org.apache.solr;
  * limitations under the License.
  */
 
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.FileWriter;
-import java.io.OutputStreamWriter;
-import java.util.Properties;
-import java.util.SortedMap;
-
 import org.apache.commons.io.FileUtils;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.EmbeddedSolrServer;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.util.ExternalPaths;
 import org.eclipse.jetty.servlet.ServletHolder;
 import org.junit.AfterClass;
@@ -37,6 +30,11 @@ import org.junit.BeforeClass;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.File;
+import java.io.OutputStreamWriter;
+import java.util.Properties;
+import java.util.SortedMap;
+
 
 abstract public class SolrJettyTestBase extends SolrTestCaseJ4 
 {
@@ -50,7 +48,7 @@ abstract public class SolrJettyTestBase extends SolrTestCaseJ4
 
   public static JettySolrRunner jetty;
   public static int port;
-  public static SolrServer server = null;
+  public static SolrClient client = null;
   public static String context;
 
   public static JettySolrRunner createJetty(String solrHome, String configFile, String schemaFile, String context,
@@ -87,36 +85,36 @@ abstract public class SolrJettyTestBase extends SolrTestCaseJ4
       jetty.stop();
       jetty = null;
     }
-    if (server != null) server.shutdown();
-    server = null;
+    if (client != null) client.shutdown();
+    client = null;
   }
 
 
-  public SolrServer getSolrServer() {
+  public SolrClient getSolrClient() {
     {
-      if (server == null) {
-        server = createNewSolrServer();
+      if (client == null) {
+        client = createNewSolrClient();
       }
-      return server;
+      return client;
     }
   }
 
   /**
-   * Create a new solr server.
+   * Create a new solr client.
    * If createJetty was called, an http implementation will be created,
    * otherwise an embedded implementation will be created.
    * Subclasses should override for other options.
    */
-  public SolrServer createNewSolrServer() {
+  public SolrClient createNewSolrClient() {
     if (jetty != null) {
       try {
-        // setup the server...
+        // setup the client...
         String url = jetty.getBaseUrl().toString() + "/" + "collection1";
-        HttpSolrServer s = new HttpSolrServer( url );
-        s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-        s.setDefaultMaxConnectionsPerHost(100);
-        s.setMaxTotalConnections(100);
-        return s;
+        HttpSolrClient client = new HttpSolrClient( url );
+        client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+        client.setDefaultMaxConnectionsPerHost(100);
+        client.setMaxTotalConnections(100);
+        return client;
       }
       catch( Exception ex ) {
         throw new RuntimeException( ex );
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractDistribZkTestBase.java b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractDistribZkTestBase.java
index 5c36fb4..1098ca5 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractDistribZkTestBase.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractDistribZkTestBase.java
@@ -102,7 +102,7 @@ public abstract class AbstractDistribZkTestBase extends BaseDistributedSearchTes
       System.clearProperty(ZkStateReader.NUM_SHARDS_PROP);
     }
 
-    controlClient = createNewSolrServer(controlJetty.getLocalPort());
+    controlClient = createNewSolrClient(controlJetty.getLocalPort());
 
     StringBuilder sb = new StringBuilder();
     for (int i = 1; i <= numShards; i++) {
@@ -112,7 +112,7 @@ public abstract class AbstractDistribZkTestBase extends BaseDistributedSearchTes
       setupJettySolrHome(jettyHome);
       JettySolrRunner j = createJetty(jettyHome, null, "shard" + (i + 2));
       jettys.add(j);
-      clients.add(createNewSolrServer(j.getLocalPort()));
+      clients.add(createNewSolrClient(j.getLocalPort()));
       sb.append(buildUrl(j.getLocalPort()));
     }
 
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
index 9a59b8f..35a3d39 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/AbstractFullDistribZkTestBase.java
@@ -17,40 +17,16 @@ package org.apache.solr.cloud;
  * limitations under the License.
  */
 
-import static org.apache.solr.cloud.OverseerCollectionProcessor.CREATE_NODE_SET;
-import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
-import static org.apache.solr.cloud.OverseerCollectionProcessor.SHARDS_PROP;
-import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
-import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
-import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.ServerSocket;
-import java.net.URI;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Random;
-import java.util.Set;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import org.apache.commons.io.FilenameUtils;
 import org.apache.http.params.CoreConnectionPNames;
 import org.apache.lucene.util.LuceneTestCase.Slow;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrQuery;
 import org.apache.solr.client.solrj.SolrRequest;
-import org.apache.solr.client.solrj.SolrServer;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
-import org.apache.solr.client.solrj.impl.CloudSolrServer;
-import org.apache.solr.client.solrj.impl.HttpSolrServer;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
 import org.apache.solr.client.solrj.request.QueryRequest;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.client.solrj.response.CollectionAdminResponse;
@@ -88,6 +64,30 @@ import org.noggit.JSONWriter;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.io.File;
+import java.io.IOException;
+import java.net.ServerSocket;
+import java.net.URI;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Map.Entry;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.atomic.AtomicInteger;
+
+import static org.apache.solr.cloud.OverseerCollectionProcessor.CREATE_NODE_SET;
+import static org.apache.solr.cloud.OverseerCollectionProcessor.NUM_SLICES;
+import static org.apache.solr.cloud.OverseerCollectionProcessor.SHARDS_PROP;
+import static org.apache.solr.common.cloud.ZkNodeProps.makeMap;
+import static org.apache.solr.common.cloud.ZkStateReader.MAX_SHARDS_PER_NODE;
+import static org.apache.solr.common.cloud.ZkStateReader.REPLICATION_FACTOR;
+
 /**
  * TODO: we should still test this works as a custom update chain as well as
  * what we test now - the default update chain
@@ -115,8 +115,8 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   String missingField = "ignore_exception__missing_but_valid_field_t";
   protected int sliceCount;
 
-  protected CloudSolrServer controlClientCloud;  // cloud version of the control client
-  protected volatile CloudSolrServer cloudClient;
+  protected CloudSolrClient controlClientCloud;  // cloud version of the control client
+  protected volatile CloudSolrClient cloudClient;
   
   protected List<CloudJettyRunner> cloudJettys = new ArrayList<>();
   protected Map<String,List<CloudJettyRunner>> shardToJetty = new HashMap<>();
@@ -162,14 +162,14 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   }
   
   static class CloudSolrServerClient {
-    SolrServer solrClient;
+    SolrClient solrClient;
     String shardName;
     int port;
     public ZkNodeProps info;
     
     public CloudSolrServerClient() {}
     
-    public CloudSolrServerClient(SolrServer client) {
+    public CloudSolrServerClient(SolrClient client) {
       this.solrClient = client;
     }
     
@@ -259,13 +259,13 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
         shardToJetty, shardToLeaderJetty);
   }
   
-  protected CloudSolrServer createCloudClient(String defaultCollection) {
-    CloudSolrServer server = new CloudSolrServer(zkServer.getZkAddress(), random().nextBoolean());
-    server.setParallelUpdates(random().nextBoolean());
-    if (defaultCollection != null) server.setDefaultCollection(defaultCollection);
-    server.getLbServer().getHttpClient().getParams()
+  protected CloudSolrClient createCloudClient(String defaultCollection) {
+    CloudSolrClient client = new CloudSolrClient(zkServer.getZkAddress(), random().nextBoolean());
+    client.setParallelUpdates(random().nextBoolean());
+    if (defaultCollection != null) client.setDefaultCollection(defaultCollection);
+    client.getLbClient().getHttpClient().getParams()
         .setParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, 30000);
-    return server;
+    return client;
   }
   
   @Override
@@ -287,7 +287,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
                                // "shard1"
 
 
-      controlClient = createNewSolrServer(controlJetty.getLocalPort());
+      controlClient = createNewSolrClient(controlJetty.getLocalPort());
       
       if (sliceCount <= 0) {
         // for now, just create the cloud client for the control if we don't
@@ -372,7 +372,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
    */
   protected List<JettySolrRunner> createJettys(int numJettys, boolean checkCreatedVsState) throws Exception {
     List<JettySolrRunner> jettys = new ArrayList<>();
-    List<SolrServer> clients = new ArrayList<>();
+    List<SolrClient> clients = new ArrayList<>();
     StringBuilder sb = new StringBuilder();
 
     if (getStateFormat() == 2) {
@@ -399,7 +399,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
       JettySolrRunner j = createJetty(jettyDir, useJettyDataDir ? getDataDir(testDir + "/jetty"
           + cnt) : null, null, "solrconfig.xml", null);
       jettys.add(j);
-      SolrServer client = createNewSolrServer(j.getLocalPort());
+      SolrClient client = createNewSolrClient(j.getLocalPort());
       clients.add(client);
     }
   
@@ -447,7 +447,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   }
 
 
-  protected SolrServer startCloudJetty(String collection, String shard) throws Exception {
+  protected SolrClient startCloudJetty(String collection, String shard) throws Exception {
     // TODO: use the collection string!!!!
     collection = DEFAULT_COLLECTION;
 
@@ -461,7 +461,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
       org.apache.commons.io.FileUtils.copyDirectory(new File(getSolrHome()), jettyDir);
       JettySolrRunner j = createJetty(jettyDir, testDir + "/jetty" + cnt, shard, "solrconfig.xml", null);
       jettys.add(j);
-      SolrServer client = createNewSolrServer(j.getLocalPort());
+      SolrClient client = createNewSolrClient(j.getLocalPort());
       clients.add(client);
 
     int retries = 60;
@@ -628,11 +628,11 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     return solrHome;
   }
   
-  protected void updateMappingsFromZk(List<JettySolrRunner> jettys, List<SolrServer> clients) throws Exception {
+  protected void updateMappingsFromZk(List<JettySolrRunner> jettys, List<SolrClient> clients) throws Exception {
     updateMappingsFromZk(jettys, clients, false);
   }
   
-  protected void updateMappingsFromZk(List<JettySolrRunner> jettys, List<SolrServer> clients, boolean allowOverSharding) throws Exception {
+  protected void updateMappingsFromZk(List<JettySolrRunner> jettys, List<SolrClient> clients, boolean allowOverSharding) throws Exception {
     ZkStateReader zkStateReader = cloudClient.getZkStateReader();
     zkStateReader.updateClusterState(true);
     cloudJettys.clear();
@@ -642,13 +642,13 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     DocCollection coll = clusterState.getCollection(DEFAULT_COLLECTION);
 
     List<CloudSolrServerClient> theClients = new ArrayList<>();
-    for (SolrServer client : clients) {
+    for (SolrClient client : clients) {
       // find info for this client in zk 
       nextClient:
       // we find out state by simply matching ports...
       for (Slice slice : coll.getSlices()) {
         for (Replica replica : slice.getReplicas()) {
-          int port = new URI(((HttpSolrServer) client).getBaseURL())
+          int port = new URI(((HttpSolrClient) client).getBaseURL())
               .getPort();
           
           if (replica.getStr(ZkStateReader.BASE_URL_PROP).contains(":" + port)) {
@@ -783,7 +783,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     }
     controlClient.add(doc);
     
-    HttpSolrServer client = (HttpSolrServer) clients
+    HttpSolrClient client = (HttpSolrClient) clients
         .get(serverNumber);
     
     UpdateRequest ureq = new UpdateRequest();
@@ -792,7 +792,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     ureq.process(client);
   }
   
-  protected void index_specific(SolrServer client, Object... fields)
+  protected void index_specific(SolrClient client, Object... fields)
       throws Exception {
     SolrInputDocument doc = new SolrInputDocument();
     for (int i = 0; i < fields.length; i += 2) {
@@ -1025,7 +1025,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   public QueryResponse queryAndCompareReplicas(SolrParams params, String shard) 
     throws Exception {
 
-    ArrayList<SolrServer> shardClients = new ArrayList<>(7);
+    ArrayList<SolrClient> shardClients = new ArrayList<>(7);
 
     updateMappingsFromZk(jettys, clients);
     ZkStateReader zkStateReader = cloudClient.getZkStateReader();
@@ -1275,7 +1275,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
         try {
           CloudJettyRunner cjetty = shardToJetty.get(s).get(i);
           ZkNodeProps props = cjetty.info;
-          SolrServer client = cjetty.client.solrClient;
+          SolrClient client = cjetty.client.solrClient;
           boolean active = props.getStr(ZkStateReader.STATE_PROP).equals(
               ZkStateReader.ACTIVE);
           if (active) {
@@ -1310,7 +1310,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     }
   }
   
-  protected SolrServer getClient(String nodeName) {
+  protected SolrClient getClient(String nodeName) {
     for (CloudJettyRunner cjetty : cloudJettys) {
       CloudSolrServerClient client = cjetty.client;
       if (client.shardName.equals(nodeName)) {
@@ -1354,7 +1354,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
         Map<String,Replica> theShards = slice.getValue().getReplicasMap();
         for (Map.Entry<String,Replica> shard : theShards.entrySet()) {
           String shardName = new URI(
-              ((HttpSolrServer) client.solrClient).getBaseURL()).getPort()
+              ((HttpSolrClient) client.solrClient).getBaseURL()).getPort()
               + "_solr_";
           if (verbose && shard.getKey().endsWith(shardName)) {
             System.err.println("shard:" + slice.getKey());
@@ -1536,11 +1536,11 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     if (VERBOSE || printLayoutOnTearDown) {
       super.printLayout();
     }
-    if (commondCloudSolrServer != null) {
-      commondCloudSolrServer.shutdown();
+    if (commondCloudSolrClient != null) {
+      commondCloudSolrClient.shutdown();
     }
     if (controlClient != null) {
-      ((HttpSolrServer) controlClient).shutdown();
+      ((HttpSolrClient) controlClient).shutdown();
     }
     if (cloudClient != null) {
       cloudClient.shutdown();
@@ -1587,12 +1587,12 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     return createCollection(null, collectionName, numShards, replicationFactor, maxShardsPerNode, null, null);
   }
 
-  protected CollectionAdminResponse createCollection(Map<String,List<Integer>> collectionInfos, String collectionName, Map<String,Object> collectionProps, SolrServer client)  throws SolrServerException, IOException{
+  protected CollectionAdminResponse createCollection(Map<String,List<Integer>> collectionInfos, String collectionName, Map<String,Object> collectionProps, SolrClient client)  throws SolrServerException, IOException{
     return createCollection(collectionInfos, collectionName, collectionProps, client, null);
   }
 
   // TODO: Use CollectionAdminRequest#createCollection() instead of a raw request
-  protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos, String collectionName, Map<String, Object> collectionProps, SolrServer client, String confSetName)  throws SolrServerException, IOException{
+  protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos, String collectionName, Map<String, Object> collectionProps, SolrClient client, String confSetName)  throws SolrServerException, IOException{
     ModifiableSolrParams params = new ModifiableSolrParams();
     params.set("action", CollectionAction.CREATE.toString());
     for (Map.Entry<String, Object> entry : collectionProps.entrySet()) {
@@ -1629,12 +1629,12 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
 
     CollectionAdminResponse res = new CollectionAdminResponse();
     if (client == null) {
-      final String baseUrl = getBaseUrl((HttpSolrServer) clients.get(clientIndex));
-      SolrServer server = createNewSolrServer("", baseUrl);
+      final String baseUrl = getBaseUrl((HttpSolrClient) clients.get(clientIndex));
+      SolrClient adminClient = createNewSolrClient("", baseUrl);
       try {
-        res.setResponse(server.request(request));
+        res.setResponse(adminClient.request(request));
       } finally {
-        if (server != null) server.shutdown();
+        if (adminClient != null) adminClient.shutdown();
       }
     } else {
       res.setResponse(client.request(request));
@@ -1644,7 +1644,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
 
 
   protected CollectionAdminResponse createCollection(Map<String,List<Integer>> collectionInfos,
-      String collectionName, int numShards, int replicationFactor, int maxShardsPerNode, SolrServer client, String createNodeSetStr) throws SolrServerException, IOException {
+      String collectionName, int numShards, int replicationFactor, int maxShardsPerNode, SolrClient client, String createNodeSetStr) throws SolrServerException, IOException {
 
     return createCollection(collectionInfos, collectionName,
         ZkNodeProps.makeMap(
@@ -1656,7 +1656,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   }
   
   protected CollectionAdminResponse createCollection(Map<String, List<Integer>> collectionInfos,
-                                                     String collectionName, int numShards, int replicationFactor, int maxShardsPerNode, SolrServer client, String createNodeSetStr, String configName) throws SolrServerException, IOException {
+                                                     String collectionName, int numShards, int replicationFactor, int maxShardsPerNode, SolrClient client, String createNodeSetStr, String configName) throws SolrServerException, IOException {
 
     return createCollection(collectionInfos, collectionName,
         ZkNodeProps.makeMap(
@@ -1668,37 +1668,37 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   }
 
   @Override
-  protected SolrServer createNewSolrServer(int port) {
+  protected SolrClient createNewSolrClient(int port) {
     try {
       // setup the server...
       String baseUrl = buildUrl(port);
       String url = baseUrl + (baseUrl.endsWith("/") ? "" : "/") + DEFAULT_COLLECTION;
-      HttpSolrServer s = new HttpSolrServer(url);
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setSoTimeout(60000);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      HttpSolrClient client = new HttpSolrClient(url);
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setSoTimeout(60000);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     } catch (Exception ex) {
       throw new RuntimeException(ex);
     }
   }
   
-  protected SolrServer createNewSolrServer(String collection, String baseUrl) {
+  protected SolrClient createNewSolrClient(String collection, String baseUrl) {
     try {
       // setup the server...
-      HttpSolrServer s = new HttpSolrServer(baseUrl + "/" + collection);
-      s.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
-      s.setDefaultMaxConnectionsPerHost(100);
-      s.setMaxTotalConnections(100);
-      return s;
+      HttpSolrClient client = new HttpSolrClient(baseUrl + "/" + collection);
+      client.setConnectionTimeout(DEFAULT_CONNECTION_TIMEOUT);
+      client.setDefaultMaxConnectionsPerHost(100);
+      client.setMaxTotalConnections(100);
+      return client;
     }
     catch (Exception ex) {
       throw new RuntimeException(ex);
     }
   }
   
-  protected String getBaseUrl(HttpSolrServer client) {
+  protected String getBaseUrl(HttpSolrClient client) {
     return client .getBaseURL().substring(
         0, client.getBaseURL().length()
             - DEFAULT_COLLECTION.length() - 1);
@@ -1711,7 +1711,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
   }
 
   private String checkCollectionExpectations(String collectionName, List<Integer> numShardsNumReplicaList, List<String> nodesAllowedToRunShards) {
-    ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+    ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();
     
     int expectedSlices = numShardsNumReplicaList.get(0);
     // The Math.min thing is here, because we expect replication-factor to be reduced to if there are not enough live nodes to spread all shards of a collection over different nodes
@@ -1766,20 +1766,20 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     }
   }
   
-  private CloudSolrServer commondCloudSolrServer;
+  private CloudSolrClient commondCloudSolrClient;
   
-  protected CloudSolrServer getCommonCloudSolrServer() {
+  protected CloudSolrClient getCommonCloudSolrClient() {
     synchronized (this) {
-      if (commondCloudSolrServer == null) {
-        commondCloudSolrServer = new CloudSolrServer(zkServer.getZkAddress(),
+      if (commondCloudSolrClient == null) {
+        commondCloudSolrClient = new CloudSolrClient(zkServer.getZkAddress(),
             random().nextBoolean());
-        commondCloudSolrServer.getLbServer().setConnectionTimeout(30000);
-        commondCloudSolrServer.setParallelUpdates(random().nextBoolean());
-        commondCloudSolrServer.setDefaultCollection(DEFAULT_COLLECTION);
-        commondCloudSolrServer.connect();
+        commondCloudSolrClient.getLbClient().setConnectionTimeout(30000);
+        commondCloudSolrClient.setParallelUpdates(random().nextBoolean());
+        commondCloudSolrClient.setDefaultCollection(DEFAULT_COLLECTION);
+        commondCloudSolrClient.connect();
       }
     }
-    return commondCloudSolrServer;
+    return commondCloudSolrClient;
   }
   
   public static String getUrlFromZk(ClusterState clusterState, String collection) {
@@ -1804,7 +1804,7 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     throw new RuntimeException("Could not find a live node for collection:" + collection);
   }
 
- public  static void waitForNon403or404or503(HttpSolrServer collectionClient)
+ public  static void waitForNon403or404or503(HttpSolrClient collectionClient)
       throws Exception {
     SolrException exp = null;
     long timeoutAt = System.currentTimeMillis() + 30000;
@@ -1836,8 +1836,8 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     long timeoutAt = System.currentTimeMillis() + 45000;
     boolean found = true;
     while (System.currentTimeMillis() < timeoutAt) {
-      getCommonCloudSolrServer().getZkStateReader().updateClusterState(true);
-      ClusterState clusterState = getCommonCloudSolrServer().getZkStateReader().getClusterState();
+      getCommonCloudSolrClient().getZkStateReader().updateClusterState(true);
+      ClusterState clusterState = getCommonCloudSolrClient().getZkStateReader().getClusterState();
       if (!clusterState.hasCollection(collectionName)) {
         found = false;
         break;
@@ -1857,23 +1857,23 @@ public abstract class AbstractFullDistribZkTestBase extends AbstractDistribZkTes
     }
     request.setPath("/admin/collections");
 
-    String baseUrl = ((HttpSolrServer) shardToJetty.get(SHARD1).get(0).client.solrClient)
+    String baseUrl = ((HttpSolrClient) shardToJetty.get(SHARD1).get(0).client.solrClient)
         .getBaseURL();
     baseUrl = baseUrl.substring(0, baseUrl.length() - "collection1".length());
 
-    HttpSolrServer baseServer = new HttpSolrServer(baseUrl);
-    baseServer.setConnectionTimeout(15000);
-    baseServer.setSoTimeout(60000 * 5);
-    NamedList r = baseServer.request(request);
-    baseServer.shutdown();
+    HttpSolrClient baseClient = new HttpSolrClient(baseUrl);
+    baseClient.setConnectionTimeout(15000);
+    baseClient.setSoTimeout(60000 * 5);
+    NamedList r = baseClient.request(request);
+    baseClient.shutdown();
     return r;
   }
 
   protected void createCollection(String collName,
-                                  CloudSolrServer client,
+                                  CloudSolrClient client,
                                   int replicationFactor ,
                                   int numShards ) throws Exception {
-    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrServer()
+    int maxShardsPerNode = ((((numShards+1) * replicationFactor) / getCommonCloudSolrClient()
         .getZkStateReader().getClusterState().getLiveNodes().size())) + 1;
 
     Map<String, Object> props = makeMap(
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/ChaosMonkey.java b/solr/test-framework/src/java/org/apache/solr/cloud/ChaosMonkey.java
index d8c1f7f..428e2b7 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/ChaosMonkey.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/ChaosMonkey.java
@@ -18,7 +18,7 @@ package org.apache.solr.cloud;
  */
 
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.embedded.JettySolrRunner;
 import org.apache.solr.cloud.AbstractFullDistribZkTestBase.CloudJettyRunner;
 import org.apache.solr.common.cloud.Slice;
@@ -73,7 +73,7 @@ public class ChaosMonkey {
   private AtomicInteger expires = new AtomicInteger();
   private AtomicInteger connloss = new AtomicInteger();
   
-  private Map<String,List<SolrServer>> shardToClient;
+  private Map<String,List<SolrClient>> shardToClient;
   private boolean expireSessions;
   private boolean causeConnectionLoss;
   private boolean aggressivelyKillLeaders;
@@ -423,14 +423,14 @@ public class ChaosMonkey {
     return numActive;
   }
   
-  public SolrServer getRandomClient(String slice) throws KeeperException, InterruptedException {
+  public SolrClient getRandomClient(String slice) throws KeeperException, InterruptedException {
     // get latest cloud state
     zkStateReader.updateClusterState(true);
 
     // get random shard
-    List<SolrServer> clients = shardToClient.get(slice);
+    List<SolrClient> clients = shardToClient.get(slice);
     int index = LuceneTestCase.random().nextInt(clients.size() - 1);
-    SolrServer client = clients.get(index);
+    SolrClient client = clients.get(index);
 
     return client;
   }
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/CloudInspectUtil.java b/solr/test-framework/src/java/org/apache/solr/cloud/CloudInspectUtil.java
index c8f76c0..f710b55 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/CloudInspectUtil.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/CloudInspectUtil.java
@@ -1,12 +1,7 @@
 package org.apache.solr.cloud;
 
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-
 import org.apache.solr.SolrTestCaseJ4;
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.common.SolrDocument;
 import org.apache.solr.common.SolrDocumentList;
@@ -14,6 +9,11 @@ import org.apache.solr.common.params.SolrParams;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
@@ -160,9 +160,9 @@ public class CloudInspectUtil {
    * 
    * @return true if the compared results are illegal.
    */
-  public static boolean compareResults(SolrServer controlServer, SolrServer cloudServer)
+  public static boolean compareResults(SolrClient controlClient, SolrClient cloudClient)
       throws SolrServerException {
-    return compareResults(controlServer, cloudServer, null, null);
+    return compareResults(controlClient, cloudClient, null, null);
   }
   
   /**
@@ -170,25 +170,25 @@ public class CloudInspectUtil {
    * 
    * @return true if the compared results are illegal.
    */
-  public static boolean compareResults(SolrServer controlServer, SolrServer cloudServer, Set<String> addFails, Set<String> deleteFails)
+  public static boolean compareResults(SolrClient controlClient, SolrClient cloudClient, Set<String> addFails, Set<String> deleteFails)
       throws SolrServerException {
     
     SolrParams q = SolrTestCaseJ4.params("q","*:*","rows","0", "tests","checkShardConsistency(vsControl)");    // add a tag to aid in debugging via logs
 
-    SolrDocumentList controlDocList = controlServer.query(q).getResults();
+    SolrDocumentList controlDocList = controlClient.query(q).getResults();
     long controlDocs = controlDocList.getNumFound();
 
-    SolrDocumentList cloudDocList = cloudServer.query(q).getResults();
+    SolrDocumentList cloudDocList = cloudClient.query(q).getResults();
     long cloudClientDocs = cloudDocList.getNumFound();
     
     // re-execute the query getting ids
-    q = SolrTestCaseJ4.params("q","*:*","rows","100000", "fl","id", "tests","checkShardConsistency(vsControl)/getIds");    // add a tag to aid in debugging via logs
-    controlDocList = controlServer.query(q).getResults();
+    q = SolrTestCaseJ4.params("q", "*:*", "rows", "100000", "fl", "id", "tests", "checkShardConsistency(vsControl)/getIds");    // add a tag to aid in debugging via logs
+    controlDocList = controlClient.query(q).getResults();
     if (controlDocs != controlDocList.getNumFound()) {
       log.error("Something changed! control now " + controlDocList.getNumFound());
     };
 
-    cloudDocList = cloudServer.query(q).getResults();
+    cloudDocList = cloudClient.query(q).getResults();
     if (cloudClientDocs != cloudDocList.getNumFound()) {
       log.error("Something changed! cloudClient now " + cloudDocList.getNumFound());
     };
@@ -220,8 +220,8 @@ public class CloudInspectUtil {
           "checkShardConsistency(vsControl)/getVers"); // add a tag to aid in
                                                        // debugging via logs
       
-      SolrDocumentList a = controlServer.query(q).getResults();
-      SolrDocumentList b = cloudServer.query(q).getResults();
+      SolrDocumentList a = controlClient.query(q).getResults();
+      SolrDocumentList b = cloudClient.query(q).getResults();
       
       log.error("controlClient :" + a + "\n\tcloudClient :" + b);
     }
diff --git a/solr/test-framework/src/java/org/apache/solr/cloud/StopableIndexingThread.java b/solr/test-framework/src/java/org/apache/solr/cloud/StopableIndexingThread.java
index d9d34a6..100798e 100644
--- a/solr/test-framework/src/java/org/apache/solr/cloud/StopableIndexingThread.java
+++ b/solr/test-framework/src/java/org/apache/solr/cloud/StopableIndexingThread.java
@@ -6,7 +6,7 @@ import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 
-import org.apache.solr.client.solrj.SolrServer;
+import org.apache.solr.client.solrj.SolrClient;
 import org.apache.solr.client.solrj.SolrServerException;
 import org.apache.solr.client.solrj.request.UpdateRequest;
 import org.apache.solr.common.SolrInputDocument;
@@ -38,16 +38,16 @@ public class StopableIndexingThread extends AbstractFullDistribZkTestBase.Stopab
   protected Set<String> deleteFails = new HashSet<>();
   protected boolean doDeletes;
   private int numCycles;
-  private SolrServer controlClient;
-  private SolrServer cloudClient;
+  private SolrClient controlClient;
+  private SolrClient cloudClient;
   private int numDeletes;
   private int numAdds;
 
-  public StopableIndexingThread(SolrServer controlClient, SolrServer cloudClient, String id, boolean doDeletes) {
+  public StopableIndexingThread(SolrClient controlClient, SolrClient cloudClient, String id, boolean doDeletes) {
     this(controlClient, cloudClient, id, doDeletes, -1);
   }
   
-  public StopableIndexingThread(SolrServer controlClient, SolrServer cloudClient, String id, boolean doDeletes, int numCycles) {
+  public StopableIndexingThread(SolrClient controlClient, SolrClient cloudClient, String id, boolean doDeletes, int numCycles) {
     super("StopableIndexingThread");
     this.controlClient = controlClient;
     this.cloudClient = cloudClient;

