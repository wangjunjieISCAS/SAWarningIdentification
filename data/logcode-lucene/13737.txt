GitDiffStart: dac1b58277c41d66197bbe2a11cc14a4a406e99c | Wed Feb 8 12:07:52 2012 +0000
diff --git a/lucene/contrib/CHANGES.txt b/lucene/contrib/CHANGES.txt
index 066d0a6..0ec6dca 100644
--- a/lucene/contrib/CHANGES.txt
+++ b/lucene/contrib/CHANGES.txt
@@ -169,6 +169,14 @@ Changes in runtime behavior
 
  * LUCENE-3626: PKIndexSplitter and MultiPassIndexSplitter now work
    per segment.  (Uwe Schindler)
+   
+ * SOLR-3105: When passed LUCENE_36 or greater as version, GermanAnalyzer,
+   SpanishAnalyzer, FrenchAnalyzer, ItalianAnalyzer, and PortugueseAnalyzer
+   use a lighter stemming approach, CatalanAnalyzer uses ElisionFilter 
+   with a set of contractions, HindiAnalyzer uses StandardTokenizer, and
+   ThaiAnalyzer uses thai stopwords. Add GermanNormalizationFilter which applies
+   the Snowball German2 algorithm to ae/oe/ue and case-folds ?. Add 
+   GalicianMinimalStemFilter for plural removal only. (Robert Muir)
 
 Optimizations
 
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
index eaaed17..4f95cad 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/ca/CatalanAnalyzer.java
@@ -19,11 +19,13 @@ package org.apache.lucene.analysis.ca;
 
 import java.io.IOException;
 import java.io.Reader;
+import java.util.Arrays;
 import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopFilter;
+import org.apache.lucene.analysis.fr.ElisionFilter;
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -37,6 +39,14 @@ import org.tartarus.snowball.ext.CatalanStemmer;
 
 /**
  * {@link Analyzer} for Catalan.
+ * <p>
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating CatalanAnalyzer:
+ * <ul>
+ *   <li> As of 3.6, ElisionFilter with a set of Catalan 
+ *        contractions is used by default.
+ * </ul>
  */
 public final class CatalanAnalyzer extends StopwordAnalyzerBase {
   private final Set<?> stemExclusionSet;
@@ -44,6 +54,12 @@ public final class CatalanAnalyzer extends StopwordAnalyzerBase {
   /** File containing default Catalan stopwords. */
   public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
   
+  private static final CharArraySet DEFAULT_ARTICLES = CharArraySet.unmodifiableSet(
+      new CharArraySet(Version.LUCENE_CURRENT, 
+          Arrays.asList(
+              "d", "l", "m", "n", "s", "t"
+          ), true));
+  
   /**
    * Returns an unmodifiable instance of the default stop words set.
    * @return default stop words set.
@@ -120,6 +136,9 @@ public final class CatalanAnalyzer extends StopwordAnalyzerBase {
       Reader reader) {
     final Tokenizer source = new StandardTokenizer(matchVersion, reader);
     TokenStream result = new StandardFilter(matchVersion, source);
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      result = new ElisionFilter(matchVersion, result, DEFAULT_ARTICLES);
+    }
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
index 9abde8c..3d2dd4d 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanAnalyzer.java
@@ -54,6 +54,7 @@ import org.tartarus.snowball.ext.German2Stemmer;
  * <p>You must specify the required {@link Version}
  * compatibility when creating GermanAnalyzer:
  * <ul>
+ *   <li> As of 3.6, GermanLightStemFilter is used for less aggressive stemming.
  *   <li> As of 3.1, Snowball stemming is done with SnowballFilter, and 
  *        Snowball stopwords are used by default.
  *   <li> As of 2.9, StopFilter preserves position
@@ -166,7 +167,7 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
    *         built from a {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
-   *         provided, and {@link SnowballFilter}
+   *         provided, {@link GermanNormalizationFilter} and {@link GermanLightStemFilter}
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
@@ -176,10 +177,14 @@ public final class GermanAnalyzer extends StopwordAnalyzerBase {
     result = new LowerCaseFilter(matchVersion, result);
     result = new StopFilter( matchVersion, result, stopwords);
     result = new KeywordMarkerFilter(result, exclusionSet);
-    if (matchVersion.onOrAfter(Version.LUCENE_31))
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      result = new GermanNormalizationFilter(result);
+      result = new GermanLightStemFilter(result);
+    } else if (matchVersion.onOrAfter(Version.LUCENE_31)) {
       result = new SnowballFilter(result, new German2Stemmer());
-    else
+    } else {
       result = new GermanStemFilter(result);
+    }
     return new TokenStreamComponents(source, result);
   }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilter.java
new file mode 100644
index 0000000..1ad4f00
--- /dev/null
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/de/GermanNormalizationFilter.java
@@ -0,0 +1,112 @@
+package org.apache.lucene.analysis.de;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.util.StemmerUtil;
+
+/**
+ * Normalizes German characters according to the heuristics
+ * of the <a href="http://snowball.tartarus.org/algorithms/german2/stemmer.html">
+ * German2 snowball algorithm</a>.
+ * It allows for the fact that √§, √∂ and √º are sometimes written as ae, oe and ue.
+ * <p>
+ * <ul>
+ *   <li> '?' is replaced by 'ss'
+ *   <li> '√§', '√∂', '√º' are replaced by 'a', 'o', 'u', respectively.
+ *   <li> 'ae' and 'oe' are replaced by 'a', and 'o', respectively.
+ *   <li> 'ue' is replaced by 'u', when not following a vowel or q.
+ * </ul>
+ * <p>
+ * This is useful if you want this normalization without using
+ * the German2 stemmer, or perhaps no stemming at all.
+ */
+public final class GermanNormalizationFilter extends TokenFilter {
+  // FSM with 3 states:
+  private static final int N = 0; /* ordinary state */
+  private static final int V = 1; /* stops 'u' from entering umlaut state */
+  private static final int U = 2; /* umlaut state, allows e-deletion */
+
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  
+  public GermanNormalizationFilter(TokenStream input) {
+    super(input);
+  }
+
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      int state = N;
+      char buffer[] = termAtt.buffer();
+      int length = termAtt.length();
+      for (int i = 0; i < length; i++) {
+        final char c = buffer[i];
+        switch(c) {
+          case 'a':
+          case 'o':
+            state = U;
+            break;
+          case 'u':
+            state = (state == N) ? U : V;
+            break;
+          case 'e':
+            if (state == U)
+              length = StemmerUtil.delete(buffer, i--, length);
+            state = V;
+            break;
+          case 'i':
+          case 'q':
+          case 'y':
+            state = V;
+            break;
+          case '√§':
+            buffer[i] = 'a';
+            state = V;
+            break;
+          case '√∂':
+            buffer[i] = 'o';
+            state = V;
+            break;
+          case '√º': 
+            buffer[i] = 'u';
+            state = V;
+            break;
+          case '?':
+            buffer[i++] = 's';
+            buffer = termAtt.resizeBuffer(1+length);
+            if (i < length)
+              System.arraycopy(buffer, i, buffer, i+1, (length-i));
+            buffer[i] = 's';
+            length++;
+            state = N;
+            break;
+          default:
+            state = N;
+        }
+      }
+      termAtt.setLength(length);
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
index 7be2b70..42f10e5 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/es/SpanishAnalyzer.java
@@ -39,6 +39,13 @@ import org.tartarus.snowball.ext.SpanishStemmer;
 
 /**
  * {@link Analyzer} for Spanish.
+ * <p>
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating SpanishAnalyzer:
+ * <ul>
+ *   <li> As of 3.6, SpanishLightStemFilter is used for less aggressive stemming.
+ * </ul>
  */
 public final class SpanishAnalyzer extends StopwordAnalyzerBase {
   private final Set<?> stemExclusionSet;
@@ -115,7 +122,7 @@ public final class SpanishAnalyzer extends StopwordAnalyzerBase {
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
-   *         provided and {@link SnowballFilter}.
+   *         provided and {@link SpanishLightStemFilter}.
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
@@ -126,7 +133,11 @@ public final class SpanishAnalyzer extends StopwordAnalyzerBase {
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
       result = new KeywordMarkerFilter(result, stemExclusionSet);
-    result = new SnowballFilter(result, new SpanishStemmer());
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      result = new SpanishLightStemFilter(result);
+    } else {
+      result = new SnowballFilter(result, new SpanishStemmer());
+    }
     return new TokenStreamComponents(source, result);
   }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
index 8d0c4a1..2c89881 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/fr/FrenchAnalyzer.java
@@ -52,6 +52,7 @@ import java.util.Set;
  * <p>You must specify the required {@link Version}
  * compatibility when creating FrenchAnalyzer:
  * <ul>
+ *   <li> As of 3.6, FrenchLightStemFilter is used for less aggressive stemming.
  *   <li> As of 3.1, Snowball stemming is done with SnowballFilter, 
  *        LowerCaseFilter is used prior to StopFilter, and ElisionFilter and 
  *        Snowball stopwords are used by default.
@@ -177,7 +178,7 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
    *         {@link StandardFilter}, {@link ElisionFilter},
    *         {@link LowerCaseFilter}, {@link StopFilter},
    *         {@link KeywordMarkerFilter} if a stem exclusion set is
-   *         provided, and {@link SnowballFilter}
+   *         provided, and {@link FrenchLightStemFilter}
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
@@ -190,7 +191,11 @@ public final class FrenchAnalyzer extends StopwordAnalyzerBase {
       result = new StopFilter(matchVersion, result, stopwords);
       if(!excltable.isEmpty())
         result = new KeywordMarkerFilter(result, excltable);
-      result = new SnowballFilter(result, new org.tartarus.snowball.ext.FrenchStemmer());
+      if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+        result = new FrenchLightStemFilter(result);
+      } else {
+        result = new SnowballFilter(result, new org.tartarus.snowball.ext.FrenchStemmer());
+      }
       return new TokenStreamComponents(source, result);
     } else {
       final Tokenizer source = new StandardTokenizer(matchVersion, reader);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilter.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilter.java
new file mode 100644
index 0000000..2d9b28f
--- /dev/null
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemFilter.java
@@ -0,0 +1,58 @@
+package org.apache.lucene.analysis.gl;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.analysis.TokenFilter;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;
+import org.apache.lucene.analysis.tokenattributes.KeywordAttribute;
+
+/**
+ * A {@link TokenFilter} that applies {@link GalicianMinimalStemmer} to stem 
+ * Galician words.
+ * <p>
+ * To prevent terms from being stemmed use an instance of
+ * {@link KeywordMarkerFilter} or a custom {@link TokenFilter} that sets
+ * the {@link KeywordAttribute} before this {@link TokenStream}.
+ * </p>
+ */
+public final class GalicianMinimalStemFilter extends TokenFilter {
+  private final GalicianMinimalStemmer stemmer = new GalicianMinimalStemmer();
+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
+  private final KeywordAttribute keywordAttr = addAttribute(KeywordAttribute.class);
+
+  public GalicianMinimalStemFilter(TokenStream input) {
+    super(input);
+  }
+  
+  @Override
+  public boolean incrementToken() throws IOException {
+    if (input.incrementToken()) {
+      if (!keywordAttr.isKeyword()) {
+        final int newlen = stemmer.stem(termAtt.buffer(), termAtt.length());
+        termAtt.setLength(newlen);
+      }
+      return true;
+    } else {
+      return false;
+    }
+  }
+}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemmer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemmer.java
new file mode 100644
index 0000000..5496490
--- /dev/null
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/gl/GalicianMinimalStemmer.java
@@ -0,0 +1,38 @@
+package org.apache.lucene.analysis.gl;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.pt.RSLPStemmerBase;
+
+/**
+ * Minimal Stemmer for Galician
+ * <p>
+ * This follows the "RSLP-S" algorithm, but modified for Galician.
+ * Hence this stemmer only applies the plural reduction step of:
+ * "Regras do lematizador para o galego"
+ * @see RSLPStemmerBase
+ */
+public class GalicianMinimalStemmer extends RSLPStemmerBase {
+  
+  private static final Step pluralStep = 
+    parse(GalicianMinimalStemmer.class, "galician.rslp").get("Plural");
+  
+  public int stem(char s[], int len) {
+    return pluralStep.apply(s, len);
+  }
+}
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
index ba32662..0d3d72e 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/hi/HindiAnalyzer.java
@@ -22,6 +22,7 @@ import java.io.Reader;
 import java.util.Set;
 
 import org.apache.lucene.analysis.miscellaneous.KeywordMarkerFilter;
+import org.apache.lucene.analysis.standard.StandardTokenizer;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.analysis.TokenStream;
@@ -34,6 +35,13 @@ import org.apache.lucene.util.Version;
 
 /**
  * Analyzer for Hindi.
+ * <p>
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating HindiAnalyzer:
+ * <ul>
+ *   <li> As of 3.6, StandardTokenizer is used for tokenization
+ * </ul>
  */
 public final class HindiAnalyzer extends StopwordAnalyzerBase {
   private final Set<?> stemExclusionSet;
@@ -110,7 +118,7 @@ public final class HindiAnalyzer extends StopwordAnalyzerBase {
    * used to tokenize all the text in the provided {@link Reader}.
    * 
    * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}
-   *         built from a {@link IndicTokenizer} filtered with
+   *         built from a {@link StandardTokenizer} filtered with
    *         {@link LowerCaseFilter}, {@link IndicNormalizationFilter},
    *         {@link HindiNormalizationFilter}, {@link KeywordMarkerFilter}
    *         if a stem exclusion set is provided, {@link HindiStemFilter}, and
@@ -119,7 +127,12 @@ public final class HindiAnalyzer extends StopwordAnalyzerBase {
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
       Reader reader) {
-    final Tokenizer source = new IndicTokenizer(matchVersion, reader);
+    final Tokenizer source;
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      source = new StandardTokenizer(matchVersion, reader);
+    } else {
+      source = new IndicTokenizer(matchVersion, reader);
+    }
     TokenStream result = new LowerCaseFilter(matchVersion, source);
     if (!stemExclusionSet.isEmpty())
       result = new KeywordMarkerFilter(result, stemExclusionSet);
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/in/IndicTokenizer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/in/IndicTokenizer.java
index 2e4c6e4..e6ae4e7 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/in/IndicTokenizer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/in/IndicTokenizer.java
@@ -20,12 +20,15 @@ package org.apache.lucene.analysis.in;
 import java.io.Reader;
 
 import org.apache.lucene.analysis.util.CharTokenizer;
+import org.apache.lucene.analysis.standard.StandardTokenizer; // javadocs
 import org.apache.lucene.util.AttributeSource;
 import org.apache.lucene.util.Version;
 
 /**
  * Simple Tokenizer for text in Indian Languages.
+ * @deprecated (3.6) Use {@link StandardTokenizer} instead.
  */
+@Deprecated
 public final class IndicTokenizer extends CharTokenizer {
  
   public IndicTokenizer(Version matchVersion, AttributeFactory factory, Reader input) {
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
index 4e90116..5e94049 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/it/ItalianAnalyzer.java
@@ -46,6 +46,7 @@ import org.tartarus.snowball.ext.ItalianStemmer;
  * <p>You must specify the required {@link Version}
  * compatibility when creating ItalianAnalyzer:
  * <ul>
+ *   <li> As of 3.6, ItalianLightStemFilter is used for less aggressive stemming.
  *   <li> As of 3.2, ElisionFilter with a set of Italian 
  *        contractions is used by default.
  * </ul>
@@ -132,7 +133,7 @@ public final class ItalianAnalyzer extends StopwordAnalyzerBase {
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link ElisionFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
-   *         provided and {@link SnowballFilter}.
+   *         provided and {@link ItalianLightStemFilter}.
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
@@ -146,7 +147,11 @@ public final class ItalianAnalyzer extends StopwordAnalyzerBase {
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
       result = new KeywordMarkerFilter(result, stemExclusionSet);
-    result = new SnowballFilter(result, new ItalianStemmer());
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      result = new ItalianLightStemFilter(result);
+    } else {
+      result = new SnowballFilter(result, new ItalianStemmer());
+    }
     return new TokenStreamComponents(source, result);
   }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
index 853f423..fd20bf9 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseAnalyzer.java
@@ -39,6 +39,13 @@ import org.tartarus.snowball.ext.PortugueseStemmer;
 
 /**
  * {@link Analyzer} for Portuguese.
+ * <p>
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating PortugueseAnalyzer:
+ * <ul>
+ *   <li> As of 3.6, PortugueseLightStemFilter is used for less aggressive stemming.
+ * </ul>
  */
 public final class PortugueseAnalyzer extends StopwordAnalyzerBase {
   private final Set<?> stemExclusionSet;
@@ -115,7 +122,7 @@ public final class PortugueseAnalyzer extends StopwordAnalyzerBase {
    *         built from an {@link StandardTokenizer} filtered with
    *         {@link StandardFilter}, {@link LowerCaseFilter}, {@link StopFilter}
    *         , {@link KeywordMarkerFilter} if a stem exclusion set is
-   *         provided and {@link SnowballFilter}.
+   *         provided and {@link PortugueseLightStemFilter}.
    */
   @Override
   protected TokenStreamComponents createComponents(String fieldName,
@@ -126,7 +133,11 @@ public final class PortugueseAnalyzer extends StopwordAnalyzerBase {
     result = new StopFilter(matchVersion, result, stopwords);
     if(!stemExclusionSet.isEmpty())
       result = new KeywordMarkerFilter(result, stemExclusionSet);
-    result = new SnowballFilter(result, new PortugueseStemmer());
+    if (matchVersion.onOrAfter(Version.LUCENE_36)) {
+      result = new PortugueseLightStemFilter(result);
+    } else {
+      result = new SnowballFilter(result, new PortugueseStemmer());
+    }
     return new TokenStreamComponents(source, result);
   }
 }
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemmer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemmer.java
index 01342ce..441d236 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemmer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/pt/PortugueseMinimalStemmer.java
@@ -24,7 +24,7 @@ package org.apache.lucene.analysis.pt;
  * <i>A study on the Use of Stemming for Monolingual Ad-Hoc Portuguese
  * Information Retrieval</i> (Orengo, et al)
  * which is just the plural reduction step of the RSLP
- * algorithm from <i>A Stemming Algorithmm for the Portuguese Language</i>,
+ * algorithm from <i>A Stemming Algorithm for the Portuguese Language</i>,
  * Orengo et al.
  * @see RSLPStemmerBase
  */
diff --git a/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java b/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
index 979339f..ca2e39d 100644
--- a/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
+++ b/modules/analysis/common/src/java/org/apache/lucene/analysis/th/ThaiAnalyzer.java
@@ -16,7 +16,9 @@ package org.apache.lucene.analysis.th;
  * limitations under the License.
  */
 
+import java.io.IOException;
 import java.io.Reader;
+import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.TokenStream;
@@ -24,22 +26,75 @@ import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.core.LowerCaseFilter;
 import org.apache.lucene.analysis.core.StopAnalyzer;
 import org.apache.lucene.analysis.core.StopFilter;
-import org.apache.lucene.analysis.standard.StandardAnalyzer;
 import org.apache.lucene.analysis.standard.StandardFilter;
 import org.apache.lucene.analysis.standard.StandardTokenizer;
+import org.apache.lucene.analysis.util.StopwordAnalyzerBase;
 import org.apache.lucene.util.Version;
 
 /**
  * {@link Analyzer} for Thai language. It uses {@link java.text.BreakIterator} to break words.
- *
- * <p><b>NOTE</b>: This class uses the same {@link Version}
- * dependent settings as {@link StandardAnalyzer}.</p>
+ * <p>
+ * <a name="version"/>
+ * <p>You must specify the required {@link Version}
+ * compatibility when creating ThaiAnalyzer:
+ * <ul>
+ *   <li> As of 3.6, a set of Thai stopwords is used by default
+ * </ul>
  */
-public final class ThaiAnalyzer extends Analyzer {
-  private final Version matchVersion;
+public final class ThaiAnalyzer extends StopwordAnalyzerBase {
+  
+  /** File containing default Thai stopwords. */
+  public final static String DEFAULT_STOPWORD_FILE = "stopwords.txt";
+  /**
+   * The comment character in the stopwords file.  
+   * All lines prefixed with this will be ignored.
+   */
+  private static final String STOPWORDS_COMMENT = "#";
+  
+  /**
+   * Returns an unmodifiable instance of the default stop words set.
+   * @return default stop words set.
+   */
+  public static Set<?> getDefaultStopSet(){
+    return DefaultSetHolder.DEFAULT_STOP_SET;
+  }
+  
+  /**
+   * Atomically loads the DEFAULT_STOP_SET in a lazy fashion once the outer class 
+   * accesses the static final set the first time.;
+   */
+  private static class DefaultSetHolder {
+    static final Set<?> DEFAULT_STOP_SET;
 
+    static {
+      try {
+        DEFAULT_STOP_SET = loadStopwordSet(false, ThaiAnalyzer.class, 
+            DEFAULT_STOPWORD_FILE, STOPWORDS_COMMENT);
+      } catch (IOException ex) {
+        // default set should always be present as it is part of the
+        // distribution (JAR)
+        throw new RuntimeException("Unable to load default stopword set");
+      }
+    }
+  }
+
+  /**
+   * Builds an analyzer with the default stop words.
+   * 
+   * @param matchVersion lucene compatibility version
+   */
   public ThaiAnalyzer(Version matchVersion) {
-    this.matchVersion = matchVersion;
+    this(matchVersion, matchVersion.onOrAfter(Version.LUCENE_36) ? DefaultSetHolder.DEFAULT_STOP_SET : StopAnalyzer.ENGLISH_STOP_WORDS_SET);
+  }
+  
+  /**
+   * Builds an analyzer with the given stop words.
+   * 
+   * @param matchVersion lucene compatibility version
+   * @param stopwords a stopword set
+   */
+  public ThaiAnalyzer(Version matchVersion, Set<?> stopwords) {
+    super(matchVersion, stopwords);
   }
 
   /**
@@ -61,6 +116,6 @@ public final class ThaiAnalyzer extends Analyzer {
       result = new LowerCaseFilter(matchVersion, result);
     result = new ThaiWordFilter(matchVersion, result);
     return new TokenStreamComponents(source, new StopFilter(matchVersion,
-        result, StopAnalyzer.ENGLISH_STOP_WORDS_SET));
+        result, stopwords));
   }
 }
diff --git a/modules/analysis/common/src/resources/org/apache/lucene/analysis/th/stopwords.txt b/modules/analysis/common/src/resources/org/apache/lucene/analysis/th/stopwords.txt
new file mode 100644
index 0000000..07f0fab
--- /dev/null
+++ b/modules/analysis/common/src/resources/org/apache/lucene/analysis/th/stopwords.txt
@@ -0,0 +1,119 @@
+# Thai stopwords from:
+# "Opinion Detection in Thai Political News Columns
+# Based on Subjectivity Analysis"
+# Khampol Sukhum, Supot Nitsuwat, and Choochart Haruechaiyasak
+‡π?∏ß‡π?
+‡π?∏°‡π?
+‡π??
+‡π??‡π?
+‡π?∏´‡π?
+‡π??
+‡π??‡∏?
+‡π?∏´‡π??
+‡π?∏•‡π?∏ß
+‡π?∏•‡∏?
+‡π?∏£‡∏?
+‡π??‡∏?
+‡π??‡π?
+‡π?‡∏??
+‡π?‡∏??‡∏?
+‡π?‡∏•‡∏¢
+‡π?‡∏£‡∏¥‡π?∏°
+‡π?‡∏£‡∏≤
+‡π?‡∏°‡∏∑‡π?∏≠
+‡π?‡∏?∏∑‡π?∏≠
+‡π?‡∏?∏£‡∏≤‡∏∞
+‡π?‡∏??‡∏??‡∏≤‡∏£
+‡π?‡∏??‡∏?
+‡π?‡∏?∏¥‡∏??‡∏?∏¢
+‡π?‡∏?∏¥‡∏?
+‡π?‡∏?∏∑‡π?∏≠‡∏??‡∏≤‡?
+‡π?‡∏?∏µ‡∏¢‡∏ß‡∏?∏±‡∏?
+‡π?‡∏?∏µ‡∏¢‡∏ß
+‡π?‡∏??‡∏?
+‡π?‡∏??‡∏≤‡∏∞
+‡π?‡∏?∏¢
+‡π?‡∏??‡∏?
+‡π?‡∏?∏≤
+‡∏?∏µ‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏∞‡π?∏£
+‡∏?∏≠‡∏?
+‡∏?∏¢‡π?∏≤‡∏?
+‡∏?∏¢‡∏π‡?
+‡∏?∏¢‡∏≤‡?
+‡∏?∏≤‡∏?
+‡∏?∏•‡∏≤‡∏¢
+‡∏?∏•‡∏±‡?‡∏?∏≤‡∏?
+‡∏?∏•‡∏±‡?
+‡∏?∏£‡∏∑‡∏≠
+‡∏??‡∏∂‡?‡∏?
+‡∏??‡∏ß‡?
+‡∏??‡∏?
+‡∏?∏∏‡∏?
+‡∏??‡∏≤‡∏´‡∏£‡∏±‡∏?
+‡∏ß‡?‡∏?
+‡∏ß‡∏±‡∏?
+‡∏•‡?
+‡∏£‡?‡∏ß‡∏°
+‡∏£‡∏≤‡∏?
+‡∏£‡∏±‡∏?
+‡∏£‡∏∞‡∏?∏ß‡π?∏≤‡∏?
+‡∏£‡∏ß‡∏?
+‡∏¢‡∏±‡∏?
+‡∏°‡∏µ
+‡∏°‡∏≤‡∏?
+‡∏°‡∏≤
+‡∏?∏£‡π?∏≠‡∏?
+‡∏??
+‡∏??‡∏≤‡?
+‡∏?∏•
+‡∏?∏≤‡∏?
+‡∏??‡∏?
+‡∏?∏µ‡π?
+‡∏??‡∏?
+‡∏?∏±‡π??
+‡∏?∏±‡∏?
+‡∏?∏≠‡∏??‡∏≤‡?
+‡∏?∏∏‡∏?
+‡∏?∏µ‡π?∏™‡∏∏‡?
+‡∏?∏µ‡π?
+‡∏??‡∏≤‡?‡∏??
+‡∏??‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡π??‡∏?∏µ‡π?
+‡∏?∏±‡π??
+‡∏??‡∏?
+‡∏?∏π‡∏?
+‡∏?∏∂‡∏?
+‡∏??‡∏??
+‡∏??‡∏≤‡?‡π?
+‡∏??‡∏≤‡?
+‡∏??‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡π??‡π??‡π?
+‡∏?∏±‡π??
+‡∏??‡∏≤‡?
+‡∏??‡∏ß‡∏¢
+‡∏?∏±‡∏?
+‡∏?∏∂‡π??
+‡∏??‡∏ß‡?
+‡∏?∏∂‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡∏?
+‡∏?∏∞
+‡∏?∏∑‡∏?
+‡∏?∏ß‡∏≤‡∏°
+‡∏?∏£‡∏±‡?‡∏?
+‡∏??
+‡∏?∏∂‡π??
+‡∏?∏≠‡∏?
+‡∏?∏≠
+‡∏??‡∏?
+‡∏??‡∏??
+‡∏??
+‡∏?∏≤‡∏?
+‡∏?∏±‡∏?
+‡∏?∏±‡∏?
+‡∏?∏ß‡π?∏≤
+‡∏?∏•‡π?∏≤‡∏?
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
index 307194b..d2b26cf 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/ca/TestCatalanAnalyzer.java
@@ -41,6 +41,13 @@ public class TestCatalanAnalyzer extends BaseTokenStreamTestCase {
     assertAnalyzesTo(a, "un", new String[] { });
   }
   
+  /** test use of elisionfilter */
+  public void testContractions() throws IOException {
+    Analyzer a = new CatalanAnalyzer(TEST_VERSION_CURRENT);
+    assertAnalyzesTo(a, "Diccionari de l'Institut d'Estudis Catalans",
+        new String[] { "diccion", "inst", "estud", "catalan" });
+  }
+  
   /** test use of exclusion set */
   public void testExclude() throws IOException {
     Set<String> exclusionSet = new HashSet<String>();
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilter.java
new file mode 100644
index 0000000..4bdeaac
--- /dev/null
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/de/TestGermanNormalizationFilter.java
@@ -0,0 +1,68 @@
+package org.apache.lucene.analysis.de;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Tests {@link GermanNormalizationFilter}
+ */
+public class TestGermanNormalizationFilter extends BaseTokenStreamTestCase {
+  private Analyzer analyzer = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String field, Reader reader) {
+      final Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+      final TokenStream stream = new GermanNormalizationFilter(tokenizer);
+      return new TokenStreamComponents(tokenizer, stream);
+    }
+  };
+  
+  /**
+   * Tests that a/o/u + e is equivalent to the umlaut form
+   */
+  public void testBasicExamples() throws IOException {
+    checkOneTerm(analyzer, "Schaltfl√§chen", "Schaltflachen");
+    checkOneTerm(analyzer, "Schaltflaechen", "Schaltflachen");
+  }
+
+  /**
+   * Tests the specific heuristic that ue is not folded after a vowel or q.
+   */
+  public void testUHeuristic() throws IOException {
+    checkOneTerm(analyzer, "dauer", "dauer");
+  }
+  
+  /**
+   * Tests german specific folding of sharp-s
+   */
+  public void testSpecialFolding() throws IOException {
+    checkOneTerm(analyzer, "wei?bier", "weissbier");
+  }
+  
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random, analyzer, 10000*RANDOM_MULTIPLIER);
+  }
+}
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
index 07fc7ad..c395246 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/fr/TestFrenchAnalyzer.java
@@ -56,7 +56,7 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 		assertAnalyzesTo(
 			fa,
 			"mot \"entreguillemet\"",
-			new String[] { "mot", "entreguillemet" });
+			new String[] { "mot", "entreguilemet" });
 
 		// let's do some french specific tests now	
 
@@ -66,7 +66,7 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 		assertAnalyzesTo(
 			fa,
 			"Jean-Fran√ßois",
-			new String[] { "jean", "fran√ßois" });
+			new String[] { "jean", "francoi" });
 
 		// 2. stopwords
 		assertAnalyzesTo(
@@ -81,16 +81,16 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 			new String[] {
 				"lanc",
 				"chism",
-				"habit",
+				"habitabl",
 				"chist",
-				"√©l√©ment",
+				"element",
 				"captif" });
 
 		// some verbs
 		assertAnalyzesTo(
 			fa,
 			"finissions souffrirent rugissante",
-			new String[] { "fin", "souffr", "rug" });
+			new String[] { "finision", "soufrirent", "rugisant" });
 
 		// some everything else
 		// aujourd'hui stays one term which is OK
@@ -101,16 +101,16 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
 				"c3po",
 				"aujourd'hui",
 				"oeuf",
-				"√Ø√¢√∂√ª?√§",
-				"anticonstitutionnel",
-				"jav" });
+				"√Øa√∂ua√§",
+				"anticonstitutionel",
+				"java" });
 
 		// some more everything else
 		// here 1940-1945 stays as one term, 1940:1945 not ?
 		assertAnalyzesTo(
 			fa,
 			"33Bis 1940-1945 1940:1945 (---i+++)*",
-			new String[] { "33bis", "1940", "1945", "1940", "1945", "i" });
+			new String[] { "33bi", "1940", "1945", "1940", "1945", "i" });
 
 	}
 	
@@ -217,9 +217,9 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
           new String[] {
               "lanc",
               "chism",
-              "habit",
+              "habitabl",
               "chist",
-              "√©l√©ment",
+              "element",
               "captif" });
 	}
 
@@ -238,7 +238,7 @@ public class TestFrenchAnalyzer extends BaseTokenStreamTestCase {
   
   public void testElision() throws Exception {
     FrenchAnalyzer fa = new FrenchAnalyzer(TEST_VERSION_CURRENT);
-    assertAnalyzesTo(fa, "voir l'embrouille", new String[] { "voir", "embrouill" });
+    assertAnalyzesTo(fa, "voir l'embrouille", new String[] { "voir", "embrouil" });
   }
   
   /**
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilter.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilter.java
new file mode 100644
index 0000000..f8be16e
--- /dev/null
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/gl/TestGalicianMinimalStemFilter.java
@@ -0,0 +1,55 @@
+package org.apache.lucene.analysis.gl;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+
+import org.apache.lucene.analysis.Analyzer;
+import org.apache.lucene.analysis.BaseTokenStreamTestCase;
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.Tokenizer;
+
+/**
+ * Simple tests for {@link GalicianMinimalStemmer}
+ */
+public class TestGalicianMinimalStemFilter extends BaseTokenStreamTestCase {
+  Analyzer a = new Analyzer() {
+    @Override
+    protected TokenStreamComponents createComponents(String fieldName, Reader reader) {
+      Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+      return new TokenStreamComponents(tokenizer, new GalicianMinimalStemFilter(tokenizer));
+    }
+  };
+  
+  public void testPlural() throws Exception {
+    checkOneTerm(a, "elefantes", "elefante");
+    checkOneTerm(a, "elefante", "elefante");
+    checkOneTerm(a, "kal√≥res", "kal√≥r");
+    checkOneTerm(a, "kal√≥r", "kal√≥r");
+  }
+  
+  public void testExceptions() throws Exception {
+    checkOneTerm(a, "mas", "mas");
+    checkOneTerm(a, "barcelon√™s", "barcelon√™s");
+  }
+  
+  /** blast some random strings through the analyzer */
+  public void testRandomStrings() throws Exception {
+    checkRandomData(random, a, 10000*RANDOM_MULTIPLIER);
+  }
+}
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
index 83d7a86..56f64f1 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/it/TestItalianAnalyzer.java
@@ -36,8 +36,8 @@ public class TestItalianAnalyzer extends BaseTokenStreamTestCase {
   public void testBasics() throws IOException {
     Analyzer a = new ItalianAnalyzer(TEST_VERSION_CURRENT);
     // stemming
-    checkOneTermReuse(a, "abbandonata", "abbandon");
-    checkOneTermReuse(a, "abbandonati", "abbandon");
+    checkOneTermReuse(a, "abbandonata", "abbandonat");
+    checkOneTermReuse(a, "abbandonati", "abbandonat");
     // stopword
     assertAnalyzesTo(a, "dallo", new String[] {});
   }
@@ -49,7 +49,7 @@ public class TestItalianAnalyzer extends BaseTokenStreamTestCase {
     Analyzer a = new ItalianAnalyzer(TEST_VERSION_CURRENT, 
         ItalianAnalyzer.getDefaultStopSet(), exclusionSet);
     checkOneTermReuse(a, "abbandonata", "abbandonata");
-    checkOneTermReuse(a, "abbandonati", "abbandon");
+    checkOneTermReuse(a, "abbandonati", "abbandonat");
   }
   
   /** blast some random strings through the analyzer */
@@ -61,7 +61,7 @@ public class TestItalianAnalyzer extends BaseTokenStreamTestCase {
   public void testContractions() throws IOException {
     Analyzer a = new ItalianAnalyzer(TEST_VERSION_CURRENT);
     assertAnalyzesTo(a, "dell'Italia", new String[] { "ital" });
-    assertAnalyzesTo(a, "l'Italiano", new String[] { "ital" });
+    assertAnalyzesTo(a, "l'Italiano", new String[] { "italian" });
   }
   
   /** test that we don't enable this before 3.2*/
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
index 9453cb2..a0e263f 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/pt/TestPortugueseAnalyzer.java
@@ -35,8 +35,8 @@ public class TestPortugueseAnalyzer extends BaseTokenStreamTestCase {
   public void testBasics() throws IOException {
     Analyzer a = new PortugueseAnalyzer(TEST_VERSION_CURRENT);
     // stemming
-    checkOneTermReuse(a, "quilom√©tricas", "quilom√©tr");
-    checkOneTermReuse(a, "quilom√©tricos", "quilom√©tr");
+    checkOneTermReuse(a, "quilom√©tricas", "quilometric");
+    checkOneTermReuse(a, "quilom√©tricos", "quilometric");
     // stopword
     assertAnalyzesTo(a, "n√£o", new String[] {});
   }
@@ -48,7 +48,7 @@ public class TestPortugueseAnalyzer extends BaseTokenStreamTestCase {
     Analyzer a = new PortugueseAnalyzer(TEST_VERSION_CURRENT, 
         PortugueseAnalyzer.getDefaultStopSet(), exclusionSet);
     checkOneTermReuse(a, "quilom√©tricas", "quilom√©tricas");
-    checkOneTermReuse(a, "quilom√©tricos", "quilom√©tr");
+    checkOneTermReuse(a, "quilom√©tricos", "quilometric");
   }
   
   /** blast some random strings through the analyzer */
diff --git a/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java b/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
index 185749c..7ab69c1 100644
--- a/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
+++ b/modules/analysis/common/src/test/org/apache/lucene/analysis/th/TestThaiAnalyzer.java
@@ -21,7 +21,9 @@ import java.io.StringReader;
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.core.StopAnalyzer;
 import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;
+import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.util.Version;
 
 /**
@@ -40,14 +42,29 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
 	 * testcase for offsets
 	 */
 	public void testOffsets() throws Exception {
-		assertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏?", 
+		assertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏?", 
 		    new String[] { "‡∏?∏≤‡∏?", "‡∏?∏µ‡π?", "‡π??‡π?", "‡∏??‡∏??", "‡π?∏™‡∏??", "‡∏ß‡?‡∏?", "‡∏?∏≤‡∏?", "‡∏?∏µ" },
 				new int[] { 0, 3, 6, 9, 13, 17, 20, 23 },
 				new int[] { 3, 6, 9, 13, 17, 20, 23, 25 });
 	}
 	
+	public void testStopWords() throws Exception {
+	  assertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏?", 
+	      new String[] { "‡π?∏™‡∏??", "‡∏?∏≤‡∏?", "‡∏?∏µ" },
+	      new int[] { 13, 20, 23 },
+	      new int[] { 17, 23, 25 },
+	      new int[] { 5, 2, 1 });
+	}
+	
+	public void testBackwardsStopWords() throws Exception {
+	   assertAnalyzesTo(new ThaiAnalyzer(Version.LUCENE_35), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏?", 
+	        new String[] { "‡∏?∏≤‡∏?", "‡∏?∏µ‡π?", "‡π??‡π?", "‡∏??‡∏??", "‡π?∏™‡∏??", "‡∏ß‡?‡∏?", "‡∏?∏≤‡∏?", "‡∏?∏µ" },
+	        new int[] { 0, 3, 6, 9, 13, 17, 20, 23 },
+	        new int[] { 3, 6, 9, 13, 17, 20, 23, 25 });
+	}
+	
 	public void testTokenType() throws Exception {
-      assertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏? ‡π??‡π?", 
+      assertAnalyzesTo(new ThaiAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET), "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏??‡∏??‡∏?∏ß‡π?∏≤‡∏?∏≤‡∏??‡∏? ‡π??‡π?", 
                        new String[] { "‡∏?∏≤‡∏?", "‡∏?∏µ‡π?", "‡π??‡π?", "‡∏??‡∏??", "‡π?∏™‡∏??", "‡∏ß‡?‡∏?", "‡∏?∏≤‡∏?", "‡∏?∏µ", "‡π??‡π?" },
                        new String[] { "<SOUTHEAST_ASIAN>", "<SOUTHEAST_ASIAN>", 
                                       "<SOUTHEAST_ASIAN>", "<SOUTHEAST_ASIAN>", 
@@ -96,8 +113,9 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
 	/*
 	 * Test that position increments are adjusted correctly for stopwords.
 	 */
+	// note this test uses stopfilter's stopset
 	public void testPositionIncrements() throws Exception {
-	  final ThaiAnalyzer analyzer = new ThaiAnalyzer(TEST_VERSION_CURRENT);
+	  final ThaiAnalyzer analyzer = new ThaiAnalyzer(TEST_VERSION_CURRENT, StopAnalyzer.ENGLISH_STOP_WORDS_SET);
     assertAnalyzesTo(analyzer, "‡∏?∏≤‡∏£‡?‡∏µ‡?‡π??‡π??‡π?∏≠‡∏? the ‡π?∏™‡∏??‡∏ß‡?‡∏≤‡?‡∏≤‡?‡∏?∏µ", 
         new String[] { "‡∏?∏≤‡∏?", "‡∏?∏µ‡π?", "‡π??‡π?", "‡∏??‡∏??", "‡π?∏™‡∏??", "‡∏ß‡?‡∏?", "‡∏?∏≤‡∏?", "‡∏?∏µ" },
         new int[] { 0, 3, 6, 9, 18, 22, 25, 28 },
@@ -113,7 +131,7 @@ public class TestThaiAnalyzer extends BaseTokenStreamTestCase {
 	}
 	
 	public void testReusableTokenStream() throws Exception {
-	  ThaiAnalyzer analyzer = new ThaiAnalyzer(TEST_VERSION_CURRENT);
+	  ThaiAnalyzer analyzer = new ThaiAnalyzer(TEST_VERSION_CURRENT, CharArraySet.EMPTY_SET);
 	  assertAnalyzesToReuse(analyzer, "", new String[] {});
 
       assertAnalyzesToReuse(
diff --git a/solr/CHANGES.txt b/solr/CHANGES.txt
index 0baec61..c648859 100644
--- a/solr/CHANGES.txt
+++ b/solr/CHANGES.txt
@@ -479,6 +479,9 @@ New Features
   CommonGramsQueryFilterFactory can optionally read stopwords in Snowball
   format (specify format="snowball").  (Robert Muir)
 
+* SOLR-3105: ElisionFilterFactory optionally allows the parameter 
+  ignoreCase (default=false).  (Robert Muir)
+
 Optimizations
 ----------------------
 * SOLR-1931: Speedup for LukeRequestHandler and admin/schema browser. New parameter
@@ -592,6 +595,9 @@ Other Changes
 
 * SOLR-3059: Example XSL stylesheet for indexing query result XML (janhoy)
 
+* SOLR-3097, SOLR-3105: Add analysis configurations for different languages to 
+  the example.  (Christian Moen, Robert Muir)
+
 Build
 ----------------------
 * SOLR-2487: Add build target to package war without slf4j jars (janhoy)
diff --git a/solr/build.xml b/solr/build.xml
index bbcf467..f57db03 100644
--- a/solr/build.xml
+++ b/solr/build.xml
@@ -625,4 +625,98 @@
       <arg value="update"/>
     </exec>
   </target>
+
+  <property name="analysis-common.res.dir"  value="../modules/analysis/common/src/resources/org/apache/lucene/analysis"/>
+  <property name="analysis-kuromoji.res.dir"  value="../modules/analysis/kuromoji/src/resources/org/apache/lucene/analysis"/>
+  <property name="analysis.conf.dest" value="${example}/solr/conf/lang"/>
+
+  <target name="sync-analyzers"
+          description="Committers' Helper: synchronizes analysis resources (e.g. stoplists) to the example">
+    <!-- arabic -->
+    <copy verbose="true" file="${analysis-common.res.dir}/ar/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_ar.txt"/>
+    <!-- bulgarian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/bg/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_bg.txt"/>
+    <!-- catalan -->
+    <copy verbose="true" file="${analysis-common.res.dir}/ca/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_ca.txt"/>
+    <!-- czech -->
+    <copy verbose="true" file="${analysis-common.res.dir}/cz/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_cz.txt"/>
+    <!-- danish -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/danish_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_da.txt"/>
+    <!-- german -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/german_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_de.txt"/>
+    <!-- greek -->
+    <copy verbose="true" file="${analysis-common.res.dir}/el/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_el.txt"/>
+    <!-- spanish -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/spanish_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_es.txt"/>
+  	<!-- basque -->
+    <copy verbose="true" file="${analysis-common.res.dir}/eu/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_eu.txt"/>
+  	<!-- persian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/fa/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_fa.txt"/>
+  	<!-- finnish -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/finnish_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_fi.txt"/>
+  	<!-- french -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/french_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_fr.txt"/>
+  	<!-- galician -->
+    <copy verbose="true" file="${analysis-common.res.dir}/gl/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_gl.txt"/>
+  	<!-- hindi -->
+    <copy verbose="true" file="${analysis-common.res.dir}/hi/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_hi.txt"/>
+  	<!-- hungarian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/hungarian_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_hu.txt"/>
+  	<!-- armenian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/hy/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_hy.txt"/>
+  	<!-- indonesian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/id/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_id.txt"/>
+  	<!-- italian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/italian_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_it.txt"/>
+    <!-- japanese -->
+    <copy verbose="true" file="${analysis-kuromoji.res.dir}/kuromoji/stopwords.txt" 
+                         tofile="${analysis.conf.dest}/stopwords_ja.txt"/>
+    <copy verbose="true" file="${analysis-kuromoji.res.dir}/kuromoji/stoptags.txt" 
+                         tofile="${analysis.conf.dest}/stoptags_ja.txt"/>
+  	<!-- latvian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/lv/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_lv.txt"/>
+  	<!-- dutch -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/dutch_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_nl.txt"/>
+  	<!-- norwegian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/norwegian_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_no.txt"/>
+  	<!-- portuguese -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/portuguese_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_pt.txt"/>
+  	<!-- romanian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/ro/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_ro.txt"/>
+  	<!-- russian -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/russian_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_ru.txt"/>
+  	<!-- swedish -->
+    <copy verbose="true" file="${analysis-common.res.dir}/snowball/swedish_stop.txt"
+                         tofile="${analysis.conf.dest}/stopwords_sv.txt"/>
+  	<!-- thai -->
+    <copy verbose="true" file="${analysis-common.res.dir}/th/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_th.txt"/>
+  	<!-- turkish -->
+    <copy verbose="true" file="${analysis-common.res.dir}/tr/stopwords.txt"
+                         tofile="${analysis.conf.dest}/stopwords_tr.txt"/>
+  </target>
 </project>
diff --git a/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java
index e1a536c..953af62 100644
--- a/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/ElisionFilterFactory.java
@@ -34,7 +34,8 @@ import org.apache.lucene.analysis.TokenStream;
  *   &lt;analyzer&gt;
  *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
  *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
- *     &lt;filter class="solr.ElisionFilterFactory" articles="stopwordarticles.txt"/&gt;
+ *     &lt;filter class="solr.ElisionFilterFactory" 
+ *       articles="stopwordarticles.txt" ignoreCase="true"/&gt;
  *   &lt;/analyzer&gt;
  * &lt;/fieldType&gt;</pre>
  *
@@ -45,10 +46,11 @@ public class ElisionFilterFactory extends BaseTokenFilterFactory implements Reso
 
   public void inform(ResourceLoader loader) {
     String articlesFile = args.get("articles");
+    boolean ignoreCase = getBoolean("ignoreCase", false);
 
     if (articlesFile != null) {
       try {
-        articles = getWordSet(loader, articlesFile, false);
+        articles = getWordSet(loader, articlesFile, ignoreCase);
       } catch (IOException e) {
         throw new RuntimeException(e);
       }
diff --git a/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..ffe731d
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/GalicianMinimalStemFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.gl.GalicianMinimalStemFilter;
+
+/**
+ * Factory for {@link GalicianMinimalStemFilter}. 
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_glplural" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GalicianMinimalStemFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ *
+ */
+public class GalicianMinimalStemFilterFactory extends BaseTokenFilterFactory {
+  public TokenStream create(TokenStream input) {
+    return new GalicianMinimalStemFilter(input);
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java
new file mode 100644
index 0000000..8c19498
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/analysis/GermanNormalizationFilterFactory.java
@@ -0,0 +1,39 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import org.apache.lucene.analysis.TokenStream;
+import org.apache.lucene.analysis.de.GermanNormalizationFilter;
+
+/**
+ * Factory for {@link GermanNormalizationFilter}.
+ * <pre class="prettyprint" >
+ * &lt;fieldType name="text_denorm" class="solr.TextField" positionIncrementGap="100"&gt;
+ *   &lt;analyzer&gt;
+ *     &lt;tokenizer class="solr.StandardTokenizerFactory"/&gt;
+ *     &lt;filter class="solr.LowerCaseFilterFactory"/&gt;
+ *     &lt;filter class="solr.GermanNormalizationFilterFactory"/&gt;
+ *   &lt;/analyzer&gt;
+ * &lt;/fieldType&gt;</pre> 
+ */
+public class GermanNormalizationFilterFactory extends BaseTokenFilterFactory {
+
+  public TokenStream create(TokenStream input) {
+    return new GermanNormalizationFilter(input);
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java
index ebac678..150886d 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestElisionFilterFactory.java
@@ -64,4 +64,22 @@ public class TestElisionFilterFactory extends BaseTokenTestCase {
     assertTokenStreamContents(stream, new String[] { "avion" });
   }
   
+  /**
+   * Test setting ignoreCase=true
+   */
+  public void testCaseInsensitive() throws Exception {
+    Reader reader = new StringReader("L'avion");
+    Tokenizer tokenizer = new MockTokenizer(reader, MockTokenizer.WHITESPACE, false);
+    ElisionFilterFactory factory = new ElisionFilterFactory();
+    factory.init(DEFAULT_VERSION_PARAM);
+    ResourceLoader loader = new SolrResourceLoader(null, null);
+    Map<String,String> args = new HashMap<String,String>();
+    args.put("articles", "frenchArticles.txt");
+    args.put("ignoreCase", "true");
+    factory.init(args);
+    factory.inform(loader);
+    TokenStream stream = factory.create(tokenizer);
+    assertTokenStreamContents(stream, new String[] { "avion" });
+  }
+  
 }
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java
new file mode 100644
index 0000000..ea3e32b
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/analysis/TestGalicianMinimalStemFilterFactory.java
@@ -0,0 +1,36 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the Galician plural stem factory is working.
+ */
+public class TestGalicianMinimalStemFilterFactory extends BaseTokenTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("elefantes");
+    GalicianMinimalStemFilterFactory factory = new GalicianMinimalStemFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "elefante" });
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java
new file mode 100644
index 0000000..8f4a3e6
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/analysis/TestGermanNormalizationFilterFactory.java
@@ -0,0 +1,36 @@
+package org.apache.solr.analysis;
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.analysis.MockTokenizer;
+import org.apache.lucene.analysis.TokenStream;
+
+/**
+ * Simple tests to ensure the German normalization factory is working.
+ */
+public class TestGermanNormalizationFilterFactory extends BaseTokenTestCase {
+  public void testStemming() throws Exception {
+    Reader reader = new StringReader("wei?bier");
+    GermanNormalizationFilterFactory factory = new GermanNormalizationFilterFactory();
+    TokenStream stream = factory.create(new MockTokenizer(reader, MockTokenizer.WHITESPACE, false));
+    assertTokenStreamContents(stream, new String[] { "weissbier" });
+  }
+}
diff --git a/solr/example/solr/conf/lang/contractions_ca.txt b/solr/example/solr/conf/lang/contractions_ca.txt
new file mode 100644
index 0000000..307a85f
--- /dev/null
+++ b/solr/example/solr/conf/lang/contractions_ca.txt
@@ -0,0 +1,8 @@
+# Set of Catalan contractions for ElisionFilter
+# TODO: load this as a resource from the analyzer and sync it in build.xml
+d
+l
+m
+n
+s
+t
diff --git a/solr/example/solr/conf/lang/contractions_fr.txt b/solr/example/solr/conf/lang/contractions_fr.txt
new file mode 100644
index 0000000..722db58
--- /dev/null
+++ b/solr/example/solr/conf/lang/contractions_fr.txt
@@ -0,0 +1,9 @@
+# Set of French contractions for ElisionFilter
+# TODO: load this as a resource from the analyzer and sync it in build.xml
+l
+m
+t
+qu
+n
+s
+j
diff --git a/solr/example/solr/conf/lang/contractions_it.txt b/solr/example/solr/conf/lang/contractions_it.txt
new file mode 100644
index 0000000..cac0409
--- /dev/null
+++ b/solr/example/solr/conf/lang/contractions_it.txt
@@ -0,0 +1,23 @@
+# Set of Italian contractions for ElisionFilter
+# TODO: load this as a resource from the analyzer and sync it in build.xml
+c
+l 
+all 
+dall 
+dell 
+nell 
+sull 
+coll 
+pell 
+gl 
+agl 
+dagl 
+degl 
+negl 
+sugl 
+un 
+m 
+t 
+s 
+v 
+d
diff --git a/solr/example/solr/conf/lang/stemdict_nl.txt b/solr/example/solr/conf/lang/stemdict_nl.txt
new file mode 100644
index 0000000..4410729
--- /dev/null
+++ b/solr/example/solr/conf/lang/stemdict_nl.txt
@@ -0,0 +1,6 @@
+# Set of overrides for the dutch stemmer
+# TODO: load this as a resource from the analyzer and sync it in build.xml
+fiets	fiets
+bromfiets	bromfiets
+ei	eier
+kind	kinder
diff --git a/solr/example/solr/conf/lang/stoptags_ja.txt b/solr/example/solr/conf/lang/stoptags_ja.txt
new file mode 100644
index 0000000..6f5cb8c
--- /dev/null
+++ b/solr/example/solr/conf/lang/stoptags_ja.txt
@@ -0,0 +1,420 @@
+#
+# This file defines a Japanese stoptag set for KuromojiPartOfSpeechStopFilter.
+#
+# Any token with a part-of-speech tag that exactly matches those defined in this
+# file are removed from the token stream.
+#
+# Set your own stoptags by uncommenting the lines below.  Note that comments are
+# not allowed on the same line as a stoptag.  See LUCENE-3745 for frequency lists,
+# etc. that can be useful for building you own stoptag set.
+#
+# The entire possible tagset is provided below for convenience.
+#
+#####
+#  noun: unclassified nouns
+#???
+#
+#  noun-common: Common nouns or nouns where the sub-classification is undefined
+#???-‰∏???
+#
+#  noun-proper: Proper nouns where the sub-classification is undefined 
+#???-?∫Ê????
+#
+#  noun-proper-misc: miscellaneous proper nouns
+#???-?∫Ê????-‰∏???
+#
+#  noun-proper-person: Personal names where the sub-classification is undefined
+#???-?∫Ê????-‰∫∫Â?
+#
+#  noun-proper-person-misc: names that cannot be divided into surname and 
+#  given name; foreign names; names where the surname or given name is unknown.
+#  e.g. ??????
+#???-?∫Ê????-‰∫∫Â?-‰∏???
+#
+#  noun-proper-person-surname: Mainly Japanese surnames.
+#  e.g. Â±±Á?
+#???-?∫Ê????-‰∫∫Â?-Âß?
+#
+#  noun-proper-person-given_name: Mainly Japanese given names.
+#  e.g. Â§??
+#???-?∫Ê????-‰∫∫Â?-??
+#
+#  noun-proper-organization: Names representing organizations.
+#  e.g. ?????, NHK
+#???-?∫Ê????-Áµ??
+#
+#  noun-proper-place: Place names where the sub-classification is undefined
+#???-?∫Ê????-?∞Â?
+#
+#  noun-proper-place-misc: Place names excluding countries.
+#  e.g. ?????, ????ª„???, ‰∫??
+#???-?∫Ê????-?∞Â?-‰∏???
+#
+#  noun-proper-place-country: Country names. 
+#  e.g. ?•Ê?, ????π„??©„???
+#???-?∫Ê????-?∞Â?-??
+#
+#  noun-pronoun: Pronouns where the sub-classification is undefined
+#???-‰ª£Â?Ë©?
+#
+#  noun-pronoun-misc: miscellaneous pronouns: 
+#  e.g. ???, ???, ?????, ?????, ??????, ?????, ?©„???, ???, ?ø„????, ?ø„???, ??????, ??????
+#???-‰ª£Â?Ë©?-‰∏???
+#
+#  noun-pronoun-contraction: Spoken language contraction made by combining a 
+#  pronoun and the particle 'wa'.
+#  e.g. ?????, ?????, ??????, ?????, ?????? 
+#???-‰ª£Â?Ë©?-Á∏??
+#
+#  noun-adverbial: Temporal nouns such as names of days or months that behave 
+#  like adverbs. Nouns that represent amount or ratios and can be used adverbially,
+#  e.g. ???, ‰∏???, ???, Â∞??
+#???-??????
+#
+#  noun-verbal: Nouns that take arguments with case and can appear followed by 
+#  'suru' and related verbs (???, ?ß„???, ?????, ??????)
+#  e.g. ?§„??????, ???, ???, ??????, ‰∏?ÂÆ??, ‰∏????
+#???-?µÂ??•Á?
+#
+#  noun-adjective-base: The base form of adjectives, words that appear before ?? ("na")
+#  e.g. ?•Â∫∑, ÂÆ??, Èß??, ???
+#???-ÂΩ¢Â????Ë™?ππ
+#
+#  noun-numeric: Arabic numbers, Chinese numerals, and counters like ‰Ω? (??), ??.
+#  e.g. 0, 1, 2, ‰Ω?, ??, Âπ?
+#???-??
+#
+#  noun-affix: noun affixes where the sub-classification is undefined
+#???-???Á´?
+#
+#  noun-affix-misc: Of adnominalizers, the case-marker ?? ("no"), and words that 
+#  attach to the base form of inflectional words, words that cannot be classified 
+#  into any of the other categories below. This category includes indefinite nouns.
+#  e.g. ????§„?, ??, ???, ?≤Ê?, Ê∞?, ?????, Â´??, ???, ??, ???, ‰∫?, ???, ÊØ?, ?????, Ê¨°Á?, 
+#       ??, ???, ????, ?§„???, Â∫??, ?§„???, Á©????, ??, ?©„???, ??, ???, Á≠?, ?????, Âºæ„?, 
+#       ???, ?µ„?, ?µ„?, ???, ?ª„?, ??, ??, ???, ??, ??, ???, ??, ?????, ??‰ª?, ???, Ë®?,
+#       ???, ?≤„?, ??, ??-?£Ë?/, ???-?£Ë?/
+#???-???Á´?-‰∏???
+#
+#  noun-affix-adverbial: noun affixes that that can behave as adverbs.
+#  e.g. ?????, ??, ?????, ?????, ???, Âæ?, ‰Ω??, ‰ª•Â?, ‰ª•È?, ‰ª•Â?, ‰ª•‰?, ‰ª•Â?, ‰∏???, ???, 
+#       ‰∏?, ???, ??, ???, ???, ?????, ???, ???, ?£„???, Áµ??, ???, ??, ???, ??, ??‰∏?, ?????, 
+#       ??‰∏?, ?????, ???, ???, Â∫?, ???, ??, ?§„?, ?ΩÂ∫¶, ?®„???, ???, ?®„?, ??, ?®„???, ??, 
+#       ?®„???, ???, ???, ‰∏?, ???, Âæ?, ?∞„???, ?¥Â?, ??, ?∂„?, ??, ?ª„?, ‰ª?, ?æ„?, ??, ?æ„?, 
+#       ??, ‰æ?, ?ø„???, ?¢Â?
+#???-???Á´?-??????
+#
+#  noun-affix-aux: noun affixes treated as ?©Â?Ë©? ("auxiliary verb") in school grammars 
+#  with the stem ???(??) ("you(da)").
+#  e.g.  ???, ???, Êß? (???)
+#???-???Á´?-?©Â?Ë©??Âπ?
+#  
+#  noun-affix-adjective-base: noun affixes that can connect to the indeclinable
+#  connection form ?? (aux "da").
+#  e.g. ?ø„???, ?µ„?
+#???-???Á´?-ÂΩ¢Â????Ë™?ππ
+#
+#  noun-special: special nouns where the sub-classification is undefined.
+#???-?πÊ?
+#
+#  noun-special-aux: The ????? ("souda") stem form that is used for reporting news, is 
+#  treated as ?©Â?Ë©? ("auxiliary verb") in school grammars, and attach to the base 
+#  form of inflectional words.
+#  e.g. ???
+#???-?πÊ?-?©Â?Ë©??Âπ?
+#
+#  noun-suffix: noun suffixes where the sub-classification is undefined.
+#???-?•Â∞æ
+#
+#  noun-suffix-misc: Of the nouns or stem forms of other parts of speech that connect 
+#  to ??? or ?ø„? and can combine into compound nouns, words that cannot be classified into
+#  any of the other categories below. In general, this category is more inclusive than 
+#  ?•Â∞æË™? ("suffix") and is usually the last element in a compound noun.
+#  e.g. ???, ???, ??, ?≤Ê? (???), ?????, ???, Ê∞??, ?????, (ÔΩ????) ??, Ê¨°Á?, Ê∏? (??) ??,
+#       ???, (?ß„?)?£„?, ??, Ë¶?, ??, Â≠?, È°?, ??, ??
+#???-?•Â∞æ-‰∏???
+#
+#  noun-suffix-person: Suffixes that form nouns and attach to person names more often
+#  than other nouns.
+#  e.g. ??, Êß?, ??
+#???-?•Â∞æ-‰∫∫Â?
+#
+#  noun-suffix-place: Suffixes that form nouns and attach to place names more often 
+#  than other nouns.
+#  e.g. ??, Â∏?, ??
+#???-?•Â∞æ-?∞Â?
+#
+#  noun-suffix-verbal: Of the suffixes that attach to nouns and form nouns, those that 
+#  can appear before ?π„? ("suru").
+#  e.g. ??, Ë¶?, ???, ?•„?, ?Ω„?, Ë≤∑„?
+#???-?•Â∞æ-?µÂ??•Á?
+#
+#  noun-suffix-aux: The stem form of ????? (Êß??) that is used to indicate conditions, 
+#  is treated as ?©Â?Ë©? ("auxiliary verb") in school grammars, and attach to the 
+#  conjunctive form of inflectional words.
+#  e.g. ???
+#???-?•Â∞æ-?©Â?Ë©??Âπ?
+#
+#  noun-suffix-adjective-base: Suffixes that attach to other nouns or the conjunctive 
+#  form of inflectional words and appear before the copula ?? ("da").
+#  e.g. ??, ??, ???
+#???-?•Â∞æ-ÂΩ¢Â????Ë™?ππ
+#
+#  noun-suffix-adverbial: Suffixes that attach to other nouns and can behave as adverbs.
+#  e.g. Âæ? (??), ‰ª•Â?, ‰ª•È?, ‰ª•Â?, ???, ‰∏?, ??, ‰∏?, ?? (??)
+#???-?•Â∞æ-??????
+#
+#  noun-suffix-classifier: Suffixes that attach to numbers and form nouns. This category 
+#  is more inclusive than ?©Ê?Ë©? ("classifier") and includes common nouns that attach 
+#  to numbers.
+#  e.g. ??, ??, ??, ??, ????ª„???, cm, kg, ???, ???, ?∫Á?, ???, ???
+#???-?•Â∞æ-?©Ê?Ë©?
+#
+#  noun-suffix-special: Special suffixes that mainly attach to inflecting words.
+#  e.g. (Ê•Ω„?) ??, (???) ??
+#???-?•Â∞æ-?πÊ?
+#
+#  noun-suffix-conjunctive: Nouns that behave like conjunctions and join two words 
+#  together.
+#  e.g. (?•Ê?) ÂØ? (??????), ÂØ? (??????), (3) ÂØ? (5), (Â•≥Â?) ?? (‰∏ªÂ©¶)
+#???-?•Á?Ë©??
+#
+#  noun-verbal_aux: Nouns that attach to the conjunctive particle ?? ("te") and are 
+#  semantically verb-like.
+#  e.g. ?????, ??¶ß, Âæ°Ë¶ß, ???
+#???-??????Á´??
+#
+#  noun-quotation: text that cannot be segmented into words, proverbs, Chinese poetry, 
+#  dialects, English, etc. Currently, the only entry for ??? Âº??????? ("noun quotation") 
+#  is ????? ("iwaku").
+#???-Âº???????
+#
+#  noun-nai_adjective: Words that appear before the auxiliary verb ??? ("nai") and
+#  behave like an adjective.
+#  e.g. ?≥„?Ë®?, ‰ª??, ?®„??ß„?, ???
+#???-???ÂΩ¢Â?Ë©??Âπ?
+#
+#####
+#  prefix: unclassified prefixes
+#?•È?Ë©?
+#
+#  prefix-nominal: Prefixes that attach to nouns (including adjective stem forms) 
+#  excluding numerical expressions.
+#  e.g. ?? (Ê∞?), ?? (Ê∞?), ?? (Á§?), ?? (ÔΩ??), È´? (??≥™), ?? (Ë¶??), ?? (Á´?¥æ)
+#?•È?Ë©?-????•Á?
+#
+#  prefix-verbal: Prefixes that attach to the imperative form of a verb or a verb
+#  in conjunctive form followed by ???/?????/??????.
+#  e.g. ?? (Ë™???????), ?? (Â∫ß„?)
+#?•È?Ë©?-????•Á?
+#
+#  prefix-adjectival: Prefixes that attach to adjectives.
+#  e.g. ?? (ÂØ???ß„????), ??? (?ß„???)
+#?•È?Ë©?-ÂΩ¢Â?Ë©??Á∂?
+#
+#  prefix-numerical: Prefixes that attach to numerical expressions.
+#  e.g. Á¥?, ?????, ÊØ??
+#?•È?Ë©?-?∞Ê?Á∂?
+#
+#####
+#  verb: unclassified verbs
+#???
+#
+#  verb-main:
+#???-???
+#
+#  verb-auxiliary:
+#???-???Á´?
+#
+#  verb-suffix:
+#???-?•Â∞æ
+#
+#####
+#  adjective: unclassified adjectives
+#ÂΩ¢Â?Ë©?
+#
+#  adjective-main:
+#ÂΩ¢Â?Ë©?-???
+#
+#  adjective-auxiliary:
+#ÂΩ¢Â?Ë©?-???Á´?
+#
+#  adjective-suffix:
+#ÂΩ¢Â?Ë©?-?•Â∞æ
+#
+#####
+#  adverb: unclassified adverbs
+#???
+#
+#  adverb-misc: Words that can be segmented into one unit and where adnominal 
+#  modification is not possible.
+#  e.g. ?????????, Â§??
+#???-‰∏???
+#
+#  adverb-particle_conjunction: Adverbs that can be followed by ??, ??, ??, 
+#  ??, ???, ??, etc.
+#  e.g. ??????, ??????, ??????, ?????, ????ß„?
+#???-?©Ë?È°??Á∂?
+#
+#####
+#  adnominal: Words that only have noun-modifying forms.
+#  e.g. ???, ???, ???, ?©„?, ??????, ????????, ‰Ω?????, ??????, ??????, ??????, ??????, 
+#       ?©„????, ?????, ?????, ?????, ?©„???, Â§ß„???, Â∞????, ??????, ?ª„???, ??????, 
+#       ??(, ??) ??? (????????)??, Âæ??????, ???????, ?????, ??????, ??????????, ‰∫°„?
+#?£‰?Ë©?
+#
+#####
+#  conjunction: Conjunctions that can occur independently.
+#  e.g. ??, ????©„?, ?????, ?????, ????©„????
+?•Á?Ë©?
+#
+#####
+#  particle: unclassified particles.
+?©Ë?
+#
+#  particle-case: case particles where the subclassification is undefined.
+?©Ë?-?ºÂ?Ë©?
+#
+#  particle-case-misc: Case particles.
+#  e.g. ???, ??, ??, ??, ??, ??, ???, ??, ??, ???
+?©Ë?-?ºÂ?Ë©?-‰∏???
+#
+#  particle-case-quote: the "to" that appears after nouns, a person?? speech, 
+#  quotation marks, expressions of decisions from a meeting, reasons, judgements,
+#  conjectures, etc.
+#  e.g. ( ??) ?? (Ëø∞„???.), ( ?ß„???) ?? (????∑Ë??∂‰?...)
+?©Ë?-?ºÂ?Ë©?-Âº??
+#
+#  particle-case-compound: Compounds of particles and verbs that mainly behave 
+#  like case particles.
+#  e.g. ?®„???, ?®„??£„?, ?®„????, ?®„???, ?®„????, ?®Â???, ?ß„??£„?, ????????, ????????, ????£„?,
+#       ??????, ??????, ?????, ??????, ??????, ??????, ??????,?????, ??????, ??????, 
+#       ?????, ??????, ??????, ?????, ????????, ??????, ????????, ??????, ?????, 
+#       ??????, ????????, ?????, ?????, ???????£„?, ????£„?, ??????, ?????, ????????, 
+#       ??????, ????????, ??????, ??????, ?????, ?????, ??????, ?????, ??????, ????£„?,
+#       ?????, ????§„???, ????£„?, ????£„?, ????£„?, ?????, ?????, ?????, ?????, ?????, ?????, 
+#       ????????, ??????, ????£„?, ??ª•?£„?, ?????, ???????, ???????, ????????, ??????, ??????,
+#       ?£„?-?£Ë?/, ?°„???-?¢Ë•øÂº?????????/, (‰Ω?) ????? (‰∫?)-?£Ë?/, ?£„????-?£Ë?/, ?®„???, ?®„????
+?©Ë?-?ºÂ?Ë©?-?£Ë?
+#
+#  particle-conjunctive:
+#  e.g. ???, ??????, ??, ?????, ????©„?, ???, ??, ?§„?, ??, ??, ??, ?®„????, ?©„????, ?®„?, ?©„?, 
+#       ?????, ???, ???, ???, ??, ?????, ?? ( ???), ??????, (?????) ???(??????)-?£Ë?/, 
+#       (Ë°??) ?°„?(??????)-?£Ë?/, (Ë®???) ????? (?????????)-?£Ë?/, (????????)?£„??£„? (Âπ≥Ê?)-?£Ë?/
+?©Ë?-?•Á??©Ë?
+#
+#  particle-dependency:
+#  e.g. ???, ???, ???, ???, ??, ??, ??
+?©Ë?-‰ø??Ë©?
+#
+#  particle-adverbial:
+#  e.g. ?????, ???, ?????, ‰Ω?, ?????, ???, (Â≠??) ???(??????Ë°???????)-?£Ë?/, 
+#       (???)????? (??????)-?£Ë?/, ???, (Áß?) ???, ???, (Áß?) ??? (??), (???) ????? (Â§ßÂ???)-?£Ë?/,
+#       (Áß?) ?????, (???) ????? (Â§ßÂ???)-?£Ë?/, ???, ???, (Áß?) ?????-?£Ë?/, ???, 
+#       (ÂΩ?)?£„???-?£Ë?/, (???) ?ß„? (?????), Á≠? (?®„?), (‰ª??) ?®„?, ?∞„???, ?∞„???-?£Ë?/, ?∞„????-?£Ë?/,
+#       ?ª„?, Á®?, ?æ„?, Ëø?, (Ë™?) ?? (??)([?©Ë?-?ºÂ?Ë©? ????? [?©Ë?-‰ø??Ë©? ??????ÁΩ?????????)
+?©Ë?-???Ë©?
+#
+#  particle-interjective: particles with interjective grammatical roles.
+#  e.g. (?æÂ≥∂) ??
+?©Ë?-????©Ë?
+#
+#  particle-coordinate:
+#  e.g. ??, ???, ???, ???, ?®„?, ???, ??, ???
+?©Ë?-‰∏???©Ë?
+#
+#  particle-final:
+#  e.g. ???, ?????, ??, ??, (??)?£„?-?£Ë?/, (?®„??£„???) ??-?πË?/, ??, ??, ???-?£Ë?/, ??, ??, ??, 
+#       ???-?£Ë?/, ???-?£Ë?/, ???-?πË?/, ??, ???-?£Ë?/, ??, ??, ??, ???-?£Ë?/, ??, ???-?£Ë?/
+?©Ë?-Áµ??Ë©?
+#
+#  particle-adverbial/conjunctive/final: The particle "ka" when unknown whether it is 
+#  adverbial, conjunctive, or sentence final. For example:
+#       (a) ?? ?? B ????. Ex:??(?ΩÂ??ßÈ??®„???) ??,(Êµ∑Â??ßÈ??®„???) ?? (.)??
+#       (b) Inside an adverb phrase. Ex:??(Âπ∏„??®„???) ?? (, Ê≠ªË???????????.)??
+#           ??(Á•???????????) ?? (, Ë©??????º„???.)??
+#       (c) ???????????. Ex:??(‰Ω??????£„?) ?? (??????????????.)??
+#  e.g. ??
+?©Ë?-???Ë©??‰∏???©Ë?Ôº???©Ë?
+#
+#  particle-adnominalizer: The "no" that attaches to nouns and modifies 
+#  non-inflectional words.
+?©Ë?-?£‰???
+#
+#  particle-adnominalizer: The "ni" and "to" that appear following nouns and adverbs 
+#  that are giongo, giseigo, or gitaigo.
+#  e.g. ??, ??
+?©Ë?-?????
+#
+#  particle-special: A particle that does not fit into one of the above classifications. 
+#  This includes particles that are used in Tanka, Haiku, and other poetry.
+#  e.g. ???, ???, ( ????????) ??, (?????) ???(??????), (‰ø?) ?? (ÂÆ?)
+?©Ë?-?πÊ?
+#
+#####
+#  auxiliary-verb:
+?©Â?Ë©?
+#
+#####
+#  interjection: Greetings and other exclamations.
+#  e.g. ??????, ??????????????, ????????, ????∞„???, ????????, ?©„????????®„?, ?????????????æ„?, 
+#       ???????æ„?, ?????????, ??????, ????????, ???, ?????, ?????, ?????????
+#???Ë©?
+#
+#####
+#  symbol: unclassified Symbols.
+Ë®??
+#
+#  symbol-misc: A general symbol not in one of the categories below.
+#  e.g. [???@$???+]
+Ë®??-‰∏???
+#
+#  symbol-comma: Commas
+#  e.g. [,??
+Ë®??-Ë™??
+#
+#  symbol-period: Periods and full stops.
+#  e.g. [.Ôº???
+Ë®??-?•Á?
+#
+#  symbol-space: Full-width whitespace.
+Ë®??-Á©∫Á?
+#
+#  symbol-open_bracket:
+#  e.g. [({????????
+Ë®??-??ºß??
+#
+#  symbol-close_bracket:
+#  e.g. [)}??????????
+Ë®??-??ºß??
+#
+#  symbol-alphabetic:
+#Ë®??-???????????
+#
+#####
+#  other: unclassified other
+#???‰ª?
+#
+#  other-interjection: Words that are hard to classify as noun-suffixes or 
+#  sentence-final particles.
+#  e.g. (??)??
+???‰ª?-???
+#
+#####
+#  filler: Aizuchi that occurs during a conversation or sounds inserted as filler.
+#  e.g. ???, ?????, ???
+????©„?
+#
+#####
+#  non-verbal: non-verbal sound.
+???Ë™??
+#
+#####
+#  fragment:
+#Ë™????
+#
+#####
+#  unknown: unknown part of speech.
+#???Ë™?
+#
+##### End of file
\ No newline at end of file
diff --git a/solr/example/solr/conf/lang/stopwords_ar.txt b/solr/example/solr/conf/lang/stopwords_ar.txt
new file mode 100644
index 0000000..2189784
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_ar.txt
@@ -0,0 +1,123 @@
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# Also see http://www.opensource.org/licenses/bsd-license.html
+# Cleaned on October 11, 2009 (not normalized, so use before normalization)
+??
+???
+???ÿß
+???
+??
+???
+???ÿß
+???
+?
+?
+ÿ´?
+ÿß?
+ÿ£?
+ÿ®
+ÿ®?ÿß
+ÿ®?
+ÿß
+ÿ£
+ÿß?
+ÿß?
+ÿ£?
+ÿ£?
+?ÿß
+??ÿß
+ÿß?ÿß
+ÿ£?ÿß
+ÿ•?ÿß
+???
+?ÿß
+??ÿß
+??ÿß
+??ÿß
+ÿπ?
+?ÿπ
+ÿßÿ∞ÿß
+ÿ•ÿ∞ÿß
+ÿß?
+ÿ£?
+ÿ•?
+ÿß??ÿß
+ÿ£??ÿß
+ÿ•??ÿß
+ÿß??
+ÿ£??
+ÿ•??
+ÿ®ÿß?
+ÿ®ÿ£?
+?ÿß?
+?ÿ£?
+?ÿß?
+?ÿ£?
+?ÿ•?
+ÿß?ÿ™?
+ÿß?ÿ™?
+ÿß?ÿ∞?
+ÿß?ÿ∞?
+ÿß?ÿ∞??
+ÿß??
+ÿß??
+ÿ•??
+ÿ•??
+ÿπ??
+ÿπ???ÿß
+ÿπ???
+ÿß?ÿß
+ÿ£?ÿß
+ÿ•?ÿß
+ÿß?ÿ∂ÿß
+ÿ£?ÿ∂ÿß
+??
+???
+??
+???
+??
+???
+??
+??
+??
+???
+???
+???
+???
+???
+???
+ÿß?ÿ™
+ÿ£?ÿ™
+??
+??ÿß
+??
+?ÿ∞?
+?ÿ∞ÿß
+ÿ™??
+ÿ∞??
+??ÿß?
+?ÿß?ÿ™
+?ÿß?
+????
+ÿ™???
+??ÿß?ÿ™
+??ÿß?
+ÿ∫?ÿ±
+ÿ®ÿπÿ∂
+?ÿØ
+?ÿ≠?
+ÿ®??
+ÿ®???ÿß
+??ÿ∞
+ÿ∂??
+ÿ≠?ÿ´
+ÿß?ÿß?
+ÿß?ÿ¢?
+ÿÆ?ÿß?
+ÿ®ÿπÿØ
+?ÿ®?
+ÿ≠ÿ™?
+ÿπ?ÿØ
+ÿπ?ÿØ?ÿß
+?ÿØ?
+ÿ¨??ÿπ
diff --git a/solr/example/solr/conf/lang/stopwords_bg.txt b/solr/example/solr/conf/lang/stopwords_bg.txt
new file mode 100644
index 0000000..1ae4ba2
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_bg.txt
@@ -0,0 +1,193 @@
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# Also see http://www.opensource.org/licenses/bsd-license.html
+–∞
+–∞–∑
+–∞–∫–æ
+–∞–ª–∞
+–±–µ
+–±–µ–∑
+–±–µ?–µ
+–±–∏
+–±–∏–ª
+–±–∏–ª–∞
+–±–∏–ª–∏
+–±–∏–ª–æ
+–±–ª–∏–∑–æ
+–±?–¥–∞?
+–±?–¥–µ
+–±??–∞
+–≤
+–≤–∞?
+–≤–∞?
+–≤–∞?–∞
+–≤–µ?–æ??–Ω–æ
+–≤–µ?–µ
+–≤–∑–µ–º–∞
+–≤–∏
+–≤–∏–µ
+–≤–∏–Ω–∞–≥–∏
+–≤?–µ
+–≤?–µ–∫–∏
+–≤?–∏?–∫–∏
+–≤?–∏?–∫–æ
+–≤??–∫–∞
+–≤?–≤
+–≤?–ø?–µ–∫–∏
+–≤????
+–≥
+–≥–∏
+–≥–ª–∞–≤–Ω–æ
+–≥–æ
+–¥
+–¥–∞
+–¥–∞–ª–∏
+–¥–æ
+–¥–æ–∫–∞?–æ
+–¥–æ–∫–æ–≥–∞
+–¥–æ?–∏
+–¥–æ?–µ–≥–∞
+–¥–æ??–∞
+–µ
+–µ–¥–≤–∞
+–µ–¥–∏–Ω
+–µ?–æ
+–∑–∞
+–∑–∞–¥
+–∑–∞–µ–¥–Ω–æ
+–∑–∞?–∞–¥–∏
+–∑–∞?–µ–≥–∞
+–∑–∞?–æ–≤–∞
+–∑–∞?–æ
+–∑–∞?–æ?–æ
+–∏
+–∏–∑
+–∏–ª–∏
+–∏–º
+–∏–º–∞
+–∏–º–∞?
+–∏?–∫–∞
+–π
+–∫–∞–∑–∞
+–∫–∞–∫
+–∫–∞–∫–≤–∞
+–∫–∞–∫–≤–æ
+–∫–∞–∫?–æ
+–∫–∞–∫?–≤
+–∫–∞?–æ
+–∫–æ–≥–∞
+–∫–æ–≥–∞?–æ
+–∫–æ–µ?–æ
+–∫–æ–∏?–æ
+–∫–æ–π
+–∫–æ–π?–æ
+–∫–æ–ª–∫–æ
+–∫–æ??–æ
+–∫?–¥–µ
+–∫?–¥–µ?–æ
+–∫?–º
+–ª–∏
+–º
+–º–µ
+–º–µ–∂–¥?
+–º–µ–Ω
+–º–∏
+–º–Ω–æ–∑–∏–Ω–∞
+–º–æ–≥–∞
+–º–æ–≥–∞?
+–º–æ–∂–µ
+–º–æ–ª?
+–º–æ–º–µ–Ω?–∞
+–º?
+–Ω
+–Ω–∞
+–Ω–∞–¥
+–Ω–∞–∑–∞–¥
+–Ω–∞–π
+–Ω–∞–ø?–∞–≤–∏
+–Ω–∞–ø?–µ–¥
+–Ω–∞–ø?–∏–º–µ?
+–Ω–∞?
+–Ω–µ
+–Ω–µ–≥–æ
+–Ω–µ?
+–Ω–∏
+–Ω–∏–µ
+–Ω–∏–∫–æ–π
+–Ω–∏?–æ
+–Ω–æ
+–Ω?–∫–æ–∏
+–Ω?–∫–æ–π
+–Ω?–º–∞
+–æ–±–∞?–µ
+–æ–∫–æ–ª–æ
+–æ?–≤–µ–Ω
+–æ?–æ–±–µ–Ω–æ
+–æ?
+–æ?–≥–æ?–µ
+–æ?–Ω–æ–≤–æ
+–æ?–µ
+–ø–∞–∫
+–ø–æ
+–ø–æ–≤–µ?–µ
+–ø–æ–≤–µ?–µ?–æ
+–ø–æ–¥
+–ø–æ–Ω–µ
+–ø–æ?–∞–¥–∏
+–ø–æ?–ª–µ
+–ø–æ??–∏
+–ø?–∞–≤–∏
+–ø?–µ–¥
+–ø?–µ–¥–∏
+–ø?–µ–∑
+–ø?–∏
+–ø?–∫
+–ø??–≤–æ
+?
+?–∞
+?–∞–º–æ
+?–µ
+?–µ–≥–∞
+?–∏
+?–∫–æ?–æ
+?–ª–µ–¥
+?–º–µ
+?–ø–æ?–µ–¥
+??–µ–¥
+??–µ??
+??–µ
+??–º
+???
+???–æ
+?
+?–∞–∑–∏
+?–∞–∫–∞
+?–∞–∫–∏–≤–∞
+?–∞–∫?–≤
+?–∞–º
+?–≤–æ–π
+?–µ
+?–µ–∑–∏
+?–∏
+?–Ω
+?–æ
+?–æ–≤–∞
+?–æ–≥–∞–≤–∞
+?–æ–∑–∏
+?–æ–π
+?–æ–ª–∫–æ–≤–∞
+?–æ?–Ω–æ
+???–±–≤–∞
+??–∫
+??–π
+??
+???
+?
+?–∞?–µ?–≤–∞
+?
+?–µ
+?–µ??–æ
+??–µ–∑
+?–µ
+?–æ–º
+?
diff --git a/solr/example/solr/conf/lang/stopwords_ca.txt b/solr/example/solr/conf/lang/stopwords_ca.txt
new file mode 100644
index 0000000..3da65de
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_ca.txt
@@ -0,0 +1,220 @@
+# Catalan stopwords from http://github.com/vcl/cue.language (Apache 2 Licensed)
+a
+abans
+ac√≠
+ah
+aix√≠
+aix√≤
+al
+als
+aleshores
+algun
+alguna
+algunes
+alguns
+alhora
+all?
+all√≠
+all√≤
+altra
+altre
+altres
+amb
+ambd√≥s
+ambdues
+apa
+aquell
+aquella
+aquelles
+aquells
+aquest
+aquesta
+aquestes
+aquests
+aqu√≠
+baix
+cada
+cadasc√∫
+cadascuna
+cadascunes
+cadascuns
+com
+contra
+d'un
+d'una
+d'unes
+d'uns
+dalt
+de
+del
+dels
+des
+despr√©s
+dins
+dintre
+donat
+doncs
+durant
+e
+eh
+el
+els
+em
+en
+encara
+ens
+entre
+√©rem
+eren
+√©reu
+es
+√©s
+esta
+est?
+est?vem
+estaven
+est?veu
+esteu
+et
+etc
+ets
+fins
+fora
+gaireb√©
+ha
+han
+has
+havia
+he
+hem
+heu
+hi 
+ho
+i
+igual
+iguals
+ja
+l'hi
+la
+les
+li
+li'n
+llavors
+m'he
+ma
+mal
+malgrat
+mateix
+mateixa
+mateixes
+mateixos
+me
+mentre
+m√©s
+meu
+meus
+meva
+meves
+molt
+molta
+moltes
+molts
+mon
+mons
+n'he
+n'hi
+ne
+ni
+no
+nogensmenys
+nom√©s
+nosaltres
+nostra
+nostre
+nostres
+o
+oh
+oi
+on
+pas
+pel
+pels
+per
+per√≤
+perqu√®
+poc 
+poca
+pocs
+poques
+potser
+propi
+qual
+quals
+quan
+quant 
+que
+qu√®
+quelcom
+qui
+quin
+quina
+quines
+quins
+s'ha
+s'han
+sa
+semblant
+semblants
+ses
+seu 
+seus
+seva
+seva
+seves
+si
+sobre
+sobretot
+s√≥c
+solament
+sols
+son 
+s√≥n
+sons 
+sota
+sou
+t'ha
+t'han
+t'he
+ta
+tal
+tamb√©
+tampoc
+tan
+tant
+tanta
+tantes
+teu
+teus
+teva
+teves
+ton
+tons
+tot
+tota
+totes
+tots
+un
+una
+unes
+uns
+us
+va
+vaig
+vam
+van
+vas
+veu
+vosaltres
+vostra
+vostre
+vostres
diff --git a/solr/example/solr/conf/lang/stopwords_cz.txt b/solr/example/solr/conf/lang/stopwords_cz.txt
new file mode 100644
index 0000000..53c6097
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_cz.txt
@@ -0,0 +1,172 @@
+a
+s
+k
+o
+i
+u
+v
+z
+dnes
+cz
+t√≠mto
+bude≈°
+budem
+byli
+jse≈°
+m≈Øj
+sv√Ωm
+ta
+tomto
+tohle
+tuto
+tyto
+jej
+zda
+pro?
+m√°te
+tato
+kam
+tohoto
+kdo
+kte?√≠
+mi
+n√°m
+tom
+tomuto
+m√≠t
+nic
+proto
+kterou
+byla
+toho
+proto≈æe
+asi
+ho
+na≈°i
+napi≈°te
+re
+co≈æ
+t√≠m
+tak≈æe
+sv√Ωch
+jej√≠
+sv√Ωmi
+jste
+aj
+tu
+tedy
+teto
+bylo
+kde
+ke
+prav√©
+ji
+nad
+nejsou
+?i
+pod
+t√©ma
+mezi
+p?es
+ty
+pak
+v√°m
+ani
+kdy≈æ
+v≈°ak
+neg
+jsem
+tento
+?l√°nku
+?l√°nky
+aby
+jsme
+p?ed
+pta
+jejich
+byl
+je≈°t?
+a≈æ
+bez
+tak√©
+pouze
+prvn√≠
+va≈°e
+kter√°
+n√°s
+nov√Ω
+tipy
+pokud
+m≈Ø≈æe
+strana
+jeho
+sv√©
+jin√©
+zpr√°vy
+nov√©
+nen√≠
+v√°s
+jen
+podle
+zde
+u≈æ
+b√Ωt
+v√≠ce
+bude
+ji≈æ
+ne≈æ
+kter√Ω
+by
+kter√©
+co
+nebo
+ten
+tak
+m√°
+p?i
+od
+po
+jsou
+jak
+dal≈°√≠
+ale
+si
+se
+ve
+to
+jako
+za
+zp?t
+ze
+do
+pro
+je
+na
+atd
+atp
+jakmile
+p?i?em≈æ
+j√°
+on
+ona
+ono
+oni
+ony
+my
+vy
+j√≠
+ji
+m?
+mne
+jemu
+tomu
+t?m
+t?mu
+n?mu
+n?mu≈æ
+jeho≈æ
+j√≠≈æ
+jeliko≈æ
+je≈æ
+jako≈æ
+na?e≈æ
diff --git a/solr/example/solr/conf/lang/stopwords_da.txt b/solr/example/solr/conf/lang/stopwords_da.txt
new file mode 100644
index 0000000..a3ff5fe
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_da.txt
@@ -0,0 +1,108 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/danish/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Danish stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ | This is a ranked list (commonest to rarest) of stopwords derived from
+ | a large text sample.
+
+
+og           | and
+i            | in
+jeg          | I
+det          | that (dem. pronoun)/it (pers. pronoun)
+at           | that (in front of a sentence)/to (with infinitive)
+en           | a/an
+den          | it (pers. pronoun)/that (dem. pronoun)
+til          | to/at/for/until/against/by/of/into, more
+er           | present tense of "to be"
+som          | who, as
+p√•           | on/upon/in/on/at/to/after/of/with/for, on
+de           | they
+med          | with/by/in, along
+han          | he
+af           | of/by/from/off/for/in/with/on, off
+for          | at/for/to/from/by/of/ago, in front/before, because
+ikke         | not
+der          | who/which, there/those
+var          | past tense of "to be"
+mig          | me/myself
+sig          | oneself/himself/herself/itself/themselves
+men          | but
+et           | a/an/one, one (number), someone/somebody/one
+har          | present tense of "to have"
+om           | round/about/for/in/a, about/around/down, if
+vi           | we
+min          | my
+havde        | past tense of "to have"
+ham          | him
+hun          | she
+nu           | now
+over         | over/above/across/by/beyond/past/on/about, over/past
+da           | then, when/as/since
+fra          | from/off/since, off, since
+du           | you
+ud           | out
+sin          | his/her/its/one's
+dem          | them
+os           | us/ourselves
+op           | up
+man          | you/one
+hans         | his
+hvor         | where
+eller        | or
+hvad         | what
+skal         | must/shall etc.
+selv         | myself/youself/herself/ourselves etc., even
+her          | here
+alle         | all/everyone/everybody etc.
+vil          | will (verb)
+blev         | past tense of "to stay/to remain/to get/to become"
+kunne        | could
+ind          | in
+n√•r          | when
+v√¶re         | present tense of "to be"
+dog          | however/yet/after all
+noget        | something
+ville        | would
+jo           | you know/you see (adv), yes
+deres        | their/theirs
+efter        | after/behind/according to/for/by/from, later/afterwards
+ned          | down
+skulle       | should
+denne        | this
+end          | than
+dette        | this
+mit          | my/mine
+ogs√•         | also
+under        | under/beneath/below/during, below/underneath
+have         | have
+dig          | you
+anden        | other
+hende        | her
+mine         | my
+alt          | everything
+meget        | much/very, plenty of
+sit          | his, her, its, one's
+sine         | his, her, its, one's
+vor          | our
+mod          | against
+disse        | these
+hvis         | if
+din          | your/yours
+nogle        | some
+hos          | by/at
+blive        | be/become
+mange        | many
+ad           | by/through
+bliver       | present tense of "to be/to become"
+hendes       | her/hers
+v√¶ret        | be
+thi          | for (conj)
+jer          | you
+s√•dan        | such, like this/like that
diff --git a/solr/example/solr/conf/lang/stopwords_de.txt b/solr/example/solr/conf/lang/stopwords_de.txt
new file mode 100644
index 0000000..f770384
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_de.txt
@@ -0,0 +1,292 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/german/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A German stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ | The number of forms in this list is reduced significantly by passing it
+ | through the German stemmer.
+
+
+aber           |  but
+
+alle           |  all
+allem
+allen
+aller
+alles
+
+als            |  than, as
+also           |  so
+am             |  an + dem
+an             |  at
+
+ander          |  other
+andere
+anderem
+anderen
+anderer
+anderes
+anderm
+andern
+anderr
+anders
+
+auch           |  also
+auf            |  on
+aus            |  out of
+bei            |  by
+bin            |  am
+bis            |  until
+bist           |  art
+da             |  there
+damit          |  with it
+dann           |  then
+
+der            |  the
+den
+des
+dem
+die
+das
+
+da?            |  that
+
+derselbe       |  the same
+derselben
+denselben
+desselben
+demselben
+dieselbe
+dieselben
+dasselbe
+
+dazu           |  to that
+
+dein           |  thy
+deine
+deinem
+deinen
+deiner
+deines
+
+denn           |  because
+
+derer          |  of those
+dessen         |  of him
+
+dich           |  thee
+dir            |  to thee
+du             |  thou
+
+dies           |  this
+diese
+diesem
+diesen
+dieser
+dieses
+
+
+doch           |  (several meanings)
+dort           |  (over) there
+
+
+durch          |  through
+
+ein            |  a
+eine
+einem
+einen
+einer
+eines
+
+einig          |  some
+einige
+einigem
+einigen
+einiger
+einiges
+
+einmal         |  once
+
+er             |  he
+ihn            |  him
+ihm            |  to him
+
+es             |  it
+etwas          |  something
+
+euer           |  your
+eure
+eurem
+euren
+eurer
+eures
+
+f√ºr            |  for
+gegen          |  towards
+gewesen        |  p.p. of sein
+hab            |  have
+habe           |  have
+haben          |  have
+hat            |  has
+hatte          |  had
+hatten         |  had
+hier           |  here
+hin            |  there
+hinter         |  behind
+
+ich            |  I
+mich           |  me
+mir            |  to me
+
+
+ihr            |  you, to her
+ihre
+ihrem
+ihren
+ihrer
+ihres
+euch           |  to you
+
+im             |  in + dem
+in             |  in
+indem          |  while
+ins            |  in + das
+ist            |  is
+
+jede           |  each, every
+jedem
+jeden
+jeder
+jedes
+
+jene           |  that
+jenem
+jenen
+jener
+jenes
+
+jetzt          |  now
+kann           |  can
+
+kein           |  no
+keine
+keinem
+keinen
+keiner
+keines
+
+k√∂nnen         |  can
+k√∂nnte         |  could
+machen         |  do
+man            |  one
+
+manche         |  some, many a
+manchem
+manchen
+mancher
+manches
+
+mein           |  my
+meine
+meinem
+meinen
+meiner
+meines
+
+mit            |  with
+muss           |  must
+musste         |  had to
+nach           |  to(wards)
+nicht          |  not
+nichts         |  nothing
+noch           |  still, yet
+nun            |  now
+nur            |  only
+ob             |  whether
+oder           |  or
+ohne           |  without
+sehr           |  very
+
+sein           |  his
+seine
+seinem
+seinen
+seiner
+seines
+
+selbst         |  self
+sich           |  herself
+
+sie            |  they, she
+ihnen          |  to them
+
+sind           |  are
+so             |  so
+
+solche         |  such
+solchem
+solchen
+solcher
+solches
+
+soll           |  shall
+sollte         |  should
+sondern        |  but
+sonst          |  else
+√ºber           |  over
+um             |  about, around
+und            |  and
+
+uns            |  us
+unse
+unsem
+unsen
+unser
+unses
+
+unter          |  under
+viel           |  much
+vom            |  von + dem
+von            |  from
+vor            |  before
+w√§hrend        |  while
+war            |  was
+waren          |  were
+warst          |  wast
+was            |  what
+weg            |  away, off
+weil           |  because
+weiter         |  further
+
+welche         |  which
+welchem
+welchen
+welcher
+welches
+
+wenn           |  when
+werde          |  will
+werden         |  will
+wie            |  how
+wieder         |  again
+will           |  want
+wir            |  we
+wird           |  will
+wirst          |  willst
+wo             |  where
+wollen         |  want
+wollte         |  wanted
+w√ºrde          |  would
+w√ºrden         |  would
+zu             |  to
+zum            |  zu + dem
+zur            |  zu + der
+zwar           |  indeed
+zwischen       |  between
+
diff --git a/solr/example/solr/conf/lang/stopwords_el.txt b/solr/example/solr/conf/lang/stopwords_el.txt
new file mode 100644
index 0000000..1a08d31
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_el.txt
@@ -0,0 +1,76 @@
+# Lucene Greek Stopwords list
+Œø
+Œ∑
+?Œø
+ŒøŒπ
+?Œ±
+?Œø?
+?Œ∑?
+??ŒΩ
+?ŒøŒΩ
+?Œ∑ŒΩ
+Œ∫Œ±Œπ 
+Œ∫Œπ
+Œ∫
+ŒµŒπŒºŒ±Œπ
+ŒµŒπ?Œ±Œπ
+ŒµŒπŒΩŒ±Œπ
+ŒµŒπŒºŒ±??Œµ
+ŒµŒπ??Œµ
+??Œø
+??ŒøŒΩ
+??Œ∑
+??Œ∑ŒΩ
+ŒºŒ±
+Œ±ŒªŒªŒ±
+Œ±?Œø
+Œ≥ŒπŒ±
+??Œø?
+ŒºŒµ
+?Œµ
+??
+?Œ±?Œ±
+Œ±ŒΩ?Œπ
+Œ∫Œ±?Œ±
+ŒºŒµ?Œ±
+Œ∏Œ±
+ŒΩŒ±
+Œ¥Œµ
+Œ¥ŒµŒΩ
+ŒºŒ∑
+ŒºŒ∑ŒΩ
+Œµ?Œπ
+ŒµŒΩ?
+ŒµŒ±ŒΩ
+Œ±ŒΩ
+?Œø?Œµ
+?Œø?
+???
+?ŒøŒπŒø?
+?ŒøŒπŒ±
+?ŒøŒπŒø
+?ŒøŒπŒøŒπ
+?ŒøŒπŒµ?
+?ŒøŒπ?ŒΩ
+?ŒøŒπŒø??
+Œ±??Œø?
+Œ±??Œ∑
+Œ±??Œø
+Œ±??ŒøŒπ
+Œ±???ŒΩ
+Œ±??Œø??
+Œ±??Œµ?
+Œ±??Œ±
+ŒµŒ∫ŒµŒπŒΩŒø?
+ŒµŒ∫ŒµŒπŒΩŒ∑
+ŒµŒ∫ŒµŒπŒΩŒø
+ŒµŒ∫ŒµŒπŒΩŒøŒπ
+ŒµŒ∫ŒµŒπŒΩŒµ?
+ŒµŒ∫ŒµŒπŒΩŒ±
+ŒµŒ∫ŒµŒπŒΩ?ŒΩ
+ŒµŒ∫ŒµŒπŒΩŒø??
+Œø???
+ŒøŒº??
+Œπ???
+Œø?Œø
+Œø?Œπ
diff --git a/solr/example/solr/conf/lang/stopwords_en.txt b/solr/example/solr/conf/lang/stopwords_en.txt
new file mode 100644
index 0000000..2c164c0
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_en.txt
@@ -0,0 +1,54 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the "License"); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# a couple of test stopwords to test that the words are really being
+# configured from this file:
+stopworda
+stopwordb
+
+# Standard english stop words taken from Lucene's StopAnalyzer
+a
+an
+and
+are
+as
+at
+be
+but
+by
+for
+if
+in
+into
+is
+it
+no
+not
+of
+on
+or
+such
+that
+the
+their
+then
+there
+these
+they
+this
+to
+was
+will
+with
diff --git a/solr/example/solr/conf/lang/stopwords_es.txt b/solr/example/solr/conf/lang/stopwords_es.txt
new file mode 100644
index 0000000..2db1476
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_es.txt
@@ -0,0 +1,354 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/spanish/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Spanish stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+
+ | The following is a ranked list (commonest to rarest) of stopwords
+ | deriving from a large sample of text.
+
+ | Extra words have been added at the end.
+
+de             |  from, of
+la             |  the, her
+que            |  who, that
+el             |  the
+en             |  in
+y              |  and
+a              |  to
+los            |  the, them
+del            |  de + el
+se             |  himself, from him etc
+las            |  the, them
+por            |  for, by, etc
+un             |  a
+para           |  for
+con            |  with
+no             |  no
+una            |  a
+su             |  his, her
+al             |  a + el
+  | es         from SER
+lo             |  him
+como           |  how
+m√°s            |  more
+pero           |  pero
+sus            |  su plural
+le             |  to him, her
+ya             |  already
+o              |  or
+  | fue        from SER
+este           |  this
+  | ha         from HABER
+s√≠             |  himself etc
+porque         |  because
+esta           |  this
+  | son        from SER
+entre          |  between
+  | est√°     from ESTAR
+cuando         |  when
+muy            |  very
+sin            |  without
+sobre          |  on
+  | ser        from SER
+  | tiene      from TENER
+tambi√©n        |  also
+me             |  me
+hasta          |  until
+hay            |  there is/are
+donde          |  where
+  | han        from HABER
+quien          |  whom, that
+  | est√°n      from ESTAR
+  | estado     from ESTAR
+desde          |  from
+todo           |  all
+nos            |  us
+durante        |  during
+  | estados    from ESTAR
+todos          |  all
+uno            |  a
+les            |  to them
+ni             |  nor
+contra         |  against
+otros          |  other
+  | fueron     from SER
+ese            |  that
+eso            |  that
+  | hab√≠a      from HABER
+ante           |  before
+ellos          |  they
+e              |  and (variant of y)
+esto           |  this
+m√≠             |  me
+antes          |  before
+algunos        |  some
+qu√©            |  what?
+unos           |  a
+yo             |  I
+otro           |  other
+otras          |  other
+otra           |  other
+√©l             |  he
+tanto          |  so much, many
+esa            |  that
+estos          |  these
+mucho          |  much, many
+quienes        |  who
+nada           |  nothing
+muchos         |  many
+cual           |  who
+  | sea        from SER
+poco           |  few
+ella           |  she
+estar          |  to be
+  | haber      from HABER
+estas          |  these
+  | estaba     from ESTAR
+  | estamos    from ESTAR
+algunas        |  some
+algo           |  something
+nosotros       |  we
+
+      | other forms
+
+mi             |  me
+mis            |  mi plural
+t√∫             |  thou
+te             |  thee
+ti             |  thee
+tu             |  thy
+tus            |  tu plural
+ellas          |  they
+nosotras       |  we
+vosotros       |  you
+vosotras       |  you
+os             |  you
+m√≠o            |  mine
+m√≠a            |
+m√≠os           |
+m√≠as           |
+tuyo           |  thine
+tuya           |
+tuyos          |
+tuyas          |
+suyo           |  his, hers, theirs
+suya           |
+suyos          |
+suyas          |
+nuestro        |  ours
+nuestra        |
+nuestros       |
+nuestras       |
+vuestro        |  yours
+vuestra        |
+vuestros       |
+vuestras       |
+esos           |  those
+esas           |  those
+
+               | forms of estar, to be (not including the infinitive):
+estoy
+est√°s
+est√°
+estamos
+est√°is
+est√°n
+est√©
+est√©s
+estemos
+est√©is
+est√©n
+estar√©
+estar√°s
+estar√°
+estaremos
+estar√©is
+estar√°n
+estar√≠a
+estar√≠as
+estar√≠amos
+estar√≠ais
+estar√≠an
+estaba
+estabas
+est√°bamos
+estabais
+estaban
+estuve
+estuviste
+estuvo
+estuvimos
+estuvisteis
+estuvieron
+estuviera
+estuvieras
+estuvi√©ramos
+estuvierais
+estuvieran
+estuviese
+estuvieses
+estuvi√©semos
+estuvieseis
+estuviesen
+estando
+estado
+estada
+estados
+estadas
+estad
+
+               | forms of haber, to have (not including the infinitive):
+he
+has
+ha
+hemos
+hab√©is
+han
+haya
+hayas
+hayamos
+hay√°is
+hayan
+habr√©
+habr√°s
+habr√°
+habremos
+habr√©is
+habr√°n
+habr√≠a
+habr√≠as
+habr√≠amos
+habr√≠ais
+habr√≠an
+hab√≠a
+hab√≠as
+hab√≠amos
+hab√≠ais
+hab√≠an
+hube
+hubiste
+hubo
+hubimos
+hubisteis
+hubieron
+hubiera
+hubieras
+hubi√©ramos
+hubierais
+hubieran
+hubiese
+hubieses
+hubi√©semos
+hubieseis
+hubiesen
+habiendo
+habido
+habida
+habidos
+habidas
+
+               | forms of ser, to be (not including the infinitive):
+soy
+eres
+es
+somos
+sois
+son
+sea
+seas
+seamos
+se√°is
+sean
+ser√©
+ser√°s
+ser√°
+seremos
+ser√©is
+ser√°n
+ser√≠a
+ser√≠as
+ser√≠amos
+ser√≠ais
+ser√≠an
+era
+eras
+√©ramos
+erais
+eran
+fui
+fuiste
+fue
+fuimos
+fuisteis
+fueron
+fuera
+fueras
+fu√©ramos
+fuerais
+fueran
+fuese
+fueses
+fu√©semos
+fueseis
+fuesen
+siendo
+sido
+  |  sed also means 'thirst'
+
+               | forms of tener, to have (not including the infinitive):
+tengo
+tienes
+tiene
+tenemos
+ten√©is
+tienen
+tenga
+tengas
+tengamos
+teng√°is
+tengan
+tendr√©
+tendr√°s
+tendr√°
+tendremos
+tendr√©is
+tendr√°n
+tendr√≠a
+tendr√≠as
+tendr√≠amos
+tendr√≠ais
+tendr√≠an
+ten√≠a
+ten√≠as
+ten√≠amos
+ten√≠ais
+ten√≠an
+tuve
+tuviste
+tuvo
+tuvimos
+tuvisteis
+tuvieron
+tuviera
+tuvieras
+tuvi√©ramos
+tuvierais
+tuvieran
+tuviese
+tuvieses
+tuvi√©semos
+tuvieseis
+tuviesen
+teniendo
+tenido
+tenida
+tenidos
+tenidas
+tened
+
diff --git a/solr/example/solr/conf/lang/stopwords_eu.txt b/solr/example/solr/conf/lang/stopwords_eu.txt
new file mode 100644
index 0000000..25f1db9
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_eu.txt
@@ -0,0 +1,99 @@
+# example set of basque stopwords
+al
+anitz
+arabera
+asko
+baina
+bat
+batean
+batek
+bati
+batzuei
+batzuek
+batzuetan
+batzuk
+bera
+beraiek
+berau
+berauek
+bere
+berori
+beroriek
+beste
+bezala
+da
+dago
+dira
+ditu
+du
+dute
+edo
+egin
+ere
+eta
+eurak
+ez
+gainera
+gu
+gutxi
+guzti
+haiei
+haiek
+haietan
+hainbeste
+hala
+han
+handik
+hango
+hara
+hari
+hark
+hartan
+hau
+hauei
+hauek
+hauetan
+hemen
+hemendik
+hemengo
+hi
+hona
+honek
+honela
+honetan
+honi
+hor
+hori
+horiei
+horiek
+horietan
+horko
+horra
+horrek
+horrela
+horretan
+horri
+hortik
+hura
+izan
+ni
+noiz
+nola
+non
+nondik
+nongo
+nor
+nora
+ze
+zein
+zen
+zenbait
+zenbat
+zer
+zergatik
+ziren
+zituen
+zu
+zuek
+zuen
+zuten
diff --git a/solr/example/solr/conf/lang/stopwords_fa.txt b/solr/example/solr/conf/lang/stopwords_fa.txt
new file mode 100644
index 0000000..3618281
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_fa.txt
@@ -0,0 +1,311 @@
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# Also see http://www.opensource.org/licenses/bsd-license.html
+ÿß?ÿß?
+?ÿØÿßÿ¥ÿ™?
+ÿ≥ÿ±ÿßÿ≥ÿ±
+ÿÆ?ÿß?
+ÿß?ÿ¥ÿß?
+??
+ÿ™ÿß????
+ÿ®?ÿ¥ÿ™ÿ±?
+ÿØ??
+Ÿæÿ≥
+?ÿßÿ¥?
+?⁄Ø?
+?ÿß
+ÿØÿßÿ¥ÿ™?ÿØ
+ÿ≥Ÿæÿ≥
+??⁄Øÿß?
+?ÿ±⁄Øÿ≤
+Ÿæ?ÿ¨
+?ÿ¥ÿß?
+ÿß?ÿ≥ÿß?
+ÿØ?⁄Øÿ±
+⁄Øÿ±???
+ÿ¥ÿØ?ÿØ
+?ÿ∑?ÿ±
+ÿØ?
+?
+ÿØ?
+?ÿÆÿ≥ÿ™??
+???
+?ÿ±ÿß
+??
+?ÿ≥ÿ∑
+?
+?ÿØÿß?
+?ÿßÿ®?
+??
+ÿ±?ÿ™
+??ÿ™
+??????
+ÿØÿ±
+?ÿ≤ÿßÿ±
+ÿ®??
+ÿ®??
+ÿ¥ÿß?ÿØ
+ÿß?ÿß
+ÿ¥?ÿßÿ≥?
+⁄Øÿ±?ÿ™?
+ÿØ?ÿØ
+ÿØÿßÿ¥ÿ™?
+ÿØÿß?ÿ≥ÿ™
+ÿØÿßÿ¥ÿ™?
+ÿÆ?ÿß???
+????ÿßÿ±ÿØ
+??ÿ™???
+ÿß?ÿØ
+ÿÆ?ÿß?ÿØ
+ÿ¨ÿ≤
+ÿß?ÿ±ÿØ?
+ÿ¥ÿØ?
+ÿ®???
+ÿÆÿØ?ÿßÿ™
+ÿ¥ÿØ?
+ÿ®ÿ±ÿÆ?
+?ÿ®?ÿØ
+ÿ®ÿ≥?ÿßÿ±?
+ÿ¨??⁄Ø?ÿ±?
+ÿ≠?
+?ÿ±ÿØ?ÿØ
+??ÿπ?
+ÿ®ÿπÿ±?
+??ÿ±ÿØ?
+?ÿ∏?ÿ±
+?ÿ®ÿß?ÿØ
+ÿ®?ÿØ?
+ÿ®?ÿØ?
+ÿØÿßÿØ
+ÿß?ÿ±ÿØ
+?ÿ≥ÿ™
+ÿ¨ÿß??
+ÿ¥?ÿØ
+ÿØ?ÿ®ÿß?
+ÿØÿßÿØ?
+ÿ®ÿß?ÿØ
+ÿ≥ÿßÿ®?
+???
+??ÿß?
+ÿß?ÿ¨ÿß
+??ÿ™ÿ±
+?ÿ¨ÿßÿ≥ÿ™
+⁄Øÿ±ÿØÿØ
+?ÿ≥?
+ÿ™ÿ±
+?ÿ±ÿØ?
+ÿ™ÿß?
+ÿØÿßÿØ?
+ÿ®?ÿØ?ÿØ
+ÿ≥ÿ±?
+ÿ¨ÿØÿß
+?ÿØÿßÿ±?ÿØ
+?⁄Øÿ±
+??ÿØ?⁄Øÿ±
+ÿØÿßÿ±ÿØ
+ÿØ??ÿØ
+ÿ®?ÿßÿ®ÿ±ÿß??
+??⁄Øÿß??
+ÿ≥?ÿ™
+ÿ¨ÿß
+ÿß???
+ÿÆ?ÿØ
+ÿØÿßÿØ?ÿØ
+ÿ≤?ÿßÿØ
+ÿØÿßÿ±?ÿØ
+ÿßÿ´ÿ±
+ÿ®ÿØ??
+ÿ®?ÿ™ÿ±??
+ÿ®?ÿ¥ÿ™ÿ±
+ÿß?ÿ®ÿ™?
+ÿ®?
+ÿ®ÿ±ÿßÿ≥ÿßÿ≥
+ÿ®?ÿ±??
+?ÿ±ÿØ
+ÿ®ÿπÿ∂?
+⁄Øÿ±?ÿ™
+ÿ™??
+ÿß?
+??????
+ÿß?
+ÿ¨ÿ±?ÿß?
+ÿ™??
+ÿ®ÿ±
+?ÿß??ÿØ
+ÿ®ÿ±ÿßÿ®ÿ±
+ÿ®ÿßÿ¥??
+?ÿØÿ™?
+⁄Ø???ÿØ
+ÿß????
+ÿ™ÿß
+ÿ™??ÿß
+ÿ¨ÿØ?ÿØ
+??ÿØ
+ÿ®?
+?ÿ¥ÿØ?
+?ÿ±ÿØ?
+?ÿ±ÿØ?
+⁄Ø??ÿØ
+?ÿ±ÿØ?
+????
+???
+?ÿ≤ÿØ
+ÿ±??
+?ÿµÿØ
+??ÿ∑
+ÿ®ÿß?ÿß?
+ÿØ?⁄Øÿ±ÿß?
+ÿß??
+ÿØ?ÿ±?ÿ≤
+ÿ™?ÿ≥ÿ∑
+ÿ≥??
+ÿß??
+ÿØÿß??ÿØ
+ÿ≥??
+ÿßÿ≥ÿ™?ÿßÿØ?
+ÿ¥?ÿß
+??ÿßÿ±
+ÿØÿßÿ±??
+ÿ≥ÿßÿÆÿ™?
+ÿ∑?ÿ±
+ÿß?ÿØ?
+ÿ±?ÿ™?
+?ÿÆÿ≥ÿ™
+ÿ®?ÿ≥ÿ™
+?ÿ≤ÿØ??
+ÿ∑?
+???ÿØ
+ÿßÿ≤
+ÿß??ÿß
+ÿ™?ÿß??
+ÿØÿßÿ¥ÿ™
+???
+ÿ∑ÿ±??
+ÿßÿ¥
+??ÿ≥ÿ™
+ÿ±?ÿ®
+??ÿß?ÿØ
+⁄Ø?ÿ™
+??ÿØ??
+??ÿ≤?
+ÿ™?ÿß?ÿØ
+ÿß?
+ÿß?ÿß
+ÿ®ÿß
+ÿß?
+ÿß?ÿØ
+ÿ™ÿ±??
+ÿß????
+ÿØ?⁄Øÿ±?
+ÿ±ÿß?
+?ÿß??
+ÿ®ÿ±?ÿ≤
+????ÿß?
+Ÿæÿßÿπ??
+?ÿ≥
+ÿ≠ÿØ?ÿØ
+?ÿÆÿ™??
+??ÿßÿ®?
+??ÿ≤
+⁄Ø?ÿ±ÿØ
+?ÿØÿßÿ±ÿØ
+ÿ∂ÿØ
+?????
+ÿ≥ÿßÿ≤?
+ÿ¥ÿß?
+??ÿ±ÿØ
+ÿ®ÿßÿ±?
+?ÿ±ÿ≥?
+ÿÆ??ÿ¥
+ÿ®ÿ±ÿÆ?ÿ±ÿØÿßÿ±
+???
+ÿÆÿßÿ±ÿ¨
+ÿ¥ÿ¥
+???ÿ≤
+ÿ™ÿ≠ÿ™
+ÿ∂??
+?ÿ≥ÿ™??
+⁄Ø?ÿ™?
+??ÿ±
+ÿ®ÿ≥?ÿßÿ±
+Ÿæ?ÿ¥
+ÿ®ÿ±ÿß?
+ÿ±?ÿ≤?ÿß?
+ÿß???
+?ÿÆ?ÿß?ÿØ
+ÿ®ÿß?ÿß
+??
+??ÿ™?
+??
+????
+??
+⁄Ø?ÿ±?
+??ÿ≥ÿ™
+ÿßÿ≥ÿ™
+?ÿ¨ÿß
+??ÿØ
+??ÿ≤
+?ÿßÿ®ÿØ
+ÿ®?ÿØ?
+ÿ≠ÿ™?
+ÿ™?ÿß??ÿØ
+ÿπ?ÿ®
+ÿÆ?ÿßÿ≥ÿ™
+???ÿØ
+ÿ®??
+ÿ™?ÿß?
+???
+?ÿß
+ÿ®ÿßÿ¥?ÿØ
+?ÿ´?
+ÿ¥ÿØ
+ÿßÿ±?
+ÿ®ÿßÿ¥ÿØ
+ÿßÿ±?
+ÿ∑ÿ®?
+ÿ®ÿπÿØ
+ÿß⁄Øÿ±
+ÿµ?ÿ±ÿ™
+ÿ∫?ÿ±
+ÿ¨ÿß?
+ÿ®?ÿ¥
+ÿ±?ÿ≤?
+ÿß?ÿØ
+ÿ≤?ÿ±ÿß
+?⁄Ø???
+ÿ®ÿßÿ±
+?ÿ∑?ÿß
+??
+ÿØÿ±ÿ®ÿßÿ±?
+??
+ÿØ?ÿØ?
+????
+⁄Øÿ∞ÿßÿ±?
+ÿ®ÿ±ÿØÿßÿ±?
+ÿπ?ÿ™
+⁄Øÿ∞ÿßÿ¥ÿ™?
+??
+???
+??
+?ÿß
+ÿ¥??ÿØ
+ÿßÿ®ÿßÿØ
+???ÿßÿ±?
+?ÿ±
+ÿß??
+ÿÆ?ÿß??ÿØ
+??ÿßÿ±
+?ÿß?
+ÿß?ÿ±?ÿ≤
+?ÿß?
+?ÿß?
+?ÿ®?
+???
+ÿ≥ÿπ?
+ÿ™ÿßÿ≤?
+ÿ±ÿß
+?ÿ≥ÿ™?ÿØ
+ÿ≤?ÿ±
+ÿ¨???
+ÿπ??ÿß?
+ÿ®?ÿØ
diff --git a/solr/example/solr/conf/lang/stopwords_fi.txt b/solr/example/solr/conf/lang/stopwords_fi.txt
new file mode 100644
index 0000000..addad79
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_fi.txt
@@ -0,0 +1,95 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/finnish/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+ 
+| forms of BE
+
+olla
+olen
+olet
+on
+olemme
+olette
+ovat
+ole        | negative form
+
+oli
+olisi
+olisit
+olisin
+olisimme
+olisitte
+olisivat
+olit
+olin
+olimme
+olitte
+olivat
+ollut
+olleet
+
+en         | negation
+et
+ei
+emme
+ette
+eiv√§t
+
+|Nom   Gen    Acc    Part   Iness   Elat    Illat  Adess   Ablat   Allat   Ess    Trans
+min√§   minun  minut  minua  minussa minusta minuun minulla minulta minulle               | I
+sin√§   sinun  sinut  sinua  sinussa sinusta sinuun sinulla sinulta sinulle               | you
+h√§n    h√§nen  h√§net  h√§nt√§  h√§ness√§ h√§nest√§ h√§neen h√§nell√§ h√§nelt√§ h√§nelle               | he she
+me     meid√§n meid√§t meit√§  meiss√§  meist√§  meihin meill√§  meilt√§  meille                | we
+te     teid√§n teid√§t teit√§  teiss√§  teist√§  teihin teill√§  teilt√§  teille                | you
+he     heid√§n heid√§t heit√§  heiss√§  heist√§  heihin heill√§  heilt√§  heille                | they
+
+t√§m√§   t√§m√§n         t√§t√§   t√§ss√§   t√§st√§   t√§h√§n  tall√§   t√§lt√§   t√§lle   t√§n√§   t√§ksi  | this
+tuo    tuon          tuot√§  tuossa  tuosta  tuohon tuolla  tuolta  tuolle  tuona  tuoksi | that
+se     sen           sit√§   siin√§   siit√§   siihen sill√§   silt√§   sille   sin√§   siksi  | it
+n√§m√§   n√§iden        n√§it√§  n√§iss√§  n√§ist√§  n√§ihin n√§ill√§  n√§ilt√§  n√§ille  n√§in√§  n√§iksi | these
+nuo    noiden        noita  noissa  noista  noihin noilla  noilta  noille  noina  noiksi | those
+ne     niiden        niit√§  niiss√§  niist√§  niihin niill√§  niilt√§  niille  niin√§  niiksi | they
+
+kuka   kenen kenet   ket√§   keness√§ kenest√§ keneen kenell√§ kenelt√§ kenelle kenen√§ keneksi| who
+ketk√§  keiden ketk√§  keit√§  keiss√§  keist√§  keihin keill√§  keilt√§  keille  kein√§  keiksi | (pl)
+mik√§   mink√§ mink√§   mit√§   miss√§   mist√§   mihin  mill√§   milt√§   mille   min√§   miksi  | which what
+mitk√§                                                                                    | (pl)
+
+joka   jonka         jota   jossa   josta   johon  jolla   jolta   jolle   jona   joksi  | who which
+jotka  joiden        joita  joissa  joista  joihin joilla  joilta  joille  joina  joiksi | (pl)
+
+| conjunctions
+
+ett√§   | that
+ja     | and
+jos    | if
+koska  | because
+kuin   | than
+mutta  | but
+niin   | so
+sek√§   | and
+sill√§  | for
+tai    | or
+vaan   | but
+vai    | or
+vaikka | although
+
+
+| prepositions
+
+kanssa  | with
+mukaan  | according to
+noin    | about
+poikki  | across
+yli     | over, across
+
+| other
+
+kun    | when
+niin   | so
+nyt    | now
+itse   | self
+
diff --git a/solr/example/solr/conf/lang/stopwords_fr.txt b/solr/example/solr/conf/lang/stopwords_fr.txt
new file mode 100644
index 0000000..c00837ea
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_fr.txt
@@ -0,0 +1,183 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/french/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A French stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+au             |  a + le
+aux            |  a + les
+avec           |  with
+ce             |  this
+ces            |  these
+dans           |  with
+de             |  of
+des            |  de + les
+du             |  de + le
+elle           |  she
+en             |  `of them' etc
+et             |  and
+eux            |  them
+il             |  he
+je             |  I
+la             |  the
+le             |  the
+leur           |  their
+lui            |  him
+ma             |  my (fem)
+mais           |  but
+me             |  me
+m√™me           |  same; as in moi-m√™me (myself) etc
+mes            |  me (pl)
+moi            |  me
+mon            |  my (masc)
+ne             |  not
+nos            |  our (pl)
+notre          |  our
+nous           |  we
+on             |  one
+ou             |  where
+par            |  by
+pas            |  not
+pour           |  for
+qu             |  que before vowel
+que            |  that
+qui            |  who
+sa             |  his, her (fem)
+se             |  oneself
+ses            |  his (pl)
+son            |  his, her (masc)
+sur            |  on
+ta             |  thy (fem)
+te             |  thee
+tes            |  thy (pl)
+toi            |  thee
+ton            |  thy (masc)
+tu             |  thou
+un             |  a
+une            |  a
+vos            |  your (pl)
+votre          |  your
+vous           |  you
+
+               |  single letter forms
+
+c              |  c'
+d              |  d'
+j              |  j'
+l              |  l'
+?              |  to, at
+m              |  m'
+n              |  n'
+s              |  s'
+t              |  t'
+y              |  there
+
+               | forms of √™tre (not including the infinitive):
+√©t√©
+√©t√©e
+√©t√©es
+√©t√©s
+√©tant
+suis
+es
+est
+sommes
+√™tes
+sont
+serai
+seras
+sera
+serons
+serez
+seront
+serais
+serait
+serions
+seriez
+seraient
+√©tais
+√©tait
+√©tions
+√©tiez
+√©taient
+fus
+fut
+f√ªmes
+f√ªtes
+furent
+sois
+soit
+soyons
+soyez
+soient
+fusse
+fusses
+f√ªt
+fussions
+fussiez
+fussent
+
+               | forms of avoir (not including the infinitive):
+ayant
+eu
+eue
+eues
+eus
+ai
+as
+avons
+avez
+ont
+aurai
+auras
+aura
+aurons
+aurez
+auront
+aurais
+aurait
+aurions
+auriez
+auraient
+avais
+avait
+avions
+aviez
+avaient
+eut
+e√ªmes
+e√ªtes
+eurent
+aie
+aies
+ait
+ayons
+ayez
+aient
+eusse
+eusses
+e√ªt
+eussions
+eussiez
+eussent
+
+               | Later additions (from Jean-Christophe Deschamps)
+ceci           |  this
+cel??          |  that
+cet            |  this
+cette          |  this
+ici            |  here
+ils            |  they
+les            |  the (pl)
+leurs          |  their (pl)
+quel           |  which
+quels          |  which
+quelle         |  which
+quelles        |  which
+sans           |  without
+soi            |  oneself
+
diff --git a/solr/example/solr/conf/lang/stopwords_gl.txt b/solr/example/solr/conf/lang/stopwords_gl.txt
new file mode 100644
index 0000000..d8760b1
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_gl.txt
@@ -0,0 +1,161 @@
+# galican stopwords
+a
+a√≠nda
+al√≠
+aquel
+aquela
+aquelas
+aqueles
+aquilo
+aqu√≠
+ao
+aos
+as
+as√≠
+√°
+ben
+cando
+che
+co
+coa
+comigo
+con
+connosco
+contigo
+convosco
+coas
+cos
+cun
+cuns
+cunha
+cunhas
+da
+dalgunha
+dalgunhas
+dalg√∫n
+dalg√∫ns
+das
+de
+del
+dela
+delas
+deles
+desde
+deste
+do
+dos
+dun
+duns
+dunha
+dunhas
+e
+el
+ela
+elas
+eles
+en
+era
+eran
+esa
+esas
+ese
+eses
+esta
+estar
+estaba
+est√°
+est√°n
+este
+estes
+estiven
+estou
+eu
+√©
+facer
+foi
+foron
+fun
+hab√≠a
+hai
+iso
+isto
+la
+las
+lle
+lles
+lo
+los
+mais
+me
+meu
+meus
+min
+mi√±a
+mi√±as
+moi
+na
+nas
+neste
+nin
+no
+non
+nos
+nosa
+nosas
+noso
+nosos
+n√≥s
+nun
+nunha
+nuns
+nunhas
+o
+os
+ou
+√≥
+√≥s
+para
+pero
+pode
+pois
+pola
+polas
+polo
+polos
+por
+que
+se
+sen√≥n
+ser
+seu
+seus
+sexa
+sido
+sobre
+s√∫a
+s√∫as
+tam√©n
+tan
+te
+ten
+te√±en
+te√±o
+ter
+teu
+teus
+ti
+tido
+ti√±a
+tiven
+t√∫a
+t√∫as
+un
+unha
+unhas
+uns
+vos
+vosa
+vosas
+voso
+vosos
+v√≥s
diff --git a/solr/example/solr/conf/lang/stopwords_hi.txt b/solr/example/solr/conf/lang/stopwords_hi.txt
new file mode 100644
index 0000000..53874db
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_hi.txt
@@ -0,0 +1,231 @@
+# Also see http://www.opensource.org/licenses/bsd-license.html
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+‡§??‡§?§∞
+‡§?§§
+‡§?§™‡§®‡§æ
+‡§?§™‡§®‡?
+‡§?§™‡§®‡?
+‡§?§≠‡•?
+‡§?§¶‡§?
+‡§?§™
+‡§?§§‡•?§Ø‡§æ‡§¶‡§?
+‡§?§® 
+‡§?§®‡§?§æ
+‡§?§®‡•?§π‡•?‡§?
+‡§?§®‡•?§π‡•??
+‡§?§®‡•?§π‡•??
+‡§?§∏
+‡§?§∏‡§?§æ
+‡§?§∏‡§??
+‡§?§∏‡§??
+‡§?§∏‡§??‡§?
+‡§?§∏‡•?
+‡§?§∏‡•?
+‡§?§®
+‡§?§®‡§?§æ
+‡§?§®‡§??
+‡§?§®‡§??
+‡§?§®‡§??
+‡§?§®‡•?§π‡•?‡§?
+‡§?§®‡•?§π‡•??
+‡§?§®‡•?§π‡•??
+‡§?§∏
+‡§?§∏‡§??
+‡§?§∏‡•?
+‡§?§∏‡•?
+‡§??
+‡§?§µ‡§?
+‡§?§∏
+‡§?§∏‡•?
+‡§?§∞
+‡§??
+‡§?§∞
+‡§?§∞‡§§‡§æ
+‡§?§∞‡§§‡?
+‡§?§∞‡§®‡§æ
+‡§?§∞‡§®‡?
+‡§?§∞‡•??
+‡§?§π‡§§‡?
+‡§?§π‡§?
+‡§?§æ
+‡§?§æ‡•??
+‡§?§ø
+‡§?§ø‡§§‡§®‡§?
+‡§?§ø‡§®‡?‡§π‡?‡§?
+‡§?§ø‡§®‡?‡§π‡?‡§?
+‡§?§ø‡§?§æ
+‡§?§ø‡§?
+‡§?§ø‡§?
+‡§?§ø‡§∏‡?
+‡§?§ø‡§∏‡?
+‡§??
+‡§??‡§?
+‡§??‡§?
+‡§??
+‡§??
+‡§??‡§?
+‡§??‡§?
+‡§??‡§®‡§∏‡§?
+‡§?§Ø‡§?
+‡§?§∞
+‡§?§¨
+‡§?§π‡§æ‡?
+‡§?§æ
+‡§?§ø‡§§‡§®‡§?
+‡§?§ø‡§?
+‡§?§ø‡§®‡?‡§π‡?‡§?
+‡§?§ø‡§®‡?‡§π‡?‡§?
+‡§?§ø‡§?
+‡§?§ø‡§∏‡?
+‡§??‡§ß‡§∞
+‡§??‡§∏‡§æ
+‡§??‡§∏‡?
+‡§??
+‡§§‡?
+‡§§‡§¨
+‡§§‡§∞‡§?
+‡§§‡§ø‡§?
+‡§§‡§ø‡§®‡?‡§π‡?‡§?
+‡§§‡§ø‡§®‡?‡§π‡?‡§?
+‡§§‡§ø‡§?
+‡§§‡§ø‡§∏‡?
+‡§§‡?
+‡§•‡§æ
+‡§•‡?
+‡§•‡?
+‡§?§¨‡§æ‡§∞‡§?
+‡§?§ø‡§?§æ
+‡§??‡§∏‡§∞‡§?
+‡§??‡§∏‡§∞‡•?
+‡§??
+‡§??‡§µ‡§æ‡§∞‡§æ
+‡§?
+‡§®‡§π‡•?‡§?
+‡§®‡§æ
+‡§®‡§ø‡§π‡§æ‡§?§§
+‡§®‡?‡§??
+‡§®‡?
+‡§?§∞
+‡§?§∞  
+‡§?§π‡§≤‡?
+‡§??‡§∞‡§æ
+‡§??
+‡§?§ø‡§?
+‡§?§®‡•?
+‡§?§π‡•?
+‡§?§π‡•?§§
+‡§?§æ‡§?
+‡§?§æ‡§≤‡§æ
+‡§?§ø‡§≤‡?‡•?§≤
+‡§??
+‡§??‡§§‡§∞
+‡§??‡§?
+‡§?§æ‡§®‡?
+‡§??
+‡§??‡§?
+‡§?§¶‡§?
+‡§?§π
+‡§?§π‡§æ‡?
+‡§?§π‡•?
+‡§?§æ
+‡§?§ø‡§? 
+‡§??
+‡§∞‡?‡•??
+‡§∞‡§π‡§?
+‡§∞‡§π‡•?
+‡§±‡?‡§µ‡§æ‡§∏‡§æ
+‡§≤‡§ø‡§?
+‡§≤‡§ø‡§??
+‡§≤‡?‡§?§ø‡§?
+‡§?
+‡§µ‡§∞‡•??
+‡§µ‡§π
+‡§µ‡§π 
+‡§µ‡§π‡§æ‡?
+‡§µ‡§π‡•?‡§?
+‡§µ‡§æ‡§≤‡?
+‡§µ‡?‡§? 
+‡§µ‡?
+‡§µ‡?‡•?§∞‡§?
+‡§∏‡?‡§?
+‡§∏‡?‡§§‡§æ
+‡§∏‡?‡§§‡?
+‡§∏‡§¨‡§∏‡?
+‡§∏‡§≠‡•?
+‡§∏‡§æ‡§?
+‡§∏‡§æ‡§??‡§?
+‡§∏‡§æ‡§?
+‡§∏‡§æ‡§∞‡§æ
+‡§∏‡?
+‡§∏‡?
+‡§π‡?
+‡§π‡?‡§?
+‡§π‡?‡§?
+‡§π‡?‡§?
+‡§π‡?
+‡§π‡?‡§?
+‡§π‡?
+‡§π‡?‡§§‡§æ
+‡§π‡?‡§§‡?
+‡§π‡?‡§§‡?
+‡§π‡?‡§®‡§æ
+‡§π‡?‡§®‡?
+# additional normalized forms of the above
+‡§?§™‡§®‡§ø
+‡§??‡§∏‡?
+‡§π‡?‡§§‡§ø
+‡§∏‡§≠‡§?
+‡§§‡§ø‡§?§π‡•??
+‡§??‡§π‡?‡§?
+‡§?§µ‡§æ‡§∞‡§?
+‡§?§∏‡§?
+‡§?§ø‡§?§π‡•??
+‡§•‡§ø
+‡§??‡§π‡?‡§?
+‡§?§∞
+‡§?§ø‡§?§π‡•??
+‡§µ‡§π‡§ø‡?
+‡§?§≠‡§?
+‡§?§®‡§?
+‡§π‡§ø
+‡§??‡§π‡§ø‡§?
+‡§??‡§π‡?‡§?
+‡§π‡?‡§?
+‡§µ‡?‡•?§∞‡§?
+‡§?§∏‡•?
+‡§∞‡§µ‡§æ‡§∏‡§?
+‡§??‡§?
+‡§®‡§ø‡§??
+‡§?§æ‡§?§ø
+‡§?§∏‡§?
+‡§??‡§∞‡§æ
+‡§?§ø‡§§‡§∞
+‡§π‡?
+‡§?§π‡§?
+‡§µ‡§π‡§æ‡?
+‡§??‡§?
+‡§?§π‡§æ‡?
+‡§?§ø‡§?§π‡•??
+‡§§‡§ø‡§?§π‡•??
+‡§?§ø‡§∏‡§ø
+‡§??
+‡§?§π‡§?
+‡§??‡§π‡§ø‡§?
+‡§?§ø‡§ß‡§∞
+‡§??‡§π‡?‡§?
+‡§?§¶‡§?
+‡§?§§‡§?§æ‡§?§ø
+‡§π‡?‡§?
+‡§??‡§®‡§∏‡§?
+‡§?§∏‡§?§ø
+‡§??‡§∏‡§∞‡•?
+‡§?§π‡§æ‡?
+‡§?§™
+‡§?§ø‡§?§π‡•??
+‡§?§®‡§?§ø
+‡§?§ø
+‡§µ‡§∞‡§?
+‡§π‡?‡§?
+‡§??‡§∏‡§æ
+‡§®‡§π‡§ø‡?
diff --git a/solr/example/solr/conf/lang/stopwords_hu.txt b/solr/example/solr/conf/lang/stopwords_hu.txt
new file mode 100644
index 0000000..1a96f1d
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_hu.txt
@@ -0,0 +1,209 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/hungarian/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+ 
+| Hungarian stop word list
+| prepared by Anna Tordai
+
+a
+ahogy
+ahol
+aki
+akik
+akkor
+alatt
+√°ltal
+√°ltal√°ban
+amely
+amelyek
+amelyekben
+amelyeket
+amelyet
+amelynek
+ami
+amit
+amolyan
+am√≠g
+amikor
+√°t
+abban
+ahhoz
+annak
+arra
+arr√≥l
+az
+azok
+azon
+azt
+azzal
+az√©rt
+azt√°n
+azut√°n
+azonban
+b√°r
+be
+bel√ºl
+benne
+cikk
+cikkek
+cikkeket
+csak
+de
+e
+eddig
+eg√©sz
+egy
+egyes
+egyetlen
+egy√©b
+egyik
+egyre
+ekkor
+el
+el√©g
+ellen
+el?
+el?sz√∂r
+el?tt
+els?
+√©n
+√©ppen
+ebben
+ehhez
+emilyen
+ennek
+erre
+ez
+ezt
+ezek
+ezen
+ezzel
+ez√©rt
+√©s
+fel
+fel√©
+hanem
+hiszen
+hogy
+hogyan
+igen
+√≠gy
+illetve
+ill.
+ill
+ilyen
+ilyenkor
+ison
+ism√©t
+itt
+j√≥
+j√≥l
+jobban
+kell
+kellett
+kereszt√ºl
+keress√ºnk
+ki
+k√≠v√ºl
+k√∂z√∂tt
+k√∂z√ºl
+legal√°bb
+lehet
+lehetett
+legyen
+lenne
+lenni
+lesz
+lett
+maga
+mag√°t
+majd
+majd
+m√°r
+m√°s
+m√°sik
+meg
+m√©g
+mellett
+mert
+mely
+melyek
+mi
+mit
+m√≠g
+mi√©rt
+milyen
+mikor
+minden
+mindent
+mindenki
+mindig
+mint
+mintha
+mivel
+most
+nagy
+nagyobb
+nagyon
+ne
+n√©ha
+nekem
+neki
+nem
+n√©h√°ny
+n√©lk√ºl
+nincs
+olyan
+ott
+√∂ssze
+?
+?k
+?ket
+pedig
+persze
+r√°
+s
+saj√°t
+sem
+semmi
+sok
+sokat
+sokkal
+sz√°m√°ra
+szemben
+szerint
+szinte
+tal√°n
+teh√°t
+teljes
+tov√°bb
+tov√°bb√°
+t√∂bb
+√∫gy
+ugyanis
+√∫j
+√∫jabb
+√∫jra
+ut√°n
+ut√°na
+utols√≥
+vagy
+vagyis
+valaki
+valami
+valamint
+val√≥
+vagyok
+van
+vannak
+volt
+voltam
+voltak
+voltunk
+vissza
+vele
+viszont
+volna
diff --git a/solr/example/solr/conf/lang/stopwords_hy.txt b/solr/example/solr/conf/lang/stopwords_hy.txt
new file mode 100644
index 0000000..60c1c50
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_hy.txt
@@ -0,0 +1,46 @@
+# example set of Armenian stopwords.
+’°’µ’§
+’°’µ’¨
+’°’µ’∂
+’°’µ’Ω
+’§’∏?
+’§’∏??
+’•’¥
+’•’∂
+’•’∂?
+’•’Ω
+’•?
+’ß
+’ß’´
+’ß’´’∂
+’ß’´’∂?
+’ß’´?
+’ß’´?
+’ß?
+’®’Ω’ø
+’©
+’´
+’´’∂
+’´’Ω’Ø
+’´?
+’Ø’°’¥
+’∞’°’¥’°?
+’∞’•’ø
+’∞’•’ø’∏
+’¥’•’∂?
+’¥’•’ª
+’¥’´
+’∂
+’∂’°
+’∂’°?
+’∂?’°
+’∂?’°’∂?
+’∏?
+’∏?’®
+’∏?’∏’∂?
+’∏?’∫’•’Ω
+’∏?
+’∏?’¥
+’∫’´’ø’´
+’æ?’°
+?
diff --git a/solr/example/solr/conf/lang/stopwords_id.txt b/solr/example/solr/conf/lang/stopwords_id.txt
new file mode 100644
index 0000000..4617f83
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_id.txt
@@ -0,0 +1,359 @@
+# from appendix D of: A Study of Stemming Effects on Information
+# Retrieval in Bahasa Indonesia
+ada
+adanya
+adalah
+adapun
+agak
+agaknya
+agar
+akan
+akankah
+akhirnya
+aku
+akulah
+amat
+amatlah
+anda
+andalah
+antar
+diantaranya
+antara
+antaranya
+diantara
+apa
+apaan
+mengapa
+apabila
+apakah
+apalagi
+apatah
+atau
+ataukah
+ataupun
+bagai
+bagaikan
+sebagai
+sebagainya
+bagaimana
+bagaimanapun
+sebagaimana
+bagaimanakah
+bagi
+bahkan
+bahwa
+bahwasanya
+sebaliknya
+banyak
+sebanyak
+beberapa
+seberapa
+begini
+beginian
+beginikah
+beginilah
+sebegini
+begitu
+begitukah
+begitulah
+begitupun
+sebegitu
+belum
+belumlah
+sebelum
+sebelumnya
+sebenarnya
+berapa
+berapakah
+berapalah
+berapapun
+betulkah
+sebetulnya
+biasa
+biasanya
+bila
+bilakah
+bisa
+bisakah
+sebisanya
+boleh
+bolehkah
+bolehlah
+buat
+bukan
+bukankah
+bukanlah
+bukannya
+cuma
+percuma
+dahulu
+dalam
+dan
+dapat
+dari
+daripada
+dekat
+demi
+demikian
+demikianlah
+sedemikian
+dengan
+depan
+di
+dia
+dialah
+dini
+diri
+dirinya
+terdiri
+dong
+dulu
+enggak
+enggaknya
+entah
+entahlah
+terhadap
+terhadapnya
+hal
+hampir
+hanya
+hanyalah
+harus
+haruslah
+harusnya
+seharusnya
+hendak
+hendaklah
+hendaknya
+hingga
+sehingga
+ia
+ialah
+ibarat
+ingin
+inginkah
+inginkan
+ini
+inikah
+inilah
+itu
+itukah
+itulah
+jangan
+jangankan
+janganlah
+jika
+jikalau
+juga
+justru
+kala
+kalau
+kalaulah
+kalaupun
+kalian
+kami
+kamilah
+kamu
+kamulah
+kan
+kapan
+kapankah
+kapanpun
+dikarenakan
+karena
+karenanya
+ke
+kecil
+kemudian
+kenapa
+kepada
+kepadanya
+ketika
+seketika
+khususnya
+kini
+kinilah
+kiranya
+sekiranya
+kita
+kitalah
+kok
+lagi
+lagian
+selagi
+lah
+lain
+lainnya
+melainkan
+selaku
+lalu
+melalui
+terlalu
+lama
+lamanya
+selama
+selama
+selamanya
+lebih
+terlebih
+bermacam
+macam
+semacam
+maka
+makanya
+makin
+malah
+malahan
+mampu
+mampukah
+mana
+manakala
+manalagi
+masih
+masihkah
+semasih
+masing
+mau
+maupun
+semaunya
+memang
+mereka
+merekalah
+meski
+meskipun
+semula
+mungkin
+mungkinkah
+nah
+namun
+nanti
+nantinya
+nyaris
+oleh
+olehnya
+seorang
+seseorang
+pada
+padanya
+padahal
+paling
+sepanjang
+pantas
+sepantasnya
+sepantasnyalah
+para
+pasti
+pastilah
+per
+pernah
+pula
+pun
+merupakan
+rupanya
+serupa
+saat
+saatnya
+sesaat
+saja
+sajalah
+saling
+bersama
+sama
+sesama
+sambil
+sampai
+sana
+sangat
+sangatlah
+saya
+sayalah
+se
+sebab
+sebabnya
+sebuah
+tersebut
+tersebutlah
+sedang
+sedangkan
+sedikit
+sedikitnya
+segala
+segalanya
+segera
+sesegera
+sejak
+sejenak
+sekali
+sekalian
+sekalipun
+sesekali
+sekaligus
+sekarang
+sekarang
+sekitar
+sekitarnya
+sela
+selain
+selalu
+seluruh
+seluruhnya
+semakin
+sementara
+sempat
+semua
+semuanya
+sendiri
+sendirinya
+seolah
+seperti
+sepertinya
+sering
+seringnya
+serta
+siapa
+siapakah
+siapapun
+disini
+disinilah
+sini
+sinilah
+sesuatu
+sesuatunya
+suatu
+sesudah
+sesudahnya
+sudah
+sudahkah
+sudahlah
+supaya
+tadi
+tadinya
+tak
+tanpa
+setelah
+telah
+tentang
+tentu
+tentulah
+tentunya
+tertentu
+seterusnya
+tapi
+tetapi
+setiap
+tiap
+setidaknya
+tidak
+tidakkah
+tidaklah
+toh
+waduh
+wah
+wahai
+sewaktu
+walau
+walaupun
+wong
+yaitu
+yakni
+yang
diff --git a/solr/example/solr/conf/lang/stopwords_it.txt b/solr/example/solr/conf/lang/stopwords_it.txt
new file mode 100644
index 0000000..4cb5b08
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_it.txt
@@ -0,0 +1,301 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/italian/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | An Italian stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ad             |  a (to) before vowel
+al             |  a + il
+allo           |  a + lo
+ai             |  a + i
+agli           |  a + gli
+all            |  a + l'
+agl            |  a + gl'
+alla           |  a + la
+alle           |  a + le
+con            |  with
+col            |  con + il
+coi            |  con + i (forms collo, cogli etc are now very rare)
+da             |  from
+dal            |  da + il
+dallo          |  da + lo
+dai            |  da + i
+dagli          |  da + gli
+dall           |  da + l'
+dagl           |  da + gll'
+dalla          |  da + la
+dalle          |  da + le
+di             |  of
+del            |  di + il
+dello          |  di + lo
+dei            |  di + i
+degli          |  di + gli
+dell           |  di + l'
+degl           |  di + gl'
+della          |  di + la
+delle          |  di + le
+in             |  in
+nel            |  in + el
+nello          |  in + lo
+nei            |  in + i
+negli          |  in + gli
+nell           |  in + l'
+negl           |  in + gl'
+nella          |  in + la
+nelle          |  in + le
+su             |  on
+sul            |  su + il
+sullo          |  su + lo
+sui            |  su + i
+sugli          |  su + gli
+sull           |  su + l'
+sugl           |  su + gl'
+sulla          |  su + la
+sulle          |  su + le
+per            |  through, by
+tra            |  among
+contro         |  against
+io             |  I
+tu             |  thou
+lui            |  he
+lei            |  she
+noi            |  we
+voi            |  you
+loro           |  they
+mio            |  my
+mia            |
+miei           |
+mie            |
+tuo            |
+tua            |
+tuoi           |  thy
+tue            |
+suo            |
+sua            |
+suoi           |  his, her
+sue            |
+nostro         |  our
+nostra         |
+nostri         |
+nostre         |
+vostro         |  your
+vostra         |
+vostri         |
+vostre         |
+mi             |  me
+ti             |  thee
+ci             |  us, there
+vi             |  you, there
+lo             |  him, the
+la             |  her, the
+li             |  them
+le             |  them, the
+gli            |  to him, the
+ne             |  from there etc
+il             |  the
+un             |  a
+uno            |  a
+una            |  a
+ma             |  but
+ed             |  and
+se             |  if
+perch√©         |  why, because
+anche          |  also
+come           |  how
+dov            |  where (as dov')
+dove           |  where
+che            |  who, that
+chi            |  who
+cui            |  whom
+non            |  not
+pi√π            |  more
+quale          |  who, that
+quanto         |  how much
+quanti         |
+quanta         |
+quante         |
+quello         |  that
+quelli         |
+quella         |
+quelle         |
+questo         |  this
+questi         |
+questa         |
+queste         |
+si             |  yes
+tutto          |  all
+tutti          |  all
+
+               |  single letter forms:
+
+a              |  at
+c              |  as c' for ce or ci
+e              |  and
+i              |  the
+l              |  as l'
+o              |  or
+
+               | forms of avere, to have (not including the infinitive):
+
+ho
+hai
+ha
+abbiamo
+avete
+hanno
+abbia
+abbiate
+abbiano
+avr√≤
+avrai
+avr?
+avremo
+avrete
+avranno
+avrei
+avresti
+avrebbe
+avremmo
+avreste
+avrebbero
+avevo
+avevi
+aveva
+avevamo
+avevate
+avevano
+ebbi
+avesti
+ebbe
+avemmo
+aveste
+ebbero
+avessi
+avesse
+avessimo
+avessero
+avendo
+avuto
+avuta
+avuti
+avute
+
+               | forms of essere, to be (not including the infinitive):
+sono
+sei
+√®
+siamo
+siete
+sia
+siate
+siano
+sar√≤
+sarai
+sar?
+saremo
+sarete
+saranno
+sarei
+saresti
+sarebbe
+saremmo
+sareste
+sarebbero
+ero
+eri
+era
+eravamo
+eravate
+erano
+fui
+fosti
+fu
+fummo
+foste
+furono
+fossi
+fosse
+fossimo
+fossero
+essendo
+
+               | forms of fare, to do (not including the infinitive, fa, fat-):
+faccio
+fai
+facciamo
+fanno
+faccia
+facciate
+facciano
+far√≤
+farai
+far?
+faremo
+farete
+faranno
+farei
+faresti
+farebbe
+faremmo
+fareste
+farebbero
+facevo
+facevi
+faceva
+facevamo
+facevate
+facevano
+feci
+facesti
+fece
+facemmo
+faceste
+fecero
+facessi
+facesse
+facessimo
+facessero
+facendo
+
+               | forms of stare, to be (not including the infinitive):
+sto
+stai
+sta
+stiamo
+stanno
+stia
+stiate
+stiano
+star√≤
+starai
+star?
+staremo
+starete
+staranno
+starei
+staresti
+starebbe
+staremmo
+stareste
+starebbero
+stavo
+stavi
+stava
+stavamo
+stavate
+stavano
+stetti
+stesti
+stette
+stemmo
+steste
+stettero
+stessi
+stesse
+stessimo
+stessero
+stando
diff --git a/solr/example/solr/conf/lang/stopwords_ja.txt b/solr/example/solr/conf/lang/stopwords_ja.txt
new file mode 100644
index 0000000..db850d3
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_ja.txt
@@ -0,0 +1,122 @@
+#
+# This file defines a stopword set for Japanese.
+#
+# The set is made up hand-picked frequent terms from taken from segmented Japanese
+# Wikipedia.  Punctuation characters and frequent kanji have mostly been left out.
+#
+# There is an overlap between these stopwords and the terms removed when used in
+# combination with the KuromojiPartOfSpeechStopFilter.  When editing this file, note
+# that comments are not allowed on the same line as stopwords.
+#
+# See LUCENE-3745 for frequency lists, etc. that can be useful for making your own set.
+#
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+??
+???
+???
+??
+???
+???
+??
+???
+?®„???
+??
+??
+???
+???
+???
+???
+???
+???
+???
+???
+???
+?æ„?
+???
+?®„???
+???
+?æ„?
+???
+???
+??
+??
+??
+???
+????£„?
+?????
+???
+???
+?????
+??
+???
+?????
+??????
+??
+?????
+???
+?????
+??????
+??
+???
+???Âæ?
+?ß„???
+???
+??
+???
+???
+???
+?ß„?
+??
+??
+??????
+?????
+???
+?????
+?ß„?
+??
+???
+???‰ª?
+??????
+???
+?æ„?
+??
+???
+??????
+?π„?
+???
+???
+?????
+?®„?
+?ß„?
+???
+?ª„?
+?????
+???
+?????
+?®„????
+?????
+?????
+??????
+?æ„???
+??
+?ª„?
+?????
+??????
+?ª„????
+?®Â???
+?®„??£„?
+?ß„?
+?®„?
+?®„???
+???
+##### End of file
diff --git a/solr/example/solr/conf/lang/stopwords_lv.txt b/solr/example/solr/conf/lang/stopwords_lv.txt
new file mode 100644
index 0000000..e21a23c
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_lv.txt
@@ -0,0 +1,172 @@
+# Set of Latvian stopwords from A Stemming Algorithm for Latvian, Karlis Kreslins
+# the original list of over 800 forms was refined: 
+#   pronouns, adverbs, interjections were removed
+# 
+# prepositions
+aiz
+ap
+ar
+apak≈°
+?rpus
+aug≈°pus
+bez
+caur
+d?ƒº
+gar
+iek≈°
+iz
+kop≈°
+labad
+lejpus
+lƒ´dz
+no
+otrpus
+pa
+par
+p?r
+p?c
+pie
+pirms
+pret
+priek≈°
+starp
+≈°aipus
+uz
+vi?pus
+virs
+virspus
+zem
+apak≈°pus
+# Conjunctions
+un
+bet
+jo
+ja
+ka
+lai
+tom?r
+tikko
+turpretƒ´
+arƒ´
+kaut
+gan
+t?d?ƒº
+t?
+ne
+tikvien
+vien
+k?
+ir
+te
+vai
+kam?r
+# Particles
+ar
+diezin
+dro≈°i
+diem≈æ?l
+neb≈´t
+ik
+it
+ta?u
+nu
+pat
+tiklab
+iek≈°pus
+nedz
+tik
+nevis
+turpretim
+jeb
+iekam
+iek?m
+iek?ms
+kolƒ´dz
+lƒ´dzko
+tiklƒ´dz
+jeb≈°u
+t?lab
+t?p?c
+nek?
+itin
+j?
+jau
+jel
+n?
+nezin
+tad
+tikai
+vis
+tak
+iekams
+vien
+# modal verbs
+b≈´t  
+biju 
+biji
+bija
+bij?m
+bij?t
+esmu
+esi
+esam
+esat 
+b≈´≈°u     
+b≈´si
+b≈´s
+b≈´sim
+b≈´siet
+tikt
+tiku
+tiki
+tika
+tik?m
+tik?t
+tieku
+tiec
+tiek
+tiekam
+tiekat
+tik≈°u
+tiks
+tiksim
+tiksiet
+tapt
+tapi
+tap?t
+topat
+tap≈°u
+tapsi
+taps
+tapsim
+tapsiet
+kƒº≈´t
+kƒºuvu
+kƒºuvi
+kƒºuva
+kƒºuv?m
+kƒºuv?t
+kƒº≈´stu
+kƒº≈´sti
+kƒº≈´st
+kƒº≈´stam
+kƒº≈´stat
+kƒº≈´≈°u
+kƒº≈´si
+kƒº≈´s
+kƒº≈´sim
+kƒº≈´siet
+# verbs
+var?t
+var?ju
+var?j?m
+var?≈°u
+var?sim
+var
+var?ji
+var?j?t
+var?si
+var?siet
+varat
+var?ja
+var?s
diff --git a/solr/example/solr/conf/lang/stopwords_nl.txt b/solr/example/solr/conf/lang/stopwords_nl.txt
new file mode 100644
index 0000000..f4d61f5
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_nl.txt
@@ -0,0 +1,117 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/dutch/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Dutch stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ | This is a ranked list (commonest to rarest) of stopwords derived from
+ | a large sample of Dutch text.
+
+ | Dutch stop words frequently exhibit homonym clashes. These are indicated
+ | clearly below.
+
+de             |  the
+en             |  and
+van            |  of, from
+ik             |  I, the ego
+te             |  (1) chez, at etc, (2) to, (3) too
+dat            |  that, which
+die            |  that, those, who, which
+in             |  in, inside
+een            |  a, an, one
+hij            |  he
+het            |  the, it
+niet           |  not, nothing, naught
+zijn           |  (1) to be, being, (2) his, one's, its
+is             |  is
+was            |  (1) was, past tense of all persons sing. of 'zijn' (to be) (2) wax, (3) the washing, (4) rise of river
+op             |  on, upon, at, in, up, used up
+aan            |  on, upon, to (as dative)
+met            |  with, by
+als            |  like, such as, when
+voor           |  (1) before, in front of, (2) furrow
+had            |  had, past tense all persons sing. of 'hebben' (have)
+er             |  there
+maar           |  but, only
+om             |  round, about, for etc
+hem            |  him
+dan            |  then
+zou            |  should/would, past tense all persons sing. of 'zullen'
+of             |  or, whether, if
+wat            |  what, something, anything
+mijn           |  possessive and noun 'mine'
+men            |  people, 'one'
+dit            |  this
+zo             |  so, thus, in this way
+door           |  through by
+over           |  over, across
+ze             |  she, her, they, them
+zich           |  oneself
+bij            |  (1) a bee, (2) by, near, at
+ook            |  also, too
+tot            |  till, until
+je             |  you
+mij            |  me
+uit            |  out of, from
+der            |  Old Dutch form of 'van der' still found in surnames
+daar           |  (1) there, (2) because
+haar           |  (1) her, their, them, (2) hair
+naar           |  (1) unpleasant, unwell etc, (2) towards, (3) as
+heb            |  present first person sing. of 'to have'
+hoe            |  how, why
+heeft          |  present third person sing. of 'to have'
+hebben         |  'to have' and various parts thereof
+deze           |  this
+u              |  you
+want           |  (1) for, (2) mitten, (3) rigging
+nog            |  yet, still
+zal            |  'shall', first and third person sing. of verb 'zullen' (will)
+me             |  me
+zij            |  she, they
+nu             |  now
+ge             |  'thou', still used in Belgium and south Netherlands
+geen           |  none
+omdat          |  because
+iets           |  something, somewhat
+worden         |  to become, grow, get
+toch           |  yet, still
+al             |  all, every, each
+waren          |  (1) 'were' (2) to wander, (3) wares, (3)
+veel           |  much, many
+meer           |  (1) more, (2) lake
+doen           |  to do, to make
+toen           |  then, when
+moet           |  noun 'spot/mote' and present form of 'to must'
+ben            |  (1) am, (2) 'are' in interrogative second person singular of 'to be'
+zonder         |  without
+kan            |  noun 'can' and present form of 'to be able'
+hun            |  their, them
+dus            |  so, consequently
+alles          |  all, everything, anything
+onder          |  under, beneath
+ja             |  yes, of course
+eens           |  once, one day
+hier           |  here
+wie            |  who
+werd           |  imperfect third person sing. of 'become'
+altijd         |  always
+doch           |  yet, but etc
+wordt          |  present third person sing. of 'become'
+wezen          |  (1) to be, (2) 'been' as in 'been fishing', (3) orphans
+kunnen         |  to be able
+ons            |  us/our
+zelf           |  self
+tegen          |  against, towards, at
+na             |  after, near
+reeds          |  already
+wil            |  (1) present tense of 'want', (2) 'will', noun, (3) fender
+kon            |  could; past tense of 'to be able'
+niets          |  nothing
+uw             |  your
+iemand         |  somebody
+geweest        |  been; past participle of 'be'
+andere         |  other
diff --git a/solr/example/solr/conf/lang/stopwords_no.txt b/solr/example/solr/conf/lang/stopwords_no.txt
new file mode 100644
index 0000000..e76f36e
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_no.txt
@@ -0,0 +1,192 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/norwegian/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Norwegian stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ | This stop word list is for the dominant bokm√•l dialect. Words unique
+ | to nynorsk are marked *.
+
+ | Revised by Jan Bruusgaard <Jan.Bruusgaard@ssb.no>, Jan 2005
+
+og             | and
+i              | in
+jeg            | I
+det            | it/this/that
+at             | to (w. inf.)
+en             | a/an
+et             | a/an
+den            | it/this/that
+til            | to
+er             | is/am/are
+som            | who/that
+p√•             | on
+de             | they / you(formal)
+med            | with
+han            | he
+av             | of
+ikke           | not
+ikkje          | not *
+der            | there
+s√•             | so
+var            | was/were
+meg            | me
+seg            | you
+men            | but
+ett            | one
+har            | have
+om             | about
+vi             | we
+min            | my
+mitt           | my
+ha             | have
+hadde          | had
+hun            | she
+n√•             | now
+over           | over
+da             | when/as
+ved            | by/know
+fra            | from
+du             | you
+ut             | out
+sin            | your
+dem            | them
+oss            | us
+opp            | up
+man            | you/one
+kan            | can
+hans           | his
+hvor           | where
+eller          | or
+hva            | what
+skal           | shall/must
+selv           | self (reflective)
+sj√∏l           | self (reflective)
+her            | here
+alle           | all
+vil            | will
+bli            | become
+ble            | became
+blei           | became *
+blitt          | have become
+kunne          | could
+inn            | in
+n√•r            | when
+v√¶re           | be
+kom            | come
+noen           | some
+noe            | some
+ville          | would
+dere           | you
+som            | who/which/that
+deres          | their/theirs
+kun            | only/just
+ja             | yes
+etter          | after
+ned            | down
+skulle         | should
+denne          | this
+for            | for/because
+deg            | you
+si             | hers/his
+sine           | hers/his
+sitt           | hers/his
+mot            | against
+√•              | to
+meget          | much
+hvorfor        | why
+dette          | this
+disse          | these/those
+uten           | without
+hvordan        | how
+ingen          | none
+din            | your
+ditt           | your
+blir           | become
+samme          | same
+hvilken        | which
+hvilke         | which (plural)
+s√•nn           | such a
+inni           | inside/within
+mellom         | between
+v√•r            | our
+hver           | each
+hvem           | who
+vors           | us/ours
+hvis           | whose
+b√•de           | both
+bare           | only/just
+enn            | than
+fordi          | as/because
+f√∏r            | before
+mange          | many
+ogs√•           | also
+slik           | just
+v√¶rt           | been
+v√¶re           | to be
+b√•e            | both *
+begge          | both
+siden          | since
+dykk           | your *
+dykkar         | yours *
+dei            | they *
+deira          | them *
+deires         | theirs *
+deim           | them *
+di             | your (fem.) *
+d√•             | as/when *
+eg             | I *
+ein            | a/an *
+eit            | a/an *
+eitt           | a/an *
+elles          | or *
+honom          | he *
+hj√•            | at *
+ho             | she *
+hoe            | she *
+henne          | her
+hennar         | her/hers
+hennes         | hers
+hoss           | how *
+hossen         | how *
+ikkje          | not *
+ingi           | noone *
+inkje          | noone *
+korleis        | how *
+korso          | how *
+kva            | what/which *
+kvar           | where *
+kvarhelst      | where *
+kven           | who/whom *
+kvi            | why *
+kvifor         | why *
+me             | we *
+medan          | while *
+mi             | my *
+mine           | my *
+mykje          | much *
+no             | now *
+nokon          | some (masc./neut.) *
+noka           | some (fem.) *
+nokor          | some *
+noko           | some *
+nokre          | some *
+si             | his/hers *
+sia            | since *
+sidan          | since *
+so             | so *
+somt           | some *
+somme          | some *
+um             | about*
+upp            | up *
+vere           | be *
+vore           | was *
+verte          | become *
+vort           | become *
+varte          | became *
+vart           | became *
+
diff --git a/solr/example/solr/conf/lang/stopwords_pt.txt b/solr/example/solr/conf/lang/stopwords_pt.txt
new file mode 100644
index 0000000..276c1b4
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_pt.txt
@@ -0,0 +1,251 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/portuguese/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Portuguese stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+
+ | The following is a ranked list (commonest to rarest) of stopwords
+ | deriving from a large sample of text.
+
+ | Extra words have been added at the end.
+
+de             |  of, from
+a              |  the; to, at; her
+o              |  the; him
+que            |  who, that
+e              |  and
+do             |  de + o
+da             |  de + a
+em             |  in
+um             |  a
+para           |  for
+  | √©          from SER
+com            |  with
+n√£o            |  not, no
+uma            |  a
+os             |  the; them
+no             |  em + o
+se             |  himself etc
+na             |  em + a
+por            |  for
+mais           |  more
+as             |  the; them
+dos            |  de + os
+como           |  as, like
+mas            |  but
+  | foi        from SER
+ao             |  a + o
+ele            |  he
+das            |  de + as
+  | tem        from TER
+?              |  a + a
+seu            |  his
+sua            |  her
+ou             |  or
+  | ser        from SER
+quando         |  when
+muito          |  much
+  | h√°         from HAV
+nos            |  em + os; us
+j√°             |  already, now
+  | est√°       from EST
+eu             |  I
+tamb√©m         |  also
+s√≥             |  only, just
+pelo           |  per + o
+pela           |  per + a
+at√©            |  up to
+isso           |  that
+ela            |  he
+entre          |  between
+  | era        from SER
+depois         |  after
+sem            |  without
+mesmo          |  same
+aos            |  a + os
+  | ter        from TER
+seus           |  his
+quem           |  whom
+nas            |  em + as
+me             |  me
+esse           |  that
+eles           |  they
+  | est√£o      from EST
+voc√™           |  you
+  | tinha      from TER
+  | foram      from SER
+essa           |  that
+num            |  em + um
+nem            |  nor
+suas           |  her
+meu            |  my
+?s             |  a + as
+minha          |  my
+  | t√™m        from TER
+numa           |  em + uma
+pelos          |  per + os
+elas           |  they
+  | havia      from HAV
+  | seja       from SER
+qual           |  which
+  | ser√°       from SER
+n√≥s            |  we
+  | tenho      from TER
+lhe            |  to him, her
+deles          |  of them
+essas          |  those
+esses          |  those
+pelas          |  per + as
+este           |  this
+  | fosse      from SER
+dele           |  of him
+
+ | other words. There are many contractions such as naquele = em+aquele,
+ | mo = me+o, but they are rare.
+ | Indefinite article plural forms are also rare.
+
+tu             |  thou
+te             |  thee
+voc√™s          |  you (plural)
+vos            |  you
+lhes           |  to them
+meus           |  my
+minhas
+teu            |  thy
+tua
+teus
+tuas
+nosso          | our
+nossa
+nossos
+nossas
+
+dela           |  of her
+delas          |  of them
+
+esta           |  this
+estes          |  these
+estas          |  these
+aquele         |  that
+aquela         |  that
+aqueles        |  those
+aquelas        |  those
+isto           |  this
+aquilo         |  that
+
+               | forms of estar, to be (not including the infinitive):
+estou
+est√°
+estamos
+est√£o
+estive
+esteve
+estivemos
+estiveram
+estava
+est√°vamos
+estavam
+estivera
+estiv√©ramos
+esteja
+estejamos
+estejam
+estivesse
+estiv√©ssemos
+estivessem
+estiver
+estivermos
+estiverem
+
+               | forms of haver, to have (not including the infinitive):
+hei
+h√°
+havemos
+h√£o
+houve
+houvemos
+houveram
+houvera
+houv√©ramos
+haja
+hajamos
+hajam
+houvesse
+houv√©ssemos
+houvessem
+houver
+houvermos
+houverem
+houverei
+houver√°
+houveremos
+houver√£o
+houveria
+houver√≠amos
+houveriam
+
+               | forms of ser, to be (not including the infinitive):
+sou
+somos
+s√£o
+era
+√©ramos
+eram
+fui
+foi
+fomos
+foram
+fora
+f√¥ramos
+seja
+sejamos
+sejam
+fosse
+f√¥ssemos
+fossem
+for
+formos
+forem
+serei
+ser√°
+seremos
+ser√£o
+seria
+ser√≠amos
+seriam
+
+               | forms of ter, to have (not including the infinitive):
+tenho
+tem
+temos
+t√©m
+tinha
+t√≠nhamos
+tinham
+tive
+teve
+tivemos
+tiveram
+tivera
+tiv√©ramos
+tenha
+tenhamos
+tenham
+tivesse
+tiv√©ssemos
+tivessem
+tiver
+tivermos
+tiverem
+terei
+ter√°
+teremos
+ter√£o
+teria
+ter√≠amos
+teriam
diff --git a/solr/example/solr/conf/lang/stopwords_ro.txt b/solr/example/solr/conf/lang/stopwords_ro.txt
new file mode 100644
index 0000000..4fdee90
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_ro.txt
@@ -0,0 +1,233 @@
+# This file was created by Jacques Savoy and is distributed under the BSD license.
+# See http://members.unine.ch/jacques.savoy/clef/index.html.
+# Also see http://www.opensource.org/licenses/bsd-license.html
+acea
+aceasta
+aceast?
+aceea
+acei
+aceia
+acel
+acela
+acele
+acelea
+acest
+acesta
+aceste
+acestea
+ace?ti
+ace?tia
+acolo
+acum
+ai
+aia
+aib?
+aici
+al
+?la
+ale
+alea
+?lea
+altceva
+altcineva
+am
+ar
+are
+a?
+a?adar
+asemenea
+asta
+?sta
+ast?zi
+astea
+?stea
+??tia
+asupra
+a≈£i
+au
+avea
+avem
+ave≈£i
+azi
+bine
+bucur
+bun?
+ca
+c?
+c?ci
+c√¢nd
+care
+c?rei
+c?ror
+c?rui
+c√¢t
+c√¢te
+c√¢≈£i
+c?tre
+c√¢tva
+ce
+cel
+ceva
+chiar
+c√Ænd
+cine
+cineva
+c√Æt
+c√Æte
+c√Æ≈£i
+c√Ætva
+contra
+cu
+cum
+cumva
+cur√¢nd
+cur√Ænd
+da
+d?
+dac?
+dar
+datorit?
+de
+deci
+deja
+deoarece
+departe
+de?i
+din
+dinaintea
+dintr
+dintre
+drept
+dup?
+ea
+ei
+el
+ele
+eram
+este
+e?ti
+eu
+face
+f?r?
+fi
+fie
+fiecare
+fii
+fim
+fi≈£i
+iar
+ieri
+√Æi
+√Æl
+√Æmi
+√Æmpotriva
+√Æn 
+√Ænainte
+√Ænaintea
+√Ænc√¢t
+√Ænc√Æt
+√Æncotro
+√Æntre
+√Æntruc√¢t
+√Æntruc√Æt
+√Æ≈£i
+la
+l√¢ng?
+le
+li
+l√Æng?
+lor
+lui
+m?
+m√¢ine
+mea
+mei
+mele
+mereu
+meu
+mi
+mine
+mult
+mult?
+mul≈£i
+ne
+nic?ieri
+nici
+nimeni
+ni?te
+noastr?
+noastre
+noi
+no?tri
+nostru
+nu
+ori
+oric√¢nd
+oricare
+oric√¢t
+orice
+oric√Ænd
+oricine
+oric√Æt
+oricum
+oriunde
+p√¢n?
+pe
+pentru
+peste
+p√Æn?
+poate
+pot
+prea
+prima
+primul
+prin
+printr
+sa
+s?
+s?i
+sale
+sau
+s?u
+se
+?i
+s√Ænt
+s√Æntem
+s√Ænte≈£i
+spre
+sub
+sunt
+suntem
+sunte≈£i
+ta
+t?i
+tale
+t?u
+te
+≈£i
+≈£ie
+tine
+toat?
+toate
+tot
+to≈£i
+totu?i
+tu
+un
+una
+unde
+undeva
+unei
+unele
+uneori
+unor
+v?
+vi
+voastr?
+voastre
+voi
+vo?tri
+vostru
+vou?
+vreo
+vreun
diff --git a/solr/example/solr/conf/lang/stopwords_ru.txt b/solr/example/solr/conf/lang/stopwords_ru.txt
new file mode 100644
index 0000000..6430769
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_ru.txt
@@ -0,0 +1,241 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/russian/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | a russian stop word list. comments begin with vertical bar. each stop
+ | word is at the start of a line.
+
+ | this is a ranked list (commonest to rarest) of stopwords derived from
+ | a large text sample.
+
+ | letter `?' is translated to `–µ'.
+
+–∏              | and
+–≤              | in/into
+–≤–æ             | alternative form
+–Ω–µ             | not
+??–æ            | what/that
+–æ–Ω             | he
+–Ω–∞             | on/onto
+?              | i
+?              | from
+?–æ             | alternative form
+–∫–∞–∫            | how
+–∞              | milder form of `no' (but)
+?–æ             | conjunction and form of `that'
+–≤?–µ            | all
+–æ–Ω–∞            | she
+?–∞–∫            | so, thus
+–µ–≥–æ            | him
+–Ω–æ             | but
+–¥–∞             | yes/and
+??             | thou
+–∫              | towards, by
+?              | around, chez
+–∂–µ             | intensifier particle
+–≤?             | you
+–∑–∞             | beyond, behind
+–±?             | conditional/subj. particle
+–ø–æ             | up to, along
+?–æ–ª?–∫–æ         | only
+–µ–µ             | her
+–º–Ω–µ            | to me
+–±?–ª–æ           | it was
+–≤–æ?            | here is/are, particle
+–æ?             | away from
+–º–µ–Ω?           | me
+–µ?–µ            | still, yet, more
+–Ω–µ?            | no, there isnt/arent
+–æ              | about
+–∏–∑             | out of
+–µ–º?            | to him
+?–µ–ø–µ??         | now
+–∫–æ–≥–¥–∞          | when
+–¥–∞–∂–µ           | even
+–Ω?             | so, well
+–≤–¥??–≥          | suddenly
+–ª–∏             | interrogative particle
+–µ?–ª–∏           | if
+?–∂–µ            | already, but homonym of `narrower'
+–∏–ª–∏            | or
+–Ω–∏             | neither
+–±???           | to be
+–±?–ª            | he was
+–Ω–µ–≥–æ           | prepositional form of –µ–≥–æ
+–¥–æ             | up to
+–≤–∞?            | you accusative
+–Ω–∏–±?–¥?         | indef. suffix preceded by hyphen
+–æ–ø???          | again
+?–∂             | already, but homonym of `adder'
+–≤–∞–º            | to you
+?–∫–∞–∑–∞–ª         | he said
+–≤–µ–¥?           | particle `after all'
+?–∞–º            | there
+–ø–æ?–æ–º          | then
+?–µ–±?           | oneself
+–Ω–∏?–µ–≥–æ         | nothing
+–µ–π             | to her
+–º–æ–∂–µ?          | usually with `–±???' as `maybe'
+–æ–Ω–∏            | they
+???            | here
+–≥–¥–µ            | where
+–µ???           | there is/are
+–Ω–∞–¥–æ           | got to, must
+–Ω–µ–π            | prepositional form of  –µ–π
+–¥–ª?            | for
+–º?             | we
+?–µ–±?           | thee
+–∏?             | them, their
+?–µ–º            | than
+–±?–ª–∞           | she was
+?–∞–º            | self
+??–æ–±           | in order to
+–±–µ–∑            | without
+–±?–¥?–æ          | as if
+?–µ–ª–æ–≤–µ–∫        | man, person, one
+?–µ–≥–æ           | genitive form of `what'
+?–∞–∑            | once
+?–æ–∂–µ           | also
+?–µ–±–µ           | to oneself
+–ø–æ–¥            | beneath
+–∂–∏–∑–Ω?          | life
+–±?–¥–µ?          | will be
+–∂              | short form of intensifer particle `–∂–µ'
+?–æ–≥–¥–∞          | then
+–∫?–æ            | who
+??–æ?           | this
+–≥–æ–≤–æ?–∏–ª        | was saying
+?–æ–≥–æ           | genitive form of `that'
+–ø–æ?–æ–º?         | for that reason
+??–æ–≥–æ          | genitive form of `this'
+–∫–∞–∫–æ–π          | which
+?–æ–≤?–µ–º         | altogether
+–Ω–∏–º            | prepositional form of `–µ–≥–æ', `–æ–Ω–∏'
+–∑–¥–µ??          | here
+??–æ–º           | prepositional form of `??–æ?'
+–æ–¥–∏–Ω           | one
+–ø–æ??–∏          | almost
+–º–æ–π            | my
+?–µ–º            | instrumental/dative plural of `?–æ?', `?–æ'
+??–æ–±?          | full form of `in order that'
+–Ω–µ–µ            | her (acc.)
+–∫–∞–∂–µ???        | it seems
+?–µ–π?–∞?         | now
+–±?–ª–∏           | they were
+–∫?–¥–∞           | where to
+–∑–∞?–µ–º          | why
+?–∫–∞–∑–∞??        | to say
+–≤?–µ?           | all (acc., gen. preposn. plural)
+–Ω–∏–∫–æ–≥–¥–∞        | never
+?–µ–≥–æ–¥–Ω?        | today
+–º–æ–∂–Ω–æ          | possible, one can
+–ø?–∏            | by
+–Ω–∞–∫–æ–Ω–µ?        | finally
+–¥–≤–∞            | two
+–æ–±             | alternative form of `–æ', about
+–¥??–≥–æ–π         | another
+?–æ??           | even
+–ø–æ?–ª–µ          | after
+–Ω–∞–¥            | above
+–±–æ–ª??–µ         | more
+?–æ?            | that one (masc.)
+?–µ?–µ–∑          | across, in
+??–∏            | these
+–Ω–∞?            | us
+–ø?–æ            | about
+–≤?–µ–≥–æ          | in all, only, of all
+–Ω–∏?            | prepositional form of `–æ–Ω–∏' (they)
+–∫–∞–∫–∞?          | which, feminine
+–º–Ω–æ–≥–æ          | lots
+?–∞–∑–≤–µ          | interrogative particle
+?–∫–∞–∑–∞–ª–∞        | she said
+??–∏            | three
+???            | this, acc. fem. sing.
+–º–æ?            | my, feminine
+–≤–ø?–æ?–µ–º        | moreover, besides
+?–æ?–æ?–æ         | good
+?–≤–æ?           | ones own, acc. fem. sing.
+??–æ–π           | oblique form of `??–∞', fem. `this'
+–ø–µ?–µ–¥          | in front of
+–∏–Ω–æ–≥–¥–∞         | sometimes
+–ª???–µ          | better
+????           | a little
+?–æ–º            | preposn. form of `that one'
+–Ω–µ–ª?–∑?         | one must not
+?–∞–∫–æ–π          | such a one
+–∏–º             | to them
+–±–æ–ª–µ–µ          | more
+–≤?–µ–≥–¥–∞         | always
+–∫–æ–Ω–µ?–Ω–æ        | of course
+–≤??            | acc. fem. sing of `all'
+–º–µ–∂–¥?          | between
+
+
+  | b: some paradigms
+  |
+  | personal pronouns
+  |
+  | ?  –º–µ–Ω?  –º–Ω–µ  –º–Ω–æ–π  [–º–Ω–æ?]
+  | ??  ?–µ–±?  ?–µ–±–µ  ?–æ–±–æ–π  [?–æ–±–æ?]
+  | –æ–Ω  –µ–≥–æ  –µ–º?  –∏–º  [–Ω–µ–≥–æ, –Ω–µ–º?, –Ω–∏–º]
+  | –æ–Ω–∞  –µ–µ  ?–∏  –µ?  [–Ω–µ–µ, –Ω?–∏, –Ω–µ?]
+  | –æ–Ω–æ  –µ–≥–æ  –µ–º?  –∏–º  [–Ω–µ–≥–æ, –Ω–µ–º?, –Ω–∏–º]
+  |
+  | –º?  –Ω–∞?  –Ω–∞–º  –Ω–∞–º–∏
+  | –≤?  –≤–∞?  –≤–∞–º  –≤–∞–º–∏
+  | –æ–Ω–∏  –∏?  –∏–º  –∏–º–∏  [–Ω–∏?, –Ω–∏–º, –Ω–∏–º–∏]
+  |
+  |   ?–µ–±?  ?–µ–±–µ  ?–æ–±–æ–π   [?–æ–±–æ?]
+  |
+  | demonstrative pronouns: ??–æ? (this), ?–æ? (that)
+  |
+  | ??–æ?  ??–∞  ??–æ  ??–∏
+  | ??–æ–≥–æ  ???  ??–æ  ??–∏
+  | ??–æ–≥–æ  ??–æ–π  ??–æ–≥–æ  ??–∏?
+  | ??–æ–º?  ??–æ–π  ??–æ–º?  ??–∏–º
+  | ??–∏–º  ??–æ–π  ??–∏–º  [??–æ?]  ??–∏–º–∏
+  | ??–æ–º  ??–æ–π  ??–æ–º  ??–∏?
+  |
+  | ?–æ?  ?–∞  ?–æ  ?–µ
+  | ?–æ–≥–æ  ??  ?–æ  ?–µ
+  | ?–æ–≥–æ  ?–æ–π  ?–æ–≥–æ  ?–µ?
+  | ?–æ–º?  ?–æ–π  ?–æ–º?  ?–µ–º
+  | ?–µ–º  ?–æ–π  ?–µ–º  [?–æ?]  ?–µ–º–∏
+  | ?–æ–º  ?–æ–π  ?–æ–º  ?–µ?
+  |
+  | determinative pronouns
+  |
+  | (a) –≤–µ?? (all)
+  |
+  | –≤–µ??  –≤??  –≤?–µ  –≤?–µ
+  | –≤?–µ–≥–æ  –≤??  –≤?–µ  –≤?–µ
+  | –≤?–µ–≥–æ  –≤?–µ–π  –≤?–µ–≥–æ  –≤?–µ?
+  | –≤?–µ–º?  –≤?–µ–π  –≤?–µ–º?  –≤?–µ–º
+  | –≤?–µ–º  –≤?–µ–π  –≤?–µ–º  [–≤?–µ?]  –≤?–µ–º–∏
+  | –≤?–µ–º  –≤?–µ–π  –≤?–µ–º  –≤?–µ?
+  |
+  | (b) ?–∞–º (himself etc)
+  |
+  | ?–∞–º  ?–∞–º–∞  ?–∞–º–æ  ?–∞–º–∏
+  | ?–∞–º–æ–≥–æ ?–∞–º?  ?–∞–º–æ  ?–∞–º–∏?
+  | ?–∞–º–æ–≥–æ ?–∞–º–æ–π ?–∞–º–æ–≥–æ  ?–∞–º–∏?
+  | ?–∞–º–æ–º? ?–∞–º–æ–π ?–∞–º–æ–º?  ?–∞–º–∏–º
+  | ?–∞–º–∏–º  ?–∞–º–æ–π  ?–∞–º–∏–º  [?–∞–º–æ?]  ?–∞–º–∏–º–∏
+  | ?–∞–º–æ–º ?–∞–º–æ–π ?–∞–º–æ–º  ?–∞–º–∏?
+  |
+  | stems of verbs `to be', `to have', `to do' and modal
+  |
+  | –±???  –±?  –±?–¥  –±?–≤  –µ???  ????
+  | –∏–º–µ
+  | –¥–µ–ª
+  | –º–æ–≥   –º–æ–∂  –º–æ??
+  | ?–º–µ
+  | ?–æ?  ?–æ?
+  | –¥–æ–ª–∂
+  | –º–æ–∂–Ω
+  | –Ω?–∂–Ω
+  | –Ω–µ–ª?–∑?
+
diff --git a/solr/example/solr/conf/lang/stopwords_sv.txt b/solr/example/solr/conf/lang/stopwords_sv.txt
new file mode 100644
index 0000000..22bddfd
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_sv.txt
@@ -0,0 +1,131 @@
+ | From svn.tartarus.org/snowball/trunk/website/algorithms/swedish/stop.txt
+ | This file is distributed under the BSD License.
+ | See http://snowball.tartarus.org/license.php
+ | Also see http://www.opensource.org/licenses/bsd-license.html
+ |  - Encoding was converted to UTF-8.
+ |  - This notice was added.
+
+ | A Swedish stop word list. Comments begin with vertical bar. Each stop
+ | word is at the start of a line.
+
+ | This is a ranked list (commonest to rarest) of stopwords derived from
+ | a large text sample.
+
+ | Swedish stop words occasionally exhibit homonym clashes. For example
+ |  s√• = so, but also seed. These are indicated clearly below.
+
+och            | and
+det            | it, this/that
+att            | to (with infinitive)
+i              | in, at
+en             | a
+jag            | I
+hon            | she
+som            | who, that
+han            | he
+p√•             | on
+den            | it, this/that
+med            | with
+var            | where, each
+sig            | him(self) etc
+f√∂r            | for
+s√•             | so (also: seed)
+till           | to
+√§r             | is
+men            | but
+ett            | a
+om             | if; around, about
+hade           | had
+de             | they, these/those
+av             | of
+icke           | not, no
+mig            | me
+du             | you
+henne          | her
+d√•             | then, when
+sin            | his
+nu             | now
+har            | have
+inte           | inte n√•gon = no one
+hans           | his
+honom          | him
+skulle         | 'sake'
+hennes         | her
+d√§r            | there
+min            | my
+man            | one (pronoun)
+ej             | nor
+vid            | at, by, on (also: vast)
+kunde          | could
+n√•got          | some etc
+fr√•n           | from, off
+ut             | out
+n√§r            | when
+efter          | after, behind
+upp            | up
+vi             | we
+dem            | them
+vara           | be
+vad            | what
+√∂ver           | over
+√§n             | than
+dig            | you
+kan            | can
+sina           | his
+h√§r            | here
+ha             | have
+mot            | towards
+alla           | all
+under          | under (also: wonder)
+n√•gon          | some etc
+eller          | or (else)
+allt           | all
+mycket         | much
+sedan          | since
+ju             | why
+denna          | this/that
+sj√§lv          | myself, yourself etc
+detta          | this/that
+√•t             | to
+utan           | without
+varit          | was
+hur            | how
+ingen          | no
+mitt           | my
+ni             | you
+bli            | to be, become
+blev           | from bli
+oss            | us
+din            | thy
+dessa          | these/those
+n√•gra          | some etc
+deras          | their
+blir           | from bli
+mina           | my
+samma          | (the) same
+vilken         | who, that
+er             | you, your
+s√•dan          | such a
+v√•r            | our
+blivit         | from bli
+dess           | its
+inom           | within
+mellan         | between
+s√•dant         | such a
+varf√∂r         | why
+varje          | each
+vilka          | who, that
+ditt           | thy
+vem            | who
+vilket         | who, that
+sitta          | his
+s√•dana         | such a
+vart           | each
+dina           | thy
+vars           | whose
+v√•rt           | our
+v√•ra           | our
+ert            | your
+era            | your
+vilkas         | whose
+
diff --git a/solr/example/solr/conf/lang/stopwords_th.txt b/solr/example/solr/conf/lang/stopwords_th.txt
new file mode 100644
index 0000000..07f0fab
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_th.txt
@@ -0,0 +1,119 @@
+# Thai stopwords from:
+# "Opinion Detection in Thai Political News Columns
+# Based on Subjectivity Analysis"
+# Khampol Sukhum, Supot Nitsuwat, and Choochart Haruechaiyasak
+‡π?∏ß‡π?
+‡π?∏°‡π?
+‡π??
+‡π??‡π?
+‡π?∏´‡π?
+‡π??
+‡π??‡∏?
+‡π?∏´‡π??
+‡π?∏•‡π?∏ß
+‡π?∏•‡∏?
+‡π?∏£‡∏?
+‡π??‡∏?
+‡π??‡π?
+‡π?‡∏??
+‡π?‡∏??‡∏?
+‡π?‡∏•‡∏¢
+‡π?‡∏£‡∏¥‡π?∏°
+‡π?‡∏£‡∏≤
+‡π?‡∏°‡∏∑‡π?∏≠
+‡π?‡∏?∏∑‡π?∏≠
+‡π?‡∏?∏£‡∏≤‡∏∞
+‡π?‡∏??‡∏??‡∏≤‡∏£
+‡π?‡∏??‡∏?
+‡π?‡∏?∏¥‡∏??‡∏?∏¢
+‡π?‡∏?∏¥‡∏?
+‡π?‡∏?∏∑‡π?∏≠‡∏??‡∏≤‡?
+‡π?‡∏?∏µ‡∏¢‡∏ß‡∏?∏±‡∏?
+‡π?‡∏?∏µ‡∏¢‡∏ß
+‡π?‡∏??‡∏?
+‡π?‡∏??‡∏≤‡∏∞
+‡π?‡∏?∏¢
+‡π?‡∏??‡∏?
+‡π?‡∏?∏≤
+‡∏?∏µ‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏∞‡π?∏£
+‡∏?∏≠‡∏?
+‡∏?∏¢‡π?∏≤‡∏?
+‡∏?∏¢‡∏π‡?
+‡∏?∏¢‡∏≤‡?
+‡∏?∏≤‡∏?
+‡∏?∏•‡∏≤‡∏¢
+‡∏?∏•‡∏±‡?‡∏?∏≤‡∏?
+‡∏?∏•‡∏±‡?
+‡∏?∏£‡∏∑‡∏≠
+‡∏??‡∏∂‡?‡∏?
+‡∏??‡∏ß‡?
+‡∏??‡∏?
+‡∏?∏∏‡∏?
+‡∏??‡∏≤‡∏´‡∏£‡∏±‡∏?
+‡∏ß‡?‡∏?
+‡∏ß‡∏±‡∏?
+‡∏•‡?
+‡∏£‡?‡∏ß‡∏°
+‡∏£‡∏≤‡∏?
+‡∏£‡∏±‡∏?
+‡∏£‡∏∞‡∏?∏ß‡π?∏≤‡∏?
+‡∏£‡∏ß‡∏?
+‡∏¢‡∏±‡∏?
+‡∏°‡∏µ
+‡∏°‡∏≤‡∏?
+‡∏°‡∏≤
+‡∏?∏£‡π?∏≠‡∏?
+‡∏??
+‡∏??‡∏≤‡?
+‡∏?∏•
+‡∏?∏≤‡∏?
+‡∏??‡∏?
+‡∏?∏µ‡π?
+‡∏??‡∏?
+‡∏?∏±‡π??
+‡∏?∏±‡∏?
+‡∏?∏≠‡∏??‡∏≤‡?
+‡∏?∏∏‡∏?
+‡∏?∏µ‡π?∏™‡∏∏‡?
+‡∏?∏µ‡π?
+‡∏??‡∏≤‡?‡∏??
+‡∏??‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡π??‡∏?∏µ‡π?
+‡∏?∏±‡π??
+‡∏??‡∏?
+‡∏?∏π‡∏?
+‡∏?∏∂‡∏?
+‡∏??‡∏??
+‡∏??‡∏≤‡?‡π?
+‡∏??‡∏≤‡?
+‡∏??‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡π??‡π??‡π?
+‡∏?∏±‡π??
+‡∏??‡∏≤‡?
+‡∏??‡∏ß‡∏¢
+‡∏?∏±‡∏?
+‡∏?∏∂‡π??
+‡∏??‡∏ß‡?
+‡∏?∏∂‡∏?
+‡∏?∏≤‡∏?
+‡∏?∏±‡∏?
+‡∏?∏∞
+‡∏?∏∑‡∏?
+‡∏?∏ß‡∏≤‡∏°
+‡∏?∏£‡∏±‡?‡∏?
+‡∏??
+‡∏?∏∂‡π??
+‡∏?∏≠‡∏?
+‡∏?∏≠
+‡∏??‡∏?
+‡∏??‡∏??
+‡∏??
+‡∏?∏≤‡∏?
+‡∏?∏±‡∏?
+‡∏?∏±‡∏?
+‡∏?∏ß‡π?∏≤
+‡∏?∏•‡π?∏≤‡∏?
diff --git a/solr/example/solr/conf/lang/stopwords_tr.txt b/solr/example/solr/conf/lang/stopwords_tr.txt
new file mode 100644
index 0000000..84d9408
--- /dev/null
+++ b/solr/example/solr/conf/lang/stopwords_tr.txt
@@ -0,0 +1,212 @@
+# Turkish stopwords from LUCENE-559
+# merged with the list from "Information Retrieval on Turkish Texts"
+#   (http://www.users.muohio.edu/canf/papers/JASIST2008offPrint.pdf)
+acaba
+altmƒ±?
+altƒ±
+ama
+ancak
+arada
+aslƒ±nda
+ayrƒ±ca
+bana
+bazƒ±
+belki
+ben
+benden
+beni
+benim
+beri
+be?
+bile
+bin
+bir
+bir√ßok
+biri
+birka√ß
+birkez
+bir?ey
+bir?eyi
+biz
+bize
+bizden
+bizi
+bizim
+b√∂yle
+b√∂ylece
+bu
+buna
+bunda
+bundan
+bunlar
+bunlarƒ±
+bunlarƒ±n
+bunu
+bunun
+burada
+√ßok
+√ß√ºnk√º
+da
+daha
+dahi
+de
+defa
+de?il
+di?er
+diye
+doksan
+dokuz
+dolayƒ±
+dolayƒ±sƒ±yla
+d√∂rt
+edecek
+eden
+ederek
+edilecek
+ediliyor
+edilmesi
+ediyor
+e?er
+elli
+en
+etmesi
+etti
+etti?i
+etti?ini
+gibi
+g√∂re
+halen
+hangi
+hatta
+hem
+hen√ºz
+hep
+hepsi
+her
+herhangi
+herkesin
+hi√ß
+hi√ßbir
+i√ßin
+iki
+ile
+ilgili
+ise
+i?te
+itibaren
+itibariyle
+kadar
+kar?ƒ±n
+katrilyon
+kendi
+kendilerine
+kendini
+kendisi
+kendisine
+kendisini
+kez
+ki
+kim
+kimden
+kime
+kimi
+kimse
+kƒ±rk
+milyar
+milyon
+mu
+m√º
+mƒ±
+nasƒ±l
+ne
+neden
+nedenle
+nerde
+nerede
+nereye
+niye
+ni√ßin
+o
+olan
+olarak
+oldu
+oldu?u
+oldu?unu
+olduklarƒ±nƒ±
+olmadƒ±
+olmadƒ±?ƒ±
+olmak
+olmasƒ±
+olmayan
+olmaz
+olsa
+olsun
+olup
+olur
+olursa
+oluyor
+on
+ona
+ondan
+onlar
+onlardan
+onlarƒ±
+onlarƒ±n
+onu
+onun
+otuz
+oysa
+√∂yle
+pek
+ra?men
+sadece
+sanki
+sekiz
+seksen
+sen
+senden
+seni
+senin
+siz
+sizden
+sizi
+sizin
+?ey
+?eyden
+?eyi
+?eyler
+?√∂yle
+?u
+?una
+?unda
+?undan
+?unlarƒ±
+?unu
+tarafƒ±ndan
+trilyon
+t√ºm
+√º√ß
+√ºzere
+var
+vardƒ±
+ve
+veya
+ya
+yani
+yapacak
+yapƒ±lan
+yapƒ±lmasƒ±
+yapƒ±yor
+yapmak
+yaptƒ±
+yaptƒ±?ƒ±
+yaptƒ±?ƒ±nƒ±
+yaptƒ±klarƒ±
+yedi
+yerine
+yetmi?
+yine
+yirmi
+yoksa
+y√ºz
+zaten
diff --git a/solr/example/solr/conf/schema.xml b/solr/example/solr/conf/schema.xml
index 5e140c0..0508bc8 100755
--- a/solr/example/solr/conf/schema.xml
+++ b/solr/example/solr/conf/schema.xml
@@ -219,7 +219,7 @@
 
     <!-- A text field with defaults appropriate for English: it
          tokenizes with StandardTokenizer, removes English stop words
-         (stopwords_en.txt), down cases, protects words from protwords.txt, and
+         (lang/stopwords_en.txt), down cases, protects words from protwords.txt, and
          finally applies Porter's stemming.  The query time analyzer
          also applies synonyms from synonyms.txt. -->
     <fieldType name="text_en" class="solr.TextField" positionIncrementGap="100">
@@ -234,7 +234,7 @@
         -->
         <filter class="solr.StopFilterFactory"
                 ignoreCase="true"
-                words="stopwords_en.txt"
+                words="lang/stopwords_en.txt"
                 enablePositionIncrements="true"
                 />
         <filter class="solr.LowerCaseFilterFactory"/>
@@ -250,7 +250,7 @@
         <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
         <filter class="solr.StopFilterFactory"
                 ignoreCase="true"
-                words="stopwords_en.txt"
+                words="lang/stopwords_en.txt"
                 enablePositionIncrements="true"
                 />
         <filter class="solr.LowerCaseFilterFactory"/>
@@ -287,7 +287,7 @@
         -->
         <filter class="solr.StopFilterFactory"
                 ignoreCase="true"
-                words="stopwords_en.txt"
+                words="lang/stopwords_en.txt"
                 enablePositionIncrements="true"
                 />
         <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" splitOnCaseChange="1"/>
@@ -300,7 +300,7 @@
         <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
         <filter class="solr.StopFilterFactory"
                 ignoreCase="true"
-                words="stopwords_en.txt"
+                words="lang/stopwords_en.txt"
                 enablePositionIncrements="true"
                 />
         <filter class="solr.WordDelimiterFilterFactory" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" splitOnCaseChange="1"/>
@@ -316,7 +316,7 @@
       <analyzer>
         <tokenizer class="solr.WhitespaceTokenizerFactory"/>
         <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="false"/>
-        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords_en.txt"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_en.txt"/>
         <filter class="solr.WordDelimiterFilterFactory" generateWordParts="0" generateNumberParts="0" catenateWords="1" catenateNumbers="1" catenateAll="0"/>
         <filter class="solr.LowerCaseFilterFactory"/>
         <filter class="solr.KeywordMarkerFilterFactory" protected="protwords.txt"/>
@@ -454,6 +454,323 @@
    -->
     <fieldtype name="geohash" class="solr.GeoHashField"/>
 
+   <!-- some examples for different languages (generally ordered by ISO code) -->
+
+    <!-- Arabic -->
+    <fieldType name="text_ar" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- for any non-arabic -->
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_ar.txt" enablePositionIncrements="true"/>
+        <!-- normalizes Ôª? to Ôª?, etc -->
+        <filter class="solr.ArabicNormalizationFilterFactory"/>
+        <filter class="solr.ArabicStemFilterFactory"/>
+      </analyzer>
+    </fieldType>
+
+    <!-- Bulgarian -->
+    <fieldType name="text_bg" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/> 
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_bg.txt" enablePositionIncrements="true"/>
+        <filter class="solr.BulgarianStemFilterFactory"/>       
+      </analyzer>
+    </fieldType>
+    
+    <!-- Catalan -->
+    <fieldType name="text_ca" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- removes l', etc -->
+        <filter class="solr.ElisionFilterFactory" ignoreCase="true" articles="lang/contractions_ca.txt"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_ca.txt" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Catalan"/>       
+      </analyzer>
+    </fieldType>
+    
+    <!-- CJK bigram (see text_ja for an alternative Japanese configuration) -->
+    <fieldType name="text_cjk" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- normalize width before bigram, as e.g. half-width dakuten combine  -->
+        <filter class="solr.CJKWidthFilterFactory"/>
+        <!-- for any non-CJK -->
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.CJKBigramFilterFactory"/>     
+      </analyzer>
+    </fieldType>
+
+    <!-- Czech -->
+    <fieldType name="text_cz" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_cz.txt" enablePositionIncrements="true"/>
+        <filter class="solr.CzechStemFilterFactory"/>       
+      </analyzer>
+    </fieldType>
+    
+    <!-- Danish -->
+    <fieldType name="text_da" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_da.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Danish"/>       
+      </analyzer>
+    </fieldType>
+    
+    <!-- German -->
+    <fieldType name="text_de" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_de.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.GermanNormalizationFilterFactory"/>
+        <filter class="solr.GermanLightStemFilterFactory"/>
+        <!-- less aggressive: <filter class="solr.GermanMinimalStemFilterFactory"/> -->
+        <!-- more aggressive: <filter class="solr.SnowballPorterFilterFactory" language="German2"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Greek -->
+    <fieldType name="text_el" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- greek specific lowercase for sigma -->
+        <filter class="solr.GreekLowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="false" words="lang/stopwords_el.txt" enablePositionIncrements="true"/>
+        <filter class="solr.GreekStemFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Spanish -->
+    <fieldType name="text_es" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_es.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SpanishLightStemFilterFactory"/>
+        <!-- more aggressive: <filter class="solr.SnowballPorterFilterFactory" language="Spanish"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Basque -->
+    <fieldType name="text_eu" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_eu.txt" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Basque"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Persian -->
+    <fieldType name="text_fa" class="solr.TextField" positionIncrementGap="100">
+      <analyzer>
+        <!-- for ZWNJ -->
+        <charFilter class="solr.PersianCharFilterFactory"/>
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.ArabicNormalizationFilterFactory"/>
+        <filter class="solr.PersianNormalizationFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_fa.txt" enablePositionIncrements="true"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Finnish -->
+    <fieldType name="text_fi" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_fi.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Finnish"/>
+        <!-- less aggressive: <filter class="solr.FinnishLightStemFilterFactory"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- French -->
+    <fieldType name="text_fr" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- removes l', etc -->
+        <filter class="solr.ElisionFilterFactory" ignoreCase="true" articles="lang/contractions_fr.txt"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_fr.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.FrenchLightStemFilterFactory"/>
+        <!-- less aggressive: <filter class="solr.FrenchMinimalStemFilterFactory"/> -->
+        <!-- more aggressive: <filter class="solr.SnowballPorterFilterFactory" language="French"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Galician -->
+    <fieldType name="text_gl" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_gl.txt" enablePositionIncrements="true"/>
+        <filter class="solr.GalicianStemFilterFactory"/>
+        <!-- less aggressive: <filter class="solr.GalicianMinimalStemFilterFactory"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Hindi -->
+    <fieldType name="text_hi" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <!-- normalizes unicode representation -->
+        <filter class="solr.IndicNormalizationFilterFactory"/>
+        <!-- normalizes variation in spelling -->
+        <filter class="solr.HindiNormalizationFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_hi.txt" enablePositionIncrements="true"/>
+        <filter class="solr.HindiStemFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Hungarian -->
+    <fieldType name="text_hu" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_hu.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Hungarian"/>
+        <!-- less aggressive: <filter class="solr.HungarianLightStemFilterFactory"/> -->   
+      </analyzer>
+    </fieldType>
+    
+    <!-- Armenian -->
+    <fieldType name="text_hy" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_hy.txt" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Armenian"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Indonesian -->
+    <fieldType name="text_id" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_id.txt" enablePositionIncrements="true"/>
+        <!-- for a less aggressive approach (only inflectional suffixes), set stemDerivational to false -->
+        <filter class="solr.IndonesianStemFilterFactory" stemDerivational="true"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Italian -->
+    <fieldType name="text_it" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <!-- removes l', etc -->
+        <filter class="solr.ElisionFilterFactory" ignoreCase="true" articles="lang/contractions_it.txt"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_it.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.ItalianLightStemFilterFactory"/>
+        <!-- more aggressive: <filter class="solr.SnowballPorterFilterFactory" language="Italian"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Latvian -->
+    <fieldType name="text_lv" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_lv.txt" enablePositionIncrements="true"/>
+        <filter class="solr.LatvianStemFilterFactory"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Dutch -->
+    <fieldType name="text_nl" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_nl.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.StemmerOverrideFilterFactory" dictionary="lang/stemdict_nl.txt" ignoreCase="false"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Dutch"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Norwegian -->
+    <fieldType name="text_no" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_no.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Norwegian"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Portuguese -->
+    <fieldType name="text_pt" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_pt.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.PortugueseLightStemFilterFactory"/>
+        <!-- less aggressive: <filter class="solr.PortugueseMinimalStemFilterFactory"/> -->
+        <!-- more aggressive: <filter class="solr.SnowballPorterFilterFactory" language="Portuguese"/> -->
+        <!-- most aggressive: <filter class="solr.PortugueseStemFilterFactory"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Romanian -->
+    <fieldType name="text_ro" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_ro.txt" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Romanian"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Russian -->
+    <fieldType name="text_ru" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_ru.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Russian"/>
+        <!-- less aggressive: <filter class="solr.RussianLightStemFilterFactory"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Swedish -->
+    <fieldType name="text_sv" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_sv.txt" format="snowball" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Swedish"/>
+        <!-- less aggressive: <filter class="solr.SwedishLightStemFilterFactory"/> -->
+      </analyzer>
+    </fieldType>
+    
+    <!-- Thai -->
+    <fieldType name="text_th" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.LowerCaseFilterFactory"/>
+        <filter class="solr.ThaiWordFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="true" words="lang/stopwords_th.txt" enablePositionIncrements="true"/>
+      </analyzer>
+    </fieldType>
+    
+    <!-- Turkish -->
+    <fieldType name="text_tr" class="solr.TextField" positionIncrementGap="100">
+      <analyzer> 
+        <tokenizer class="solr.StandardTokenizerFactory"/>
+        <filter class="solr.TurkishLowerCaseFilterFactory"/>
+        <filter class="solr.StopFilterFactory" ignoreCase="false" words="lang/stopwords_tr.txt" enablePositionIncrements="true"/>
+        <filter class="solr.SnowballPorterFilterFactory" language="Turkish"/>
+      </analyzer>
+    </fieldType>
  </types>
 
 
diff --git a/solr/example/solr/conf/stopwords_en.txt b/solr/example/solr/conf/stopwords_en.txt
deleted file mode 100644
index 2c164c0..0000000
--- a/solr/example/solr/conf/stopwords_en.txt
+++ /dev/null
@@ -1,54 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-# a couple of test stopwords to test that the words are really being
-# configured from this file:
-stopworda
-stopwordb
-
-# Standard english stop words taken from Lucene's StopAnalyzer
-a
-an
-and
-are
-as
-at
-be
-but
-by
-for
-if
-in
-into
-is
-it
-no
-not
-of
-on
-or
-such
-that
-the
-their
-then
-there
-these
-they
-this
-to
-was
-will
-with

