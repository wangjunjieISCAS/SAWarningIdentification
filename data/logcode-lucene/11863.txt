GitDiffStart: e003b49cabe9bf024c33d7cd95cc6e42bdfc37fd | Tue Jul 17 10:53:28 2012 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 1498e94..0d4bcfc 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -42,6 +42,10 @@ API Changes
   reusing the object. But the name was often confused with TokenStream.reset().
   (Robert Muir)
 
+* LUCENE-4228: Refactored CharFilter to extend java.io.FilterReader. CharFilters
+  filter another reader and you override correct() for offset correction.
+  (Robert Muir)
+
 Optimizations
 
 * LUCENE-4171: Performance improvements to Packed64.
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
index 3eb4ee7..1a96076 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/BaseCharFilter.java
@@ -17,9 +17,10 @@
 
 package org.apache.lucene.analysis.charfilter;
 
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.util.ArrayUtil;
 
+import java.io.Reader;
 import java.util.Arrays;
 
 /**
@@ -34,7 +35,7 @@ public abstract class BaseCharFilter extends CharFilter {
   private int diffs[];
   private int size = 0;
   
-  public BaseCharFilter(CharStream in) {
+  public BaseCharFilter(Reader in) {
     super(in);
   }
 
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/CharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/CharFilter.java
deleted file mode 100644
index f71e1cb..0000000
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/CharFilter.java
+++ /dev/null
@@ -1,82 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis.charfilter;
-
-import java.io.IOException;
-
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.Tokenizer;
-
-/**
- * Subclasses of CharFilter can be chained to filter CharStream.
- * They can be used as {@link java.io.Reader} with additional offset
- * correction. {@link Tokenizer}s will automatically use {@link #correctOffset}
- * if a CharFilter/CharStream subclass is used.
- */
-public abstract class CharFilter extends CharStream {
-
-  protected CharStream input;
-
-  protected CharFilter(CharStream in) {
-    input = in;
-  }
-
-  /**
-   * Subclass may want to override to correct the current offset.
-   *
-   * @param currentOff current offset
-   * @return corrected offset
-   */
-  protected int correct(int currentOff) {
-    return currentOff;
-  }
-
-  /**
-   * Chains the corrected offset through the input
-   * CharFilter.
-   */
-  @Override
-  public final int correctOffset(int currentOff) {
-    return input.correctOffset(correct(currentOff));
-  }
-
-  @Override
-  public void close() throws IOException {
-    input.close();
-  }
-
-  @Override
-  public int read(char[] cbuf, int off, int len) throws IOException {
-    return input.read(cbuf, off, len);
-  }
-
-  @Override
-  public boolean markSupported(){
-    return input.markSupported();
-  }
-
-  @Override
-  public void mark( int readAheadLimit ) throws IOException {
-    input.mark(readAheadLimit);
-  }
-
-  @Override
-  public void reset() throws IOException {
-    input.reset();
-  }
-}
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
index fabd33c..4cfc117 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.java
@@ -1,4 +1,4 @@
-/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 5/18/12 12:24 PM */
+/* The following code was generated by JFlex 1.5.0-SNAPSHOT on 7/16/12 4:05 PM */
 
 package org.apache.lucene.analysis.charfilter;
 
@@ -20,13 +20,13 @@ package org.apache.lucene.analysis.charfilter;
  */
 
 import java.io.IOException;
+import java.io.Reader;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.util.Version;
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.util.CharArrayMap;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.OpenStringBuilder;
@@ -40,8 +40,8 @@ import org.apache.lucene.analysis.util.OpenStringBuilder;
 /**
  * This class is a scanner generated by 
  * <a href="http://www.jflex.de/">JFlex</a> 1.5.0-SNAPSHOT
- * on 5/18/12 12:24 PM from the specification file
- * <tt>C:/svn/lucene/dev/trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex</tt>
+ * on 7/16/12 4:05 PM from the specification file
+ * <tt>/home/rmuir/workspace/lucene-trunk/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex</tt>
  */
 public final class HTMLStripCharFilter extends BaseCharFilter {
 
@@ -30647,7 +30647,7 @@ public final class HTMLStripCharFilter extends BaseCharFilter {
   /**
    * @param source
    */
-  public HTMLStripCharFilter(CharStream source) {
+  public HTMLStripCharFilter(Reader source) {
     super(source);
     this.zzReader = source;
   }
@@ -30657,7 +30657,7 @@ public final class HTMLStripCharFilter extends BaseCharFilter {
    * @param escapedTags Tags in this set (both start and end tags)
    *  will not be filtered out.
    */
-  public HTMLStripCharFilter(CharStream source, Set<String> escapedTags) {
+  public HTMLStripCharFilter(Reader source, Set<String> escapedTags) {
     super(source);
     this.zzReader = source;
     if (null != escapedTags) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
index 3e384b1..3cd2526 100755
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/HTMLStripCharFilter.jflex
@@ -18,13 +18,13 @@ package org.apache.lucene.analysis.charfilter;
  */
 
 import java.io.IOException;
+import java.io.Reader;
 import java.util.Arrays;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Set;
 
 import org.apache.lucene.util.Version;
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.util.CharArrayMap;
 import org.apache.lucene.analysis.util.CharArraySet;
 import org.apache.lucene.analysis.util.OpenStringBuilder;
@@ -173,7 +173,7 @@ InlineElment = ( [aAbBiIqQsSuU]                   |
   /**
    * @param source
    */
-  public HTMLStripCharFilter(CharStream source) {
+  public HTMLStripCharFilter(Reader source) {
     super(source);
     this.zzReader = source;
   }
@@ -183,7 +183,7 @@ InlineElment = ( [aAbBiIqQsSuU]                   |
    * @param escapedTags Tags in this set (both start and end tags)
    *  will not be filtered out.
    */
-  public HTMLStripCharFilter(CharStream source, Set<String> escapedTags) {
+  public HTMLStripCharFilter(Reader source, Set<String> escapedTags) {
     super(source);
     this.zzReader = source;
     if (null != escapedTags) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilter.java
index 39061e2..ca59e79 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/charfilter/MappingCharFilter.java
@@ -21,8 +21,7 @@ import java.io.IOException;
 import java.io.Reader;
 import java.util.Map;
 
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter; // javadocs
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.RollingCharBuffer;
 import org.apache.lucene.util.fst.CharSequenceOutputs;
@@ -51,8 +50,8 @@ public class MappingCharFilter extends BaseCharFilter {
   private int replacementPointer;
   private int inputOff;
 
-  /** Default constructor that takes a {@link CharStream}. */
-  public MappingCharFilter(NormalizeCharMap normMap, CharStream in) {
+  /** Default constructor that takes a {@link Reader}. */
+  public MappingCharFilter(NormalizeCharMap normMap, Reader in) {
     super(in);
     buffer.reset(in);
 
@@ -66,15 +65,10 @@ public class MappingCharFilter extends BaseCharFilter {
     }
   }
 
-  /** Easy-use constructor that takes a {@link Reader}. */
-  public MappingCharFilter(NormalizeCharMap normMap, Reader in) {
-    this(normMap, CharReader.get(in));
-  }
-
   @Override
   public void reset() throws IOException {
     super.reset();
-    buffer.reset(input);
+    buffer.reset(in);
     replacement = null;
     inputOff = 0;
   }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
index eff8eac..cfac094 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianAnalyzer.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 import java.io.Reader;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.ar.ArabicNormalizationFilter;
@@ -134,6 +133,6 @@ public final class PersianAnalyzer extends StopwordAnalyzerBase {
    */
   @Override
   protected Reader initReader(String fieldName, Reader reader) {
-    return new PersianCharFilter(CharReader.get(reader)); 
+    return new PersianCharFilter(reader); 
   }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
index cf3a820..20e66b0 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/fa/PersianCharFilter.java
@@ -18,9 +18,9 @@ package org.apache.lucene.analysis.fa;
  */
 
 import java.io.IOException;
+import java.io.Reader;
 
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.charfilter.CharFilter;
+import org.apache.lucene.analysis.CharFilter;
 
 /**
  * CharFilter that replaces instances of Zero-width non-joiner with an
@@ -28,7 +28,7 @@ import org.apache.lucene.analysis.charfilter.CharFilter;
  */
 public class PersianCharFilter extends CharFilter {
 
-  public PersianCharFilter(CharStream in) {
+  public PersianCharFilter(Reader in) {
     super(in);
   }
   
@@ -45,4 +45,9 @@ public class PersianCharFilter extends CharFilter {
     }
     return charsRead;
   }
+
+  @Override
+  protected int correct(int currentOff) {
+    return currentOff; // we don't change the length of the string
+  }
 }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java
index da20c9b..0c5ff2a 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternReplaceCharFilter.java
@@ -23,7 +23,6 @@ import java.io.StringReader;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.charfilter.BaseCharFilter;
 
 /**
@@ -54,7 +53,7 @@ public class PatternReplaceCharFilter extends BaseCharFilter {
   private final String replacement;
   private Reader transformedInput;
 
-  public PatternReplaceCharFilter(Pattern pattern, String replacement, CharStream in) {
+  public PatternReplaceCharFilter(Pattern pattern, String replacement, Reader in) {
     super(in);
     this.pattern = pattern;
     this.replacement = replacement;
@@ -64,16 +63,29 @@ public class PatternReplaceCharFilter extends BaseCharFilter {
   public int read(char[] cbuf, int off, int len) throws IOException {
     // Buffer all input on the first call.
     if (transformedInput == null) {
-      StringBuilder buffered = new StringBuilder();
-      char [] temp = new char [1024];
-      for (int cnt = input.read(temp); cnt > 0; cnt = input.read(temp)) {
-        buffered.append(temp, 0, cnt);
-      }
-      transformedInput = new StringReader(processPattern(buffered).toString());
+      fill();
     }
 
     return transformedInput.read(cbuf, off, len);
   }
+  
+  private void fill() throws IOException {
+    StringBuilder buffered = new StringBuilder();
+    char [] temp = new char [1024];
+    for (int cnt = in.read(temp); cnt > 0; cnt = in.read(temp)) {
+      buffered.append(temp, 0, cnt);
+    }
+    transformedInput = new StringReader(processPattern(buffered).toString());
+  }
+
+  @Override
+  public int read() throws IOException {
+    if (transformedInput == null) {
+      fill();
+    }
+    
+    return transformedInput.read();
+  }
 
   @Override
   protected int correct(int currentOff) {
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
index 9901aef..3a7f1df 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/ClassicAnalyzer.java
@@ -114,9 +114,9 @@ public final class ClassicAnalyzer extends StopwordAnalyzerBase {
     tok = new StopFilter(matchVersion, tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void reset(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) throws IOException {
         src.setMaxTokenLength(ClassicAnalyzer.this.maxTokenLength);
-        super.reset(reader);
+        super.setReader(reader);
       }
     };
   }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
index fdec88a..18c791e 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/StandardAnalyzer.java
@@ -115,9 +115,9 @@ public final class StandardAnalyzer extends StopwordAnalyzerBase {
     tok = new StopFilter(matchVersion, tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void reset(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) throws IOException {
         src.setMaxTokenLength(StandardAnalyzer.this.maxTokenLength);
-        super.reset(reader);
+        super.setReader(reader);
       }
     };
   }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java
index 8b8f494..a9c2bbd 100755
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/standard/UAX29URLEmailAnalyzer.java
@@ -104,9 +104,9 @@ public final class UAX29URLEmailAnalyzer extends StopwordAnalyzerBase {
     tok = new StopFilter(matchVersion, tok, stopwords);
     return new TokenStreamComponents(src, tok) {
       @Override
-      protected void reset(final Reader reader) throws IOException {
+      protected void setReader(final Reader reader) throws IOException {
         src.setMaxTokenLength(UAX29URLEmailAnalyzer.this.maxTokenLength);
-        super.reset(reader);
+        super.setReader(reader);
       }
     };
   }
diff --git a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharFilterFactory.java b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharFilterFactory.java
index 82c830e..449c875 100644
--- a/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharFilterFactory.java
+++ b/lucene/analysis/common/src/java/org/apache/lucene/analysis/util/CharFilterFactory.java
@@ -17,13 +17,15 @@ package org.apache.lucene.analysis.util;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.CharFilter;
 
 /**
- * Abstract parent class for analysis factories that create {@link CharStream}
+ * Abstract parent class for analysis factories that create {@link CharFilter}
  * instances.
  */
 public abstract class CharFilterFactory extends AbstractAnalysisFactory {
 
-  public abstract CharStream create(CharStream input);
+  public abstract CharFilter create(Reader input);
 }
diff --git a/lucene/analysis/common/src/java/overview.html b/lucene/analysis/common/src/java/overview.html
index eae0c5f..a251be2 100644
--- a/lucene/analysis/common/src/java/overview.html
+++ b/lucene/analysis/common/src/java/overview.html
@@ -24,7 +24,7 @@
     For an introduction to Lucene's analysis API, see the {@link org.apache.lucene.analysis} package documentation.
     </p>
     <p>
-    This module contains concrete components ({@link org.apache.lucene.analysis.charfilter.CharFilter}s,
+    This module contains concrete components ({@link org.apache.lucene.analysis.CharFilter}s,
     {@link org.apache.lucene.analysis.Tokenizer}s, and ({@link org.apache.lucene.analysis.TokenFilter}s) for 
     analyzing different types of content. It also provides a number of {@link org.apache.lucene.analysis.Analyzer}s
     for different languages that you can use to get started quickly. 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
index 038d375..5fd64e0 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/HTMLStripCharFilterTest.java
@@ -29,7 +29,6 @@ import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.util._TestUtil;
@@ -46,7 +45,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new HTMLStripCharFilter(CharReader.get(reader));
+        return new HTMLStripCharFilter(reader);
       }
     };
   }
@@ -60,7 +59,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "\nthis is some text\n here is a link and " +
             "another link. " +
             "This is an entity: & plus a <.  Here is an &. ";
-    HTMLStripCharFilter reader = new HTMLStripCharFilter(CharReader.get(new StringReader(html)));
+    HTMLStripCharFilter reader = new HTMLStripCharFilter(new StringReader(html));
     StringBuilder builder = new StringBuilder();
     int ch = -1;
     char [] goldArray = gold.toCharArray();
@@ -79,7 +78,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   //Some sanity checks, but not a full-fledged check
   public void testHTML() throws Exception {
     InputStream stream = getClass().getResourceAsStream("htmlStripReaderTest.html");
-    HTMLStripCharFilter reader = new HTMLStripCharFilter(CharReader.get(new InputStreamReader(stream, "UTF-8")));
+    HTMLStripCharFilter reader = new HTMLStripCharFilter(new InputStreamReader(stream, "UTF-8"));
     StringBuilder builder = new StringBuilder();
     int ch = -1;
     while ((ch = reader.read()) != -1){
@@ -96,7 +95,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   public void testMSWord14GeneratedHTML() throws Exception {
     InputStream stream = getClass().getResourceAsStream("MS-Word 14 generated.htm");
-    HTMLStripCharFilter reader = new HTMLStripCharFilter(CharReader.get(new InputStreamReader(stream, "UTF-8")));
+    HTMLStripCharFilter reader = new HTMLStripCharFilter(new InputStreamReader(stream, "UTF-8"));
     String gold = "This is a test";
     StringBuilder builder = new StringBuilder();
     int ch = 0;
@@ -117,7 +116,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "\u0393";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new HTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -132,7 +131,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "  <foo> \u00DCbermensch = \u0393 bar \u0393";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new HTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -147,7 +146,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "  <junk/>   ! @ and ??";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new HTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -161,7 +160,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String test = "aaa bbb <reserved ccc=\"ddddd\"> eeee </reserved> ffff <reserved ggg=\"hhhh\"/> <other/>";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new HTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -346,7 +345,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     for (int i = 0 ; i < testGold.length ; i += 2) {
       String test = testGold[i];
       String gold = testGold[i + 1];
-      Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+      Reader reader = new HTMLStripCharFilter(new StringReader(test));
       StringBuilder builder = new StringBuilder();
       int ch = 0;
       while ((ch = reader.read()) != -1){
@@ -370,7 +369,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     testBuilder.append("-->foo");
     String gold = "foo";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(testBuilder.toString())));
+    Reader reader = new HTMLStripCharFilter(new StringReader(testBuilder.toString()));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -388,7 +387,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     appendChars(testBuilder, HTMLStripCharFilter.getInitialBufferSize() + 500);
     testBuilder.append("?>");
     gold = "";
-    reader = new HTMLStripCharFilter(CharReader.get(new StringReader(testBuilder.toString())));
+    reader = new HTMLStripCharFilter(new StringReader(testBuilder.toString()));
     ch = 0;
     builder = new StringBuilder();
     try {
@@ -406,7 +405,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     appendChars(testBuilder, HTMLStripCharFilter.getInitialBufferSize() + 500);
     testBuilder.append("/>");
     gold = "";
-    reader = new HTMLStripCharFilter(CharReader.get(new StringReader(testBuilder.toString())));
+    reader = new HTMLStripCharFilter(new StringReader(testBuilder.toString()));
     ch = 0;
     builder = new StringBuilder();
     try {
@@ -430,7 +429,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   private void processBuffer(String test, String assertMsg) throws IOException {
     // System.out.println("-------------------processBuffer----------");
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(test))));//force the use of BufferedReader
+    Reader reader = new HTMLStripCharFilter(new BufferedReader(new StringReader(test)));//force the use of BufferedReader
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -448,7 +447,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     String test = "<!--- three dashes, still a valid comment ---> ";
     String gold = " ";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(test))));//force the use of BufferedReader
+    Reader reader = new HTMLStripCharFilter(new BufferedReader(new StringReader(test)));//force the use of BufferedReader
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -464,7 +463,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
 
   public void doTestOffsets(String in) throws Exception {
-    HTMLStripCharFilter reader = new HTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(in))));
+    HTMLStripCharFilter reader = new HTMLStripCharFilter(new BufferedReader(new StringReader(in)));
     int ch = 0;
     int off = 0;     // offset in the reader
     int strOff = -1; // offset in the original string
@@ -491,7 +490,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   static void assertLegalOffsets(String in) throws Exception {
     int length = in.length();
-    HTMLStripCharFilter reader = new HTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(in))));
+    HTMLStripCharFilter reader = new HTMLStripCharFilter(new BufferedReader(new StringReader(in)));
     int ch = 0;
     int off = 0;
     while ((ch = reader.read()) != -1) {
@@ -526,7 +525,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
         + " alt =  \"Alt: <!--#echo var='${IMAGE_CAPTION:<!--comment-->\\'Comment\\'}'  -->\"\n\n"
         + " title=\"Title: <!--#echo var=\"IMAGE_CAPTION\"-->\">two";
     String gold = "onetwo";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -540,7 +539,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     test = "one<script><!-- <!--#config comment=\"<!-- \\\"comment\\\"-->\"--> --></script>two";
     gold = "one\ntwo";
-    reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    reader = new HTMLStripCharFilter(new StringReader(test));
     ch = 0;
     builder = new StringBuilder();
     try {
@@ -557,7 +556,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testScriptQuotes() throws Exception {
     String test = "one<script attr= bare><!-- action('<!-- comment -->', \"\\\"-->\\\"\"); --></script>two";
     String gold = "one\ntwo";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -572,7 +571,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     test = "hello<script><!-- f('<!--internal--></script>'); --></script>";
     gold = "hello\n";
-    reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    reader = new HTMLStripCharFilter(new StringReader(test));
     ch = 0;
     builder = new StringBuilder();
     try {
@@ -591,7 +590,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "one<script no-value-attr></script>two";
     Set<String> escapedTags = new HashSet<String>(Arrays.asList("SCRIPT"));
     Reader reader = new HTMLStripCharFilter
-        (CharReader.get(new StringReader(test)), escapedTags);
+        (new StringReader(test), escapedTags);
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -612,7 +611,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
                 + "-->\n"
                 + "</style>two";
     String gold = "one\ntwo";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -631,7 +630,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "one<style type=\"text/css\"></style>two";
     Set<String> escapedTags = new HashSet<String>(Arrays.asList("STYLE"));
     Reader reader = new HTMLStripCharFilter
-        (CharReader.get(new StringReader(test)), escapedTags);
+        (new StringReader(test), escapedTags);
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -656,7 +655,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     for (int i = 0 ; i < testGold.length ; i += 2) {
       String test = testGold[i];
       String gold = testGold[i + 1];
-      Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+      Reader reader = new HTMLStripCharFilter(new StringReader(test));
       StringBuilder builder = new StringBuilder();
       int ch = 0;
       while ((ch = reader.read()) != -1){
@@ -671,7 +670,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "one<BR class='whatever'>two</\nBR\n>";
     Set<String> escapedTags = new HashSet<String>(Arrays.asList("BR"));
     Reader reader = new HTMLStripCharFilter
-        (CharReader.get(new StringReader(test)), escapedTags);
+        (new StringReader(test), escapedTags);
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -688,7 +687,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testInlineTagsNoSpace() throws Exception {
     String test = "one<sPAn class=\"invisible\">two<sup>2<sup>e</sup></sup>.</SpaN>three";
     String gold = "onetwo2e.three";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -705,7 +704,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testCDATA() throws Exception {
     String test = "one<![CDATA[<one><two>three<four></four></two></one>]]>two";
     String gold = "one<one><two>three<four></four></two></one>two";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -720,7 +719,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     test = "one<![CDATA[two<![CDATA[three]]]]><![CDATA[>four]]>five";
     gold = "onetwo<![CDATA[three]]>fourfive";
-    reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    reader = new HTMLStripCharFilter(new StringReader(test));
     ch = 0;
     builder = new StringBuilder();
     try {
@@ -737,7 +736,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testUppercaseCharacterEntityVariants() throws Exception {
     String test = " &QUOT;-&COPY;&GT;>&LT;<&REG;&AMP;";
     String gold = " \"-\u00A9>><<\u00AE&";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -754,7 +753,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testMSWordMalformedProcessingInstruction() throws Exception {
     String test = "one<?xml:namespace prefix = o ns = \"urn:schemas-microsoft-com:office:office\" />two";
     String gold = "onetwo";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -771,7 +770,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testSupplementaryCharsInTags() throws Exception {
     String test = "one<ð©??±é??¹æ???>two<???ð©?>three ???ð©?</???ð©?>four</ð©??±é??¹æ???>five<??????>six<??????/>seven";
     String gold = "one\ntwo\nthree ???ð©?\nfour\nfive\nsix\nseven";
-    Reader reader = new HTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new HTMLStripCharFilter(new StringReader(test));
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -822,7 +821,7 @@ public class HTMLStripCharFilterTest extends BaseTokenStreamTestCase {
       }
     }
     Reader reader = new HTMLStripCharFilter
-        (CharReader.get(new StringReader(text.toString())));
+        (new StringReader(text.toString()));
     while (reader.read() != -1);
   }
 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestCharFilter.java
deleted file mode 100644
index df7efff..0000000
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestCharFilter.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis.charfilter;
-
-import java.io.StringReader;
-
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.charfilter.CharFilter;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestCharFilter extends LuceneTestCase {
-
-  public void testCharFilter1() throws Exception {
-    CharStream cs = new CharFilter1( CharReader.get( new StringReader("") ) );
-    assertEquals( "corrected offset is invalid", 1, cs.correctOffset( 0 ) );
-  }
-
-  public void testCharFilter2() throws Exception {
-    CharStream cs = new CharFilter2( CharReader.get( new StringReader("") ) );
-    assertEquals( "corrected offset is invalid", 2, cs.correctOffset( 0 ) );
-  }
-
-  public void testCharFilter12() throws Exception {
-    CharStream cs = new CharFilter2( new CharFilter1( CharReader.get( new StringReader("") ) ) );
-    assertEquals( "corrected offset is invalid", 3, cs.correctOffset( 0 ) );
-  }
-
-  public void testCharFilter11() throws Exception {
-    CharStream cs = new CharFilter1( new CharFilter1( CharReader.get( new StringReader("") ) ) );
-    assertEquals( "corrected offset is invalid", 2, cs.correctOffset( 0 ) );
-  }
-
-  static class CharFilter1 extends CharFilter {
-
-    protected CharFilter1(CharStream in) {
-      super(in);
-    }
-
-    @Override
-    protected int correct(int currentOff) {
-      return currentOff + 1;
-    }
-  }
-
-  static class CharFilter2 extends CharFilter {
-
-    protected CharFilter2(CharStream in) {
-      super(in);
-    }
-
-    @Override
-    protected int correct(int currentOff) {
-      return currentOff + 2;
-    }
-  }
-}
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
index 88d786b..c4fab55 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/charfilter/TestMappingCharFilter.java
@@ -29,8 +29,7 @@ import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -60,7 +59,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
   }
 
   public void testReaderReset() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "x" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "x" ) );
     char[] buf = new char[10];
     int len = cs.read(buf, 0, 10);
     assertEquals( 1, len );
@@ -76,55 +75,55 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
   }
 
   public void testNothingChange() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "x" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "x" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"x"}, new int[]{0}, new int[]{1}, 1);
   }
 
   public void test1to1() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "h" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "h" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"i"}, new int[]{0}, new int[]{1}, 1);
   }
 
   public void test1to2() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "j" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "j" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"jj"}, new int[]{0}, new int[]{1}, 1);
   }
 
   public void test1to3() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "k" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "k" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"kkk"}, new int[]{0}, new int[]{1}, 1);
   }
 
   public void test2to4() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "ll" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "ll" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"llll"}, new int[]{0}, new int[]{2}, 2);
   }
 
   public void test2to1() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "aa" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "aa" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"a"}, new int[]{0}, new int[]{2}, 2);
   }
 
   public void test3to1() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "bbb" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "bbb" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"b"}, new int[]{0}, new int[]{3}, 3);
   }
 
   public void test4to2() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "cccc" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "cccc" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[]{"cc"}, new int[]{0}, new int[]{4}, 4);
   }
 
   public void test5to0() throws Exception {
-    CharStream cs = new MappingCharFilter( normMap, new StringReader( "empty" ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( "empty" ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[0], new int[]{}, new int[]{}, 5);
   }
@@ -149,7 +148,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
   //
   public void testTokenStream() throws Exception {
     String testString = "h i j k ll cccc bbb aa";
-    CharStream cs = new MappingCharFilter( normMap, CharReader.get( new StringReader( testString ) ) );
+    CharFilter cs = new MappingCharFilter( normMap, new StringReader( testString ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
       new String[]{"i","i","jj","kkk","llll","cc","b","a"},
@@ -171,8 +170,8 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
   //    h,8,9 => i,8,9
   public void testChained() throws Exception {
     String testString = "aaaa ll h";
-    CharStream cs = new MappingCharFilter( normMap,
-        new MappingCharFilter( normMap, CharReader.get( new StringReader( testString ) ) ) );
+    CharFilter cs = new MappingCharFilter( normMap,
+        new MappingCharFilter( normMap, new StringReader( testString ) ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
       new String[]{"a","llllllll","i"},
@@ -193,7 +192,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MappingCharFilter(normMap, CharReader.get(reader));
+        return new MappingCharFilter(normMap, reader);
       }
     };
     
@@ -219,7 +218,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MappingCharFilter(map, CharReader.get(reader));
+        return new MappingCharFilter(map, reader);
       }
     };
     
@@ -241,7 +240,7 @@ public class TestMappingCharFilter extends BaseTokenStreamTestCase {
 
         @Override
         protected Reader initReader(String fieldName, Reader reader) {
-          return new MappingCharFilter(map, CharReader.get(reader));
+          return new MappingCharFilter(map, reader);
         }
       };
       int numRounds = 100;
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
index 3be69e6..549f819 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/cjk/TestCJKAnalyzer.java
@@ -23,7 +23,6 @@ import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -216,7 +215,7 @@ public class TestCJKAnalyzer extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MappingCharFilter(norm, CharReader.get(reader));
+        return new MappingCharFilter(norm, reader);
       }
     };
     
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
index a0fe4fc..fa06c3d 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/compound/TestCompoundWordTokenFilter.java
@@ -24,7 +24,6 @@ import java.util.Arrays;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenFilter;
 import org.apache.lucene.analysis.TokenStream;
@@ -327,7 +326,7 @@ public class TestCompoundWordTokenFilter extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MappingCharFilter(normMap, CharReader.get(reader));
+        return new MappingCharFilter(normMap, reader);
       }
     };
 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
index 1019e88..d0e6d80 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestBugInSomething.java
@@ -1,11 +1,12 @@
 package org.apache.lucene.analysis.core;
 
 import java.io.Reader;
+import java.io.StringReader;
 import java.nio.CharBuffer;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockCharFilter;
 import org.apache.lucene.analysis.MockTokenFilter;
 import org.apache.lucene.analysis.MockTokenizer;
@@ -64,7 +65,7 @@ public class TestBugInSomething extends BaseTokenStreamTestCase {
     checkAnalysisConsistency(random(), a, false, "wmgddzunizdomqyj");
   }
   
-  CharStream wrappedStream = new CharStream() {
+  CharFilter wrappedStream = new CharFilter(new StringReader("bogus")) {
 
     @Override
     public void mark(int readAheadLimit) {
@@ -107,8 +108,8 @@ public class TestBugInSomething extends BaseTokenStreamTestCase {
     }
 
     @Override
-    public int correctOffset(int currentOff) {
-      throw new UnsupportedOperationException("correctOffset(int)");
+    public int correct(int currentOff) {
+      throw new UnsupportedOperationException("correct(int)");
     }
 
     @Override
@@ -123,7 +124,7 @@ public class TestBugInSomething extends BaseTokenStreamTestCase {
   };
   
   public void testWrapping() throws Exception {
-    CharStream cs = new TestRandomChains.CheckThatYouDidntReadAnythingReaderWrapper(wrappedStream);
+    CharFilter cs = new TestRandomChains.CheckThatYouDidntReadAnythingReaderWrapper(wrappedStream);
     try {
       cs.mark(1);
       fail();
@@ -177,7 +178,7 @@ public class TestBugInSomething extends BaseTokenStreamTestCase {
       cs.correctOffset(1);
       fail();
     } catch (Exception e) {
-      assertEquals("correctOffset(int)", e.getMessage());
+      assertEquals("correct(int)", e.getMessage());
     }
     
     try {
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
index a508a85..9148672 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/core/TestRandomChains.java
@@ -44,8 +44,7 @@ import java.util.regex.Pattern;
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
 import org.apache.lucene.analysis.CachingTokenFilter;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.EmptyTokenizer;
 import org.apache.lucene.analysis.MockGraphTokenFilter;
 import org.apache.lucene.analysis.MockRandomLookaheadTokenFilter;
@@ -101,7 +100,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
 
   static List<Constructor<? extends Tokenizer>> tokenizers;
   static List<Constructor<? extends TokenFilter>> tokenfilters;
-  static List<Constructor<? extends CharStream>> charfilters;
+  static List<Constructor<? extends CharFilter>> charfilters;
 
   // TODO: fix those and remove
   private static final Set<Class<?>> brokenComponents = Collections.newSetFromMap(new IdentityHashMap<Class<?>,Boolean>());
@@ -170,7 +169,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
     getClassesForPackage("org.apache.lucene.analysis", analysisClasses);
     tokenizers = new ArrayList<Constructor<? extends Tokenizer>>();
     tokenfilters = new ArrayList<Constructor<? extends TokenFilter>>();
-    charfilters = new ArrayList<Constructor<? extends CharStream>>();
+    charfilters = new ArrayList<Constructor<? extends CharFilter>>();
     for (final Class<?> c : analysisClasses) {
       final int modifiers = c.getModifiers();
       if (
@@ -179,7 +178,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
         || c.isSynthetic() || c.isAnonymousClass() || c.isMemberClass() || c.isInterface()
         || brokenComponents.contains(c)
         || c.isAnnotationPresent(Deprecated.class)
-        || !(Tokenizer.class.isAssignableFrom(c) || TokenFilter.class.isAssignableFrom(c) || CharStream.class.isAssignableFrom(c))
+        || !(Tokenizer.class.isAssignableFrom(c) || TokenFilter.class.isAssignableFrom(c) || CharFilter.class.isAssignableFrom(c))
       ) {
         continue;
       }
@@ -197,10 +196,10 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
           assertTrue(ctor.toGenericString() + " has unsupported parameter types",
             allowedTokenFilterArgs.containsAll(Arrays.asList(ctor.getParameterTypes())));
           tokenfilters.add(castConstructor(TokenFilter.class, ctor));
-        } else if (CharStream.class.isAssignableFrom(c)) {
+        } else if (CharFilter.class.isAssignableFrom(c)) {
           assertTrue(ctor.toGenericString() + " has unsupported parameter types",
             allowedCharFilterArgs.containsAll(Arrays.asList(ctor.getParameterTypes())));
-          charfilters.add(castConstructor(CharStream.class, ctor));
+          charfilters.add(castConstructor(CharFilter.class, ctor));
         } else {
           fail("Cannot get here");
         }
@@ -524,7 +523,6 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
     allowedCharFilterArgs = Collections.newSetFromMap(new IdentityHashMap<Class<?>,Boolean>());
     allowedCharFilterArgs.addAll(argProducers.keySet());
     allowedCharFilterArgs.add(Reader.class);
-    allowedCharFilterArgs.add(CharStream.class);
   }
   
   @SuppressWarnings("unchecked")
@@ -560,8 +558,6 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
       Class<?> paramType = paramTypes[i];
       if (paramType == Reader.class) {
         args[i] = reader;
-      } else if (paramType == CharStream.class) {
-        args[i] = CharReader.get(reader);
       } else {
         args[i] = newRandomArg(random, paramType);
       }
@@ -701,7 +697,7 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
       int numFilters = random.nextInt(3);
       for (int i = 0; i < numFilters; i++) {
         while (true) {
-          final Constructor<? extends CharStream> ctor = charfilters.get(random.nextInt(charfilters.size()));
+          final Constructor<? extends CharFilter> ctor = charfilters.get(random.nextInt(charfilters.size()));
           final Object args[] = newCharFilterArgs(random, spec.reader, ctor.getParameterTypes());
           reader = createComponent(ctor, args, descr);
           if (reader != null) {
@@ -760,24 +756,16 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
     }
   }
   
-  // wants charfilter to be a filterreader...
-  // do *NOT*, do *NOT* refactor me to be a charfilter: LUCENE-3990
-  static class CheckThatYouDidntReadAnythingReaderWrapper extends CharStream {
+  static class CheckThatYouDidntReadAnythingReaderWrapper extends CharFilter {
     boolean readSomething;
-    CharStream in;
     
     CheckThatYouDidntReadAnythingReaderWrapper(Reader in) {
-      this.in = CharReader.get(in);
+      super(in);
     }
     
     @Override
-    public int correctOffset(int currentOff) {
-      return in.correctOffset(currentOff);
-    }
-
-    @Override
-    public void close() throws IOException {
-      in.close();
+    public int correct(int currentOff) {
+      return currentOff; // we don't change any offsets
     }
 
     @Override
@@ -799,32 +787,12 @@ public class TestRandomChains extends BaseTokenStreamTestCase {
     }
 
     @Override
-    public void mark(int readAheadLimit) throws IOException {
-      in.mark(readAheadLimit);
-    }
-
-    @Override
-    public boolean markSupported() {
-      return in.markSupported();
-    }
-
-    @Override
     public int read(char[] cbuf) throws IOException {
       readSomething = true;
       return in.read(cbuf);
     }
 
     @Override
-    public boolean ready() throws IOException {
-      return in.ready();
-    }
-
-    @Override
-    public void reset() throws IOException {
-      in.reset();
-    }
-
-    @Override
     public long skip(long n) throws IOException {
       readSomething = true;
       return in.skip(n);
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java
index 66c15a8..2407c1c 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/miscellaneous/TestPerFieldAnalyzerWrapper.java
@@ -68,7 +68,7 @@ public class TestPerFieldAnalyzerWrapper extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MockCharFilter(CharReader.get(reader), 7);
+        return new MockCharFilter(reader, 7);
       }
     };
     assertAnalyzesTo(a, "ab",
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer.java
index 73437cc..9534cba 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/path/TestPathHierarchyTokenizer.java
@@ -23,7 +23,6 @@ import java.util.Random;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.charfilter.MappingCharFilter;
 import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
@@ -123,7 +122,7 @@ public class TestPathHierarchyTokenizer extends BaseTokenStreamTestCase {
     builder.add("\\", "/");
     NormalizeCharMap normMap = builder.build();
     String path = "c:\\a\\b\\c";
-    CharStream cs = new MappingCharFilter(normMap, new StringReader(path));
+    Reader cs = new MappingCharFilter(normMap, new StringReader(path));
     PathHierarchyTokenizer t = new PathHierarchyTokenizer( cs );
     assertTokenStreamContents(t,
         new String[]{"c:", "c:/a", "c:/a/b", "c:/a/b/c"},
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
index 7501c5e..e1abda2 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternReplaceCharFilter.java
@@ -26,8 +26,7 @@ import java.util.regex.Pattern;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
@@ -102,8 +101,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
 
   private void checkOutput(String input, String pattern, String replacement,
       String expectedOutput, String expectedIndexMatchedOutput) throws IOException {
-    CharStream cs = new PatternReplaceCharFilter(pattern(pattern), replacement,
-        CharReader.get(new StringReader(input)));
+      CharFilter cs = new PatternReplaceCharFilter(pattern(pattern), replacement,
+        new StringReader(input));
 
     StringBuilder output = new StringBuilder();
     for (int chr = cs.read(); chr > 0; chr = cs.read()) {
@@ -138,8 +137,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   // this is test.
   public void testNothingChange() throws IOException {
     final String BLOCK = "this is test.";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1$2$3",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1$2$3",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "test." },
@@ -152,8 +151,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   // aa bb cc
   public void testReplaceByEmpty() throws IOException {
     final String BLOCK = "aa bb cc";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts, new String[] {});
   }
@@ -163,8 +162,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   // aa#bb#cc
   public void test1block1matchSameLength() throws IOException {
     final String BLOCK = "aa bb cc";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2#$3",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2#$3",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa#bb#cc" },
@@ -179,8 +178,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   // aa##bb###cc dd
   public void test1block1matchLonger() throws IOException {
     final String BLOCK = "aa bb cc dd";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1##$2###$3",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1##$2###$3",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa##bb###cc", "dd" },
@@ -194,8 +193,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   //  aa  aa
   public void test1block2matchLonger() throws IOException {
     final String BLOCK = " a  a";
-    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("a"), "aa",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa", "aa" },
@@ -210,8 +209,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   // aa#bb dd
   public void test1block1matchShorter() throws IOException {
     final String BLOCK = "aa  bb   cc dd";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1#$2",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa#bb", "dd" },
@@ -226,8 +225,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   //   aa  bb  cc --- aa bb aa  bb  cc
   public void test1blockMultiMatches() throws IOException {
     final String BLOCK = "  aa bb cc --- aa bb aa   bb   cc";
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1  $2  $3",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)\\s+(cc)"), "$1  $2  $3",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa", "bb", "cc", "---", "aa", "bb", "aa", "bb", "cc" },
@@ -246,8 +245,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   public void test2blocksMultiMatches() throws IOException {
     final String BLOCK = "  aa bb cc --- aa bb aa. bb aa   bb cc";
 
-    CharStream cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)"), "$1##$2",
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("(aa)\\s+(bb)"), "$1##$2",
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa##bb", "cc", "---", "aa##bb", "aa.", "bb", "aa##bb", "cc" },
@@ -262,8 +261,8 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
   //  aa b - c . --- b aa . c c b
   public void testChain() throws IOException {
     final String BLOCK = " a bb - ccc . --- bb a . ccc ccc bb";
-    CharStream cs = new PatternReplaceCharFilter( pattern("a"), "aa",
-        CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = new PatternReplaceCharFilter( pattern("a"), "aa",
+        new StringReader( BLOCK ) );
     cs = new PatternReplaceCharFilter( pattern("bb"), "b", cs );
     cs = new PatternReplaceCharFilter( pattern("ccc"), "c", cs );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
@@ -315,7 +314,7 @@ public class TestPatternReplaceCharFilter extends BaseTokenStreamTestCase {
 
         @Override
         protected Reader initReader(String fieldName, Reader reader) {
-          return new PatternReplaceCharFilter(p, replacement, CharReader.get(reader));
+          return new PatternReplaceCharFilter(p, replacement, reader);
         }
       };
 
diff --git a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
index df7e2c2..1d88f0c 100644
--- a/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
+++ b/lucene/analysis/common/src/test/org/apache/lucene/analysis/pattern/TestPatternTokenizer.java
@@ -26,8 +26,7 @@ import java.util.regex.Pattern;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.analysis.Analyzer.TokenStreamComponents;
@@ -83,7 +82,7 @@ public class TestPatternTokenizer extends BaseTokenStreamTestCase
     NormalizeCharMap.Builder builder = new NormalizeCharMap.Builder();
     builder.add("&uuml;", "Ã¼");
     NormalizeCharMap normMap = builder.build();
-    CharStream charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
+    CharFilter charStream = new MappingCharFilter( normMap, new StringReader( INPUT ) );
 
     // create PatternTokenizer
     TokenStream stream = new PatternTokenizer(charStream, Pattern.compile("[,;/\\s]+"), -1);
@@ -93,7 +92,7 @@ public class TestPatternTokenizer extends BaseTokenStreamTestCase
         new int[] { 12, 25, 28, 33 },
         INPUT.length());
     
-    charStream = new MappingCharFilter( normMap, CharReader.get( new StringReader( INPUT ) ) );
+    charStream = new MappingCharFilter( normMap, new StringReader( INPUT ) );
     stream = new PatternTokenizer(charStream, Pattern.compile("GÃ¼nther"), 0);
     assertTokenStreamContents(stream,
         new String[] { "GÃ¼nther", "GÃ¼nther" },
diff --git a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
index af59014..07d7119 100644
--- a/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
+++ b/lucene/analysis/kuromoji/src/java/org/apache/lucene/analysis/ja/JapaneseIterationMarkCharFilter.java
@@ -17,11 +17,11 @@ package org.apache.lucene.analysis.ja;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
-import org.apache.lucene.analysis.charfilter.CharFilter;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.util.RollingCharBuffer;
 
 import java.io.IOException;
+import java.io.Reader;
 
 /**
  * Normalizes Japanese horizontal iteration marks (odoriji) to their expanded form.
@@ -147,7 +147,7 @@ public class JapaneseIterationMarkCharFilter extends CharFilter {
    *
    * @param input char stream
    */
-  public JapaneseIterationMarkCharFilter(CharStream input) {
+  public JapaneseIterationMarkCharFilter(Reader input) {
     this(input, NORMALIZE_KANJI_DEFAULT, NORMALIZE_KANA_DEFAULT);
   }
 
@@ -159,7 +159,7 @@ public class JapaneseIterationMarkCharFilter extends CharFilter {
    * @param normalizeKanji indicates whether kanji iteration marks should be normalized
    * @param normalizeKana indicates whether kana iteration marks should be normalized
    */
-  public JapaneseIterationMarkCharFilter(CharStream input, boolean normalizeKanji, boolean normalizeKana) {
+  public JapaneseIterationMarkCharFilter(Reader input, boolean normalizeKanji, boolean normalizeKana) {
     super(input);
     this.normalizeKanji = normalizeKanji;
     this.normalizeKana = normalizeKana;
@@ -453,4 +453,10 @@ public class JapaneseIterationMarkCharFilter extends CharFilter {
   private boolean inside(char c, char[] map, char offset) {
     return c >= offset && c < offset + map.length;
   }
+
+
+  @Override
+  protected int correct(int currentOff) {
+    return currentOff; // this filter doesn't change the length of strings
+  }
 }
diff --git a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseIterationMarkCharFilter.java b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseIterationMarkCharFilter.java
index 40fd14f0..4df3812 100644
--- a/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseIterationMarkCharFilter.java
+++ b/lucene/analysis/kuromoji/src/test/org/apache/lucene/analysis/ja/TestJapaneseIterationMarkCharFilter.java
@@ -19,11 +19,9 @@ package org.apache.lucene.analysis.ja;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
-import org.apache.lucene.analysis.charfilter.CharFilter;
 
 import java.io.IOException;
 import java.io.Reader;
@@ -40,7 +38,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
 
     @Override
     protected Reader initReader(String fieldName, Reader reader) {
-      return new JapaneseIterationMarkCharFilter(CharReader.get(reader));
+      return new JapaneseIterationMarkCharFilter(reader);
     }
   };
 
@@ -53,7 +51,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
 
     @Override
     protected Reader initReader(String fieldName, Reader reader) {
-      return new JapaneseIterationMarkCharFilter(CharReader.get(reader));
+      return new JapaneseIterationMarkCharFilter(reader);
     }
   };
   
@@ -138,7 +136,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
   public void testKanjiOnly() throws IOException {
     // Test kanji only repetition marks
     CharFilter filter = new JapaneseIterationMarkCharFilter(
-        CharReader.get(new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????")),
+        new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????"),
         true, // kanji
         false // no kana
     );
@@ -148,7 +146,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
   public void testKanaOnly() throws IOException {
     // Test kana only repetition marks
     CharFilter filter = new JapaneseIterationMarkCharFilter(
-        CharReader.get(new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????")),
+        new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????"),
         false, // no kanji
         true   // kana
     );
@@ -158,7 +156,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
   public void testNone() throws IOException {
     // Test no repetition marks
     CharFilter filter = new JapaneseIterationMarkCharFilter(
-        CharReader.get(new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????")),
+        new StringReader("??????????????¨ä?ç·??????¸ã?é£??????§ã???bc?¨ã?????????"),
         false, // no kanji
         false  // no kana
     );
@@ -210,7 +208,7 @@ public class TestJapaneseIterationMarkCharFilter extends BaseTokenStreamTestCase
     assertEquals(expected, actual);
   }
 
-  private String readFully(CharStream stream) throws IOException {
+  private String readFully(Reader stream) throws IOException {
     StringBuffer buffer = new StringBuffer();
     int ch;
     while ((ch = stream.read()) != -1) {
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java b/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
index 2ca2993..fe2008c 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Analyzer.java
@@ -69,7 +69,7 @@ public abstract class Analyzer {
    * instance of {@link TokenStreamComponents}. It returns the sink of the
    * components and stores the components internally. Subsequent calls to this
    * method will reuse the previously stored components after resetting them
-   * through {@link TokenStreamComponents#reset(Reader)}.
+   * through {@link TokenStreamComponents#setReader(Reader)}.
    * </p>
    * 
    * @param fieldName the name of the field the created TokenStream is used for
@@ -83,7 +83,7 @@ public abstract class Analyzer {
       components = createComponents(fieldName, r);
       reuseStrategy.setReusableComponents(fieldName, components);
     } else {
-      components.reset(r);
+      components.setReader(r);
     }
     return components.getTokenStream();
   }
@@ -181,7 +181,7 @@ public abstract class Analyzer {
      * @throws IOException
      *           if the component's reset method throws an {@link IOException}
      */
-    protected void reset(final Reader reader) throws IOException {
+    protected void setReader(final Reader reader) throws IOException {
       source.setReader(reader);
     }
 
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
new file mode 100644
index 0000000..b5fc791
--- /dev/null
+++ b/lucene/core/src/java/org/apache/lucene/analysis/CharFilter.java
@@ -0,0 +1,55 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.FilterReader;
+import java.io.Reader;
+
+/**
+ * Subclasses of CharFilter can be chained to filter a Reader
+ * They can be used as {@link java.io.Reader} with additional offset
+ * correction. {@link Tokenizer}s will automatically use {@link #correctOffset}
+ * if a CharFilter subclass is used.
+ */
+public abstract class CharFilter extends FilterReader {
+
+  /**
+   * Create a new CharFilter wrapping the provided reader.
+   * @param in a Reader, can also be a CharFilter for chaining.
+   */
+  public CharFilter(Reader in) {
+    super(in);
+  }
+  
+  /**
+   * Subclasses override to correct the current offset.
+   *
+   * @param currentOff current offset
+   * @return corrected offset
+   */
+  protected abstract int correct(int currentOff);
+  
+  /**
+   * Chains the corrected offset through the input
+   * CharFilter(s).
+   */
+  public final int correctOffset(int currentOff) {
+    final int corrected = correct(currentOff);
+    return (in instanceof CharFilter) ? ((CharFilter) in).correctOffset(corrected) : corrected;
+  }
+}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharReader.java b/lucene/core/src/java/org/apache/lucene/analysis/CharReader.java
deleted file mode 100644
index f07d166..0000000
--- a/lucene/core/src/java/org/apache/lucene/analysis/CharReader.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis;
-
-import java.io.IOException;
-import java.io.Reader;
-
-/**
- * CharReader is a Reader wrapper. It reads chars from
- * Reader and outputs {@link CharStream}, defining an
- * identify function {@link #correctOffset} method that
- * simply returns the provided offset.
- */
-public final class CharReader extends CharStream {
-
-  private final Reader input;
-  
-  public static CharStream get(Reader input) {
-    return input instanceof CharStream ?
-      (CharStream)input : new CharReader(input);
-  }
-
-  private CharReader(Reader in) {
-    input = in;
-  }
-
-  @Override
-  public int correctOffset(int currentOff) {
-    return currentOff;
-  }
-
-  @Override
-  public void close() throws IOException {
-    input.close();
-  }
-
-  @Override
-  public int read(char[] cbuf, int off, int len) throws IOException {
-    return input.read(cbuf, off, len);
-  }
-
-  @Override
-  public int read() throws IOException {
-    return input.read();
-  }
-
-  @Override
-  public boolean markSupported(){
-    return input.markSupported();
-  }
-
-  @Override
-  public void mark( int readAheadLimit ) throws IOException {
-    input.mark(readAheadLimit);
-  }
-
-  @Override
-  public void reset() throws IOException {
-    input.reset();
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/CharStream.java b/lucene/core/src/java/org/apache/lucene/analysis/CharStream.java
deleted file mode 100644
index 22d710d..0000000
--- a/lucene/core/src/java/org/apache/lucene/analysis/CharStream.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.lucene.analysis;
-
-import java.io.Reader;
-
-/**
- * CharStream adds {@link #correctOffset}
- * functionality over {@link Reader}.  All Tokenizers accept a
- * CharStream instead of {@link Reader} as input, which enables
- * arbitrary character based filtering before tokenization. 
- * The {@link #correctOffset} method fixed offsets to account for
- * removal or insertion of characters, so that the offsets
- * reported in the tokens match the character offsets of the
- * original Reader.
- */
-public abstract class CharStream extends Reader {
-
-  /**
-   * Called by CharFilter(s) and Tokenizer to correct token offset.
-   *
-   * @param currentOff offset as seen in the output
-   * @return corrected offset based on the input
-   */
-  public abstract int correctOffset(int currentOff);
-}
diff --git a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
index 72b522b..1b39489 100644
--- a/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
+++ b/lucene/core/src/java/org/apache/lucene/analysis/Tokenizer.java
@@ -65,15 +65,15 @@ public abstract class Tokenizer extends TokenStream {
     }
   }
   
-  /** Return the corrected offset. If {@link #input} is a {@link CharStream} subclass
-   * this method calls {@link CharStream#correctOffset}, else returns <code>currentOff</code>.
+  /** Return the corrected offset. If {@link #input} is a {@link CharFilter} subclass
+   * this method calls {@link CharFilter#correctOffset}, else returns <code>currentOff</code>.
    * @param currentOff offset as seen in the output
    * @return corrected offset based on the input
-   * @see CharStream#correctOffset
+   * @see CharFilter#correctOffset
    */
   protected final int correctOffset(int currentOff) {
     assert input != null: "this tokenizer is closed";
-    return (input instanceof CharStream) ? ((CharStream) input).correctOffset(currentOff) : currentOff;
+    return (input instanceof CharFilter) ? ((CharFilter) input).correctOffset(currentOff) : currentOff;
   }
 
   /** Expert: Reset the tokenizer to a new reader.  Typically, an
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java
new file mode 100644
index 0000000..746ff74
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestCharFilter.java
@@ -0,0 +1,70 @@
+package org.apache.lucene.analysis;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.Reader;
+import java.io.StringReader;
+
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestCharFilter extends LuceneTestCase {
+
+  public void testCharFilter1() throws Exception {
+    CharFilter cs = new CharFilter1(new StringReader(""));
+    assertEquals("corrected offset is invalid", 1, cs.correctOffset(0));
+  }
+
+  public void testCharFilter2() throws Exception {
+    CharFilter cs = new CharFilter2(new StringReader(""));
+    assertEquals("corrected offset is invalid", 2, cs.correctOffset(0));
+  }
+
+  public void testCharFilter12() throws Exception {
+    CharFilter cs = new CharFilter2(new CharFilter1(new StringReader("")));
+    assertEquals( "corrected offset is invalid", 3, cs.correctOffset(0));
+  }
+
+  public void testCharFilter11() throws Exception {
+    CharFilter cs = new CharFilter1(new CharFilter1(new StringReader("")));
+    assertEquals( "corrected offset is invalid", 2, cs.correctOffset(0));
+  }
+
+  static class CharFilter1 extends CharFilter {
+
+    protected CharFilter1(Reader in) {
+      super(in);
+    }
+
+    @Override
+    protected int correct(int currentOff) {
+      return currentOff + 1;
+    }
+  }
+
+  static class CharFilter2 extends CharFilter {
+
+    protected CharFilter2(Reader in) {
+      super(in);
+    }
+
+    @Override
+    protected int correct(int currentOff) {
+      return currentOff + 2;
+    }
+  }
+}
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java b/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
index 15c5792..6b067f2 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestMockAnalyzer.java
@@ -123,7 +123,7 @@ public class TestMockAnalyzer extends BaseTokenStreamTestCase {
     for (int i = 0; i < num; i++) {
       String s = _TestUtil.randomHtmlishString(random(), 20);
       StringReader reader = new StringReader(s);
-      MockCharFilter charfilter = new MockCharFilter(CharReader.get(reader), 2);
+      MockCharFilter charfilter = new MockCharFilter(reader, 2);
       MockAnalyzer analyzer = new MockAnalyzer(random());
       TokenStream ts = analyzer.tokenStream("bogus", charfilter);
       ts.reset();
diff --git a/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java b/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
index 8a6005e..c84a62c 100644
--- a/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
+++ b/lucene/core/src/test/org/apache/lucene/analysis/TestMockCharFilter.java
@@ -33,7 +33,7 @@ public class TestMockCharFilter extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new MockCharFilter(CharReader.get(reader), 7);
+        return new MockCharFilter(reader, 7);
       }
     };
     
diff --git a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
index 20839cc..814fdb9 100644
--- a/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
+++ b/lucene/test-framework/src/java/org/apache/lucene/analysis/MockCharFilter.java
@@ -24,13 +24,12 @@ import java.util.TreeMap;
 
 /** the purpose of this charfilter is to send offsets out of bounds
   if the analyzer doesn't use correctOffset or does incorrect offset math. */
-public class MockCharFilter extends CharStream {
-  final CharStream in;
+public class MockCharFilter extends CharFilter {
   final int remainder;
   
   // for testing only
   public MockCharFilter(Reader in, int remainder) {
-    this.in = CharReader.get(in);
+    super(in);
     // TODO: instead of fixed remainder... maybe a fixed
     // random seed?
     this.remainder = remainder;
@@ -94,11 +93,11 @@ public class MockCharFilter extends CharStream {
   }
 
   @Override
-  public int correctOffset(int currentOff) {
+  public int correct(int currentOff) {
     SortedMap<Integer,Integer> subMap = corrections.subMap(0, currentOff+1);
     int ret = subMap.isEmpty() ? currentOff : currentOff + subMap.get(subMap.lastKey());
     assert ret >= 0 : "currentOff=" + currentOff + ",diff=" + (ret-currentOff);
-    return in.correctOffset(ret); // chain the call
+    return ret;
   }
   
   protected void addOffCorrectMap(int off, int cumulativeDiff) {
diff --git a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/HTMLStripTransformer.java b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/HTMLStripTransformer.java
index 0160f43..e62c329 100644
--- a/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/HTMLStripTransformer.java
+++ b/solr/contrib/dataimporthandler/src/java/org/apache/solr/handler/dataimport/HTMLStripTransformer.java
@@ -17,7 +17,6 @@
 package org.apache.solr.handler.dataimport;
 
 import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
-import org.apache.lucene.analysis.CharReader;
 
 import java.io.IOException;
 import java.io.StringReader;
@@ -73,7 +72,7 @@ public class HTMLStripTransformer extends Transformer {
     StringBuilder out = new StringBuilder();
     StringReader strReader = new StringReader(value);
     try {
-      HTMLStripCharFilter html = new HTMLStripCharFilter(CharReader.get(strReader.markSupported() ? strReader : new BufferedReader(strReader)));
+      HTMLStripCharFilter html = new HTMLStripCharFilter(strReader.markSupported() ? strReader : new BufferedReader(strReader));
       char[] cbuf = new char[1024 * 10];
       while (true) {
         int count = html.read(cbuf);
diff --git a/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java
index bdc5e05..6e91a95 100644
--- a/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/HTMLStripCharFilterFactory.java
@@ -18,10 +18,10 @@ package org.apache.solr.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 
+import java.io.Reader;
 import java.util.HashSet;
 import java.util.Map;
 import java.util.Set;
@@ -44,7 +44,7 @@ import java.util.regex.Pattern;
   Set<String> escapedTags = null;
   Pattern TAG_NAME_PATTERN = Pattern.compile("[^\\s,]+");
 
-  public HTMLStripCharFilter create(CharStream input) {
+  public HTMLStripCharFilter create(Reader input) {
     HTMLStripCharFilter charFilter;
     if (null == escapedTags) {
       charFilter = new HTMLStripCharFilter(input);
diff --git a/solr/core/src/java/org/apache/solr/analysis/JapaneseIterationMarkCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/JapaneseIterationMarkCharFilterFactory.java
index 97c3007..68f3b10 100644
--- a/solr/core/src/java/org/apache/solr/analysis/JapaneseIterationMarkCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/JapaneseIterationMarkCharFilterFactory.java
@@ -17,12 +17,13 @@ package org.apache.solr.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.ja.JapaneseIterationMarkCharFilter;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 
+import java.io.Reader;
 import java.util.Map;
 
 /**
@@ -46,7 +47,7 @@ public class JapaneseIterationMarkCharFilterFactory extends CharFilterFactory im
   private boolean normalizeKana = true;
 
   @Override
-  public CharStream create(CharStream input) {
+  public CharFilter create(Reader input) {
     return new JapaneseIterationMarkCharFilter(input, normalizeKanji, normalizeKana);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilter.java b/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilter.java
index e0af248..071d710 100644
--- a/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilter.java
+++ b/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilter.java
@@ -26,8 +26,6 @@ import java.util.HashMap;
 import java.util.Set;
 
 import org.apache.lucene.analysis.charfilter.BaseCharFilter;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
 
 /**
  * <p>
@@ -72,21 +70,21 @@ public class LegacyHTMLStripCharFilter extends BaseCharFilter {
 
   public static void main(String[] args) throws IOException {
     Reader in = new LegacyHTMLStripCharFilter(
-            CharReader.get(new InputStreamReader(System.in, Charset.defaultCharset())));
+            new InputStreamReader(System.in, Charset.defaultCharset()));
     int ch;
     while ( (ch=in.read()) != -1 ) System.out.print((char)ch);
   }
 
-  public LegacyHTMLStripCharFilter(CharStream source) {
-    super(source.markSupported() ? source : CharReader.get(new BufferedReader(source)));
+  public LegacyHTMLStripCharFilter(Reader source) {
+    super(source.markSupported() ? source : new BufferedReader(source));
   }
 
-  public LegacyHTMLStripCharFilter(CharStream source, Set<String> escapedTags){
+  public LegacyHTMLStripCharFilter(Reader source, Set<String> escapedTags){
     this(source);
     this.escapedTags = escapedTags;
   }
 
-  public LegacyHTMLStripCharFilter(CharStream source, Set<String> escapedTags, int readAheadLimit){
+  public LegacyHTMLStripCharFilter(Reader source, Set<String> escapedTags, int readAheadLimit){
     this(source);
     this.escapedTags = escapedTags;
     this.readAheadLimit = readAheadLimit;
@@ -105,7 +103,7 @@ public class LegacyHTMLStripCharFilter extends BaseCharFilter {
       return ch;
     }
     numRead++;
-    return input.read();
+    return in.read();
   }
 
   private int nextSkipWS() throws IOException {
@@ -120,7 +118,7 @@ public class LegacyHTMLStripCharFilter extends BaseCharFilter {
       return pushed.charAt(len-1);
     }
     numRead++;
-    int ch = input.read();
+    int ch = in.read();
     push(ch);
     return ch;
   }
@@ -182,11 +180,11 @@ public class LegacyHTMLStripCharFilter extends BaseCharFilter {
 
   private void saveState() throws IOException {
     lastMark = numRead;
-    input.mark(readAheadLimit);
+    in.mark(readAheadLimit);
   }
 
   private void restoreState() throws IOException {
-    input.reset();
+    in.reset();
     pushed.setLength(0);
   }
 
@@ -775,12 +773,6 @@ public class LegacyHTMLStripCharFilter extends BaseCharFilter {
     return i;
   }
 
-  @Override
-  public void close() throws IOException {
-    input.close();
-  }
-
-
   private static final HashMap<String,Character> entityTable;
   static {
     entityTable = new HashMap<String,Character>();
diff --git a/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilterFactory.java
index 09cc1f9..4e81778 100644
--- a/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/LegacyHTMLStripCharFilterFactory.java
@@ -18,7 +18,8 @@ package org.apache.solr.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
+import java.io.Reader;
+
 import org.apache.lucene.analysis.util.CharFilterFactory;
 
 /**
@@ -52,7 +53,7 @@ import org.apache.lucene.analysis.util.CharFilterFactory;
 @Deprecated
 public class LegacyHTMLStripCharFilterFactory extends CharFilterFactory {
 
-  public LegacyHTMLStripCharFilter create(CharStream input) {
+  public LegacyHTMLStripCharFilter create(Reader input) {
     return new LegacyHTMLStripCharFilter(input);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java
index f68b800..a518e4a 100644
--- a/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/MappingCharFilterFactory.java
@@ -19,12 +19,13 @@ package org.apache.solr.analysis;
 
 import java.io.File;
 import java.io.IOException;
+import java.io.Reader;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.charfilter.MappingCharFilter;
 import org.apache.lucene.analysis.charfilter.NormalizeCharMap;
 import org.apache.lucene.analysis.util.*;
@@ -78,7 +79,7 @@ public class MappingCharFilterFactory extends CharFilterFactory implements
     }
   }
 
-  public CharStream create(CharStream input) {
+  public CharFilter create(Reader input) {
     return new MappingCharFilter(normMap,input);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
index 2e9f2ef..ca6fe6a 100644
--- a/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/PatternReplaceCharFilterFactory.java
@@ -17,10 +17,11 @@
 
 package org.apache.solr.analysis;
 
+import java.io.Reader;
 import java.util.Map;
 import java.util.regex.Pattern;
 
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.pattern.PatternReplaceCharFilter;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 
@@ -53,7 +54,7 @@ public class PatternReplaceCharFilterFactory extends CharFilterFactory {
     // TODO: throw exception if you set maxBlockChars or blockDelimiters ?
   }
 
-  public CharStream create(CharStream input) {
+  public CharFilter create(Reader input) {
     return new PatternReplaceCharFilter( p, replacement, input );
   }
 }
diff --git a/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java b/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java
index 6bcadcd..a0ae871 100644
--- a/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java
+++ b/solr/core/src/java/org/apache/solr/analysis/PersianCharFilterFactory.java
@@ -17,7 +17,9 @@ package org.apache.solr.analysis;
  * limitations under the License.
  */
 
-import org.apache.lucene.analysis.CharStream;
+import java.io.Reader;
+
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.fa.PersianCharFilter;
 import org.apache.lucene.analysis.util.AbstractAnalysisFactory;
 import org.apache.lucene.analysis.util.CharFilterFactory;
@@ -37,7 +39,7 @@ import org.apache.lucene.analysis.util.MultiTermAwareComponent;
 public class PersianCharFilterFactory extends CharFilterFactory implements MultiTermAwareComponent {
 
   @Override
-  public CharStream create(CharStream input) {
+  public CharFilter create(Reader input) {
     return new PersianCharFilter(input);
   }
 
diff --git a/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java b/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java
index e76ef49..3c8af5e 100644
--- a/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java
+++ b/solr/core/src/java/org/apache/solr/analysis/TokenizerChain.java
@@ -50,7 +50,7 @@ public final class TokenizerChain extends SolrAnalyzer {
   @Override
   public Reader initReader(String fieldName, Reader reader) {
     if (charFilters != null && charFilters.length > 0) {
-      CharStream cs = CharReader.get( reader );
+      Reader cs = reader;
       for (CharFilterFactory charFilter : charFilters) {
         cs = charFilter.create(cs);
       }
diff --git a/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java b/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
index 6bfdc24..c53a801 100644
--- a/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
+++ b/solr/core/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase.java
@@ -18,8 +18,6 @@
 package org.apache.solr.handler;
 
 import org.apache.lucene.analysis.Analyzer;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.tokenattributes.*;
 import org.apache.lucene.analysis.util.CharFilterFactory;
@@ -41,6 +39,7 @@ import org.apache.solr.response.SolrQueryResponse;
 import org.apache.solr.schema.FieldType;
 
 import java.io.IOException;
+import java.io.Reader;
 import java.io.StringReader;
 import java.util.*;
 import org.apache.commons.lang.ArrayUtils;
@@ -106,7 +105,7 @@ public abstract class AnalysisRequestHandlerBase extends RequestHandlerBase {
     if( cfiltfacs != null ){
       String source = value;
       for(CharFilterFactory cfiltfac : cfiltfacs ){
-        CharStream reader = CharReader.get(new StringReader(source));
+        Reader reader = new StringReader(source);
         reader = cfiltfac.create(reader);
         source = writeCharStream(namedList, reader);
       }
@@ -287,7 +286,7 @@ public abstract class AnalysisRequestHandlerBase extends RequestHandlerBase {
     return tokensNamedLists;
   }
   
-  private String writeCharStream(NamedList<Object> out, CharStream input ){
+  private String writeCharStream(NamedList<Object> out, Reader input ){
     final int BUFFER_SIZE = 1024;
     char[] buf = new char[BUFFER_SIZE];
     int len = 0;
diff --git a/solr/core/src/java/org/apache/solr/update/processor/HTMLStripFieldUpdateProcessorFactory.java b/solr/core/src/java/org/apache/solr/update/processor/HTMLStripFieldUpdateProcessorFactory.java
index 16be5fb..5e2afbc 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/HTMLStripFieldUpdateProcessorFactory.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/HTMLStripFieldUpdateProcessorFactory.java
@@ -21,7 +21,6 @@ import org.apache.solr.core.SolrCore;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.response.SolrQueryResponse;
 
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.charfilter.HTMLStripCharFilter;
 
 import org.apache.commons.io.IOUtils;
@@ -69,7 +68,7 @@ public final class HTMLStripFieldUpdateProcessorFactory extends FieldMutatingUpd
           Reader in = null;
           try {
             in = new HTMLStripCharFilter
-              (CharReader.get(new StringReader(s.toString())));
+              (new StringReader(s.toString()));
             IOUtils.copy(in, result);
             return result.toString();
           } catch (IOException e) {
diff --git a/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java b/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
index 68d2ace..1c7dae2 100644
--- a/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
+++ b/solr/core/src/test/org/apache/solr/analysis/LegacyHTMLStripCharFilterTest.java
@@ -28,7 +28,6 @@ import java.util.Set;
 
 import org.apache.lucene.analysis.Analyzer;
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.Tokenizer;
 import org.apache.lucene.util._TestUtil;
@@ -45,7 +44,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = " this is some text  here is a  link  and " +
             "another  link . " +
             "This is an entity: & plus a <.  Here is an &.  ";
-    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(html)));
+    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(new StringReader(html));
     StringBuilder builder = new StringBuilder();
     int ch = -1;
     char [] goldArray = gold.toCharArray();
@@ -63,7 +62,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   //Some sanity checks, but not a full-fledged check
   public void testHTML() throws Exception {
     InputStream stream = getClass().getResourceAsStream("htmlStripReaderTest.html");
-    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(CharReader.get(new InputStreamReader(stream, "UTF-8")));
+    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(new InputStreamReader(stream, "UTF-8"));
     StringBuilder builder = new StringBuilder();
     int ch = -1;
     while ((ch = reader.read()) != -1){
@@ -83,7 +82,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "\u0393";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new LegacyHTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -100,7 +99,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "  <foo> \u00DCbermensch = \u0393 bar \u0393";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new LegacyHTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -117,7 +116,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String gold = "  <junk/>   ! @ and ??";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new LegacyHTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -133,7 +132,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     String test = "aaa bbb <reserved ccc=\"ddddd\"> eeee </reserved> ffff <reserved ggg=\"hhhh\"/> <other/>";
     Set<String> set = new HashSet<String>();
     set.add("reserved");
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(test)), set);
+    Reader reader = new LegacyHTMLStripCharFilter(new StringReader(test), set);
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -150,7 +149,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
   public void testMalformedHTML() throws Exception {
     String test = "a <a hr<ef=aa<a>> </close</a>";
     String gold = "a <a hr<ef=aa > </close ";
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(test)));
+    Reader reader = new LegacyHTMLStripCharFilter(new StringReader(test));
     StringBuilder builder = new StringBuilder();
     int ch = 0;
     while ((ch = reader.read()) != -1){
@@ -199,7 +198,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
   private void processBuffer(String test, String assertMsg) throws IOException {
     // System.out.println("-------------------processBuffer----------");
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(test))));//force the use of BufferedReader
+    Reader reader = new LegacyHTMLStripCharFilter(new BufferedReader(new StringReader(test)));//force the use of BufferedReader
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -216,7 +215,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
     String test = "<!--- three dashes, still a valid comment ---> ";
     String gold = "  ";
-    Reader reader = new LegacyHTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(test))));//force the use of BufferedReader
+    Reader reader = new LegacyHTMLStripCharFilter(new BufferedReader(new StringReader(test)));//force the use of BufferedReader
     int ch = 0;
     StringBuilder builder = new StringBuilder();
     try {
@@ -231,7 +230,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
 
   public void doTestOffsets(String in) throws Exception {
-    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(CharReader.get(new BufferedReader(new StringReader(in))));
+    LegacyHTMLStripCharFilter reader = new LegacyHTMLStripCharFilter(new BufferedReader(new StringReader(in)));
     int ch = 0;
     int off = 0;     // offset in the reader
     int strOff = -1; // offset in the original string
@@ -268,7 +267,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
 
       @Override
       protected Reader initReader(String fieldName, Reader reader) {
-        return new LegacyHTMLStripCharFilter(CharReader.get(new BufferedReader(reader)));
+        return new LegacyHTMLStripCharFilter(new BufferedReader(reader));
       }
     };
     
@@ -280,7 +279,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
     int maxNumElements = 10000;
     String text = _TestUtil.randomHtmlishString(random(), maxNumElements);
     Reader reader
-        = new LegacyHTMLStripCharFilter(CharReader.get(new StringReader(text)));
+        = new LegacyHTMLStripCharFilter(new StringReader(text));
     while (reader.read() != -1);
   }
 
@@ -315,7 +314,7 @@ public class LegacyHTMLStripCharFilterTest extends BaseTokenStreamTestCase {
       }
     }
     Reader reader = new LegacyHTMLStripCharFilter
-        (CharReader.get(new StringReader(text.toString())));
+        (new StringReader(text.toString()));
     while (reader.read() != -1);
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestArabicFilters.java b/solr/core/src/test/org/apache/solr/analysis/TestArabicFilters.java
index 9e06570..8296b5f 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestArabicFilters.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestArabicFilters.java
@@ -23,7 +23,6 @@ import java.util.Collections;
 import java.util.Map;
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.lucene.analysis.Tokenizer;
 
@@ -78,7 +77,7 @@ public class TestArabicFilters extends BaseTokenStreamTestCase {
     tokenizerFactory.setLuceneMatchVersion(TEST_VERSION_CURRENT);
     Map<String, String> args = Collections.emptyMap();
     tokenizerFactory.init(args);
-    TokenStream stream = tokenizerFactory.create(charfilterFactory.create(CharReader.get(reader)));
+    TokenStream stream = tokenizerFactory.create(charfilterFactory.create(reader));
     assertTokenStreamContents(stream, new String[] { "??", "Ø®?Ø±Ø¯" });
   }
 }
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java
index cfdf062..da7f390 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestHTMLStripCharFilterFactory.java
@@ -38,7 +38,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     Map<String,String> args = new HashMap<String,String>();
     args.put("escapedTags", "a, Title");
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "only", "a", "test." },
@@ -53,7 +53,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     HTMLStripCharFilterFactory factory = new HTMLStripCharFilterFactory();
     Map<String,String> args = new HashMap<String,String>();
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "only", "a", "test." },
@@ -69,7 +69,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     Map<String,String> args = new HashMap<String,String>();
     args.put("escapedTags", "U i");
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "<u>this</u>", "is", "only", "a", "<I>test</I>." },
@@ -85,7 +85,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     Map<String,String> args = new HashMap<String,String>();
     args.put("escapedTags", ",, , ");
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "only", "a", "test." },
@@ -101,7 +101,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     Map<String,String> args = new HashMap<String,String>();
     args.put("escapedTags", "");
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "only", "a", "test." },
@@ -117,7 +117,7 @@ public class TestHTMLStripCharFilterFactory extends BaseTokenStreamTestCase {
     Map<String,String> args = new HashMap<String,String>();
     args.put("escapedTags", ", B\r\n\t");
     factory.init(args);
-    CharStream cs = factory.create(CharReader.get(new StringReader(text)));
+    CharFilter cs = factory.create(new StringReader(text));
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "<b>only</b>", "a", "test." },
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseIterationMarkCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestJapaneseIterationMarkCharFilterFactory.java
index 8289ae2..8bde4c6 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestJapaneseIterationMarkCharFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestJapaneseIterationMarkCharFilterFactory.java
@@ -18,8 +18,7 @@ package org.apache.solr.analysis;
  */
 
 import org.apache.lucene.analysis.BaseTokenStreamTestCase;
-import org.apache.lucene.analysis.CharReader;
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockTokenizer;
 import org.apache.lucene.analysis.TokenStream;
 import org.apache.solr.core.SolrResourceLoader;
@@ -38,7 +37,7 @@ public class TestJapaneseIterationMarkCharFilterFactory extends BaseTokenStreamT
   public void testIterationMarksWithKeywordTokenizer() throws IOException {
     final String text = "????¦¬é¹¿ã??????????????????¹ã?";
     JapaneseIterationMarkCharFilterFactory filterFactory = new JapaneseIterationMarkCharFilterFactory();
-    CharStream filter = filterFactory.create(CharReader.get(new StringReader(text)));
+    CharFilter filter = filterFactory.create(new StringReader(text));
     TokenStream tokenStream = new MockTokenizer(filter, MockTokenizer.KEYWORD, false);
     assertTokenStreamContents(tokenStream, new String[]{"???é¦?¹¿é¦?¹¿????¨ã????????????"});
   }
@@ -53,8 +52,8 @@ public class TestJapaneseIterationMarkCharFilterFactory extends BaseTokenStreamT
     Map<String, String> filterArgs = Collections.emptyMap();
     filterFactory.init(filterArgs);
 
-    CharStream filter = filterFactory.create(
-        CharReader.get(new StringReader("????¦¬é¹¿ã??????????????????¹ã?"))
+    CharFilter filter = filterFactory.create(
+        new StringReader("????¦¬é¹¿ã??????????????????¹ã?")
     );
     TokenStream tokenStream = tokenizerFactory.create(filter);
     assertTokenStreamContents(tokenStream, new String[]{"???", "é¦?¹¿é¦?¹¿???", "?¨ã???????", "??", "?¹ã?"});
@@ -72,8 +71,8 @@ public class TestJapaneseIterationMarkCharFilterFactory extends BaseTokenStreamT
     filterArgs.put("normalizeKana", "false");
     filterFactory.init(filterArgs);
     
-    CharStream filter = filterFactory.create(
-        CharReader.get(new StringReader("????¦¬é¹¿ã??????????????????¹ã?"))
+    CharFilter filter = filterFactory.create(
+        new StringReader("????¦¬é¹¿ã??????????????????¹ã?")
     );
     TokenStream tokenStream = tokenizerFactory.create(filter);
     assertTokenStreamContents(tokenStream, new String[]{"???", "é¦?¹¿é¦?¹¿???", "?¨ã???", "??", "??", "??", "???", "??"});
@@ -91,8 +90,8 @@ public class TestJapaneseIterationMarkCharFilterFactory extends BaseTokenStreamT
     filterArgs.put("normalizeKana", "true");
     filterFactory.init(filterArgs);
 
-    CharStream filter = filterFactory.create(
-        CharReader.get(new StringReader("????¦¬é¹¿ã??????????????????¹ã?"))
+    CharFilter filter = filterFactory.create(
+        new StringReader("????¦¬é¹¿ã??????????????????¹ã?")
     );
     TokenStream tokenStream = tokenizerFactory.create(filter);
     assertTokenStreamContents(tokenStream, new String[]{"????", "é¦?¹¿", "??", "??", "???", "?¨ã???????", "??", "?¹ã?"});
diff --git a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java b/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
index 26ab438..80cac56 100644
--- a/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
+++ b/solr/core/src/test/org/apache/solr/analysis/TestPatternReplaceCharFilterFactory.java
@@ -39,8 +39,8 @@ public class TestPatternReplaceCharFilterFactory extends BaseTokenStreamTestCase
     args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
     args.put("replacement", "$1$2$3");
     factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "this", "is", "test." },
@@ -56,8 +56,8 @@ public class TestPatternReplaceCharFilterFactory extends BaseTokenStreamTestCase
     Map<String,String> args = new HashMap<String,String>();
     args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
     factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     ts.reset();
     assertFalse(ts.incrementToken());
@@ -75,8 +75,8 @@ public class TestPatternReplaceCharFilterFactory extends BaseTokenStreamTestCase
     args.put("pattern", "(aa)\\s+(bb)\\s+(cc)");
     args.put("replacement", "$1#$2#$3");
     factory.init(args);
-    CharStream cs = factory.create(
-          CharReader.get( new StringReader( BLOCK ) ) );
+    CharFilter cs = factory.create(
+          new StringReader( BLOCK ) );
     TokenStream ts = new MockTokenizer(cs, MockTokenizer.WHITESPACE, false);
     assertTokenStreamContents(ts,
         new String[] { "aa#bb#cc" },
diff --git a/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java b/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
index 86ad09a..8b67cbf 100644
--- a/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
+++ b/solr/test-framework/src/java/org/apache/solr/analysis/MockCharFilterFactory.java
@@ -17,9 +17,10 @@ package org.apache.solr.analysis;
  * limitations under the License.
  */
 
+import java.io.Reader;
 import java.util.Map;
 
-import org.apache.lucene.analysis.CharStream;
+import org.apache.lucene.analysis.CharFilter;
 import org.apache.lucene.analysis.MockCharFilter;
 import org.apache.lucene.analysis.util.CharFilterFactory;
 
@@ -40,7 +41,7 @@ public class MockCharFilterFactory extends CharFilterFactory {
   }
 
   @Override
-  public CharStream create(CharStream input) {
+  public CharFilter create(Reader input) {
     return new MockCharFilter(input, remainder);
   }
 }

