GitDiffStart: b3d191832cc355149c67e4c095fd08aae5ad7d4e | Mon Oct 12 12:15:07 2015 +0000
diff --git a/lucene/CHANGES.txt b/lucene/CHANGES.txt
index 348f025..26d99b2 100644
--- a/lucene/CHANGES.txt
+++ b/lucene/CHANGES.txt
@@ -99,6 +99,11 @@ API Changes
 
 * LUCENE-6803: Deprecate sandbox Regexp Query. (Uwe Schindler)
 
+* LUCENE-6301: org.apache.lucene.search.Filter is now deprecated. You should use
+  Query objects instead of Filters, and the BooleanClause.Occur.FILTER clause in
+  order to let Lucene know that a Query should be used for filtering but not
+  scoring.
+
 Optimizations
 
 * LUCENE-6708: TopFieldCollector does not compute the score several times on the
diff --git a/lucene/MIGRATE.txt b/lucene/MIGRATE.txt
index 8e1f770..98d7bc1 100644
--- a/lucene/MIGRATE.txt
+++ b/lucene/MIGRATE.txt
@@ -31,10 +31,12 @@ situations where some documents do not have values for fields wrapped in other
 ValueSources.  Users who want to preserve the previous behavior may need to wrap 
 their ValueSources in a "DefFunction" along with a ConstValueSource of "0.0".
 
-## Removal of FilteredQuery (LUCENE-6583)
+## Removal of Filter and FilteredQuery (LUCENE-6301,LUCENE-6583)
 
-FilteredQuery has been removed. Instead, you can construct a BooleanQuery with
-one MUST clause for the query, and one FILTER clause for the filter.
+Filter and FilteredQuery have been removed. Regular queries can be used instead
+of filters as they have been optimized for the filtering case. And you can
+construct a BooleanQuery with one MUST clause for the query, and one FILTER
+clause for the filter in order to have similar behaviour to FilteredQuery.
 
 ## PhraseQuery and BooleanQuery made immutable (LUCENE-6531 LUCENE-6570)
 
diff --git a/lucene/core/src/java/org/apache/lucene/search/BitsFilteredDocIdSet.java b/lucene/core/src/java/org/apache/lucene/search/BitsFilteredDocIdSet.java
deleted file mode 100644
index 77829ae..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/BitsFilteredDocIdSet.java
+++ /dev/null
@@ -1,63 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.util.Objects;
-
-import org.apache.lucene.util.Bits;
-
-/**
- * This implementation supplies a filtered DocIdSet, that excludes all
- * docids which are not in a Bits instance. This is especially useful in
- * {@link org.apache.lucene.search.Filter} to apply the {@code acceptDocs}
- * passed to {@code getDocIdSet()} before returning the final DocIdSet.
- *
- * @see DocIdSet
- * @see org.apache.lucene.search.Filter
- */
-
-public final class BitsFilteredDocIdSet extends FilteredDocIdSet {
-
-  private final Bits acceptDocs;
-  
-  /**
-   * Convenience wrapper method: If {@code acceptDocs == null} it returns the original set without wrapping.
-   * @param set Underlying DocIdSet. If {@code null}, this method returns {@code null}
-   * @param acceptDocs Allowed docs, all docids not in this set will not be returned by this DocIdSet.
-   * If {@code null}, this method returns the original set without wrapping.
-   */
-  public static DocIdSet wrap(DocIdSet set, Bits acceptDocs) {
-    return (set == null || acceptDocs == null) ? set : new BitsFilteredDocIdSet(set, acceptDocs);
-  }
-  
-  /**
-   * Constructor.
-   * @param innerSet Underlying DocIdSet
-   * @param acceptDocs Allowed docs, all docids not in this set will not be returned by this DocIdSet
-   */
-  public BitsFilteredDocIdSet(DocIdSet innerSet, Bits acceptDocs) {
-    super(innerSet);
-    this.acceptDocs = Objects.requireNonNull(acceptDocs, "Bits must not be null");
-  }
-
-  @Override
-  protected boolean match(int docid) {
-    return acceptDocs.get(docid);
-  }
-
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/Filter.java b/lucene/core/src/java/org/apache/lucene/search/Filter.java
deleted file mode 100644
index 105e3bd..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/Filter.java
+++ /dev/null
@@ -1,135 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Set;
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.util.Bits;
-
-/**
- *  Convenient base class for building queries that only perform matching, but
- *  no scoring. The scorer produced by such queries always returns 0 as score.
- */
-public abstract class Filter extends Query {
-
-  private final boolean applyLazily;
-
-  /** Filter constructor. When {@code applyLazily} is true and the produced
-   *  {@link DocIdSet}s support {@link DocIdSet#bits() random-access}, Lucene
-   *  will only apply this filter after other clauses. */
-  protected Filter(boolean applyLazily) {
-    this.applyLazily = applyLazily;
-  }
-
-  /** Default Filter constructor that will use the
-   *  {@link DocIdSet#iterator() doc id set iterator} when consumed through
-   *  the {@link Query} API. */
-  protected Filter() {
-    this(false);
-  }
-
-  /**
-   * Creates a {@link DocIdSet} enumerating the documents that should be
-   * permitted in search results. <b>NOTE:</b> null can be
-   * returned if no documents are accepted by this Filter.
-   * <p>
-   * Note: This method will be called once per segment in
-   * the index during searching.  The returned {@link DocIdSet}
-   * must refer to document IDs for that segment, not for
-   * the top-level reader.
-   *
-   * @param context a {@link org.apache.lucene.index.LeafReaderContext} instance opened on the index currently
-   *         searched on. Note, it is likely that the provided reader info does not
-   *         represent the whole underlying index i.e. if the index has more than
-   *         one segment the given reader only represents a single segment.
-   *         The provided context is always an atomic context, so you can call
-   *         {@link org.apache.lucene.index.LeafReader#fields()}
-   *         on the context's reader, for example.
-   *
-   * @param acceptDocs
-   *          Bits that represent the allowable docs to match (typically deleted docs
-   *          but possibly filtering other documents)
-   *
-   * @return a DocIdSet that provides the documents which should be permitted or
-   *         prohibited in search results. <b>NOTE:</b> <code>null</code> should be returned if
-   *         the filter doesn't accept any documents otherwise internal optimization might not apply
-   *         in the case an <i>empty</i> {@link DocIdSet} is returned.
-   */
-  public abstract DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException;
-
-  //
-  // Query compatibility
-  //
-
-  @Override
-  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
-    return new Weight(this) {
-
-      @Override
-      public void extractTerms(Set<Term> terms) {}
-
-      @Override
-      public float getValueForNormalization() throws IOException {
-        return 0f;
-      }
-
-      @Override
-      public void normalize(float norm, float boost) {}
-
-      @Override
-      public Explanation explain(LeafReaderContext context, int doc) throws IOException {
-        final Scorer scorer = scorer(context);
-        final boolean match = (scorer != null && scorer.advance(doc) == doc);
-        if (match) {
-          assert scorer.score() == 0f;
-          return Explanation.match(0f, "Match on id " + doc);
-        } else {
-          return Explanation.match(0f, "No match on id " + doc);
-        }
-      }
-
-      @Override
-      public Scorer scorer(LeafReaderContext context) throws IOException {
-        final DocIdSet set = getDocIdSet(context, null);
-        if (set == null) {
-          return null;
-        }
-        if (applyLazily && set.bits() != null) {
-          final Bits bits = set.bits();
-          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());
-          final TwoPhaseIterator twoPhase = new TwoPhaseIterator(approximation) {
-            @Override
-            public boolean matches() throws IOException {
-              return bits.get(approximation.docID());
-            }
-          };
-          return new ConstantScoreScorer(this, 0f, twoPhase);
-        }
-        final DocIdSetIterator iterator = set.iterator();
-        if (iterator == null) {
-          return null;
-        }
-        return new ConstantScoreScorer(this, 0f, iterator);
-      }
-
-    };
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java b/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
deleted file mode 100644
index 628c099..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSet.java
+++ /dev/null
@@ -1,112 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.Collection;
-
-import org.apache.lucene.util.Accountable;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.RamUsageEstimator;
-
-/**
- * Abstract decorator class for a DocIdSet implementation
- * that provides on-demand filtering/validation
- * mechanism on a given DocIdSet.
- *
- * <p>
- * Technically, this same functionality could be achieved
- * with ChainedFilter (under queries/), however the
- * benefit of this class is it never materializes the full
- * bitset for the filter.  Instead, the {@link #match}
- * method is invoked on-demand, per docID visited during
- * searching.  If you know few docIDs will be visited, and
- * the logic behind {@link #match} is relatively costly,
- * this may be a better way to filter than ChainedFilter.
- *
- * @see DocIdSet
- */
-
-public abstract class FilteredDocIdSet extends DocIdSet {
-  private final DocIdSet _innerSet;
-  
-  /**
-   * Constructor.
-   * @param innerSet Underlying DocIdSet
-   */
-  public FilteredDocIdSet(DocIdSet innerSet) {
-    _innerSet = innerSet;
-  }
-
-  /** Return the wrapped {@link DocIdSet}. */
-  public DocIdSet getDelegate() {
-    return _innerSet;
-  }
-
-  @Override
-  public long ramBytesUsed() {
-    return RamUsageEstimator.NUM_BYTES_OBJECT_REF + _innerSet.ramBytesUsed();
-  }
-  
-  @Override
-  public Collection<Accountable> getChildResources() {
-    return _innerSet.getChildResources();
-  }
-
-  @Override
-  public Bits bits() throws IOException {
-    final Bits bits = _innerSet.bits();
-    return (bits == null) ? null : new Bits() {
-      @Override
-      public boolean get(int docid) {
-        return bits.get(docid) && FilteredDocIdSet.this.match(docid);
-      }
-
-      @Override
-      public int length() {
-        return bits.length();
-      }
-    };
-  }
-
-  /**
-   * Validation method to determine whether a docid should be in the result set.
-   * @param docid docid to be tested
-   * @return true if input docid should be in the result set, false otherwise.
-   */
-  protected abstract boolean match(int docid);
-
-  /**
-   * Implementation of the contract to build a DocIdSetIterator.
-   * @see DocIdSetIterator
-   * @see FilteredDocIdSetIterator
-   */
-  @Override
-  public DocIdSetIterator iterator() throws IOException {
-    final DocIdSetIterator iterator = _innerSet.iterator();
-    if (iterator == null) {
-      return null;
-    }
-    return new FilteredDocIdSetIterator(iterator) {
-      @Override
-      protected boolean match(int docid) {
-        return FilteredDocIdSet.this.match(docid);
-      }
-    };
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSetIterator.java b/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSetIterator.java
index 92a8735..016788f 100644
--- a/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSetIterator.java
+++ b/lucene/core/src/java/org/apache/lucene/search/FilteredDocIdSetIterator.java
@@ -22,8 +22,7 @@ import java.io.IOException;
 /**
  * Abstract decorator class of a DocIdSetIterator
  * implementation that provides on-demand filter/validation
- * mechanism on an underlying DocIdSetIterator.  See {@link
- * FilteredDocIdSet}.
+ * mechanism on an underlying DocIdSetIterator.
  */
 public abstract class FilteredDocIdSetIterator extends DocIdSetIterator {
   protected DocIdSetIterator _innerIter;
diff --git a/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java b/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
deleted file mode 100644
index 533b23f..0000000
--- a/lucene/core/src/java/org/apache/lucene/search/QueryWrapperFilter.java
+++ /dev/null
@@ -1,94 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.util.Bits;
-
-/** 
- * Constrains search results to only match those which also match a provided
- * query.  
- *
- * <p> This could be used, for example, with a {@link NumericRangeQuery} on a suitably
- * formatted date field to implement date filtering.  One could re-use a single
- * CachingWrapperFilter(QueryWrapperFilter) that matches, e.g., only documents modified 
- * within the last week.  This would only need to be reconstructed once per day.
- */
-public class QueryWrapperFilter extends Filter {
-  private final Query query;
-
-  /** Constructs a filter which only matches documents matching
-   * <code>query</code>.
-   */
-  public QueryWrapperFilter(Query query) {
-    if (query == null)
-      throw new NullPointerException("Query may not be null");
-    this.query = query;
-  }
-  
-  @Override
-  public Query rewrite(IndexReader reader) throws IOException {
-    return new BoostQuery(new ConstantScoreQuery(query), 0f);
-  }
-  
-  /** returns the inner Query */
-  public final Query getQuery() {
-    return query;
-  }
-
-  @Override
-  public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
-    // get a private context that is used to rewrite, createWeight and score eventually
-    final LeafReaderContext privateContext = context.reader().getContext();
-    final Weight weight = new IndexSearcher(privateContext).createNormalizedWeight(query, false);
-    
-    DocIdSet set = new DocIdSet() {
-      @Override
-      public DocIdSetIterator iterator() throws IOException {
-        return weight.scorer(privateContext);
-      }
-
-      @Override
-      public long ramBytesUsed() {
-        return 0L;
-      }
-    };
-    return BitsFilteredDocIdSet.wrap(set, acceptDocs);
-  }
-
-  @Override
-  public String toString(String field) {
-    return "QueryWrapperFilter(" + query.toString(field) + ")";
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (super.equals(o) == false) {
-      return false;
-    }
-    return this.query.equals(((QueryWrapperFilter)o).query);
-  }
-
-  @Override
-  public int hashCode() {
-    return 31 * super.hashCode() + query.hashCode();
-  }
-}
diff --git a/lucene/core/src/java/org/apache/lucene/search/package-info.java b/lucene/core/src/java/org/apache/lucene/search/package-info.java
index 899eb31..107a47f 100644
--- a/lucene/core/src/java/org/apache/lucene/search/package-info.java
+++ b/lucene/core/src/java/org/apache/lucene/search/package-info.java
@@ -500,8 +500,6 @@
  *           Weight object is an internal representation of the Query that allows the Query 
  *           to be reused by the IndexSearcher.</li>
  *       <li>The IndexSearcher that initiated the call.</li>     
- *       <li>A {@link org.apache.lucene.search.Filter Filter} for limiting the result set.
- *           Note, the Filter may be null.</li>                   
  *       <li>A {@link org.apache.lucene.search.Sort Sort} object for specifying how to sort
  *           the results if the standard score-based sort method is not desired.</li>                   
  *   </ol>       
@@ -509,8 +507,7 @@
  *    we call one of the search methods of the IndexSearcher, passing in the
  *    {@link org.apache.lucene.search.Weight Weight} object created by
  *    {@link org.apache.lucene.search.IndexSearcher#createNormalizedWeight(org.apache.lucene.search.Query,boolean)
- *     IndexSearcher.createNormalizedWeight(Query,boolean)}, 
- *    {@link org.apache.lucene.search.Filter Filter} and the number of results we want.
+ *     IndexSearcher.createNormalizedWeight(Query,boolean)} and the number of results we want.
  *    This method returns a {@link org.apache.lucene.search.TopDocs TopDocs} object,
  *    which is an internal collection of search results. The IndexSearcher creates
  *    a {@link org.apache.lucene.search.TopScoreDocCollector TopScoreDocCollector} and
diff --git a/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java b/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
index f6ccdc2..699803f 100644
--- a/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
+++ b/lucene/core/src/test/org/apache/lucene/search/JustCompileSearch.java
@@ -24,7 +24,6 @@ import org.apache.lucene.index.FieldInvertState;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.similarities.Similarity;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.PriorityQueue;
 
 /**
@@ -130,34 +129,6 @@ final class JustCompileSearch {
     
   }
 
-  static final class JustCompileFilter extends Filter {
-    // Filter is just an abstract class with no abstract methods. However it is
-    // still added here in case someone will add abstract methods in the future.
-    
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
-      return null;
-    }
-
-    @Override
-    public String toString(String field) {
-      return "JustCompileFilter";
-    }
-  }
-
-  static final class JustCompileFilteredDocIdSet extends FilteredDocIdSet {
-
-    public JustCompileFilteredDocIdSet(DocIdSet innerSet) {
-      super(innerSet);
-    }
-
-    @Override
-    protected boolean match(int docid) {
-      throw new UnsupportedOperationException(UNSUPPORTED_MSG);
-    }
-    
-  }
-
   static final class JustCompileFilteredDocIdSetIterator extends FilteredDocIdSetIterator {
 
     public JustCompileFilteredDocIdSetIterator(DocIdSetIterator innerIter) {
diff --git a/lucene/core/src/test/org/apache/lucene/search/MockFilter.java b/lucene/core/src/test/org/apache/lucene/search/MockFilter.java
deleted file mode 100644
index 9333226..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/MockFilter.java
+++ /dev/null
@@ -1,47 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.FixedBitSet;
-import org.apache.lucene.util.Bits;
-
-public class MockFilter extends Filter {
-  private boolean wasCalled;
-
-  @Override
-  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
-    wasCalled = true;
-    FixedBitSet bits = new FixedBitSet(context.reader().maxDoc());
-    return new BitDocIdSet(bits);
-  }
-
-  @Override
-  public String toString(String field) {
-    return "MockFilter";
-  }
-
-  public void clear() {
-    wasCalled = false;
-  }
-
-  public boolean wasCalled() {
-    return wasCalled;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/SingleDocTestFilter.java b/lucene/core/src/test/org/apache/lucene/search/SingleDocTestFilter.java
deleted file mode 100644
index eb6f640..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/SingleDocTestFilter.java
+++ /dev/null
@@ -1,59 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.FixedBitSet;
-
-public class SingleDocTestFilter extends Filter {
-  private int doc;
-
-  public SingleDocTestFilter(int doc) {
-    this.doc = doc;
-  }
-
-  @Override
-  public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-    FixedBitSet bits = new FixedBitSet(context.reader().maxDoc());
-    bits.set(doc);
-    if (acceptDocs != null && !acceptDocs.get(doc)) bits.clear(doc);
-    return new BitDocIdSet(bits);
-  }
-
-  @Override
-  public String toString(String field) {
-    return "SingleDocTestFilter(" + doc + ")";
-  }
-
-  @Override
-  public boolean equals(Object obj) {
-    if (super.equals(obj) == false) {
-      return false;
-    }
-    return doc == ((SingleDocTestFilter) obj).doc;
-  }
-
-  @Override
-  public int hashCode() {
-    return 31 * super.hashCode() + doc;
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
index 9015e37..1431cc0 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestCachingWrapperQuery.java
@@ -18,6 +18,7 @@ package org.apache.lucene.search;
  */
 
 import java.io.IOException;
+import java.util.concurrent.atomic.AtomicBoolean;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
@@ -39,7 +40,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
   DirectoryReader ir;
   IndexSearcher is;
   RandomIndexWriter iw;
-  
+
   @Override
   public void setUp() throws Exception {
     super.setUp();
@@ -60,7 +61,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
     ir = iw.getReader();
     is = newSearcher(ir);
   }
-  
+
   @Override
   public void tearDown() throws Exception {
     iw.close();
@@ -80,14 +81,14 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
     assertEquals(hits3.totalHits, hits4.totalHits);
     CheckHits.checkEqual(f1, hits3.scoreDocs, hits4.scoreDocs);
   }
-  
+
   /** test null iterator */
   public void testEmpty() throws Exception {
     BooleanQuery.Builder expected = new BooleanQuery.Builder();
     Query cached = new CachingWrapperQuery(expected.build(), MAYBE_CACHE_POLICY);
     assertQueryEquals(expected.build(), cached);
   }
-  
+
   /** test iterator returns NO_MORE_DOCS */
   public void testEmpty2() throws Exception {
     BooleanQuery.Builder expected = new BooleanQuery.Builder();
@@ -96,7 +97,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
     Query cached = new CachingWrapperQuery(expected.build(), MAYBE_CACHE_POLICY);
     assertQueryEquals(expected.build(), cached);
   }
-  
+
   /** test iterator returns single document */
   public void testSingle() throws Exception {
     for (int i = 0; i < 10; i++) {
@@ -106,7 +107,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
       assertQueryEquals(expected, cached);
     }
   }
-  
+
   /** test sparse filters (match single documents) */
   public void testSparse() throws Exception {
     for (int i = 0; i < 10; i++) {
@@ -118,15 +119,43 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
       assertQueryEquals(expected, cached);
     }
   }
-  
+
   /** test dense filters (match entire index) */
   public void testDense() throws Exception {
-    Query query = new MatchAllDocsQuery();
-    Filter expected = new QueryWrapperFilter(query);
+    Query expected = new MatchAllDocsQuery();
     Query cached = new CachingWrapperQuery(expected, MAYBE_CACHE_POLICY);
     assertQueryEquals(expected, cached);
   }
 
+  private static class MockQuery extends Query {
+
+    private final AtomicBoolean wasCalled = new AtomicBoolean();
+
+    public boolean wasCalled() {
+      return wasCalled.get();
+    }
+
+    public void clear() {
+      wasCalled.set(false);
+    }
+
+    @Override
+    public String toString(String field) {
+      return "Mock";
+    }
+
+    @Override
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return new ConstantScoreWeight(this) {
+        @Override
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          wasCalled.set(true);
+          return new ConstantScoreScorer(this, score(), DocIdSetIterator.all(context.reader().maxDoc()));
+        }
+      };
+    }
+  }
+
   public void testCachingWorks() throws Exception {
     Directory dir = newDirectory();
     RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
@@ -135,7 +164,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
     IndexReader reader = SlowCompositeReaderWrapper.wrap(DirectoryReader.open(dir));
     IndexSearcher searcher = newSearcher(reader);
     LeafReaderContext context = (LeafReaderContext) reader.getContext();
-    MockFilter filter = new MockFilter();
+    MockQuery filter = new MockQuery();
     CachingWrapperQuery cacher = new CachingWrapperQuery(filter, QueryCachingPolicy.ALWAYS_CACHE);
 
     // first time, nested filter is called
@@ -257,7 +286,7 @@ public class TestCachingWrapperQuery extends LuceneTestCase {
 
     reader = refreshReader(reader);
     searcher = newSearcher(reader, false);
-        
+
     docs = searcher.search(new ConstantScoreQuery(query), 1);
     assertEquals("[query + filter] Should find 2 hits...", 2, docs.totalHits);
     assertTrue(query.missCount > missCount);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java b/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
index ff5820a..65a2697 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestConstantScoreQuery.java
@@ -26,14 +26,12 @@ import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.MultiReader;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.similarities.ClassicSimilarity;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.LuceneTestCase;
 
@@ -130,31 +128,32 @@ public class TestConstantScoreQuery extends LuceneTestCase {
     }
   }
 
-  // a filter for which other queries don't have special rewrite rules
-  private static class FilterWrapper extends Filter {
+  // a query for which other queries don't have special rewrite rules
+  private static class QueryWrapper extends Query {
 
-    private final Filter in;
-    
-    FilterWrapper(Filter in) {
+    private final Query in;
+
+    QueryWrapper(Query in) {
       this.in = in;
     }
-    
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return in.getDocIdSet(context, acceptDocs);
-    }
 
     @Override
     public String toString(String field) {
-      return in.toString(field);
+      return "MockQuery";
     }
     
     @Override
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return in.createWeight(searcher, needsScores);
+    }
+
+    @Override
     public boolean equals(Object obj) {
       if (super.equals(obj) == false) {
         return false;
       }
-      return in.equals(((FilterWrapper) obj).in);
+      QueryWrapper that = (QueryWrapper) obj;
+      return in.equals(that.in);
     }
 
     @Override
@@ -175,7 +174,7 @@ public class TestConstantScoreQuery extends LuceneTestCase {
     IndexReader r = w.getReader();
     w.close();
 
-    Filter filterB = new FilterWrapper(new QueryWrapperFilter(new TermQuery(new Term("field", "b"))));
+    Query filterB = new QueryWrapper(new TermQuery(new Term("field", "b")));
     Query query = new ConstantScoreQuery(filterB);
 
     IndexSearcher s = newSearcher(r);
@@ -185,7 +184,7 @@ public class TestConstantScoreQuery extends LuceneTestCase {
         .build();
     assertEquals(1, s.search(filtered, 1).totalHits); // Query for field:b, Filter field:b
 
-    Filter filterA = new FilterWrapper(new QueryWrapperFilter(new TermQuery(new Term("field", "a"))));
+    Query filterA = new QueryWrapper(new TermQuery(new Term("field", "a")));
     query = new ConstantScoreQuery(filterA);
 
     filtered = new BooleanQuery.Builder()
@@ -198,35 +197,6 @@ public class TestConstantScoreQuery extends LuceneTestCase {
     d.close();
   }
 
-  // LUCENE-5307
-  // don't reuse the scorer of filters since they have been created with bulkScorer=false
-  public void testQueryWrapperFilter() throws IOException {
-    Directory d = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    Document doc = new Document();
-    doc.add(newStringField("field", "a", Field.Store.NO));
-    w.addDocument(doc);
-    IndexReader r = w.getReader();
-    w.close();
-
-    final Query wrapped = AssertingQuery.wrap(random(), new TermQuery(new Term("field", "a")));
-    Filter filter = new QueryWrapperFilter(wrapped);
-    IndexSearcher s = newSearcher(r);
-    assert s instanceof AssertingIndexSearcher;
-    // this used to fail
-    s.search(new ConstantScoreQuery(filter), new TotalHitCountCollector());
-    
-    // check the rewrite
-    Query rewritten = filter;
-    for (Query q = rewritten.rewrite(r); q != rewritten; q = rewritten.rewrite(r)) {
-      rewritten = q;
-    }
-    assertEquals(new BoostQuery(new ConstantScoreQuery(wrapped), 0), rewritten);
-    
-    r.close();
-    d.close();
-  }
-
   public void testPropagatesApproximations() throws IOException {
     Directory dir = newDirectory();
     RandomIndexWriter w = new RandomIndexWriter(random(), dir);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java
deleted file mode 100644
index f4b3e53..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestDateFilter.java
+++ /dev/null
@@ -1,197 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import org.apache.lucene.document.Field;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.document.DateTools;
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-
-import java.io.IOException;
-
-/**
- * DateFilter JUnit tests.
- * 
- * 
- */
-public class TestDateFilter extends LuceneTestCase {
- 
-  /**
-   *
-   */
-  public void testBefore() throws IOException {
-    // create an index
-    Directory indexStore = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), indexStore);
-    
-    long now = System.currentTimeMillis();
-    
-    Document doc = new Document();
-    // add time that is in the past
-    doc.add(newStringField("datefield", DateTools.timeToString(now - 1000, DateTools.Resolution.MILLISECOND), Field.Store.YES));
-    doc.add(newTextField("body", "Today is a very sunny day in New York City", Field.Store.YES));
-    writer.addDocument(doc);
-    
-    IndexReader reader = writer.getReader();
-    writer.close();
-    IndexSearcher searcher = newSearcher(reader);
-    
-    // filter that should preserve matches
-    // DateFilter df1 = DateFilter.Before("datefield", now);
-    Filter df1 = new QueryWrapperFilter(TermRangeQuery.newStringRange("datefield", DateTools
-        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), DateTools
-        .timeToString(now, DateTools.Resolution.MILLISECOND), false, true));
-    // filter that should discard matches
-    // DateFilter df2 = DateFilter.Before("datefield", now - 999999);
-    Filter df2 = new QueryWrapperFilter(TermRangeQuery.newStringRange("datefield", DateTools
-        .timeToString(0, DateTools.Resolution.MILLISECOND), DateTools
-        .timeToString(now - 2000, DateTools.Resolution.MILLISECOND), true,
-        false));
-    
-    // search something that doesn't exist with DateFilter
-    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
-    
-    // search for something that does exists
-    Query query2 = new TermQuery(new Term("body", "sunny"));
-    
-    ScoreDoc[] result;
-    
-    // ensure that queries return expected results without DateFilter first
-    result = searcher.search(query1, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    result = searcher.search(query2, 1000).scoreDocs;
-    assertEquals(1, result.length);
-    
-    // run queries with DateFilter
-    Query filtered = new BooleanQuery.Builder()
-        .add(query1, Occur.MUST)
-        .add(df1, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query1, Occur.MUST)
-        .add(df2, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query2, Occur.MUST)
-        .add(df1, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(1, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query2, Occur.MUST)
-        .add(df2, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    reader.close();
-    indexStore.close();
-  }
-  
-  /**
-   *
-   */
-  public void testAfter() throws IOException {
-    // create an index
-    Directory indexStore = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), indexStore);
-    
-    long now = System.currentTimeMillis();
-    
-    Document doc = new Document();
-    // add time that is in the future
-    doc.add(newStringField("datefield", DateTools.timeToString(now + 888888, DateTools.Resolution.MILLISECOND), Field.Store.YES));
-    doc.add(newTextField("body", "Today is a very sunny day in New York City", Field.Store.YES));
-    writer.addDocument(doc);
-    
-    IndexReader reader = writer.getReader();
-    writer.close();
-    IndexSearcher searcher = newSearcher(reader);
-    
-    // filter that should preserve matches
-    // DateFilter df1 = DateFilter.After("datefield", now);
-    Filter df1 = new QueryWrapperFilter(TermRangeQuery.newStringRange("datefield", DateTools
-        .timeToString(now, DateTools.Resolution.MILLISECOND), DateTools
-        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND), true,
-        false));
-    // filter that should discard matches
-    // DateFilter df2 = DateFilter.After("datefield", now + 999999);
-    Filter df2 = new QueryWrapperFilter(TermRangeQuery.newStringRange("datefield", DateTools
-        .timeToString(now + 999999, DateTools.Resolution.MILLISECOND),
-        DateTools.timeToString(now + 999999999,
-            DateTools.Resolution.MILLISECOND), false, true));
-    
-    // search something that doesn't exist with DateFilter
-    Query query1 = new TermQuery(new Term("body", "NoMatchForThis"));
-    
-    // search for something that does exists
-    Query query2 = new TermQuery(new Term("body", "sunny"));
-    
-    ScoreDoc[] result;
-    
-    // ensure that queries return expected results without DateFilter first
-    result = searcher.search(query1, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    result = searcher.search(query2, 1000).scoreDocs;
-    assertEquals(1, result.length);
-    
-    // run queries with DateFilter
-    Query filtered = new BooleanQuery.Builder()
-        .add(query1, Occur.MUST)
-        .add(df1, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query1, Occur.MUST)
-        .add(df2, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query2, Occur.MUST)
-        .add(df1, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(1, result.length);
-    
-    filtered = new BooleanQuery.Builder()
-        .add(query2, Occur.MUST)
-        .add(df2, Occur.FILTER)
-        .build();
-    result = searcher.search(filtered, 1000).scoreDocs;
-    assertEquals(0, result.length);
-    reader.close();
-    indexStore.close();
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java b/lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java
deleted file mode 100644
index ab2a4c9..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestDocIdSet.java
+++ /dev/null
@@ -1,196 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Iterator;
-
-import junit.framework.Assert;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestDocIdSet extends LuceneTestCase {
-  public void testFilteredDocIdSet() throws Exception {
-    final int maxdoc=10;
-    final DocIdSet innerSet = new DocIdSet() {
-
-      @Override
-      public long ramBytesUsed() {
-        return 0L;
-      }
-
-        @Override
-        public DocIdSetIterator iterator() {
-          return new DocIdSetIterator() {
-
-            int docid = -1;
-            
-            @Override
-            public int docID() {
-              return docid;
-            }
-            
-            @Override
-            public int nextDoc() {
-              docid++;
-              return docid < maxdoc ? docid : (docid = NO_MORE_DOCS);
-            }
-
-            @Override
-            public int advance(int target) throws IOException {
-              return slowAdvance(target);
-            }
-            
-            @Override
-            public long cost() {
-              return 1;
-            } 
-          };
-        } 
-      };
-
-
-    DocIdSet filteredSet = new FilteredDocIdSet(innerSet){
-        @Override
-        protected boolean match(int docid) {
-          return docid%2 == 0;  //validate only even docids
-        }
-      };
-
-    DocIdSetIterator iter = filteredSet.iterator();
-    ArrayList<Integer> list = new ArrayList<>();
-    int doc = iter.advance(3);
-    if (doc != DocIdSetIterator.NO_MORE_DOCS) {
-      list.add(Integer.valueOf(doc));
-      while((doc = iter.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
-        list.add(Integer.valueOf(doc));
-      }
-    }
-
-    int[] docs = new int[list.size()];
-    int c=0;
-    Iterator<Integer> intIter = list.iterator();
-    while(intIter.hasNext()) {
-      docs[c++] = intIter.next().intValue();
-    }
-    int[] answer = new int[]{4,6,8};
-    boolean same = Arrays.equals(answer, docs);
-    if (!same) {
-      System.out.println("answer: " + Arrays.toString(answer));
-      System.out.println("gotten: " + Arrays.toString(docs));
-      fail();
-    }
-  }
-  
-  public void testNullDocIdSet() throws Exception {
-    // Tests that if a Filter produces a null DocIdSet, which is given to
-    // IndexSearcher, everything works fine. This came up in LUCENE-1754.
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(newStringField("c", "val", Field.Store.NO));
-    writer.addDocument(doc);
-    IndexReader reader = writer.getReader();
-    writer.close();
-    
-    // First verify the document is searchable.
-    IndexSearcher searcher = newSearcher(reader);
-    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
-    
-    // Now search w/ a Filter which returns a null DocIdSet
-    Filter f = new Filter() {
-      @Override
-      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
-        return null;
-      }
-      @Override
-      public String toString(String field) {
-        return "nullDocIdSetFilter";
-      }
-    };
-
-    Query filtered = new BooleanQuery.Builder()
-        .add(new MatchAllDocsQuery(), Occur.MUST)
-        .add(f, Occur.FILTER)
-        .build();
-    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);
-    reader.close();
-    dir.close();
-  }
-
-  public void testNullIteratorFilteredDocIdSet() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(newStringField("c", "val", Field.Store.NO));
-    writer.addDocument(doc);
-    IndexReader reader = writer.getReader();
-    writer.close();
-    
-    // First verify the document is searchable.
-    IndexSearcher searcher = newSearcher(reader);
-    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
-    
-      // Now search w/ a Filter which returns a null DocIdSet
-    Filter f = new Filter() {
-      @Override
-      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
-        final DocIdSet innerNullIteratorSet = new DocIdSet() {
-          @Override
-          public DocIdSetIterator iterator() {
-            return null;
-          } 
-
-          @Override
-          public long ramBytesUsed() {
-            return 0L;
-          }
-        };
-        return new FilteredDocIdSet(innerNullIteratorSet) {
-          @Override
-          protected boolean match(int docid) {
-            return true;
-          }
-        };
-      }
-      @Override
-      public String toString(String field) {
-        return "nullDocIdSetFilter";
-      }
-    };
-    
-    Query filtered = new BooleanQuery.Builder()
-        .add(new MatchAllDocsQuery(), Occur.MUST)
-        .add(f, Occur.FILTER)
-        .build();
-    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);
-    reader.close();
-    dir.close();
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestFilterCachingPolicy.java b/lucene/core/src/test/org/apache/lucene/search/TestFilterCachingPolicy.java
deleted file mode 100644
index b487f77..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestFilterCachingPolicy.java
+++ /dev/null
@@ -1,56 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-import java.io.IOException;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestFilterCachingPolicy extends LuceneTestCase {
-
-  public void testLargeSegmentDetection() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
-    final int numDocs = atLeast(100);
-    for (int i = 0; i < numDocs; ++i) {
-      w.addDocument(new Document());
-    }
-    final IndexReader reader = w.getReader();
-    for (float minSizeRatio : new float[] {Float.MIN_VALUE, 0.01f, 0.1f, 0.9f}) {
-      final QueryCachingPolicy policy = new QueryCachingPolicy.CacheOnLargeSegments(0, minSizeRatio);
-      for (LeafReaderContext ctx : reader.leaves()) {
-        final Filter filter = new QueryWrapperFilter(new TermQuery(new Term("field", "value")));
-        final boolean shouldCache = policy.shouldCache(filter, ctx);
-        final float sizeRatio = (float) ctx.reader().maxDoc() / reader.maxDoc();
-        assertEquals(sizeRatio >= minSizeRatio, shouldCache);
-        assertTrue(new QueryCachingPolicy.CacheOnLargeSegments(numDocs, Float.MIN_VALUE).shouldCache(filter, ctx));
-        assertFalse(new QueryCachingPolicy.CacheOnLargeSegments(numDocs + 1, Float.MIN_VALUE).shouldCache(filter, ctx));
-      }
-    }
-    reader.close();
-    w.close();
-    dir.close();
-  }
-
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java b/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
index 514ff64..6e75359 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestNeedsScores.java
@@ -74,13 +74,6 @@ public class TestNeedsScores extends LuceneTestCase {
     assertEquals(5, searcher.search(constantScore, 5).totalHits);
   }
   
-  /** when converted to a filter */
-  public void testQueryWrapperFilter() throws Exception {
-    Query term = new TermQuery(new Term("field", "this"));
-    Filter filter = new QueryWrapperFilter(new AssertNeedsScores(term, false));
-    assertEquals(5, searcher.search(filter, 5).totalHits);
-  }
-  
   /** when not sorting by score */
   public void testSortByField() throws Exception {
     Query query = new AssertNeedsScores(new MatchAllDocsQuery(), false);
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestQueryCachingPolicy.java b/lucene/core/src/test/org/apache/lucene/search/TestQueryCachingPolicy.java
new file mode 100644
index 0000000..5fb5e97
--- /dev/null
+++ b/lucene/core/src/test/org/apache/lucene/search/TestQueryCachingPolicy.java
@@ -0,0 +1,56 @@
+package org.apache.lucene.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestQueryCachingPolicy extends LuceneTestCase {
+
+  public void testLargeSegmentDetection() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter w = new RandomIndexWriter(random(), dir);
+    final int numDocs = atLeast(100);
+    for (int i = 0; i < numDocs; ++i) {
+      w.addDocument(new Document());
+    }
+    final IndexReader reader = w.getReader();
+    for (float minSizeRatio : new float[] {Float.MIN_VALUE, 0.01f, 0.1f, 0.9f}) {
+      final QueryCachingPolicy policy = new QueryCachingPolicy.CacheOnLargeSegments(0, minSizeRatio);
+      for (LeafReaderContext ctx : reader.leaves()) {
+        final Query query = new TermQuery(new Term("field", "value"));
+        final boolean shouldCache = policy.shouldCache(query, ctx);
+        final float sizeRatio = (float) ctx.reader().maxDoc() / reader.maxDoc();
+        assertEquals(sizeRatio >= minSizeRatio, shouldCache);
+        assertTrue(new QueryCachingPolicy.CacheOnLargeSegments(numDocs, Float.MIN_VALUE).shouldCache(query, ctx));
+        assertFalse(new QueryCachingPolicy.CacheOnLargeSegments(numDocs + 1, Float.MIN_VALUE).shouldCache(query, ctx));
+      }
+    }
+    reader.close();
+    w.close();
+    dir.close();
+  }
+
+}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java b/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
deleted file mode 100644
index ef6d214..0000000
--- a/lucene/core/src/test/org/apache/lucene/search/TestQueryWrapperFilter.java
+++ /dev/null
@@ -1,229 +0,0 @@
-package org.apache.lucene.search;
-
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.lucene.document.Document;
-import org.apache.lucene.document.Field;
-import org.apache.lucene.document.Field.Store;
-import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BooleanClause.Occur;
-import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.English;
-import org.apache.lucene.util.LuceneTestCase;
-
-public class TestQueryWrapperFilter extends LuceneTestCase {
-
-  // a filter for which other queries don't have special rewrite rules
-  private static class FilterWrapper extends Filter {
-
-    private final Filter in;
-    
-    FilterWrapper(Filter in) {
-      this.in = in;
-    }
-    
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      return in.getDocIdSet(context, acceptDocs);
-    }
-
-    @Override
-    public String toString(String field) {
-      return in.toString(field);
-    }
-    
-    @Override
-    public boolean equals(Object obj) {
-      if (super.equals(obj) == false) {
-        return false;
-      }
-      return in.equals(((FilterWrapper) obj).in);
-    }
-
-    @Override
-    public int hashCode() {
-      return 31 * super.hashCode() + in.hashCode();
-    }
-  }
-
-  public void testBasic() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(newTextField("field", "value", Field.Store.NO));
-    writer.addDocument(doc);
-    IndexReader reader = writer.getReader();
-    writer.close();
-
-    TermQuery termQuery = new TermQuery(new Term("field", "value"));
-
-    // should not throw exception with primitive query
-    QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
-
-    IndexSearcher searcher = newSearcher(reader);
-    TopDocs hits = searcher.search(qwf, 10);
-    assertEquals(1, hits.totalHits);
-    hits = searcher.search(new FilterWrapper(qwf), 10);
-    assertEquals(1, hits.totalHits);
-
-    // should not throw exception with complex primitive query
-    BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder();
-    booleanQuery.add(termQuery, Occur.MUST);
-    booleanQuery.add(new TermQuery(new Term("field", "missing")),
-        Occur.MUST_NOT);
-    qwf = new QueryWrapperFilter(termQuery);
-
-    hits = searcher.search(qwf, 10);
-    assertEquals(1, hits.totalHits);
-    hits = searcher.search(new FilterWrapper(qwf), 10);
-    assertEquals(1, hits.totalHits);
-
-    // should not throw exception with non primitive Query (doesn't implement
-    // Query#createWeight)
-    qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));
-
-    hits = searcher.search(qwf, 10);
-    assertEquals(1, hits.totalHits);
-    hits = searcher.search(new FilterWrapper(qwf), 10);
-    assertEquals(1, hits.totalHits);
-
-    // test a query with no hits
-    termQuery = new TermQuery(new Term("field", "not_exist"));
-    qwf = new QueryWrapperFilter(termQuery);
-    hits = searcher.search(qwf, 10);
-    assertEquals(0, hits.totalHits);
-    hits = searcher.search(new FilterWrapper(qwf), 10);
-    assertEquals(0, hits.totalHits);
-    reader.close();
-    dir.close();
-  }
-
-  public void testRandom() throws Exception {
-    final Directory d = newDirectory();
-    final RandomIndexWriter w = new RandomIndexWriter(random(), d);
-    w.w.getConfig().setMaxBufferedDocs(17);
-    final int numDocs = atLeast(100);
-    final Set<String> aDocs = new HashSet<>();
-    for(int i=0;i<numDocs;i++) {
-      final Document doc = new Document();
-      final String v;
-      if (random().nextInt(5) == 4) {
-        v = "a";
-        aDocs.add(""+i);
-      } else {
-        v = "b";
-      }
-      final Field f = newStringField("field", v, Field.Store.NO);
-      doc.add(f);
-      doc.add(newStringField("id", ""+i, Field.Store.YES));
-      w.addDocument(doc);
-    }
-
-    final int numDelDocs = atLeast(10);
-    for(int i=0;i<numDelDocs;i++) {
-      final String delID = ""+random().nextInt(numDocs);
-      w.deleteDocuments(new Term("id", delID));
-      aDocs.remove(delID);
-    }
-
-    final IndexReader r = w.getReader();
-    w.close();
-    final TopDocs hits = newSearcher(r).search(new QueryWrapperFilter(new TermQuery(new Term("field", "a"))),
-                                                     numDocs);
-    assertEquals(aDocs.size(), hits.totalHits);
-    for(ScoreDoc sd: hits.scoreDocs) {
-      assertTrue(aDocs.contains(r.document(sd.doc).get("id")));
-    }
-    r.close();
-    d.close();
-  }
-  
-  public void testThousandDocuments() throws Exception {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    for (int i = 0; i < 1000; i++) {
-      Document doc = new Document();
-      doc.add(newStringField("field", English.intToEnglish(i), Field.Store.NO));
-      writer.addDocument(doc);
-    }
-    
-    IndexReader reader = writer.getReader();
-    writer.close();
-    
-    IndexSearcher searcher = newSearcher(reader);
-    
-    for (int i = 0; i < 1000; i++) {
-      TermQuery termQuery = new TermQuery(new Term("field", English.intToEnglish(i)));
-      QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
-      TopDocs td = searcher.search(qwf, 10);
-      assertEquals(1, td.totalHits);
-    }
-    
-    reader.close();
-    dir.close();
-  }
-
-  public void testScore() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(new StringField("foo", "bar", Store.NO));
-    writer.addDocument(doc);
-    writer.commit();
-    final IndexReader reader = writer.getReader();
-    writer.close();
-    final IndexSearcher searcher = new IndexSearcher(reader);
-    final Query query = new QueryWrapperFilter(new TermQuery(new Term("foo", "bar")));
-    final TopDocs topDocs = searcher.search(query, 1);
-    assertEquals(1, topDocs.totalHits);
-    assertEquals(0f, topDocs.scoreDocs[0].score, 0f);
-    reader.close();
-    dir.close();
-  }
-
-  public void testQueryWrapperFilterPropagatesApproximations() throws IOException {
-    Directory dir = newDirectory();
-    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
-    Document doc = new Document();
-    doc.add(new StringField("foo", "bar", Store.NO));
-    writer.addDocument(doc);
-    writer.commit();
-    final IndexReader reader = writer.getReader();
-    writer.close();
-    final IndexSearcher searcher = new IndexSearcher(reader);
-    searcher.setQueryCache(null); // to still have approximations
-    final Query query = new QueryWrapperFilter(new RandomApproximationQuery(new TermQuery(new Term("foo", "bar")), random()));
-    final Weight weight = searcher.createNormalizedWeight(query, random().nextBoolean());
-    final Scorer scorer = weight.scorer(reader.leaves().get(0));
-    assertNotNull(scorer.asTwoPhaseIterator());
-    reader.close();
-    dir.close();
-  }
-
-  public void testBasics() {
-    QueryUtils.check(new QueryWrapperFilter(new TermQuery(new Term("foo", "bar"))));
-  }
-}
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestScorerPerf.java b/lucene/core/src/test/org/apache/lucene/search/TestScorerPerf.java
index ff583d5..73ebd40 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestScorerPerf.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestScorerPerf.java
@@ -14,6 +14,7 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BitDocIdSet;
+import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
@@ -140,30 +141,35 @@ public class TestScorerPerf extends LuceneTestCase {
     }
   }
 
-  private static class BitSetFilter extends Filter {
+  private static class BitSetQuery extends Query {
+
     private final FixedBitSet docs;
 
-    BitSetFilter(FixedBitSet docs) {
+    BitSetQuery(FixedBitSet docs) {
       this.docs = docs;
     }
 
     @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      assertNull("acceptDocs should be null, as we have an index without deletions", acceptDocs);
-      return new BitDocIdSet(docs);
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return new ConstantScoreWeight(this) {
+        @Override
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          return new ConstantScoreScorer(this, score(), new BitSetIterator(docs, docs.approximateCardinality()));
+        }
+      };
     }
-
+    
     @Override
     public String toString(String field) {
       return "randomBitSetFilter";
     }
-  
+    
     @Override
     public boolean equals(Object obj) {
       if (super.equals(obj) == false) {
         return false;
       }
-      return docs == ((BitSetFilter) obj).docs;
+      return docs == ((BitSetQuery) obj).docs;
     }
 
     @Override
@@ -174,7 +180,7 @@ public class TestScorerPerf extends LuceneTestCase {
 
   FixedBitSet addClause(BooleanQuery.Builder bq, FixedBitSet result) {
     final FixedBitSet rnd = sets[random().nextInt(sets.length)];
-    Query q = new ConstantScoreQuery(new BitSetFilter(rnd));
+    Query q = new BitSetQuery(rnd);
     bq.add(q, BooleanClause.Occur.MUST);
     if (validate) {
       if (result==null) result = rnd.clone();
diff --git a/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java b/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
index 9ec83eb..d6b93d0 100644
--- a/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
+++ b/lucene/core/src/test/org/apache/lucene/search/TestSortRandom.java
@@ -36,10 +36,8 @@ import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
@@ -147,9 +145,8 @@ public class TestSortRandom extends LuceneTestCase {
         sort = new Sort(sf, SortField.FIELD_DOC);
       }
       final int hitCount = TestUtil.nextInt(random, 1, r.maxDoc() + 20);
-      final RandomFilter f = new RandomFilter(random.nextLong(), random.nextFloat(), docValues);
-      hits = s.search(new ConstantScoreQuery(f),
-                      hitCount, sort, random.nextBoolean(), random.nextBoolean());
+      final RandomQuery f = new RandomQuery(random.nextLong(), random.nextFloat(), docValues);
+      hits = s.search(f, hitCount, sort, random.nextBoolean(), random.nextBoolean());
 
       if (VERBOSE) {
         System.out.println("\nTEST: iter=" + iter + " " + hits.totalHits + " hits; topN=" + hitCount + "; reverse=" + reverse + "; sortMissingLast=" + sortMissingLast + " sort=" + sort);
@@ -218,35 +215,40 @@ public class TestSortRandom extends LuceneTestCase {
     dir.close();
   }
   
-  private static class RandomFilter extends Filter {
+  private static class RandomQuery extends Query {
     private final long seed;
     private float density;
     private final List<BytesRef> docValues;
     public final List<BytesRef> matchValues = Collections.synchronizedList(new ArrayList<BytesRef>());
 
     // density should be 0.0 ... 1.0
-    public RandomFilter(long seed, float density, List<BytesRef> docValues) {
+    public RandomQuery(long seed, float density, List<BytesRef> docValues) {
       this.seed = seed;
       this.density = density;
       this.docValues = docValues;
     }
 
     @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Random random = new Random(context.docBase ^ seed);
-      final int maxDoc = context.reader().maxDoc();
-      final NumericDocValues idSource = DocValues.getNumeric(context.reader(), "id");
-      assertNotNull(idSource);
-      final FixedBitSet bits = new FixedBitSet(maxDoc);
-      for(int docID=0;docID<maxDoc;docID++) {
-        if (random.nextFloat() <= density && (acceptDocs == null || acceptDocs.get(docID))) {
-          bits.set(docID);
-          //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
-          matchValues.add(docValues.get((int) idSource.get(docID)));
-        }
-      }
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return new ConstantScoreWeight(this) {
+        @Override
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          Random random = new Random(context.docBase ^ seed);
+          final int maxDoc = context.reader().maxDoc();
+          final NumericDocValues idSource = DocValues.getNumeric(context.reader(), "id");
+          assertNotNull(idSource);
+          final FixedBitSet bits = new FixedBitSet(maxDoc);
+          for(int docID=0;docID<maxDoc;docID++) {
+            if (random.nextFloat() <= density) {
+              bits.set(docID);
+              //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
+              matchValues.add(docValues.get((int) idSource.get(docID)));
+            }
+          }
 
-      return new BitDocIdSet(bits);
+          return new ConstantScoreScorer(this, score(), new BitSetIterator(bits, bits.approximateCardinality()));
+        }
+      };
     }
 
     @Override
@@ -259,7 +261,7 @@ public class TestSortRandom extends LuceneTestCase {
       if (super.equals(obj) == false) {
         return false;
       }
-      RandomFilter other = (RandomFilter) obj;
+      RandomQuery other = (RandomQuery) obj;
       return seed == other.seed && docValues == other.docValues;
     }
 
diff --git a/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java b/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
index 4548b5c..e244d1d 100644
--- a/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
+++ b/lucene/expressions/src/test/org/apache/lucene/expressions/TestExpressionSorts.java
@@ -32,11 +32,9 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.CheckHits;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TermQuery;
diff --git a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
index 0ab3d1e..7027269 100644
--- a/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
+++ b/lucene/facet/src/test/org/apache/lucene/facet/TestDrillSideways.java
@@ -39,31 +39,28 @@ import org.apache.lucene.facet.sortedset.SortedSetDocValuesReaderState;
 import org.apache.lucene.facet.taxonomy.TaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
 import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.IndexWriterConfig;
+import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RandomAccessWeight;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.SimpleCollector;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.Weight;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.IOUtils;
 import org.apache.lucene.util.InPlaceMergeSorter;
 import org.apache.lucene.util.InfoStream;
@@ -646,29 +643,45 @@ public class TestDrillSideways extends FacetTestCase {
         }
       }
 
-      Filter filter;
+      Query filter;
       if (random().nextInt(7) == 6) {
         if (VERBOSE) {
           System.out.println("  only-even filter");
         }
-        filter = new Filter() {
-            @Override
-            public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-              int maxDoc = context.reader().maxDoc();
-              final FixedBitSet bits = new FixedBitSet(maxDoc);
-              for(int docID=0;docID < maxDoc;docID++) {
-                // Keeps only the even ids:
-                if ((acceptDocs == null || acceptDocs.get(docID)) && (Integer.parseInt(context.reader().document(docID).get("id")) & 1) == 0) {
-                  bits.set(docID);
-                }
+        filter = new Query() {
+
+          @Override
+          public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+            return new RandomAccessWeight(this) {
+              @Override
+              protected Bits getMatchingDocs(final LeafReaderContext context) throws IOException {
+                return new Bits() {
+
+                  @Override
+                  public boolean get(int docID) {
+                    try {
+                      return (Integer.parseInt(context.reader().document(docID).get("id")) & 1) == 0;
+                    } catch (NumberFormatException | IOException e) {
+                      throw new RuntimeException(e);
+                    }
+                  }
+
+                  @Override
+                  public int length() {
+                    return context.reader().maxDoc();
+                  }
+                  
+                };
               }
-              return new BitDocIdSet(bits);
-            }
-            @Override
-            public String toString(String field) {
-              return "drillSidewaysTestFilter";
-            }
-          };
+            };
+          }
+
+          @Override
+          public String toString(String field) {
+            return "drillSidewaysTestFilter";
+          }
+
+        };
       } else {
         filter = null;
       }
@@ -865,7 +878,7 @@ public class TestDrillSideways extends FacetTestCase {
 
   private TestFacetResult slowDrillSidewaysSearch(IndexSearcher s, List<Doc> docs,
                                                         String contentToken, String[][] drillDowns,
-                                                        String[][] dimValues, Filter onlyEven) throws Exception {
+                                                        String[][] dimValues, Query onlyEven) throws Exception {
     int numDims = dimValues.length;
 
     List<Doc> hits = new ArrayList<>();
diff --git a/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java b/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java
index 06bcd2a..05f8453 100644
--- a/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java
+++ b/lucene/grouping/src/test/org/apache/lucene/search/grouping/GroupingSearchTest.java
@@ -28,10 +28,8 @@ import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.queries.function.valuesource.BytesRefFieldSource;
-import org.apache.lucene.search.CachingWrapperQuery;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
@@ -159,7 +157,7 @@ public class GroupingSearchTest extends LuceneTestCase {
     assertEquals(1, group.scoreDocs.length);
     assertEquals(6, group.scoreDocs[0].doc);
 
-    Filter lastDocInBlock = new QueryWrapperFilter(new TermQuery(new Term("groupend", "x")));
+    Query lastDocInBlock = new TermQuery(new Term("groupend", "x"));
     groupingSearch = new GroupingSearch(lastDocInBlock);
     groups = groupingSearch.search(indexSearcher, new TermQuery(new Term("content", "random")), 0, 10);
 
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
index 3689a81..ce05eed 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest.java
@@ -71,7 +71,6 @@ import org.apache.lucene.search.PhraseQuery;
 import org.apache.lucene.search.PhraseQuery.Builder;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.RegexpQuery;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TermRangeQuery;
@@ -585,8 +584,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
   
   public void testToParentBlockJoinQuery() throws Exception {
     BitSetProducer parentFilter = new QueryBitSetProducer(
-        new QueryWrapperFilter(
-          new TermQuery(new Term(FIELD_NAME, "parent"))));
+        new TermQuery(new Term(FIELD_NAME, "parent")));
     
     query = new ToParentBlockJoinQuery(new TermQuery(new Term(FIELD_NAME, "child")),
         parentFilter, ScoreMode.None);
@@ -611,8 +609,7 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
   
   public void testToChildBlockJoinQuery() throws Exception {
     BitSetProducer parentFilter = new QueryBitSetProducer(
-        new QueryWrapperFilter(
-          new TermQuery(new Term(FIELD_NAME, "parent"))));
+        new TermQuery(new Term(FIELD_NAME, "parent")));
     
     BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder();
     booleanQuery.add(new ToChildBlockJoinQuery(new TermQuery(
@@ -910,8 +907,8 @@ public class HighlighterTest extends BaseTokenStreamTestCase implements Formatte
         numHighlights = 0;
         if (random().nextBoolean()) {
           BooleanQuery.Builder bq = new BooleanQuery.Builder();
-          bq.add(new ConstantScoreQuery(new QueryWrapperFilter(new TermQuery(
-              new Term(FIELD_NAME, "kennedy")))), Occur.MUST);
+          bq.add(new ConstantScoreQuery(new TermQuery(
+              new Term(FIELD_NAME, "kennedy"))), Occur.MUST);
           bq.add(new ConstantScoreQuery(new TermQuery(new Term(FIELD_NAME, "kennedy"))), Occur.MUST);
           doSearching(bq.build());
         } else {
diff --git a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldQueryTest.java b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldQueryTest.java
index 32d881f..de7a9d5 100644
--- a/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldQueryTest.java
+++ b/lucene/highlighter/src/test/org/apache/lucene/search/vectorhighlight/FieldQueryTest.java
@@ -23,14 +23,11 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
-import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.BoostQuery;
 import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.PrefixQuery;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.RegexpQuery;
@@ -39,7 +36,6 @@ import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.search.WildcardQuery;
 import org.apache.lucene.search.vectorhighlight.FieldQuery.QueryPhraseMap;
 import org.apache.lucene.search.vectorhighlight.FieldTermStack.TermInfo;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 
 public class FieldQueryTest extends AbstractTestCase {
@@ -938,30 +934,6 @@ public class FieldQueryTest extends AbstractTestCase {
     new FieldQuery(q, reader, true, true );
   }
   
-  public void testFlattenFilteredQuery() throws Exception {
-    initBoost();
-    Filter filter = new Filter() {
-      @Override
-      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs)
-          throws IOException {
-        return null;
-      }
-      @Override
-      public String toString(String field) {
-        return "filterToBeFlattened";
-      }
-    };
-    Query query = new BooleanQuery.Builder()
-        .add(pqF( "A" ), Occur.MUST)
-        .add(filter, Occur.FILTER)
-        .build();
-    query = new BoostQuery(query, boost);
-    FieldQuery fq = new FieldQuery( query, true, true );
-    Set<Query> flatQueries = new HashSet<>();
-    fq.flatten( query, reader, flatQueries, 1f );
-    assertCollectionQueries( flatQueries, tq( boost, "A" ) );
-  }
-  
   public void testFlattenConstantScoreQuery() throws Exception {
     initBoost();
     Query query = new ConstantScoreQuery(pqF( "A" ));
diff --git a/lucene/join/src/java/org/apache/lucene/search/join/package-info.java b/lucene/join/src/java/org/apache/lucene/search/join/package-info.java
index 1356ba6..6133f99 100644
--- a/lucene/join/src/java/org/apache/lucene/search/join/package-info.java
+++ b/lucene/join/src/java/org/apache/lucene/search/join/package-info.java
@@ -29,7 +29,7 @@
  * 
  * <p>When you index in this way, the documents in your index are divided
  *   into parent documents (the last document of each block) and child
- *   documents (all others).  You provide a {@link org.apache.lucene.search.Filter} that identifies the
+ *   documents (all others).  You provide a {@link org.apache.lucene.search.join.BitSetProducer} that identifies the
  *   parent documents, as Lucene does not currently record any information
  *   about doc blocks.</p>
  * 
diff --git a/lucene/join/src/test/org/apache/lucene/search/join/TestCheckJoinIndex.java b/lucene/join/src/test/org/apache/lucene/search/join/TestCheckJoinIndex.java
index 2d76482..214c103 100644
--- a/lucene/join/src/test/org/apache/lucene/search/join/TestCheckJoinIndex.java
+++ b/lucene/join/src/test/org/apache/lucene/search/join/TestCheckJoinIndex.java
@@ -30,7 +30,6 @@ import org.apache.lucene.index.NoMergePolicy;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.search.MatchNoDocsQuery;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.LuceneTestCase;
@@ -88,7 +87,7 @@ public class TestCheckJoinIndex extends LuceneTestCase {
 
     final IndexReader reader = w.getReader();
     w.close();
-    BitSetProducer parentsFilter = new QueryBitSetProducer(new QueryWrapperFilter(new TermQuery(new Term("parent", "true"))));
+    BitSetProducer parentsFilter = new QueryBitSetProducer(new TermQuery(new Term("parent", "true")));
     try {
       CheckJoinIndex.check(reader, parentsFilter);
       fail("Invalid index");
@@ -128,7 +127,7 @@ public class TestCheckJoinIndex extends LuceneTestCase {
     final IndexReader reader = w.getReader();
     w.close();
 
-    BitSetProducer parentsFilter = new QueryBitSetProducer(new QueryWrapperFilter(new TermQuery(new Term("parent", "true"))));
+    BitSetProducer parentsFilter = new QueryBitSetProducer(new TermQuery(new Term("parent", "true")));
     try {
       CheckJoinIndex.check(reader, parentsFilter);
       fail("Invalid index");
diff --git a/lucene/misc/src/java/org/apache/lucene/search/BlockJoinComparatorSource.java b/lucene/misc/src/java/org/apache/lucene/search/BlockJoinComparatorSource.java
index 6463bfa..e0b9f19 100644
--- a/lucene/misc/src/java/org/apache/lucene/search/BlockJoinComparatorSource.java
+++ b/lucene/misc/src/java/org/apache/lucene/search/BlockJoinComparatorSource.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.SortingMergePolicy;
-import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSet;
 
 /**
@@ -38,7 +37,7 @@ import org.apache.lucene.util.BitSet;
 // TODO: can/should we clean this thing up (e.g. return a proper sort value)
 // and move to the join/ module?
 public class BlockJoinComparatorSource extends FieldComparatorSource {
-  final Filter parentsFilter;
+  final Query parentsFilter;
   final Sort parentSort;
   final Sort childSort;
 
@@ -49,7 +48,7 @@ public class BlockJoinComparatorSource extends FieldComparatorSource {
    * @param parentsFilter Filter identifying parent documents
    * @param parentSort Sort for parent documents
    */
-  public BlockJoinComparatorSource(Filter parentsFilter, Sort parentSort) {
+  public BlockJoinComparatorSource(Query parentsFilter, Sort parentSort) {
     this(parentsFilter, parentSort, new Sort(SortField.FIELD_DOC));
   }
 
@@ -61,7 +60,7 @@ public class BlockJoinComparatorSource extends FieldComparatorSource {
    * @param parentSort Sort for parent documents
    * @param childSort Sort for child documents in the same block
    */
-  public BlockJoinComparatorSource(Filter parentsFilter, Sort parentSort, Sort childSort) {
+  public BlockJoinComparatorSource(Query parentsFilter, Sort parentSort, Sort childSort) {
     this.parentsFilter = parentsFilter;
     this.parentSort = parentSort;
     this.childSort = childSort;
@@ -119,14 +118,14 @@ public class BlockJoinComparatorSource extends FieldComparatorSource {
         if (parentBits != null) {
           throw new IllegalStateException("This comparator can only be used on a single segment");
         }
-        final DocIdSet parents = parentsFilter.getDocIdSet(context, null);
+        IndexSearcher searcher = new IndexSearcher(context.reader());
+        searcher.setQueryCache(null);
+        final Weight weight = searcher.createNormalizedWeight(parentsFilter, false);
+        final DocIdSetIterator parents = weight.scorer(context);
         if (parents == null) {
           throw new IllegalStateException("LeafReader " + context.reader() + " contains no parents!");
         }
-        if (parents instanceof BitDocIdSet == false) {
-          throw new IllegalStateException("parentFilter must return BitSet; got " + parents);
-        }
-        parentBits = (BitSet) parents.bits();
+        parentBits = BitSet.of(parents, context.reader().maxDoc());
         parentLeafComparators = new LeafFieldComparator[parentComparators.length];
         for (int i = 0; i < parentComparators.length; i++) {
           parentLeafComparators[i] = parentComparators[i].getLeafComparator(context);
diff --git a/lucene/misc/src/test/org/apache/lucene/index/TestBlockJoinSorter.java b/lucene/misc/src/test/org/apache/lucene/index/TestBlockJoinSorter.java
index 006f2ad..5a83d07 100644
--- a/lucene/misc/src/test/org/apache/lucene/index/TestBlockJoinSorter.java
+++ b/lucene/misc/src/test/org/apache/lucene/index/TestBlockJoinSorter.java
@@ -17,94 +17,29 @@ package org.apache.lucene.index;
  * limitations under the License.
  */
 
-import static org.apache.lucene.search.DocIdSet.EMPTY;
-
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
-import java.util.Map;
-import java.util.WeakHashMap;
 
 import org.apache.lucene.analysis.MockAnalyzer;
 import org.apache.lucene.document.Document;
 import org.apache.lucene.document.Field.Store;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.StringField;
-import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.IndexWriterConfig;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.index.RandomIndexWriter;
-import org.apache.lucene.index.Term;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.BlockJoinComparatorSource;
-import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.ArrayUtil;
-import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSet;
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
-import org.apache.lucene.util.SparseFixedBitSet;
 
 public class TestBlockJoinSorter extends LuceneTestCase {
 
-  private static class BitSetCachingWrapperFilter extends Filter {
-
-    private final Filter filter;
-    private final Map<Object,BitDocIdSet> cache = Collections.synchronizedMap(new WeakHashMap<Object,BitDocIdSet>());
-
-    public BitSetCachingWrapperFilter(Filter filter) {
-      this.filter = filter;
-    }
-
-    @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, final Bits acceptDocs) throws IOException {
-      final LeafReader reader = context.reader();
-      final Object key = reader.getCoreCacheKey();
-
-      BitDocIdSet docIdSet = cache.get(key);
-      if (docIdSet == null) {
-        final DocIdSet uncached = filter.getDocIdSet(context, null);
-        final DocIdSetIterator it = uncached == null ? null : uncached.iterator();
-        if (it != null) {
-          docIdSet = new BitDocIdSet(BitSet.of(it, context.reader().maxDoc()));
-        }
-        if (docIdSet == null) {
-          docIdSet = new BitDocIdSet(new SparseFixedBitSet(context.reader().maxDoc()));
-        }
-        cache.put(key, docIdSet);
-      }
-
-      return docIdSet == EMPTY ? null : BitsFilteredDocIdSet.wrap(docIdSet, acceptDocs);
-    }
-
-    @Override
-    public boolean equals(Object obj) {
-      if (super.equals(obj) == false) {
-        return false;
-      }
-      return filter.equals(((BitSetCachingWrapperFilter) obj).filter);
-    }
-
-    @Override
-    public int hashCode() {
-      return 31 * super.hashCode() + filter.hashCode();
-    }
-
-    @Override
-    public String toString(String field) {
-      return getClass().getName() + "(" + filter.toString(field) + ")";
-    }
-  }
-
   public void test() throws IOException {
     final int numParents = atLeast(200);
     IndexWriterConfig cfg = newIndexWriterConfig(new MockAnalyzer(random()));
@@ -132,8 +67,11 @@ public class TestBlockJoinSorter extends LuceneTestCase {
     writer.close();
 
     final LeafReader reader = getOnlySegmentReader(indexReader);
-    final Filter parentsFilter = new BitSetCachingWrapperFilter(new QueryWrapperFilter(new TermQuery(new Term("parent", "true"))));
-    final FixedBitSet parentBits = (FixedBitSet) parentsFilter.getDocIdSet(reader.getContext(), null).bits();
+    final Query parentsFilter = new TermQuery(new Term("parent", "true"));
+    IndexSearcher searcher = newSearcher(reader);
+    final Weight weight = searcher.createNormalizedWeight(parentsFilter, false);
+    final DocIdSetIterator parents = weight.scorer(reader.getContext());
+    final BitSet parentBits = BitSet.of(parents, reader.maxDoc());
     final NumericDocValues parentValues = reader.getNumericDocValues("parent_val");
     final NumericDocValues childValues = reader.getNumericDocValues("child_val");
 
diff --git a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
index 085b440..1c9b7d7 100644
--- a/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
+++ b/lucene/misc/src/test/org/apache/lucene/uninverting/TestFieldCacheSortRandom.java
@@ -39,17 +39,19 @@ import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.index.NumericDocValues;
 import org.apache.lucene.index.RandomIndexWriter;
 import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.ConstantScoreScorer;
+import org.apache.lucene.search.ConstantScoreWeight;
 import org.apache.lucene.search.FieldDoc;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.search.TopFieldDocs;
+import org.apache.lucene.search.Weight;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
-import org.apache.lucene.util.BitDocIdSet;
-import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
 import org.apache.lucene.util.LuceneTestCase;
@@ -160,7 +162,7 @@ public class TestFieldCacheSortRandom extends LuceneTestCase {
         sort = new Sort(sf, SortField.FIELD_DOC);
       }
       final int hitCount = TestUtil.nextInt(random, 1, r.maxDoc() + 20);
-      final RandomFilter f = new RandomFilter(random.nextLong(), random.nextFloat(), docValues);
+      final RandomQuery f = new RandomQuery(random.nextLong(), random.nextFloat(), docValues);
       int queryType = random.nextInt(2);
       if (queryType == 0) {
         hits = s.search(new ConstantScoreQuery(f),
@@ -251,35 +253,40 @@ public class TestFieldCacheSortRandom extends LuceneTestCase {
     dir.close();
   }
   
-  private static class RandomFilter extends Filter {
+  private static class RandomQuery extends Query {
     private final long seed;
     private float density;
     private final List<BytesRef> docValues;
     public final List<BytesRef> matchValues = Collections.synchronizedList(new ArrayList<BytesRef>());
 
     // density should be 0.0 ... 1.0
-    public RandomFilter(long seed, float density, List<BytesRef> docValues) {
+    public RandomQuery(long seed, float density, List<BytesRef> docValues) {
       this.seed = seed;
       this.density = density;
       this.docValues = docValues;
     }
 
     @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      Random random = new Random(seed ^ context.docBase);
-      final int maxDoc = context.reader().maxDoc();
-      final NumericDocValues idSource = DocValues.getNumeric(context.reader(), "id");
-      assertNotNull(idSource);
-      final FixedBitSet bits = new FixedBitSet(maxDoc);
-      for(int docID=0;docID<maxDoc;docID++) {
-        if (random.nextFloat() <= density && (acceptDocs == null || acceptDocs.get(docID))) {
-          bits.set(docID);
-          //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
-          matchValues.add(docValues.get((int) idSource.get(docID)));
-        }
-      }
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return new ConstantScoreWeight(this) {
+        @Override
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          Random random = new Random(seed ^ context.docBase);
+          final int maxDoc = context.reader().maxDoc();
+          final NumericDocValues idSource = DocValues.getNumeric(context.reader(), "id");
+          assertNotNull(idSource);
+          final FixedBitSet bits = new FixedBitSet(maxDoc);
+          for(int docID=0;docID<maxDoc;docID++) {
+            if (random.nextFloat() <= density) {
+              bits.set(docID);
+              //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
+              matchValues.add(docValues.get((int) idSource.get(docID)));
+            }
+          }
 
-      return new BitDocIdSet(bits);
+          return new ConstantScoreScorer(this, score(), new BitSetIterator(bits, bits.approximateCardinality()));
+        }
+      };
     }
 
     @Override
@@ -292,7 +299,7 @@ public class TestFieldCacheSortRandom extends LuceneTestCase {
       if (super.equals(obj) == false) {
         return false;
       }
-      RandomFilter other = (RandomFilter) obj;
+      RandomQuery other = (RandomQuery) obj;
       return seed == other.seed && docValues == other.docValues;
     }
 
diff --git a/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java b/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java
index cf4561e..6b1538c 100644
--- a/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java
+++ b/lucene/sandbox/src/test/org/apache/lucene/search/TestTermAutomatonQuery.java
@@ -47,6 +47,7 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.store.Directory;
 import org.apache.lucene.util.BitDocIdSet;
+import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.FixedBitSet;
@@ -584,7 +585,7 @@ public class TestTermAutomatonQuery extends LuceneTestCase {
         if (VERBOSE) {
           System.out.println("  use random filter");
         }
-        RandomFilter filter = new RandomFilter(random().nextLong(), random().nextFloat());
+        RandomQuery filter = new RandomQuery(random().nextLong(), random().nextFloat());
         q1 = new BooleanQuery.Builder()
             .add(q1, Occur.MUST)
             .add(filter, Occur.FILTER)
@@ -630,29 +631,33 @@ public class TestTermAutomatonQuery extends LuceneTestCase {
     return result;
   }
 
-  private static class RandomFilter extends Filter {
+  private static class RandomQuery extends Query {
     private final long seed;
     private float density;
 
     // density should be 0.0 ... 1.0
-    public RandomFilter(long seed, float density) {
+    public RandomQuery(long seed, float density) {
       this.seed = seed;
       this.density = density;
     }
 
     @Override
-    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
-      int maxDoc = context.reader().maxDoc();
-      FixedBitSet bits = new FixedBitSet(maxDoc);
-      Random random = new Random(seed ^ context.docBase);
-      for(int docID=0;docID<maxDoc;docID++) {
-        if (random.nextFloat() <= density && (acceptDocs == null || acceptDocs.get(docID))) {
-          bits.set(docID);
-          //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
+    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+      return new ConstantScoreWeight(this) {
+        @Override
+        public Scorer scorer(LeafReaderContext context) throws IOException {
+          int maxDoc = context.reader().maxDoc();
+          FixedBitSet bits = new FixedBitSet(maxDoc);
+          Random random = new Random(seed ^ context.docBase);
+          for(int docID=0;docID<maxDoc;docID++) {
+            if (random.nextFloat() <= density) {
+              bits.set(docID);
+              //System.out.println("  acc id=" + idSource.getInt(docID) + " docID=" + docID);
+            }
+          }
+          return new ConstantScoreScorer(this, score(), new BitSetIterator(bits, bits.approximateCardinality()));
         }
-      }
-
-      return new BitDocIdSet(bits);
+      };
     }
 
     @Override
@@ -665,7 +670,7 @@ public class TestTermAutomatonQuery extends LuceneTestCase {
       if (super.equals(obj) == false) {
         return false;
       }
-      RandomFilter other = (RandomFilter) obj;
+      RandomQuery other = (RandomQuery) obj;
       return seed == other.seed && density == other.density;
     }
 
diff --git a/solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java b/solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
index 065216c..78b9f5c 100644
--- a/solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
+++ b/solr/contrib/analytics/src/java/org/apache/solr/analytics/accumulator/FacetingAccumulator.java
@@ -34,7 +34,6 @@ import java.util.TreeMap;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
 import org.apache.solr.analytics.accumulator.facet.FacetValueAccumulator;
 import org.apache.solr.analytics.accumulator.facet.FieldFacetAccumulator;
@@ -58,6 +57,7 @@ import org.apache.solr.common.util.NamedList;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.QParser;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.search.SyntaxError;
diff --git a/solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java b/solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
index 3ea48fe..2f02fa0 100644
--- a/solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
+++ b/solr/contrib/analytics/src/java/org/apache/solr/analytics/request/AnalyticsStats.java
@@ -23,7 +23,6 @@ import java.util.List;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.solr.analytics.accumulator.BasicAccumulator;
 import org.apache.solr.analytics.accumulator.FacetingAccumulator;
 import org.apache.solr.analytics.accumulator.ValueAccumulator;
@@ -32,6 +31,7 @@ import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.request.SolrQueryRequest;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
diff --git a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java
index 5014619..b52b209 100644
--- a/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java
+++ b/solr/contrib/dataimporthandler/src/test/org/apache/solr/handler/dataimport/TestHierarchicalDocBuilder.java
@@ -31,7 +31,6 @@ import org.apache.lucene.index.Term;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.search.join.QueryBitSetProducer;
@@ -460,7 +459,7 @@ public class TestHierarchicalDocBuilder extends AbstractDataImportHandlerTestCas
   private BitSetProducer createParentFilter(String type) {
     BooleanQuery.Builder parentQuery = new BooleanQuery.Builder();
     parentQuery.add(new TermQuery(new Term("type_s", type)), Occur.MUST);
-    return new QueryBitSetProducer(new QueryWrapperFilter(parentQuery.build()));
+    return new QueryBitSetProducer(parentQuery.build());
   }
   
   private String nextId() {
diff --git a/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java b/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
index 6243df5..bf48ee5 100644
--- a/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
+++ b/solr/core/src/java/org/apache/solr/handler/component/ExpandComponent.java
@@ -54,7 +54,7 @@ import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
+import org.apache.solr.search.QueryWrapperFilter;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.Sort;
diff --git a/solr/core/src/java/org/apache/solr/query/SolrRangeQuery.java b/solr/core/src/java/org/apache/solr/query/SolrRangeQuery.java
index b9493b7..fc28459 100644
--- a/solr/core/src/java/org/apache/solr/query/SolrRangeQuery.java
+++ b/solr/core/src/java/org/apache/solr/query/SolrRangeQuery.java
@@ -37,14 +37,12 @@ import org.apache.lucene.search.ConstantScoreScorer;
 import org.apache.lucene.search.ConstantScoreWeight;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.AttributeSource;
-import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.DocIdSetBuilder;
 import org.apache.lucene.util.FixedBitSet;
@@ -53,7 +51,7 @@ import org.apache.solr.search.DocSet;
 import org.apache.solr.search.DocSetBuilder;
 import org.apache.solr.search.DocSetProducer;
 import org.apache.solr.search.ExtendedQueryBase;
-import org.apache.solr.search.SolrConstantScoreQuery;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 
 /** @lucene.experimental */
diff --git a/solr/core/src/java/org/apache/solr/request/DocValuesFacets.java b/solr/core/src/java/org/apache/solr/request/DocValuesFacets.java
index 1efd8f3..04709a1 100644
--- a/solr/core/src/java/org/apache/solr/request/DocValuesFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/DocValuesFacets.java
@@ -26,7 +26,6 @@ import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRefBuilder;
@@ -37,6 +36,7 @@ import org.apache.solr.common.util.NamedList;
 import org.apache.solr.schema.FieldType;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.LongPriorityQueue;
 
diff --git a/solr/core/src/java/org/apache/solr/request/DocValuesStats.java b/solr/core/src/java/org/apache/solr/request/DocValuesStats.java
index 5405c52..60cf32d 100644
--- a/solr/core/src/java/org/apache/solr/request/DocValuesStats.java
+++ b/solr/core/src/java/org/apache/solr/request/DocValuesStats.java
@@ -30,7 +30,6 @@ import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.LongValues;
 import org.apache.solr.common.SolrException;
@@ -41,6 +40,7 @@ import org.apache.solr.handler.component.StatsValuesFactory;
 import org.apache.solr.schema.FieldType;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 
 /**
diff --git a/solr/core/src/java/org/apache/solr/request/IntervalFacets.java b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
index fe4cee0..257b398 100644
--- a/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java
@@ -17,7 +17,6 @@ import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.NumericUtils;
@@ -30,6 +29,7 @@ import org.apache.solr.schema.SchemaField;
 import org.apache.solr.schema.TrieDateField;
 import org.apache.solr.search.DocIterator;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.QueryParsing;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.search.SyntaxError;
diff --git a/solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting.java b/solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting.java
index 3c5821b..54513ed 100644
--- a/solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting.java
+++ b/solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting.java
@@ -23,7 +23,6 @@ import org.apache.lucene.index.SortedDocValues;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
 import org.apache.lucene.util.CharsRefBuilder;
@@ -34,6 +33,7 @@ import org.apache.solr.common.params.FacetParams;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.schema.FieldType;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.BoundedTreeSet;
 
diff --git a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
index cebf640..0001890 100644
--- a/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
+++ b/solr/core/src/java/org/apache/solr/request/SimpleFacets.java
@@ -29,7 +29,6 @@ import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilterCollector;
 import org.apache.lucene.search.LeafCollector;
 import org.apache.lucene.search.Query;
@@ -62,6 +61,7 @@ import org.apache.solr.schema.SchemaField;
 import org.apache.solr.schema.TrieField;
 import org.apache.solr.search.BitDocSet;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.Grouping;
 import org.apache.solr.search.HashDocSet;
 import org.apache.solr.search.Insanity;
diff --git a/solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java b/solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java
index b27be14..83c204f 100644
--- a/solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java
+++ b/solr/core/src/java/org/apache/solr/response/transform/ChildDocTransformerFactory.java
@@ -21,7 +21,6 @@ import java.io.IOException;
 import org.apache.lucene.index.StorableField;
 import org.apache.lucene.index.StoredDocument;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.join.QueryBitSetProducer;
 import org.apache.lucene.search.join.BitSetProducer;
@@ -38,6 +37,7 @@ import org.apache.solr.schema.SchemaField;
 import org.apache.solr.search.DocIterator;
 import org.apache.solr.search.DocList;
 import org.apache.solr.search.QParser;
+import org.apache.solr.search.QueryWrapperFilter;
 import org.apache.solr.search.SyntaxError;
 
 /**
diff --git a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
index 8980068..5a81e26 100644
--- a/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
+++ b/solr/core/src/java/org/apache/solr/schema/CurrencyField.java
@@ -42,15 +42,15 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.FieldValueQuery;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.SortField;
 import org.apache.lucene.uninverting.UninvertingReader.Type;
 import org.apache.solr.common.SolrException;
 import org.apache.solr.common.SolrException.ErrorCode;
 import org.apache.solr.response.TextResponseWriter;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.QParser;
+import org.apache.solr.search.QueryWrapperFilter;
 import org.apache.solr.search.SolrConstantScoreQuery;
 import org.apache.solr.search.function.ValueSourceRangeFilter;
 import org.slf4j.Logger;
diff --git a/solr/core/src/java/org/apache/solr/search/BitDocSet.java b/solr/core/src/java/org/apache/solr/search/BitDocSet.java
index 9f4ca21..5f4ee22 100644
--- a/solr/core/src/java/org/apache/solr/search/BitDocSet.java
+++ b/solr/core/src/java/org/apache/solr/search/BitDocSet.java
@@ -22,10 +22,8 @@ import java.util.Collections;
 
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.BitSetIterator;
diff --git a/solr/core/src/java/org/apache/solr/search/BitsFilteredDocIdSet.java b/solr/core/src/java/org/apache/solr/search/BitsFilteredDocIdSet.java
new file mode 100644
index 0000000..6aa53e6
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/search/BitsFilteredDocIdSet.java
@@ -0,0 +1,63 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.util.Objects;
+
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.util.Bits;
+
+/**
+ * This implementation supplies a filtered DocIdSet, that excludes all
+ * docids which are not in a Bits instance. This is especially useful in
+ * {@link org.apache.solr.search.Filter} to apply the {@code acceptDocs}
+ * passed to {@code getDocIdSet()} before returning the final DocIdSet.
+ *
+ * @see DocIdSet
+ * @see org.apache.solr.search.Filter
+ */
+public final class BitsFilteredDocIdSet extends FilteredDocIdSet {
+
+  private final Bits acceptDocs;
+  
+  /**
+   * Convenience wrapper method: If {@code acceptDocs == null} it returns the original set without wrapping.
+   * @param set Underlying DocIdSet. If {@code null}, this method returns {@code null}
+   * @param acceptDocs Allowed docs, all docids not in this set will not be returned by this DocIdSet.
+   * If {@code null}, this method returns the original set without wrapping.
+   */
+  public static DocIdSet wrap(DocIdSet set, Bits acceptDocs) {
+    return (set == null || acceptDocs == null) ? set : new BitsFilteredDocIdSet(set, acceptDocs);
+  }
+  
+  /**
+   * Constructor.
+   * @param innerSet Underlying DocIdSet
+   * @param acceptDocs Allowed docs, all docids not in this set will not be returned by this DocIdSet
+   */
+  public BitsFilteredDocIdSet(DocIdSet innerSet, Bits acceptDocs) {
+    super(innerSet);
+    this.acceptDocs = Objects.requireNonNull(acceptDocs, "Bits must not be null");
+  }
+
+  @Override
+  protected boolean match(int docid) {
+    return acceptDocs.get(docid);
+  }
+
+}
diff --git a/solr/core/src/java/org/apache/solr/search/DocSet.java b/solr/core/src/java/org/apache/solr/search/DocSet.java
index de98d07..8f6b4f3 100644
--- a/solr/core/src/java/org/apache/solr/search/DocSet.java
+++ b/solr/core/src/java/org/apache/solr/search/DocSet.java
@@ -19,7 +19,6 @@ package org.apache.solr.search;
 
 import java.io.Closeable;
 
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.Accountable;
 import org.apache.solr.common.SolrException;
 
diff --git a/solr/core/src/java/org/apache/solr/search/DocSetBase.java b/solr/core/src/java/org/apache/solr/search/DocSetBase.java
index 3e54f8a..a37f049 100644
--- a/solr/core/src/java/org/apache/solr/search/DocSetBase.java
+++ b/solr/core/src/java/org/apache/solr/search/DocSetBase.java
@@ -21,10 +21,8 @@ import java.io.IOException;
 
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.BitDocIdSet;
 import org.apache.lucene.util.FixedBitSet;
diff --git a/solr/core/src/java/org/apache/solr/search/DocSetUtil.java b/solr/core/src/java/org/apache/solr/search/DocSetUtil.java
index f9047ee..8d141ac 100644
--- a/solr/core/src/java/org/apache/solr/search/DocSetUtil.java
+++ b/solr/core/src/java/org/apache/solr/search/DocSetUtil.java
@@ -20,10 +20,8 @@ package org.apache.solr.search;
 
 import java.io.IOException;
 import java.util.List;
-import java.util.Map;
 
 import org.apache.lucene.index.DirectoryReader;
-import org.apache.lucene.index.ExitableDirectoryReader;
 import org.apache.lucene.index.Fields;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
@@ -31,12 +29,9 @@ import org.apache.lucene.index.PostingsEnum;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
-import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
-import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.Bits;
diff --git a/solr/core/src/java/org/apache/solr/search/Filter.java b/solr/core/src/java/org/apache/solr/search/Filter.java
new file mode 100644
index 0000000..6f968a8
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/search/Filter.java
@@ -0,0 +1,144 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.ConstantScoreScorer;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.Explanation;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.TwoPhaseIterator;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
+
+/**
+ *  Convenient base class for building queries that only perform matching, but
+ *  no scoring. The scorer produced by such queries always returns 0 as score.
+ */
+public abstract class Filter extends Query {
+
+  private final boolean applyLazily;
+
+  /** Filter constructor. When {@code applyLazily} is true and the produced
+   *  {@link DocIdSet}s support {@link DocIdSet#bits() random-access}, Lucene
+   *  will only apply this filter after other clauses. */
+  protected Filter(boolean applyLazily) {
+    this.applyLazily = applyLazily;
+  }
+
+  /** Default Filter constructor that will use the
+   *  {@link DocIdSet#iterator() doc id set iterator} when consumed through
+   *  the {@link Query} API. */
+  protected Filter() {
+    this(false);
+  }
+
+  /**
+   * Creates a {@link DocIdSet} enumerating the documents that should be
+   * permitted in search results. <b>NOTE:</b> null can be
+   * returned if no documents are accepted by this Filter.
+   * <p>
+   * Note: This method will be called once per segment in
+   * the index during searching.  The returned {@link DocIdSet}
+   * must refer to document IDs for that segment, not for
+   * the top-level reader.
+   *
+   * @param context a {@link org.apache.lucene.index.LeafReaderContext} instance opened on the index currently
+   *         searched on. Note, it is likely that the provided reader info does not
+   *         represent the whole underlying index i.e. if the index has more than
+   *         one segment the given reader only represents a single segment.
+   *         The provided context is always an atomic context, so you can call
+   *         {@link org.apache.lucene.index.LeafReader#fields()}
+   *         on the context's reader, for example.
+   *
+   * @param acceptDocs
+   *          Bits that represent the allowable docs to match (typically deleted docs
+   *          but possibly filtering other documents)
+   *
+   * @return a DocIdSet that provides the documents which should be permitted or
+   *         prohibited in search results. <b>NOTE:</b> <code>null</code> should be returned if
+   *         the filter doesn't accept any documents otherwise internal optimization might not apply
+   *         in the case an <i>empty</i> {@link DocIdSet} is returned.
+   */
+  public abstract DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException;
+
+  //
+  // Query compatibility
+  //
+
+  @Override
+  public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {
+    return new Weight(this) {
+
+      @Override
+      public void extractTerms(Set<Term> terms) {}
+
+      @Override
+      public float getValueForNormalization() throws IOException {
+        return 0f;
+      }
+
+      @Override
+      public void normalize(float norm, float boost) {}
+
+      @Override
+      public Explanation explain(LeafReaderContext context, int doc) throws IOException {
+        final Scorer scorer = scorer(context);
+        final boolean match = (scorer != null && scorer.advance(doc) == doc);
+        if (match) {
+          assert scorer.score() == 0f;
+          return Explanation.match(0f, "Match on id " + doc);
+        } else {
+          return Explanation.match(0f, "No match on id " + doc);
+        }
+      }
+
+      @Override
+      public Scorer scorer(LeafReaderContext context) throws IOException {
+        final DocIdSet set = getDocIdSet(context, null);
+        if (set == null) {
+          return null;
+        }
+        if (applyLazily && set.bits() != null) {
+          final Bits bits = set.bits();
+          final DocIdSetIterator approximation = DocIdSetIterator.all(context.reader().maxDoc());
+          final TwoPhaseIterator twoPhase = new TwoPhaseIterator(approximation) {
+            @Override
+            public boolean matches() throws IOException {
+              return bits.get(approximation.docID());
+            }
+          };
+          return new ConstantScoreScorer(this, 0f, twoPhase);
+        }
+        final DocIdSetIterator iterator = set.iterator();
+        if (iterator == null) {
+          return null;
+        }
+        return new ConstantScoreScorer(this, 0f, iterator);
+      }
+
+    };
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/search/FilteredDocIdSet.java b/solr/core/src/java/org/apache/solr/search/FilteredDocIdSet.java
new file mode 100644
index 0000000..2cc6153
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/search/FilteredDocIdSet.java
@@ -0,0 +1,115 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.Collection;
+
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.FilteredDocIdSetIterator;
+import org.apache.lucene.util.Accountable;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.RamUsageEstimator;
+
+/**
+ * Abstract decorator class for a DocIdSet implementation
+ * that provides on-demand filtering/validation
+ * mechanism on a given DocIdSet.
+ *
+ * <p>
+ * Technically, this same functionality could be achieved
+ * with ChainedFilter (under queries/), however the
+ * benefit of this class is it never materializes the full
+ * bitset for the filter.  Instead, the {@link #match}
+ * method is invoked on-demand, per docID visited during
+ * searching.  If you know few docIDs will be visited, and
+ * the logic behind {@link #match} is relatively costly,
+ * this may be a better way to filter than ChainedFilter.
+ *
+ * @see DocIdSet
+ */
+
+public abstract class FilteredDocIdSet extends DocIdSet {
+  private final DocIdSet _innerSet;
+  
+  /**
+   * Constructor.
+   * @param innerSet Underlying DocIdSet
+   */
+  public FilteredDocIdSet(DocIdSet innerSet) {
+    _innerSet = innerSet;
+  }
+
+  /** Return the wrapped {@link DocIdSet}. */
+  public DocIdSet getDelegate() {
+    return _innerSet;
+  }
+
+  @Override
+  public long ramBytesUsed() {
+    return RamUsageEstimator.NUM_BYTES_OBJECT_REF + _innerSet.ramBytesUsed();
+  }
+  
+  @Override
+  public Collection<Accountable> getChildResources() {
+    return _innerSet.getChildResources();
+  }
+
+  @Override
+  public Bits bits() throws IOException {
+    final Bits bits = _innerSet.bits();
+    return (bits == null) ? null : new Bits() {
+      @Override
+      public boolean get(int docid) {
+        return bits.get(docid) && FilteredDocIdSet.this.match(docid);
+      }
+
+      @Override
+      public int length() {
+        return bits.length();
+      }
+    };
+  }
+
+  /**
+   * Validation method to determine whether a docid should be in the result set.
+   * @param docid docid to be tested
+   * @return true if input docid should be in the result set, false otherwise.
+   */
+  protected abstract boolean match(int docid);
+
+  /**
+   * Implementation of the contract to build a DocIdSetIterator.
+   * @see DocIdSetIterator
+   * @see FilteredDocIdSetIterator
+   */
+  @Override
+  public DocIdSetIterator iterator() throws IOException {
+    final DocIdSetIterator iterator = _innerSet.iterator();
+    if (iterator == null) {
+      return null;
+    }
+    return new FilteredDocIdSetIterator(iterator) {
+      @Override
+      protected boolean match(int docid) {
+        return FilteredDocIdSet.this.match(docid);
+      }
+    };
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/search/Grouping.java b/solr/core/src/java/org/apache/solr/search/Grouping.java
index f7c9137..7a0d466 100644
--- a/solr/core/src/java/org/apache/solr/search/Grouping.java
+++ b/solr/core/src/java/org/apache/solr/search/Grouping.java
@@ -36,7 +36,6 @@ import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.CachingCollector;
 import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.ScoreDoc;
diff --git a/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java
index fa8edc7..3b67a96 100644
--- a/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/HashQParserPlugin.java
@@ -18,49 +18,34 @@
 package org.apache.solr.search;
 
 import java.io.IOException;
-import java.io.Serializable;
 import java.util.List;
-import java.util.concurrent.ArrayBlockingQueue;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Semaphore;
-import java.util.concurrent.Future;
-import com.google.common.primitives.Longs;
 
+import org.apache.lucene.index.IndexReaderContext;
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.index.IndexReaderContext;
+import org.apache.lucene.index.NumericDocValues;
+import org.apache.lucene.index.SortedDocValues;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.LeafCollector;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.Weight;
 import org.apache.lucene.util.BitDocIdSet;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.CharsRef;
 import org.apache.lucene.util.CharsRefBuilder;
 import org.apache.lucene.util.FixedBitSet;
-
-import org.apache.lucene.util.Bits;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.solr.common.params.SolrParams;
-import org.apache.solr.common.util.SolrjNamedThreadFactory;
-import org.apache.solr.core.CloseHook;
+import org.apache.solr.common.util.NamedList;
 import org.apache.solr.request.SolrQueryRequest;
-import org.apache.solr.schema.IndexSchema;
 import org.apache.solr.schema.FieldType;
+import org.apache.solr.schema.IndexSchema;
 import org.apache.solr.schema.StrField;
-import org.apache.solr.schema.TrieField;
-import org.apache.solr.core.SolrCore;
 
-import org.apache.lucene.search.Query;
-import org.apache.lucene.search.ConstantScoreQuery;
-import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.Scorer;
-import org.apache.lucene.search.Weight;
-import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
-import org.apache.lucene.index.SortedDocValues;
-import org.apache.lucene.index.NumericDocValues;
-import org.apache.lucene.util.BytesRef;
-
-import org.apache.solr.common.util.NamedList;
+import com.google.common.primitives.Longs;
 
 /**
 * syntax fq={!hash workers=11 worker=4 keys=field1,field2}
diff --git a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
index 44e7e66..bdcfd6f 100644
--- a/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/JoinQParserPlugin.java
@@ -33,7 +33,6 @@ import org.apache.lucene.search.ConstantScoreScorer;
 import org.apache.lucene.search.ConstantScoreWeight;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
diff --git a/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java b/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java
new file mode 100644
index 0000000..24fc22e
--- /dev/null
+++ b/solr/core/src/java/org/apache/solr/search/QueryWrapperFilter.java
@@ -0,0 +1,102 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.search.BoostQuery;
+import org.apache.lucene.search.ConstantScoreQuery;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.NumericRangeQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.util.Bits;
+
+/** 
+ * Constrains search results to only match those which also match a provided
+ * query.  
+ *
+ * <p> This could be used, for example, with a {@link NumericRangeQuery} on a suitably
+ * formatted date field to implement date filtering.  One could re-use a single
+ * CachingWrapperFilter(QueryWrapperFilter) that matches, e.g., only documents modified 
+ * within the last week.  This would only need to be reconstructed once per day.
+ */
+public class QueryWrapperFilter extends Filter {
+  private final Query query;
+
+  /** Constructs a filter which only matches documents matching
+   * <code>query</code>.
+   */
+  public QueryWrapperFilter(Query query) {
+    if (query == null)
+      throw new NullPointerException("Query may not be null");
+    this.query = query;
+  }
+  
+  @Override
+  public Query rewrite(IndexReader reader) throws IOException {
+    return new BoostQuery(new ConstantScoreQuery(query), 0f);
+  }
+  
+  /** returns the inner Query */
+  public final Query getQuery() {
+    return query;
+  }
+
+  @Override
+  public DocIdSet getDocIdSet(final LeafReaderContext context, final Bits acceptDocs) throws IOException {
+    // get a private context that is used to rewrite, createWeight and score eventually
+    final LeafReaderContext privateContext = context.reader().getContext();
+    final Weight weight = new IndexSearcher(privateContext).createNormalizedWeight(query, false);
+    
+    DocIdSet set = new DocIdSet() {
+      @Override
+      public DocIdSetIterator iterator() throws IOException {
+        return weight.scorer(privateContext);
+      }
+
+      @Override
+      public long ramBytesUsed() {
+        return 0L;
+      }
+    };
+    return BitsFilteredDocIdSet.wrap(set, acceptDocs);
+  }
+
+  @Override
+  public String toString(String field) {
+    return "QueryWrapperFilter(" + query.toString(field) + ")";
+  }
+
+  @Override
+  public boolean equals(Object o) {
+    if (super.equals(o) == false) {
+      return false;
+    }
+    return this.query.equals(((QueryWrapperFilter)o).query);
+  }
+
+  @Override
+  public int hashCode() {
+    return 31 * super.hashCode() + query.hashCode();
+  }
+}
diff --git a/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java b/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
index 4d9d5f8..fec517b 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrConstantScoreQuery.java
@@ -3,14 +3,12 @@ package org.apache.solr.search;
 import java.io.IOException;
 import java.util.Map;
 
-import org.apache.lucene.index.IndexReader;
 import org.apache.lucene.index.LeafReaderContext;
 import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.ConstantScoreScorer;
 import org.apache.lucene.search.ConstantScoreWeight;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
diff --git a/solr/core/src/java/org/apache/solr/search/SolrFilter.java b/solr/core/src/java/org/apache/solr/search/SolrFilter.java
index 2383501..f1798d3 100644
--- a/solr/core/src/java/org/apache/solr/search/SolrFilter.java
+++ b/solr/core/src/java/org/apache/solr/search/SolrFilter.java
@@ -18,7 +18,6 @@
 package org.apache.solr.search;
 
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.util.Bits;
diff --git a/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java b/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
index 7b1349d..90aace0 100644
--- a/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
+++ b/solr/core/src/java/org/apache/solr/search/SortedIntDocSet.java
@@ -22,10 +22,8 @@ import java.util.Collections;
 
 import org.apache.lucene.index.LeafReader;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.Accountable;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
diff --git a/solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java b/solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java
index 2bcbccb..434b1e3 100644
--- a/solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java
+++ b/solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java
@@ -26,10 +26,8 @@ import org.apache.lucene.search.AutomatonQuery;
 import org.apache.lucene.search.BooleanClause;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.DocValuesTermsQuery;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
 import org.apache.lucene.util.BytesRefBuilder;
diff --git a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
index 389ebd7..c9a5e7a 100644
--- a/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
+++ b/solr/core/src/java/org/apache/solr/search/facet/FacetField.java
@@ -39,7 +39,6 @@ import org.apache.lucene.index.Terms;
 import org.apache.lucene.index.TermsEnum;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.util.BytesRef;
@@ -54,6 +53,7 @@ import org.apache.solr.schema.FieldType;
 import org.apache.solr.schema.SchemaField;
 import org.apache.solr.schema.TrieField;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.HashDocSet;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.search.SortedIntDocSet;
diff --git a/solr/core/src/java/org/apache/solr/search/function/ValueSourceRangeFilter.java b/solr/core/src/java/org/apache/solr/search/function/ValueSourceRangeFilter.java
index 240f516..b411e8b 100644
--- a/solr/core/src/java/org/apache/solr/search/function/ValueSourceRangeFilter.java
+++ b/solr/core/src/java/org/apache/solr/search/function/ValueSourceRangeFilter.java
@@ -22,8 +22,8 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.IndexSearcher;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.util.Bits;
+import org.apache.solr.search.BitsFilteredDocIdSet;
 import org.apache.solr.search.SolrFilter;
 
 import java.io.IOException;
diff --git a/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java b/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
index 1b03ef2..6e69e48 100644
--- a/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
+++ b/solr/core/src/java/org/apache/solr/search/grouping/CommandHandler.java
@@ -27,14 +27,12 @@ import org.apache.lucene.queries.function.ValueSource;
 import org.apache.lucene.search.BooleanClause.Occur;
 import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.Collector;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.MultiCollector;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.TimeLimitingCollector;
 import org.apache.lucene.search.TotalHitCountCollector;
 import org.apache.lucene.search.grouping.AbstractAllGroupHeadsCollector;
 import org.apache.lucene.search.grouping.function.FunctionAllGroupHeadsCollector;
-import org.apache.lucene.search.grouping.function.FunctionAllGroupsCollector;
 import org.apache.lucene.search.grouping.term.TermAllGroupHeadsCollector;
 import org.apache.solr.common.util.NamedList;
 import org.apache.solr.schema.FieldType;
diff --git a/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParser.java b/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParser.java
index abdce80..c93e482 100644
--- a/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParser.java
+++ b/solr/core/src/java/org/apache/solr/search/join/BlockJoinParentQParser.java
@@ -20,13 +20,10 @@ package org.apache.solr.search.join;
 import java.io.IOException;
 
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.Query;
-import org.apache.lucene.search.QueryWrapperFilter;
-import org.apache.lucene.search.join.QueryBitSetProducer;
 import org.apache.lucene.search.join.BitSetProducer;
+import org.apache.lucene.search.join.QueryBitSetProducer;
 import org.apache.lucene.search.join.ScoreMode;
 import org.apache.lucene.search.join.ToParentBlockJoinQuery;
 import org.apache.lucene.util.BitDocIdSet;
@@ -34,6 +31,8 @@ import org.apache.lucene.util.BitSet;
 import org.apache.lucene.util.Bits;
 import org.apache.solr.common.params.SolrParams;
 import org.apache.solr.request.SolrQueryRequest;
+import org.apache.solr.search.BitsFilteredDocIdSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.QParser;
 import org.apache.solr.search.QueryParsing;
 import org.apache.solr.search.SolrCache;
@@ -96,7 +95,7 @@ class BlockJoinParentQParser extends QParser {
   }
 
   private BitSetProducer createParentFilter(Query parentQ) {
-    return new QueryBitSetProducer(new QueryWrapperFilter(parentQ));
+    return new QueryBitSetProducer(parentQ);
   }
 
   // We need this wrapper since BitDocIdSetFilter does not extend Filter
diff --git a/solr/core/src/java/org/apache/solr/search/join/GraphQuery.java b/solr/core/src/java/org/apache/solr/search/join/GraphQuery.java
index 7dff2e9..17647b0 100644
--- a/solr/core/src/java/org/apache/solr/search/join/GraphQuery.java
+++ b/solr/core/src/java/org/apache/solr/search/join/GraphQuery.java
@@ -33,7 +33,6 @@ import org.apache.lucene.search.BooleanQuery;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
 import org.apache.lucene.search.Explanation;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.Query;
 import org.apache.lucene.search.Scorer;
@@ -48,6 +47,7 @@ import org.apache.lucene.util.automaton.DaciukMihovAutomatonBuilder;
 import org.apache.solr.handler.component.ResponseBuilder;
 import org.apache.solr.search.BitDocSet;
 import org.apache.solr.search.DocSet;
+import org.apache.solr.search.Filter;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
diff --git a/solr/core/src/test/org/apache/solr/search/TestDocSet.java b/solr/core/src/test/org/apache/solr/search/TestDocSet.java
index 6fb425a..bdd5844 100644
--- a/solr/core/src/test/org/apache/solr/search/TestDocSet.java
+++ b/solr/core/src/test/org/apache/solr/search/TestDocSet.java
@@ -38,7 +38,6 @@ import org.apache.lucene.index.SortedSetDocValues;
 import org.apache.lucene.index.StoredFieldVisitor;
 import org.apache.lucene.search.DocIdSet;
 import org.apache.lucene.search.DocIdSetIterator;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.util.BitSetIterator;
 import org.apache.lucene.util.Bits;
 import org.apache.lucene.util.FixedBitSet;
diff --git a/solr/core/src/test/org/apache/solr/search/TestFilteredDocIdSet.java b/solr/core/src/test/org/apache/solr/search/TestFilteredDocIdSet.java
new file mode 100644
index 0000000..de3c849
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/search/TestFilteredDocIdSet.java
@@ -0,0 +1,202 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Iterator;
+
+import junit.framework.Assert;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.DocIdSetIterator;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestFilteredDocIdSet extends LuceneTestCase {
+  public void testFilteredDocIdSet() throws Exception {
+    final int maxdoc=10;
+    final DocIdSet innerSet = new DocIdSet() {
+
+      @Override
+      public long ramBytesUsed() {
+        return 0L;
+      }
+
+        @Override
+        public DocIdSetIterator iterator() {
+          return new DocIdSetIterator() {
+
+            int docid = -1;
+            
+            @Override
+            public int docID() {
+              return docid;
+            }
+            
+            @Override
+            public int nextDoc() {
+              docid++;
+              return docid < maxdoc ? docid : (docid = NO_MORE_DOCS);
+            }
+
+            @Override
+            public int advance(int target) throws IOException {
+              return slowAdvance(target);
+            }
+            
+            @Override
+            public long cost() {
+              return 1;
+            } 
+          };
+        } 
+      };
+
+
+    DocIdSet filteredSet = new FilteredDocIdSet(innerSet){
+        @Override
+        protected boolean match(int docid) {
+          return docid%2 == 0;  //validate only even docids
+        }
+      };
+
+    DocIdSetIterator iter = filteredSet.iterator();
+    ArrayList<Integer> list = new ArrayList<>();
+    int doc = iter.advance(3);
+    if (doc != DocIdSetIterator.NO_MORE_DOCS) {
+      list.add(Integer.valueOf(doc));
+      while((doc = iter.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
+        list.add(Integer.valueOf(doc));
+      }
+    }
+
+    int[] docs = new int[list.size()];
+    int c=0;
+    Iterator<Integer> intIter = list.iterator();
+    while(intIter.hasNext()) {
+      docs[c++] = intIter.next().intValue();
+    }
+    int[] answer = new int[]{4,6,8};
+    boolean same = Arrays.equals(answer, docs);
+    if (!same) {
+      System.out.println("answer: " + Arrays.toString(answer));
+      System.out.println("gotten: " + Arrays.toString(docs));
+      fail();
+    }
+  }
+  
+  public void testNullDocIdSet() throws Exception {
+    // Tests that if a Filter produces a null DocIdSet, which is given to
+    // IndexSearcher, everything works fine. This came up in LUCENE-1754.
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(newStringField("c", "val", Field.Store.NO));
+    writer.addDocument(doc);
+    IndexReader reader = writer.getReader();
+    writer.close();
+    
+    // First verify the document is searchable.
+    IndexSearcher searcher = newSearcher(reader);
+    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
+    
+    // Now search w/ a Filter which returns a null DocIdSet
+    Filter f = new Filter() {
+      @Override
+      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
+        return null;
+      }
+      @Override
+      public String toString(String field) {
+        return "nullDocIdSetFilter";
+      }
+    };
+
+    Query filtered = new BooleanQuery.Builder()
+        .add(new MatchAllDocsQuery(), Occur.MUST)
+        .add(f, Occur.FILTER)
+        .build();
+    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);
+    reader.close();
+    dir.close();
+  }
+
+  public void testNullIteratorFilteredDocIdSet() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(newStringField("c", "val", Field.Store.NO));
+    writer.addDocument(doc);
+    IndexReader reader = writer.getReader();
+    writer.close();
+    
+    // First verify the document is searchable.
+    IndexSearcher searcher = newSearcher(reader);
+    Assert.assertEquals(1, searcher.search(new MatchAllDocsQuery(), 10).totalHits);
+    
+      // Now search w/ a Filter which returns a null DocIdSet
+    Filter f = new Filter() {
+      @Override
+      public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) {
+        final DocIdSet innerNullIteratorSet = new DocIdSet() {
+          @Override
+          public DocIdSetIterator iterator() {
+            return null;
+          } 
+
+          @Override
+          public long ramBytesUsed() {
+            return 0L;
+          }
+        };
+        return new FilteredDocIdSet(innerNullIteratorSet) {
+          @Override
+          protected boolean match(int docid) {
+            return true;
+          }
+        };
+      }
+      @Override
+      public String toString(String field) {
+        return "nullDocIdSetFilter";
+      }
+    };
+    
+    Query filtered = new BooleanQuery.Builder()
+        .add(new MatchAllDocsQuery(), Occur.MUST)
+        .add(f, Occur.FILTER)
+        .build();
+    Assert.assertEquals(0, searcher.search(filtered, 10).totalHits);
+    reader.close();
+    dir.close();
+  }
+
+}
diff --git a/solr/core/src/test/org/apache/solr/search/TestQueryWrapperFilter.java b/solr/core/src/test/org/apache/solr/search/TestQueryWrapperFilter.java
new file mode 100644
index 0000000..df33e86
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/search/TestQueryWrapperFilter.java
@@ -0,0 +1,240 @@
+package org.apache.solr.search;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import java.io.IOException;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.apache.lucene.document.Document;
+import org.apache.lucene.document.Field;
+import org.apache.lucene.document.Field.Store;
+import org.apache.lucene.document.StringField;
+import org.apache.lucene.index.IndexReader;
+import org.apache.lucene.index.LeafReaderContext;
+import org.apache.lucene.index.RandomIndexWriter;
+import org.apache.lucene.index.Term;
+import org.apache.lucene.search.BooleanClause.Occur;
+import org.apache.lucene.search.BooleanQuery;
+import org.apache.lucene.search.DocIdSet;
+import org.apache.lucene.search.FuzzyQuery;
+import org.apache.lucene.search.IndexSearcher;
+import org.apache.lucene.search.Query;
+import org.apache.lucene.search.RandomApproximationQuery;
+import org.apache.lucene.search.ScoreDoc;
+import org.apache.lucene.search.Scorer;
+import org.apache.lucene.search.TermQuery;
+import org.apache.lucene.search.TopDocs;
+import org.apache.lucene.search.Weight;
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.util.Bits;
+import org.apache.lucene.util.English;
+import org.apache.lucene.util.LuceneTestCase;
+
+public class TestQueryWrapperFilter extends LuceneTestCase {
+
+  // a filter for which other queries don't have special rewrite rules
+  private static class FilterWrapper extends Filter {
+
+    private final Filter in;
+    
+    FilterWrapper(Filter in) {
+      this.in = in;
+    }
+    
+    @Override
+    public DocIdSet getDocIdSet(LeafReaderContext context, Bits acceptDocs) throws IOException {
+      return in.getDocIdSet(context, acceptDocs);
+    }
+
+    @Override
+    public String toString(String field) {
+      return in.toString(field);
+    }
+    
+    @Override
+    public boolean equals(Object obj) {
+      if (super.equals(obj) == false) {
+        return false;
+      }
+      return in.equals(((FilterWrapper) obj).in);
+    }
+
+    @Override
+    public int hashCode() {
+      return 31 * super.hashCode() + in.hashCode();
+    }
+  }
+
+  public void testBasic() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(newTextField("field", "value", Field.Store.NO));
+    writer.addDocument(doc);
+    IndexReader reader = writer.getReader();
+    writer.close();
+
+    TermQuery termQuery = new TermQuery(new Term("field", "value"));
+
+    // should not throw exception with primitive query
+    QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
+
+    IndexSearcher searcher = newSearcher(reader);
+    TopDocs hits = searcher.search(qwf, 10);
+    assertEquals(1, hits.totalHits);
+    hits = searcher.search(new FilterWrapper(qwf), 10);
+    assertEquals(1, hits.totalHits);
+
+    // should not throw exception with complex primitive query
+    BooleanQuery.Builder booleanQuery = new BooleanQuery.Builder();
+    booleanQuery.add(termQuery, Occur.MUST);
+    booleanQuery.add(new TermQuery(new Term("field", "missing")),
+        Occur.MUST_NOT);
+    qwf = new QueryWrapperFilter(termQuery);
+
+    hits = searcher.search(qwf, 10);
+    assertEquals(1, hits.totalHits);
+    hits = searcher.search(new FilterWrapper(qwf), 10);
+    assertEquals(1, hits.totalHits);
+
+    // should not throw exception with non primitive Query (doesn't implement
+    // Query#createWeight)
+    qwf = new QueryWrapperFilter(new FuzzyQuery(new Term("field", "valu")));
+
+    hits = searcher.search(qwf, 10);
+    assertEquals(1, hits.totalHits);
+    hits = searcher.search(new FilterWrapper(qwf), 10);
+    assertEquals(1, hits.totalHits);
+
+    // test a query with no hits
+    termQuery = new TermQuery(new Term("field", "not_exist"));
+    qwf = new QueryWrapperFilter(termQuery);
+    hits = searcher.search(qwf, 10);
+    assertEquals(0, hits.totalHits);
+    hits = searcher.search(new FilterWrapper(qwf), 10);
+    assertEquals(0, hits.totalHits);
+    reader.close();
+    dir.close();
+  }
+
+  public void testRandom() throws Exception {
+    final Directory d = newDirectory();
+    final RandomIndexWriter w = new RandomIndexWriter(random(), d);
+    w.w.getConfig().setMaxBufferedDocs(17);
+    final int numDocs = atLeast(100);
+    final Set<String> aDocs = new HashSet<>();
+    for(int i=0;i<numDocs;i++) {
+      final Document doc = new Document();
+      final String v;
+      if (random().nextInt(5) == 4) {
+        v = "a";
+        aDocs.add(""+i);
+      } else {
+        v = "b";
+      }
+      final Field f = newStringField("field", v, Field.Store.NO);
+      doc.add(f);
+      doc.add(newStringField("id", ""+i, Field.Store.YES));
+      w.addDocument(doc);
+    }
+
+    final int numDelDocs = atLeast(10);
+    for(int i=0;i<numDelDocs;i++) {
+      final String delID = ""+random().nextInt(numDocs);
+      w.deleteDocuments(new Term("id", delID));
+      aDocs.remove(delID);
+    }
+
+    final IndexReader r = w.getReader();
+    w.close();
+    final TopDocs hits = newSearcher(r).search(new QueryWrapperFilter(new TermQuery(new Term("field", "a"))),
+                                                     numDocs);
+    assertEquals(aDocs.size(), hits.totalHits);
+    for(ScoreDoc sd: hits.scoreDocs) {
+      assertTrue(aDocs.contains(r.document(sd.doc).get("id")));
+    }
+    r.close();
+    d.close();
+  }
+  
+  public void testThousandDocuments() throws Exception {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    for (int i = 0; i < 1000; i++) {
+      Document doc = new Document();
+      doc.add(newStringField("field", English.intToEnglish(i), Field.Store.NO));
+      writer.addDocument(doc);
+    }
+    
+    IndexReader reader = writer.getReader();
+    writer.close();
+    
+    IndexSearcher searcher = newSearcher(reader);
+    
+    for (int i = 0; i < 1000; i++) {
+      TermQuery termQuery = new TermQuery(new Term("field", English.intToEnglish(i)));
+      QueryWrapperFilter qwf = new QueryWrapperFilter(termQuery);
+      TopDocs td = searcher.search(qwf, 10);
+      assertEquals(1, td.totalHits);
+    }
+    
+    reader.close();
+    dir.close();
+  }
+
+  public void testScore() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(new StringField("foo", "bar", Store.NO));
+    writer.addDocument(doc);
+    writer.commit();
+    final IndexReader reader = writer.getReader();
+    writer.close();
+    final IndexSearcher searcher = new IndexSearcher(reader);
+    final Query query = new QueryWrapperFilter(new TermQuery(new Term("foo", "bar")));
+    final TopDocs topDocs = searcher.search(query, 1);
+    assertEquals(1, topDocs.totalHits);
+    assertEquals(0f, topDocs.scoreDocs[0].score, 0f);
+    reader.close();
+    dir.close();
+  }
+
+  public void testQueryWrapperFilterPropagatesApproximations() throws IOException {
+    Directory dir = newDirectory();
+    RandomIndexWriter writer = new RandomIndexWriter(random(), dir);
+    Document doc = new Document();
+    doc.add(new StringField("foo", "bar", Store.NO));
+    writer.addDocument(doc);
+    writer.commit();
+    final IndexReader reader = writer.getReader();
+    writer.close();
+    final IndexSearcher searcher = new IndexSearcher(reader);
+    searcher.setQueryCache(null); // to still have approximations
+    final Query query = new QueryWrapperFilter(new RandomApproximationQuery(new TermQuery(new Term("foo", "bar")), random()));
+    final Weight weight = searcher.createNormalizedWeight(query, random().nextBoolean());
+    final Scorer scorer = weight.scorer(reader.leaves().get(0));
+    assertNotNull(scorer.asTwoPhaseIterator());
+    reader.close();
+    dir.close();
+  }
+
+  public void testBasics() {
+    org.apache.lucene.search.QueryUtils.check(new QueryWrapperFilter(new TermQuery(new Term("foo", "bar"))));
+  }
+}
diff --git a/solr/core/src/test/org/apache/solr/search/TestSort.java b/solr/core/src/test/org/apache/solr/search/TestSort.java
index 41bd79c..728d252 100644
--- a/solr/core/src/test/org/apache/solr/search/TestSort.java
+++ b/solr/core/src/test/org/apache/solr/search/TestSort.java
@@ -34,15 +34,12 @@ import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexWriter;
 import org.apache.lucene.index.IndexWriterConfig;
 import org.apache.lucene.index.LeafReaderContext;
-import org.apache.lucene.search.BitsFilteredDocIdSet;
 import org.apache.lucene.search.Collector;
 import org.apache.lucene.search.DocIdSet;
-import org.apache.lucene.search.Filter;
 import org.apache.lucene.search.FilterCollector;
 import org.apache.lucene.search.FilterLeafCollector;
 import org.apache.lucene.search.IndexSearcher;
 import org.apache.lucene.search.LeafCollector;
-import org.apache.lucene.search.MatchAllDocsQuery;
 import org.apache.lucene.search.ScoreDoc;
 import org.apache.lucene.search.Sort;
 import org.apache.lucene.search.SortField;
diff --git a/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java b/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
index 177e77c..0816f6b 100644
--- a/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
+++ b/solr/core/src/test/org/apache/solr/update/AddBlockUpdateTest.java
@@ -39,7 +39,6 @@ import javax.xml.stream.XMLStreamReader;
 
 import org.apache.commons.io.output.ByteArrayOutputStream;
 import org.apache.lucene.index.Term;
-import org.apache.lucene.search.QueryWrapperFilter;
 import org.apache.lucene.search.TermQuery;
 import org.apache.lucene.search.TermRangeQuery;
 import org.apache.lucene.search.TopDocs;
@@ -53,6 +52,7 @@ import org.apache.solr.common.SolrInputDocument;
 import org.apache.solr.common.util.ExecutorUtil;
 import org.apache.solr.common.util.JavaBinCodec;
 import org.apache.solr.handler.loader.XMLLoader;
+import org.apache.solr.search.QueryWrapperFilter;
 import org.apache.solr.search.SolrIndexSearcher;
 import org.apache.solr.util.DefaultSolrThreadFactory;
 import org.apache.solr.util.RefCounted;
@@ -562,8 +562,8 @@ public class AddBlockUpdateTest extends SolrTestCaseJ4 {
   
   protected ToParentBlockJoinQuery join(final String childTerm) {
     return new ToParentBlockJoinQuery(
-        new TermQuery(new Term(child, childTerm)), new QueryBitSetProducer(new QueryWrapperFilter(
-            new TermRangeQuery(parent, null, null, false, false))), ScoreMode.None);
+        new TermQuery(new Term(child, childTerm)), new QueryBitSetProducer(
+            new TermRangeQuery(parent, null, null, false, false)), ScoreMode.None);
   }
   
   private Collection<? extends Callable<Void>> callables(List<Document> blocks) {

